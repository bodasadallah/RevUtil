{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more analysis around the quality of the collected dataset and the potential noise it might contain. While it implies that the authors should conduct additional analysis, it does not specify what kind of analysis is needed or how to conduct it. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the artificially created dataset and its potential noise, specifically mentioning the \"pristine\" set of tweets and out-of-context images. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that more analysis is needed around the quality of the dataset and the amount of noise it might have. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the dataset might have noise due to the artificial creation process, and it provides a specific example of the \"pristine\" set of tweets that might contain misinformation or out-of-context images. However, the comment lacks specific examples or references to support the claim that the dataset is indeed noisy. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the issue without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset, suggesting that it might contain noise due to its artificial creation process. It provides a specific example of the \"pristine\" set of tweets that might not be pristine enough and could contain misinformation or out-of-context images. This feedback is valuable as it highlights a potential weakness in the dataset that the authors should address. However, the comment could be more helpful if it suggested specific analyses or methods to evaluate the dataset's quality and noise level. Overall, the comment is mostly helpful as it points out a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific theoretical aspects to explore or methods to demonstrate convergence. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where these aspects should be addressed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the theory profs or convergence properties should be explored or demonstrated. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that it does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. This feedback is clear and actionable, as it points out a critical area where the paper could be improved by providing more theoretical analysis and experimental evidence. However, the comment could be more helpful if it offered specific suggestions on how to address these gaps, such as recommending specific theoretical frameworks or methods to demonstrate convergence. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the authors\\' choice of operators and suggests considering the \"and\" operator or element-wise max. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The authors are left to infer that they should consider these alternatives, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections, \"261\" and \"272,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the authors\\' choice of operators and suggesting that the \"and\" operator or element-wise max might be better options. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' choice of operators and suggests considering the \"and\" operator or element-wise max. However, it does not provide any reasoning, examples, or references to support why these alternatives might be better options. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the authors\\' choice of operators and suggests considering the \"and\" operator or element-wise max. This feedback is somewhat helpful as it identifies a potential area for improvement by questioning the authors\\' choice of operators, which could enhance the clarity and understanding of their work. However, the comment lacks specific guidance or examples on how to implement these changes or why they might be beneficial. While it points out a potential weakness, it does not provide detailed instructions or suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the description of HIERENC is unclear and suggests that it might introduce noise due to the averaging of multiple contextual representations. However, it does not provide explicit guidance on how to clarify the description or address the issue of noise. The authors are left to infer that they need to clarify the description and possibly reconsider the averaging approach. While the comment identifies a potential problem, it lacks concrete instructions on how to resolve it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, explaining that the averaging of multiple contextual representations might introduce noise and suggesting that only one instantiation is likely correct. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of HIERENC is unclear and suggests that averaging multiple contextual representations might introduce noise. The reviewer provides a logical reasoning by explaining that only one instantiation is likely correct and that averaging multiple representations could lead to noise. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning and potential consequences to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of HIERENC, noting that the averaging of multiple contextual representations might introduce noise. It provides a logical reasoning that only one instantiation is likely correct, which could lead to noise. This feedback is clear and actionable, as it points out a potential weakness in the description and suggests a possible improvement. However, the comment could be more helpful if it provided specific suggestions on how to clarify the description or address the issue of noise. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification or explanation for their choice. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors mention selecting 10 answers from all correct answers, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the potential impact of this selection on the underestimation of performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the selection of only 10 answers from all correct answers and its potential impact on performance underestimation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. This is a relevant question that could prompt the authors to reconsider their methodology or provide additional context to explain their choice. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a discrepancy in the description of the data sources, specifically noting that line 226-238 suggests the authors selected sentences from raw data, while line 242-244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This feedback provides a clear and explicit action for the authors to take, specifying exactly what needs to be revised to improve the clarity of the description. The action is concrete and leaves no ambiguity, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (226-238 and 242-244) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the description of the data sources, suggesting that the authors should revise the description to mention Li et al. (2019a) earlier to clarify and improve the precision of the information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a discrepancy in the description of the data sources, specifically noting that line 226-238 suggests the authors selected sentences from raw data, while line 242-244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This claim is somewhat verifiable as it provides a logical reasoning for the suggested revision, but it lacks specific examples or references to support the claim fully. The authors would need to make an effort to verify the claim by revisiting the lines in question and considering the suggested revision. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific discrepancy in the description of the data sources, noting that line 226-238 suggests the authors selected sentences from raw data, while line 242-244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This feedback is clear and actionable, as it provides a concrete suggestion for how the authors can revise their description to avoid confusion and ensure clarity. By addressing this issue, the authors can improve the accuracy and comprehensibility of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the purpose of the average duration reported in Table 1 and asks for a supporting explanation. It does not provide explicit instructions or suggestions for the authors to follow, but it implies that the authors should clarify the purpose of the reported duration and potentially include information about the time spent by the user waiting for the model to generate a response. While the action is implied, it is clear and concrete, as it guides the authors to provide a more detailed explanation or clarification in their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in Table 1 and requests a supporting explanation, including whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the purpose of the average duration reported in Table 1 and requests a supporting explanation. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification and does not present an argument or claim that needs justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the purpose of the average duration reported in Table 1, noting the lack of a supporting explanation. It highlights an area where the authors could provide more clarity and context for their readers. By asking for a clearer explanation, the comment prompts the authors to consider how their readers might interpret the reported duration and whether it includes time spent by the user waiting for the model to generate a response. This feedback is somewhat helpful as it identifies a potential gap in the paper that could be addressed to enhance its clarity and comprehensibility. However, it could be more helpful if it offered specific suggestions on how to provide the requested explanation or what additional context might be beneficial. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests clarification on the splits used for obtaining the ATIS numbers in Table 4. This is a direct and concrete action for the authors to take, as it clearly identifies the specific area that needs clarification. The comment also expresses gratitude for the authors\\' response, which implies that the authors have already addressed this issue. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the splits used for obtaining the ATIS numbers. This provides clear guidance on what the authors need to address to improve the clarity of their work. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests clarification on the splits used for obtaining the ATIS numbers in Table 4. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual request for additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of clarity needed in the paper, specifically regarding the splits used for obtaining the ATIS numbers in Table 4. By asking for clarification, the reviewer provides actionable feedback that can help the authors improve the transparency and understandability of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is somewhat helpful as it directs the authors to a clear area for improvement but lacks depth in its guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It suggests that there may be a cognitive bias among NLP researchers to phrase results in a certain way, and it recommends correcting the wording. However, the comment does not provide specific guidance on how to rephrase the sentence or what alternative phrasing would be more appropriate. While the action is implicit, as the authors can infer that they need to revise the wording, the lack of concrete details makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.791,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, suggesting that the authors should correct the phrase \"on par or better\" to avoid a cognitive bias among NLP researchers. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a general cognitive bias among NLP researchers to phrase results in a certain way, specifically by mapping instances where they perform worse to \"on par\" and the rest to \"better.\" The reviewer suggests that the wording in the paper should be corrected, but does not provide specific examples or references to support this claim. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. The authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It points out a potential cognitive bias among NLP researchers to phrase results in a certain way, which could lead to misinterpretation. The reviewer suggests correcting the wording to avoid this bias. While the comment highlights an important area for improvement, it lacks specific guidance on how to rephrase the sentence or what alternative phrasing would be more appropriate. This limits the comment\\'s helpfulness, as it provides a clear direction but does not offer detailed suggestions for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOS-Q and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOS-V. While the comment identifies areas of confusion, it does not provide explicit instructions or suggestions on how to address these issues. The authors are left to infer that they need to clarify or explain these points, but without concrete guidance, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning the interpretation of results, particularly regarding the comparison between NVSB and GT Mel A for Chinese MOS-Q and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOS-V. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions about the interpretation of results in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOS-Q and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOS-V. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOS-Q and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOS-V. While it identifies areas of confusion, it does not provide any guidance or suggestions on how the authors might address these issues or clarify the interpretation of the results. The feedback lacks actionable advice or detailed analysis, making it barely helpful for the authors in improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a formatting issue in Tables 2 and 3, specifically noting the inconsistent spacing between accuracy and standard deviation. This is an explicit observation that the authors can directly address by ensuring consistent spacing in their tables. The comment provides a clear and concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation in these tables, which affects the presentation\\'s aesthetics. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that inconsistent spacing between accuracy and standard deviation in Tables 2 and 3 affects the presentation\\'s aesthetics. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific formatting issue in Tables 2 and 3, noting inconsistent spacing between accuracy and standard deviation. This is a clear and actionable observation that the authors can address to improve the presentation of their data. By pointing out this inconsistency, the comment provides valuable feedback that can help the authors enhance the aesthetics and readability of their tables. However, the comment could be more helpful if it offered suggestions on how to standardize the spacing or provided examples of how other tables in the field handle this issue. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing antecedent in the text and suggests checking the references for format issues, such as capitalization and bibliographic details. While the comment identifies a specific issue with the references, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to check the references for formatting errors, but the comment lacks concrete details on what specific issues to look for or how to correct them. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the line number \"781,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the references, suggesting that they should be checked for format, such as capitalization and bibliographic details. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing antecedent in the text and suggests checking the references for formatting issues, such as capitalization and bibliographic details. However, the comment does not provide any specific examples or references to support the claim that the references are missing or incorrectly formatted. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that there is a missing antecedent in the text. It also suggests checking the references for formatting issues, such as capitalization and bibliographic details. While the comment provides some actionable feedback, it lacks depth and does not offer detailed guidance on how to address the formatting issues or what specific changes are needed. The authors are given a clear direction but may need to infer more detailed instructions to fully resolve the issue. Therefore, the comment is somewhat helpful, as it points out a specific problem but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and image-text models, and that the paper summarizes this work. The reviewer suggests that the only new effort is to apply similar ideas to video-text models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the novelty or what specific aspects of the paper could be revised to enhance its originality. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a lack of novelty in the paper, specifically mentioning that adversarial attacks on text have been done on many NLP and image-text models, and that the paper summarizes this work. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered a lack of novelty, namely the application of similar ideas to video-text models. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, specifically mentioning that adversarial attacks on text have been done on many NLP and image-text models. It further notes that the paper summarizes this work and only adds a new effort by applying similar ideas to video-text models. The comment is somewhat verifiable as it provides a logical reasoning for the claim, but it lacks specific examples or references to substantiate the claim fully. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and image-text models. It highlights that the paper summarizes this work and only adds a new effort by applying similar ideas to video-text models. While the comment points out a potential issue with the paper\\'s originality, it does not provide specific suggestions or guidance on how the authors might address this lack of novelty or enhance the originality of their work. The feedback is somewhat helpful as it alerts the authors to a potential weakness, but it lacks actionable advice or detailed insights to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It provides a clear and concrete suggestion to improve the organization of the section by recommending separate paragraphs for lexical features and sentence-level features. This explicit guidance offers a direct action for the authors to take, making the comment highly actionable. Authors know exactly what changes to make to improve the clarity and coherence of their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the intertwined explanations for features and the suggestion to organize the section with separate paragraphs for lexical features and sentence-level features. This provides clear guidance on how to improve the clarity and coherence of the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It suggests that the section would be more coherent with separate paragraphs for lexical features and sentence-level features. While the comment provides a logical reasoning for the suggested improvement, it lacks specific examples or references to support the claim that the current organization is confusing. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization and clarity of the explanations for features in Section 3.2. It suggests that the section would be more coherent and easier to understand with separate paragraphs dedicated to lexical features and sentence-level features. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the organization and readability of their draft. By following this advice, the authors can enhance the clarity and comprehensibility of their explanations, which is valuable for improving the overall quality of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a more concise presentation or offering suggestions for prioritizing content. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not specify which section or part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the assumptions or experimental results are problematic or how they could be improved. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that dedicating a whole section and experimental results for the assumptions is a significant amount of space. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it could be improved. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not provide any specific guidance or suggestions on how the authors might address this issue, such as by streamlining the content or focusing on the most important aspects. The comment lacks actionable feedback, leaving the authors without a clear path forward to improve their draft. Therefore, it is rated as barely helpful, as it identifies a potential issue but does not offer detailed guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include an ablation study to evaluate the importance of the post-processing steps proposed to filter out \"false-positive\" neurons. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment somewhat actionable. The authors can infer that they need to conduct an ablation study but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of integrated gradients to measure attribution and the proposed post-processing steps to filter out \"false-positive\" neurons. It also suggests an ablation study, providing clear guidance on what needs to be addressed. However, the comment does not specify which part of the paper should include the ablation study, making it fully grounded but under-specific. Therefore, this comment is categorized as fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that using integrated gradients to measure attribution has been studied in existing papers and suggests that an ablation study may be needed to evaluate the importance of the post-processing steps proposed to filter out \"false-positive\" neurons. However, the comment lacks specific references to these existing studies or detailed reasoning to support the claim that an ablation study is necessary. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered somewhat verifiable, as it provides a logical suggestion but lacks the necessary evidence or detailed reasoning to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that could be improved by suggesting an ablation study to evaluate the importance of the post-processing steps proposed to filter out \"false-positive\" neurons. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance their work. However, the comment could be more helpful if it explained why an ablation study is necessary or how it would benefit the paper. Despite this, the suggestion is valuable and provides a clear direction for the authors to improve their draft. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how an antecedent is identified when the prediction is a pronoun, and it suggests a method of matching the head of noun phrases. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the method. The comment lacks concrete instructions or examples, leaving the authors uncertain about how to implement the suggested approach. Therefore, the comment is somewhat actionable, as it identifies a potential issue but does not offer detailed guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to identifying antecedents in the context of a prediction involving a pronoun. It suggests a method of matching the head of noun phrases, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but the comment lacks explicit grounding. The comment is specific in detailing the issue with identifying antecedents in the context of a pronoun, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about identifying antecedents in the context of a prediction involving a pronoun. It suggests a method of matching the head of noun phrases, but it does not provide any supporting evidence, reasoning, or references to justify the claim that this method is insufficient. The comment lacks detailed explanation or examples, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the methodology proposed by the authors, specifically regarding the identification of antecedents in the context of a prediction involving a pronoun. It raises a valid point about the limitations of the proposed method when the head word is not a pronoun. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it highlights a potential weakness, it lacks actionable advice or detailed feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it points out a specific area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It implies that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a potential area for improvement, it does not provide explicit instructions on how to incorporate these baselines or what specific aspects of the comparison should be addressed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"MST baseline\" and suggests that it might be an example of a model that only considers different senses but not sememes. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more baselines based on related work to clarify the comparison between the proposed models and those that only consider different senses. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. The comment provides a logical reasoning by pointing out the potential comparison between the MST baseline and models that only consider different senses. However, it lacks specific examples or references to support the claim that the inclusion of more baselines would strengthen the paper. Therefore, the claim is somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper regarding the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and proposes that the paper would be strengthened by including more baselines based on related work. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their comparison and strengthen their paper. However, the comment could be more helpful if it offered specific examples of related work or baselines that should be considered. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the abstract could be improved by providing an example of the inconsistency between evaluating with gold answers and human evaluation. While the comment implies that the authors should include such an example, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include an example to make the abstract more effective. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved: adding an example of the inconsistency between evaluating with gold answers and human evaluation. This specificity helps the authors understand the issue and how to address it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the abstract is well-written and invokes intrigue, but it also provides a suggestion for improvement. The reviewer suggests that including an example of the inconsistency between evaluating with gold answers and human evaluation could enhance the abstract. However, the comment lacks specific examples or references to support the claim that including such an example would improve the abstract. While the suggestion is logical, the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the abstract is well-written and invokes intrigue, which is a positive observation. It also provides a specific suggestion for improvement by recommending the inclusion of an example to illustrate the inconsistency between evaluating with gold answers and human evaluation. This feedback is actionable and constructive, as it guides the authors on how to enhance their abstract to better convey the significance of their work. However, the comment could be more helpful if it provided a specific example of the inconsistency or suggested how to present it effectively. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect. The comment lacks actionable details, such as recommending specific ways to present the selection process or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve the clarity of this section. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"frame similarity factors and attributes similarity factors,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the selection process of these factors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors. It points out that the process is unclear, which is a valid observation that could help the authors improve the clarity and transparency of their work. However, the comment lacks depth and does not provide specific suggestions or examples on how to clarify the selection process or what aspects might be unclear. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This provides a clear and direct action for the authors to take, which is to include these discussions in their draft. The comment is specific and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"joint learning process\" for RNN and CopyRNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the convergence of the proposed joint learning process and how stable points in the probabilistic metric space are obtained. This provides clear guidance on what the authors need to clarify or expand upon in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This claim is somewhat verifiable as it logically suggests that understanding the convergence process is crucial for reproducing results. However, the comment lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully grasp the importance of this discussion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that discussions on the convergence of the proposed joint learning process are required. This feedback is clear and actionable, as it directs the authors to clarify how stable points in the probabilistic metric space are obtained. By addressing this point, the authors can enhance the clarity and reproducibility of their results. However, the comment could be more helpful if it provided additional guidance on how to structure these discussions or what specific aspects should be covered. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). Additionally, it mentions that it would be better to use the same terminology for the model in Tables 1 and 2. While the comment provides explicit actions to take, it does not offer concrete guidance on how to implement these suggestions. The authors are given a clear direction but lack detailed instructions on how to execute these tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, \"681\" and \"778,\" allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed, namely the discussion of results for the task of inferring knowledge on objects and the inclusion of results for model (B) in Tables 1 and 2. Additionally, it points out a potential inconsistency in terminology and suggests using the same terminology for the model in Tables 1 and 2. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). It also mentions that it would be better to use the same terminology for the model in Tables 1 and 2. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that using the same terminology would be beneficial. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and implement the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors discuss the results for the task of inferring knowledge on objects and include results for model (B) in Tables 1 and 2. It also points out a potential inconsistency in terminology, recommending the use of the same terminology for the model in Tables 1 and 2. This feedback is clear and offers concrete steps for improvement, guiding the authors on how to enhance the clarity and completeness of their results section. However, the comment could be more helpful if it provided additional context or examples on how to implement these suggestions effectively. Overall, the comment is mostly helpful as it directs the authors toward significant improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific sentence in line 212 that is not correct and suggests a correction. It provides a clear and explicit action for the authors to make the sentence more accurate by suggesting that they should say they do a bidirectional encoder instead of a GRU. The comment also references Figure 2, which provides a concrete example of what the correct sentence should look like. This level of detail and specificity makes the action explicit and concrete, ensuring that the authors know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the sentence, suggesting that it should be revised to accurately reflect the process. The comment provides a clear suggestion for correction, which is to use a bidirectional encoder instead of a GRU. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sentence in line 212 is not correct, suggesting that the correct way would be to use a bidirectional encoder instead of a GRU. The reviewer supports this claim by referencing Figure 2, which shows a bidirectional encoder. This provides a clear and specific example to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or additional examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the sentence in line 212, noting that it is not strictly correct. It suggests a correction by proposing that the authors should use a bidirectional encoder instead of a GRU. The comment is clear and actionable, providing the authors with a precise suggestion for improving the accuracy of their statement. By addressing this issue, the authors can enhance the clarity and correctness of their work. However, the comment could be more helpful if it explained why the current statement is incorrect or provided additional context or examples to support the suggestion. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment implies that the authors should consider including these baselines, it does not provide explicit instructions or detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should include additional baselines but are not given specific steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, it does not specify which part of the paper this extension or the baselines should be added to, making it weakly grounded. The comment is specific in suggesting the inclusion of character embeddings as a baseline, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension is necessary or how character embeddings would enhance the work. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to implement these additional baselines or why they are necessary. The suggestion is somewhat helpful as it points out a potential area for enhancement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the baseline models: the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. It explicitly instructs the authors to compare their work with Campos et al. and to include comparisons with other domain adaptation methods. The comment provides concrete guidance on what needs to be added to the paper, making it highly actionable. The authors know exactly what steps to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"Line 277,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline models are weak and suggests that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. While the comment highlights a potential issue with the baseline models, it does not provide specific examples or references to Campos et al. or other domain adaptation methods to substantiate the claim. This lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to make a significant effort to verify the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the weakness of the baseline models used. It points out that the authors have not compared their work with Campos et al. (2020), which also uses feedback in QA tasks, and have not included comparisons with other domain adaptation methods. This feedback is clear and actionable, as it provides specific guidance on what the authors need to address to strengthen their work. By addressing these comparisons, the authors can significantly enhance the rigor and relevance of their study. However, the comment could be more helpful if it included suggestions on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is mostly helpful as it effectively highlights a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the y-axis label in Figure 5 should use \"Exact Match ratio\" directly. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is highly actionable as it clearly specifies what needs to be done to enhance the clarity of the figure.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the y-axis label, and suggests using \"Exact Match ratio\" directly. This provides clear guidance on how to improve the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the y-axis label in Figure 5 should use \"Exact Match ratio\" directly. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the clarity of Figure 5 by recommending that the y-axis label use \"Exact Match ratio\" directly. This feedback is clear and direct, offering a straightforward way for the authors to enhance the readability and understanding of the figure. By addressing this point, the authors can improve the clarity and accessibility of their visual presentation, which is valuable for the overall quality of the paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential societal biases in the knowledge bases used in the study and questions whether these biases are addressed. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to assess or mitigate these biases, nor is there any suggestion for further exploration or discussion. As a result, the authors are left without any clear direction on how to address this issue. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the potential societal biases in the knowledge bases used in the study and questions whether these biases are addressed. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the knowledge bases should be considered or how the authors might address these biases. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the potential societal biases in the knowledge bases used in the study and questions whether these biases are addressed. However, the comment lacks any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the potential societal biases in the knowledge bases used in the study and questions whether these biases are addressed. While it identifies an important area for consideration, the comment lacks specificity and does not provide actionable guidance on how the authors might address these biases or what steps to take. The mention of a personal preference for attacking implicit offensive texts with reasoning chains is not directly relevant to the issue at hand. Overall, the comment provides some insight but lacks depth and actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that while it is easier to show that something (e.g., attention in seq2seq MTL) is not working, the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide explicit guidance on how to identify the reasons for failure or how to modify the attention mechanism. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate and address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it is easier to show that something (e.g., attention in seq2seq MTL) is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. The authors can infer that it relates to the discussion of attention mechanisms, but this inference is not direct. The comment is specific in its suggestion to investigate and modify the attention mechanism, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it is easier to show that something (e.g., attention in seq2seq MTL) is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a common issue in research, where it is easier to show that something is not working but more challenging to identify the underlying reasons and make improvements. It suggests that the true value lies in finding out why a particular aspect (e.g., attention in seq2seq MTL) is not working and changing the attention mechanism to make it work. While the comment identifies a general problem, it does not provide specific guidance or suggestions on how to address this issue or what aspects of the attention mechanism need improvement. The feedback is somewhat helpful as it points out a common problem but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in reference [1]. However, it does not provide specific guidance on which baselines should be included or how to justify the omission of others. The action is implicit and somewhat vague, as the authors are left to infer that they need to include more baselines but are not given detailed instructions on which ones to include or how to justify the omission. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"MCNC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in reference [1]. The comment provides a clear direction for improvement by asking the authors to justify the reason for not including these baselines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in reference [1]. However, the comment does not provide specific examples of these baselines or explain why they are considered strong. Without this additional context or justification, the claim lacks verifiability. The authors would need to infer the importance of including these baselines and the reasoning behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by suggesting that Table 3 should include many strong baselines that are not currently compared. It specifically mentions a reference [1] that lists additional baselines that could be included. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting the inclusion of additional baselines. However, the comment could be more helpful if it explained why these baselines are important or how they might impact the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper relies on supplemental space to contain the paper, which makes it not truly independent. It specifically mentions the reference to Supplementary Figure 6 in S3.1 and the model comparison and other details of the span vs. sentence investigation as examples of this reliance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the independence of the paper. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to independence but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as S3.1 and the model comparison, allowing the authors to accurately identify the parts being addressed. It also specifies the issue of reliance on supplemental space and the lack of independence in the paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper relies on supplemental space to contain the paper, which makes it not truly independent. It supports this claim by referencing specific sections, such as S3.1 and the model comparison, where the paper references supplementary figures and details of the span vs. sentence investigation. This provides a clear and specific basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it relies heavily on supplemental space to contain the main content. This is a critical observation, as it suggests that the paper may not be truly independent and could benefit from more self-contained sections. The comment also points out specific examples, such as the reference to Supplementary Figure 6 in S3.1 and the model comparison, where the reliance on supplemental space is evident. While the comment highlights a critical weakness, it does not provide detailed suggestions on how the authors might address this issue or improve the independence of the paper. This limits the comment\\'s helpfulness, as it provides insight but lacks actionable guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. Bi-LSTM-CRF model. It also asks about the KNs in source language or in English, as the mentions have been translated to English. The authors are instructed to correct Figure 3. While the comment provides explicit actions to take, it does not specify how to implement these changes or what specific details should be added to the input or figure. The action is clear but lacks concrete guidance on execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as adding information about the input being word embeddings and clarifying the KNs in source language or in English. The comment also provides a clear request for correction, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. Bi-LSTM-CRF model. It also asks about the KNs in source language or in English, as the mentions have been translated to English. The comment is somewhat verifiable as it provides a logical suggestion for clarifying the input and references a specific model for comparison. However, it lacks specific examples or references to support the claim that adding this information would be beneficial. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors add information about the input being word embeddings, similar to the Lample et al. Bi-LSTM-CRF model. It also raises a question about the KNs in source language or in English, given that the mentions have been translated to English. This feedback is clear and offers a concrete way for the authors to improve their draft by clarifying the input and potentially enhancing the clarity of their work. However, the comment could be more helpful if it provided additional context or examples of how this information would benefit the paper. Overall, the comment is mostly helpful as it guides the authors toward making a significant improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely low-resource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve the experiments. The feedback is vague and lacks concrete steps for the authors to take, leaving them without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the main weaknesses of the paper, specifically the experiments, which are limited to an extremely low-resource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the experiments and the potential of the proposed augmentation method, but without clear grounding, the authors may struggle to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are the main weakness of the paper, as they are limited to an extremely low-resource regime and sentence classification, which is not the only case for data augmentation in real-world applications. The reviewer also suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. While the comment identifies specific limitations and potential areas for improvement, it lacks detailed reasoning or references to support the claim that the experiments are weak. The suggestion for expanding the scope of the experiments is logical but could be strengthened with more specific examples or references. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely low-resource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks but was not demonstrated. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might address these weaknesses or expand the scope of their experiments. The feedback is somewhat helpful as it points out potential gaps in the paper, but it could be more beneficial with more detailed and actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether concept map extraction should be treated as a separate task. It acknowledges that generic summarization systems build similar knowledge graphs and generate summaries accordingly, but also notes that with an increase in node numbers, concept maps become harder to distinguish. The comment suggests that general summaries should be more readable. While the comment implies that the authors should consider whether to treat concept map extraction as a separate task, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their approach to concept map extraction. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether concept map extraction should be treated as a separate task. It acknowledges that generic summarization systems build similar knowledge graphs and generate summaries accordingly, but also notes that with an increase in node numbers, concept maps become harder to distinguish. The comment suggests that general summaries should be more readable. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results section where concept map extraction is discussed. The authors can infer that this comment pertains to the methodology or results section. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether concept map extraction should be treated as a separate task. It acknowledges that generic summarization systems build similar knowledge graphs and generate summaries accordingly, but also notes that with an increase in node numbers, concept maps become harder to distinguish. The comment suggests that general summaries should be more readable. While the comment provides logical reasoning by comparing generic summarization systems and concept maps, it lacks specific examples or references to support the claim that concept maps become harder to distinguish with an increase in node numbers. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about whether concept map extraction should be treated as a separate task. It acknowledges that generic summarization systems build similar knowledge graphs and generate summaries accordingly, but also notes that with an increase in node numbers, concept maps become harder to distinguish. The comment suggests that general summaries should be more readable. While the comment identifies a potential issue with the current approach, it lacks specific suggestions or guidance on how the authors might address this concern or improve the readability of their summaries. The feedback is somewhat helpful as it prompts the authors to consider the trade-offs between concept map extraction and general summaries, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to describe the traits of the experts and justify why annotation must be carried out by them, outside of its commercial value. It also asks specific questions about the expertise of the annotators, whether annotation differs from what non-experts would do, and if it introduces any linguistic challenges. These questions provide clear guidance on what the authors need to address to improve their draft. The action is explicit and concrete, as it specifies exactly what needs to be added or clarified. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first point, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of the traits of the experts and the justification for why annotation must be carried out by them, outside of its commercial value. The comment also raises questions about the expertise of the annotators, whether annotation differs from what non-experts would do, and if it introduces any linguistic challenges. This level of detail provides clear guidance on what the authors need to address to improve their draft, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the expertise of the annotators and the justification for why annotation must be carried out by them, outside of its commercial value. It suggests that the authors should provide more information about the traits of the experts and the linguistic challenges introduced by the annotation process. While the comment highlights areas for improvement, it lacks specific examples or references to support the claim that the annotation process introduces linguistic challenges. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement by asking the authors to describe the traits of the experts and justify why annotation must be carried out by them, outside of its commercial value. It raises specific questions about the expertise of the annotators, whether annotation differs from what non-experts would do, and if it introduces any linguistic challenges. This feedback is valuable as it prompts the authors to clarify and substantiate their claims about the expertise and process involved in annotation. By addressing these points, the authors can enhance the transparency and credibility of their work. Therefore, the comment is mostly helpful, as it provides clear and actionable guidance for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that lines 102-106 are misleading, as they refer to a \"such distribution\" that cannot be related to the discussion in the previous section. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific changes or clarifications to be made to the text. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 102-106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the misleading statement regarding \"such distribution\" and its relation to the discussion in the previous section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that lines 102-106 are misleading, as they refer to a \"such distribution\" that cannot be related to the discussion in the previous section. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text, noting that lines 102-106 are misleading due to the use of the term \"such distribution.\" It points out that this reference cannot be related to the discussion in the previous section. While the comment highlights a potential problem, it does not provide any suggestions or guidance on how the authors might clarify or correct this issue. The feedback is somewhat helpful as it alerts the authors to a potential problem, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. While the action is implied, it is clear and provides a concrete direction for the authors to take. The comment explicitly states what the authors should do, which is to include examples of the system on actual texts. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including examples of the system on actual texts, rather than focusing on other components and models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where examples could be included. Without explicit references, the authors may struggle to identify the exact areas that need attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The comment suggests including examples of the system on actual texts, rather than focusing on other components and models. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. This feedback is somewhat helpful as it points out a potential area for improvement in the paper, which could enhance the reader\\'s understanding of the system\\'s capabilities. However, the comment lacks specific guidance on how to implement this suggestion or what specific examples would be most effective. Without additional details or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s claims would benefit from more in-depth analysis. However, it does not provide specific examples or details of which claims need more analysis or how to conduct this analysis. The authors are left to infer that they need to conduct more in-depth analysis, but without concrete guidance on which claims to focus on or how to approach this analysis, the action remains vague. Therefore, this comment is somewhat actionable, as it implies an action but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a number of claims from the paper would benefit from more in-depth analysis, but it does not specify which claims are being referred to or where in the paper they are made. This lack of specificity makes it difficult for the authors to identify the exact parts of the paper that need further analysis. Additionally, the comment does not provide any guidance on what specific aspects of these claims require more in-depth analysis. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that a number of claims from the paper would benefit from more in-depth analysis. However, it does not provide any specific examples or reasoning to support why these claims need more analysis or what aspects of the claims are insufficiently explored. Without detailed justification or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a number of claims from the paper would benefit from more in-depth analysis. However, it does not specify which claims are being referred to or provide any examples of where these claims could be improved with additional analysis. Without specific guidance or examples, the authors are left with a general suggestion to conduct more in-depth analysis without clear direction on which areas to focus on. This lack of specificity and actionable feedback limits the helpfulness of the comment, making it barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific areas where the presentation of the model needs improvement: the pooling method used for embedding features (line 397) and the clarity of Equation (7) in line 472. It provides explicit questions about the pooling method and the definition of E_i in Equation (7), asking whether it represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability. This feedback is clear and provides concrete actions for the authors to take, such as clarifying the pooling method and the definition of E_i. The explicit nature of the questions and suggestions makes this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be improved, namely the clarity of the pooling method used for embedding features and the definition of E_i in Equation (7). The comment provides detailed guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity of the pooling method used for embedding features (line 397) and the definition of E_i in Equation (7) in line 472. It suggests that the LHS of Equation (7) should be a conditional probability. The comment provides logical reasoning by pointing out that the pooling method and the definition of E_i are unclear, and it questions whether they represent the type or identity of AC i. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the context and details to fully understand and address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the presentation of the model needs improvement, providing clear and actionable feedback. It points out that the pooling method used for embedding features is not clearly explained and that Equation (7) in line 472 is not clear enough, questioning whether E_i represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability, which is a valuable suggestion for clarifying the model's presentation. This feedback is detailed and constructive, offering the authors a clear path to enhance the clarity and understanding of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper raises two hypotheses about multilinguality and country/language-specific bias but does not actually study them or discuss them further. It suggests that the hypotheses could be tested as given and that the paper should delve deeper into these topics. While the comment identifies a specific issue with the paper, it does not provide explicit instructions on how to address it or what specific aspects of the hypotheses should be explored. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the hypotheses and discuss them in more detail. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 078-086, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper raises two hypotheses but does not study them or discuss them further, nor are they mentioned or discussed again. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper raises two hypotheses about multilinguality and country/language-specific bias but does not study or discuss them further. The reviewer suggests that the hypotheses could be tested as given and that the paper should delve deeper into these topics. However, the comment lacks specific examples or references to support the claim that the hypotheses are not studied or discussed adequately. While the reviewer provides some reasoning, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it raises two hypotheses about multilinguality and country/language-specific bias but does not study or discuss them further. This is considered misleading, as the hypotheses are not followed up on or even mentioned again in the paper. The comment suggests that the paper should delve deeper into these topics, at least to some extent, to provide a more comprehensive understanding of the hypotheses and their implications. While the feedback highlights a critical gap in the paper, it could be more helpful by offering specific suggestions on how to address this issue or what aspects of the hypotheses should be explored further. Overall, the comment is somewhat helpful as it points out a significant oversight but lacks detailed guidance on how to improve the draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential use of feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to achieve better results. While the comment implies that the authors should explore this possibility, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the same feature set from the cited work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the potential use of feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to achieve better results. However, the comment does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the use of a particular feature set, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using feature engineering could improve the performance of the paper, citing an example from Uto et al. (2020) where a QWK of 0.801 was achieved using a set of hand-crafted features. This provides a logical basis for the claim, as it suggests that using similar features could potentially enhance the results of the current work. However, the comment lacks specific details on how the feature engineering could be implemented or which features from Uto et al. (2020) could be adapted. This makes the claim somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the potential use of feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to achieve better results. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to implement this suggestion or what specific features from Uto et al. (2020) could be adapted. The feedback is somewhat helpful as it points out a potential area for enhancement, but it could be more beneficial with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the use of the Challenge Set (CS) and seeks clarification on its role in the evaluation process. It implies that the authors should provide more information about how the CS is used, whether it is used for augmenting the training material, and the data split used. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the CS. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Challenge Set\" (CS), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the CS is used, whether it is used for augmenting the training material, and the data split used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the use of the Challenge Set (CS) in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the use of the Challenge Set (CS) in the paper, specifically inquiring about its role in evaluation and whether it is used for augmenting the training material. It also asks for clarification on the data split used. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential gap in the paper, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the paper\\'s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words. It also questions the use of \"knowledge\" in the context of the paper, noting that it is usually used to refer to external knowledge sources like a knowledge base of entities. The reviewer expresses hesitation in calling it \"knowledge\" due to its limited scope. While the comment identifies areas for clarification and potential misuse of terminology, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the meaning of \"knowledge\" and how it relates to the substructure. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but lacks concrete instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s claim of generalization to different knowledge and questions the use of the term \"knowledge.\" It suggests that the substructure should be represented as a sequence of words and questions the applicability of the term \"knowledge\" in this context. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the term \"knowledge\" and suggesting a more appropriate representation, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using the term \"knowledge.\" The reviewer provides a logical reasoning by explaining that \"knowledge\" is usually used to refer to external knowledge sources like a knowledge base of entities, whereas in this context, it is limited to syntax or semantics. The comment is mostly verifiable as it provides a clear rationale for the claim, making it somewhat verifiable. However, it could be strengthened by providing specific examples or references to support the distinction between external and internal knowledge. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using the term \"knowledge.\" It also questions the use of \"knowledge\" in the context of the paper, noting that it is usually used to refer to external knowledge sources like a knowledge base of entities, whereas here it is limited to syntax or semantics. The reviewer expresses hesitation in calling it \"knowledge\" and provides a logical reasoning for this distinction. This feedback is somewhat helpful as it points out a potential misuse of terminology and highlights an area for clarification. However, it could be more helpful if it offered specific suggestions on how to clarify the terminology or address the issue. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the performance of the TWSI model on nouns and questions the generalizability of the clustering approach to all parts of speech. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment implies that the authors should investigate the gap between the oracle GAP for PPDBClus and the performance of the clustering approach, but it does not specify how to conduct this investigation or what specific aspects to focus on. Additionally, it does not offer suggestions on how to improve the uniformity of the performance across all parts of speech. As a result, the comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance of the TWSI model on nouns and the contradiction with the claim of generalizability to all parts of speech. It mentions the oracle GAP for PPDBClus and the fact that the performance is higher than most clustering approaches. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the performance and the contradiction with the claim, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the performance of the TWSI model on nouns and questions the generalizability of the clustering approach to all parts of speech. It mentions the oracle GAP for PPDBClus and the fact that the performance is higher than most clustering approaches, which directly contradicts the claim that the clustering approach is generalizable. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim somewhat verifiable, as it requires further elaboration for the authors to fully understand and address the issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a concern about the performance of the TWSI model on nouns, which is a significant issue. It also points out the contradiction between the claim of generalizability to all parts of speech and the fact that the performance is not uniform across all parts of speech. This feedback is valuable as it highlights a potential weakness in the paper that the authors should address. However, the comment could be more helpful if it provided specific suggestions on how to investigate and understand the gap between the oracle GAP for PPDBClus and the performance of the clustering approach. Additionally, it could offer guidance on how to improve the uniformity of the performance across all parts of speech. Overall, the comment is somewhat helpful as it directs the authors to a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It explicitly asks for examples of spurious structures to help clarify the discussion. While the comment identifies a specific area for improvement, it does not provide detailed guidance on how to address the issue or what specific examples should be included. The action is explicit but somewhat vague, as the authors know they need to provide examples but may not be entirely sure of the exact format or content. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, stating that it is too abstract and does not provide insights into why the new model is better than MH. The comment also requests examples of spurious structures to help clarify the discussion. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. The reviewer requests examples of spurious structures to help clarify the discussion. However, the comment lacks specific examples or detailed reasoning to support the claim that the discussion is abstract or unclear. Without additional context or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides a general critique without sufficient justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstractness of the discussion in Section 5.2, noting that it does not provide insights into why the new model is better than MH. The reviewer requests examples of spurious structures to help clarify the discussion. This feedback is somewhat helpful as it points out a clear area for improvement, but it lacks depth and specificity. The authors are given a direction to address the issue, but the comment could be more beneficial if it provided more detailed guidance or examples of what constitutes spurious structures. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. The reviewer provides a specific suggestion for how to implement this baseline, which is to use learned matrices of $\\\\mathcal{R}^{r \\\\times r}$, $\\\\mathcal{R}^{r \\\\times o}$, $\\\\mathcal{R}^{r}$, etc. This feedback is explicit and provides concrete guidance on how to modify the PCFG to include the suggested baseline. The authors know exactly what changes to make to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific task of adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added, namely a baseline with smaller state size and parameterized matrices. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. The comment provides a logical reasoning for this suggestion, noting that this baseline could help compare perplexity but not parsing F-1. However, the comment lacks specific examples or references to support the claim that this baseline would be beneficial or how it would impact the results. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. This feedback is actionable and offers a clear direction for the authors to enhance their work by addressing a potential issue with comparability. However, the comment could be more helpful if it explained why this baseline is necessary or how it would impact the results, which would provide additional context and guidance for the authors. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is an explicit action that the authors can directly implement by adding a statement to their paper. The comment is clear and provides a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a statement about the maximum number of tasks done by any annotator. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information could be included. Without explicit references or clear indications, the authors may struggle to identify the exact location to address this suggestion. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should state the maximum number of tasks done by any annotator. However, it does not provide any reasoning, evidence, or examples to support why this information is important or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is a specific and actionable piece of feedback that could help improve the transparency and reproducibility of the study. By including this information, the authors can provide more detailed insights into the variability of task completion across annotators, which could be valuable for understanding the robustness of their results. However, the comment could be more helpful if it explained why this information is important or how it could impact the interpretation of the findings. Overall, the comment is mostly helpful as it identifies a clear area for improvement but could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested. However, it does not provide explicit guidance on how the authors should address this issue. The comment lacks actionable steps or suggestions for improvement, leaving the authors uncertain about how to enhance the clarity and coherence of their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment does not specify which parts of the paper are particularly challenging to understand or where the authors could provide more clarity. Without explicit references to sections or figures, the authors may struggle to identify the exact areas that need improvement. Therefore, the comment is weakly grounded because it does not specify where the issue is located, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant challenge in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested, as well as how the different pieces of the puzzle fit together. While the comment points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it directs the authors to focus on improving the clarity and coherence of their work, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and direct action for the authors to take, as it provides a specific and concrete step to enhance the presentation of their results. The comment is highly actionable because it clearly specifies what needs to be added to the table, making it easy for the authors to implement the suggested change.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding the hard prompt baseline to Table 1 to show the increase in performance of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion section, but this inference is not direct. The comment is specific in suggesting the inclusion of the hard prompt baseline, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. However, it does not provide any reasoning or evidence to support why this inclusion is necessary or how it would benefit the paper. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and actionable suggestion that could enhance the presentation of the results. By including the hard prompt baseline, the authors can provide a more comprehensive comparison of their methods, allowing readers to better understand the performance improvements. However, the comment could be more helpful if it explained why the inclusion of the hard prompt baseline is important or how it would benefit the paper. Overall, the comment is mostly helpful as it directs the authors to a specific improvement that could enhance the clarity and comprehensiveness of their results.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. While the comment implies that the authors should include numerical results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include numerical results to address the reviewer\\'s curiosity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the application to popular algorithms should be discussed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for numerical results and application to popular algorithms, but it is not grounded as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of numerical results in the paper. It expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. This feedback is somewhat helpful as it highlights a gap in the paper that could be addressed to enhance its comprehensiveness and rigor. However, the comment lacks specific guidance on how to implement these improvements or what specific numerical results should be included. To be more helpful, the comment could provide examples of what kind of numerical results would be relevant or suggest how to integrate these findings into the existing work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental comparisons are not sufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments with these wider backbones. The comment is specific in detailing what additional comparisons are needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental comparisons and suggests testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what additional comparisons are needed and why they are important. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental comparisons are not sufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2x) and ResNet50 (4x). However, the comment does not provide any supporting evidence, reasoning, or references to justify why these additional comparisons are necessary or how they would impact the results. Without such justification, the claim remains unverifiable, as it lacks the necessary information to support the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental comparisons, specifically noting that the proposed InvP method is not tested with wider backbones like ResNet50 (2x) and ResNet50 (4x). This feedback is valuable as it suggests a potential area for improvement in the experimental design, which could enhance the robustness and generalizability of the results. However, the comment could be more helpful if it provided specific guidance on how to implement these additional comparisons or why they are important. Overall, the comment is mostly helpful as it points out a relevant area for improvement but lacks detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the probabilistic connection is not well-established and recommends either strengthening it formally or adjusting the language to clarify the connection. This provides a clear and explicit action for the authors to take, either by making the connection more formal or by adjusting the language to enhance clarity. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the probabilistic connection is not well-established and recommends either strengthening it formally or adjusting the language to clarify the connection. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the connection is discussed. The authors can infer that it relates to the discussion of the probabilistic connection, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the probabilistic connection is not well-established and suggests that it should be either strengthened formally or clarified through language adjustments. However, the comment lacks specific examples or detailed reasoning to support why the connection is not well-established or how it could be improved. Without specific examples or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity in the probabilistic connection. It suggests that the authors either strengthen this connection formally or adjust the language to clarify it. This feedback is clear and actionable, providing the authors with a direct path to improve the draft by either making the connection more formal or by adjusting the language to enhance clarity. However, the comment could be more helpful if it provided specific examples or guidance on how to strengthen the connection or clarify the language. Overall, the comment is mostly helpful as it effectively points out a weakness and offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is explicit in its request for additional evidence, providing a clear action for the authors to take. However, it does not specify what kind of evidence would be sufficient or how to present it, leaving some room for interpretation. Therefore, the comment is mostly actionable, as it identifies a specific area for improvement but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests providing empirical evidence to support the claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what kind of evidence would be sufficient. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this claim is made, the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, the comment does not provide any specific reasoning or examples to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is somewhat helpful as it identifies a specific area where the paper could be strengthened by providing empirical evidence. However, the comment lacks detailed guidance on what kind of evidence would be sufficient or how to present it effectively. While it points out a potential weakness, it does not offer actionable steps for the authors to address it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with high-dimensional domains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or suggestions for modifications to improve the scalability of the robust training scheme. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the applicability of the robust training scheme, specifically questioning its scalability to practical datasets, particularly those with high-dimensional domains. However, it does not specify which part of the paper this concern is based on, such as a specific section or figure where the robust training scheme is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. The comment is specific in its critique of the scalability issue but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the robust training scheme is unlikely to scale to practical datasets, particularly those with high-dimensional domains. The comment provides a logical reasoning by suggesting that the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors may find it challenging to fully understand and address the concern without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with high-dimensional domains. It points out that the accuracy might unfavorably scale unless the size of V scales exponentially with the dimension. While the comment highlights a potential limitation, it lacks specific suggestions or guidance on how the authors might address this issue or improve the scalability of their robust training scheme. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of datasets and the duration of four years for studying style shifts. It suggests that without understanding the type of style shifts that occur during this period, it is difficult to appreciate what the model is capturing. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete steps or specific actions for the authors to take, such as recommending additional datasets or discussing the type of style shifts that occur during the four-year period. As a result, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of datasets and the duration of four years for studying style shifts. However, it does not specify which part of the paper this question pertains to, such as a specific section or dataset description. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its question about the type of style shifts that occur during the four-year period, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of datasets and the duration of four years for studying style shifts, suggesting that it may not be sufficient to capture all style shifts. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate why four years might not be sufficient or what kind of style shifts might occur during this period. As a result, the claim is somewhat verifiable, as it raises a valid question but lacks the necessary support to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of datasets and the duration of four years for studying style shifts. It questions whether four years is sufficient to capture all style shifts and suggests that the authors should provide more information on the type of style shifts that occur during this period. This feedback is somewhat helpful as it prompts the authors to consider the limitations of their dataset choice and the potential impact on the model\\'s performance. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending additional datasets or discussing the specific style shifts that might occur during the four-year period. Overall, the comment identifies a relevant concern but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the callout to Table 5 should be changed to Table 3 and provides the correct page and section number. Additionally, it points out that the figure 6 callout is not directing properly. This feedback is clear and provides specific actions for the authors to take, ensuring that they know exactly what needs to be corrected. The explicit nature of the instructions and the concrete details on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5\" and \"figure 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the callout to Table 5 and the figure 6 callout. This provides clear guidance on how to correct the errors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the callout to Table 5 should be changed to Table 3 and that the figure 6 callout is not directing properly. However, the comment does not provide any supporting evidence, reasoning, or examples to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out a mistake in the callout to Table 5, which should be changed to Table 3, and noting that the figure 6 callout is not directing properly. This level of detail and clarity is highly helpful as it allows the authors to easily identify and correct errors in their draft. By addressing these specific issues, the authors can improve the accuracy and clarity of their paper, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant concern with the experiments, specifically the lack of comparisons with other models, such as SketchRNN. It explicitly states that the paper should include comparisons with other models to provide a more comprehensive understanding of its results. The comment is clear and provides a concrete action for the authors to take, which is to include comparisons with other models. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of comparisons with other models, and suggests including comparisons with SketchRNN. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons with other models, specifically mentioning SketchRNN, and that this lack of comparisons contributes to the poor motivation problem. The comment provides a logical reasoning by suggesting that comparisons with other models would enhance the paper\\'s comprehensiveness and credibility. However, it does not provide specific examples or references to support the claim that SketchRNN is a relevant comparison, nor does it explain why this comparison is necessary. While the claim is somewhat verifiable, it could be strengthened with additional justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern with the paper\\'s experiments, specifically the lack of comparisons with other models. It points out that the paper only includes self-comparisons, which contributes to the poor motivation problem. The comment suggests that comparisons with SketchRNN could be beneficial. While the comment highlights an important area for improvement, it does not provide specific guidance on how to conduct these comparisons or what aspects to focus on. This limits the comment\\'s helpfulness, as it offers a clear direction but lacks detailed instructions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment recommends conducting more analysis and providing comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\\' viewpoint regarding the benefits of increased model capacity for both CNNs and ViTs. The comment provides specific observations about the performance of DeiT-B models compared to DeiT-S, noting that DeiT-B does not outperform DeiT-S in certain datasets. However, it does not provide explicit guidance on how to conduct the additional analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the details of the analysis and comments required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by recommending more analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. The comment provides specific observations about the performance of DeiT-B models compared to DeiT-S, noting that DeiT-B does not outperform DeiT-S in certain datasets. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim that the authors\\' viewpoint is incorrect regarding the benefits of increased model capacity for both CNNs and ViTs. The reviewer provides specific observations from Figure 3, noting that DeiT-B models do not outperform DeiT-S in certain datasets and that CNNs consistently improve their performance with increased capacity. This claim is supported by detailed observations and comparisons, making it mostly verifiable. However, the comment could be strengthened by providing more context or references to similar studies that support the authors\\' viewpoint. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by recommending additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\\' viewpoint regarding the benefits of increased model capacity for both CNNs and ViTs, offering specific observations about the performance of DeiT-B models compared to DeiT-S in certain datasets. This feedback is valuable as it encourages the authors to reconsider their conclusions and potentially revise their analysis to better support their claims. However, the comment could be more helpful if it provided suggestions on how to conduct the additional analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and offers a clear rationale for the critique.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the paper is not difficult to follow but points out specific areas that may cause confusion. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve clarity or what specific changes should be made to avoid confusion. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not specify which sections or parts of the paper these areas are located in, making it difficult for the authors to pinpoint the exact issues. The comment is specific in identifying potential areas of confusion but lacks grounding as it does not specify where these issues are located in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the identified areas of confusion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any detailed guidance or suggestions on how to address these areas of confusion. Without actionable feedback or specific examples, the authors are left without a clear path to improve the clarity of their draft. Therefore, the comment is barely helpful, as it points out an issue but lacks depth and specificity in its guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the claim of \"no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. This feedback is clear and directs the authors to review the references mentioned to understand the tools available in the reinforcement learning setting. The action is explicit and concrete, as the authors know exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim of \"no corresponding set of tools for the reinforcement learning setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides references to support the claim, which helps the authors understand the context and the basis of the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"there is no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. This provides a clear and specific justification for the claim, making it fully verifiable. The references and logical reasoning offered by the reviewer provide a solid foundation for the authors to understand and address the issue. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment challenges the claim that there is no corresponding set of tools for the reinforcement learning setting, providing references to support the assertion. This feedback is valuable as it not only corrects an apparent misconception but also directs the authors to relevant sources that could be used to enhance their work. By addressing this point, the authors can improve the accuracy and completeness of their paper. However, the comment could be more helpful if it provided additional context or analysis on why these references are relevant or how they could be integrated into the paper. Overall, the comment is mostly helpful as it offers actionable guidance for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results more accessible or how to improve the technical competency required to understand them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not specify which part of the paper this issue pertains to, such as the results section or a particular technique. The authors cannot confidently determine which part of the paper needs attention, making this comment weakly grounded. The comment is specific in its critique of the technical competency required to understand the results, but without explicit references to sections or techniques, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. This feedback highlights a potential weakness in the paper\\'s presentation, as it may not be accessible to a broader audience. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to address this issue. Without detailed advice or examples, the authors may struggle to understand and implement the necessary improvements. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. While the comment implies that the authors should make this distinction, it does not provide explicit instructions or concrete steps on how to implement this distinction. The authors are left to infer that they should make this distinction, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this distinction is necessary or how it would improve the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. This feedback is somewhat helpful as it identifies a potential area for clarification and differentiation in the paper. However, the comment lacks specific guidance on how to implement this distinction or why it is important for the paper. While it points out a potential issue, it does not provide detailed suggestions or examples on how to address it, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the end-to-end system, questioning the conclusion that the direct model is clearly better. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the amount of data used to train the text disambiguation model compared to the end-to-end system, questioning the conclusion that the direct model is clearly better. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the discrepancy in data usage and the conclusion, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the amount of data used to train the text disambiguation model is significantly lower than the data used for the end-to-end system, which raises questions about the conclusion that the direct model is clearly better. However, the comment does not provide specific data or references to support this claim, making it difficult for the authors to verify the validity of the assertion. The lack of detailed evidence or examples makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the conclusion drawn about the superiority of the direct model compared to the end-to-end system. It points out that the difference between the two systems is only a few percentage points, which raises questions about the validity of the conclusion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues with the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. While the comment highlights specific areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and evidence for GaRare's advantages over GaLore, as well as clarify the process of updating parameters. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement these improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for GaRare and provides a specific suggestion for improvement by suggesting a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. The comment is somewhat verifiable as it provides a logical reasoning for the need for a more detailed explanation, but it lacks specific examples or references to support the claim about the lack of motivation or the need for a more detailed algorithmic presentation. This makes the claim somewhat verifiable, as it requires further elaboration to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve their draft. However, the comment could be more helpful if it offered specific suggestions on how to address these issues, such as providing examples or references to similar works that have successfully motivated their algorithms or presented detailed algorithmic explanations. Despite this, the feedback is mostly helpful as it directs the authors to key areas needing improvement, which can significantly enhance the clarity and comprehensiveness of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in real-world datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides explicit actions, it does not offer detailed guidance on how to conduct the ablation study or the specific experiment with ATT(+H). The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to implement the suggestions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 4 left\" and \"visDial dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely conducting an ablation study on the visDial dataset and conducting an experiment on the performance of ATT(+H) in figure 4 left. The comment provides detailed guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in real-world datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides a logical request for additional experiments, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact experiments and analyses required to address the suggestion. Therefore, the comment is somewhat verifiable, as it provides a clear direction but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in real-world datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the proposed model did not consider relevant attention retrieval from the attention memory. This feedback is clear and offers a concrete direction for the authors to improve their draft by conducting additional experiments and analyses. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers valuable suggestions for enhancing the paper, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of a reference to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add these references to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific works, \"Continuous Conditional Random Fields [Ristovski 2013]\" and \"Continuous Conditional Neural Fields [Baltrusaitis 2014],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of references to similar work that shares a similar structure and inference capabilities. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the relevance or significance of these references. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. This feedback is somewhat helpful as it points out a potential gap in the literature review that could enhance the authors\\' understanding and comparison of their work. However, the comment could be more helpful if it provided specific examples or references to these similar works, which would guide the authors in incorporating them into their analysis. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. It also questions whether any input serves as white paper and points out that Figure 2 suggests Gaussian noise input does not work as well as WPA. The reviewer notes that the authors spend a lot of time showing WPA improves the test performance of the original model but do not provide insights into how WPA works. This feedback highlights a gap in the paper that needs to be addressed, suggesting that the authors should provide more detailed explanations or analysis to support their claims. The comment is explicit in its request for clarification and actionable, as it clearly identifies areas where the authors can improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"np.ones input,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of why WPA works and the implications of the results shown in Figure 2. The comment provides a clear direction for the authors to improve their draft by explaining the model's predictions and the limitations of Gaussian noise input. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the effectiveness of WPA and suggests that the authors should provide more insights into how it works. It references Figure 2, which appears to suggest that Gaussian noise input does not work as well as WPA. The reviewer also points out that the paper spends a lot of time showing WPA improves test performance but lacks insights into its mechanism. This claim is somewhat verifiable as it provides a logical basis for the suggestion to explain WPA\\'s effectiveness, but it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the paper, highlighting several areas where the authors could improve their work. It suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. The comment also questions whether any input serves as a white paper and points out that Figure 2 suggests Gaussian noise input does not work as well as WPA. The reviewer notes that the paper spends a lot of time showing WPA improves the test performance of the original model but fails to provide useful insights into how WPA works. This feedback is valuable as it identifies specific areas where the authors can enhance their draft, such as providing more detailed explanations or analysis to support their claims. However, the comment could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is mostly helpful as it provides actionable feedback that can guide the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method part of the paper is similar to a related work mentioned, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification on this similarity. While the comment implies that the authors should provide more information or explanation regarding the similarities, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"method part\" of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the similarity to a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and requests clarification on this similarity. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the method part of the paper is similar to a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the similarity between the method part of the paper and a related work, \"Generating Adversarial Disturbances for Controller Verification.\" It suggests that the authors should provide more clarification on this similarity and its implications. While the comment highlights an area for improvement, it lacks specific guidance on how the authors might address this issue or what additional clarification is needed. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison with other methods and consider promoting existing methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the proposed method, such as the use of a proposal generator pretrained on MSCOCO and its potential impact on comparisons with other methods. It also questions whether the proposed technique can promote existing class incremental semantic segmentation methods. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its questions about fairness and potential impact, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about fairness or the potential impact on existing methods. This makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. While it identifies areas for consideration, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a critical issue with the experimental section, noting that important parameters/thresholds (minimum cluster size and conductance threshold) are not discussed or mentioned in the experimental section. It explicitly states that the authors need to address this omission by discussing how these parameters are set and how sensitive the performance is to them. The comment provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"End of Sec.2\" and the \"experimental section (Sec. 3),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of discussion on the minimum cluster size and conductance threshold parameters in the experimental section. This provides clear guidance on what the authors need to include in their paper to improve it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental section does not discuss or mention the important parameters/thresholds (minimum cluster size and conductance threshold). However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this omission and how it affects the paper\\'s results. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically the lack of discussion on important parameters (minimum cluster size and conductance threshold) in the experimental section. It points out that these parameters are not mentioned or discussed in the experimental section, despite their potential impact on the results. This feedback is clear and actionable, as it directs the authors to include a discussion on these parameters and their sensitivity to the results. By addressing this issue, the authors can significantly improve the clarity and robustness of their experimental section. However, the comment could be more helpful if it provided specific suggestions on how to discuss these parameters or examples of how they might affect the results. Overall, the comment is mostly helpful as it highlights a significant gap in the paper that the authors can address to enhance its rigor and comprehensiveness.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 4 could benefit from a slower development to improve readability. However, it does not provide specific guidance on how to achieve this or what aspects of the section need more development. The comment lacks concrete details on how to implement this suggestion, such as recommending additional content or a different structure. As a result, the authors are left without clear instructions on how to enhance the readability of the section. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the section is \"very tersely written\" and could benefit from a slower development for easier readability. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Section 4 is \"very tersely written\" and could benefit from a slower development to improve readability. However, the comment does not provide any specific reasoning or examples to support this claim. It lacks detailed justification or references to similar works that might have addressed this issue, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the writing style of Section 4, noting that it is \"very tersely written\" and could benefit from a slower development to improve readability. While it highlights a potential problem, it lacks specific suggestions or guidance on how to achieve this improvement. The feedback is somewhat helpful as it points out an area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less data-efficient and harder to train. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific changes could be made to improve the approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less data-efficient and harder to train. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the use of reinforcement learning, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less data-efficient and harder to train. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to studies that have demonstrated the inefficiency or difficulty of using reinforcement learning for static VQA tasks. Without such support, the claim remains unverifiable, as it is based on a personal opinion without sufficient evidence or reasoning. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less data-efficient and harder to train. While the comment identifies a potential issue, it lacks specificity and actionable guidance on how the authors might address this concern. It does not provide suggestions on how to mitigate the potential weakness or improve the approach. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback provides clear and concrete actions for the authors to take, making it highly actionable. The comment is specific about what needs to be included and explained, giving the authors a clear path to improve their draft. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the previous question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the distribution of videos of different lengths within the benchmark and the explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not provide relevant explanations regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This claim is somewhat verifiable as it logically points out a gap in the paper\\'s explanation and provides a specific suggestion for improvement. However, the comment lacks detailed reasoning or references to support the importance of this explanation or the impact of the distribution on the assessment of reasoning ability and robustness. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of explanation regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the draft. By addressing this issue, the authors can enhance the transparency and clarity of their work, which is valuable for improving the paper\\'s comprehensibility and credibility. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors clarify how the implemented billinear layer differs from other approaches that perform billinear pooling. It raises questions about the major difference, whether it is the dimensionality of embeddings, and how the billinear layer is swapped out with other approaches. Additionally, it asks about the compression of representations using Equation (3) in this case. While the comment provides specific questions that need clarification, it does not offer explicit guidance on how to address these points. The authors can infer that they need to provide more detailed explanations or examples to clarify these aspects, but the action is implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the differences between the billinear layer and other approaches that perform billinear pooling. The comment raises questions about the dimensionality of embeddings, how the billinear layer is swapped out with other approaches, and whether the compression of representations using Equation (3) is still done in this case. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the differences between the billinear layer and other approaches that perform billinear pooling. It suggests that the major difference might be the dimensionality of embeddings, and it asks about the compression of representations using Equation (3) in this case. The comment is somewhat verifiable as it provides logical reasoning by questioning the differences between the billinear layer and other approaches, but it lacks specific examples or references to support the claim. The authors might need to provide more detailed explanations or references to fully address the questions raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area where the authors need to clarify the differences between the billinear layer and other approaches that perform billinear pooling. It raises important questions about the dimensionality of embeddings and how the billinear layer is swapped out with other approaches, such as the hadarmard product and MCB approaches. Additionally, it questions whether the compression of representations using Equation (3) is still done in this case. This feedback is clear and actionable, as it guides the authors to provide more detailed explanations or examples to address these points. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects should be emphasized. Overall, the comment is valuable in prompting the authors to clarify their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the availability of the promised dataset, suggesting that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how to address the issue, such as suggesting ways to make the dataset more accessible or how to mitigate the potential impact of this limitation. As a result, the authors are left without any clear direction on how to proceed with this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is publicly accessible. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the dataset\\'s availability, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the promised dataset has not yet been made publicly available, suggesting that a cautious approach should be taken regarding the contribution until the dataset is accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a significant concern about the availability of the promised dataset, suggesting that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. This is a relevant and important point, as the availability of the dataset is crucial for the validity and impact of the contribution. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or mitigate the potential impact of the dataset\\'s unavailability. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the limited novelty of the proposed method and its similarity to other attentional modules in previous works. It specifically mentions that the group attention design is related to ResNeSt but not discussed in the paper. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should discuss the similarities and differences between their work and previous works, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"group attention design\" and \"ResNeSt,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty and the similarity to other attentional modules in previous works, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. The reviewer supports this claim by referencing specific works, such as ResNeSt, and noting that the group attention design is related to these works but not discussed in the paper. However, the comment lacks detailed comparisons or specific examples from these works to fully substantiate the claim. While the references provide some context, the comment could be strengthened by offering more specific examples or detailed analysis to fully support the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to other attentional modules in previous works. It specifically mentions the group attention design and its relation to ResNeSt, which is not discussed in the paper. This feedback is valuable as it highlights a potential weakness in the originality of the work, prompting the authors to address this issue and provide a more comprehensive discussion of related works. However, the comment could be more helpful if it offered suggestions on how to differentiate the method or discuss its unique contributions. Overall, the comment is mostly helpful as it provides actionable feedback on a critical aspect of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, as the preactivation values of two networks are the same membrane potentials, resulting in a high cosine similarity. This feedback provides a clear and explicit action for the authors to take, which is to include the illustration of the results in the paper. The comment is specific and provides concrete guidance on how to implement the suggested change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 3 e.\" and \"Eqn 13,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the illustration of the results of the latter loss term of Eqn 13. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results of the latter loss term of Eqn 13 should be illustrated directly, as the preactivation values of two networks are the same membrane potentials, resulting in a high cosine similarity. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this illustration is necessary or how it would enhance the understanding of the results. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in the paper, specifically suggesting that the authors should illustrate the results of the latter loss term of Eqn 13 directly. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and comprehensiveness of the paper. By addressing this point, the authors can enhance the understanding and interpretation of their results, which is valuable for improving the draft. However, the comment could be more helpful if it explained why this illustration is important or how it would benefit the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper regarding the lack of comparison with test-time adaptation (TTA) methods, specifically mentioning [A-B]. It suggests that a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of robustness in video action recognition and the lack of comparison with test-time adaptation (TTA) methods, such as [A-B]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a comparison with TTA methods to prove the superiority of data processing over model parameter adjustment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison with test-time adaptation (TTA) methods, specifically mentioning [A-B]. The reviewer suggests that such a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. However, the comment does not provide specific examples or references to support the claim that TTA methods are relevant or how they could be applied to the paper. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of comparison with test-time adaptation (TTA) methods, such as [A-B], which are relevant to the issue of robustness in video action recognition. It suggests that a comparison with these methods could provide valuable insights into the effectiveness of data processing versus model parameter adjustment. While the comment highlights an important area for improvement, it does not offer specific guidance on how to conduct such a comparison or what specific aspects to focus on. This limits the comment\\'s helpfulness, as it provides a clear direction but lacks detailed instructions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific error in the first expression for J (\u03b8) and suggests that it should be Q (s t 0, \u03c0\u03b8(s t 0)). This provides a clear and direct action for the authors to take, as they are instructed to correct the mistake in the expression. The comment is explicit and concrete, giving the authors a precise action to take to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J (\u03b8), suggesting that it should be Q (s t 0, \u03c0\u03b8(s t 0)). This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first expression for J (\u03b8) is incorrect and should be Q (s t 0, \u03c0\u03b8(s t 0)). However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific error in the first expression for J (\u03b8) in Section 3.2.1, noting that it should be Q (s t 0, \u03c0\u03b8(s t 0)). This is a clear and actionable piece of feedback that can help the authors correct a mistake in their draft. However, the comment could be more helpful if it provided additional context or explanation on why this error occurred or how it affects the overall understanding of the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing correction, which can improve the clarity and accuracy of their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with capitalization in the paper, including specific references that need capitalization. It also mentions that various words in the references need capitalization. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to correct these issues. The authors are left to infer that they should review and correct the capitalization in the references and in the paper itself. The action is implicit and somewhat vague, as it lacks detailed guidance on how to apply the corrections. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p. 8\" and \"Various words in many of the references need capitalization,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with capitalization in the references and provides examples of specific references that need correction. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and observations about capitalization in the paper and references. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies several issues with capitalization in the paper and references, which is a clear and actionable piece of feedback. It provides specific examples of capitalization errors, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many of the papers, and \"Advances in neural information processing systems\" in several of the papers. Additionally, it points out capitalization errors in the references section. This level of detail and specificity is highly helpful, as it empowers the authors to make precise corrections to improve the clarity and professionalism of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the missing parameter values for task 1 and the Boltzmann policy, specifically asking about the model parameters and the method used to choose them. While it does not explicitly instruct the authors to provide these details, the questions imply that the authors should include this information in their draft. The comment is somewhat actionable as it provides a clear direction for the authors to address the missing information, but it lacks explicit instructions on how to present this information.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific tasks, such as \"task 1\" and the Boltzmann policy, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the missing information, such as the model parameters and the method used to choose them, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification about specific parameter values and the method used to choose them. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific missing information about the model parameters and the method used to choose them, particularly for task 1 and the Boltzmann policy. By asking these questions, the reviewer highlights areas where the authors need to provide more detail or clarification in their draft. However, the comment could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar information has been presented in other works. While it points out important areas for improvement, the feedback lacks depth and actionable guidance, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. The reviewer implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. While the comment does not explicitly instruct the authors to conduct these experiments, it provides a clear direction for action. The authors can infer that they need to conduct comparisons to validate their results, making the action implicit but still clear. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. It implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. However, the comment does not specify which part of the paper this claim is made in, nor does it provide details on what specific comparisons should be conducted. While the authors might have an idea of where this claim is made, the lack of explicit grounding and specificity makes it difficult for them to pinpoint the exact section that needs attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. The reviewer implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. While the comment provides a logical reasoning for the need for such comparisons, it lacks specific examples or references to support the claim that the performance is mainly due to the first step. This makes the claim somewhat verifiable, as the authors would need to conduct the suggested comparisons to fully understand and address the reviewer\\'s concern.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. It implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. While the comment identifies a potential weakness in the paper\\'s claims, it lacks specific guidance on how to conduct these comparisons or what aspects of the experiments should be compared. This limits the comment\\'s helpfulness, as it provides a direction for improvement but does not offer detailed instructions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to explain why they believe applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 deteriorates performance compared to only applying it to layers 3 and 4. It provides a clear and direct action for the authors to take, which is to provide an explanation or rationale for this observation. The comment is specific and actionable, as it guides the authors on how to address the issue by offering a clear direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the authors about the performance deterioration when Conditional Batch Norm (CBN) is applied to layers 2, 3, and 4, compared to only layers 3 and 4. The comment asks for an explanation or rationale, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2 deteriorates performance compared to only applying it to layers 3 and 4. However, the comment lacks specific details or evidence to support this claim, such as data or comparisons to substantiate the observed performance deterioration. Without such details, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the application of Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2, noting that this approach deteriorates performance compared to only applying it to layers 3 and 4. It prompts the authors to provide an explanation or rationale for this observation, which is a clear and actionable suggestion. By addressing this issue, the authors can improve the clarity and robustness of their results. However, the comment could be more helpful if it included specific suggestions on how to interpret or analyze the performance differences. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the lack of comparison with a highly relevant method, specifically mentioning [1] and its proposed approach of utilizing previous knowledge with inter-task ensemble. It also highlights the absence of a comparison with the current task's performance using intra-task ensemble. The comment clearly identifies the missing element of comparison, providing a direct action for the authors to include this analysis in their draft. The explicit nature of the suggestion and the concrete details on what to compare make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, specifically mentioning [1] and its approach of utilizing previous knowledge with inter-task ensemble. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the absence of a comparison with the current task's performance using intra-task ensemble. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning [1] and its approach of utilizing previous knowledge with inter-task ensemble. The reviewer also notes the absence of a comparison with the current task's performance using intra-task ensemble. However, the comment does not provide specific details or references to [1] or the method being compared, making it difficult for the authors to fully understand and address the critique. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the specific method being referred to and the basis for the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of comparison with a highly relevant method that proposes to utilize previous knowledge with inter-task ensemble. It also highlights the absence of a comparison with the current task's performance using intra-task ensemble. This feedback is clear and actionable, as it points out specific areas where the paper could be strengthened by including comparisons with relevant methods. However, the comment could be more helpful if it provided additional context or examples of how these comparisons could be conducted or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending clarification or suggesting a specific approach to improve the clarity. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"Witness oracle,\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the Witness oracle is confusing or how it could be clarified. The comment lacks specificity regarding the issue and does not provide guidance on how to address it. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the required implicit call to the Witness oracle being confusing. This feedback is somewhat helpful as it points out a potential source of confusion for readers, which could impact the clarity and accessibility of the paper. However, the comment lacks depth and does not provide suggestions on how to clarify or improve the explanation of this concept. Without additional guidance or examples, the authors may struggle to fully address the issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the proposed method's inability to handle headpose and questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to a previous work. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The comment implies that the authors should consider incorporating headpose control into their method, but it lacks concrete steps or detailed instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"headpose,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the method cannot handle headpose and why it cannot be conditioned like a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the proposed method\\'s inability to handle headpose, noting that a previous work has already demonstrated control over both facial expression and headpose. The comment suggests that the authors should consider incorporating headpose control into their method, similar to the previous work. However, the comment lacks specific references or detailed reasoning to support why this is a significant issue or how it could be addressed. While it highlights a potential gap in the methodology, the lack of detailed justification makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the proposed method, noting that it cannot handle headpose while suggesting that a previous work has already demonstrated control over both facial expression and headpose. It questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to the previous work. This feedback is somewhat helpful as it points out a gap in the methodology and provides a specific reference to a previous work that could serve as a benchmark or inspiration for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or incorporate the headpose control into the NeRF. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns that appear only a few times in the training set. It references external works that use similar triggers, such as Chen et al. (2017) and Gu et al. (2019). The comment suggests that a few training examples with such triggers could have a significant impact on the trained model. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions to take. The action is implicit and somewhat vague, as the authors can infer that they need to consider the impact of these spurious features but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the similarity between the spurious features and backdoor triggers, and it references external works to provide context. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, suggesting that these features are artificial patterns that only appear a few times in the training set. The reviewer references external works, such as Chen et al. (2017) and Gu et al. (2019), to support this claim. This provides a logical basis for the claim, as it references established knowledge about backdoor triggers and their impact on models. However, the comment could be strengthened by providing more detailed examples or specific references to the spurious features in the paper. Overall, the claim is mostly verifiable, as it is supported by references and logical reasoning, but it could be further substantiated with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting the similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers. It references external works that use similar triggers, such as Chen et al. (2017) and Gu et al. (2019), to provide context and support the claim. This feedback is valuable as it highlights a potential weakness in the paper that could impact its robustness and generalizability. However, the comment could be more helpful if it suggested specific actions for the authors to take, such as addressing the impact of these spurious features or discussing potential mitigation strategies. Overall, the comment is somewhat helpful as it points out a relevant issue but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the structural optimization component is emphasized several times but notes that the optimization algorithm seems to be directly borrowed from previous works, which could be confusing and reduce the contribution. However, it does not provide explicit guidance on how the authors should address this issue or suggest improvements. The comment lacks concrete actions or specific suggestions for enhancing the contribution, such as recommending alternative optimization algorithms or explaining the novelty of the approach. As a result, the authors are left without clear direction on how to improve their draft in this area. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the structural optimization component, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper discusses this component, making it weakly grounded. The comment is specific in pointing out that the optimization algorithm seems to be directly borrowed from previous works, which could be confusing and reduce the contribution. This provides clear guidance on what needs to be addressed, but without explicit references to sections, the authors may struggle to pinpoint the exact part of the paper being discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the structural optimization component is emphasized several times but notes that the optimization algorithm seems to be directly borrowed from previous works, which could be confusing and reduce the contribution. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. Without concrete evidence or detailed reasoning, the claim is not fully verifiable, leaving the authors without clear guidance on how to improve their draft. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the use of a direct optimization algorithm from previous works. It points out that this could be confusing and reduce the contribution of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the contribution of their work. While it highlights a potential weakness, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides insight into a potential problem but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue with the baseline models or how to improve the pipeline style method. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the pipeline style method, which includes two models, and notes that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses the pipeline style method or the baseline models, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issue of average results and the need for better introduction of baseline models, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some indication but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the pipeline style method, which includes two models, not yielding better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address these issues. Without specific recommendations or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not offer detailed guidance for addressing them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT's output. The reviewer questions why this observation needs to be made using the authors\\' methodology, as it has been made in previous works. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve their methodology. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their methodology but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\\'s output. However, it does not specify which part of the paper this observation is made in, making it weakly grounded. The comment is specific in detailing the issue with the methodology and questioning why this observation needs to be made again. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have reproduced a well-known result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\\'s output. The reviewer questions why this observation needs to be made again, as it has been made in previous works. The comment is somewhat verifiable as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion that this observation is unnecessary. The authors may need to further substantiate the claim by providing evidence or references to similar works that have already addressed this issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors for reproducing a well-known result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\\'s output. The reviewer questions why this observation needs to be made again, as it has been made in previous works. While the comment identifies a potential redundancy in the authors\\' approach, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is somewhat helpful as it points out a potential weakness in the paper, but it lacks actionable advice or detailed critique to fully support the authors in making improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing a specific work ([A]). This direct suggestion provides a clear and concrete action for the authors to take, ensuring that they are aware of the need to include this information in their discussion of related work. The comment is highly actionable as it clearly specifies what needs to be added to the paper, making it easy for the authors to implement the suggested change.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section on related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of related work on modular networks for VQA, such as [A]. This provides clear guidance on how to improve the paper by adding relevant references. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is crucial to mention related work on modular networks for VQA, specifically referencing work [A]. This claim is somewhat verifiable as it logically suggests that including this work would provide a more comprehensive overview of related work in the field. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to make an effort to understand the importance of including this reference and how it would enhance their work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s discussion of related work, noting that it is crucial to mention related work on modular networks for VQA, such as [A]. This feedback is clear and actionable, as it directs the authors to include relevant references that could enhance the comprehensiveness and accuracy of their discussion. By addressing this point, the authors can ensure that their work is properly contextualized and grounded in the existing literature. However, the comment could be more helpful if it provided additional guidance on how to integrate these references effectively into the paper. Overall, the comment is mostly helpful as it effectively points out a gap in the literature review and offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors primarily focus on SSC and do not compare their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should contrast their method with these other methods. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons to these methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on SSC and the need to contrast the method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison with other methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors primarily focus on SSC and do not contrast their method with other methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact methods being compared. Without detailed comparisons or references, the claim is not fully substantiated, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. This feedback is somewhat helpful as it points out a gap in the paper\\'s comparison with other methods, which could enhance its comprehensiveness and relevance. However, the comment lacks specific suggestions on how to address this issue, such as which methods to include or how to structure the comparison. While it highlights an area for improvement, the lack of detailed guidance limits its utility for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to clarify the distinction between when the proposed method is trained using only weak supervision and when it is semi-supervised trained. The reviewer suggests renaming the column in Table 1 to \"Fully supervised\" from \"Supervised\" to reflect this distinction. Additionally, the reviewer proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. These suggestions are clear and provide specific guidance on how to improve the clarity of the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semi-supervised training and the renaming of the column in Table 1. The comment provides detailed guidance on how to clarify this distinction and suggests a more detailed approach for specifying the data used to train each model. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the distinction between weak supervision and semi-supervised training, specifically in Table 1. The reviewer provides a specific example of renaming the column to \"Fully supervised\" from \"Supervised\" to reflect this distinction. Additionally, the reviewer proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. This suggestion is based on logical reasoning and common knowledge about the distinction between weak supervision and semi-supervised training. The comment is mostly verifiable as it provides a clear rationale for the claim and offers a concrete suggestion for improvement. However, it could be strengthened by referencing specific literature or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback on improving the clarity of the paper. It identifies a specific issue with the distinction between weak supervision and semi-supervised training, particularly in Table 1, and suggests renaming the column to \"Fully supervised\" to reflect this distinction. The reviewer also proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. This feedback is highly helpful as it offers concrete steps for the authors to take to improve the clarity and accuracy of their work. By addressing these suggestions, the authors can enhance the readability and comprehensibility of their paper, making it more accessible to readers. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. However, it also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment implies that the authors should address this issue by improving the novelty or differentiating aspects of their work, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should focus on enhancing the novelty or differentiating aspects of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. It also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. However, the comment does not specify which part of the paper discusses these contributions or how they are evaluated. Without explicit references to sections or specific aspects of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. However, the comment does not provide specific examples or detailed reasoning to support these claims. It mentions that it is difficult to differentiate the paper from its predecessors, but it does not explain why this is the case or how the paper could be improved in this regard. The lack of specific examples or detailed reasoning makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique and potentially make additional efforts to understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. However, it also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment identifies a potential issue with the paper\\'s novelty, it lacks specific suggestions or guidance on how the authors might address this challenge. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable advice or detailed insights for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to remove the statement about semantic segmentation being a low-level cue, as it is not accurate given that categories are specified for each pixel. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"semantic\" segmentation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the statement about semantic segmentation being a low-level cue. This provides clear guidance on what needs to be revised or removed from the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"semantic\" segmentation is not low-level since categories are specified for each pixel. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to remove the statement about semantic segmentation being a low-level cue. This feedback is valuable as it helps the authors clarify their terminology and ensure that their claims align with the technical accuracy of their work. By addressing this point, the authors can improve the clarity and precision of their paper. However, the comment could be more helpful if it explained why the statement is inaccurate or provided additional context on the implications of this correction. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this discrepancy or what specific changes should be made to the tables. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or correct the results, but the comment lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the discrepancy in performance without reinforcement learning (RL) dropping lower than without dependency tree and highlights the missing cases in the tables where dependency tree and RL are not used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance without reinforcement learning (RL) dropped lower than without dependency tree in the ablation experiment. However, it does not provide any supporting evidence, such as data or comparisons, to substantiate this claim. Additionally, the comment mentions that the two tables do not list the cases where dependency tree and RL are not used, but it does not explain why this is a concern or how it affects the results. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the results of the ablation experiment, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. This feedback is somewhat helpful as it highlights an area where the authors need to clarify or correct their results. However, the comment lacks specific suggestions on how to address the discrepancy or what additional information should be included in the tables. While it provides some direction, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies the main weakness of the paper as the lack of comprehensive experimental evaluation, specifically the limited consideration of datasets from Federated learning benchmarks. It suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. While the comment provides a clear direction for improvement by recommending specific works to consider, it does not explicitly instruct the authors on how to incorporate these works into their evaluation or how to address the identified weakness. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the main weakness of the paper, which is the lack of comprehensive experimental evaluation on different datasets and model types. The comment suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main weakness of the paper is the limited scope of the experiments, specifically the use of only the CIFAR-10 dataset and the lack of consideration of other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consider relevant works like FedProx and FedMAX to expand the experimental evaluation. While the comment provides a logical reasoning for the need to consider additional datasets, it lacks specific examples or references to the works mentioned, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a clear direction for improvement but requires more detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which only consider the CIFAR-10 dataset and do not consider other datasets from Federated learning benchmarks. It suggests that the authors should consider relevant works like FedProx and FedMAX to expand the experimental evaluation. This feedback is clear and actionable, as it provides specific guidance on how the authors can enhance the comprehensiveness and relevance of their experiments. By addressing this feedback, the authors can significantly improve the quality and impact of their work. However, the comment could be more helpful if it provided additional details on how these works could be integrated or what specific aspects of the experiments should be expanded. Overall, the comment is mostly helpful as it effectively directs the authors to a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the validity of the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, it does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to verify the claim. The comment implies that the authors should consider using another dataset, but it lacks concrete instructions or detailed suggestions on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the table and the claim about accuracy and completeness, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the claim and suggests using another dataset for the ablation study. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. This is a constructive suggestion that could help the authors strengthen their argument by providing additional evidence or comparisons. However, the comment lacks specific guidance on which dataset to use or how to conduct the ablation study. While it identifies a potential weakness, it does not offer detailed instructions or examples on how to address it, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the authors\\' approach of considering only a single vulnerability at a time. It acknowledges the data imbalance issue and questions the ecological validity of such a study. The reviewer also mentions that previous work has considered multiple vulnerabilities or weaknesses simultaneously and asks if the authors are arguing that identifying one vulnerability at a time is an intended use case. The comment concludes by stating that the results are difficult to interpret or may only show marginal improvements. While the comment identifies a potential issue with the methodology, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their approach to vulnerability discovery. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"vulnerability discovery methodology\" and the \"single vulnerability\" approach, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the ecological validity of the study and the results\\' interpretability. The comment provides a clear critique of the methodology and suggests that previous work has considered multiple vulnerabilities or weaknesses at once. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the vulnerability discovery methodology, specifically questioning the authors\\' approach of considering only a single vulnerability at a time. It acknowledges the data imbalance issue and questions the ecological validity of such a study. The reviewer references previous work that considered multiple vulnerabilities or weaknesses simultaneously and reports whether or not the code contains any such vulnerability. The comment suggests that the authors may be arguing that identifying one vulnerability at a time is an intended use case. However, it does not provide specific examples or references to support the claim that previous work considered multiple vulnerabilities. The lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to infer the basis of the reviewer\\'s critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the methodology used for vulnerability discovery, specifically questioning the authors\\' approach of considering only a single vulnerability at a time. It acknowledges the data imbalance issue and questions the ecological validity of such a study. The reviewer references previous work that considered multiple vulnerabilities or weaknesses simultaneously and suggests that the authors\\' approach may not be appropriate. The comment also points out that the results are difficult to interpret, or at best, only show marginal improvements. This feedback is somewhat helpful as it highlights a potential weakness in the methodology and suggests that the authors should reconsider their approach. However, it could be more helpful if it provided specific suggestions on how to address the issue or improve the study\\'s validity. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It suggests that additional explanations are needed to address this issue. However, the comment does not provide specific guidance on how to provide these explanations or what aspects of the relationship should be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanations but may not be entirely sure of the exact details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by the theorems. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2 is not intuitive enough. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks the necessary evidence or explanation to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It points out that while the theorems prove conformity to a clearer community structure, the relationship with degree bias is not intuitive. This feedback is valuable as it highlights a potential gap in the paper\\'s explanation, which the authors can address to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify this relationship or examples of how other works have addressed this issue. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the construction of clean exemplar manifolds for a non-stochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this question. The authors are left to infer that they need to clarify this aspect of their work, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 182-183, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the construction of clean exemplar manifolds for a non-stochastic network and how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the construction of clean exemplar manifolds for a non-stochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. The comment is somewhat verifiable as it highlights a potential inconsistency in the authors\\' explanation, but it lacks specific examples or references to support the claim that the construction of clean exemplar manifolds is unclear. The authors might need to provide additional clarification or examples to fully address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the paper regarding the construction of clean exemplar manifolds for a non-stochastic network. It raises a specific question about how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks, which is a critical aspect of the methodology. By pointing out this discrepancy, the comment provides the authors with a clear and actionable step to address a potential weakness in their work. However, the comment could be more helpful if it offered suggestions on how to clarify this issue or provided examples of how similar questions have been addressed in related literature. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, it does not provide explicit guidance on what additional information is needed or how to clarify this notation. The comment implies that the authors should provide more information, but it lacks concrete steps or suggestions on how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it is confusing. However, it does not specify which part of the paper this notation is used in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does provide some specificity by indicating that more information is required, such as what S and Xt represent. However, without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, the comment does not provide any specific reasoning or examples to support this claim, nor does it offer suggestions for how the authors might clarify the notation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the notation used to separate \"static\" and temporal features into two variables. It points out that this notation is confusing and suggests that more information is required to clarify it. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address this confusion or provide additional information. The feedback is somewhat helpful as it directs the authors to a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3 is not clear and lacks explanation. It suggests that the paper should provide more motivation for this specific form, indicating that it is empirical. However, the comment does not explicitly instruct the authors on how to address this issue or what specific details should be included to clarify the motivation. While the action is implied, it is not as concrete as it could be, as it lacks detailed guidance on how to improve the clarity of the motivation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3\" and \"the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the motivation for the choice of this specific form. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3 is not straightforward and clear. The reviewer notes that the paper states the choice is empirical but lacks detailed motivation for this specific form. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3 is not clear and lacks detailed explanation. It points out that the paper states the choice is empirical but does not provide sufficient motivation for this specific form. While the comment highlights an important area for improvement, it does not offer specific suggestions or guidance on how the authors might clarify the motivation or provide additional context. This limits the comment\\'s helpfulness, as it provides insight but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by providing more details, particularly on the definition of the resistance distance and explanations on Algorithm 1. While the comment implies that these details should be added, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details but may not be entirely sure which specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s content, specifically mentioning the \"many graph notions\" and the difficulty in understanding them. It also provides specific suggestions for improvement, such as the definition of the resistance distance and more explanations on Algorithm 1. However, the comment does not explicitly mention which sections or parts of the paper these issues are related to, making it weakly grounded. The suggestions are specific, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is difficult to understand due to the many graph notions and provides a general observation that the writing is generally good but could be improved with more details. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s complexity due to the many graph notions discussed. It acknowledges that the writing is generally good but suggests that more details could be provided, particularly regarding the definition of the resistance distance and explanations on Algorithm 1. While the comment provides some guidance on areas for improvement, it lacks specific suggestions or examples on how to enhance these explanations. This limits the comment\\'s helpfulness, as it points out an area for improvement but does not offer detailed guidance on how to address it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the originality or suggest alternative approaches to improve the paper. As a result, the authors are left without any clear direction on how to improve the originality of their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of originality, specifically mentioning that the main idea of variable splitting is not new and the algorithm is not new. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered unoriginal, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a limitation in the originality of the paper, specifically noting that the main idea of variable splitting is not new and the algorithm is not new. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the evaluation of shape model invariance, specifically asking if there are any quantitative results on testing images. While the comment implies that the authors should include such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide quantitative results on testing images. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the evaluation on transformations of training images and asks for quantitative results on testing images. This provides clear guidance on what additional information is needed to support the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the evaluation on transformations of training images for the shape model invariance study. It suggests that quantitative results on testing images might be needed to fully prove the point. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid point about the evaluation of shape model invariance, specifically questioning the use of transformations of training images to prove the point. It suggests that quantitative results on testing images might be necessary to fully substantiate the claim. While the comment identifies a potential weakness in the evaluation, it does not provide specific guidance or suggestions on how to address this issue. The authors are left with a clear direction but without detailed instructions on how to implement the suggested improvement. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the omission of a related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the state-of-the-art. The action is clear and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the omission of this related work and its potential impact on the understanding of the state-of-the-art. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared with the current work. The reviewer provides a logical reasoning by suggesting that the AAAI15 paper deals with hypergraph data with tensors, which is relevant to the current work. However, the comment lacks specific examples or references to the content of the AAAI15 paper, making it somewhat verifiable. The authors would need to conduct additional research to fully understand the relevance and potential contributions of the AAAI15 paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which is relevant to the current work but has been overlooked. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the state-of-the-art. This feedback is clear and actionable, as it directs the authors to include a relevant reference that could enhance their understanding and analysis. However, the comment could be more helpful if it provided specific insights or suggestions on how to integrate this reference into the paper. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it would be beneficial to test its scalability on normal machines with a few cores. It also questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific tests should be conducted. The action is implicit and somewhat vague, as the authors need to infer that they should test scalability and clarify the computation of optimal transport. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Approach\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the scalability of the method and questions how the authors compute the optimal transport distance, particularly in relation to the Sinkhorn method. The comment provides clear guidance on what needs to be addressed, such as testing scalability on normal machines and clarifying the computation of optimal transport. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it is not clear how scalable the method is. The reviewer questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies potential issues, it lacks specific examples or references to support the claim that the method is not scalable or how it could be improved. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the scalability of the method and its computation of optimal transport distance. It raises questions about how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. This feedback is valuable as it prompts the authors to consider the scalability of their method on normal machines with a few cores, which is an important aspect for practical applications. Additionally, the comment highlights the need to clarify the computation of optimal transport, providing a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to test scalability or how to address the computational issue. Overall, the comment is mostly helpful as it provides actionable guidance for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of an ablation study, specifically mentioning the \\sigma in the RBF kernel and the \\eta and \\tau in equation (7), which could cause confusion and extra experimentation for practitioners. It suggests that these elements should be analyzed to provide a more comprehensive understanding of the model's performance. While the comment explicitly identifies the missing analysis, it does not provide specific guidance on how to conduct the ablation study or what aspects to focus on. The action is clear but lacks detailed instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"equation (7),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing, namely an analysis of the \\sigma in the RBF kernel and the \\eta and \\tau in equation (7), which could cause confusion and extra experimentation for practitioners. The comment provides a clear direction for improvement by suggesting these elements should be analyzed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some ablation studies are missing, specifically mentioning the \\sigma in the RBF kernel and the \\eta and \\tau in equation (7), which could cause confusion and extra experimentation for practitioners. The comment suggests that these elements should be analyzed to provide a more comprehensive understanding of the model's performance. However, the comment lacks specific examples or detailed reasoning to support why these elements are crucial or how they affect performance. While it identifies a potential issue, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of an ablation study that could cause confusion and extra experimentation for practitioners. It specifically mentions the \\sigma in the RBF kernel and the \\eta and \\tau in equation (7), which are crucial elements that should be analyzed to provide a more comprehensive understanding of the model's performance. The comment also offers minor suggestions for improvement, such as analyzing the impact of \\lambda on performance. This feedback is clear and actionable, providing the authors with specific areas to address to enhance the clarity and comprehensiveness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper is extremely hard to follow, indicating that the authors need to improve the clarity and comprehensibility of their work. However, it does not provide any specific guidance on how to achieve this improvement, such as suggesting ways to simplify the experimental procedures or evaluations or offering examples of how the paper could be made more accessible. The lack of explicit or implicit actions makes it difficult for the authors to know exactly what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the paper is difficult to follow, but it does not specify which parts of the paper are particularly challenging to understand. Without explicit references to sections, figures, or specific experimental procedures, the authors cannot confidently determine which parts need improvement. The comment lacks specificity regarding what aspects of the paper are confusing or how they could be clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is \"extremely hard to follow,\" indicating that the reviewer had difficulty understanding the experimental procedures and evaluations. However, the comment does not provide specific examples or details about what aspects of the paper were challenging to follow, nor does it offer suggestions for improvement. Without these details, the authors may find it difficult to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, stating that it is \"extremely hard to follow.\" This feedback highlights a critical weakness in the clarity and accessibility of the paper, which is important for ensuring that readers can understand and engage with the research. However, the comment lacks specificity and does not provide any guidance on how the authors might improve the clarity or structure of their work. Without actionable suggestions or examples, the authors are left without a clear path forward to address this issue. Therefore, the comment is somewhat helpful, as it points out a significant problem but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the claim made in section 2 that INRs operate on a per-data-instance basis, suggesting that this is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a per-data-instance basis, suggesting that this is not an advantage. However, the comment does not provide specific guidance on what aspect of the claim is questionable or how it could be improved. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the claim that INRs operate on a per-data-instance basis, suggesting that this is not an advantage. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the claim made in section 2 that INRs operate on a per-data-instance basis, suggesting that this is not an advantage. The reviewer points out that a model that can only handle a single time series data is almost useless. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this concern or what aspects of the claim are misleading. As a result, the comment is not helpful, as it does not provide the authors with a clear path forward to enhance their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to consider introducing specific aspects of their model that are relevant to the example model. It provides a clear example of what needs to be addressed, such as the fact that the model is not operating in a setting with infinite subdivisions for \\u03b3^1 and \\u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is concrete and provides specific guidance on how to improve the draft by introducing these aspects. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction of specific aspects of the model that are relevant to the example model, such as the fact that the model is not operating in a setting with infinite subdivisions for \\u03b3^1 and \\u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should introduce specific aspects of their model that are relevant to the example model, such as the fact that the model is not operating in a setting with infinite subdivisions for \\u03b3^1 and \\u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). This claim is somewhat verifiable as it provides a logical reasoning for why these aspects should be introduced, but it lacks specific examples or references to support the claim fully. The authors might need to infer the exact aspects to include and how they would be introduced, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors introduce specific aspects of their model that are relevant to the example model. It highlights the importance of clarifying that the model is not operating in a setting with infinite subdivisions for \\u03b3^1 and \\u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is clear and directs the authors to enhance the clarity and completeness of their model description. By addressing these points, the authors can improve the understanding and applicability of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTa-base and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. Additionally, it recommends including more analysis and discussion for GPT-2, specifically asking for the results of Figure 2 for GPT-2. The comment provides explicit actions for the authors to take, such as expanding the experiments to include more models and including additional analysis for GPT-2. The suggestions are concrete and provide clear guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to investigate whether the results can be generalized to other models, and it provides a concrete suggestion to include more analysis and discussion for GPT-2. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited to RoBERTa-base and questions whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. The reviewer provides a logical reasoning by pointing out that the experiments should be expanded to include more models, such as GPT-2, and that this would be beneficial for understanding the generalizability of the results. However, the comment lacks specific examples or references to support the claim that these differences would significantly impact the results. Therefore, the claim is somewhat verifiable, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTa-base and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture, and provides a specific example by asking for more analysis and discussion of GPT-2. This feedback is clear and actionable, as it directs the authors to expand their experiments and include additional analysis to enhance the generalizability of their results. By addressing these points, the authors can significantly improve the robustness and applicability of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. While the comment implies that the authors should explore these applications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their work to include these other areas. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the model and experiments to other research areas, such as NLP or simpler models in the image domain (CNNs). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. However, the comment lacks specific examples or references to support the claim that the model and experiments are limited to image data and ViT. Without such evidence or reasoning, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. This feedback is valuable as it prompts the authors to consider expanding their work beyond the specific focus on transformers in vision, which could enhance the method\\'s versatility and broader applicability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might explore these other areas. Overall, the comment is mostly helpful as it encourages the authors to consider a broader scope for their work, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate TTA methods on more conditions of natural distribution shift, like WILDS [9], to strengthen the paper. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Performance of TTA methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating TTA methods on more conditions of natural distribution shift, like WILDS, to strengthen the paper. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that using non-standard benchmarks breaks popular TTA methods and recommends evaluating TTA on more conditions of natural distribution shift, like WILDS. However, the comment does not provide specific examples or references to support this claim, nor does it explain why using non-standard benchmarks is significant or how it affects the performance of TTA methods. Without additional context or evidence, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the suggestion without further elaboration.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies an interesting observation about the performance of TTA methods under non-standard benchmarks, suggesting that evaluating these methods on more conditions of natural distribution shift, like WILDS, could strengthen the paper. This feedback is somewhat helpful as it points out a potential area for improvement and provides a specific suggestion for enhancing the paper. However, it lacks detailed guidance on how to implement this suggestion or what specific aspects of the TTA methods should be evaluated. While it offers a direction for improvement, the comment could be more actionable with additional details. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. The reviewer suggests that this condition is not realistic and may lead to unreasonably large learning rates when learning on large-scale datasets. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on whether the authors should adjust the condition, provide a rationale for its necessity, or explore alternative approaches. As a result, the authors are left without actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. It provides a clear rationale for why this condition is not realistic and may lead to unreasonably large learning rates when learning on large-scale datasets. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the learning rate condition and its implications, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the condition on the learning rate is not scalable, as it does not grow with the number of samples in practice. The reviewer provides a logical reasoning by explaining that this condition leads to unreasonably large learning rates when learning on large-scale datasets. However, the comment lacks specific examples or references to support the claim that this condition is not realistic. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. This is a critical observation, as it highlights a potential flaw in the methodology that could lead to unreasonably large learning rates when learning on large-scale datasets. The reviewer provides a logical reasoning for why this condition is not realistic and suggests that the authors need a way to precisely characterize the benefit of large learning rates. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or explore alternative approaches. Despite this, the feedback is still valuable as it points out a critical aspect of the methodology that the authors should consider improving. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the paper need clarification. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of tensor networks to represent PMF of discrete variables and questions the significance of the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of clarity regarding the utility of tensor networks and the significance of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. It highlights a potential weakness in the paper\\'s contribution, which could impact its impact and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the paper\\'s significance. While it points out a potential area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use a more convincing setting for training, similar to that used in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification. It provides a specific reference to the paper by He et al. (EMNLP 2018) as an example of a convincing setting. This feedback is explicit and provides a clear action for the authors to take, which is to adopt a more convincing training approach. The suggestion is concrete and provides a direct path for the authors to follow, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)\" and suggests that the label distribution of unlabeled data during training is impractical in real-world applications. It also references a specific paper, \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018,\" which provides a more convincing setting for training. This level of detail allows the authors to identify the specific part of the paper being addressed and the issue being raised. The comment is also specific, as it clearly specifies what needs to be addressed regarding the training setting. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unlabeled data from the preprocessed Amazon review dataset is perfectly balanced, which is impractical in real-world applications. The reviewer suggests that the authors should use a more convincing setting, like the one described in the paper \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018,\" which directly samples unlabeled data from millions of reviews. The comment provides a specific reference to a relevant paper, which supports the claim by offering a practical example of a more convincing setting. This makes the claim mostly verifiable, as it provides a logical basis and a concrete example for the authors to consider. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the unlabeled data from the preprocessed Amazon review dataset, noting that it is perfectly balanced, which is impractical in real-world applications. It suggests that the authors should use a more convincing setting, like the one described in the paper \"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018,\" which directly samples unlabeled data from millions of reviews. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving their draft. By addressing this issue, the authors can enhance the realism and applicability of their work. However, the comment could be more helpful if it explained why this specific setting is more convincing or how it might impact the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding how to sample from the DPP if the eigenfunctions e_n are inaccessible, referencing a specific line in the paper (line 130). It also mentions a similar issue with sampling from the leverage score in a previous work. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the clarity of their explanation. The action is implicit and vague, as the authors are left to infer that they need to clarify their sampling process, but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 130\" and \"Eq (10),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the problem of sampling from the DPP when the eigenfunctions e_n are inaccessible, and it references a similar issue in a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing a specific line in the paper (line 130). It also mentions a similar issue in a previous work, suggesting that sampling from the DPP might be more difficult than sampling from the leverage score. However, the comment lacks specific examples or detailed reasoning to support the claim that sampling from the DPP is more challenging. While it points out a potential problem, the lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to further explore the issue to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper regarding the sampling process from the DPP when the eigenfunctions e_n are inaccessible. It references a specific line in the paper (line 130) and compares it to a similar issue in a previous work, suggesting that sampling from the DPP might be more difficult than sampling from the leverage score. This feedback is clear and actionable, as it points out a potential gap in the explanation and provides a reference to a similar problem in the literature. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the clarity of the explanation. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and provides a relevant reference, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the evaluation of the generalizability of observations to few-shot learners beyond Prototypical Networks. It points out that this limitation may impact the scope of the submission's contributions regarding understanding the properties of episodic training. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to evaluate the generalizability. The action is implicit and somewhat vague, as the authors can infer that they need to expand their evaluation to include other few-shot learners, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of evaluation on the generalizability of observations to few-shot learners beyond Prototypical Networks. This provides full grounding as it clearly identifies the part of the paper being addressed, which is the evaluation section. However, the comment is not specific in detailing what aspects of the evaluation are missing or how the authors could address this gap. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the observations presented do not evaluate the generalizability to few-shot learners beyond Prototypical Networks, which may limit the scope of the paper\\'s contributions regarding understanding the properties of episodic training. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation of the generalizability of observations to few-shot learners beyond Prototypical Networks. It points out that this limitation may impact the scope of the paper\\'s contributions regarding understanding the properties of episodic training. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this gap. Providing examples of other few-shot learners or offering suggestions on how to evaluate the generalizability would enhance the helpfulness of the comment. As it stands, the comment is somewhat helpful, as it directs the authors\\' attention to a critical area for improvement but does not fully support them in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the contribution of different modalities of different instances, specifically mentioning that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address this issue, specifically asking for guidance on how to deal with the problem. However, the comment does not provide explicit instructions or concrete suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider the contribution of different modalities and address the problem, but the comment lacks detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the contribution of different modalities of different instances, specifically mentioning modalities A and B and their performance in different instances. It raises a question about how to deal with the problem of removing the modal subset of all instances, as described in Equation 3. This provides full grounding as it clearly identifies the part of the paper being addressed, which is the discussion of modalities and their contribution. The comment is also specific because it details the issue of removing the modal subset and asks for guidance on how to address it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the contribution of different modalities of different instances, specifically mentioning that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address the problem of removing the modal subset of all instances, as described in Equation 3. However, the comment lacks specific examples or references to support the claim that the contribution of different modalities is different. Without detailed evidence or reasoning, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper regarding the contribution of different modalities of different instances. It highlights that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address the problem of removing the modal subset of all instances, as described in Equation 3. This feedback is somewhat helpful as it points out a potential issue that the authors need to consider and address. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative methods or discussing potential implications. While it provides some insight, the feedback could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback provides clear and concrete actions for the authors to take, such as adding a description of the evaluation process and addressing language issues. The comment is specific and direct, giving the authors a clear understanding of what needs to be added or improved. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues on page, providing specific guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that it does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback is clear and actionable, as it provides the authors with a concrete direction for improving their draft by adding a description of the evaluation process and addressing language issues. However, the comment could be more helpful if it offered suggestions on how to structure the evaluation section or provided examples of what such a description might look like. Overall, the comment is mostly helpful as it guides the authors toward improving their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the experimental results and questions the absence of experiments on a specific setting. It highlights the need for experiments on surveillance in museums with thresholded rewards and privacy-preserving data collection. While the comment identifies a specific issue with the experimental section, it does not provide explicit guidance on how to address this concern. The authors are left to infer that they should include experiments on these settings, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental results and the specific setting of the POMDP problem with non-convex value functions. It also specifies the issue with the experiments section, noting the absence of experiments on surveillance in museums with thresholded rewards and privacy-preserving data collection. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the experimental results, specifically the absence of experiments on specific settings. It references the examples of surveillance in museums with thresholded rewards and privacy-preserving data collection as motivating cases for the paper. However, the comment lacks specific evidence or detailed reasoning to support why these examples are insufficient or why the experiments are not useful. The claim is somewhat verifiable, as it highlights a potential issue but does not provide sufficient justification or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental results, questioning the validity of the paper\\'s claims. It points out the absence of experiments on specific settings, such as surveillance in museums with thresholded rewards and privacy-preserving data collection, which are used as examples to motivate the paper\\'s solution. This feedback highlights a critical gap in the experimental section, making it clear that the authors need to address this issue to strengthen their work. However, the comment could be more helpful if it provided suggestions on how to conduct these additional experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors\\' attention to a crucial area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \\u03c4 and the use of sparse labels. It questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. The comment implies that the authors should clarify this confusion by providing more detailed explanations or examples. However, it does not explicitly instruct the authors to make these changes or suggest specific ways to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should address the confusion and provide more detailed explanations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Method Section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the description of the MFDA setting, particularly the use of sparse labels and the notation for target domain \\u03c4. The comment further questions the use of unlabeled data in source domains and references the original MFDA paper by Yue et al. (2021a) for clarification. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \\u03c4 and the use of sparse labels. The reviewer questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper by Yue et al. (2021a). The comment is somewhat verifiable as it provides a logical basis for the confusion, referencing the original paper for clarification. However, it lacks specific examples or detailed explanations to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for target domain \\u03c4 is unlabeled and questions the use of sparse labels, which is not consistent with the original MFDA paper by Yue et al. (2021a). The comment also highlights the confusion regarding the use of unlabeled data in source domains during training. By pointing out these inconsistencies and questions, the comment provides clear and actionable feedback for the authors to improve the clarity and accuracy of their description. However, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how the description could be improved. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that epoch-wise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after each full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a clear rationale for why epoch-wise analysis could be valuable, it does not explicitly instruct the authors on how to implement this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that epoch-wise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It provides a specific example of how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after each full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The suggestion is specific, as it clearly outlines the potential benefits of epoch-wise analysis and how it could be applied to the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that epoch-wise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after each full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a logical reasoning for the potential benefits of epoch-wise analysis, it lacks specific examples or references to support the claim. The suggestion is somewhat verifiable, as it provides a clear rationale but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It suggests that epoch-wise analysis, particularly in finite sum settings, could offer insights into the behavior of optimization algorithms. The reviewer highlights the potential benefits of this analysis, such as investigating the effect of batch size or different sampling strategies on the progress of algorithms after each full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. This feedback is valuable as it offers a specific direction for the authors to enhance their analysis and provide a more comprehensive understanding of their results. However, the comment could be more helpful if it included examples or references to similar studies that have successfully employed epoch-wise analysis. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the immense workload, the incremental contribution, and the lack of citation of key baselines. It also points out that the paper focuses on RAG for EHR and suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific details to include. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"details in the article\" and \"your workload is immense,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the contribution being incremental and the lack of citation of key baselines, as well as the need to introduce essential RAG algorithms like MedRetriever and KGRAG. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is incremental and essentially a combination of GraphRAG and GraphCare, referencing the lack of citation of key baselines and the absence of essential RAG algorithms like MedRetriever and KGRAG. The reviewer supports this claim by referencing specific works, which provides a logical basis for the critique. However, the comment could be strengthened by providing more detailed reasoning or examples of how these algorithms would enhance the paper. Overall, the claim is mostly verifiable due to the reference to specific works, but it could be further substantiated with additional details or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the immense workload and the incremental contribution, which are not fully explained. It points out that the paper essentially combines GraphRAG and GraphCare, and that key baselines were not cited. The reviewer also suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced to enhance the paper's contribution. These suggestions provide clear and actionable feedback for the authors to improve their draft. However, the comment could be more helpful if it offered specific guidance on how to integrate these algorithms or what aspects of the workload and contribution should be emphasized. Overall, the comment is mostly helpful as it highlights areas for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the distinction between the three classes of extreme speech, particularly the difficulty in differentiating between derogatory and exclusionary extreme speech. It questions the annotation of a specific instance in the sample data file and seeks clarification on the local regulation over speech that might influence the classification. The reviewer implies that the authors should provide more detailed explanations or examples to clarify this distinction. While the comment does not explicitly instruct the authors to make changes, it implies a clear action for the authors to take, such as providing additional context or examples to clarify the distinction. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the \"sample data file,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the distinction between derogatory and exclusionary extreme speech, and it provides a specific example from the sample data file to illustrate the confusion. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the distinction between the three classes of extreme speech, specifically derogatory and exclusionary extreme speech. The reviewer questions the annotation of a specific instance in the sample data file and seeks clarification on the local regulation over speech that might influence the classification. The comment is somewhat verifiable as it provides a specific example to illustrate the confusion, but it lacks detailed reasoning or references to support the claim that the distinction is unclear. The authors would need to provide more detailed explanations or examples to fully address the reviewer\\'s concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the distinction between the three classes of extreme speech, particularly between derogatory and exclusionary extreme speech. It questions the annotation of a specific instance in the sample data file and seeks clarification on the local regulation over speech that might influence the classification. This feedback is valuable as it highlights a potential area of confusion in the paper that could impact the reader\\'s understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the distinction or examples of how to differentiate between the classes. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be included in the graph and why it is important. The comment also offers a rationale for why this graph is necessary, helping the authors understand the potential sources of performance improvement. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be included in the graph and why it is important to understand the sources of performance improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This claim is somewhat verifiable as it logically suggests that such a graph would help clarify whether the performance improvement is solely due to the network design or whether it is influenced by the nature of ImageNet. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This is a specific and detailed piece of feedback that can help the authors better understand the performance improvement and its potential sources. The comment also offers a rationale for why this graph is important, highlighting the potential influence of the nature of ImageNet on performance and the need to distinguish between network design and other factors. This level of detail and guidance makes the comment highly helpful, as it empowers the authors to make a meaningful enhancement to their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper needs to be mathematically correct and provides a specific example of a notation issue with \"L_l\" instead of \"L.\" It also mentions that the notation should be introduced beforehand. While the comment identifies areas that need attention, it does not provide explicit instructions on how to address these issues or what specific changes are needed. The authors are left to infer that they need to make these corrections, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.\" and \"L_l instead of just L,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the notation \"L_l\" and suggests that it should be introduced beforehand. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper needs to be mathematically correct and provides specific examples of notation issues, such as \"L_l\" instead of \"L.\" It also questions the notation \"L_l\" and suggests that it should be introduced beforehand. While the comment identifies specific issues, it lacks detailed reasoning or references to support why these changes are necessary or how they would improve the paper. The authors are left to infer the importance of these corrections, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the notation used in the paper, suggesting that it needs to be mathematically correct and providing examples of notation errors. It also questions the notation \"L_l\" and suggests that it should be introduced beforehand. This feedback is clear and actionable, as it directs the authors to make necessary corrections to ensure mathematical correctness and improve the clarity of their notation. However, the comment could be more helpful if it provided additional guidance on how to address these issues or suggested alternative approaches. Overall, the comment is mostly helpful as it effectively points out areas for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also notes that this limitation prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take to study the effect of noise accumulation. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to implement the suggested study. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sequential ensembling\" and \"homomorphic encryption,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the importance of studying the effect of noise accumulation in the context of homomorphic encryption, which is a critical limitation for using deep neural networks on encrypted data. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that noise accumulation in the context of homomorphic encryption is a critical limitation for using deep neural networks on encrypted data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical limitation in the study of sequential ensembling in the context of homomorphic encryption. It points out that the accumulation of noise in homomorphic encryption prevents the use of even single deep neural networks on encrypted data. This is a valuable observation that highlights a significant gap in the literature and provides a clear direction for future research. However, the comment could be more helpful if it offered suggestions on how the authors might address this limitation or what specific aspects of the study should be explored. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance of the baseline model and the time-aware model is similar when trained and evaluated with the same time-step, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation time-steps are different. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the method. The action is implicit and somewhat vague, as the authors need to infer that they should consider different time-steps for training and evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the baseline model and the time-aware model is similar when trained and evaluated with the same time-step, which raises questions about the effectiveness of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation time-steps are different. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of the baseline model and the time-aware model is similar when trained and evaluated with the same time-step, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation time-steps are different. However, the comment lacks specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to infer the relevance of different time-steps and how they might impact the effectiveness of the proposed methods. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the effectiveness of the proposed methods, noting that the performance of the baseline model and the time-aware model is similar when trained and evaluated with the same time-step. This observation raises questions about the novelty and practical relevance of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation time-steps are different. While the comment highlights an important point, it lacks specific suggestions or guidance on how the authors might address this issue or explore different time-steps. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the disentanglement aspect of the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed. The reviewer suggests that the authors should clarify this aspect by explaining how disentanglement is realized and what types of bias are involved. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Broader Impacts and Limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how disentanglement is achieved and guaranteed without certain bias types. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that disentanglement is not clearly explained and questions how it is achieved and guaranteed without certain bias types. While the comment references the \"Broader Impacts and Limitations\" section, it does not provide specific examples or detailed reasoning to support the claim that disentanglement is unclear. The reference to the \"Broader Impacts and Limitations\" section suggests that the authors have acknowledged the limitation, but the comment lacks further elaboration or evidence to substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the disentanglement aspect in the paper. It points out that while the \"Broader Impacts and Limitations\" section acknowledges a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed without certain bias types. The comment suggests that the authors should clarify this aspect to enhance the clarity and comprehensiveness of their work. This feedback is clear and actionable, as it directs the authors to address a specific gap in their explanation of disentanglement. However, it could be more helpful if it provided examples or additional guidance on how to effectively present this information. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case, the authors should use a standard regularization trick. While the comment implies that the authors should apply this standard technique, it does not provide explicit instructions on how to implement it or which specific regularization trick to use. The action is clear but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the use of a standard regularization trick, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this standard technique is necessary or how it would improve the comparison. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered a valid suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance on which standard regularization trick to use or how it would impact the comparison. The feedback is somewhat helpful as it points out a potential issue but does not offer detailed instructions or examples to help the authors address it effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This is a clear and concrete action for the authors to take, as it provides a specific enhancement to the figure that would help clarify the impact of mean teacher on learning. The suggestion is direct and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 3\" and \"left graph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is a learning curve for a model without mean teacher or pi regularization. This provides clear guidance on how to enhance the figure and compare the impact of mean teacher on learning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This is a request for additional data or analysis, which is a logical suggestion for improving the paper. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would impact the results. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is somewhat verifiable, as it provides a logical suggestion but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It recommends adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This additional analysis would help clarify whether mean teacher accelerates or slows down learning. By suggesting this enhancement, the comment offers a clear and constructive way for the authors to improve their draft. However, it could be more helpful if it provided additional context or rationale for why this comparison is important or how it might impact the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed objective in Eq. 2 in line 128 requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S. It also notes that the effect on the number of parameters versus prior work, such as AlignFlow, has not been discussed clearly. While the comment identifies a specific issue with the discussion of parameters and prior work, it does not provide explicit guidance on how to address this issue or what specific aspects of the discussion need clarification. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information about the number of parameters and their comparison to prior work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 128\" and \"Eq. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the objective requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S, and that the effect on the number of parameters versus prior work, such as AlignFlow, has not been discussed clearly. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed objective in Eq. 2 in line 128 requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S, and that the effect on the number of parameters versus prior work, such as AlignFlow, has not been discussed clearly. However, the comment lacks specific examples or references to support the claim about the number of parameters or the comparison to prior work. The reasoning is based on logical reasoning and common knowledge, but it does not provide detailed evidence or references to substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks specific examples or references to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed objective in Eq. 2 in line 128, noting that it requires optimization over both the parameters of the transformation \\phi and the shared model \\theta_S. It also points out that the effect on the number of parameters versus prior work, such as AlignFlow, has not been discussed clearly. This feedback is somewhat helpful as it highlights a potential gap in the discussion of the number of parameters and their comparison to prior work. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific aspects of the discussion need clarification. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the need to discuss how to handle different types of inputs and the disorganization of the citation. While the first point suggests that the authors should discuss their solutions for handling different input types, it does not provide specific guidance on how to structure this discussion or what aspects to cover. The second point mentions that the citation seems disorganized but does not offer suggestions for improvement. Both points are implicit, as the authors need to infer what actions to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to discuss \"different types of inputs\" and the disorganization of the citation, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to discuss how to handle different input types and the disorganization of the citation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two claims: the need to discuss different types of inputs and the disorganization of the citation. The first claim is somewhat verifiable as it suggests that the paper should include a discussion on how to handle different input types, but it lacks specific examples or detailed reasoning on why this is necessary. The second claim about the citation being disorganized is somewhat verifiable as it points out a potential issue but does not provide specific examples or guidance on how to improve the organization. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two areas for improvement: discussing different types of inputs and addressing the disorganization of the citation. While it highlights these issues, it does not provide specific guidance or suggestions on how to address them. The comment lacks depth and actionable advice, leaving the authors with a general understanding of what needs to be improved but without detailed steps to achieve it. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, specifically mentioning the OfficeHome dataset where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the implications of Eq. 4 and potentially improve the results in Table 5, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the implications of Eq. 4 and noting the lack of significant improvement in the designed solutions in Table 5, particularly on the OfficeHome dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This claim is somewhat verifiable as it provides some logical reasoning and specific examples to support the observation. However, it could be strengthened by providing more detailed analysis or references to substantiate the claim further. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This feedback is somewhat helpful as it points out a potential issue with the results and suggests that the authors might need to reconsider their approach. However, the comment could be more helpful if it provided suggestions on how to address this issue or improve the results. Overall, the comment identifies a specific area for improvement but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of specific state-of-the-art references in the face recognition experiment, particularly mentioning \"Baidu's work\" and its reported results. It also highlights the use of the triplet loss and the similarity to the Webface dataset. The comment provides a clear and specific action for the authors to include these references in their work. Additionally, it suggests that the VRF achieved a better result than reported in Table 3, which could be a valuable comparison for the authors to make. The action is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and the specific references that are missing, such as \"Baidu\\'s work\" and \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding.\" It also provides specific details about the triplet loss and the reported results, which allows the authors to identify the exact parts of the paper being addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some state-of-the-art references are missing in the face recognition experiment, specifically mentioning \"Baidu\\'s work\" and its reported results. The reviewer provides a specific reference to the work, which is a clear and verifiable claim. Additionally, the comment provides a detailed comparison with the Webface dataset, which further strengthens the claim. The inclusion of specific references and data points makes the claim fully verifiable, as it provides clear evidence and logical reasoning for the claim. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup in the paper, noting the absence of certain state-of-the-art references, such as \"Baidu\\'s work\" and its reported results. It provides a detailed comparison with the Webface dataset, highlighting the reported results and suggesting that the VRF achieved a better result than reported in Table 3. This feedback is clear and actionable, as it directs the authors to include these references and potentially compare their results with the state-of-the-art. By addressing this feedback, the authors can enhance the rigor and comprehensiveness of their experimental evaluation. Therefore, the comment is mostly helpful, as it provides a concrete direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Wh-types\" or transformable. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the generalization. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to question answering, but the comment lacks concrete details on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Wh-types\" or transformable. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with the question answering process, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the question answering process, which involves template mapping to transform questions into masked statements, might lead to poor generalization to questions that are not \"Wh-types\" or transformable. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to studies or literature that demonstrate the limitations of this approach or how it affects generalization. As a result, the claim is somewhat verifiable, as it requires further elaboration and evidence to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Wh-types\" or transformable. While the comment highlights a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or improve their question answering process. The feedback is somewhat helpful as it points out a potential problem but does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or suggestions for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"VolumeDeform [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the issue is: the use of a volumetric representation in the deformation field is not novel, as it has been proposed by VolumeDeform [1]. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, the comment does not provide specific details or references to VolumeDeform to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any constructive feedback or suggestions for improvement. It lacks depth and actionable guidance, leaving the authors without a clear understanding of how to address the issue or enhance their work. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the ICL-HAR has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. It suggests that this issue should be discussed or at least acknowledged in the main text in more detail. This provides a clear and direct action for the authors to take, as they are instructed to address this issue in their draft. The comment is specific and provides concrete guidance on how to improve the paper by discussing or acknowledging the impact of the ICL-HAR on accuracy scores. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the ICL-HAR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ICL-HAR, stating that it has impeded accuracy scores and dropping them from 70.4 to 55.6 on TRIP. This provides clear guidance on what needs to be addressed in the paper, namely the discussion or acknowledgment of this issue in more detail. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ICL-HAR has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. This claim is supported by the provided data, which shows a significant decline in accuracy scores. However, the comment could be strengthened by providing more detailed analysis or explanation of why this decline occurred or how it affects the overall contribution of the paper. While the data itself is a strong indicator, additional context or reasoning would enhance the verifiability of the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ICL-HAR, noting that it has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. This is a clear and actionable observation that the authors should address in their draft. The comment suggests that the issue should be discussed or at least acknowledged in the main text in more detail, providing a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or what aspects of the ICL-HAR might be contributing to the accuracy drop. Overall, the comment is mostly helpful as it highlights a significant issue that the authors should address to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to cite the source of the rock-paper-scissors example, which is clearly inspired by previous work. This is a direct and concrete action, as it specifies the exact source that needs to be cited. The authors know exactly what needs to be done to address the comment, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to cite the source of the example. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by previous work and suggests that the source should be cited appropriately. However, the comment does not provide specific examples or references to the previous work that inspired the example, making it difficult for the authors to verify the claim. Without additional context or evidence, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the rock-paper-scissors example is inspired by previous work and should be appropriately cited. This is a clear and actionable piece of feedback, as it directly instructs the authors to cite the source of the example. By addressing this point, the authors can ensure that their work is properly credited and that they are not inadvertently plagiarizing others\\' work. Therefore, the comment is highly helpful, as it provides a clear and constructive suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the innovations or how to improve the performance of the oracle expert. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the innovations in network architecture design and constraint embedding are limited, and that the performance is constrained by the performance of the oracle expert. However, it does not specify which part of the paper discusses these innovations or the performance of the oracle expert, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the issue of limited innovation and the constraint on performance, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the innovations in network architecture design and constraint embedding are limited, and that the performance is constrained by the performance of the oracle expert. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically that the innovations in network architecture design and constraint embedding are limited, and that the performance is constrained by the performance of the oracle expert. While it highlights a potential issue, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this limitation or improve their work. Without detailed feedback or constructive advice, the authors are left without a clear path forward. Therefore, the comment is rated as barely helpful, as it points out a weakness but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that comparing the performance of a model pre-trained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors instead. It further suggests that the authors should provide the performance of the model pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. While the comment provides a clear action\u2014to demonstrate the importance of the projection errors and fine-tune the model on real-world datasets\u2014it does not specify how to implement this action or what specific steps to take. The authors are left with a general idea of what needs to be done but without detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of comparing the performance of a model pre-trained on synthetic data, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the need to demonstrate the importance of the proposed three projection errors and suggests providing performance metrics for models pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that comparing the performance of a model pre-trained on synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors instead. The comment provides a logical reasoning by suggesting that fine-tuning the model on real-world datasets with different losses is necessary to showcase the model's performance. However, the comment lacks specific examples or references to support the claim that the current comparison is unfair. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s comparison of model performance, suggesting that comparing a model pre-trained on synthetic data is unfair. It recommends demonstrating the importance of the proposed three projection errors and provides a clear suggestion for improvement by suggesting that the authors should provide performance metrics for models pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. This feedback is actionable and offers a clear direction for the authors to enhance their analysis and presentation. However, it could be more helpful if it included specific examples or guidance on how to implement the suggested changes. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, it does not explicitly instruct the authors to average over subword representations or provide guidance on how to implement this suggestion. The action is implied and somewhat vague, as the authors need to infer that they should consider averaging over subword representations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider averaging over subword representations, as done by Hewitt and Manning (2019, footnote 4). This feedback is actionable and provides a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it is common practice to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, the comment does not provide specific examples or detailed reasoning to support why this is a common practice or how it would benefit the current work. While it references a specific work, the lack of detailed explanation or justification makes the claim somewhat verifiable. The authors would need to infer the importance of this suggestion and potentially conduct additional research to fully understand its relevance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the language used in the paper, noting that it is common practice to average over subword representations in similar cases. It provides a reference to a specific work by Hewitt and Manning (2019, footnote 4) to support this claim. This feedback is somewhat helpful as it points out a potential area for improvement and offers a reference for further exploration. However, it could be more helpful if it provided more detailed guidance on how to implement this suggestion or why it might be beneficial for the authors to consider it. Overall, the comment is somewhat helpful as it directs the authors to a potential area for improvement but lacks depth and actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to discuss the difference between their method and traditional methods. While the comment provides a clear action to take, it lacks specific guidance on how to conduct the calibration curves or what aspects of the traditional method should be discussed. The authors are given a general direction but may need to infer the exact steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the model AUC and its ability to assess model discriminant ability, as well as the consistency between predicted scores and actual risks. It suggests conducting calibration curves to demonstrate this consistency, which is crucial for the clinical scoring system. The comment also mentions the difference between the traditional method and the authors\\' method, which could be discussed in the paper. However, the comment does not explicitly mention which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as conducting calibration curves and discussing the difference between traditional and novel methods. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model AUC can assess the model discriminant ability but may not demonstrate consistency between predicted scores and actual risks. It suggests that this consistency is crucial for the clinical scoring system and recommends conducting calibration curves to show the agreement. The comment also mentions the importance of discussing the difference between the traditional method and the authors\\' method. While the comment provides a logical reasoning for the need to demonstrate consistency, it lacks specific examples or references to support the claim about the importance of calibration curves. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of demonstrating consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. The comment suggests conducting calibration curves to show this consistency, offering a specific and concrete step for the authors to take. Additionally, it encourages the authors to discuss the difference between their method and traditional methods, providing a direction for further exploration and comparison. While the comment could be more helpful by offering examples of how to conduct calibration curves or suggesting specific aspects of the traditional method to discuss, it still provides valuable guidance for improving the draft. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of discussion on how to ensure that the conditions for DICE are met, and the observation that the range of ID and OOD does not change much with sparsification. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to discuss these conditions and consider how sparsification affects them, but the comment lacks detailed guidance on how to implement these improvements. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by pointing out the lack of discussion on how to ensure DICE meets certain conditions, such as the range of ID and OOD not changing much with sparsification and the need for identical mean in Lemma 2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. These claims are based on observations from Figure 4 and the text, respectively. However, the comment lacks specific examples or detailed reasoning to support these claims, making it somewhat verifiable. The authors would need to infer the significance of these observations and the implications for DICE, which may not be immediately clear. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement in the paper, particularly regarding the discussion of conditions for DICE and the impact of sparsification on the range of ID and OOD. It points out that the conditions are crucial for DICE but are not well discussed, and it highlights the need for more detailed explanation on how to ensure these conditions are met. While the comment provides valuable insights into potential weaknesses and areas for improvement, it could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is mostly helpful as it directs the authors\\' attention to important aspects of their work that need further exploration and discussion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the integration of updates across all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. While the comment implies that the authors should consider these changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these changes to improve the readability and clarity of their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the integration of updates across all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. However, it does not specify which part of the paper these sections are located in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these sections are, the comment lacks full grounding. It is specific about the need for breaking out the sections and improving readability, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the integration of updates across all possible environments and suggests that it might be for space reasons. It also suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. While the comment provides a logical reasoning for the suggestion to break out the sections, it lacks specific examples or references to support the claim about the integration of updates. The suggestion for formatting improvements is more straightforward and verifiable. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the suggestions but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the integration of updates across all possible environments, suggesting that it might be for space reasons. It also points out that the bolded sections in page 6 are currently a large wall of text and should be broken out into paragraphs for better readability. While the comment raises valid points, it lacks specific suggestions or guidance on how to address these issues, such as recommending a specific formatting or restructuring approach. The feedback is somewhat helpful as it highlights areas for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these issues, but without specific guidance on how to do so, the action remains vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues related to the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specific concerns, it lacks grounding as it does not specify where these issues are addressed in the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the strength and fairness of the experiments, questioning the use of position kernels and the absence of certain baselines. It also suggests that the paper lacks discussion on limitations and societal impacts. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique to address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the strength and fairness of the experiments, the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. It provides specific suggestions for addressing these issues, such as using default settings of baselines in the literature and comparing the proposed approach with other baselines. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how other papers have addressed similar issues. Overall, the comment is mostly helpful as it provides actionable feedback that can help the authors improve their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a drop in correlation after a short period of training, which increases with more training iterations. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue or improve their draft. There is no guidance on whether this drop is a concern, what factors might be contributing to it, or how the authors might mitigate it. As a result, the comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions a drop in correlation after a short period of training, which increases with more training iterations. However, it does not specify which part of the paper this observation is based on, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine which part of the paper needs attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the correlation drop need to be addressed or how it might be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is a drop in correlation after a short period of training, which increases with more training iterations. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific observation about the correlation drop after a short period of training, which increases with more training iterations. This is a clear and actionable point that could guide the authors in understanding and addressing a potential issue in their work. However, the comment lacks depth and does not provide suggestions on how to investigate or mitigate this drop in correlation. While it points out a relevant observation, it could be more helpful if it included specific recommendations or analysis techniques for the authors to consider. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of insight into the performance of sparsity patterns and questions whether this is unique to the sparsity detection problem or applies to GNNs in general. It suggests that the authors should provide more insight into this observation. However, the comment does not specify what kind of insight is needed or how the authors should present it. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or analysis but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance of sparsity patterns and asking for more insight into whether this is unique to the sparsity detection problem or applies to GNNs in general. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the performance of sparsity patterns and whether this is unique to the sparsity detection problem or applies to GNNs in general. It suggests that the authors should provide more insight into this observation. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the performance is unexpected or noteworthy. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a direction for further exploration but lacks sufficient justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the performance of sparsity patterns, noting that they seem to perform equally well across different patterns. It questions whether this is unique to the sparsity detection problem or applies to GNNs in general. The comment suggests that the authors should provide more insight into this observation, which could be a valuable contribution to the field. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide the requested insight. While it points out an area for improvement, it does not offer detailed advice on how to achieve it, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention it. This provides a clear and direct action for the authors to take, ensuring that they either include the temperature or acknowledge its absence in the paper. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing temperature parameter, \u03c4, and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides clear guidance on how to improve the derivation section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. The reviewer suggests that either the temperature should be shown in a rigorous way or that the paper should mention its absence. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the temperature should be included or why its absence is problematic. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the derivation from Equation 3 to Equation 4, noting that the temperature parameter, \u03c4, is missing. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention its absence. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improvement. By addressing this issue, the authors can enhance the rigor and clarity of their derivation, which is valuable for the overall quality and credibility of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add a citation on differential privacy, specifically mentioning a standard work like [2]. This is a clear and direct action for the authors to take, as it provides a specific reference to include in the paper. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the addition of a citation on differential privacy, such as a standard work like [2]. This provides clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like [2]. This is a factual suggestion that does not involve an opinion, judgment, or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a specific and actionable suggestion for improving the draft. By recommending the inclusion of a citation on differential privacy, the reviewer offers a clear and concise way for the authors to enhance the paper\\'s credibility and comprehensiveness. This guidance is valuable as it directs the authors to a well-established reference that can help readers better understand the context and significance of the work. By addressing this feedback, the authors can significantly improve the clarity and depth of their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme. The reviewer provides a specific example of an additional assumption (the test set being drawn from the same distribution as the query set) and points out that this assumption is natural in many machine learning settings. The reviewer also notes an issue with the inequality on line 310, suggesting that it has the wrong sign. While the comment identifies specific areas of concern, it does not provide explicit guidance on how to address these issues or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and correct the inequality. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of Section 3.2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the claim, suggesting that it is too extreme and provides a specific example of an additional assumption that is natural in many machine learning settings. Additionally, it points out an issue with the inequality on line 310, which is incorrect. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the additional assumption of using the same distribution for the test and query sets is natural in many machine learning settings. The reviewer provides a logical reasoning by pointing out that this assumption is common in practice. However, the comment lacks specific examples or references to support the claim that this assumption is not significant. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific critique of the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme. The reviewer offers a logical reasoning by pointing out that the additional assumption of using the same distribution for the test and query sets is natural in many machine learning settings. This feedback is valuable as it challenges the authors to reconsider their claim and potentially revise it to align with common practices in the field. Additionally, the comment identifies an issue with the inequality on line 310, which is incorrect. However, the comment could be more helpful if it provided suggestions on how to address these issues or improve the draft. Overall, the comment is mostly helpful as it offers actionable feedback on the claim and the inequality, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. Additionally, it recommends including a discussion on the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. While the comment provides explicit actions, it lacks concrete details on how to conduct these comparisons or what specific aspects of the methods should be discussed. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of Shapely values over other methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for experimental comparisons with other methods and a discussion on the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. It also recommends a discussion on the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that Shapely values are superior to other methods. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the need for experimental comparisons with other methods, such as CaCE or raw gradients, to support the authors\\' argument for using Shapely values over other methods. Additionally, it recommends a significant discussion on the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. This feedback is valuable as it guides the authors to strengthen their argument and provide a more comprehensive analysis of their method. However, the comment could be more helpful if it included specific examples or references to similar studies that have conducted such comparisons. Overall, the comment is mostly helpful as it offers clear and actionable guidance for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should make this comparison, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 needs this comparison or what aspects of the prior efforts should be compared. This makes it difficult for the authors to pinpoint the exact section that needs improvement. Additionally, the comment lacks specificity regarding what aspects of the prior efforts should be compared or how this comparison would enhance the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in Section 6 by suggesting that the manuscript could benefit from comparing the perspective taken in the present work to the contributions of prior efforts. This feedback is somewhat helpful as it points out a specific area where the manuscript could enhance its analysis and comparison with existing literature. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but not detailed steps for implementation. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. While the comment implies that the authors should conduct this experiment, it does not explicitly instruct them to do so. The action is concrete, as it specifies the exact change needed (examining performance with different numbers of scenarios), but it is somewhat vague because it does not provide detailed guidance on how to implement this experiment or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the training process or results, but this inference is not direct. The comment is specific in suggesting the need for an experiment with different scenario numbers, but it lacks grounding as it does not pinpoint the exact section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential relationship between the performance and the number of scenarios used for training, suggesting that examining performance with different numbers of scenarios could be interesting. This feedback is somewhat helpful as it points out a potential area for further exploration and experimentation. However, it lacks specific guidance on how to implement this experiment or what aspects of the performance to focus on. While it provides a direction for improvement, it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between generating a quality label and the model's ability to predict it. It suggests that disturbances in the training data might affect the model's ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or test their model under such disturbances. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between generating a quality label and the model\\'s ability to predict it, suggesting that disturbances in the training data might affect the model\\'s ability to generate the correct quality label. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this issue is discussed. The authors can infer that it relates to the model evaluation or training process, but this inference is not direct. The comment is specific in its inquiry about the model\\'s ability to predict quality labels, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the relationship between generating a quality label and the model\\'s ability to predict it. It suggests that disturbances in the training data might affect the model\\'s ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the relationship between generating a quality label and the model\\'s ability to predict it, suggesting that disturbances in the training data might affect the model\\'s ability to generate the correct quality label, potentially indicating a decrease in quality. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern or test their model under disturbances. The feedback is somewhat helpful as it prompts the authors to consider the robustness of their model, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, additional experiments, or guidance on how to enhance the validation process. As a result, the authors are left without any clear direction on how to address the comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not specify which part of the paper these experiments are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the types of experiments conducted, but it lacks grounding as it does not specify where in the paper this information is presented. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that these experiments are comprehensive. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and cross-domain imitation. However, it lacks specificity and actionable feedback. It does not provide guidance on how the authors could improve or expand upon these experiments, nor does it offer suggestions for further validation or analysis. As a result, the comment is somewhat helpful, as it identifies a strength but does not provide detailed guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the setting described in the paper is only partially strategic or game theoretic, as the opponent does not behave strategically. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the strategic nature of the setting or what specific changes should be made to make it more game theoretic. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the setting described in the paper, suggesting that it is only partially strategic or game theoretic due to the opponent not behaving strategically. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the setting but lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the setting described in the paper is only partially strategic or game theoretic because the opponent does not behave strategically. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s setting, noting that it is only partially strategic or game theoretic due to the opponent not behaving strategically. This is a relevant observation that could prompt the authors to reconsider the nature of their setting and explore ways to enhance its strategic depth. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional strategic elements or game-theoretic approaches. While it points out a potential weakness, it does not provide actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a direct and concrete action for the authors to take, which is to improve the clarity of the illustration in Appendix A.2. The comment is specific about what needs to be addressed, making it highly actionable. Authors know exactly what needs to be done to enhance the clarity of their illustration, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be improved in the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. It points out that the illustration is not clear, which is a critical aspect of the paper\\'s presentation. This feedback is actionable as it directs the authors to improve the clarity of the illustration, ensuring that readers can better understand the environment\\'s state space. However, the comment could be more helpful if it provided suggestions on how to enhance the clarity or offered examples of how similar illustrations have been effectively presented. Despite this, the comment is mostly helpful as it highlights a specific area for improvement, which is valuable for the authors to address.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors\\' approach is only applicable to small or medium-scale problems, suggesting that it may not be effective for truly large problems. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to adapt the approach for larger problems or what specific steps to consider. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors\\' approach is only applicable to small or medium-scale problems, implying that it may not be effective for truly large problems. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the applicability of the approach to large problems, but without clear references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' approach is only applicable to small or medium-scale problems, suggesting that it may not be effective for truly large problems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a limitation in the applicability of the authors\\' approach, suggesting that it is only applicable to small or medium-scale problems. This is a relevant observation that could impact the scope and impact of the work. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this limitation or expand their approach to larger problems. Without detailed feedback or constructive advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the bounded noise assumption in the context of stochastic optimization literature and suggests that it is somewhat restrictive. It references external works that have explored extending these noise conditions, providing specific references to papers by A. Khaled and P. Richt\\'arik, R. Gower, O. Sebbouh, and N. Loizou. While the comment does not explicitly instruct the authors to adopt these references or incorporate the ideas from these papers, it does imply that the authors should consider these works to enhance their understanding of the topic. The action is implicit but concrete, as the authors can infer that they should explore these references to broaden their perspective. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the bounded noise assumption, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for the critique by explaining the commonness and restrictiveness of the assumption in the stochastic optimization literature. The comment references specific works by A. Khaled and P. Richt\\'arik, R. Gower, O. Sebbouh, and N. Loizou, which provides a clear direction for the authors to explore related literature and potentially enhance their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature, referencing specific works by A. Khaled and P. Richt\\'arik, R. Gower, O. Sebbouh, and N. Loizou. These references provide a basis for the claim, as they discuss extensions to the bounded noise assumption and explore related topics. However, the comment could be strengthened by providing more detailed explanations or comparisons of these works to the current paper. As it stands, the references serve as a starting point for the authors to explore, but the comment lacks comprehensive justification or detailed analysis. Therefore, the comment is somewhat verifiable, as it provides a foundation for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the bounded noise assumption, which is common in stochastic optimization literature but somewhat restrictive. It references specific works by A. Khaled and P. Richt\\'arik, R. Gower, O. Sebbouh, and N. Loizou that explore extensions to the bounded noise assumption. This feedback is somewhat helpful as it points out a gap in the literature that the authors could address by incorporating these references or discussing the limitations of the bounded noise assumption in their work. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these references or what aspects of the bounded noise assumption should be further explored. Overall, the comment offers a direction for improvement but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation for using characteristic function regularization is not clear. However, it does not provide any explicit or implicit suggestions for how the authors might clarify this motivation or what specific aspects of the motivation are unclear. There is no guidance on how to address this issue, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the motivation for using characteristic function regularization is not clear, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine whether it relates to the introduction, methodology, or results sections. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a lack of clarity in the motivation for using characteristic function regularization, which is an important aspect of the paper. However, it does not provide specific guidance or suggestions on how the authors might clarify this motivation or what aspects of the methodology are unclear. Without actionable feedback or detailed explanations, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, as it points out an area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the contribution is incremental because these techniques are not novel. However, the comment does not provide any explicit or implicit actions for the authors to take to address this limitation or improve their draft. There is no guidance on how to differentiate their work from existing techniques or how to enhance the contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the paper, namely that the combination of these techniques is not novel and therefore the contribution is considered incremental. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. However, the comment lacks specific examples or references to these existing techniques, making it difficult for the authors to understand the basis of the claim. Additionally, the reasoning is not fully developed, as it does not explain why these techniques are not novel or how they contribute to the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. While the comment highlights a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this limitation or enhance their contribution. The feedback lacks actionable advice or detailed critique, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referred to. This feedback is clear and concrete, as it specifies exactly what needs to be added or clarified in the paper. The authors know exactly what information is missing and how to address it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"aggregation operation after \"Integration,\"\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the details of the aggregation operation and the acknowledgment of other architectures if they are referred to. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the aggregation operation after \"Integration\" needs further clarification and that if other architectures are referred to, their structure should be acknowledged properly. However, the comment does not provide specific examples or detailed reasoning to support why these clarifications are necessary or how they would improve the paper. Without additional context or examples, the claim is somewhat verifiable, as it requires the authors to infer the importance of the suggested clarifications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires further clarification, namely the aggregation operation after \"Integration.\" It suggests that the authors provide more details in the main paper and acknowledge the structure of other architectures if they are referred to. This feedback is clear and actionable, as it directs the authors to enhance the clarity and completeness of their explanation. However, the comment could be more helpful if it provided specific examples or guidance on what additional details should be included. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any explicit guidance or suggestions on how to address these issues. The authors are left to infer that they need to improve their writing quality, but without concrete steps or examples, they may struggle to know where to focus their efforts. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides some specificity in identifying the issues, it lacks full grounding as it does not explicitly mention the sections or paragraphs where these problems occur. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address them effectively. Without specific examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies significant writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. While it highlights these problems, it does not provide specific examples or guidance on how to address them. The comment lacks actionable advice or suggestions on how to improve the writing quality, such as recommending specific editing techniques or offering examples of clearer or more effective sentences. As a result, the feedback is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to run the corresponding experiments and add the results to the figures and Table 1. It also clarifies specific aspects of the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. Additionally, it suggests adding examples of random data in the appendix. These actions are clear and specific, leaving no ambiguity about what the authors need to do to address the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 3c\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as running the corresponding experiments and adding the results to the figures and Table 1. The comment also clarifies specific aspects of the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. Additionally, it suggests adding examples of random data in the appendix. This level of detail provides clear guidance for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for clarification and additional experiments. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying areas where the paper could be improved. It points out that the figures do not show results for untrained networks and suggests running the corresponding experiments and adding them to the figures and Table 1. Additionally, it clarifies specific aspects of the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. The comment also suggests adding examples of random data in the appendix. This level of detail and guidance is highly beneficial for the authors, as it empowers them to make significant improvements to their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"100 steps\" in the context of a search model comparison. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or address this issue. Without guidance or direction, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on what \"100 steps\" means in the context of the search model comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"100 steps\" in the context of a search model comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"100 steps\" in the context of a search model comparison, specifically in section 5.1. This question highlights a potential area of confusion or ambiguity in the paper, which could be clarified to enhance the reader\\'s understanding. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the potential of exploring energy models for image generation and suggests that it is less explored compared to GANs and VAEs. However, it also points out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. While the comment implies that the authors should consider this similarity and potentially address it in their work, it does not provide explicit guidance on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should address the similarity to the prior work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of energy models for image generation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the use of energy models for image generation is less explored compared to GANs and VAEs, and it acknowledges that the motivation and goals of the model are similar to a prior VAE paper. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the comparison to the prior work. The lack of specific examples or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the comparison and potentially conduct additional research to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the potential of exploring energy models for image generation and notes that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. This feedback is somewhat helpful as it highlights an area of potential interest and a similarity to prior work, providing the authors with a direction for further exploration or clarification. However, the comment could be more helpful if it offered specific suggestions on how to address the similarity or how to differentiate the model from prior work. Overall, the comment provides some insight but lacks actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the results are statistically significant. This feedback is explicit and provides a clear action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is also concrete, as it specifies the need for statistical analysis and the importance of determining statistical significance. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the improvement over previous methods, specifically mentioning the results in Table 1 and Fig. 5. It also suggests repeating the experiments and conducting statistical significance analysis on the numbers. However, it does not specify which part of the paper these results are presented in, making it weakly grounded. The comment is specific in suggesting the need for statistical analysis and the importance of determining statistical significance. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement over previous methods is small, about 0.2%-1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation. Additionally, it suggests repeating the experiments and conducting statistical significance analysis to determine whether the results are statistically significant. The comment provides some logical reasoning by pointing out the lack of statistical significance analysis, but it lacks specific examples or references to support the claim about the size of the improvement. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the improvement over previous methods is small, about 0.2%-1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The comment suggests repeating the experiments and conducting statistical significance analysis to address this issue. While the feedback is clear and actionable, it could be more helpful if it provided specific guidance on how to conduct the statistical analysis or what metrics to focus on. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a concrete suggestion for addressing it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends conducting experiments on a different benchmark, such as Atari, to verify the generalizability of the method. This suggestion is clear and provides a specific action for the authors to take. Additionally, it highlights the importance of evaluating the method on a diverse set of domains to ensure its applicability beyond the robotic manipulation domain. The comment is concrete in its guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation on a single domain, Meta World, and the need to run experiments on a different benchmark like Atari. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the need to evaluate the method on a different benchmark to verify its generalizability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is evaluated only on the tasks from Meta World, a robotic manipulation domain, which makes it difficult to judge whether the results will generalize to other domains. The reviewer suggests conducting experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is based on the need to verify whether the method works with discrete action spaces and high-dimensional observations. The claim is somewhat verifiable as it provides a logical reasoning for the need to test the method on a broader range of domains. However, it lacks specific examples or references to studies that have successfully generalized to other domains, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the evaluation of the method, noting that it is evaluated only on the tasks from Meta World, a robotic manipulation domain. This observation highlights the need for broader applicability and generalizability, as the results may not be representative of other domains. The comment provides a clear and actionable suggestion by recommending conducting experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion not only addresses the issue of generalizability but also provides a specific testbed for verifying the method's performance with discrete action spaces and high-dimensional observations. By offering a concrete and constructive suggestion, the comment is highly helpful in guiding the authors towards improving their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The comment implies that the authors should add more depth to the explanation of the model, but it lacks concrete instructions or examples on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not specify which part of the paper this analysis should be included in, nor does it provide details on what aspects of the model should be analyzed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is specific in suggesting the need for an analysis but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper, noting that while the method is presented well and the experiments are thorough, there is a lack of analysis on what the model does. This feedback highlights an area for improvement, suggesting that the authors should include an analysis of the model's functionality, which could be interesting. However, the comment does not provide specific guidance or examples on how to conduct this analysis or what aspects to focus on. While it points out a potential weakness, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the task setup is not described clearly, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify these aspects in their draft, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the task setup, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date are not clearly described. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the task setup, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that these aspects are unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the task setup, particularly regarding the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. This feedback is clear and actionable, as it points out areas where the authors need to provide more detailed information to ensure that their task setup is understandable. However, the comment could be more helpful if it offered suggestions on how to clarify these aspects or provided examples of how similar tasks have been described in the literature. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors discuss the reason why the proposed algorithm, DMLCBO, does not achieve the convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$ and the theoretical technique difference between DMLCBO and previous works that have achieved this rate, such as SUSTAIN and MRBO. This feedback provides a clear and concrete action for the authors to take, as it specifies the need for a detailed discussion on the convergence rate and theoretical differences. The comment is explicit and provides specific guidance on what to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed algorithm, DMLCBO, and references specific works, SUSTAIN and MRBO, which have achieved a convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the reason why DMLCBO does not achieve the same convergence rate and the theoretical technique difference between DMLCBO and the mentioned works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm, DMLCBO, does not achieve the same convergence rate as previous works, specifically mentioning SUSTAIN and MRBO, which have achieved $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$. The reviewer supports this claim by referencing these specific works and their convergence rates, providing a logical basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or references to the theoretical differences between DMLCBO and the mentioned works. Despite this, the claim is mostly verifiable due to the reference to specific works and the logical reasoning provided.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the convergence rate of the proposed algorithm, DMLCBO, compared to previous works that have achieved a convergence rate of $\\\\mathcal{\\\\widetilde O}(\\\\epsilon^{-3})$. It highlights the potential gap in achieving the same rate and encourages the authors to discuss the reason for this difference and the theoretical technique differences between DMLCBO and the mentioned works, such as SUSTAIN and MRBO. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and address in their draft. By addressing these points, the authors can enhance the clarity and rigor of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of the approach section in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the approach section. The comment implies that the authors should include the approach section in the main paper, but it lacks concrete details on how to integrate it or what specific content should be included. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"approach section\" and the \"supplementary material,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the approach section in the main paper and the use of supplementary material as additional information rather than an extension to the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach section is missing in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the approach section should be included or how the supplementary material should be used. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the approach section is missing in the main paper. It suggests that the supplementary material should be used as additional information rather than an extension to the paper. While the comment highlights an important oversight, it lacks specific guidance on how to address this issue or what content should be included in the approach section. The feedback is somewhat helpful as it points out a critical gap in the paper, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the statement regarding the biological plausibility of backpropagation in the introduction may be too weak and points out that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to strengthen the statement. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the statement and provide more robust evidence or reasoning to support it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement in the introduction regarding the biological plausibility of backpropagation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the weakness of the statement and the widely accepted view that backpropagation is biologically implausible. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement regarding the biological plausibility of backpropagation in the introduction is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the introduction regarding the biological plausibility of backpropagation. It points out that the statement may be too weak and that the widely accepted view is that backpropagation is biologically implausible. This feedback is somewhat helpful as it highlights an area where the authors may need to provide more robust evidence or reasoning to support their claims. However, the comment could be more helpful if it suggested specific ways to strengthen the statement or provided examples of alternative perspectives or evidence that could be considered. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the modulator is heuristically designed and questions the scalability issue, suggesting that there might be a need for tedious hyperparameter tuning for diverse training data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the scalability issue or suggestions for improving the modulator design. As a result, the authors are left without any clear direction on how to improve their draft based on this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of scalability in the modulator design, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the scalability issue and the potential need for hyperparameter tuning, but without clear grounding, the authors cannot confidently determine which part of the paper this pertains to. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the modulator is heuristically designed and questions the scalability issue, suggesting that there might be a need for tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the modulator design, suggesting that it might require tedious hyperparameter tuning for diverse training data. This is a relevant concern that could impact the practicality and efficiency of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the scalability of the modulator. Without actionable advice or detailed feedback, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide enough detail for the authors to effectively address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that f_R and f_P can be adapted over time but highlights the incorporation of domain knowledge into their structure. It suggests that a less informed f_R/f_P might require an impractical amount of data to learn. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or suggestions for improving the experiments. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of domain knowledge being incorporated into the structure of the experiments, specifically mentioning f_R and f_P. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the impractical amount of data required for a less informed f_R/f_P. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments performed here incorporate a great deal of domain knowledge into their structure, which could require an impractical amount of data to learn for a less informed f_R/f_P. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the incorporation of domain knowledge into the experiments and highlights the potential impracticality of learning for a less informed f_R/f_P. However, it lacks specific suggestions or guidance on how the authors might address this issue or improve their experiments. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should conduct experiments to explore these aspects, but it lacks concrete guidance on what specific experiments to conduct or how to analyze the results. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as the need for experiments on data acquisition and performance changes. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that obtaining labeled data is necessary for imitation learning and suggests that experiments should be conducted to explore difficulties in data acquisition and performance changes with data size. However, the comment lacks specific examples or references to support the claim that these experiments are necessary or how they would impact the results. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. It highlights the need for experiments to explore these aspects, which is a crucial aspect of the methodology. However, the comment lacks specific suggestions on how to conduct these experiments or what specific aspects to focus on. While it points out an important area for improvement, it does not provide actionable guidance, making it somewhat helpful. The authors are given a direction to explore but without detailed guidance, the feedback is limited in its utility. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the connection between the necessary conditions for overparameterization and generalization bounds. It suggests that the constructions of ReLU networks for robust memorization may not necessarily lead to robust generalization. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they need to clarify the connection between necessary conditions and generalization bounds, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of overparameterization and its implications on generalization bounds. It suggests that the necessary conditions for overparameterization may have stronger implications if they are connected to generalization bounds. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the connection between necessary conditions and generalization bounds, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the connection between overparameterization and generalization bounds, suggesting that the necessary conditions for overparameterization may have stronger implications if they are connected to generalization bounds. The reviewer acknowledges that the authors acknowledge this in the conclusion but considers it a serious question. However, the comment lacks specific examples or references to support the claim that the constructions of ReLU networks for robust memorization would not necessarily lead to robust generalization. Without detailed evidence or examples, the claim remains somewhat verifiable, as it provides a logical argument but lacks the necessary substantiation to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper regarding the connection between overparameterization and generalization bounds. It suggests that the necessary conditions for overparameterization may have stronger implications if they are connected to generalization bounds. While the reviewer acknowledges that the authors acknowledge this in the conclusion, the comment highlights a serious question that the authors need to address. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. However, it does not provide specific guidance on how the authors should address this issue or what additional exploration is needed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the generalizability of their results. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s exploration of the implications of the proposed method for other NLP tasks, suggesting that the paper\\'s generalizability is somewhat limited due to this lack of exploration. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which somewhat limits its generalizability. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. This observation highlights a potential weakness in the generalizability of the results, which could impact the paper\\'s impact and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional exploration could be conducted. While it points out an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the use of the terminology \"certificate\" in the paper, as it has a strong meaning in complexity theory. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to avoid misinterpretation. The action is implicit and vague, as the authors are left to infer that they need to reconsider the use of this terminology and possibly provide clarification. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the terminology \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of the terminology \"certificate\" in some contexts could be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the terminology \"certificate\" in the paper, noting that it has a strong meaning in complexity theory. This is a valuable observation that could lead to confusion or misinterpretation by readers. However, the comment does not provide specific guidance on how the authors should address this issue or suggest alternative terminology. While it highlights a potential problem, it lacks actionable advice or detailed suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should mention the recent work on untrained NNs for inverse problems in imaging, specifically mentioning the paper by Ulyanov et al. (CVPR 2018). It also recommends placing the current method in context and potentially comparing it with these methods. While the comment provides a clear action\u2014mentioning the relevant work and potentially comparing the current method\u2014it does not specify how to integrate this information into the paper or what specific aspects of the comparison should be highlighted. The action is explicit but somewhat vague in terms of execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"OOD experiments\" and the \"untrained NNs\" for inverse problems in imaging, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely mentioning the recent work by Ulyanov et al. (CVPR 2018) and placing the current method in context. Additionally, it suggests comparing the current method with those class of methods. This provides clear guidance on how to enhance the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the current work is interesting because the trained network can provide strong OOD generalization. However, it also mentions that untrained NNs, like those used in the Ulyanov et al. (CVPR 2018) paper, can be used for inverse problems across a wide range of images. The reviewer suggests that the current work should be placed in context by mentioning these existing methods and potentially comparing them. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to the Ulyanov et al. paper or other relevant works that could further substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the suggestion but requires more detailed evidence or references to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion by pointing out that the current work on OOD experiments is interesting due to the strong generalization capabilities of the trained network. However, it also highlights a potential limitation by mentioning that untrained NNs, like those used in the Ulyanov et al. (CVPR 2018) paper, can be used for inverse problems across a wide range of images. The comment suggests that the current work should be placed in context by mentioning these existing methods and potentially comparing them. This feedback is valuable as it encourages the authors to consider the broader context of their work and potentially enhance its impact by integrating these comparisons. However, the comment could be more helpful if it provided specific guidance on how to integrate these comparisons or what aspects to focus on. Overall, the comment is mostly helpful as it offers actionable suggestions for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments are limited to toy data and recommends expanding the scope to include real data. It explicitly states that there is a range of problems with real data where barycenters can be used and suggests that the method's performance should be demonstrated in those settings. This provides a clear and concrete action for the authors to take, as it specifies the need to include real data experiments and the potential benefits of doing so. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests expanding the scope of the experiments to include real data, which implies that the current experiments are limited to toy data. However, it does not specify which part of the paper discusses the experiments or where the limitation is mentioned, making it weakly grounded. The comment is specific in suggesting that real data experiments could be beneficial and highlighting the potential use of barycenters in real-world scenarios. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments are limited to toy data and recommends expanding the scope to include real data. However, the comment does not provide any specific examples or references to support the claim that real data experiments would be beneficial or necessary. Without such evidence or reasoning, the authors may find it challenging to understand the basis of the suggestion and how it could improve their work. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or examples to fully substantiate the recommendation.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, noting that they are currently limited to toy data. It suggests expanding the scope to include real data, which could provide a more comprehensive understanding of the method's performance in various settings. This feedback is clear and actionable, as it directs the authors to consider incorporating real-world data experiments to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these experiments or what aspects of real-world data to focus on. Overall, the comment is mostly helpful as it points out a significant area for improvement and offers a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment implies that additional experiments are necessary, it does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions on how to implement the suggested experiments. The action is implicit and somewhat vague, as the authors need to infer the specific details of how to proceed with the additional experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results. The references provided are relevant but do not directly address the comment. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. The comment provides references to relevant works, which supports the claim that these experiments could enhance the paper. However, the comment lacks detailed reasoning or specific examples of how these additional experiments would benefit the paper. While the references provide some context, the claim could be strengthened with more detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides some support but lacks full clarity and depth.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions or suggestions for the authors. Therefore, the comment is somewhat helpful as it points out a potential area for improvement but does not provide actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed sample selection mechanism is not clearly explained in terms of how it preserves the label distribution. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific ways to clarify the mechanism or suggesting alternative explanations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed sample selection mechanism, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding how the mechanism preserves the label distribution. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the proposed sample selection mechanism in preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the proposed sample selection mechanism, noting that it is not clear how it preserves the label distribution. This feedback is somewhat helpful as it points out a potential weakness in the paper that the authors should address to improve clarity and understanding. However, the comment lacks depth and does not provide specific suggestions or examples on how to clarify the mechanism or what aspects of the explanation are unclear. While it highlights an area for improvement, it does not fully guide the authors on how to address the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any explicit or implicit suggestions for improvement or additional models to consider. The authors are left without guidance on how to enhance the scope or relevance of their evaluation. As a result, the comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the results and analysis, noting that they are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not specify which part of the paper this critique pertains to, such as the results or analysis sections. Without explicit references to sections or figures, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the evaluation are limited by the choice of models. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to other models or studies that could be considered, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a limitation in the evaluation of results and analysis, noting that only two relatively old and small models are considered. This feedback highlights an area where the authors could potentially expand the scope and relevance of their work by including more diverse models. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional models or methods to consider. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. The reviewer implies that this makes the motivation for Algorithm 1 unclear. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address this issue. It lacks actionable details, such as suggesting how to clarify the motivation or how to incorporate this insight into the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation of Algorithm 1, suggesting that the prox-linear subproblem can be reformulated using the conjugate function, making the motivation unclear. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is somewhat verifiable as it provides a logical reasoning based on the conjugate function, which is a well-known mathematical concept. However, the comment lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation could lead to a clearer understanding of the problem and its solution. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the motivation for Algorithm 1. While it points out a potential weakness, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS, particularly when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take based on this observation. There is no guidance on how to incorporate this understanding into the paper or what specific aspects of the paper should be revised to reflect this perspective. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion that LS and KD are equivalent under certain conditions, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that KD can be considered a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without additional context or evidence, the claim remains unverifiable, as it does not provide sufficient justification for the authors to address the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. It provides a specific example of when this equivalence occurs, which is when the teacher network is uniformly distributed and the temperature is set at 1. This feedback is somewhat helpful as it offers a potential insight into the relationship between KD and LS, which could be useful for the authors to consider when discussing their methodology or results. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate this understanding into the paper. Overall, the comment offers a valuable perspective but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results on large-scale datasets, such as ImageNet, to verify the effectiveness of their proposed method. This feedback is explicit and provides a clear action for the authors to take, which is to include results on larger datasets. The comment also mentions that competing dynamic-pruning methods are outdated, implying that the authors should consider more recent works. However, it does not specify which recent works should be included or how to incorporate them into the paper. While the action is clear, the lack of detailed guidance on how to implement it makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.3. 2021\" and \"Competing dynamic-pruning methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of results on large-scale datasets, such as ImageNet, to verify the effectiveness of the proposed method. Additionally, it points out that competing dynamic-pruning methods are outdated, suggesting that more recent works should be included. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that competing dynamic-pruning methods are outdated and suggests that more recent works should be included. However, the comment does not provide specific examples of these outdated methods or recent works that should be considered. Without detailed references or specific examples, the claim lacks sufficient evidence or justification to be fully verifiable. The authors would need to make a significant effort to identify and incorporate the suggested works, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors include results on large-scale datasets, such as ImageNet, to verify the effectiveness of their proposed method. It also points out that competing dynamic-pruning methods are outdated, implying that more recent works should be considered. This feedback is specific and offers a concrete direction for improvement, making it mostly helpful. However, it could be more helpful if it provided examples of recent works that should be included or detailed guidance on how to incorporate them into the paper. Overall, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to provide an explanation for why the performance degrades when using additional information about missing, wrong, or redundant information. This is a clear and direct request, giving the authors a specific action to take. The comment is specific in its request for an explanation, which provides a concrete direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why the performance degrades when using additional information about missing, wrong, or redundant information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance degradation when using additional information about missing, wrong, or redundant information. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the performance degradation when using additional information about missing, wrong, or redundant information. This is a clear and actionable request for the authors to provide an explanation or analysis of this phenomenon. By addressing this question, the authors can improve the clarity and robustness of their results. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of similar cases. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. The reviewer explicitly asks for clarification on these points, providing a clear direction for the authors to improve the clarity of their explanations. The action is explicit and concrete, as it specifies exactly what needs to be addressed to improve the readability of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the clarity of the explanations, providing examples of unclear statements and asking for clarification. This level of detail helps the authors understand what needs to be addressed to improve the clarity of their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first two sections of the paper are hard to read due to unclear explanations of previous approaches. It provides specific examples of unclear statements, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. These examples are detailed and provide a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or references to support the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity and readability of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides examples of unclear statements and requests for clarification, which are valuable insights for the authors to improve the draft. By highlighting these areas, the comment offers actionable feedback that can help the authors enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the explanations or offered alternative approaches to present the information more effectively. Overall, the comment is mostly helpful as it directs the authors to specific areas needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the captions should be more descriptive and provides a specific example of the issue, noting that it is annoying to have to search through the text for the interpretation of figures, which is usually on a different page. Additionally, it requests an explanation of the scramble network. While the comment provides a clear action to make the captions more descriptive and an explicit request for an explanation of the scramble network, it does not offer detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specifics of how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the captions and the issue of having to search through the text for the interpretation of figures, which is usually on a different page. It also mentions the need to explain the scramble network, providing clear guidance on what needs to be addressed. However, the comment lacks specificity regarding how to make the captions more descriptive or how to explain the scramble network. While the authors can identify the parts of the paper being addressed, the lack of detailed guidance on how to implement the suggested improvements limits the comment\\'s specificity. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the captions are not descriptive and that it is annoying to have to search through the text for the interpretation of figures, which are usually on a different page. The comment also requests an explanation of the scramble network. While the comment identifies a specific issue with the captions, it lacks detailed reasoning or examples to support why this is a problem or how it could be improved. The suggestion to make the captions more descriptive is logical, but the lack of specific guidance or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the captions should be more descriptive, which would improve the clarity and accessibility of the figures. It also highlights the issue of having to search through the text for the interpretation of figures, which is usually on a different page. This feedback is valuable as it directly addresses a common challenge in scientific writing and offers a clear solution to improve the draft. Additionally, the comment requests an explanation of the scramble network, which could further enhance the clarity and understanding of the paper. Overall, the comment is highly helpful as it provides clear and actionable guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the choice of using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that the motivation for this choice is not well-explained. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the motivation should be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to provide a clearer rationale for the choice but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of randomly sampled CIFAR images as backgrounds to make the task harder, questioning the motivation behind this choice. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the motivation behind the choice but lacks detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that this choice is not well-motivated and implies that the authors should provide a clearer rationale for this decision. However, the comment lacks specific examples or references to support the claim that the motivation is unclear or unjustified. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not well-motivated. It highlights a potential weakness in the paper\\'s rationale for the experimental setup, which could be improved by providing a clearer explanation of why this particular dimension of difficulty is interesting. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or what additional information could be included to strengthen the motivation. While it identifies a potential area for improvement, the feedback lacks depth and actionable steps, making it somewhat helpful but not comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy in the paper\\'s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds the flat minima, the analysis about flatness is missing. The reviewer suggests that the authors should provide an analysis of the losses of the noise-injected models after training to substantiate their claim. This feedback is explicit and provides a clear action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the analysis about flatness\" and \"the loss used for training base model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the losses of the noise-injected models after training to substantiate the claim about the flatness of the minima found by the proposed method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis about the flatness of the minima is missing, and it suggests that minimizing the averaged loss across the noise-injected models does not ensure the flatness of the minima. The reviewer provides a logical reasoning by explaining that the loss used for training the base model is the averaged loss for the noise-injected models, and that the convergence analysis on this loss does not guarantee the flatness of the minima. However, the comment lacks specific examples or references to support the claim that the analysis on the losses of the noise-injected models after training is necessary to substantiate the claim about the flatness of the minima. This makes the claim somewhat verifiable, as it provides a logical argument but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper\\'s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds the flat minima, the analysis about flatness is missing. The reviewer provides a logical explanation, noting that minimizing the averaged loss across the noise-injected models does not ensure the flatness of the minima. This feedback is highly helpful as it directs the authors to a specific area where the paper\\'s argument is flawed and suggests a clear and actionable solution: conducting an analysis of the losses of the noise-injected models after training to substantiate the claim about the flatness of the minima. By addressing this feedback, the authors can significantly improve the clarity and robustness of their argument. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to make the text inside the figure and labels roughly the same size as the manuscript text. This is a clear and direct action that the authors can easily implement to improve the readability of their figures. The comment provides concrete guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"text inside the figure and the labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the size of the text compared to the manuscript text. This provides clear guidance on how to improve the readability of the figures. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text inside the figure and labels is too small to read without zooming, suggesting that it should be roughly the same size as the manuscript text. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the readability of the figures. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the readability of the figures, noting that the text inside the figure and the labels are too small to read without zooming. It provides a clear and actionable suggestion to make the text roughly the same size as the manuscript text. This feedback is valuable as it directly addresses a usability concern that could impact the accessibility and comprehension of the figures. However, the comment could be more helpful if it included examples or additional guidance on how to achieve this improvement. Overall, the comment is mostly helpful as it effectively points out a specific issue and offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This provides a direct and concrete action for the authors to take, which is to revise the introduction to clarify the motivation. The comment is specific in identifying the issue and offers a clear direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the motivation. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation is not clear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely the lack of clarity in the motivation. It suggests that the introduction should be revised to make the paper easier to follow. While the comment highlights a critical area for improvement, it does not provide specific guidance on how to revise the introduction or what aspects of the motivation are unclear. This limits the comment\\'s helpfulness, as it points out a problem but does not offer detailed suggestions for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the features or positions are problematic or how they could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to validate the alignment or what specific steps to take to ensure its validity. As a result, the authors are left without any clear direction on how to improve their draft in this area. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the alignment of relabeled reward data with human annotator judgments, indicating that this alignment is insufficiently validated. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of insufficient validation, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the insufficient validation of the alignment between relabeled reward data and human annotator judgments. This is a critical point that could impact the reliability and robustness of the results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional validation methods or providing examples of how to validate the alignment. Without actionable advice, the authors are left with a clear area for improvement but without a clear path forward. Therefore, the comment is somewhat helpful, as it points out a significant weakness but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model is somewhat complicated and recommends improving its presentation in Section 4, possibly by referring to the supplement. It also provides specific suggestions for enhancing the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These explicit actions and concrete details provide clear guidance on how the authors can improve the presentation of their model, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, such as suggesting the use of notation and breakout diagrams to enhance the presentation of the model. This level of detail provides a clear direction for the authors to follow, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the model is somewhat complicated and recommends improving its presentation in Section 4. It provides a specific suggestion to replace natural language descriptions with notation and adds breakout diagrams to illustrate the attention mechanisms. This claim is somewhat verifiable as it offers a logical suggestion for improving the presentation, but it lacks detailed justification or examples to fully substantiate the claim. The authors might need to explore the specific benefits of using notation and diagrams to understand the full impact of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the presentation of the model in Section 4, noting that it is somewhat complicated and requires careful reading. It provides specific suggestions for improving the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These suggestions are actionable and can help the authors enhance the clarity and accessibility of their presentation. However, the comment could be more helpful if it explained why these changes are necessary or how they would benefit the reader. Overall, the comment is mostly helpful as it provides clear and constructive feedback, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper only conducts experiments on a limited number of molecules and provides in-distribution testing for these samples. It suggests that the method's value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or expand their experiments to include more molecules. The action is implicit and vague, as the authors are left to infer that they need to consider expanding their experiments to include more molecules. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limited scope of the experiments conducted in the paper, specifically mentioning that only a few molecules are tested and that in-distribution testing is provided for these samples. However, it does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its critique of the limited scope of the experiments and the potential limitations of the method if it requires training for each molecule individually. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only conducts experiments on a limited number of molecules and provides in-distribution testing for these samples. It suggests that the method's value would be limited if it requires training for each molecule individually. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically noting that the experiments are conducted on a limited number of molecules and only provide in-distribution testing for these samples. It suggests that the method's value would be limited if it requires training for each molecule individually. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s scope and suggests an area for improvement. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this limitation or expand their experiments to include more molecules. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the symbols or how to make them more accessible to the reader. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not specify which symbols or parts of the paper are causing this issue, making it difficult for the authors to pinpoint the exact areas that need improvement. Without specific references to sections, figures, or symbols, the authors cannot effectively address the issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any specific examples or guidance on how to simplify these symbols or make them more accessible to the reader. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the origin of the red line in Figure 3 and whether there is a ground truth for the test data. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the source of the red line and the ground truth, but it lacks specific instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the red line in the figure and asks for clarification on the origin of the test data and the existence of a ground truth. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions about the origin of the red line in Figure 3 and the existence of a ground truth for the test data. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the origin of the red line in Figure 3 and the existence of a ground truth for the test data. This is a valid point that could help the authors clarify their methodology and ensure that their results are robust. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide explicit instructions or concrete steps for the authors to take. It lacks actionable details, such as recommending specific modifications or experiments to address this concern. As a result, the authors are left without a clear path forward, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, such as specific experiments or sections where the results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the role of periodicity in the results, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a logical basis for the question but lacks sufficient evidence or references to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve their results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending experiments or modifications to the model. While it provides a thought-provoking insight, it could be more helpful with additional actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not well-written and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues, such as suggesting particular formatting changes or improvements to the figures and tables. The authors are left to infer that they need to improve the writing and formatting, but without concrete steps, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the paper\\'s writing quality, suggesting that it may be rushed and difficult to read. It mentions specific areas for improvement, such as presentation and formatting, particularly in figures and tables. However, the comment does not explicitly mention which sections or parts of the paper are problematic, making it weakly grounded. The authors can infer that it relates to the sections on presentation and formatting, but this inference is not direct. The comment is specific in detailing what needs to be improved, such as the figures and tables, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not well-written and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of specificity and detailed evidence or references makes the claim borderline verifiable, as it provides some indication but not enough detail for the authors to fully understand and act upon the feedback. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s writing quality, suggesting that it may be rushed and difficult to read. It highlights specific areas for improvement, such as presentation and formatting, particularly in figures and tables. While the comment provides some insight into the areas needing attention, it lacks detailed guidance or specific suggestions on how to improve the writing and formatting. The authors are left with a general understanding of the issues but without actionable steps to address them. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not provide comprehensive guidance for the authors to make significant improvements to their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the introduction to orthogonality in Part 2 could be more detailed. This provides a clear and direct action for the authors to take, which is to expand or clarify the introduction to make it more comprehensive. The comment is specific in identifying the need for more detail, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Part 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction to orthogonality. This provides clear guidance on what the authors need to improve, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific reasoning or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the introduction to orthogonality in Part 2. It suggests that the introduction could be more detailed, providing a clear direction for the authors to enhance their draft. However, the comment lacks specific guidance on what aspects of the introduction need more detail or how to achieve this improvement. While it points out a potential weakness, it does not offer actionable steps or examples to help the authors address it effectively. Therefore, the comment is somewhat helpful, as it provides a general direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should highlight the novelty of its result in relation to prior work, particularly regarding the removal of double descent in certain anisotropic settings. While the comment implies that the authors should clarify the novelty of their result, it does not provide specific guidance on how to do so or what aspects of the paper should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the novelty of their result. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the theoretical results of prior work that show sample-wise multiple descent in linear regression, which provides a clear reference point for the authors to address. It also specifies the main contribution of the paper, which is the result that optimal regularization can remove double descent in certain anisotropic settings. The comment suggests that if this is not the case, the paper should better highlight the novelty of their result in relation to prior results. However, it does not provide specific guidance on how to achieve this or what aspects of the paper should be emphasized. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper\\'s main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, which is based on prior work that theoretically shows sample-wise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the particular techniques and tools used in the paper but suggests that the claims seem correct. This provides a logical basis for the claim but lacks specific references or detailed evidence to fully substantiate it. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires more detailed evidence or references to fully support it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s contribution, noting that the main result about removing double descent in certain anisotropic settings is based on prior work that theoretically shows sample-wise multiple descent in linear regression. The reviewer suggests that the paper should better highlight the novelty of its result in relation to prior results, as the theoretical basis is already established. While the comment provides a clear direction for improvement, it lacks specific guidance on how to effectively highlight the novelty or what aspects of the paper should be emphasized. This limits the comment\\'s helpfulness, as it points out an area for improvement but does not offer detailed suggestions for enhancing the paper. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed methods, contrastive training objective and contrastive search, are independent and lack a clear connection on both the intuition and the algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to integrate the methods or improve their connection. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed methods, specifically contrastive training objective and contrastive search, and notes that they are independent methods with little inner connection on both the intuition and the algorithm. However, it does not specify which part of the paper these methods are discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the methods\\' independence, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed methods, contrastive training objective and contrastive search, are independent and lack a clear connection on both the intuition and the algorithm. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed methods, contrastive training objective and contrastive search, noting that they are independent and lack a clear connection on both the intuition and the algorithm. This feedback highlights a potential weakness in the paper\\'s presentation and suggests that the authors should consider integrating these methods more effectively. However, the comment does not provide detailed guidance on how to achieve this integration or what specific aspects of the methods need to be addressed. While it points out an area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern regarding the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the claim is to establish the paper as a foundation model, the authors should clarify this and demonstrate a future useful application. While the comment implies that the authors should provide a comparison and justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the goal of the paper and the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the absence of a justification for the benefits of the proposed method over these existing methods. It also suggests that if the claim is to establish the paper as a foundation model, the authors should clarify this and demonstrate a future useful application. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the claim is to establish the paper as a foundation model, the authors should clarify this and demonstrate a future useful application. While the comment identifies a potential issue with the paper\\'s goal and suggests a need for comparison and justification, it lacks specific examples or references to support the claim that existing DAS earthquake detectors exist. This makes the claim somewhat verifiable, as the authors would need to infer the need for comparison and justification based on the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the paper\\'s goal, noting the absence of a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, and the lack of justification for the benefits of the proposed method over these existing methods. It suggests that if the paper is to establish a foundation model, the authors should clarify this and demonstrate a future useful application. This feedback is clear and actionable, as it points out a critical area for improvement in the paper\\'s justification and comparison with existing work. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of how similar comparisons have been conducted in similar works. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCT-pair) and what about the ablation studies of MCT without the adaptive metrics. While these questions imply that the authors should address these issues, they do not provide explicit instructions or concrete guidance on how to do so. The authors can infer that they need to clarify the discrepancy in the results and potentially include ablation studies, but the comment lacks specific details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCT-pair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the alignment of results and asking about the ablation studies of MCT without adaptive metrics. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that are relevant to the paper\\'s content and methodology. First, it questions the alignment of results between Table 6 and Table 1 (MCT-pair), which could indicate a discrepancy or inconsistency in the data. Second, it asks about the ablation studies of MCT without the adaptive metrics, suggesting that this could provide valuable insights into the model\\'s performance. While the comment identifies areas for clarification and potential enhancement, it does not offer specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of the need for clarification but without detailed instructions on how to proceed. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR-10 models on distribution shifts. It references specific works, such as RobustBench and Croce et al. (2021), where similar analyses were conducted on a smaller scale. The reviewer also mentions that [A, B] have evaluated the robustness of adversarially trained models to unseen attacks. While the comment highlights the existing work, it does not provide explicit guidance on how the authors should address this issue or improve their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should either expand on the existing analyses or provide new insights to differentiate their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific works, such as RobustBench and Croce et al. (2021), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses have been conducted in prior works, which may not be surprising due to the limited scale. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR-10 models on distribution shifts. It references specific works, such as RobustBench and Croce et al. (2021), where similar analyses were conducted on a smaller scale. Additionally, it mentions that [A, B] have evaluated the robustness of adversarially trained models to unseen attacks. The comment provides specific references to external works, which supports the claim that the analyses are not novel. This makes the claim mostly verifiable, as it provides a solid foundation for the authors to understand the existing work in their field. However, the comment could be strengthened by further explaining why the current analyses are not novel or how they could be improved.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the work, noting that similar analyses have been conducted in prior works, specifically on a smaller scale. It references specific works, such as RobustBench and Croce et al. (2021), where similar analyses were conducted on a smaller scale. Additionally, it mentions that [A, B] have evaluated the robustness of adversarially trained models to unseen attacks. While the comment highlights a potential weakness in the novelty of the work, it does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work. The feedback is somewhat helpful as it points out a potential problem but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the 10 sub-tasks are simplistic for bAbi and that more discussions are required. However, it does not provide any specific guidance on what kind of discussions are needed or how the authors should address this issue. The comment lacks actionable details, such as recommending additional analyses or discussions that could be included to enhance the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the 10 sub-tasks are simplistic for bAbi and that more discussions are required. However, it does not specify which part of the paper these sub-tasks are discussed in or where the discussions are lacking. Without explicit references to sections or specific sub-tasks, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what kind of discussions are needed or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the 10 sub-tasks are simplistic for bAbi and suggests that more discussions are required. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples of how the sub-tasks are simplistic or how they could be improved with additional discussions. Without such support, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the 10 sub-tasks presented in the paper, suggesting that they may be too simplistic for bAbi. It highlights the need for more discussions to address this concern. However, the comment lacks specificity and does not provide guidance on what kind of discussions are needed or how the authors could improve the sub-tasks. Without actionable suggestions or detailed feedback, the authors are left with a general idea of what needs to be addressed but without clear direction on how to do so. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It asks whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. While the comment implies that the authors should consider this limitation and potentially explore alternatives, it does not provide explicit instructions or concrete suggestions on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider extending the approach to longer subsequences. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its inquiry about whether the limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It does not present an opinion, judgment, or suggestion that requires verification. It is a factual observation seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a valid concern about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It questions whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. This feedback prompts the authors to consider whether their approach is limited by the choice of window size or if it can be extended to accommodate longer sequences. While the comment identifies a potential weakness, it does not provide specific suggestions or guidance on how to address this limitation or explore alternative approaches. The feedback is somewhat helpful as it points out an area for consideration, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the hyper-parameters $b$ (bit-width) and $\\\\alpha$ (stability factor) introducing significant computational overhead in the pursuit of determining the optimal trade-off between model size and accuracy. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative approaches or methods to mitigate the computational overhead. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of hyper-parameters $b$ (bit-width) and $\\\\alpha$ (stability factor) introducing significant computational overhead in the pursuit of determining the optimal trade-off between model size and accuracy. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the hyper-parameters and their impact on computational overhead. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the hyper-parameters $b$ (bit-width) and $\\\\alpha$ (stability factor) may introduce significant computational overhead in the pursuit of determining the optimal trade-off between model size and accuracy. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the hyper-parameters $b$ (bit-width) and $\\\\alpha$ (stability factor) introducing significant computational overhead in the pursuit of determining the optimal trade-off between model size and accuracy. This is a relevant concern that could impact the efficiency and effectiveness of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending alternative hyper-parameter settings or methods to mitigate the computational overhead. While it points out a potential problem, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper and suggests that related work might be relevant but not necessarily detrimental to the novelty of the paper. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions to take. The comment lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"sequence of episodes\" and suggesting that related work might be relevant but not detrimental to the novelty of the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and observations about the definition of \"sequence of episodes\" and the relevance of related work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper, which is a relevant point for clarity. It also suggests that related work might be relevant but not detrimental to the novelty of the paper. While the comment identifies a potential area for improvement by suggesting the inclusion of related work, it lacks specific guidance or suggestions on how to address this issue or incorporate related work. The feedback is somewhat helpful as it points out a potential gap in the paper, but it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the classification of the study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes should be made to the study. The comment lacks actionable advice or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the study\\'s classification but lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. While it identifies a potential issue with the study\\'s designation, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify or reframe their study. The feedback is somewhat helpful as it points out a potential misclassification, but it does not offer actionable advice or detailed critique to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps to consider. The authors are left without any clear direction on how to proceed with this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the inclusion of AccNet in a larger predictor. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation. It suggests that it might make sense to include AccNet in this context. However, the comment lacks specific guidance or actionable advice on how the authors might address this question or what potential benefits or drawbacks of such an inclusion might be. While it prompts the authors to consider a potential integration, it does not provide detailed feedback or suggestions for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any guidance on how the authors should address this issue or suggest ways to expand the testing to other datasets. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a limitation in the proposed metric, noting that it is only tested on a single dataset. However, it does not specify which dataset or which part of the paper discusses this metric, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue with the testing of the metric, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed metric is only tested on a single dataset, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this limitation or how it affects the validity of the metric. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a limitation in the paper, noting that the proposed metric is only tested on a single dataset. This is a relevant observation that could impact the generalizability and applicability of the metric. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets for testing or discussing the implications of this limitation. While it points out a potential weakness, the feedback does not offer actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the proposed TransferNorm (TN) architecture to similar competitors like AutoDial and AdaBN. This feedback provides a clear and explicit action for the authors to take, which is to extend the evaluation to include these additional competitors. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the evaluation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"comparing several base DA methods with and without the proposed TransferNorm architecture.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN, which are direct competitors to the TransferNorm architecture. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN, which are direct competitors to the TransferNorm architecture. However, the comment does not provide specific reasoning or evidence to support why these additional comparisons would enhance the evaluation. While it implies that the current evaluation is incomplete, the lack of detailed justification or examples makes the claim somewhat verifiable. The authors would need to infer the importance of including these comparisons themselves, which could lead to confusion or misunderstanding. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the evaluation section by suggesting that the base DA methods should be evaluated with and without the proposed TransferNorm architecture, as well as with other architectural competitors like AutoDial and AdaBN. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their evaluation by including additional comparisons that could strengthen their analysis. By addressing this suggestion, the authors can improve the comprehensiveness and rigor of their evaluation, which is valuable for the paper\\'s overall quality and impact. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6. It also mentions that the lack of definitions hindered understanding in an initial read. The reviewer provides specific references to similar works that have defined these terms, which offers a clear direction for the authors to address these issues. By explicitly mentioning the undefined terms and providing examples of how they have been defined in other works, the comment offers concrete guidance on how to improve the clarity and accessibility of the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"L73\" and \"L166,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue of undefined abbreviations and the lack of definition for superscript notation in Equation 6, which hindered understanding. Additionally, it provides examples of similar works that have defined these terms, offering clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6, which hindered understanding in an initial read. The reviewer provides references to similar works that have defined these terms, offering a logical basis for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these definitions impacted understanding. As it stands, the claim is mostly verifiable, as it is supported by references and logical reasoning, but it could be further substantiated to achieve a higher verifiability score.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6, which hindered understanding in an initial read. It provides examples of similar works that have defined these terms, offering clear guidance on how the authors can improve the clarity and accessibility of their paper. By pointing out these specific issues and providing references to similar works, the comment offers actionable feedback that can help the authors enhance the readability and comprehensibility of their draft. However, the comment could be more helpful if it included suggestions on how to address these issues, such as recommending specific definitions or approaches. Overall, the comment is mostly helpful as it identifies important areas for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue. There is no guidance on what specific changes or improvements could be made to the evaluation or baselines. Without actionable advice or concrete steps, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"evaluation\" and \"baselines used in the paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation being weak and the baselines not being designed for fair classification. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation, noting that the baselines used in the paper are not designed for fair classification. This is a critical observation that highlights a potential weakness in the paper\\'s methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending alternative baselines or methods for evaluating fairness. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the setting but may not be entirely sure of the exact details to address. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first three paragraphs of section 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting needs to be spelled out more clearly and suggesting that the authors may be trying to present something in greater generality than what is actually presented, which muddles the exposition. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. The reviewer suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors may find it challenging to understand the exact issue without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It suggests that the authors may be presenting something in greater generality than what is actually shown, which muddles the exposition. This feedback is clear and actionable, as it points out a specific area where the authors need to clarify their work to improve the reader\\'s understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the setting or what specific aspects need to be addressed. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the convincing nature of the experiments and questions the choice of the old baseline, R3D and C3D. It suggests that the authors should consider using more recent baselines or compare their method with other 3D CNN approaches, such as X3D, SlowFast, etc. While the comment implies that the authors should address these issues, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of the old baseline and suggesting that the proposed method should be compared with more recent 3D CNN approaches. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the convincing nature of the experiments and suggests that the authors should consider using more recent baselines or compare their method with other 3D CNN approaches. While the comment raises a valid point about the choice of baselines, it lacks specific examples or references to support the claim that the proposed method does not work on these newer approaches. The suggestion to compare with other 3D CNNs is logical, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experiments, questioning the choice of the old baseline and suggesting that the proposed method should be compared with more recent 3D CNN approaches. This feedback is valuable as it prompts the authors to consider alternative baselines and comparisons that could strengthen the paper\\'s experimental validation. However, the comment could be more helpful if it provided specific examples of recent baselines or detailed guidance on how to conduct these comparisons. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more actionable with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify how the attention module is attached to the backbone ResNet-20 architecture, including the number of attention modules used, their placement (after each block or stage), and how they are integrated into the overall architecture. This feedback provides clear and specific guidance on what the authors need to address to improve the clarity of their draft. The action is concrete, as it details the exact information that needs to be clarified, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"attention module attached to the backbone ResNet-20 architecture\" and asks for clarification on the number of attention modules, their placement, and how they are integrated into the architecture. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified, such as the number of attention modules, their placement, and how they are integrated into the architecture. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how the attention module is attached to the backbone ResNet-20 architecture, specifically asking for clarification on the number of attention modules, their placement, and how they are integrated into the architecture. This is a request for more detailed information, which is not a claim but rather a request for clarification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the integration of the attention module with the backbone ResNet-20 architecture. It asks for clarification on the number of attention modules used, their placement, and how they are integrated into the architecture. This feedback is clear and actionable, as it provides the authors with specific questions to address in order to improve the clarity of their draft. By addressing these points, the authors can enhance the understanding of their method and its implementation. However, the comment could be more helpful if it offered suggestions on how to present this information in the paper, such as through additional figures or explanations. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the proposed method's performance at low bitrates compared to baselines and suggests that a related work on implementing content-adaptive algorithms in learned video compression should be discussed or compared. While the comment implies that the authors should provide more information about the bitrate range used for BD-rate comparison and consider the related work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"BD-rate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the bitrate range used for comparison and suggests a related work for discussion or comparison. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the proposed method\\'s performance at low bitrates compared to baselines and suggests that a related work on implementing content-adaptive algorithms in learned video compression should be discussed or compared. However, the comment does not provide specific evidence or references to support the claim that the proposed method is stronger at high bitrates but close to baselines at low bitrates. Additionally, the suggestion for a related work is made without further explanation or justification. This lack of detailed support makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that it performs stronger at high bitrates but is close to the baselines at low bitrates. It raises a question about the precise bitrate range used for BD-rate comparison and suggests that a related work on implementing content-adaptive algorithms in learned video compression should be discussed or compared. This feedback is somewhat helpful as it points out a specific area for improvement and provides a potential reference for further exploration. However, the comment could be more helpful if it offered more detailed guidance on how to address the issue or provided specific suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should make this distinction, it does not provide explicit instructions on how to do so or what specific aspects of the paper need to be revised. The action is implicit and somewhat vague, as the authors need to infer that they need to make a distinction between the two concepts. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide detailed guidance on how to make this distinction. The authors can infer that it relates to the discussion or analysis of the results, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would benefit the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. This feedback is somewhat helpful as it identifies a potential area for clarification and differentiation in the paper. However, the comment lacks specific guidance on how to make this distinction or what aspects of the paper need to be revised to achieve this clarity. While it points out a potential issue, it does not provide detailed suggestions or examples to help the authors fully understand and address the concern. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the improvements on three tasks over previous works and self-implemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what additional analysis should be conducted. The comment lacks concrete details or specific actions for the authors to take, leaving them uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the improvements on three tasks over previous works and self-implemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not specify which tasks, previous works, or self-implemented baselines are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what additional analysis should be conducted or how it could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvements on three tasks over previous works and self-implemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the improvements on three tasks over previous works and self-implemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide specific examples or details on what aspects of the analysis are lacking or how the authors could improve it. The comment lacks actionable guidance or suggestions for enhancing the analysis, leaving the authors without clear direction on how to address the critique. As a result, the feedback is not helpful, as it does not provide the authors with a path to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should make the proof of Theorem 8 clearer, but it lacks specific instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to improve the clarity of the proof, but without concrete steps on how to achieve this. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the linear convergence rates relying on Theorem 8, which is buried in the appendix and whose proof is unclear. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. This is a clear and actionable point that the authors can address to improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the proof or how to better integrate Theorem 8 into the main text. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the inaccuracy of a statement about the Walkman algorithm and the lack of clarity in the reference to \"it\" in Section 3. The comment explicitly instructs the authors to correct the inaccuracy regarding the Walkman algorithm, specifying that it is solved by ADMM with two versions. It also points out the lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors clarify the intended reference. These actions are explicit and provide concrete guidance on what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about the Walkman algorithm, noting that it is solved by ADMM with two versions, and that it is inaccurate to say that these works are all based on simple SGD for decentralized optimization. Additionally, it points out the lack of clarity in the reference to \"it\" in Section 3. This provides clear guidance on what needs to be addressed in these parts of the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that \"these works are all based on the simple SGD for decentralized optimization.\" It provides a specific correction by noting that the Walkman algorithm is solved by ADMM with two versions, which contradicts the statement. This is a logical and factual observation that does not require external references or additional evidence to support the claim. Therefore, the comment is fully verifiable, as it provides a clear and accurate rebuttal to the original statement.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies specific inaccuracies in the paper, particularly in the Related Work section. It points out that the Walkman algorithm is solved by ADMM with two versions, which contradicts the statement that these works are all based on simple SGD for decentralized optimization. This feedback is clear and actionable, as it directs the authors to correct the inaccuracy in their claims. Additionally, it highlights a lack of clarity in the reference to \"it\" in Section 3, which could be improved for better understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the reference or improve the explanation in Section 3. Overall, the feedback is valuable in guiding the authors to correct their claims and improve the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the theoretical result, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates to existing rates in the literature. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this comparison or what specific rates should be compared. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" and the \"utility guarantees,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results are only valid when the features and noise are Gaussian, which is a strong requirement on the data. Additionally, it suggests that the authors should compare their rates to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main theoretical result in the paper provides utility guarantees only when the features and noise are Gaussian, which is a strong requirement on the data. The reviewer suggests that this assumption is not necessary for previous algorithms and that the authors should compare their rates to existing rates in the literature. The claim is somewhat verifiable as it provides a logical reasoning for the requirement and suggests a potential area for improvement. However, it lacks specific examples or references to existing works that support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the theoretical result of the paper, noting that the utility guarantees are only applicable when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates to existing rates in the literature, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific examples of existing works or rates that should be compared, or if it offered guidance on how to conduct this comparison. Despite this, the feedback is still actionable and provides a clear direction for the authors to enhance their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This implies that the authors should include such a comparison in their paper. However, the comment does not specify how to conduct this comparison or what specific aspects to focus on, leaving some ambiguity. While the action is clear in principle, the lack of detailed guidance on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a potential comparison that could enhance the paper, but without clear guidance on where to integrate it, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be useful to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or beneficial. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a comparison that could enhance the paper\\'s credibility and rigor. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, which limits its usefulness. While it points out a potential improvement, the authors are left to determine the exact details and execution of the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it implies that the authors should include additional experiments, it does not specify which specific baselines or comparisons should be included. The action is clear but lacks concrete details on which additional experiments to conduct or how to present them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it references specific works that focus on similar questions, it does not provide detailed reasoning or evidence to support why these additional comparisons are necessary or how they would enhance the paper. The reference to specific works is a helpful starting point, but the comment lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the suggestion but requires more detailed explanation to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section, suggesting that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method. It references specific works that focus on similar questions, providing a clear direction for the authors to expand their experimental analysis. However, the comment could be more helpful by offering specific suggestions on which additional baselines or comparisons to include, or how to present the results in a more comprehensive manner. Overall, the feedback is somewhat helpful as it points out a gap in the experimental section but lacks detailed guidance on how to address it fully.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This is a clear and explicit action for the authors to take, as it provides a specific direction for improving the presentation of results. The comment is concrete because it specifies the exact changes needed to be made, such as presenting average results on the test set and defining error bars. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the presentation of results. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not present convincing results due to the reporting of best results on the development set with hyper-parameter search and model selection on the development set. The reviewer suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This claim is somewhat verifiable as it logically points out a potential issue with the presentation of results, but it lacks specific examples or references to support the claim. The suggestion for presenting results on the test set is reasonable, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in the paper, noting that the authors report the best results on the development set with hyper-parameter search and model selection on the development set, which is not enough to be convincing. The comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of results, which is crucial for the credibility and impact of the paper. By addressing this point, the authors can significantly enhance the clarity and persuasiveness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends that the authors include more values of the parameter \\u03b1 in their ablation study. It specifies that at least 1e-2 and 1e-3 should be considered, providing clear guidance on what additional values to include. This feedback is concrete and actionable, as it directly instructs the authors on how to enhance their study by adding more values of \\u03b1. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficient ablation study on \\u03b1 and recommends providing more values of \\u03b1, such as 1e-2 and 1e-3. This provides clear guidance on what additional data or analysis is needed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study on \\u03b1 is insufficient, as it only considers values of 1e-4, 1e-1, and 5e-1 with a large gap between 1e-4 and 1e-1. The reviewer recommends adding more values, such as 1e-2 and 1e-3, to provide a more comprehensive analysis. This claim is somewhat verifiable as it logically suggests that a broader range of \\u03b1 values could provide a more comprehensive understanding of the model's behavior. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ablation study on the parameter \\u03b1, noting that it only considers a limited range of values (1e-4, 1e-1, and 5e-1) with a large gap between 1e-4 and 1e-1. The reviewer recommends adding more values, such as 1e-2 and 1e-3, to provide a more comprehensive analysis. This feedback is clear and actionable, as it directly instructs the authors on how to improve their study by expanding the range of \\u03b1 values. By addressing this point, the authors can enhance the robustness and comprehensiveness of their ablation study, which is crucial for understanding the model's behavior. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topic-word parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the questions are explicit, the comment lacks concrete guidance on how to address them. The authors know they need to provide this information but are not given specific steps to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topic-word parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the dataset and methodology sections. The comment is specific in detailing what needs to be addressed, making it fully grounded. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the dataset used in the paper, including the number of topics, the method for obtaining topic-word parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the comment identifies areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are given direction but not detailed steps on how to improve their draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis on BRP-NAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. This feedback implies that the authors should expand their analysis to include more comparisons and consider additional NAS approaches. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on which NAS approaches to include or how to conduct the analysis. While the action is implied, it is not as clear as it could be, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis on BRP-NAS, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the analysis is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. This provides clear guidance on what needs to be addressed in the analysis section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis on BRP-NAS is barebones because it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. However, the comment does not provide specific examples or references to these other approaches, nor does it explain why they are relevant or how they would enhance the analysis. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the analysis section of the paper, specifically noting that the BRP-NAS analysis only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot approaches. This feedback highlights an area where the paper could be expanded to provide a more comprehensive analysis. However, the comment does not offer specific suggestions on how to address this issue or which NAS approaches to consider, leaving the authors with a general direction but without detailed guidance on how to improve their draft. While it points out a relevant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a subjective opinion about the zero-shot version and its connection to density estimation, stating that it distracts from the main point of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes, if any, should be made to the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the zero-shot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the distraction but lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the zero-shot version and its connection to density estimation are distracting from the main point of the paper, which is about learning effective prototypes for few-shot learning. However, the comment lacks specific reasoning or evidence to support this claim, such as examples or references to similar works that might have addressed this issue. Without detailed justification or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a subjective opinion about the zero-shot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address the issue or improve the clarity of the paper. As a result, it offers limited value to the authors in terms of enhancing the draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors need to provide more information on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for details on the translation and filtering methodology to assess the dataset quality. This feedback is clear and concrete, as it specifies exactly what information is missing and what needs to be added. Therefore, the comment is highly actionable, as it provides a direct and specific action for the authors to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of details on the filtering process used to create the dataset and the need for more information on the translation and filtering methodology to assess dataset quality. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"details around the filtering process used to create the Arabic climate change QA dataset are lacking.\" This is a factual observation about the content of the paper, as it highlights a specific area where more information is needed. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would impact the assessment of the dataset quality. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the lack of details on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the transparency and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiment results could be enriched by adding attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that these additions would improve the results, it does not provide specific guidance on how to implement these changes or what specific types of attacks or threshold analyses should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to enhance their results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or figures where these additions could be made. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that these additions would improve the results. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered borderline verifiable, as it provides a general direction but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experiment results by suggesting the addition of attacks with different strengths and an exploration of how different thresholds influence detection performance. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experimental analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or what specific types of attacks or threshold analyses should be considered. Despite this, the feedback is mostly helpful as it directs the authors toward improving their experimental design and results.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer notes that this is different from Figure 4, as the discriminator is co-adapting with the generator, which could lead to getting stuck at a local optimum. While the comment provides a clear action\u2014to evaluate the claim by training a discriminator\u2014it does not offer specific guidance on how to implement this evaluation or what metrics to use. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the claim to reduce exposure bias and the need to train a discriminator on generations from the learned model. The comment provides a clear direction for the authors to follow, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer explains that this is different from Figure 4, as the discriminator is co-adapting with the generator, which could lead to getting stuck at a local optimum. This claim is somewhat verifiable as it provides a logical reasoning for the need to evaluate the claim and explains the difference between Figure 1 and Figure 4. However, the comment lacks specific examples or references to support the claim fully, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for evaluating the claim of the paper, which is to train a discriminator on generations from the learned model to confirm if the paper successfully reduces exposure bias. The reviewer explains the difference between Figure 1 and Figure 4, noting that the former involves co-adaptation between the discriminator and generator, while the latter is a static representation. This feedback is valuable as it guides the authors on how to test their claim and provides a specific method for evaluation. However, the comment could be more helpful if it offered additional insights or examples on how to implement this evaluation or what metrics to use. Overall, the comment is mostly helpful as it provides a clear direction for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. While the action is implicit, it is clear and concrete, as it specifies what additional information is needed to be included in the paper. The authors know exactly what to do to address the comment, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance difference resulting from using different image sizes and variations of ResNets. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by including additional data or analysis. However, the comment lacks depth and does not provide specific guidance on how to present this information or what specific insights would be valuable. While it points out a potential gap in the paper, it does not offer detailed suggestions for improvement, making it somewhat helpful but not fully actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to present and describe the Algorithm in detail, which is helpful for understanding the proposed method. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the algorithm is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to present and describe the algorithm in detail, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and comprehensibility of their work. By addressing this suggestion, the authors can improve the reader\\'s ability to understand and evaluate the proposed method. However, the comment could be more helpful if it included specific examples or guidance on how to present and describe the algorithm in detail. Overall, the comment is mostly helpful as it identifies a clear area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a runtime comparison at test time would be interesting to include in the paper. While it implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a runtime comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a runtime comparison at test time, which is related to the use of Chebyshev polynomials to achieve a speed-up. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the comparison could be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a runtime comparison, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a runtime comparison at test time would be interesting to include in the paper, given the mention of using Chebyshev polynomials to achieve a speed-up. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a runtime comparison at test time would be interesting to include in the paper, given the mention of using Chebyshev polynomials to achieve a speed-up. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a specific comparison that could enhance the paper\\'s contribution. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. While it points out a potential improvement, it does not fully address the authors\\' needs for comprehensive feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or suggestions on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should consider the applicability of their method to natural images. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, it does not specify which part of the paper this question pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its question about the applicability of the method to natural images, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, the comment lacks any supporting evidence, reasoning, or references to justify why this limitation is a concern or how it affects the paper\\'s contribution. Without such information, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. This is an important consideration for the broader applicability of the method in real-world scenarios. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or expand their work to include natural images. While it identifies a potential limitation, it does not offer actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the prompts in Table 6 and 7 are not well-organized, with all sentences squeezed together. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the organization or presentation of the prompts, nor are there suggestions for alternative approaches. As a result, the authors are left without any clear direction on how to improve their draft in this area. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Table 6, 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the prompts being poorly organized, with all sentences squeezed together. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prompts in Table 6 and 7 are not well-organized, with all sentences squeezed together. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization of the prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is somewhat helpful as it points out a clear area for improvement in the presentation of the prompts. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the organization. While it highlights a potential problem, it does not offer actionable guidance or detailed advice for the authors to enhance their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between sub-figures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to improve the clarity of the figures and label the modules, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"CMAF, L_BT, VoLTA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the clarity of the figures, particularly the confusion regarding the relation between sub-figures and the lack of labeling for certain modules. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the figures are not clear, specifically mentioning Figure 2 and the confusion regarding the relation between sub-figures. It also notes that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the basis of the confusion and the importance of labeling the modules. Therefore, the comment is somewhat verifiable, as it provides some evidence but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between sub-figures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. This feedback is clear and actionable, as it provides the authors with specific areas to focus on to improve the clarity and labeling of their figures. By addressing these issues, the authors can enhance the readability and comprehension of their paper. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar issues have been addressed in other works. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that if FFNs are omitted due to a linear decomposition issue, the authors should consider whether there is existing work that offers a way around this limitation. If not, the comment recommends adding a line or two acknowledging the lack of a solution and describing it as an open (hard) problem. This feedback provides a clear and explicit action for the authors to take, ensuring they know exactly what steps to consider to improve their draft. The suggestion is concrete and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of FFNs being omitted due to a linear decomposition problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering existing work for a way around the issue and proposes adding a line or two to acknowledge the problem as an open (hard) problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that FFNs are omitted due to a linear decomposition issue and questions whether there is existing work that offers a way around this limitation. The comment suggests that if not, a line or two should be added acknowledging the problem as an open (hard) problem. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific references or examples to fully substantiate the claim. The authors might need to conduct additional research to verify the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper regarding the omission of FFNs due to a linear decomposition problem. It suggests that the authors should consider whether there is existing work that offers a way around this limitation, such as an approximation. If not, the comment recommends adding a line or two acknowledging the problem as an open (hard) problem. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the readability and clarity of their paper. By addressing this issue, the authors can enhance the comprehensibility and depth of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the use of perplexity as a measure of semantic information retention after fine-tuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to control domain drift. The comment lacks actionable details, such as recommending specific methods or experiments to explore, making it difficult for the authors to know how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the use of perplexity as a measure of semantic information retention after fine-tuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the use of perplexity and the need to control domain drift, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of perplexity as a measure of semantic information retention after fine-tuning, noting that there are also factors such as domain drift that need to be controlled. However, the comment does not provide specific examples or references to support the claim that perplexity is an inappropriate measure or that domain drift is a significant issue. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the use of perplexity as a measure of semantic information retention after fine-tuning, noting that there are also factors such as domain drift that need to be controlled. This is an important point that could impact the validity and reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or control domain drift. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. While these questions imply that the authors should investigate the effect of image number and provide an explanation for BYOL, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an analysis and provide an explanation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific questions about the cluster structure and its impact on model performance, as well as the first appearance of BYOL in the abstract. However, it does not explicitly mention which part of the paper these questions pertain to, such as specific sections or figures. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for an explanation of the impact of the number of images and the introduction of BYOL, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for clarification and additional explanation. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. This feedback is somewhat helpful as it prompts the authors to consider an aspect of their model that could impact its performance and provides a specific area for clarification. However, the comment could be more helpful if it offered suggestions on how to investigate or explain these aspects, such as recommending specific experiments or analyses. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information to clarify the reasoning behind the method's effectiveness. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of understanding the rationale behind the observed effects, specifically regarding the L_pixel component. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that providing stronger arguments or intuitions to explain why the method works would be beneficial. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind the method's effectiveness, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. However, the comment does not provide specific examples or references to support the claim that the current explanation is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the rationale behind the observed effects, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions to explain why the method works would be beneficial. This feedback is somewhat helpful as it points out an area where the authors could enhance their explanation, which could lead to a clearer understanding of the method's effectiveness. However, the comment lacks specific suggestions on how to provide these arguments or intuitions, leaving the authors with a general direction but not detailed guidance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. The comment is clear and concrete, giving the authors specific details to include in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related Work section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more comprehensive overview of existing methods and their limitations, including sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This provides clear guidance on what needs to be improved in the Related Work section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Related Work section is lacking details, specifically mentioning the need for a more comprehensive overview of existing methods and their limitations. The reviewer provides a list of specific methods to consider, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This detailed list of examples and references provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by further explaining why these specific methods are important or how they relate to the paper\\'s focus. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the Related Work section, identifying a lack of comprehensive details and suggesting specific methods to include. It details the need for a more comprehensive overview of existing methods and their limitations, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This detailed guidance helps the authors understand what is missing in their Related Work section and how to improve it. By addressing these points, the authors can significantly enhance the context and relevance of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and points out that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to improve the dataset. The action is implicit and somewhat vague, as the authors can infer that they need to consider the size and diversity of their training data but are not given specific instructions on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and compares them to the typical training data for LLMs, which is on trillions of tokens. The comment suggests that the dataset needs to be massive to cover varied domains. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. The authors can infer that it relates to the dataset used for training, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing the concern about the training data. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, comparing them to the typical training data for LLMs, which is on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that 44k dialogues are insufficient. This makes the claim somewhat verifiable, as the authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, given that LLMs are typically trained on trillions of tokens. The comment suggests that the dataset needs to be massive to cover varied domains, which is a critical point for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this concern, such as recommending additional data collection or suggesting ways to improve the diversity of the existing data. While it identifies a potential weakness, the feedback could be more helpful with additional actionable advice. Therefore, the comment is somewhat helpful, as it provides insight into a potential issue but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\\' understanding of fine-grained errors like technique errors. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what alternative metrics or approaches might be more suitable. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the use of binary classification as a baseline metric and expresses skepticism about its ability to assess models\\' understanding of fine-grained errors like technique errors. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in its critique of the binary classification as a baseline, but it lacks grounding as it does not point to a particular section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the appropriateness of using binary classification as a baseline metric, suggesting that it may not be adequate for assessing models\\' understanding of fine-grained errors like technique errors. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to alternative metrics or methods that could be used instead. As a result, the claim is somewhat verifiable, as it raises a valid concern but lacks the necessary justification to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the use of binary classification as a baseline metric, suggesting that it may not be adequate for assessing models\\' understanding of fine-grained errors like technique errors. While it raises a valid concern, the comment lacks specific suggestions or alternatives for how the authors might address this issue. It does not provide guidance on how to improve the baseline metrics or what other metrics might be more appropriate for assessing the models\\' understanding of fine-grained errors. As a result, the comment is somewhat helpful, as it points out a potential weakness but does not offer actionable advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work only uses binary features and questions whether the method is applicable to real and categorical features. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to consider real and categorical features. The comment lacks concrete details on how to incorporate these features or what specific modifications are needed. As a result, the authors are left without clear instructions on how to improve their draft in this area. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of binary features in the work and questions whether the method is applicable to real and categorical features. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the limitation of binary features and suggesting that the method may not be applicable to real and categorical features. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work only uses binary features, which is a factual observation. However, it questions whether the method is applicable to real and categorical features, suggesting that this limitation needs to be addressed. The comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors may need to infer the importance of considering real and categorical features, but the lack of detailed evidence or reasoning makes the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the work, noting that it only uses binary features while real-world data typically includes a mix of binary, real, and categorical features. This is a relevant observation that could impact the applicability and generalizability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate real and categorical features into their analysis. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or guidance on what aspects of the writing are unclear or how to improve it. The comment lacks concrete details or suggestions on how to address the issues, leaving the authors without a clear understanding of what changes to make. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide examples of what needs to be clarified. Without specific references to sections, figures, or specific points in the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing need improvement. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not provide specific examples or detailed reasoning to support why the writing is unclear or how it could be improved. Without specific references or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or detailed guidance on what aspects of the writing are unclear or how to improve it. Without actionable feedback or specific suggestions, the authors are left without a clear understanding of what changes to make to enhance the clarity and readability of their paper. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback provides a clear and explicit action for the authors to take, which is to consider using additional metrics for evaluating their results. The suggestion is concrete, as it specifies a specific metric to use, making it easy for the authors to implement the change. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation of results, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting the use of BERTScore as an alternative metric, providing some guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, the comment does not provide any supporting evidence or reasoning for why BERTScore is a better choice or why the current metrics are insufficient. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the use of a different metric. However, the comment lacks depth and does not provide detailed guidance on why BERTScore might be a better choice or how it could be integrated into the evaluation process. Additionally, it does not address other potential metrics or discuss the implications of using a different metric. While the suggestion is a step in the right direction, it could be more helpful with additional context and explanation. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, specifically mentioning metrics like MMLU and Big Bench for language generation. While the comment does not explicitly instruct the authors to conduct this comparison, it provides a clear direction for how to enhance the evaluation of their metric. The action is implicit but concrete, as it specifies the metrics to compare and the conditions under which SynTextBench should be used. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"large amount of work on LLM evaluation\" and references specific metrics like MMLU and Big Bench, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of SynTextBench to other metrics proposed in the literature and how to use SynTextBench under specific conditions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that there has been a large amount of work on LLM evaluation and that some of the metrics do not satisfy the proposed desiderata. It also mentions that it would be beneficial to compare SynTextBench to other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. The comment provides a logical reasoning for why this comparison is important, but it lacks specific examples or references to support the claim that some metrics do not satisfy the desiderata. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to compare their SynTextBench metric to other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. This feedback is valuable as it guides the authors in demonstrating the strengths and limitations of their metric in the context of existing evaluations. By addressing this suggestion, the authors can enhance the clarity and robustness of their evaluation, which is essential for the credibility and impact of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific conditions should be considered. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the algorithm for constructing coresets is not novel, as it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. However, it does not provide any guidance on how the authors might address this issue or suggest ways to improve the novelty of their work. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what steps to take to enhance the novelty of their algorithm. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"algorithm for construction of coresets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, stating that the algorithm is not novel because it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the algorithm for constructing coresets is not novel because it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the novelty of the paper, noting that the algorithm for constructing coresets is not novel as it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. This feedback is clear and actionable, as it points out a weakness in the paper\\'s originality and suggests that the authors should consider how to differentiate their work from existing frameworks. However, the comment could be more helpful if it provided suggestions on how to enhance the novelty or offered examples of how other works have successfully differentiated themselves. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the writing and annotations are difficult to follow, but it does not provide any specific guidance on how to improve them. It lacks actionable advice or suggestions on how to make the writing and annotations clearer or more accessible. Without concrete steps or examples, the authors are left without a clear understanding of what changes to make to enhance the clarity of their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"poor writing and annotations,\" but it does not specify which parts of the paper are affected by this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing and annotations are difficult to follow. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing and annotations are difficult to follow. However, it does not provide any specific examples or detailed reasoning to support this claim. Without such evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a general issue with the writing and annotations being difficult to follow. However, it lacks specificity and does not provide any guidance on how to improve the clarity or accessibility of the content. Without actionable suggestions or examples, the authors are left without a clear understanding of what changes to make to enhance the quality of their work. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should provide an explanation or analysis to clarify this discrepancy. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. The comment does not present any claims or opinions but rather seeks clarification or explanation. It is a request for further information or analysis, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter-2017 $\\rightarrow$ Twitter-2015\" setting. This is a relevant observation that could prompt the authors to further analyze their results and provide a more comprehensive explanation. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a potential area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this methodology is discussed. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its question about the methodology but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. This is an important point that could impact the validity and generalizability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what potential implications it might have on the study. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to enhance the paper. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this acknowledgment pertains to, making it weakly grounded. The comment does provide a specific suggestion for improvement, which is to consider the relaxation proposed by Guzman et al. This provides some level of specificity, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a minor suggestion. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. It identifies a minor suggestion, but without further elaboration or guidance, the authors are left without a clear understanding of how to enhance their work. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of discussion on the scalability bounds of FedDES, specifically mentioning the need for a clear discussion on memory requirements and computational complexity. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should include a discussion on scalability bounds, but the comment lacks concrete suggestions on what aspects to focus on or how to present this information. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"upper limits of FedDES's scalability\" and \"memory requirements or computational complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the scalability bounds, memory requirements, and computational complexity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a thorough exploration of the upper limits of FedDES's scalability and does not provide a clear discussion on memory requirements or computational complexity. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of a thorough exploration of the scalability bounds of FedDES. It points out that there is no clear discussion on memory requirements or computational complexity, which are crucial aspects of the system\\'s performance. This feedback is valuable as it highlights an area where the authors can enhance their draft by providing a more comprehensive analysis of the system\\'s scalability. However, the comment could be more helpful if it offered specific suggestions on how to address these gaps or provided examples of how similar studies have approached this issue. Overall, the comment is mostly helpful as it directs the authors\\' attention to an important area for improvement, but it lacks detailed guidance on execution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should generate instances with more constraints and variables, as the paper currently has few instances with more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a clear and explicit action. The comment also raises a concern about LLMs' ability to model problems with large instance sizes, providing a specific direction for improvement. However, it does not offer detailed guidance on how to implement this suggestion or what specific constraints and variables should be included. While the action is clear, the lack of concrete details on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should generate instances with more constraints and variables, as few instances in the paper have more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a specific suggestion for improvement. However, the comment does not explicitly mention which sections or parts of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for more variables and constraints, but without clear grounding, it is difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks instances with more constraints and variables, as few instances have more than 7 variables. This claim is based on the observation that the paper currently has few instances with large instance sizes, which raises concerns about LLMs\\' ability to model such problems. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the concern. While the suggestion is logical, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the limited number of instances with more than 7 variables, which raises concerns about LLMs\\' ability to model problems with large instance sizes. This feedback is clear and actionable, as it suggests that the authors should consider generating instances with more constraints and variables to test the limits of their model. However, the comment could be more helpful if it provided specific guidance on how to implement this suggestion, such as recommending particular constraints or variables to include. Overall, the comment is mostly helpful as it points out a critical area for improvement but lacks detailed guidance on execution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific suggestions for improving the presentation of results, such as labeling the y-axis in Figures 2 and 3 and using a scatter plot with x/y axes being runtime/performance. It also recommends highlighting the best results in tables. These explicit actions are clear and concrete, giving the authors a direct path to enhance their draft. The comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be improved, such as the ambiguous labeling of the y-axis and the lack of runtime representation in the figures. The suggestion to use a scatter plot with runtime/performance axes is clear and provides a concrete action for the authors to take. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results presentation in Figures 2 and 3 could be improved by labeling the y-axis more clearly and including runtime information. The comment provides a specific suggestion to use a scatter plot with x/y axes being runtime/performance, which is a clear and actionable improvement. However, the comment lacks detailed reasoning or references to support why this change would be beneficial or how it would enhance the reader\\'s understanding of the results. While the suggestion is logical, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on how to improve the presentation of results in the paper. It points out that the y-axis in Figures 2 and 3 is ambiguous and suggests using a scatter plot with x/y axes being runtime/performance to clarify the results. Additionally, it recommends highlighting the best results in tables, which is a helpful suggestion for enhancing the clarity and interpretability of the results. These suggestions are clear and provide the authors with concrete steps to improve the presentation of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It seeks clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment implies that the authors should provide more information or clarification on this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement \"NodeSort differentially sorts nodes depending on the base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the implications of this statement, including whether the base node affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the implications of a statement regarding \"NodeSort differentially sorting nodes depending on the base node.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node,\" seeking clarification on whether the base node affects the ordering, key nodes for attention, and model performance. This is a relevant question that could help the authors better understand the potential impact of their method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential area for clarification, it lacks actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. This question implies that the authors should clarify or correct the arrow direction to better align with the intended purpose of the figure. While the comment does not explicitly instruct the authors to make a change, it provides a clear direction for improvement by pointing out a potential inconsistency in the figure. The action is implicit but concrete, as the authors can infer the need to adjust the arrow direction to better align with the intended purpose. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the direction of the arrow in the figure, which is a clear indication of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the direction of the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. The reviewer seems to assume that the main purpose of the figure is to influence n^(i), but this assumption is not explicitly stated or justified. The comment lacks specific reasoning or evidence to support the claim that the arrow should be reversed, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the direction of the arrow in Figure 2, specifically questioning why it goes from a Gaussian space into the latent space rather than the other way around. This feedback highlights a potential inconsistency in the figure, which could be confusing for readers. By pointing out this issue, the comment prompts the authors to clarify or correct the figure to better align with the intended purpose. However, the comment does not provide specific suggestions or guidance on how to address this issue, which limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a potential problem but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that many abbreviations lack definitions and cause confusion, specifically mentioning \"AR\" in Table 5 as an example. It provides a clear and specific action for the authors to take, which is to define these abbreviations in the text or provide a glossary. This guidance is direct and concrete, leaving no ambiguity about what needs to be done to improve the clarity of the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abbreviation \"AR\" in Table 5, noting that it stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many abbreviations lack definitions and cause confusion. It provides a specific example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This claim is somewhat verifiable as it highlights a specific issue with the paper\\'s clarity, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to infer the significance of this issue and how it affects the clarity of the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that many abbreviations lack definitions and cause confusion. It provides a clear example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is actionable as it directs the authors to clarify these abbreviations to improve the clarity and accessibility of their work. However, the comment could be more helpful if it suggested ways to standardize the use of abbreviations throughout the paper or provided guidance on how to effectively communicate these definitions. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific technical considerations should be explored or how to address them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what technical considerations are being questioned or how they might impact the analysis. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not present any claims, opinions, or suggestions that require verification. It is a request for clarification, which is not a claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, which is a relevant point for the authors to address. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might explore or justify their choice of using advantage over q value. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the setting of Unsupervised Online Adaptation is strange, as it requires a training set, including documents, queries, and labels. The reviewer suggests that this is not \"Unsupervised\" because the training set also requires annotations. While the comment identifies a potential issue with the labeling process, it does not provide explicit guidance on how to address this issue or suggest specific changes to improve the clarity or accuracy of the description. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the nature of the training set and its annotation requirements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The comment provides clear guidance on what needs to be addressed, namely the clarification of the training set and its annotation requirements. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The reviewer supports this claim by referencing Section 3.1, where the model's training requirements are described. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a logical basis for the critique, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, noting that the model requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. This is a relevant observation that could impact the clarity and accuracy of the paper\\'s description. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the clarity of the description. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an issue with the performance comparison in Table 1, specifically noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This implies that the comparison is unfair and suggests that the authors should address this issue to ensure fairness in their evaluation. However, the comment does not provide explicit guidance on how to rectify this issue or what specific changes should be made to the evaluation process. While the action is implied, it is not detailed enough for the authors to know exactly how to implement the suggested change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance comparison, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights while most baselines use a uniform weight of 1. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness, but it lacks specific examples or references to support the assertion that this difference significantly impacts the comparison. The authors would need to further investigate and analyze the impact of these sample weights to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance comparison in Table 1, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This is a relevant observation that could impact the fairness and validity of the comparison. However, the comment does not provide suggestions or guidance on how the authors might address this issue, such as recommending a standardized weighting scheme or explaining the potential impact of this difference. While it points out a relevant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the time complexity of the system if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the time complexity or suggestions for adjusting the buffer size. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"reply buffer,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of high time complexity if the buffer is too large, providing clear guidance on what needs to be addressed. However, the comment could be more specific by suggesting ways to mitigate the time complexity or providing examples of how other similar systems have handled this issue. Therefore, the comment is fully grounded and under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the time complexity will be too high if the reply buffer is too large. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the system if the reply buffer is too large. This is a relevant concern that could impact the performance and scalability of the system. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue. It does not offer actionable advice or examples of how to mitigate the time complexity, leaving the authors without a clear path forward. Therefore, the comment is somewhat helpful as it points out a potential problem but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a specific direction for improvement, it does not offer concrete guidance on how to implement these changes or which specific baselines to consider. The authors are left to infer the necessary steps to take, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative approaches to consider, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why these alternative approaches would be beneficial or how they would improve the paper. Without specific examples or detailed explanations, the claim remains unverifiable, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is somewhat helpful as it provides a specific direction for improvement by suggesting alternative approaches to consider. However, the comment could be more helpful if it offered examples of how these alternative approaches have been applied in similar contexts or provided guidance on how to implement them effectively. While the suggestion is actionable, it lacks depth and specificity, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that a brief conclusion and a summary of the article\\'s contributions are needed. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, as it specifies the exact content that should be included in the conclusion and summary. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the need for a brief conclusion and a summary of the article\\'s contributions, providing full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be addressed, namely the need for a conclusion and a summary of the paper\\'s contributions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a brief conclusion and a summary of the article\\'s contributions are needed. However, it does not provide any supporting evidence, reasoning, or examples to justify why these elements are necessary or how they would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of a brief conclusion and a summary of the paper\\'s contributions. This feedback is clear and actionable, as it directly guides the authors on how to enhance the final section of their paper. By providing a concrete suggestion for improving the paper\\'s conclusion, the comment offers valuable insight that can help the authors better communicate the significance and impact of their work. However, the comment could be more helpful if it included specific examples or suggestions on how to structure the conclusion and summary. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the synthetic experiment in a non-separable case and questions how the data distribution illustrated in Figure 1 is inseparable from the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or approaches to consider, making it difficult for the authors to know how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the data distribution in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the synthetic experiment in a non-separable case, specifically questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, the comment lacks specific examples or references to support this claim or provide a detailed explanation of why the experiment might be problematic. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the synthetic experiment in a non-separable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This is a valid point that could lead to a deeper understanding of the experiment's limitations and potential sources of error. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the experiment. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is somewhat helpful, as it identifies a potential problem but does not provide a clear path for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. This feedback implies that the authors should include this comparison in their paper to enhance the results\\' meaningfulness. While the action is implied, it is clear and concrete, as it specifies the need for a specific comparison and provides a direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what specific aspects of the framework should be compared. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential comparison. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that such a comparison would be beneficial. The authors are left to infer the relevance of this suggestion without detailed guidance or evidence. Therefore, the claim is somewhat verifiable, as it provides a logical basis but lacks the necessary depth and specificity to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for improving the paper by recommending a comparison with a method designed to defend against multiple attacks. This feedback is actionable as it points out a specific area for enhancement, which could enhance the paper\\'s contribution and relevance. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects of the framework should be compared. Overall, the comment is mostly helpful as it identifies a clear area for improvement and offers a direction for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. However, it does not provide any guidance on how to address this issue or suggest improvements to the presentation. The comment lacks explicit instructions or concrete details on how to improve the presentation, leaving the authors uncertain about what changes to make. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"results\" and the \"first 1000 episodes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes and questioning the reason for presenting them in this way. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results are presented in a convoluted way, specifically mentioning the disregard of safety violations in the first 1000 episodes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the results are presented in this manner or why the safety violations are important. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. This is a clear and actionable observation that can help the authors improve the clarity and completeness of their results section. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining why safety violations are important or how they could be incorporated into the results presentation. Despite this, the feedback is mostly helpful as it points out a critical area for improvement in the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to define the bounds for \\tau_i^l, which is important for understanding the time-warp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the bounds for \\tau_i^l, which is important for understanding the time-warp function. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment requests the definition of the bounds for \\tau_i^l, which is important for understanding the time-warp function. However, it does not provide any supporting evidence or reasoning to justify why this definition is necessary or how it would impact the understanding of the function. Without additional context or explanation, the claim is not fully verifiable, as it lacks the necessary justification to be considered fully verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is specific and actionable, as it directly instructs the authors to define the bounds for \\tau_i^l, which is important for understanding the time-warp function. This feedback is clear and provides a concrete step for the authors to take in order to improve their draft. However, the comment could be more helpful if it explained why defining these bounds is crucial or how it would enhance the clarity of the paper. Despite this, the feedback is mostly helpful as it guides the authors toward a specific improvement that can significantly impact the comprehensibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment identifies these errors, it does not provide explicit guidance on how to correct them. The authors are left to infer that they need to revise these sections to correct the errors and add a title. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be corrected, namely the writing errors and the lack of a title. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This is a factual observation that does not require verification or justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This feedback is clear and actionable, as it points out specific areas that need correction to improve the clarity and professionalism of the paper. However, the comment could be more helpful if it provided suggestions on how to correct these errors or offered guidance on how to improve the overall writing quality. Despite this, the feedback is mostly helpful as it directs the authors to specific areas for improvement, which can enhance the clarity and professionalism of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests elaborating on the reasoning behind the statement on line 134, which pertains to the theorem about the standard sigmoid function. It also mentions that elaborating on why this theorem holds would be useful, particularly in the context of the RNN and URNN convergence. While the comment provides a clear direction for the authors to expand on the explanation, it does not specify exactly how to do so or what additional details should be included. The action is explicit but somewhat vague in terms of execution, as the authors know they need to elaborate but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the reasoning behind the statement regarding the standard sigmoid function and its relation to the RNN and URNN convergence. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests elaborating on the reasoning behind a statement on line 134 and Theorem 4.1. It provides a logical basis for the suggestion by explaining that the RNN will converge to the nearest FP, unlike the URNN. However, the comment lacks specific examples or references to support the claim that elaboration is necessary. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors elaborate on the reasoning behind a statement on line 134 and Theorem 4.1. It highlights the importance of elaborating on why the theorem holds, particularly in the context of the RNN and URNN convergence. This feedback is clear and constructive, as it guides the authors to enhance the clarity and depth of their explanation. By addressing this suggestion, the authors can improve the understanding and comprehensibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the efficiency of pairwise matching, noting that it is very low and difficult to use in practical applications. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their pairwise matching. There is no guidance on potential solutions, alternative approaches, or specific actions to take. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, specifically noting that it is very low and difficult to use in practical application systems. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem with the efficiency of pairwise matching, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the efficiency of pairwise matching, noting that it is very low and difficult to use in practical application systems. This feedback highlights a potential weakness in the paper that could impact its practical applicability. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the efficiency of their pairwise matching. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance on how to improve the allocation or what aspects of the figure are considered naive. The comment lacks concrete details on how to address the issue, leaving the authors uncertain about how to apply the feedback. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions \"Figure 1,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the allocation of Figure 1, suggesting that it is too naive and could have been edited more wisely. However, the comment lacks specificity regarding what aspects of the figure are considered naive or how it could be improved. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the critique, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance or suggestions on how to improve the allocation or what aspects of the figure are considered naive. The comment lacks depth and actionable feedback, leaving the authors without clear direction on how to address the issue. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the plan-based method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to those with pre-defined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to improve the generalizability of their method. The authors are left to infer that they need to consider this issue and find ways to improve their method, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it highlights an area for improvement but does not provide explicit instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the plan-based method, specifically mentioning the requirement for manually designing a plan based on the ground truth in advance, which is unrealistic in real-world scenarios. It also compares the learned plan methods to those with pre-defined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. However, the comment does not specify which part of the paper discusses the plan-based method or where the comparison to Table 2 is made. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue with the plan-based method and its limitations, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the plan-based method is unrealistic in real-world scenarios due to the requirement for manually designing a plan based on the ground truth in advance. It also compares the learned plan methods to those with pre-defined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment provides some reasoning and logical reasoning, it lacks specific examples or references to support the claim that the plan-based method is unrealistic. The comparison to Table 2 is not detailed enough to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some support but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the plan-based method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in real-world scenarios. It also highlights a limitation in the learned plan methods compared to those with pre-defined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. This feedback is somewhat helpful as it points out a critical issue that the authors need to address, but it lacks specific suggestions or guidance on how to improve the method or address the identified limitations. The comment could be more helpful if it provided actionable steps or examples of how the authors might address these concerns, such as suggesting alternative approaches or methods for improving generalizability. Overall, the comment is somewhat helpful as it identifies a significant issue but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the first sentence of the abstract needs to be rewritten. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, as it specifies the exact part of the paper that needs attention, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the first sentence of the abstract, allowing the authors to accurately identify the part of the paper being addressed. However, it does not provide specific details on what is wrong with the first sentence or how it should be rewritten. This lack of specificity makes the comment weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the first sentence of the abstract needs to be rewritten. However, it does not provide any reasoning, evidence, or examples to support why this change is necessary or how it would improve the paper. Without additional context or explanation, the claim is not verifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the first sentence of the abstract, suggesting that it needs to be rewritten. While this feedback is clear and actionable, it lacks depth and does not provide any further explanation or guidance on what aspects of the sentence need improvement. The authors are given a specific task to address, but without additional context or suggestions, the comment may not fully support the authors in making the necessary changes. Therefore, it is somewhat helpful, as it points out a specific area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method's performance. While the comment implies that this is a necessary step, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this exercise. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\\'s performance. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. The authors can infer that it relates to the experimental setup, but this inference is not direct. The comment is specific in suggesting the need for multiple train/test splits, but it lacks grounding as it does not pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\\'s performance. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the paper. The suggestion is based on a general understanding of standard practices in the field, but lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some rationale but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experimental setup by suggesting that the authors should consider using multiple train/test splits or folds to provide a more accurate illustration of the method\\'s performance. This feedback is somewhat helpful as it points out a common practice in the field and encourages the authors to enhance their experimental design. However, the comment lacks specific guidance on how to implement this suggestion or what specific benefits it might bring to the paper. While it highlights an area for improvement, it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the method or what specific aspects of the method are overly complex. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, such as a particular section or methodology. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the method are considered overly complex or how they might be simplified. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide specific guidance or suggestions on how to simplify the method or what aspects might be overly complex. Without actionable feedback or detailed insights, the authors are left without a clear path forward to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to determine what constitutes a significant contribution or how to improve the transferability of the method. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section, method, or result. Without explicit references to sections or elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the method or transferability need improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary information to support the assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might improve the transferability of their method or what aspects of the contribution are lacking. Without actionable feedback or detailed reasoning, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the hGRU architecture appears ad-hoc and not well-motivated. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the motivation or clarify the architecture. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the hGRU architecture appears ad-hoc and not well-motivated, but it does not specify which part of the paper discusses this architecture. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part needs attention. Additionally, the comment lacks specificity regarding what aspects of the architecture are considered ad-hoc or poorly motivated. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the hGRU architecture appears ad-hoc and not well-motivated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to support the assertion, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the hGRU architecture appears ad-hoc and not well-motivated, which could be a concern for the authors. However, it lacks specificity and does not provide any actionable feedback or suggestions on how to address this issue. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and suggests that the authors should provide average return results with more env steps. While the comment implies that the authors should make a change to Line 8 and potentially include additional results, it does not explicitly instruct them to do so. The action is concrete, as it specifies the change needed and the additional information to be provided, but it is somewhat vague because it does not provide detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 8 of Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of s_t instead of s_n and suggests providing average return results with more env steps. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and a request for additional results. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the use of s_t instead of s_n on Line 8 of Algorithm 1, which is a clear and actionable point for the authors to address. It also suggests providing average return results with more env steps, which could be beneficial for understanding the asymptotic performance of the proposed method. However, the comment could be more helpful if it provided additional context or examples to guide the authors in implementing these changes. Overall, the comment is mostly helpful as it identifies a specific area for improvement and offers actionable suggestions, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the challenges when analyzing Adam under the (L0,L1)-smoothness condition. It suggests that the authors should explain the challenges and the differences between their work and that of Zhang et al. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context and explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of Adam under the (L0,L1)-smoothness condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the challenges and the differences between the authors\\' work and that of Zhang et al. This provides clear guidance on what the authors need to clarify or improve in their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the challenges when analyzing Adam under the (L0,L1)-smoothness condition are unclear and suggests that the authors should explain these challenges, especially in comparison to Zhang et al. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the challenges when analyzing Adam under the (L0,L1)-smoothness condition. It suggests that the authors should clarify these challenges and explain the differences between their work and that of Zhang et al. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity and depth of their analysis. By addressing these points, the authors can improve the comprehensibility and rigor of their work. However, the comment could be more helpful if it offered specific examples or suggestions on how to present these challenges and comparisons. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests toning down the statement about the neural network memorizing critical points, as it is not accurate according to the reviewer's understanding. Additionally, it advises the authors to compress the method section, particularly on essential definitions, and to double-check for grammatical errors, focusing on plurals and articles. These are clear and specific actions that the authors can take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be toned down and suggests compressing the method section for essential definitions. Additionally, it points out grammatical errors and provides specific examples, such as \"l.\" This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement about the neural network memorizing critical points is inaccurate, as it does not memorize exact \"critical points\" as in TopoNet [24]. The reviewer provides a logical reasoning by referencing TopoNet, which suggests that the neural network memorizes critical points differently. However, the comment lacks specific examples or references to the exact inaccuracies in the original statement, making it somewhat verifiable. The suggestion to tone down the statement is somewhat supported by the reference to TopoNet, but more detailed evidence or examples would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the manuscript. It identifies a misleading statement about the neural network memorizing critical points, suggesting that the authors should tone down this claim. This is a clear and important correction that can improve the accuracy of the paper. Additionally, the comment advises the authors to compress the method section, particularly on essential definitions, and to double-check for grammatical errors, particularly with plurals and articles. This detailed feedback is highly helpful as it guides the authors on how to improve the clarity and accuracy of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a factual statement about the prevalence of person re-ID methods based on pedestrian detectors and mentions a specific work that combines detection and re-ID. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this information or what specific aspects of the paper need to be revised based on this knowledge. As a result, the comment lacks actionability and is not helpful for the authors in improving their draft. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a factual statement about the prevalence of person re-ID methods based on pedestrian detectors and mentions a specific work that combines detection and re-ID. However, it does not specify which part of the paper this information pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the paper should be addressed or improved based on this information. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point provides a factual statement about the prevalence of person re-ID methods based on pedestrian detectors and mentions a specific work that combines detection and re-ID. This is a descriptive statement that does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a factual statement about the prevalence of person re-ID methods based on pedestrian detectors and mentions a specific work that combines detection and re-ID. However, it does not offer any insights, suggestions, or guidance on how this information could be used to improve the paper. Without actionable feedback or a connection to the paper\\'s content, the comment lacks utility for the authors. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is specific in detailing what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce what the section is about, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment suggests adding a first sentence to introduce what Section 3.2 is about. However, it does not provide any reasoning, evidence, or examples to support why this addition is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their paper. By providing a specific and direct recommendation, the comment offers a straightforward way for the authors to enhance the organization and flow of their content. However, the comment could be more helpful if it explained why this introduction is important or how it would benefit the reader. Overall, the comment is mostly helpful as it provides a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, it does not provide explicit guidance on what the authors should do to address this issue or how to clarify the statement. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the meaning of the term, but the comment lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this statement is problematic or unclear. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. This feedback highlights a potential inconsistency or confusion in the paper, which could be clarified to improve the clarity and coherence of the text. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative phrasing might be more appropriate. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution, and upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. The reviewer provides a clear and specific suggestion for how to rephrase the statement to improve clarity. This feedback is explicit and concrete, as it directly instructs the authors on how to revise their draft to better convey the concept of uncertainty. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper where the uncertainty is defined, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear suggestion for clarifying the definition of uncertainty by suggesting that the epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. This provides a clear direction for the authors to improve the clarity of their explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution. The reviewer provides a logical explanation of how this process works, which is based on common knowledge in the field of uncertainty modeling. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further develop the explanation to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. This feedback is clear and constructive, as it offers a precise way to enhance the explanation of the concept of uncertainty. By following this suggestion, the authors can significantly improve the clarity and accessibility of their draft, making it more understandable to readers. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors experimented with using domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for clarification on the number of questions created for the zero-shot intent classifier and its accuracy. While the comment implies that the authors should provide more information about their experimental setup, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about their experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the usage of domain ontologies to avoid placeholder generation and seeks clarification on the number of questions created for the zero-shot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the usage of domain ontologies to avoid placeholder generation and seeks clarification on the number of questions created for the zero-shot intent classifier and its accuracy. However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are important or how they relate to the paper\\'s content. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the usage of domain ontologies to avoid placeholder generation in the evaluated responses, which is a relevant and potentially important aspect of the paper. It also seeks clarification on the number of questions created for the zero-shot intent classifier and its accuracy, which could provide valuable insights into the experimental setup and results. However, the comment does not offer specific suggestions or guidance on how the authors might address these questions or improve their work. While it identifies areas for further exploration, it lacks actionable advice or detailed feedback, making it somewhat helpful but not comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper is missing citations to set it in the context of other MARL work, specifically mentioning self-play and population-play with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and provides concrete actions for the authors to take, namely, to include these citations to enhance the context of their work. The explicit nature of the suggestion and the provided examples make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for citations to set the paper in the context of other MARL work, specifically mentioning self-play and population-play with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly outlines what needs to be addressed by including these citations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is missing citations to set it in the context of other MARL work, specifically mentioning self-play and population-play with respect to exploration and coordination. The reviewer provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This provides a clear and concrete basis for the claim, as it offers specific references that can help the authors understand the broader context of their work. Therefore, the claim is fully verifiable, as it is supported by explicit and relevant references.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that the paper lacks citations to set it in the context of other MARL work, particularly self-play and population-play with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and actionable, as it directs the authors to include these citations to enhance the context and relevance of their work. By addressing this suggestion, the authors can significantly improve the comprehensiveness and impact of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests comparing the proposed method with other self-supervised learning methods that are not based on contrastive learning. While the suggestion is clear, it lacks specific guidance on which methods to compare with or how to conduct the comparison. The authors are left to infer that they should explore other methods, but without detailed instructions on how to do so, the action remains vague. Therefore, the comment is somewhat actionable, as it provides a direction but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed method with other self-supervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this comparison could be made. The authors may infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison with other methods, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the proposed method with other self-supervised learning methods that are not based on contrastive learning. However, it does not provide any supporting evidence, examples, or references to justify why this comparison is necessary or beneficial. Without such details, the claim remains unverifiable, as it lacks the necessary information to support the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests comparing the proposed method with other self-supervised learning methods that are not based on contrastive learning. This is a valuable suggestion as it could help the authors broaden the scope of their work and demonstrate the applicability of their method in a wider context. However, the comment lacks specificity and does not provide guidance on which methods to compare with or how to conduct the comparison. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. While the comment implies that the authors should provide a clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between the two processes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the abstention process differs from a decision threshold used by the models, and it suggests that the authors clarify this distinction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the abstention process, asking for clarification on how it differs from a decision threshold used by the models. This is a clear and actionable request for the authors to provide additional explanation or clarification in their draft. By addressing this question, the authors can improve the clarity and understanding of their methodology. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the comparison with Megatron, suggesting that it is overrated and points out that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer also raises a question about the authors\\' claim of parameter efficiency, suggesting that if this claim is valid, it could apply to these other works as well. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the comparison with Megatron and clarify their claims about parameter efficiency. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison with Megatron, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the overrating of the comparison and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment also raises a question about the authors\\' claim of parameter efficiency, which is relevant to the experimental setup. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment provides a logical reasoning by comparing the performance of these models, which supports the claim that the comparison with Megatron is overrated. However, the comment could be strengthened by providing specific examples or references to these other models, which would further substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical argument but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between COCO-LM and Megatron, suggesting that the performance of these models is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This feedback is valuable as it challenges the authors to reconsider the significance of their comparison and potentially adjust their conclusions accordingly. Additionally, the comment raises a question about the authors\\' claim of parameter efficiency, prompting them to clarify their experimental setup and the potential impact of changing BPE vocabulary on performance. While the comment provides actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or what specific aspects of the comparison or parameter efficiency should be further explored. Overall, the comment is mostly helpful as it directs the authors to consider important aspects of their work that could be improved.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis from lines 128 to 149 is not convincing and suggests that the GS-P-50 model has smaller class selectivity score, which means it shares more features with ResNet-50. The reviewer also hypothesizes that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the analysis. The reference to external works, while helpful, does not offer detailed instructions on how to apply this information to the draft. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of convincingness and consider the implications of the external references. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 128 to 149,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the analysis, noting that the GS-P-50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet-50. The comment further hypothesizes that additional context may allow the network to reduce its dependency. This provides clear guidance on what needs to be addressed in the analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis from lines 128 to 149 is not convincing enough, based on the histogram in Figure 3, which shows that the GS-P-50 model has a smaller class selectivity score compared to ResNet-50. The reviewer references external works [1] and [2] to support the claim that GS-P-50 shares more features with ResNet-50, suggesting that additional context may allow the network to reduce its dependency. However, the comment does not provide detailed reasoning or examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment could be strengthened by explaining how the external works support the claim or by providing specific examples from the references. Therefore, the claim is somewhat verifiable, as it requires further elaboration to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis presented in the paper, noting that the analysis from lines 128 to 149 is not convincing enough. It points out that the GS-P-50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet-50. The reviewer hypothesizes that additional context may allow the network to reduce its dependency. While the comment provides a clear direction for improvement by suggesting that the authors address the issue of convincingness, it lacks specific guidance on how to improve the analysis or what aspects of the analysis are lacking. The reference to external works is helpful but does not fully address the critique. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of convincing evidence in the paper's conclusions, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer suggests that the results might be due to limited exploration of combination methods and points to recent work that has shown the potential of feature replay methods in continual learning. While the comment provides a specific area for improvement by suggesting the exploration of combination methods, it does not offer concrete guidance on how to implement this suggestion or what specific combination methods should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific conclusion about continuous learning with unlabeled data accumulating noise, which allows the authors to identify the part of the paper being addressed. It also specifies the issue by pointing out that the results might be due to limited exploration of combination methods and references specific works that have shown the potential of feature replay methods in continual learning. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the conclusions in the paper are not convincing, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer supports this claim by referencing recent works that have shown the potential of feature replay methods in continual learning, such as [R1] and [R2] (FRoST) in CCD. Additionally, the reviewer suggests that a more recent work [R3] employs feature replay to continually adjust the feature space, which also achieves remarkable performance for continual category discovery. This provides a robust basis for the claim, as it references specific works that support the critique. However, the comment could be strengthened by providing more detailed analysis or comparisons to further substantiate the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s conclusions, noting that some of them are not convincing. It provides a detailed example by pointing out that the claim about continuous learning with unlabeled data accumulating noise might be due to the limited exploration of combination methods. The reviewer references recent works that have shown the potential of feature replay methods in continual learning, such as [R1] and [R2] (FRoST) in CCD, and a more recent work [R3] that employs feature replay to continually adjust the feature space. This feedback is highly helpful as it not only highlights a weakness in the paper\\'s conclusions but also offers specific examples and references to support the critique. By providing actionable suggestions, the comment guides the authors on how to strengthen their arguments and improve the paper. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. It suggests that the authors should compare their work with a chain-of-thought prompting approach, which is a specific and concrete suggestion for improvement. This feedback provides clear guidance on what the authors need to do to enhance their comparisons and make their work more robust. The explicit nature of the suggestion and the concrete example of a potential baseline make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of meaningful baselines and the suggestion to compare with a chain-of-thought prompting approach. This provides clear guidance on what the authors need to improve in their comparisons. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors should compare their work with a chain-of-thought prompting approach. While the comment identifies a potential issue with the baselines, it does not provide specific examples or detailed reasoning to support the claim that the current baselines are insufficient. The suggestion to compare with a chain-of-thought prompting approach is a logical suggestion, but the comment lacks the necessary evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the lack of meaningful baselines limits the comparisons made in the paper. It suggests that the authors should consider using a chain-of-thought prompting approach as a more meaningful baseline. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that could enhance the robustness and credibility of the paper. By addressing this point, the authors can significantly strengthen their comparisons and demonstrate the effectiveness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the model is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its inquiry about the pretraining process and its generalizability. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the pretraining process of the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. While the comment identifies a potential area for clarification or discussion, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential gap in the paper, but it could be more beneficial with additional context or suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to ensure that the observations and design decisions are not dependent on specific hardware or software. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which part of the paper this pertains to. The authors cannot confidently determine which sections or elements of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the observations or design decisions are dependent on hardware or software. Without clear guidance on what needs to be addressed or improved, the authors cannot effectively address the comment. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it affects their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. While it identifies a potential problem, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or what specific aspects of the paper might be affected. Without detailed suggestions or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study in Table. While the comment implies that the authors should investigate these issues, it does not provide explicit instructions or concrete steps for how to address them. The authors can infer that they need to assess the accuracy of the ground truth and the noticeability of the difference, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study in Table. However, it does not specify which part of the paper these questions pertain to, such as a specific section or table. The authors can infer that it relates to the results or analysis sections, but this inference is not direct. The comment is specific in its inquiry about the accuracy and noticeability of the differences, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study in Table. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the accuracy and reliability of the results presented in the paper. It questions whether the small differences observed are actually noticeable or due to noise or randomness in the training process. Additionally, it points out a lack of difference between the results reported in the ablation study in Table. While the comment identifies potential issues, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve their analysis. The feedback is somewhat helpful as it prompts the authors to consider the reliability of their results, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of important experimental details in the main text and the lack of explanations or interpretations in the Appendix. It specifically mentions the PCA experiments in Figures 3, 7, and 8 as examples of missing information. While the comment identifies areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include more detailed explanations and interpretations in the main text and Appendix, but the comment lacks concrete guidance on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of explanations or interpretations for the PCA experiments in these figures. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. The reviewer provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This provides a clear and specific basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that highlight the importance of including explanations and interpretations in the main text. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. It provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is clear and actionable, as it directs the authors to include more detailed explanations and interpretations in the main text and Appendix. However, the comment could be more helpful if it suggested ways to improve the presentation of these details or provided examples of how similar studies have addressed this issue. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of new evaluation metrics and the limited exploration of existing metrics in the experimental analysis section. It explicitly states that there needs to be an in-depth exploration of the reasons for the experimental results. This provides a clear and concrete action for the authors to take, which is to conduct a more thorough analysis of the experimental results and consider proposing new metrics. The comment is specific in detailing what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental analysis section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of new evaluation metrics and the limited exploration of existing metrics. The comment suggests an in-depth exploration of the reasons for the experimental results, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that no new evaluation metrics are proposed and that existing metrics are linearly combined. It suggests that the experimental analysis section needs an in-depth exploration of the reasons for the experimental results. However, the comment does not provide specific examples or references to support the claim that existing metrics are insufficient or that the exploration is lacking. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors may find it challenging to understand the basis of the critique without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting the lack of new evaluation metrics and the limited exploration of existing metrics. It suggests that the experimental analysis section needs an in-depth exploration of the reasons for the experimental results. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by proposing new metrics or conducting a more thorough analysis of the existing ones. However, the comment could be more helpful if it offered examples of how to conduct such an exploration or provided guidance on what specific aspects to focus on. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, it does not provide explicit guidance on how to resolve this issue or suggest alternative notations. The action is implicit and vague, as the authors are left to infer that they need to clarify or change the notation to avoid confusion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L166\" and \"L176,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"K,\" which is being used for both a known kernel function and the number of layers, causing confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"K,\" noting that it is being used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176), which can cause confusion. This feedback is clear and actionable, as it points out a potential source of confusion in the paper and suggests a way to clarify the notation. However, the comment could be more helpful if it provided examples of how the notation could be clarified or revised. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for non-Gaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the concern about the practical impact or suggestions for improving the paper to better demonstrate its relevance. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for non-Gaussian problems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the theoretical interest and the potential practical impact, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for non-Gaussian problems. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the weak recovery problem studied is primarily of theoretical interest and questioning the practical impact of the AMP algorithm for non-Gaussian problems. This feedback highlights a potential limitation in the paper\\'s relevance and applicability, which could impact its impact on the field. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or demonstrate the practical relevance of their work. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the connection to human cognition, questioning the relevance of the authors\\' suggestion that cognitively basic adaptation mechanisms might have a significant impact on self-organization. It suggests that the authors should provide more evidence or references to support their claim. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on what kind of evidence or references would be helpful. The action is implicit and somewhat vague, as the authors need to infer that they should provide more evidence or references to support their claim. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the connection to human cognition and questions the relevance of the authors\\' suggestion that cognitively basic adaptation mechanisms might have a significant impact on self-organization. It references the authors\\' statement about the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation, which are typically associated with human cognition. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the authors\\' suggestion and the need for more evidence or references to support it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the relevance of the connection to human cognition, citing the authors\\' statement about the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation. The reviewer suggests that it would be surprising for a behavioral economist to ignore these factors and implies that more evidence or references are needed to support the claim. However, the comment lacks specific examples or references to substantiate the claim, making it somewhat verifiable. The authors would need to further develop the reasoning or provide additional evidence to fully address the reviewer\\'s concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the relevance of the connection to human cognition, questioning the authors\\' suggestion that cognitively basic adaptation mechanisms might have a significant impact on self-organization. It points out that the problem is reductionist and lacks mechanisms like bargaining and negotiation, which are typically associated with human cognition. The comment suggests that it would be surprising for a behavioral economist to ignore these factors and implies that more evidence or references are needed to support the claim. While the comment identifies a potential weakness in the argument, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is somewhat helpful as it highlights a potential gap in the argument, but it could be more beneficial with additional actionable advice. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, it does not provide specific guidance on how to tone down the language or suggest alternative phrasing. The comment lacks explicit instructions or concrete examples of what constitutes overly exaggerated or flamboyant language, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the wording being overly exaggerated and suggests that the word choice is flamboyant in multiple places. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or references to overly exaggerated or flamboyant language, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant in multiple places. This feedback is somewhat helpful as it points out a potential weakness in the language used, which could be revised to be more appropriate and professional. However, the comment lacks specific examples or suggestions on how to tone down the language or what alternative phrasing might be more appropriate. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific direction for the experiments, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the need for ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides full grounding as it clearly identifies the part of the paper that needs revision. The comment is also specific because it specifies the exact comparison that needs to be made, which is the number of learnable parameters and GFLOPs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting additional experiments. By doing so, the authors can demonstrate the effectiveness of their method in comparison to other approaches, which could enhance the paper\\'s contribution and credibility. However, the comment could be more helpful if it included suggestions on how to design and conduct these experiments, such as which metrics to use or how to interpret the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific baselines to compare against or detailing the expected utility measure. The comment lacks concrete steps for the authors to take, leaving them uncertain about how to improve their draft. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for comparison to baselines. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison to simple feature acquisition baselines like expected utility or some other measure, which is a significant weakness. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure to prove the effectiveness of the proposed approach. This is a critical oversight that could impact the credibility and impact of the paper. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting which baselines to compare against or how to implement the comparison. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions for improvement, but it does not provide explicit instructions or concrete actions for the authors to take. The comment mentions that Figure 5a seems strange and asks for more explanations, but it does not specify what aspects of the figure are problematic or how to address them. Similarly, it mentions the handling of DVS input when the input is in AER format but does not offer guidance on how to improve this aspect. The comment also suggests analyzing energy consumption like reference [15] did, but it does not provide specific steps or examples on how to implement this analysis. Overall, the comment lacks explicit instructions and is vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 5a\" and \"11,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with \"Fig. 5a\" and suggests providing more explanations, as well as addressing the handling of DVS input when the input is in AER format. Additionally, it suggests analyzing energy consumption like reference [15] did, which provides clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of several questions and suggestions for improvement, rather than making a subjective claim or opinion. It does not contain any claims or judgments that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides several pieces of feedback that can help the authors improve their draft. It points out that Figure 5a seems strange and suggests that more explanations are needed. It also questions how the authors handled DVS input when the input is in AER format, which is a relevant concern for the paper. Additionally, the comment suggests analyzing energy consumption like reference [15] did, which could strengthen the paper\\'s foundation. While the comment identifies areas for improvement, it lacks specific guidance or examples on how to address these issues. Therefore, the authors can benefit from the feedback but may need to infer the exact steps to take. Overall, the comment is somewhat helpful, as it provides valuable insights but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It specifically mentions the use of separate embeddings and positional encoding, but it does not provide explicit guidance on how the embeddings are combined or how they are fed into the CSCM. The comment implies that the authors should provide more detailed information on this process, but it does not specify exactly what needs to be clarified or how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"text\" and \"CSCM,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, how historical observations are combined with inputs known over all time given differences in sequence lengths. The comment provides a clear direction for the authors to address the issue by asking for clarifications on the embedding and positional encoding methods used. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It mentions the use of separate embeddings and positional encoding, but it does not provide any supporting evidence, reasoning, or references to justify the claim that clarification is needed. The comment lacks specific examples or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper regarding the combination of historical observations and inputs known over all time, given differences in sequence lengths. It points out that the text mentions separate embeddings and positional encoding but lacks clarity on how these are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed information on the embedding and positional encoding methods used. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects should be clarified. Overall, the comment is mostly helpful as it effectively guides the authors toward improving the clarity and completeness of their explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the introduction of multi-granularity and multi-scale as a common approach to convolutional networks, suggesting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the introduction of multi-granularity and multi-scale as a common approach to convolutional networks, suggesting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing what is considered a common approach and what is lacking in the paper, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of multi-granularity and multi-scale to enhance model performance is a common approach in convolutional networks, and that merely migrating this approach to the field of MLMs is not innovative. The reviewer supports this claim by referencing the article itself, which implies that the authors should have known this. However, the comment lacks specific examples or references to support the claim that the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. This lack of detailed evidence or examples makes the claim somewhat verifiable, as it provides some support but not enough to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the introduction of multi-granularity and multi-scale as a common approach to convolutional networks, suggesting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. While the comment identifies a potential weakness in the paper\\'s contribution, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. The feedback is somewhat helpful as it highlights a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\\\lambda$ is not discussed in the paper, and their values are not specified. This implies that the authors should include a discussion on the sensitivity of these parameters and specify their values. The comment is explicit in its request for additional information, providing clear guidance on what needs to be added to the paper. However, it does not specify how to present this information, leaving some room for interpretation. Therefore, the comment is mostly actionable, as it identifies a specific area for improvement but lacks detailed instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\\\lambda$, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on the sensitivity of these parameters and the absence of their values in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\\\lambda$ is not discussed in the paper, and their values are not specified. This is a factual observation that highlights a gap in the paper\\'s content. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the paper\\'s overall quality. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of discussion on the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\\\lambda$. It highlights that their values are not specified in the paper, which is a critical omission that could impact the validity and reliability of the results. This feedback is clear and actionable, as it directs the authors to include a discussion on the sensitivity of these parameters and their values. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what specific aspects to consider. Overall, the comment is mostly helpful as it effectively points out a gap in the paper that the authors can address to enhance its rigor and clarity.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments to address the concerns raised. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarity-aware positive sample selection or the transfer performance of the model. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the concerns about the model's generalization and suggesting additional experiments, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that selecting positive samples without introducing perturbation noise could lead to lower generalization performance. The comment is somewhat verifiable as it provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments to validate the claim, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how to conduct these additional experiments or what specific downstream tasks should be considered. The feedback is somewhat helpful as it points out a potential issue but does not provide detailed guidance on how to resolve it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to provide more discussion on the power of different architectures but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the architectures should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that fast SMP is less expressive than SMP. Without such evidence or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the architectures should be discussed. The comment is somewhat helpful as it points out a potential gap in the paper, but it does not provide actionable advice or detailed guidance for improvement. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of train-val-test, rather than simply different initialisation seeds. This feedback provides a clear and explicit action for the authors to take, which is to consider using different splits of the training, validation, and testing datasets to test the robustness of their methods. The comment is specific in detailing the change needed to improve the robustness of the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of train-val-test, rather than simply different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results section. The authors can infer that it relates to the evaluation or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that evaluating methods across different splits of train-val-test would be more robust than simply using different initialisation seeds. However, the comment does not provide any supporting evidence, examples, or references to justify why this approach would be more robust or how it would improve the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of train-val-test, rather than simply different initialisation seeds. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the robustness of their results. By suggesting a change in the evaluation approach, the comment offers a concrete way for the authors to enhance the quality and reliability of their findings. However, the comment could be more helpful if it explained why this change would be beneficial or how it would impact the results. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the first two bullets about contributions at the end of the introduction should be combined together. This is an explicit action that the authors can directly implement to simplify the introduction. The comment provides a clear and concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests combining the first two bullets about contributions at the end of the introduction. However, it does not specify which part of the introduction these bullets are located in, making it weakly grounded. The comment is specific in suggesting a potential simplification of the introduction by combining these two bullets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests combining the first two bullets about contributions at the end of the introduction. However, it does not provide any supporting evidence, reasoning, or examples to justify why this combination would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific improvement by recommending that the authors combine the first two bullets about contributions at the end of the introduction. This feedback is clear and actionable, as it provides a concrete suggestion for simplifying the introduction and making it more coherent. By following this advice, the authors can streamline their paper and enhance its readability. However, the comment could be more helpful if it explained why combining these bullets would be beneficial or how it would improve the overall structure of the introduction. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clearly defined. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify these concepts or what specific changes should be made to improve the clarity. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the types of situations and social norms, such as physical and psychological safety, are not clearly defined in the main paper. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of these situations and social norms are unclear or how they could be clarified. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the types of situations and social norms, such as physical and psychological safety, are not clearly defined in the main paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a lack of clarity in the paper regarding the types of situations and social norms, such as physical and psychological safety, which are mentioned but not clearly defined. This feedback is somewhat helpful as it points out an area where the authors could improve the clarity and comprehensibility of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as providing examples or clarifying definitions. While it highlights a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the paper's potential benefits and appreciates its focus on a specific problem. However, it points out the need to demonstrate the algorithm's improvement over existing solutions by addressing robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment implies that the authors should provide more evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional evidence to substantiate their claims. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment acknowledges the paper\\'s focus on a specific problem and appreciates its potential benefits to the neuroscience community. It highlights the need to demonstrate the algorithm\\'s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The comment suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where the algorithm\\'s performance is discussed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the paper\\'s potential benefits and appreciates its focus on a specific problem. It highlights the need to demonstrate the algorithm\\'s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment identifies a critical area for improvement, it lacks specific examples or references to support the claim about the algorithm\\'s improvement over existing solutions. This makes the claim somewhat verifiable, as it provides a direction for improvement but lacks detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the paper\\'s potential benefits and appreciates its focus on a specific problem in the neuroscience community. It identifies a critical area for improvement, namely the need to demonstrate the algorithm\\'s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment provides a clear direction for improvement, it lacks specific suggestions or examples on how to address this issue. The authors are given a general idea of what needs to be improved but are not provided with actionable steps to achieve it. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully guide the authors on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more baselines should be compared and more domains should be tested. It also mentions that the choices of weighting and learning density functions are not strongly motivated, and that stronger empirical results are needed. However, the comment does not provide specific guidance on which baselines to compare or how to test the additional domains. The authors are left to infer that they need to expand their experimental setup, but without concrete suggestions on which baselines or domains to include, the action remains vague. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more baselines should be compared and more domains should be tested, and it mentions the choices of weighting and learning density functions as areas for improvement. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or experiments where these improvements could be made. Additionally, it lacks specific guidance on which baselines or domains should be included. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that more baselines should be compared and more domains should be tested, and it critiques the choices of weighting and learning density functions as not being strongly motivated. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, suggesting that more baselines should be compared and more domains should be tested. It also critiques the choices of weighting and learning density functions as not being strongly motivated, implying that stronger empirical results are needed. However, the comment lacks specific suggestions on which baselines or domains to include, making it somewhat helpful as it points out areas for improvement but does not provide detailed guidance on how to address them. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to define the dashed lines in figures 2A-B and 4B. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete request, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig. 2A-B\" and \"fig. 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the dashed lines in these figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests clarification about the dashed lines in figures 2A-B and 4B. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it directly addresses a specific issue by requesting clarification on the definition of the dashed lines in figures 2A-B and 4B. This feedback is clear and actionable, as it guides the authors to provide a necessary explanation for their figures, which could enhance the clarity and understanding of their work. By addressing this point, the authors can improve the readability and comprehensibility of their draft, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the comparability of the results or what specific aspects need to be improved. As a result, the authors are left without any clear direction on how to enhance the significance of their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the results are not comparable or how they could be improved. Without clear guidance on where to focus the revision, the authors may struggle to address the issue effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results are not comparable to existing methods, which suggests that the significance of the proposed methods is questionable. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not provide any specific examples or guidance on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of novelty in the paper, specifically noting that it is a straightforward application of existing literature, such as DeCorr, in a specific application domain. It highlights the main contribution as the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment implies that the authors should provide more insights into these challenges, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of unique insights. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DeCorr [1],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems, despite being a straightforward application of existing literature. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr. The reviewer supports this claim by mentioning the focus on general deep graph neural networks and the transposition of DeCorr's insights into graph collaborative filtering. However, the comment also acknowledges that modifications like different penalty coefficients for users and items are proposed. While the claim is somewhat verifiable due to the mention of DeCorr and the proposed modifications, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it lacks novelty and is a straightforward application of existing literature, specifically DeCorr. It highlights the main contribution as the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. This feedback is somewhat helpful as it identifies a critical area for improvement, namely the need to provide more insights into the unique challenges of overcorrelation. However, the comment could be more helpful if it offered specific suggestions on how to address this gap or provided examples of what such insights might entail. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multi-sphere icosahedral discretization process. However, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the clarity of the symbols or the explanation of the process. The authors are left to infer that they need to clarify the symbols and provide more information on the process, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multi-sphere icosahedral discretization process. This provides clear guidance on what needs to be addressed in the figure and the process. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multi-sphere icosahedral discretization process. However, the comment does not provide specific examples or detailed reasoning to support the claim of ambiguity or the need for clarification. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multi-sphere icosahedral discretization process. This feedback is somewhat helpful as it points out a potential area for improvement in the clarity and comprehensibility of the figure. However, it lacks depth and does not provide specific suggestions or guidance on how to address the ambiguity or improve the explanation of the symbols. While it highlights an issue, the comment could be more helpful with additional details or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the paper regarding the assumption that the spectrum of a kernel is sub-gaussian, noting that this assumption excludes popular classes of kernels like Matern kernels. The reviewer suggests that the results could be restrictive due to this assumption. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to broaden the scope of the results. The action is implicit and somewhat vague, as the authors can infer that they need to consider the impact of this assumption on their results but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the assumption regarding the spectrum of a kernel being sub-gaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this assumption excludes popular classes of kernels like Matern kernels, which could limit the scope of the results. This provides clear guidance on what needs to be addressed in terms of the assumptions made and the potential impact on the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the assumption of the spectrum of a kernel being sub-gaussian is a limitation, as it excludes popular classes of kernels like Matern kernels. The reviewer supports this claim by noting that Matern kernels only decay polynomially, which could restrict the applicability of the results. However, the comment lacks specific examples or references to Matern kernels or other relevant literature to fully substantiate the claim. While the reasoning is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper regarding the assumption that the spectrum of a kernel is sub-gaussian, which excludes popular classes of kernels like Matern kernels. This is a relevant point that could impact the applicability and generalizability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or broaden the scope of their results. While it highlights an important issue, the feedback lacks actionable advice or detailed insights, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it appears to be a key factor in performance gain. While the comment explicitly states the need for more discussion on the unsupervised pretraining, it does not provide specific guidance on how to integrate this discussion into the main paper. The authors are left to infer that they should add more details about the pretraining method, but the comment lacks concrete steps or examples on how to do so. Therefore, the action is explicit but somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"unsupervised pretraining,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on the unsupervised pretraining in the main paper, and it suggests focusing more on this aspect. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unsupervised pretraining is a key factor in performance gain, based on data from Table 4. However, it does not provide specific evidence or detailed reasoning to support this claim, such as data analysis or comparisons with other methods. The comment suggests that the unsupervised pretraining is more important than other modules presented in the paper, but it lacks specific examples or detailed justification to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for further exploration but requires more detailed evidence or reasoning to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the unsupervised pretraining is a key factor in performance gain but is not discussed in detail in the main paper. It suggests that the authors should focus more on the pretraining method, as it appears to be more important than other modules presented in the paper. This feedback is clear and actionable, providing the authors with a direct suggestion on how to enhance their draft by including more detailed discussion on the unsupervised pretraining. However, the comment could be more helpful if it offered specific guidance on how to integrate this discussion into the main paper or provided examples of how other papers have effectively discussed similar topics. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\\'s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they might need to consider this aspect in their methodology or experimental design, but the comment lacks concrete steps or detailed advice on how to implement this change. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\\'s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. While the authors might have an idea of where this discussion might occur, the comment lacks full grounding. It is specific in its critique of the methodology but does not provide detailed guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\\'s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate the claim that knowing the speaker\\'s gender beforehand is a drawback. As a result, the claim is somewhat verifiable, as it provides a logical argument but lacks the necessary evidence or references to fully support it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the choice of ELM (male/female) and whether this requires knowledge of the speaker\\'s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker\\'s identity. This feedback is somewhat helpful as it identifies a potential issue with the methodology that the authors may need to address. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what alternative approaches might be considered. Overall, the comment offers a valuable insight but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the writing is difficult to follow in many places and suggests simplifying it. However, it does not provide specific examples or guidance on how to achieve this simplification. The authors are left to infer that they need to make their writing more accessible, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the writing is difficult to follow in many places and suggests simplifying it. However, it does not specify which parts of the paper are particularly challenging or where the simplification is needed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing is difficult to follow in many places and suggests simplifying it. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or examples, the authors may find it challenging to understand where the writing is difficult to follow and how to simplify it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper\\'s writing, noting that it is difficult to follow in many places and suggests simplifying it. While this feedback highlights a potential problem, it lacks specificity and does not provide actionable guidance on how to improve the writing or which sections are particularly challenging. Without detailed suggestions or examples, the authors may struggle to address the issue effectively. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to [31]. However, it does not provide any guidance on how the authors might address this issue or what specific changes could be made to improve the paper. The comment lacks explicit or implicit actions, leaving the authors without direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to [31]. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. Additionally, the comment does not provide specific details on what is considered incremental or how the new loss is insufficient. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to [31]. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to [31]. However, it does not provide any specific feedback or suggestions on how the authors might address this issue or improve the paper. Without actionable guidance or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. Additionally, it asks how to determine which $P^*$ to fix in practice. While the comment implies that the authors should provide more detailed explanations or examples, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more information or examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"the invertible function $f^*$,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the proof of Theorem 1 and the dependence of $f^*$ on the fixed $P^*$. The comment suggests providing intuition for the proof and inquires about the impact of different distributions on determining $f^*$. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification regarding the proof of Theorem 1 and the dependence of the invertible function $f^*$ on the fixed $P^*$. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the proof of Theorem 1 and the dependence of the invertible function $f^*$ on the fixed $P^*$. It suggests providing intuition for the proof and inquires about the impact of different distributions on determining $f^*$. This feedback is valuable as it prompts the authors to consider the clarity and depth of their explanations, particularly in the context of mathematical proofs. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions or improve the clarity of the paper. Overall, the comment is mostly helpful as it directs the authors to consider important aspects of their work that could be further developed.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks guidance on how the authors might clarify or justify the notation choices, leaving the authors uncertain about how to proceed. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of notation, expecting them to be analogous but noting a discrepancy. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. However, the comment does not provide any reasoning, explanation, or evidence to support why the notation should be analogous or why the discrepancy exists. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the notation used in equations (7) and (10), expecting them to be analogous but noting a discrepancy. This feedback highlights a potential issue in the clarity or consistency of the paper, prompting the authors to reconsider their notation choices. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as explaining the rationale behind the notation or proposing alternative approaches. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide empirical evidence to demonstrate the applicability of their model to real-world diffusion processes. While the comment implies that the authors should conduct experiments or provide examples to support their claims, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors know they need to provide empirical evidence but may not be entirely sure of the specifics of what is expected. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of the model to real-world diffusion processes, suggesting that the authors should provide empirical evidence to demonstrate its effectiveness. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for empirical evidence, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the applicability of the model to real-world diffusion processes is a concern, and it provides a logical reasoning for this claim. The reviewer acknowledges that the authors have defined an interesting problem with elegant solutions but emphasizes the need for empirical evidence to demonstrate the model's effectiveness in real-world scenarios. This claim is somewhat verifiable as it provides a rationale for the need for empirical evidence but lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the applicability of the proposed model to real-world diffusion processes. It acknowledges the elegance of the solutions presented but highlights the need for empirical evidence to demonstrate the model's effectiveness in real-world scenarios. This feedback is clear and actionable, as it directs the authors to provide empirical evidence to substantiate their claims. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what aspects of the diffusion process should be considered. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the action is implicit, it is clear that the authors need to expand their testing to include more datasets. The comment provides a specific suggestion for improvement, which is to test on additional datasets. However, it does not offer detailed guidance on which datasets to use or how to conduct the additional testing. Therefore, the action is somewhat actionable, as it provides a clear direction but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the testing and evaluation of the method, but this inference is not direct. The comment is specific in suggesting the need for additional testing, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not provide any supporting evidence, reasoning, or references to justify why testing on more datasets would be beneficial or necessary. The claim is based on a logical assumption, but without additional context or examples, it lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. This is a reasonable suggestion that could improve the robustness and generalizability of the results. However, the comment lacks specificity and does not provide guidance on which datasets to use or how to conduct the additional testing. Without detailed suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a discrepancy between the description in Section 4.2 and the equation in the section, specifically regarding the question representation and the use of r^q. It suggests clarifying this discrepancy and provides a specific question about the meaning of \\sigma in the equation. Additionally, it raises a concern about the stability of the computation involving two sigmoid activations. The comment is explicit in its request for clarification and provides concrete guidance on what needs to be addressed. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the equation in Section 4.2, pointing out the lack of a term for r^q, which is the question representation, and questioning the meaning of \\sigma in the equation. The comment also suggests clarifying these points and raises a concern about the stability of the computation involving two sigmoid activations. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the question representation in Section 4.2, noting that the equation does not include a term for r^q, which is the question representation. It also questions the meaning of \\sigma in the equation and suggests that multiplying two sigmoid activations might be ill-conditioned and numerically unstable. The comment provides logical reasoning by pointing out the discrepancy between the description and the equation, and it suggests clarifying these issues. However, it lacks specific examples or references to support the claim about stability, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but could benefit from more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the question representation in Section 4.2, noting that the equation does not include a term for r^q, which is the question representation. It also questions the meaning of \\sigma in the equation and raises a concern about the stability of the computation involving two sigmoid activations. The comment provides clear and actionable feedback by suggesting that the authors clarify these points to improve the clarity and accuracy of their work. By addressing these issues, the authors can enhance the understanding and robustness of their method. Therefore, the comment is highly helpful, as it offers detailed guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, and that alternatives already exist. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to differentiate their contribution from existing work. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the main contribution, which is the combination of attention with other linear mechanisms. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what alternatives are mentioned or how the authors could address the issue of novelty. Without clear guidance on where to focus improvement efforts, the authors may struggle to effectively respond to this feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, the comment does not provide specific examples or references to these alternatives, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or reasoning, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, it does not provide specific examples or suggestions on how the authors might address this issue or differentiate their work from existing alternatives. Without actionable feedback or guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and concrete action that the authors can take to improve their draft. The comment provides a specific suggestion for visualizing the results, which is a direct and actionable point. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing a plot of how different weights of the model move, specifically after unlearning, to see which layers are affected the most. However, it does not specify which part of the paper this plot should be included in, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a plot to visualize the results. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This claim is somewhat verifiable as it logically follows that such a plot could provide insight into the impact of unlearning on different layers. However, the comment lacks specific examples or references to similar studies that have already demonstrated the importance of such a plot. This makes the claim somewhat verifiable, as the authors would need to make a logical inference to understand the necessity of this plot. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors include a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and constructive piece of feedback that could help the authors better understand and communicate the impact of their method. By addressing this suggestion, the authors can enhance the clarity and comprehensiveness of their results. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. It further points out that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment identifies a potential issue with the novelty of the paper, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they need to provide more novelty or depth in their methodology section, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"methodology aspect\" and \"ENCODE part,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the novelty of the paper, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. The reviewer further suggests that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment identifies a potential issue with the novelty of the paper, it lacks specific references or detailed reasoning to support the claim that the ENCODE part is already proposed. The suggestion about the decomposition part is somewhat vague, as it does not provide a clear explanation of what the authors should do to address this issue. Therefore, the claim is somewhat verifiable, as it provides some insight but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the paper, particularly regarding the ENCODE part, which is already proposed in a previous work. It further points out that the incremental contribution lies in the decomposition part, which involves factoring M_v into factor D and slicing Phi_v. While the comment highlights a potential weakness in the paper\\'s novelty, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it alerts the authors to a potential problem, but it lacks actionable advice or detailed insights that could help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. While the comment identifies a potential gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify the domain of the inputs, but it is vague because it lacks specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the inputs are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or addressed regarding the domain of the inputs. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper\\'s validity. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper regarding the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned. This is a relevant point that could impact the validity and generalizability of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the domain of the inputs. While it points out a potential weakness, it does not provide actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare the performance of their proposed CLN (region proposal generation algorithm) with that of another work. While the comment implies that the authors should conduct a performance comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the details of the comparison themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not specify which part of the paper discusses the CLN or where the performance comparison should be included. The authors cannot confidently determine which section or part of the paper is being addressed, making this comment not grounded. Additionally, the comment lacks specificity regarding what aspects of the performance comparison should be considered or how it should be conducted. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct the comparison or what aspects to focus on. The comment is somewhat helpful as it points out a potential area for enhancement, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3: Somewhat Helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the presentation is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It also recommends the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment provides a clear action\u2014adding an illustrative figure\u2014it does not specify which concepts should be illustrated or how the figure should be designed. The authors are given a clear direction to add an illustrative figure but are left to determine the specifics of implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the presentation, specifically mentioning that it is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It also suggests the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the presentation and notation in chapter 3. The suggestion for an illustrative figure provides some specificity, making the comment weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the presentation is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. While the comment identifies specific issues with the presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for an illustrative figure is a logical point, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation, noting that it is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation by adding an illustrative figure. However, the comment could be more helpful if it offered specific guidance on what elements should be illustrated or how the figure should be designed to enhance clarity. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\u00e2\u0080\u0099 and the independence of x and y given W. The reviewer suggests that taking Z\u00e2\u0080\u0099 to be the empty set would lead to a contradiction with Eq. (7), which states that x and y are dependent given W. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to resolve the conflict. The authors are left to infer that they need to reconsider the definition of Z\u00e2\u0080\u0099 and possibly revise the statement regarding independence. While the comment identifies a potential issue, it lacks concrete instructions on how to resolve it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, particularly regarding the definition of Z\\u0027 and the independence of x and y given W. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\\u0027 and the independence of x and y given W. The reviewer provides a logical explanation by taking Z\\u0027 to be the empty set, which would lead to a contradiction with Eq. (7). However, the comment lacks specific references or examples to support the claim, making it somewhat verifiable. The authors would need to further explore the issue to fully understand and address the conflict. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\\u0027 and the independence of x and y given W. By taking Z\\u0027 to be the empty set, the reviewer demonstrates a logical contradiction that could be addressed. However, the comment does not provide specific suggestions or guidance on how the authors might resolve this issue or improve the clarity of the definitions. While it points out a potential problem, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out that the visual presentation, specifically the subscripts, could be improved for better readability and aesthetic appeal. While the comment identifies an area for enhancement, it does not provide explicit guidance on how to achieve this improvement. The authors are left to infer that they should make changes to the subscripts, but without specific suggestions or examples, the action remains vague. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the visual presentation of the subscripts, for better readability and aesthetic appeal. This provides clear guidance on how to improve the figure. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the visual presentation of the subscripts in Figure 3 could be enhanced for better readability and aesthetic appeal. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks the necessary evidence or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out a specific area for improvement. It identifies the visual presentation, specifically the subscripts, as needing enhancement for better readability and aesthetic appeal. While the comment provides a clear direction for improvement, it lacks detailed guidance or suggestions on how to achieve this enhancement. The authors are left to infer that they should make changes to the subscripts, but without specific guidance, the feedback is somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this confusion or what specific aspects of the comparison should be clarified. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the problem of gradient bias in Batch Normalization and the potential of Online Normalization. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the difference between Online Normalization and Batch Normalization, asking why Online Normalization is unbiased while Batch Normalization is biased. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that Online Normalization is unbiased and Batch Normalization is biased, suggesting that the authors have not adequately explained this difference. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. This is a relevant point that could help the authors clarify their explanation of these concepts. However, the comment does not provide any actionable feedback or suggestions for improvement, such as recommending specific sections of the paper that need clarification or offering alternative explanations. Without such guidance, the authors may find it challenging to address the issue effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors have reduced whitespace throughout the paper, resulting in cramped equations and captions too close to the figures. This is seen as a violation of the 9-page paper limit. The comment provides a clear and direct action for the authors to take, which is to address the issue of whitespace by adjusting the layout of equations and captions. However, it does not provide specific guidance on how to achieve this, such as suggesting a particular layout or font size. While the action is explicit, the lack of concrete details on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of whitespace throughout the paper, specifically mentioning that equations are crammed together and captions are too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9-page paper limit due to the reduced whitespace. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper violates the 9-page limit due to the reduced whitespace, specifically mentioning cramped equations and captions too close to the figures. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to the paper\\'s layout or content, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the layout of the paper, noting that equations are crammed together and captions are too close to the figures, which violates the 9-page paper limit. This is a clear and actionable observation that the authors can address to improve the readability and adherence to the formatting guidelines. However, the comment could be more helpful if it provided suggestions on how to improve the spacing or layout to address the issue. Overall, the comment is mostly helpful as it highlights a significant problem and offers a direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical details or formulations, nor are there suggestions for how to better highlight the novelty of the scheme or procedure. As a result, the authors are left without any clear direction on how to enhance their draft based on this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the technical details or formulations are lacking or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide any specific guidance or suggestions on how the authors might improve the technical details or formulations to better highlight the novelty of their work. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential issue but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the concept of local interactions, asking whether it refers to interactions within a time window or within the same modality. While the comment identifies an area of confusion, it does not provide explicit guidance on how the authors should clarify this concept in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer definition or explanation of the concept. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the concept of local interactions, specifically questioning whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it weakly grounded. The comment is specific in its questioning of the concept, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the concept of local interactions, specifically asking whether it refers to interactions within a time window or within the same modality. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the confusion. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the clarity of the concept of local interactions, specifically questioning whether it refers to interactions within a time window or within the same modality. This feedback is somewhat helpful as it identifies a potential area of confusion in the paper that could be clarified for readers. However, the comment lacks specific guidance or suggestions on how the authors might clarify this concept, such as providing examples or additional context. While it points out a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims better results in the Molecule generation experiment but notes that adding the proposed constrained method actually yields lower validity and diversity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the addition of the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the addition of the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment, as stated in Table.3. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claims regarding the Molecule generation experiment, specifically noting that the addition of the proposed constrained method actually yields lower validity and diversity. This is a critical observation that could impact the paper\\'s conclusions and credibility. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their results. While it points out a potential problem, it does not provide actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about how the archetype positions are updated after initialisation in Algorithm 2. It explicitly asks the authors to clarify this aspect, providing a clear action for the authors to take. The comment is explicit in its request for clarification, making it highly actionable. The authors know exactly what needs to be addressed and how to implement the action, as they are prompted to provide a comment on this aspect. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"the query Q consists of the archetypes z_1, \u00e2\u0080\u00a6, z_k,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the update of archetype positions after initialisation. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the clarity of the update process for the archetype positions in Algorithm 2. It does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the update process for the archetype positions in Algorithm 2. It asks the authors to clarify this aspect, which is important for understanding the methodology. This feedback is clear and actionable, as it prompts the authors to provide additional explanation or clarification in their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the resting-state was recorded (eyes-open or eyes-closed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These are all clear and concrete actions that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the \"empirical study\" and \"supplement,\" allowing the authors to accurately identify the sections being addressed. It also specifies what is missing, such as recording parameters for the MRI, preprocessing steps, and the condition under which the resting-state was recorded (eyes-open or eyes-closed). Additionally, it suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims about the missing information in the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the resting-state was recorded (eyes-open or eyes-closed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These claims are somewhat verifiable as they are based on logical reasoning and common knowledge about empirical studies. However, the comment could be strengthened by providing specific references or examples to support the claims or by offering more detailed explanations of the missing information. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the resting-state was recorded (eyes-open or eyes-closed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the transparency and completeness of their empirical study. By addressing these points, the authors can significantly improve the clarity and robustness of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential risk of methods that exploit relationships between action units, specifically noting that the relationships can differ across datasets. It suggests that the paper lacks cross-dataset experiments, which would be a good way to test the generalization of the work. While the comment implies that the authors should conduct cross-dataset experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the need for cross-dataset experiments and determine how to implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of cross-dataset experiments, which is a critical aspect of testing the generalization of the work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that methods that exploit relationships between action units can suffer from differences in co-occurrences across datasets, as seen in Figure 1. The reviewer suggests that cross-dataset experiments are necessary to test the generalization of such work. While the comment provides a logical reasoning for the need to test generalization, it lacks specific examples or references to datasets or studies that demonstrate these differences. This makes the claim somewhat verifiable, as the authors would need to infer the significance of the issue and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant risk associated with methods that exploit relationships between action units, noting that these relationships can differ across datasets. It highlights a specific example of this issue by pointing out the co-occurrence of AU1 and AU12 in Figure 1, which illustrates the difference in correlation across datasets. The comment suggests that cross-dataset experiments are necessary to test the generalization of the work. While it provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to conduct cross-dataset experiments or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so or provide specific guidance on what details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more information about the environment. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this information should be included in, nor does it provide details on what aspects of the environment should be described. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need attention or improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not provide any reasoning, examples, or references to support why this additional information is necessary or how it would enhance the paper. Without such justification, the claim is unverifiable, as it lacks the necessary evidence or explanation to guide the authors in improving their draft. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what aspects of the environment should be described or how this additional information would enhance the paper. The feedback is somewhat helpful as it points out a potential gap in the paper, but it does not offer actionable steps for the authors to address this issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should reconsider their statement about over-parameterization, which is currently presented as a negative aspect. The reviewer provides a counterargument that over-parameterization can be beneficial for supervised learning of deep neural networks, citing theoretical work that supports this claim. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their stance on over-parameterization. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 47 - 48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the authors\\' claim about over-parameterization and provides a counterargument by suggesting that over-parameterization can be beneficial for supervised learning of deep neural networks. The comment also references a specific theoretical work, which adds further context and specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the authors\\' claim about over-parameterization, suggesting that it can be beneficial for supervised learning of deep neural networks. The reviewer provides a counterargument by referencing theoretical work that supports the benefits of over-parameterization, such as [1]. This reference provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or specific references to the theoretical work, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment challenges the authors\\' claim about over-parameterization, suggesting that it can be beneficial for supervised learning of deep neural networks. The reviewer provides a counterargument by referencing theoretical work that supports the benefits of over-parameterization, such as [1]. This feedback is valuable as it encourages the authors to reconsider their stance on over-parameterization and potentially reframe their argument or provide additional context to support their position. However, the comment could be more helpful if it offered specific suggestions on how the authors might address this issue or what additional evidence or arguments could be included to strengthen their case. Overall, the comment is somewhat helpful as it prompts the authors to reconsider their position but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues: the time-consuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific aspects of the training and testing process should be described. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed description and comparison with existing work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the time-consuming nature of training the shape model and the complexity of the parsing model, suggesting that the processing efficiency of training and testing should be described and compared with existing work. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the training and testing process, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the shape model is time-consuming due to its training in pixel level (though sparsity by landmark) and the model being trained independently on all font images and characters. Additionally, it suggests that the parsing model is a high-order factor graph with four types of factors, which affects processing efficiency. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. However, the comment lacks specific examples or references to existing work that could substantiate the claim about processing efficiency. While the reasoning is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the time-consuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment highlights important areas for improvement, it lacks specific guidance on how to address these issues or what aspects of the training and testing process should be described and compared. The feedback is somewhat helpful as it points out areas that need attention, but it could be more actionable with additional details or suggestions on how to improve the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. While the comment implies that the authors should explore other domain adaptation methods, it does not provide specific guidance on which methods to use or how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore other domain adaptation methods to enhance their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. However, the comment does not specify which parts of the paper these critiques pertain to, such as sections, figures, or specific techniques. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the use of old and simple methods, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors combine two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. The reviewer suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. The claim is somewhat verifiable as it provides a specific example of an older method being used and suggests a potential improvement. However, it lacks detailed evidence or references to support the claim that more recent methods are indeed more effective. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on which domain adaptation methods to consider or how to implement them. The feedback is somewhat helpful as it points out an area for improvement but does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that a discussion on the prompt dataset creation for the few-shot case, along with its source, should be included in the paper. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and guidance on what to discuss. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that a discussion on the prompt dataset creation for the few-shot case, along with its source, should be included in the paper. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. This makes the comment weakly grounded, as the authors cannot confidently determine the exact location of the discussion. The comment is specific in suggesting what needs to be addressed, providing clear guidance on what the authors should include in their paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the prompt dataset creation for the few-shot case, along with its source, should be included in the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a discussion on the prompt dataset creation for the few-shot case, along with its source, should be included in the paper. This feedback is somewhat helpful as it identifies a specific area for improvement, which is the inclusion of a discussion on the dataset creation process. However, the comment lacks depth and does not provide detailed guidance on how to conduct this discussion or what specific aspects should be covered. While it points out a gap in the paper, it does not offer actionable steps or examples to help the authors effectively address the issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the clarity of the motivation or how to differentiate the paper from incremental engineering papers. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not specify which part of the paper is problematic or where the motivation is unclear. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation or the paper are unclear or how they could be clarified. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or originality of their work. Without actionable feedback or detailed insights into what aspects of the paper are unclear or lacking, the authors are left without a clear path for improvement. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests an ablation on the weighting method of the cross-entropy loss, specifically mentioning that it would be beneficial to see how it affects the performance of the method in a scenario where the game has repetitive background sounds. The reviewer provides a clear rationale for why this ablation is important, noting that the weighting might have helped remedy the underperformance in such scenarios. However, the comment does not explicitly instruct the authors to conduct this ablation or provide detailed guidance on how to implement it. While the action is implied, the lack of concrete steps makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an ablation on the weighting method of the cross-entropy loss, specifically mentioning the scenario where the game has repetitive background sounds. This provides a clear reference to the section where the authors discuss the performance of their method in Atlantis. However, the comment does not specify which part of the paper should include this ablation, making it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, namely the weighting method of the cross-entropy loss in the context of repetitive background sounds. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an ablation on the weighting method of the cross-entropy loss, specifically mentioning that it would be beneficial to see how it affects performance in a scenario where the game has repetitive background sounds. The reviewer provides a rationale for why this ablation might be important, noting that the weighting might have helped remedy the underperformance in such scenarios. However, the comment lacks specific examples or references to support the claim that the weighting method could improve performance in these conditions. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an ablation on the weighting method of the cross-entropy loss, specifically mentioning a scenario where the game has repetitive background sounds. This is a valuable suggestion as it could help the authors understand the impact of their method on different scenarios. The comment is clear and actionable, providing a specific direction for the authors to explore and potentially improve their draft. However, it could be more helpful if it included suggestions on how to conduct the ablation or what specific aspects to focus on. Overall, the comment is mostly helpful as it identifies a potential area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for Text-to-SQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to demonstrate novelty and incremental improvements, but the comment lacks concrete suggestions on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific issue of the lack of novelty and incremental nature of the work, as well as the problem of column operations in designing semantic parsers for Text-to-SQL. It also mentions the design of a new dataset, which is a different train/test split of an existing dataset, SQUALL. Additionally, it points out a synthetic benchmark paper based on a single question template. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be improved, such as demonstrating novelty and incremental improvements, and providing suggestions for addressing the issue of column operations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is incremental in nature, specifically addressing a problem of column operations in designing semantic parsers for Text-to-SQL. The reviewer provides some justification by mentioning that the proposed dataset is a different train/test split of an existing dataset, SQUALL, and that the synthetic benchmark paper is based on a single question template. However, the comment could be strengthened by providing more detailed examples or references to support the claim of lack of novelty. As it stands, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for Text-to-SQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template, which further highlights the lack of novelty. This feedback is clear and actionable, as it directs the authors to address the issue of novelty and incremental nature in their work. However, the comment could be more helpful if it provided suggestions on how to demonstrate novelty or incremental improvements, such as by suggesting alternative approaches or datasets. Overall, the comment is mostly helpful as it effectively identifies a critical weakness and offers direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experiments are limited to one game environment and suggests that more experiments are necessary. This provides a clear and direct action for the authors to take, which is to expand their experimental scope to include additional game environments. The comment is specific in its request for additional experiments, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to conduct more experiments, but without clear references to specific sections or experiments, the authors may struggle to identify where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation is problematic or how it affects the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, noting that they are conducted on only one game environment. It suggests that more experiments are necessary to provide a broader understanding of the results. This feedback is clear and actionable, as it directs the authors to expand their experimental scope to include additional game environments. However, the comment could be more helpful if it provided specific suggestions on which environments to include or how to structure these additional experiments. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This is a clear and direct action for the authors to take, as it specifies the need for a detailed explanation with examples. The comment provides a concrete direction for improvement, ensuring that the authors know exactly what needs to be done to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a detailed explanation with examples. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are important or how removing them would contribute to the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors need to provide more detail and explanation. It points out that the removal of certain assumptions like bounded variance and bounded gradients is an important contribution, but it does not provide examples or further explanation of why these assumptions are important. This feedback is somewhat helpful as it highlights a gap in the paper that the authors need to address, but it lacks depth and specificity. The comment could be more helpful if it offered suggestions on how to present the examples or examples themselves, which would guide the authors in making the necessary improvements. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the authors\\' claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific information about the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet-18, as well as the accuracy, which is around 70%. This explicit comparison and concrete data provide the authors with a clear action to take: they need to address the issue of slow speed and low accuracy by improving their implementation. The comment is explicit and provides concrete details on how to apply the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim of implementing ImageNet for the first time, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed information about the slow speed and low accuracy, including specific times and accuracies for testing with AlexNet and ResNet-18. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' implementation of ImageNet is slow and has low accuracy, citing specific times and accuracies for testing with AlexNet and ResNet-18. This claim is supported by the provided data, which allows the authors to verify the accuracy of the claim. However, the comment could be strengthened by providing additional context or references to similar studies that have experienced similar issues, which would further substantiate the claim. Overall, the claim is mostly verifiable, as it is supported by specific data but could be improved with additional context or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the authors\\' claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific information about the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet-18, as well as the accuracy, which is around 70%. This feedback is clear and actionable, as it points out a specific issue that the authors need to address to improve the credibility of their work. By addressing this concern, the authors can enhance the transparency and reliability of their claims. However, the comment could be more helpful if it suggested ways to improve the speed or accuracy, such as providing suggestions for optimization or additional experiments. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests adding a few more sentences to explain the experimental setting for continual learning, and it explicitly requests an explanation of the correspondence between the learning curves and M-PHATE in Figure 3. The reviewer also asks specific questions about the learning curves, such as why the worse-performing model results in structural collapse and what the accuracy number represents. These questions provide clear guidance on what the authors need to address to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including explaining the experimental setting for continual learning, the correspondence between the learning curves and M-PHATE, and the accuracy number for the last task. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors add a few more sentences to explain the experimental setting for continual learning. It also requests an explanation of the correspondence between the learning curves and M-PHATE in Figure 3, asking why the worse-performing model results in structural collapse and what the accuracy number represents. These questions are clear and provide the authors with a concrete direction for improving their draft. By addressing these points, the authors can enhance the clarity and comprehensiveness of their experimental setup and results. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer any explicit guidance or actionable steps for the authors to take. The comment lacks specific instructions or suggestions on how to incorporate this idea into their work. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that labeled data might provide effective information for consistency training, but it lacks detailed guidance on how to implement this suggestion or what specific aspects of the paper should be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. The reviewer supports this suggestion by referencing two external works, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which provide examples of how labeled data can be used for consistency training. However, the comment lacks detailed reasoning or specific examples from the authors\\' work to fully substantiate the claim. While the references provide some support, the comment could be strengthened by explaining why labeled data might be beneficial or how it could be integrated into the authors\\' approach. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks full justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer specific guidance or actionable steps for the authors to explore this idea further. The references to external works, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" provide some context and support the suggestion, but the comment could be more helpful by offering detailed suggestions on how to incorporate labeled data into the existing work. Overall, the comment provides some insight but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experimental part needs to be reorganized and improved, and it provides specific suggestions for how to do so. It suggests that the experimental content listed in the main text should highlight the superiority of the method, and it provides a list of experimental suggestions that should be included in the main text. These suggestions are concrete and provide clear guidance on what changes the authors should make to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental part\" and the \"experimental section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the reorganization and highlighting of the experimental content to showcase the superiority of the method. The suggestions for improvement are detailed and provide a clear direction for the authors to follow. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental part needs to be reorganized and improved, suggesting that the experimental content listed in the main text does not effectively highlight the superiority of the method. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to specific sections of the paper where the issue is apparent, making it difficult for the authors to understand and address the critique. As a result, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary detail to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental part of the paper, noting that the experimental content listed in the main text does not effectively highlight the superiority of the method. It provides a clear and actionable suggestion to reorganize the experimental section and offers specific guidance on what should be included, such as experimental suggestions in the main text. This feedback is valuable as it directs the authors to improve the clarity and effectiveness of their experimental section, which is crucial for the paper\\'s credibility and impact. However, the comment could be more helpful if it provided examples of how the experimental content should be reorganized or if it explained why the current structure is ineffective. Overall, the comment is mostly helpful as it offers a clear path for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the classification error of the proposed network and suggests reporting the classification accuracy on ImageNet data. It also requests theoretical justifications, if possible. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should report the classification accuracy and provide theoretical justifications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed classification network, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the classification error of the proposed network and suggests reporting the accuracy on ImageNet data. Additionally, it requests theoretical justifications, which provides clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the classification error of the proposed network and questions whether it is as good as the standard softmax network. The reviewer suggests reporting the classification accuracy on ImageNet data and provides a theoretical justification for the issue. However, the comment lacks specific examples or references to support the claim about the classification error or the need for theoretical justifications. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the classification error of the proposed network and questions whether it is as good as the standard softmax network. It suggests reporting the classification accuracy on ImageNet data and provides a theoretical justification for the issue. This feedback is actionable as it prompts the authors to address the classification accuracy and potentially provide theoretical justifications. However, the comment could be more helpful if it offered specific suggestions on how to improve the classification accuracy or provided examples of theoretical justifications. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what specific changes could be made to improve the argument or simulations. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific argument related to the practicality of the recognition process, particularly in the context of old vs. new judgments. However, it does not specify which part of the paper this argument is discussed in, making it weakly grounded. The comment is specific in its critique of the argument, questioning the feasibility of implementing an exhaustive list for concrete predictions through simulations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. The reviewer points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. This claim is somewhat verifiable as it provides a logical reasoning for the difficulty in implementing the argument, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. While the comment identifies a potential weakness in the argument, it lacks specific suggestions or guidance on how the authors might address this issue or improve their simulations. The feedback is somewhat helpful as it highlights a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pre-trained model as the compared methods. It points out that if not, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the initialization process and possibly re-run experiments with different initialization methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness of the comparison due to the initialization of the proposed method before the fine-tuning stage. The comment suggests that if the compared methods were not initialized with the same or similar pre-trained model, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pre-trained model as the compared methods. The reviewer supports this claim by referencing Table 1, which shows the inferior performance of the proposed method without SSL compared to most of the compared methods. This provides a logical basis for the claim, as it highlights a potential issue in the experimental setup that could affect the results. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have addressed this issue. Overall, the claim is mostly verifiable, as it is supported by a reference to Table 1 and logical reasoning, but it could be further substantiated with additional evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the initialization of the proposed method before the fine-tuning stage. It points out that if the compared methods were not initialized with the same or similar pre-trained model, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. This feedback is valuable as it highlights a potential source of bias in the experimental setup and suggests a way to address it by clarifying the initialization process. However, the comment could be more helpful if it provided specific guidance on how to clarify the initialization or suggested alternative methods for initialization. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using better meta-data embeddings for their zero-shot learning results on the CUB dataset, specifically referring to Table 3 on page 7. It also provides a specific example of a related work that used better meta-data embeddings, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016.\" The comment is explicit in its suggestion to use better meta-data embeddings and provides a specific reference to a related work. However, it does not provide detailed guidance on how to implement this suggestion or what specific steps to take. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of better meta-data embeddings for the zero-shot learning results on the CUB dataset. The comment provides a specific example of a related work that used better meta-data embeddings, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the authors should consider this approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider using better meta-data embeddings for their zero-shot learning results on the CUB dataset, specifically referring to Table 3 on page 7. The reviewer provides a specific example of a related work that used better meta-data embeddings, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016.\" This reference provides a clear rationale for the suggestion, as it demonstrates that better meta-data embeddings can lead to improved performance. However, the comment could be strengthened by providing more detailed analysis or specific examples of how the proposed method could benefit from these embeddings. Overall, the claim is mostly verifiable, as it is supported by a specific example and logical reasoning, but it could be further substantiated with additional evidence or detailed explanation.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by recommending the use of better meta-data embeddings for the zero-shot learning results on the CUB dataset. It references a specific example from a related work, Table 1 in \"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\" which demonstrates the potential for better performance using better meta-data embeddings. This feedback is clear and actionable, as it guides the authors on how to enhance their results and potentially improve their paper\\'s impact. However, the comment could be more helpful if it provided additional context or detailed guidance on how to implement this suggestion. Overall, the comment is mostly helpful as it offers a concrete direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors include a plot with sparsity on the x-axis and performance on the y-axis to compare the flexibility of SGC with LoRA. This explicit suggestion provides a clear and concrete action for the authors to take, as it specifies the exact type of visualization needed to demonstrate the practical benefits of SGC. The comment is specific in detailing what needs to be added to the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the limited applicability of SGC and the need for a plot to compare its flexibility with LoRA. It specifies the issue by suggesting a visualization with sparsity on the x-axis and performance on the y-axis. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that SGC offers a more flexible, fine-grained tradeoff but is limited in practicality due to the need for extra tuning. The reviewer suggests including a plot to compare the flexibility of SGC with LoRA, which could more intuitively demonstrate the practical benefits of SGC at different sparsity levels. This claim is somewhat verifiable as it provides a logical reasoning for the need for a visualization but lacks specific examples or references to support the claim fully. The suggestion is a clear direction for improvement, but the lack of detailed evidence or examples makes it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s claim about the flexibility and performance of SGC, specifically in the context of compute-constrained scenarios. It suggests including a plot to demonstrate the flexibility of SGC compared to LoRA, which could help illustrate the practical benefits of SGC at different sparsity levels. This feedback is clear and actionable, providing a specific suggestion for improving the paper by adding a visualization that could enhance the authors\\' argument. However, the comment could be more helpful if it explained why this visualization is necessary or how it would contribute to the paper\\'s overall contribution. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, and suggests that the code should be published if the main advantage is its computation time. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for the shorter training time or consider publishing the code. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments\" and \"German and Law school dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reason for the shorter training time in Gerrymandering compared to Independent, and suggests that the code should be published if the main advantage is its computation time. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might be unreasonable. It also mentions that the code should be published if the main advantage is its computation time. However, the comment lacks specific evidence or references to support the claim that the shorter training time is unreasonable or that the code should be published. The reasoning is based on logical reasoning and assumptions, but without detailed justification or examples, it is difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might be unreasonable. It also mentions that the code should be published if the main advantage is its computation time. While the comment identifies a potential issue with the experimental setup, it lacks specific guidance or suggestions on how to address this concern or improve the paper. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarifies the additional information that CD captures on top of Predictive Uncertainty. It also questions why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples\" (line 115). The reviewer does not provide specific guidance on how to implement these suggestions, leaving the authors to infer the actions needed. The feedback is explicit in identifying the need for clarification and alternate formulations, but it lacks concrete details on how to achieve these improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 113\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the additional information captured by Confidence Diversity (CD) and why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the additional information captured by Confidence Diversity (CD) and why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" However, the comment lacks specific examples or references to support these claims. It does not provide detailed reasoning or evidence to substantiate the critique, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It also questions the additional information captured by CD on top of Predictive Uncertainty and why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" This feedback is clear and actionable, as it provides the authors with a concrete direction for enhancing their draft by clarifying the concept of CD and its relationship to other measures. However, the comment could be more helpful if it offered specific examples or references to support the claims about entropy and CD. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and depth of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. It also points out that the abstract statement about beating a human who learned Kalamang is misleading due to the limited human data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the human baseline. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue of the human baseline being weaker, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the human baseline, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the human baseline only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. Additionally, it highlights the misleading statement in the abstract about beating a human who learned Kalamang from the same resources. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the human baseline is considerably weaker than the model baseline due to the limited amount of speech recordings followed by the human. The reviewer supports this claim by pointing out that the human baseline only closely follows a little more than 1 hour of speech recordings, which is a significant limitation compared to the model baseline. Additionally, the reviewer critiques the abstract statement about beating a human who learned Kalamang, noting that it is misleading due to the limited human data. This provides a logical and somewhat verifiable basis for the claim, as it highlights a specific issue with the human baseline and the abstract statement. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. This is a critical observation that could impact the validity and applicability of the human baseline. Additionally, the comment points out that the abstract statement about beating a human who learned Kalamang is misleading due to the limited human data. This feedback is valuable as it highlights a potential weakness in the study that the authors should address to strengthen their work. However, the comment could be more helpful if it provided suggestions on how to improve the human baseline or how to address the misleading statement in the abstract. Overall, the comment is somewhat helpful as it identifies a critical issue and offers some guidance, but it could be more comprehensive with additional suggestions for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the assumption for termination states of instructions is quite strong, particularly when it comes to labeling a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the assumption for termination states of instructions, particularly the issue of labeling a large number of data manually. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the problem of manual labeling and the associated expense, but it lacks detailed guidance on how to address this issue or what specific changes could be made. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption for termination states of instructions is \"quite strong,\" particularly when it comes to labeling a large number of data manually. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the assumption for termination states of instructions, particularly when it comes to labeling a large number of data manually. This is a relevant point that could impact the feasibility and cost-effectiveness of the proposed method. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue or mitigate its impact. Without detailed feedback or constructive advice, the authors are left without a clear path forward, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the paper regarding the nature of the contribution with respect to ECE_sweep. It explicitly states that the contribution is not clearly described and suggests that the authors should be upfront about it. The reviewer provides a concrete example of what is missing, which is the autotuning of a hyperparameter in the estimate. This feedback is specific and provides a clear direction for the authors to improve their draft by clarifying the contribution. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ECE_sweep\" and the issue with the contribution being unclearly described. It specifies the problem by pointing out that the contribution is not clearly described, particularly regarding the autotuning of a hyperparameter in the estimate. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the contribution with respect to ECE_sweep is not clearly described in the text. It provides a specific example of the issue, which is the autotuning of a hyperparameter in the estimate, and suggests that this is not fundamentally different from the contribution. The reviewer acknowledges confusion and provides a clear explanation of the issue, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim that this is not a fundamentally different contribution. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the contribution regarding ECE_sweep. It points out that the contribution is not clearly described, particularly regarding the autotuning of a hyperparameter in the estimate. The reviewer acknowledges that this led to confusion and suggests that the paper should be more upfront about the contribution. This feedback is clear and actionable, as it provides a concrete example of what needs to be clarified and improved in the paper. By addressing this issue, the authors can enhance the clarity and understanding of their contribution, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, it does not provide explicit guidance on which methods should be used as a baseline or how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors can infer that they need to consider using these methods as a baseline but are not given specific instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This provides clear guidance on what needs to be addressed in the paper, namely the inclusion of these methods as baselines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the related work section, noting that it discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s analysis, which could be addressed by including these methods as baselines. However, the comment lacks depth and does not provide specific suggestions on how to incorporate these methods or why they are important. Additionally, it does not address other aspects of the paper, such as its originality or contributions. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully guide the authors on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a confusion regarding whether the authors are referring to a particular efficient proxy or a family of efficient proxies. It suggests that the term \"Efficient Proxy\" might be a misnomer, as there is no specific proxy called \"Efficient Proxy.\" However, the comment does not provide explicit guidance on how the authors should clarify this confusion or what specific changes should be made to the text. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terminology and possibly revise the text to avoid confusion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"Efficient Proxy,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology, suggesting that the authors might be referring to a family of efficient proxies rather than a single proxy. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of whether the authors are referring to a particular efficient proxy or a family of efficient proxies. It suggests that the term \"Efficient Proxy\" might be misleading, as there is no specific proxy called \"Efficient Proxy.\" The comment provides a logical reasoning based on the context of the term \"is,\" which could be interpreted as referring to a particular proxy, but the lack of a specific proxy named \"Efficient Proxy\" suggests it might be a family of proxies. This reasoning is somewhat verifiable, as it provides a plausible explanation but lacks specific references or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper regarding the term \"Efficient Proxy.\" It points out that the use of \"is\" might suggest a particular proxy, but the lack of a specific proxy called \"Efficient Proxy\" suggests that it might refer to a family of efficient proxies. This feedback is somewhat helpful as it highlights a potential issue with the clarity of the terminology used in the paper. However, it does not provide specific suggestions on how the authors might clarify this confusion or improve the terminology. To be more helpful, the comment could offer guidance on how to address this issue or suggest alternative terminology that would be clearer. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors stack multiple methods, including those from Mirzasoleiman et al., 2020 and a group-learning setting, and then use a classical method, DBSCAN, for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what changes should be made to improve the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the use of multiple methods, including those from Mirzasoleiman et al., 2020 and a group-learning setting, and then using a classical method, DBSCAN, for clustering. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the stacking of methods and the use of DBSCAN, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors stack multiple methods, including those from Mirzasoleiman et al., 2020 and a group-learning setting, and then use a classical method, DBSCAN, for clustering. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is problematic or how it affects the paper\\'s outcomes. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to substantiate the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the paper\\'s methodology, specifically the stacking of multiple methods, including those from Mirzasoleiman et al., 2020 and a group-learning setting, and then using a classical method, DBSCAN, for clustering. While the comment identifies a potential problem, it lacks specific guidance or suggestions on how the authors might address this issue or improve their methodology. The feedback could be more helpful if it provided suggestions on how to integrate the different methods or how to justify the use of DBSCAN in the context of the paper. As it stands, the comment is somewhat helpful, as it alerts the authors to a potential weakness but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. It also mentions that the authors might have missed this in the appendix. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the resilience of the metric to the choice of random projection. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the chosen random projection matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. The comment also mentions that the authors might have missed this in the appendix, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the variability in results with the chosen random projection matrix, suggesting that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this might be unlikely with random projections but suggests investigating the resilience of the metric to the choice of random projection. The comment is somewhat verifiable as it provides a logical reasoning for the need to test the resilience of the metric, but it lacks specific examples or references to support the claim about pathological projection matrices. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results obtained using the chosen random projection matrix, suggesting that pathological projection matrices could skew the MFTMA capacity and width scores. It also points out that the authors might have missed this in the appendix. While the comment raises an important question about the robustness of the metric, it lacks specific guidance or suggestions on how to address this issue. The authors are left to infer that they should investigate the resilience of the metric to the choice of random projection, which could be more explicit. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the synthetic data used in the paper, specifically asking for examples of what \"support data\" and \"predicted training count data\" might look like. It also requests that the model used be explicitly described, potentially by adding it to the appendix. While the comment implies that the authors should provide more detailed information about the synthetic data and the model, it does not explicitly instruct them to do so. The actions are somewhat clear but require some effort to implement, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"support data\" and \"predicted training count data\" in Figure 1, as well as requests that the model used be explicitly described. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about specific terms used in the paper, such as \"support data\" and \"predicted training count data,\" and requests additional information about the model used. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the clarity and specificity of the synthetic data used in the paper. It specifically asks for examples of what \"support data\" and \"predicted training count data\" might look like, as well as requests that the model used be explicitly described. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and transparency of the paper. By addressing these questions, the authors can enhance the understanding and reproducibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just being limited to the ablation study. This implies that the authors should expand their evaluation to include a broader assessment of the method's performance. However, the comment does not provide specific guidance on how to implement this change or what additional evaluation should be included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just being limited to the ablation study. However, it does not specify which part of the paper this evaluation is currently limited to, nor does it provide guidance on how to expand the evaluation. The authors can infer that it relates to the evaluation section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a change. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of FGT is limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of FGT, noting that it is currently limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for expanding the evaluation to include a broader assessment of the method's performance. However, the comment could be more helpful if it offered additional guidance on how to implement this change or what specific aspects of the method should be evaluated. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to enhance the model's complexity or complexity analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as the model description, results, or analysis. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the model\\'s simplicity are problematic or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the model seems overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the model\\'s complexity. Without actionable feedback or detailed analysis, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as barely helpful, as it identifies a potential weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the scope of the work or how to demonstrate its broader impact. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the narrow focus, but it lacks grounding as it does not identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and how it affects the paper\\'s impact. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a limitation of the work, specifically its narrow focus on a specific task (climate change QA) in a specific language (Arabic), which could limit its broader impact. While it identifies a potential issue, it does not provide any actionable suggestions or guidance on how the authors might address this limitation or expand the scope of their work. The comment lacks depth and specificity, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as barely helpful, as it highlights a potential weakness but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not contribute novelly to the understanding of the winner-take-all property, as it uses extremely simplified settings and reports findings that have been previously reported in other works. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the originality or how to present the findings in a more novel or innovative way. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"winner-take-all property\" and \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not contribute novelly to the understanding of this behavior due to the use of extremely simplified settings and the repetition of findings from previous works. This provides clear guidance on what needs to be addressed to improve the originality of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not contribute novelly to the understanding of the winner-take-all property due to the use of extremely simplified settings and the repetition of findings from previous works. However, the comment lacks specific references to these previous works or detailed examples of how the findings have been reported elsewhere. Without such references or detailed justification, the claim is difficult for the authors to verify or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it does not contribute novelly to the understanding of the winner-take-all property due to the use of extremely simplified settings and the repetition of findings from previous works. This is a critical observation that could impact the paper\\'s originality and impact. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from previous studies. While it points out a potential weakness, it does not provide actionable feedback to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some run-times in the experiments to help readers understand the method's practicality. While the comment explicitly states these actions, it does not provide detailed guidance on how to present the information or what specific examples to include. The authors are given a clear direction but may need to infer the exact implementation of these suggestions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests mentioning the negligible computational cost of CHR in the main paper and providing a rough example of run-times in the experiments. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the computational cost discussion or the experimental results, but this inference is not direct. The comment is specific in suggesting the inclusion of computational cost information and examples, but it lacks grounding as it does not pinpoint the exact section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests mentioning the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some run-times in the experiments to help readers understand the method's practicality. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of including these details, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It recommends mentioning the negligible computational cost of CHR in the main paper, which could help motivate the method. Additionally, it suggests providing a rough example of some run-times in the experiments to help readers understand the method's practicality. This feedback is specific and offers concrete steps for the authors to enhance the clarity and applicability of their work. By addressing these points, the authors can improve the comprehensiveness and accessibility of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends that the authors elucidate the EEG token quantization process in greater detail, specifically addressing the ambiguity in interpretation. It suggests that the authors should clarify whether the spatial arrangement of the EEG sensors played a role in this process. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the ambiguity in the interpretation of the EEG topography plots and the need to clarify the role of the spatial arrangement of the EEG sensors in the EEG token quantization process. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 presents ambiguity in interpretation due to the EEG topography plots for both the input and output during the EEG token quantization process. The reviewer suggests that the authors should elucidate this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role. While the comment identifies a potential issue with interpretation, it lacks specific examples or references to support the claim that the spatial arrangement of the sensors is relevant. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It suggests that the authors should elucidate this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role in the process. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and understanding of the figure. By addressing this issue, the authors can enhance the comprehensibility of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what specific changes should be made to the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, it does not specify which part of the paper discusses these distances or where the distinction is made. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the distinction are unclear or unnecessary. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is unnecessary. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. While it identifies a potential redundancy in the paper, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to enhance their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors leverage the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes could be made to improve the directness of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' approach to addressing the problem, specifically mentioning the use of the Witness oracle and its complexity. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspect of the complexity issue is problematic or how it could be addressed. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors do not address the problem directly by leveraging the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the authors\\' approach, specifically the use of the Witness oracle and its complexity. It suggests that the authors may not be addressing the problem directly, as the oracle is described as \"polynomial time\" in the tabular case. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their approach. Without detailed guidance or examples, the authors are left without a clear path forward, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should discuss relevant literature on using moment matching (instead of quantile regression) for distributional RL, specifically mentioning the paper by Nguyen-Tang et al. AAAI\\u002721, \\u201cDistributional Reinforcement Learning via Moment Matching.\\u201d This provides a clear and direct action for the authors to take, as they are instructed to include this discussion in their paper. The comment is specific and provides concrete guidance on how to enhance the literature review section. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific paragraph (lines 22-30) and discusses the use of moment matching in distributional RL. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on moment matching and its relevance to distributional RL. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional RL. The reviewer supports this claim by referencing a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by Nguyen-Tang et al. AAAI\\u002721, which provides a relevant example of using moment matching in distributional RL. This reference provides a clear and specific justification for the claim, making it mostly verifiable. However, the comment could be further strengthened by discussing why moment matching is preferable to quantile regression or how it could enhance the paper\\'s contribution. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional RL. It suggests that the authors should discuss this approach, which is relevant to the paper\\'s topic. By providing a specific reference to a related work, the comment offers a clear and actionable suggestion for improvement. However, it could be more helpful if it explained why moment matching is important or how it could enhance the paper\\'s contribution. Overall, the comment is mostly helpful as it directs the authors to a relevant literature source and provides a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should compare their work with existing code completion commercial applications, such as Copilot, as a baseline. It provides a specific suggestion for testing on a smaller subset of RepoEval and highlights the importance of comparing with state-of-the-art code completion systems. This feedback is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. It specifies that this comparison should be tested on a smaller subset of RepoEval and is essential for comparing with state-of-the-art code completion systems. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the evaluation or comparison sections, the lack of explicit grounding makes it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, which is to test the performance of the proposed system against state-of-the-art applications. However, the comment lacks specific examples or references to these applications, making it somewhat challenging for the authors to fully understand and implement the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of baselines, specifically comparing the proposed work with existing code completion commercial applications like Copilot. This feedback is valuable as it highlights a potential gap in the evaluation and offers a specific direction for the authors to enhance their work. By including these baselines, the authors can better contextualize their findings and demonstrate the novelty and effectiveness of their approach. However, the comment could be more helpful if it provided additional guidance on how to select the subset of RepoEval for testing or how to compare the results with the state-of-the-art systems. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. While the comment implies that the authors should consider expanding their evaluation to include more tasks or datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that understanding the criteria behind the selection and exploring other tasks or datasets might yield different insights. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. However, the comment does not provide specific examples, references, or detailed reasoning to support why this choice might impact the generalizability of the results. While it highlights a potential issue, the lack of detailed justification makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. This feedback is somewhat helpful as it prompts the authors to consider the broader implications of their evaluation choices and how they might impact the generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional tasks or datasets might be relevant to include. Overall, the comment offers a valuable direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the second paragraph in the introduction discusses modelling curves but does not clearly state what is being modelled (presumably tumour growth). While the comment identifies a potential issue with the clarity of the introduction, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to clarify the modelled curves, but the comment lacks specific suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second paragraph of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the content is not immediately obvious and suggests that the modelled curves are likely related to tumour growth. This provides clear guidance on what needs to be clarified in the introduction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the second paragraph in the introduction discusses modelling curves but does not clearly state what is being modelled. This is a subjective observation that requires the reviewer to provide additional context or explanation to support the claim. Without further elaboration or examples, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue in the introduction, specifically the lack of clarity regarding what is being modelled in the second paragraph. It points out that the mention of modelling curves is not immediately obvious and suggests that the modelled curves are likely related to tumour growth. While the comment highlights an area for improvement, it does not provide specific suggestions or guidance on how to clarify the introduction or what additional information might be needed. This limits the comment\\'s helpfulness, as it offers insight but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the performance of the model and baselines on test samples from the observational (in) distribution. It suggests that it would be useful to show this performance. While the comment implies that the authors should include this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"shifted-MNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the performance difference between shift=0 and shift~N (0, \u03c3 2) and suggests including performance on test samples from the observational (in) distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the performance difference between shift=0 and shift~N (0, \u03c3 2) in the context of \"shifted-MNIST,\" suggesting that both cases incorporate a domain shift. The comment also suggests including performance on test samples from the observational (in) distribution. While the comment raises a logical question, it lacks specific examples or references to support the claim that shift=0 is significantly better than shift~N (0, \u03c3 2). This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning behind the claim to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance difference between shift=0 and shift~N (0, \u03c3 2) in the context of \"shifted-MNIST,\" suggesting that both cases incorporate a domain shift. It also suggests including performance on test samples from the observational (in) distribution. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address the issue. The authors are given a direction to explore but are not provided with detailed steps or examples on how to conduct the analysis. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully guide the authors on how to implement it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of detail in the experimental description, suggesting that increased clarity would be beneficial. It explicitly states that the current description is insufficient and points to a specific section (\"Questions\") for further details. This provides a clear and direct action for the authors to take, which is to enhance the clarity of the experimental details. The comment also offers a reference point for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental details\" and the \"Questions\" section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the experimental details and the need for increased clarity to better judge the results. This provides clear guidance on what the authors need to improve, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental description lacks detail and clarity, which hinders the reader's ability to judge the results. However, the comment does not provide specific examples or detailed reasoning to support this claim. It references the \"Questions\" section for further details, but this alone is not sufficient to fully substantiate the claim. The lack of specific examples or detailed reasoning makes the claim somewhat verifiable, as the authors would need to refer to the \"Questions\" section to understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the lack of detail in the experimental description, which hinders the reader\\'s ability to fully understand and evaluate the results. It suggests that increased clarity in the experimental details would be beneficial, providing a clear direction for improvement. However, the comment does not offer specific suggestions or examples of what additional details could be included, nor does it provide guidance on how to improve the clarity of the existing description. While it highlights an important area for improvement, the lack of detailed feedback limits its usefulness. Therefore, the comment is somewhat helpful, as it points out a critical issue but lacks actionable guidance for the authors to address it effectively.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more explanation to clarify the main contributions of the paper, specifically regarding the optimization strategies and their corresponding results. It suggests discussing different scenarios, such as minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is clear and concrete, as it specifies exactly what the authors need to address to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more explanation regarding the optimization strategies and their corresponding results. The comment provides a clear direction for the authors to improve their draft by discussing different scenarios and their implications. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks clarity regarding the optimization strategies and their corresponding results, specifically mentioning the contribution of the CBR. The reviewer provides a specific example of what could be discussed, such as the consequences of minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This suggestion is based on logical reasoning and a clear understanding of the paper\\'s content, making the claim mostly verifiable. However, it could be strengthened by providing more detailed examples or references to similar studies. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity, specifically regarding the optimization strategies and their corresponding results. It suggests that the authors should provide more explanation to make the main contributions of the paper clearer. The comment provides a concrete example by asking what would happen by minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is actionable and constructive, as it guides the authors on how to enhance the clarity and comprehensibility of their work. However, it could be more helpful if it offered additional suggestions or examples on how to present this information effectively. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is an explicit action, as it clearly instructs the authors to include a definition of treewidth. The comment also provides a specific suggestion for how to improve the paper by including a definition, making it concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, methodology, or results sections. The authors can infer that it relates to the proofs, but this inference is not direct. The comment is specific in suggesting the inclusion of a definition, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their work. By including a definition, the authors can ensure that readers understand the concept and its importance in the context of the paper. However, the comment could be more helpful if it provided additional guidance on how to present the definition or examples of its use in the proofs. Overall, the comment is mostly helpful as it identifies a specific area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. This feedback provides a clear and explicit action for the authors to take, which is to include an analysis of the quality of the local minima. The comment is specific in detailing what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of Algorithm 1 and the local minima, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of these local minima, such as the approximation ratio under certain assumptions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, suggesting that the authors analyze the quality of the local minima, particularly the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their analysis and improve the paper. By addressing this suggestion, the authors can strengthen their work by providing more detailed insights into the performance of their algorithm. However, the comment could be more helpful if it included specific examples or references to similar analyses in the literature, which would guide the authors in implementing this suggestion effectively. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the paper is not self-contained and suggests that the supplementary material is necessary to understand large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproduction of their results. While the comment identifies a specific issue with the self-containment and provides a clear action for the authors to take, it does not offer detailed guidance on how to improve the self-containment or what specific aspects of the supplementary material should be included. The action is explicit but somewhat vague, as the authors need to determine which parts of the supplementary material are most critical for self-containment. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"supplementary\" material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the self-containment of the paper and the need for the authors to release the source code of their experiments for reproducibility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not self-contained and suggests that the supplementary material is necessary to understand large parts of the main paper and enable reproducibility. The reviewer also requests the authors to release the source code of their experiments. While the comment identifies a potential issue with the self-containment of the paper, it lacks specific examples or detailed reasoning to support why the supplementary material is necessary or how the source code release would enhance reproducibility. The claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary evidence or detailed justification to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the self-containment of the paper, noting that the supplementary material is necessary to understand large parts of the main paper and enable reproducibility. It also requests the authors to release the source code of their experiments to allow for reproduction of their results. This feedback is clear and actionable, as it provides specific guidance on how to improve the self-containment and reproducibility of the paper. However, the comment could be more helpful if it offered suggestions on how to improve the supplementary material or what specific aspects of the source code should be released. Overall, the comment is mostly helpful as it directs the authors to address a critical aspect of their paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, and references a specific sentence regarding the performance of the secret model with or without fusion. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the algorithms should be clarified or how the authors might address the issue of information redundancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode algorithms\" and the specific sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it asks for clarification on how information redundancy is built into the algorithms and seeks an explanation of the sentence regarding the secret model. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on how information redundancy is built into the Fill, Propagate, Decode algorithms. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms, specifically referencing a sentence about the performance of the secret model with or without fusion. This question highlights a potential area for clarification or explanation in the paper, which could help the authors improve the transparency and understanding of their method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the algorithms need further clarification. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It implies that the authors should consider ablating this feature to determine its impact on the model. However, the comment does not provide explicit instructions or concrete suggestions on how to conduct this ablation or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an ablation study to address the question. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the model, namely the use of multiple INs at different speeds in the dynamics predictor. However, it does not specify which part of the paper this feature is discussed in, making it weakly grounded. The comment is specific in questioning the importance of the added complexity and suggesting an ablation study to determine whether one IN would suffice. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider ablating this feature to determine its impact on the model. However, the comment lacks any supporting evidence, reasoning, or references to justify why this feature is important or how it affects the model\\'s performance. Without such justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider ablating this feature to determine its impact on the model. This feedback is somewhat helpful as it prompts the authors to consider a potential area for improvement and provides a direction for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to conduct the ablation study or what aspects to focus on. Overall, the comment provides a valuable insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the opponent in the experiments does not aim to maximize the multi-agent payoff proposed by the authors, which is a surprise. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their experimental design. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the opponent does not aim to maximize the multi-agent payoff proposed by the authors, which is a clear and specific critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the opponent in the experiments does not aim to maximize the multi-agent payoff proposed by the authors, which is a surprise. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the experimental setup, specifically noting that the opponent does not aim to maximize the multi-agent payoff proposed by the authors. This observation highlights a potential weakness in the experimental design, as it suggests that the opponent's behavior may not accurately reflect the proposed method. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve their experimental design. Without specific advice or constructive feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. It implies that the authors should clarify the reasoning behind these choices, specifically mentioning the attention model paper that the algorithm iterates on. While the comment does not explicitly instruct the authors to provide this rationale, it clearly points out what needs to be added to improve the draft. The action is concrete, as it specifies the need for clarification and provides a direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"REINFORCE algorithm\" and \"PPO,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors provide a rationale for why certain choices were made, such as the use of REINFORCE versus PPO. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. The reviewer implies that this choice might be related to the attention model paper that the algorithm iterates on, but does not provide specific evidence or references to support this claim. While the suggestion is logical, it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the suggestion but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the draft. It points out that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. By doing so, the authors can clarify their methodology and provide a more transparent explanation of their decisions. This feedback is clear and constructive, as it directly addresses a potential area of confusion and offers a straightforward way to enhance the clarity and comprehensibility of the paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about a statement in Theorem 5.1, specifically regarding the potential disadvantage of MMD DRO compared to the variance regularized problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this confusion or what specific steps to take to clarify the statement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, which might indicate a disadvantage of MMD DRO compared to the variance regularized problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, specifically regarding the potential disadvantage of MMD DRO compared to the variance regularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding a statement in Theorem 5.1, which might indicate a disadvantage of MMD DRO compared to the variance regularized problem. This feedback is somewhat helpful as it points out a potential issue that the authors need to address, but it lacks depth and does not provide specific suggestions or guidance on how to clarify the statement or resolve the confusion. The comment highlights an area for improvement but does not offer actionable steps for the authors to take. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide more information on how to use morphologic segmentation across different domains and how it should be conducted differently for each domain. It also questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on morphologic segmentation across domains. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"morphologic segmentation\" and \"domain\" aspects, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of morphologic segmentation across domains and how it should differ for each domain. The comment also raises important questions about the assumption of morphologic segmentation invariance across domains, which is relevant to the task of domain adaptation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks information on how to use morphologic segmentation across domains and how it should be conducted differently for each domain. It questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. The comment suggests that the paper assumes morphologic segmentation to be invariant, which is a logical claim based on the paper\\'s focus on domain adaptation. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the need for more information on morphologic segmentation across domains, but the lack of detailed evidence or examples makes the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the use of morphologic segmentation across domains and how it should differ for each domain. It questions the assumption of morphologic segmentation invariance across domains, given the task of domain adaptation. This feedback is valuable as it highlights an important area for improvement in the paper, particularly regarding the applicability of morphologic segmentation across different domains. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions or how to conduct morphologic segmentation differently for each domain. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical aspect of their work that needs further exploration and clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique used in LUMP. This is a clear and direct action, as it specifies exactly what needs to be done to improve the draft. The authors know exactly what additional experiments are needed and how to implement them, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of experimental results demonstrating the pure contribution of the proposed method without the mixup technique used in LUMP. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mixup technique used in LUMP should be excluded from the proposed method to demonstrate its pure contribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the results. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the mixup technique used in LUMP is also adopted for the proposed method in the experiments on SplitCIFAR-100 and SplitTiny-ImageNet. It suggests that the authors should include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their draft by including additional experiments. However, the comment could be more helpful if it explained why the mixup technique is important or how its exclusion might impact the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their experimental setup.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the object detection-based attention being performed on the image or on some convolutional feature map. It suggests clarifying this point and potentially rescaling based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the attention mechanism and potentially rescale based on the receptive field. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the object detection-based attention, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on whether the attention is performed on the image or on some convolutional feature map, and whether rescaling is done based on the receptive field. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the object detection-based attention and its implementation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the object detection-based attention mechanism, asking whether it is performed on the image or on some convolutional feature map. It also suggests that clarification is needed regarding whether rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the attention mechanism and its implementation. However, the comment could be more helpful if it offered suggestions on how to clarify these points or provided examples of how similar attention mechanisms are typically implemented. Overall, the comment is mostly helpful as it identifies a specific area for clarification and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of a discussion about Set Transformer and other related works that use summary tokens. This provides a clear and direct action for the authors to take, which is to include a discussion on these topics. The comment is specific in identifying the missing content and provides a concrete action for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Set Transformer\" and \"other related works that also use summary tokens,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the use of summary tokens and related works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that there is a missing discussion about Set Transformer and other related works that use summary tokens. However, it does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of a discussion about Set Transformer and other related works that use summary tokens. This feedback is clear and actionable, as it directs the authors to expand their literature review to include relevant works that could enhance their understanding and analysis. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it provided additional context or examples of how these works could be integrated into the paper. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the high-frequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide explicit guidance on how to address this issue or what specific analysis should be conducted. The action is implicit and somewhat vague, as the authors can infer that they need to provide theoretical support but are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the high-frequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or figure where this analysis is discussed. Without explicit references or clear indications, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the high-frequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the high-frequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. This feedback is somewhat helpful as it prompts the authors to consider a potential gap in their analysis and provides a direction for further exploration. However, the comment lacks specific guidance or suggestions on how to address this issue or what kind of theoretical support would be beneficial. To be more helpful, the comment could provide examples of similar analyses or suggest specific areas for further investigation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of details regarding how the network fits the residual instead of directly learning the input-output mapping. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more information about the network's training process, but it lacks concrete steps or suggestions for improvement. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of detail regarding how the network fits the residual instead of directly learning the input-output mapping. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of lacking details regarding the network's training process, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the lack of details regarding how the network fits the residual instead of directly learning the input-output mapping. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that this is a significant issue or a gap in the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of details on how the network fits the residual instead of directly learning the input-output mapping. This is a relevant point that could impact the clarity and understanding of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what additional details might be needed. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the experiment setup in Section 3.3, specifically asking about data augmentation methods and learning rate. While the comment implies that the authors should provide more details about these aspects, it does not explicitly instruct them to do so. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" provides some context but does not offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the experiment setup. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for details about the experiment setup, such as data augmentation methods and learning rate, and provides a reference to a related paper for context. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods and learning rate. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" is helpful in providing context but does not offer actionable advice. Overall, the comment is somewhat helpful as it points out a potential area for improvement but lacks depth and specificity in its guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider an error in the initial calibration steps (steps 1 and 2) as a possible explanation for the speed disparities observed between the RSPs and FDs. However, it does not provide explicit instructions or concrete guidance on how to investigate or address this potential error. The authors are left to infer that they should look into the initial calibration steps, but without specific suggestions on how to do so or what specific aspects to focus on, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or examples to substantiate the claim, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the initial calibration steps, suggesting that an error might explain the speed disparities observed between the RSPs and FDs. While it highlights an area for further investigation, it lacks specific guidance or suggestions on how the authors might address this issue or what specific aspects of the initial calibration steps should be examined. The comment is somewhat helpful as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the resemblance between artificial and biological networks. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of artificial networks trained using ASAP (and similar methods) not necessarily resembling biological networks, except for the weight transport problem. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the resemblance of artificial and biological networks, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any constructive feedback or suggestions for improvement. The comment does not offer guidance on how the authors might address this issue or improve the resemblance between artificial and biological networks. Without actionable advice or specific recommendations, the comment does not assist the authors in enhancing their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors conducted statistical significance tests for the numbers presented in the comparison between the proposed method and baselines. While it implies that the authors should consider conducting such tests, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct statistical significance tests. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in its request for statistical significance tests, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. However, it does not provide any evidence, reasoning, or examples to support the claim that statistical significance tests should be conducted. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. It prompts the authors to consider whether they conducted statistical significance tests, which is an important aspect of evaluating the effectiveness of their method. This feedback is somewhat helpful as it identifies a potential area for improvement and encourages the authors to consider conducting statistical significance tests. However, the comment could be more helpful if it provided specific guidance on how to conduct these tests or what statistical tests might be appropriate. Overall, the comment is somewhat helpful as it points out a potential weakness but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the paper\\'s focus on learning HMMs with non-parametric emission distributions but questions how these distributions affect inference. It specifically asks about the inference tasks that can be computed with an NP-SPEC-HMM, such as filtering, smoothing, and marginal observation likelihood. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on the impact of emission distributions on inference tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on learning HMMs with non-parametric emission distributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how these emission distributions affect inference and asks about the inference tasks that can be computed with an NP-SPEC-HMM. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference tasks in a discrete HMM. It asks which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NP-SPEC-HMM. This is a request for clarification rather than a claim or opinion, as it does not express an assertion or suggestion that requires verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the impact of non-parametric emission distributions on inference tasks in a discrete HMM. It specifically questions which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NP-SPEC-HMM. This feedback is valuable as it prompts the authors to clarify and expand on the implications of their work regarding inference tasks. However, the comment could be more helpful if it provided suggestions on how to address this gap or examples of how the authors might present this information. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results, including identifying the factors contributing to the poor performance. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it is not as concrete as it could be, leaving some ambiguity about the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, noting that the authors only mention poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This claim is somewhat verifiable as it highlights a gap in the analysis but lacks specific examples or detailed reasoning to support the claim fully. The authors would need to infer the need for a more detailed analysis themselves, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the results. By pointing out the lack of analysis, the comment empowers the authors to enhance their draft by including a more detailed explanation of the factors contributing to the poor performance. However, the comment could be more helpful if it suggested specific areas to explore or provided examples of how to conduct a deeper analysis. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. While the comment implies that the authors should consider expanding their dataset analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analyses. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific section where the authors discuss the datasets considered, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions why only 10 out of 120 datasets are considered and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid point about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This feedback is somewhat helpful as it identifies a potential area for improvement in the dataset analysis, which could enhance the paper\\'s comprehensiveness and rigor. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, making it somewhat helpful but not fully actionable. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation in the introduction, specifically the low-rank factorization, is unnecessary given that the main result is about polytopes. The reviewer also expresses interest in seeing implications for low-rank matrix factorization explicitly discussed. While the comment implies that the authors should reconsider the motivation and potentially include more discussion on low-rank factorization, it does not provide explicit instructions on how to do so. The action is concrete, as it specifies what needs to be addressed, but the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"low-rank factorization\" in the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary nature of the low-rank factorization and the potential implications for low-rank matrix factorization. This provides clear guidance on what the authors should consider and discuss in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation in the introduction, specifically the low-rank factorization, is unnecessary given that the main result is about polytopes. The reviewer suggests that if the result has implications for low-rank matrix factorization, it should be explicitly discussed. However, the comment lacks specific examples or references to support the claim that the low-rank factorization is unnecessary or to justify the need for explicit discussion on low-rank matrix factorization. This makes the claim somewhat verifiable, as it requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation in the introduction, specifically the inclusion of the low-rank factorization. It suggests that this factor may be unnecessary given the main result about polytopes. The reviewer expresses interest in seeing implications for low-rank matrix factorization explicitly discussed. While the comment highlights a potential weakness in the paper, it does not provide specific guidance on how to address this issue or what aspects of the low-rank factorization should be discussed. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks detailed suggestions or examples to fully support the authors in making those improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the labels for each dataset in 4.1, specifically asking for clarification on where the labels are coming from. It implies that the authors should provide explicit information about the labeling process for each dataset, including the generated ones and those like cas-peal-r1 and mugshot. While the comment does not explicitly instruct the authors to add this information, it clearly points out what needs to be clarified and provides a concrete action for improvement. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the labels for each dataset, including the origin of the labels and how they are applied to datasets like cas-peal-r1 and mugshot. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the labels for each dataset in 4.1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the labels for each dataset in 4.1, specifically asking for clarification on where the labels are coming from. This is a relevant point as it pertains to the transparency and clarity of the dataset used in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multi-person case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of incrementalism or suggestions for improvement. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multi-person case, producing identity/tag heatmaps with joint heatmaps. However, it does not specify which part of the paper this assessment is based on, such as the methodology or results sections. This makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the authors could improve their work to address this issue. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multi-person case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any specific details or references to support this claim, such as how the paper is incremental or how the adaptation affects the results. Without additional context or evidence, the claim is difficult for the authors to verify or address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multi-person case, producing identity/tag heatmaps with joint heatmaps. However, it does not provide any specific feedback or suggestions on how the authors could improve their work or address the issue of incrementalism. Without actionable guidance or constructive criticism, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the sensitivity of performance and sample efficiency to the \u03bb parameters, and questions how \u03bb is calculated. It also mentions that the authors explain why ELLA does not increase sample efficiency in a COMBO environment but does not fully understand the implications. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment does not explicitly instruct the authors on how to address these issues or provide specific guidance on how to improve the explanation or calculations. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the process of calculating \u03bb and improve the explanation of the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines on pages 8 and 9, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning how \u03bb is calculated and the explanation of ELLA\\'s sample efficiency in a COMBO environment. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters, questioning how \u03bb is calculated and the explanation of ELLA\\'s sample efficiency in a COMBO environment. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific examples or detailed reasoning to support the claim that performance and sample efficiency are sensitive to \u03bb parameters. The references are provided as a means of context, but they do not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the sensitivity of performance and sample efficiency to \u03bb parameters, which is a critical aspect of the paper. It raises questions about how \u03bb is calculated and the explanation of ELLA\\'s sample efficiency in a COMBO environment, which are important areas for clarification. The reviewer also provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve the explanation. While it points out areas for improvement, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific method used to solve the min-min problem, which is mentioned in passing. However, it does not provide any guidance or suggestions on how the authors should address this issue. The comment lacks explicit instructions or concrete details on what the authors should do to clarify or expand on this aspect of their work. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of an alternating direction method to solve the min-min problem, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what needs to be addressed or improved regarding this method, making it under-specific. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the specific method used to solve the min-min problem. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the specific method used to solve the min-min problem, which is mentioned in passing. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or detailed advice, making it barely helpful for the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the effectiveness of lower bound double q-learning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in other environments. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these concerns or improve the draft. The authors are left without any clear direction on how to respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure2\" and \"MsPacman,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of lower bound double q-learning, particularly in the context of convergence and overestimation of true maximum values. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effectiveness of lower bound double q-learning is doubtful, based on observations from Figure 2 and specific environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. The reviewer provides some evidence by mentioning the slight performance decrease in MsPacman and the convergence of algorithms in other environments. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some support, the lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to further explore the data or literature to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the effectiveness of lower bound double q-learning, specifically questioning its performance in certain environments and its tendency to overestimate true maximum values. It provides specific examples from Figure 2 and other environments, which helps the authors understand the basis of the critique. However, the comment could be more helpful if it offered suggestions on how to address these concerns or improve the algorithm. While it highlights a relevant area for improvement, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or suggest alternative approaches to explore. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspect of the novelty is lacking or how it could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. This feedback highlights a potential weakness in the paper\\'s contribution, which could be addressed by providing more novel or innovative approaches to model interpretation. However, the comment does not offer specific suggestions or guidance on how the authors might enhance the novelty or address this limitation. While it points out an area for improvement, the lack of actionable advice makes it somewhat helpful, as it provides insight but not a clear path for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the observed behavior, but it lacks concrete steps or suggestions for improvement. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig.3-4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small, and suggests that it should approach vanilla methods from above but from below. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. This feedback identifies a potential discrepancy in the results that the authors may need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this issue or improve their analysis. While it points out a potential area for further exploration, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper, noting that it does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not doing so in the author response, the comment suggests that they should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback provides a clear and explicit action for the authors to take, which is to include comparisons with these systems. The comment is specific and provides concrete guidance on how to improve the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors have explained their reasons for not comparing their results with some earlier research work from 2020. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the comparison with earlier systems with worse performances, such as Taghipour and Ng (2016). Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not compare its results with some earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer suggests that the authors should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). However, the comment lacks specific examples or references to support the claim that these earlier systems are indeed worse performers. Without detailed evidence or comparisons, the claim is somewhat verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper, noting that it does not compare its results with some earlier research work from 2020, despite the authors explaining their reasons for not doing so. The comment suggests that the authors should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by including comparisons with relevant systems. However, the comment could be more helpful if it explained why these comparisons are important or how they would strengthen the paper. Overall, the comment is mostly helpful as it points out a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the choice of significance testing method used in the paper, suggesting that a paired test setting like the Wilcoxon signed-ranked test might be more appropriate. While the comment implies that the authors should consider using a different test, it does not explicitly instruct them to do so or provide guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choice of significance testing method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the choice of significance testing method used in the paper, specifically questioning the appropriateness of the current method. However, it does not specify which part of the paper discusses this choice, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in suggesting an alternative test, the Wilcoxon signed-ranked test, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples of why the current test might be inappropriate or how the suggested test would be more suitable. As a result, the claim is not fully verifiable, as it relies on a vague suggestion without sufficient justification or evidence. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. While it identifies a potential issue with the current choice, it does not provide specific guidance or examples of alternative tests that could be used. The comment lacks depth and does not offer actionable steps for the authors to address the concern. As a result, it provides some insight but does not fully support the authors in improving their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not provide specific guidance on how to expand the experiments or what additional aspects to consider. The action is implicit and somewhat vague, as the authors can infer that they need to broaden the scope of their experiments but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its critique of the limitations of the experiments, but without explicit references to sections or details, it is difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments are limited in scope and that the model size and baselines are restrictive, which limits the comprehensiveness and generalizability of the results. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the limitations and how they might address them. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope and comprehensiveness of the experiments, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the generalizability of the results. This feedback is somewhat helpful as it highlights an area where the authors could potentially expand their experiments to enhance the robustness and applicability of their findings. However, the comment lacks specific suggestions on how to address these limitations or what additional experiments could be conducted. To be more helpful, the comment could provide guidance on how to broaden the scope of the experiments or suggest alternative approaches to consider. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors elaborate on the Hoeffding's bound and its implications for stochastic algorithms. It provides a clear and specific action for the authors to take, which is to elaborate on the topic. The comment is explicit and provides concrete guidance on what needs to be added to the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 124-125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the Hoeffding's bound and its implications for stochastic algorithms. This provides clear guidance on what the authors need to address in this section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Hoeffding's bound holds true for any w as long as samples are drawn independently, and that stochastic algorithms impose conditioning on the previous iterate to guarantee the inequality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific section of the paper (Line 124-125) and suggests that the authors elaborate on the Hoeffding's bound and its implications for stochastic algorithms. This feedback is clear and actionable, as it directs the authors to provide more detailed information on a topic that is likely important for the paper\\'s understanding and relevance. However, the comment could be more helpful if it included specific questions or points to consider in elaborating on this topic. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and depth of their discussion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, specifically mentioning MAML and implicit-MAML, to Table 1. While the comment implies that the authors should consider adding this information, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is clear but lacks concrete details on how to execute it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding an optimization-based meta-learning approach, specifically mentioning MAML and implicit-MAML, to Table 1. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this addition would be relevant. The authors can infer that it relates to the table or data presentation, but this inference is not direct. The comment is specific in suggesting the addition of a particular approach, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, specifically mentioning MAML and implicit-MAML, to Table 1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it would enhance their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding an optimization-based meta-learning approach, specifically mentioning MAML and implicit-MAML, to Table 1. This is a specific and actionable suggestion that could potentially enhance the paper by providing additional context and insights into the optimization methods used. However, the comment lacks depth and does not explain why this addition would be beneficial or how it would impact the paper\\'s overall contribution. While it identifies a potential area for improvement, the lack of detailed guidance or rationale makes it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using few-shot examples for CoT. This feedback provides a clear and direct action for the authors to take, which is to include an ablation study to address this issue. The comment is specific and provides concrete guidance on what needs to be added to the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of an ablation study, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of an ablation study to explain why the prompt was chosen in a specific way, such as using few-shot examples for CoT. This provides clear guidance on what the authors need to add to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using few-shot examples for CoT. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this ablation study is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting the inclusion of an ablation study to explain why the prompt was chosen in a particular way, such as using few-shot examples for CoT. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by addressing a gap in the experimental design. However, the comment could be more helpful if it included examples or detailed guidance on how to conduct the ablation study or what specific aspects to consider. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to be careful with the terms \"causal mechanisms\" and \"temporal relationship,\" as they are not interchangeable. This feedback is clear and provides a specific action for the authors to take, ensuring that they use the terms correctly. The comment is concrete, as it specifies the exact issue and offers a direct way to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of terms like \"causal mechanisms\" and \"temporal relationship,\" providing guidance on how to avoid confusion and ensure clarity in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the use of terms \"causal mechanisms\" and \"temporal relationship,\" suggesting that they are not interchangeable. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it points out a specific issue with the use of terms like \"causal mechanisms\" and \"temporal relationship\" in the paper. It highlights the need for careful consideration of these terms to avoid confusion and ensure clarity in the paper. However, the comment does not provide detailed guidance on how to address this issue or suggest alternative terms that could be used. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful but not comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what alternative demonstrations could be used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific statement from the paper, \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\" allowing the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not detail what aspect of the demonstration is questionable or how it could be improved. It suggests that \"better than random\" may not be a strong demonstration of capability, but without further explanation or examples, the authors are left without clear guidance on how to address this concern. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the claim that \"better than random\" is a strong demonstration of capability. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to justify why \"better than random\" might not be a strong demonstration. As a result, the claim is unverifiable, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any specific reasoning or examples to support this claim or offer alternative demonstrations that could be used. The comment lacks depth and actionable guidance, leaving the authors without clear direction on how to address the concern or improve their demonstration. As a result, the feedback is not helpful, as it does not provide the authors with meaningful insights or suggestions for improvement. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a desire for a discussion on how the results relate to the lower bounds on kernel learning using low-rank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" While it implies that the authors should include this discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion on this topic. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using low-rank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the results need to be addressed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, it is not specific, as it lacks detailed guidance on what aspects of the results need to be discussed or how they relate to the lower bounds. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using low-rank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered fully verifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using low-rank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" This feedback is somewhat helpful as it identifies a potential area for further exploration and discussion. However, it lacks specific guidance on how the authors should integrate this discussion into their paper or what aspects of the results need to be addressed. While it points out a relevant reference, it does not provide detailed suggestions on how to effectively incorporate this discussion into the paper. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to clarify the assumptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the assumptions and the significance of their results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are discussed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the novelty and significance of the results, but without clear grounding, it lacks full specificity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. The reviewer provides a reference to a related work by Dombrowski et al. (2022) to support their claim about the use of PCA. However, the comment lacks detailed explanation or analysis of why the assumptions are unclear or how they impact the paper\\'s significance. The reference to the external work is helpful but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive justification or detailed reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the novelty and significance of the paper, suggesting that the use of PCA to reduce interaction count is intuitive and that the assumptions made are unclear. It references a related work by Dombrowski et al. (2022) to support its claim. While the comment identifies a potential weakness in the paper\\'s novelty and significance, it lacks specific guidance on how the authors might address these concerns or what aspects of the assumptions need clarification. The reference to the external work is helpful, but the comment could be more actionable by providing more detailed feedback on how to improve the paper. Overall, the comment is somewhat helpful as it points out a potential issue but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the few-shot RC models considered in the paper, noting that they are not state-of-the-art models. It asks a question about how the performance of these models compares to relation extraction/generation models in few-shot settings. While the comment implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the few-shot RC models considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of these models compared to relation extraction/generation models in few-shot settings. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim that the few-shot RC models considered in the paper are not state-of-the-art models. However, it does not provide any specific references or examples to support this claim, nor does it compare the performance of these models to other models in the field. Without such evidence or comparisons, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the few-shot RC models considered are not state-of-the-art models. It raises a relevant question about how the performance of these models compares to relation extraction/generation models in few-shot settings. This feedback is somewhat helpful as it prompts the authors to consider a potential limitation in their work and to address it by providing a comparison. However, the comment could be more helpful if it suggested specific models or methods for comparison or provided guidance on how to conduct the comparison. Overall, the comment is somewhat helpful as it points out an area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the results section, specifically that the results only apply to shallow fully-connected ReLU networks. However, it does not provide any guidance on how the authors should address this limitation or suggest ways to expand the results to include other network architectures. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results only apply to shallow fully-connected ReLU networks, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results in section 4 apply only to shallow fully-connected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the results section, noting that the results only apply to shallow fully-connected ReLU networks. This is a relevant observation that could impact the generalizability and applicability of the results. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or expand their results to include other network architectures. While it points out an area for improvement, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should enhance the background knowledge and literature description. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper\\'s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, it does not specify which sections or parts of the paper need these improvements, making it weakly grounded. The comment is specific in suggesting that the background knowledge and literature description should be brought forward, but without explicit references to sections or parts of the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper\\'s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, the comment does not provide specific examples or references to support why these changes would be beneficial or how they would improve the paper. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s organization, suggesting that it could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. This feedback is somewhat helpful as it points out a specific area for improvement, but it lacks depth and does not provide detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specific steps to take. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While it identifies a potential gap in the comparison, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include these models in their comparison, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific models, \"PanopticFPN\" and \"Mask2Former,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of these models in the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these models should be included in the comparison. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared. This feedback is valuable as it highlights an area where the paper could be expanded to include more comprehensive comparisons. However, the comment lacks depth and does not provide specific suggestions on how to incorporate these models or what aspects of their performance should be compared. While it points out a potential weakness, it does not offer actionable guidance for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to provide results or observations regarding the use of sequential MCB versus a single MCT layer for the decision head. This is a clear and direct request, as it specifies exactly what the authors need to include in their discussion. The action is concrete, as it specifies the exact information that should be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB versus a single MCT layer for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of results or observations regarding this discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the discussion of using sequential MCB versus a single MCT layer for the decision head was interesting but lacks results or observations. However, it does not provide any supporting evidence, reasoning, or examples to substantiate why this discussion is important or how it could be improved. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of interest in the paper, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It points out that while the discussion is interesting, no results or observations are shown. This feedback is somewhat helpful as it prompts the authors to provide additional information or insights into their findings, which could enhance the clarity and depth of their discussion. However, the comment could be more helpful if it offered suggestions on how to present these results or observations, such as through additional figures or tables. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific language issues to address, such as \"we typically considers\" and \"two permutation\" in various sections. It also encourages the authors to proofread the entire paper for language problems. While the comment identifies specific areas that need attention, it does not provide detailed guidance on how to correct these issues or improve the language. The actions are explicit but somewhat vague, as the authors know what needs to be fixed but may not be entirely sure of the exact process. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"the above of (7),\" \"the above of Theorem 1,\" and \"the above of (14),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the language issues, such as \"we typically considers\" and \"two permutation,\" providing clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of comments on language usage and suggestions for proofreading the paper. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific language issues in the paper, such as \"we typically considers\" and \"two permutation,\" which are examples of unclear or incorrect phrasing. It also encourages the authors to proofread the entire paper for language problems. While the comment provides actionable feedback on improving the language and clarity of the paper, it could be more helpful if it offered suggestions on how to improve the language or provided examples of better phrasing. Overall, the comment is somewhat helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. While the comment implies that the authors should consider these aspects, it does not provide explicit instructions or concrete steps on how to address them. The authors can infer that they need to consider these points, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the choice of 20 distribution sets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the number of distribution sets for each class can be controlled and what the implications would be if only a few distribution sets are selected. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the choice of 20 distribution sets is problematic. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also inquires about the implications of selecting only a few distribution sets. This feedback is somewhat helpful as it prompts the authors to consider the potential limitations and consequences of their choice. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these issues. While it highlights an important area for consideration, the lack of detailed guidance limits its utility. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models, which raises concerns about its broader applicability. The reviewer suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this limitation or expand the scope of their framework. The action is implicit and somewhat vague, as the authors need to infer that they should consider broadening the scope of their framework. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluative framework, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited scope of the framework, which is restricted to only three Question-Answering tasks and two language models, and raises concerns about its broader applicability. The comment suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluative framework is limited in scope, restricted to only three Question-Answering tasks and two language models, which raises concerns about its broader applicability. The comment suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. However, the comment lacks specific examples or references to substantiate these concerns, making it somewhat verifiable. The authors would need to infer the potential applicability issues and address them themselves, rather than having clear guidance on how to improve the framework. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. This observation raises concerns about the method\\'s broader applicability, as it may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. While the comment highlights a potential issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or expand the scope of their framework. The feedback is somewhat helpful as it points out a potential weakness, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should showcase their approach using transformer-based (masked) language models, which are more current and relevant in NLP trends. This is a clear and concrete action for the authors to take, as it provides a specific direction for improvement. The comment also highlights the issue with using obsolete language models, which adds context and guidance for the authors. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the specific language models used, such as n-gram HMM and RNN, which are considered obsolete. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly suggests that the authors should showcase their approach using transformer-based (masked) language models, which are more current and relevant in NLP trends. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the perplexity experiments are carried out on obsolete language models, specifically n-gram HMM and RNN, which are not commonly used nowadays. The reviewer suggests that the authors should showcase their approach using transformer-based (masked) language models to align the paper with current NLP trends. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to current NLP trends or the relevance of transformer-based models. The authors would need to make an effort to understand and address the suggestion, which justifies a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the perplexity experiments, noting that they are carried out on obsolete language models (n-gram HMM, RNN) that are no longer commonly used in NLP. The reviewer suggests that the authors should showcase their approach using transformer-based (masked) language models, which are more current and relevant in NLP trends. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that could enhance the relevance and impact of the paper. By addressing this point, the authors can better align their work with current research trends and demonstrate the applicability of their approach. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experiments are insufficient and suggests that more empirical experiments or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments or referencing specific works to support their claims. The explicit nature of the suggestions and the detailed guidance on what needs to be done make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"simplified self-attention model\" considered in the theoretical analysis, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The mention of Kaplan et al. 2020 provides additional context and guidance for the authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are insufficient and suggests the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The reviewer references Kaplan et al. 2020 as a potential source for comparison. However, the comment lacks specific examples or detailed reasoning to support why the current experiments are insufficient or how additional experiments would address the issue. The reference to Kaplan et al. 2020 provides some context but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental setup, noting that the experiments are insufficient to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that more empirical experiments or toy experiments are needed to address this gap. Additionally, it references the result in Kaplan et al. 2020 as a potential source for comparison. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their experimental setup and substantiate their claims. By addressing these points, the authors can significantly improve the robustness and credibility of their work. However, the comment could be more helpful if it provided additional details on what specific aspects of the theoretical analysis or empirical results need validation. Overall, the comment is mostly helpful as it effectively directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, making it unclear how it can be estimated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might clarify this issue or what specific steps they could take to address it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the discussion on the misestimation of mu, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper this discussion is located in, making it weakly grounded. The comment is specific in pointing out the issue with the estimation of mu, as it is the proportion of missing observations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the discussion on the misestimation of mu, noting that it is the proportion of missing observations. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the discussion is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, making it unclear how it can be estimated. This is a relevant point that could lead to confusion in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this issue or improve the discussion. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests presenting the performance as a function of the distance of initialization M^0 to the ground-truth M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This feedback is explicit and provides concrete guidance on how to implement the suggestion. The authors know exactly what steps to take to address the issue of sensitivity to initialization. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sensitivity to initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for presenting the performance as a function of the distance of initialization, with a detailed explanation of how to implement this. This includes the distance range for initialization and the expected trend in performance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests presenting the performance as a function of the distance of initialization M^0 to the ground-truth M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This claim is somewhat verifiable as it logically suggests that the mean error and variance should increase as the quality of initialization decreases. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for addressing the issue of sensitivity to initialization. It suggests presenting the performance as a function of the distance of initialization M^0 to the ground-truth M^*, which is a clear and concrete approach. The comment also specifies the distance range (0.01:0.01:0.1) and explains the expected trend in performance, which is a valuable detail for the authors to consider. This feedback is highly helpful as it offers a clear path for the authors to improve their draft by addressing a critical aspect of their methodology. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary use of the absolute value operation in the definition of the Frobenius norm. This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This is a factual observation about the mathematical definition of the Frobenius norm, which does not require an opinion or subjective judgment. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definition of the Frobenius norm in line 77, noting that the absolute value operation is unnecessary because tensor entries are real numbers. This is a clear and actionable piece of feedback that can help the authors improve the clarity and accuracy of their draft. By pointing out this oversight, the comment provides the authors with a concrete step to take in revising their manuscript. However, it could be more helpful if it offered suggestions on how to better explain this point in the context of the paper or provided additional examples to illustrate the point. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider providing high-probability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should provide high-probability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the use of ensemble methods and robustness measures, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should provide high-probability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to ensemble methods or robustness measures that have been successfully used in similar contexts. This makes the claim somewhat verifiable, as the authors would need to infer the specifics of how to implement these suggestions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It recommends adding high-probability bounds by using ensemble methods, as performed in the experiments, and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is specific and offers a concrete direction for enhancing the paper\\'s rigor and comprehensiveness. By addressing these points, the authors can significantly improve the quality and credibility of their work. However, the comment could be more helpful if it provided examples of how these suggestions have been implemented successfully in other works or detailed guidance on how to implement them in the current context. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation for the work is good but that the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so or provide specific guidance on how to implement these evaluations. The action is implicit and somewhat vague, as the authors need to infer the need for these additional evaluations and determine how to incorporate them into their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the motivation for the work is good but the results are less impressive, and it recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these aspects are discussed, the comment lacks full grounding. It is specific in suggesting additional evaluations but does not provide detailed guidance on how to implement them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the motivation for the work is good but the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, the comment lacks specific examples or detailed reasoning to support why the results are less impressive or how these additional aspects should be evaluated. Without specific examples or references, the claim is difficult for the authors to verify and address. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results, suggesting that they are less impressive despite a good motivation. It recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these additional evaluations or what specific metrics should be considered. This limits the comment\\'s helpfulness, as it points out an area for improvement but does not offer detailed instructions on how to address it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the paper's motivation for diversity, noting that the model does not enforce diversity explicitly. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might incorporate diversity into their model or what specific steps they should take to ensure that their model enforces diversity. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s motivation for diversity, specifically mentioning that the model does not enforce diversity explicitly. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the model\\'s lack of diversity enforcement, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model. The reviewer expresses disappointment at the lack of diversity in the model. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the paper\\'s motivation for diversity, noting that the model does not enforce diversity explicitly. This is a critical point as it undermines the paper\\'s claims about promoting diversity. However, the comment lacks specificity and actionable suggestions on how the authors might address this issue or improve their model to enforce diversity. Without detailed guidance or examples, the authors may struggle to understand the exact areas needing improvement or how to implement changes. Therefore, the comment is somewhat helpful, as it points out a critical weakness but does not provide enough direction for the authors to effectively address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on how the authors should address this issue or what specific experiments should be included. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without clear grounding, the authors may struggle to determine where to address these issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence affects the paper\\'s conclusions. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue by pointing out the absence of certain experiments, such as contrastive learning and adversarial learning. This feedback is somewhat helpful as it highlights a potential gap in the experimental setup, which the authors should address to provide a more comprehensive evaluation of their work. However, the comment lacks depth and does not offer suggestions on how to incorporate these experiments or what specific aspects of the paper would benefit from their inclusion. While it points out a potential area for improvement, it does not fully guide the authors on how to address it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap between the lower and upper bounds in the paper, specifically mentioning that the independence number may be a better bound for some graphs. It also provides additional remarks about the results on the adaptive adversary and the counterfactual feedback. However, the comment does not offer explicit guidance on how to address this issue or what specific changes should be made to improve the paper. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the use of the independence number and consider its impact on the results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the gap between the lower and upper bounds, specifically mentioning the use of \\u00b2 instead of \\u00b3^{1/3} and the results on the adaptive adversary and counterfactual feedback. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the gap between the lower and upper bounds and the potential impact on the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a gap between the lower and upper bounds in the paper, specifically mentioning the use of \\u00b2 instead of \\u00b3^{1/3}. The reviewer also suggests that the independence number may be a better bound for some graphs and provides examples of the results on the adaptive adversary and counterfactual feedback. However, the comment lacks specific examples or detailed reasoning to support the claim that the independence number is a better bound. While the reviewer provides some insight into potential issues, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap between the lower and upper bounds in the paper, specifically mentioning the use of \\u00b2 instead of \\u00b3^{1/3}. It also points out that the independence number may be a better bound for some graphs, providing examples of the results on the adaptive adversary and counterfactual feedback. This feedback is somewhat helpful as it highlights a potential issue with the bounds and suggests an alternative approach. However, the comment could be more helpful if it provided more detailed guidance on how to address this gap or how to use the independence number as a better bound. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to use DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The suggestion to use DinoV2 Frechet Distances is specific and provides a concrete detail for the authors to implement, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"simplistic Inception network\" and \"FIDs,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of DinoV2 Frechet Distances for comparisons in addition to the widely used FID metric. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are \"clear flaws associated with FIDs and the simplistic Inception network,\" but it does not provide specific examples or references to support this claim. The suggestion to use DinoV2 Frechet Distances is made without further explanation or justification, leaving the authors without a clear understanding of why this alternative metric is preferred. The lack of detailed reasoning or evidence makes the claim unverifiable, as it does not provide sufficient support for the authors to understand and address the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of FIDs and the simplistic Inception network, noting that there are clear flaws associated with these methods. It provides a constructive suggestion by recommending the use of DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is actionable and offers a clear path for improvement, guiding the authors to consider alternative metrics for evaluating their work. However, the comment could be more helpful if it explained why DinoV2 Frechet Distances are preferred over FIDs or provided examples of their advantages. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of the paper and asks for clarification on how it differs from a specific reference. While it implies that the authors should provide a comparison with the reference, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed comparison to justify the novelty of their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the novelty of the paper and seeks clarification on how it differs from a specific reference. However, it does not specify which part of the paper this question pertains to, such as the introduction, methodology, or results section. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its request for a comparison with the reference, but without explicit grounding, it is difficult for the authors to pinpoint the exact issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the paper and seeks clarification on how it differs from a specific reference. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the novelty is incremental. Without such details, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the novelty of the paper and seeks clarification on how it differs from a specific reference. While it identifies a potential issue with the paper\\'s novelty, it does not provide specific guidance or suggestions on how the authors might address this concern. The comment lacks depth and does not offer actionable advice or examples to help the authors improve their draft. As a result, it provides limited value to the authors in terms of improving their work. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their analysis. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them without a clear path forward. As a result, the action is implicit and vague, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"CUB and SOP datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the reported ablation studies, where the complete loss function performed worse than those with missing terms. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. This observation raises a valid concern about the validity of the results and prompts the authors to question why this might be the case. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions that this would allow for inspection of the long-range inference capacity of the model. The reviewer explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. The action is explicit and concrete, as it clearly specifies what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions the need to inspect the long-range inference capacity of the model. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the need for the experiment. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an experiment where the image is occluded to simulate irregularity in neural/behavioral data and to inspect the long-range inference capacity of the model. The reviewer provides a logical reasoning for why this experiment would be beneficial, noting that it would simulate real-world scenarios where keypoint detection may fail. However, the comment lacks specific examples or references to similar experiments in the literature, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but could be further supported with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending an experiment where the image is occluded to simulate irregularity in neural/behavioral data. This suggestion is relevant as it addresses a potential limitation in the current study and offers a way to test the model's long-range inference capacity. The reviewer also explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. This feedback is highly helpful as it guides the authors on how to enhance their study with a specific and meaningful addition. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer recommends using a second y-axis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not specify which alternative visualization should be used or how to implement the change. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which implies negative rates, and suggests using a second y-axis or another visualization that is more physically accurate. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer suggests using a second y-axis or another visualization that is more physically accurate. However, the comment lacks specific reasoning or examples to support why Figure 6C is awkward or how it implies negative rates. Without detailed justification or references, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates when it should represent positive rates. The reviewer suggests using a second y-axis or another visualization that is more physically accurate. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the accuracy and clarity of their visual representation. However, the comment could be more helpful if it included additional details on how to implement the suggested changes or examples of alternative visualizations. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should test inverse triples in other embedding models besides CP, which could provide additional insights into the effectiveness of their approach. While the comment implies that the authors should conduct these tests, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should test inverse triples in other embedding models besides CP, which could provide additional insights into the effectiveness of their approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental setup, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting a potential test that could enhance the paper, but without clear grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that introducing inverse triples could be used in other embedding models besides CP, but it does not provide any evidence or reasoning to support this claim. The comment lacks specific examples or references to other models where this approach might be applicable, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the authors test inverse triples in other embedding models besides CP. This is a relevant point as it could provide additional insights into the effectiveness of their approach. However, the comment lacks specific guidance on how to implement this test or what other models should be considered. While it highlights a potential area for improvement, it does not offer detailed instructions or examples, making it somewhat helpful. The authors are given a direction but not a clear path to follow, which limits the comment\\'s utility. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the statement in the abstract is unclear and suggests that it should be revised to be more high-level. It also implies that technical details are not necessary for the abstract. While the comment provides a clear action\u2014to clarify the statement and simplify the abstract\u2014it does not offer specific guidance on how to achieve this clarity or what aspects of the statement are unclear. The authors are left to infer the necessary changes, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement in the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement regarding the low-rank feature subspace, a small number of attacked samples, and other mild assumptions. The comment provides a clear direction for improvement by suggesting that the abstract should be more high-level and that technical details are not necessary. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement in the abstract is unclear and suggests that it should be revised to be more high-level. The reviewer provides a specific example of the unclear statement, \"with a low-rank feature subspace, a small number of attacked samples, and other mild assumptions,\" which is helpful in clarifying the issue. However, the comment lacks detailed reasoning or references to support why this statement is unclear or how it could be clarified. While the example is helpful, the lack of further explanation or justification makes the claim somewhat verifiable, as it requires more detailed guidance for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and suggests that it should be revised to be more high-level. It provides a clear example of the problematic statement, \"with a low-rank feature subspace, a small number of attacked samples, and other mild assumptions,\" which helps the authors understand the exact part of the abstract that needs improvement. The comment also suggests that technical details are not necessary for the abstract, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it offered suggestions on how to simplify the statement or provided examples of how to achieve a more high-level abstract. Overall, the comment is somewhat helpful as it identifies a specific issue and offers a direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific guidance or suggestions on how to achieve this improvement. The authors are left to infer that they need to make changes to the algorithm, but without concrete steps or examples, they may struggle to determine what exactly is required. As a result, the comment is vague and lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of the paper discusses Algorithm 2 or where it is located. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of Algorithm 2 need improvement or how to achieve this improvement. Without clear guidance or examples, the authors may struggle to understand and address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there is room to improve the complexity of Algorithm 2, which is a relevant observation. However, it lacks specificity and does not provide any guidance or suggestions on how to achieve this improvement. Without actionable advice or examples, the authors are left without a clear path to follow, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning language-related tasks. It also provides a rationale for why expected test loss might not be as meaningful for language-related tasks. However, the comment does not explicitly instruct the authors to include these results or provide guidance on how to incorporate them into the paper. While the suggestion is clear, the lack of concrete steps or detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results in other modalities, specifically mentioning language-related tasks. It also provides a rationale for why expected test loss might not be as meaningful for language-related tasks. However, the comment does not specify which part of the paper should include these results or how they should be integrated. While the authors might have an idea of where to include these results, the lack of explicit guidance makes it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, but the lack of grounding makes it challenging for the authors to pinpoint the exact section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning language-related tasks. The comment provides a rationale for why expected test loss might not be as meaningful for language-related tasks, suggesting that people care more about OOD performance. However, the comment lacks specific examples or references to support the claim that expected test loss is not as relevant for language-related tasks. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include results in other modalities, specifically mentioning language-related tasks. It provides a rationale for why expected test loss might not be as meaningful for language-related tasks, suggesting that people care more about OOD performance. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a logical basis for the suggestion. However, the comment could be more helpful if it offered specific guidance on how to incorporate these results or what aspects of OOD performance should be prioritized. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"few-shot\" in graph link prediction. It highlights the importance of considering how to effectively use \"few-shot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment implies that the authors should provide more detailed justification for their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"few-shot situation for graph link prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not consider how to effectively use \"few-shot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"few-shot\" in graph link prediction. The reviewer suggests that the paper does not consider how to effectively use \"few-shot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment identifies a potential gap in the paper, it lacks specific examples or references to support the claim that the method does not effectively use \"few-shot.\" This makes the claim somewhat verifiable, as the authors would need to further develop the reasoning to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the motivation of the work, specifically in the context of few-shot learning. It points out that the paper defines a few-shot situation for graph link prediction but does not consider how to effectively use the concept of \"few-shot\" or how to ensure the trained model can generalize well to new tasks with 0/few training steps. This feedback is valuable as it highlights a gap in the paper that could impact its impact and relevance. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how other works have effectively leveraged the \"few-shot\" concept. Despite this, the comment still offers a clear direction for the authors to improve their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community's work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not provide explicit guidance on how the authors should address this critique or improve their approach. It lacks actionable details, such as recommending specific ways to enhance the novelty or suggesting alternative approaches. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\\'s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not specify which part of the paper discusses the use of GP, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where GP is discussed, the comment lacks full grounding. It is specific in detailing the critique of the approach, but without explicit references to the paper sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of Gaussian Processes (GP) is straightforward and naive, suggesting that the approach is not novel. The reviewer supports this claim by referencing the community\\'s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. This reference provides a basis for the claim, but it does not offer detailed reasoning or examples to fully substantiate the critique. The authors might need to explore the literature further to understand the specific aspects of the critique. Therefore, the comment is somewhat verifiable, as it provides some support but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\\'s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. While the comment identifies a potential weakness in the paper\\'s contribution, it lacks specific guidance on how the authors might address this critique or improve their approach. It does not provide actionable suggestions or examples of how to enhance the novelty or innovation of the work. As a result, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the statement in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. It points out that this claim is not supported by the authors\\' experience, as evidenced by the training of 1500-dimensional LSTMs on PTB. The reviewer also asks about the application of dropout to both embeddings and hidden states. While the comment identifies a specific issue with the statement, it does not provide explicit guidance on how to address it or what changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and provide evidence or clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the supplemental section D.4, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that smaller architectures are necessary for LM compared to GAN models, suggesting that the baseline models are not properly regularized. The reviewer also asks about the application of dropout to both embeddings and hidden states. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim made in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. The reviewer provides a counterexample by citing the training of 1500-dimensional LSTMs on PTB, suggesting that the baseline models are not properly regularized. This provides a logical and somewhat verifiable argument against the claim, as it challenges the basis of the statement. However, the comment could be strengthened by providing more detailed evidence or references to support the counterexample. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific claim in the supplemental section D.4 that is questionable, suggesting that the statement about smaller architectures being necessary for LM compared to GAN models is not supported by the authors\\' experience. The reviewer provides a counterexample by citing the training of 1500-dimensional LSTMs on PTB, which challenges the claim that baseline models are not properly regularized. Additionally, the comment asks about the application of dropout to both embeddings and hidden states, which could be a relevant area for clarification or discussion. While the comment identifies a potential weakness in the paper, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their analysis. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some of the ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly challenging to locate. The action is implicit and vague, as the authors are left to infer that they need to improve the clarity of the writing, but without concrete steps on how to achieve this. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"previous sections\" and \"the following contents,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the ablations being difficult to locate in the following contents, and it suggests that the writing could be improved in this part. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without specific examples or references, the claim lacks verifiability, making it challenging for the authors to understand and act upon the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. It suggests that the writing could be improved in this part, providing a clear and actionable suggestion for the authors to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it offered specific guidance on how to improve the writing or provided examples of how similar sections have been effectively written in other papers. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, which can significantly enhance the clarity and readability of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the differential privacy application is currently \"half-baked\" and encourages the authors to think through it more clearly. It also highlights the novelty of the online algorithm and robustness, which should be integrated into the main paper. However, the comment does not provide specific guidance on how to improve the differential privacy application or what aspects need more clarity. The feedback lacks concrete steps or detailed suggestions, leaving the authors uncertain about how to address the issues. As a result, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. It also mentions the online algorithm and robustness as being interesting and novel, and suggests that the experimental results in the appendix would be better in the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application, making it weakly grounded. The comment is specific in its critique of the differential privacy application and the suggestion to integrate the online algorithm and robustness into the main paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. However, the comment does not provide specific reasoning or examples to support this claim. It mentions the online algorithm and robustness as being interesting and novel, but this does not address the issue of the differential privacy application being \"half-baked.\" The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors may find it challenging to understand and address the issue without further explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the differential privacy application, suggesting that it is currently \"half-baked.\" It encourages the authors to think through it more clearly and integrate the online algorithm and robustness into the main paper. This feedback is somewhat helpful as it points out a specific area for improvement, but it lacks detailed guidance or suggestions on how to address the issue. The authors are given a general direction but may need to infer more specific steps to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-though. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their work. There is no explicit or implicit action for the authors to take, such as suggesting ways to enhance the contribution or providing examples of how to differentiate the two approaches. As a result, the comment lacks actionability and does not help the authors improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment compares the contribution of multilingual chain-of-thought to the villa chain-of-though, but it does not specify which part of the paper this comparison is made in. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered incremental or how the authors might address this issue. Without explicit references or detailed guidance, the authors cannot effectively understand or address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-though. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment compares the contribution of multilingual chain-of-thought to the villa chain-of-though, suggesting that the former is incremental. However, it does not provide any further explanation or guidance on how the authors might address this issue or improve their work. Without specific suggestions or examples, the comment lacks actionable feedback that could help the authors enhance their draft. Therefore, it is rated as barely helpful, as it identifies a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not provide explicit guidance on how to implement this change or what specific aspects of the methodology need to be adjusted. The action is implied and somewhat vague, as the authors need to infer that they should consider using robotic manipulation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to use robotic manipulation, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current methodology is insufficient or why robotic manipulation would be more appropriate. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that the proposed methodology may not be specific to bimanual manipulation. It recommends using robotic manipulation instead, which could be more appropriate. This feedback is somewhat helpful as it points out a potential limitation in the methodology and provides a suggestion for improvement. However, the comment lacks depth and does not explain why robotic manipulation is more appropriate or how it would address the issue. To be more helpful, the comment could provide additional context or examples to support the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include the METEOR results, which are reported in recent works. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment is specific and provides concrete guidance on how to implement the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the inclusion of METEOR results, which is a specific aspect of the paper. However, it does not specify which part of the paper should include these results, such as a specific section or table. This makes the comment weakly grounded, as the authors cannot confidently determine the exact location of the METEOR results in the paper. The comment is specific in its request for the inclusion of METEOR results, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include the METEOR results, which are reported in recent works. However, the comment does not provide any supporting evidence, references, or reasoning to justify why this inclusion is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include the METEOR results, which are reported in recent works. This is a clear and actionable suggestion that can help improve the paper by providing additional context and comparisons. However, the comment lacks depth and does not explain why the inclusion of these results is important or how they might enhance the paper. While it identifies a specific area for improvement, it could be more helpful if it provided more detailed guidance or justification for the inclusion of these results. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern regarding the comparability of G-effect values across various unlearning objectives and approaches. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting ways to improve the comparability of G-effect values or recommending specific analyses to be conducted. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of G-effect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the comparability of G-effect values across various unlearning objectives and approaches. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern regarding the comparability of G-effect values across various unlearning objectives and approaches. It points out that studying G-effects of each learning objective in isolation raises questions about the validity of these comparisons. This feedback is somewhat helpful as it highlights an area that the authors should consider addressing, but it lacks specific suggestions or guidance on how to improve the comparability of G-effect values. The authors are given a direction to explore, but the comment could be more actionable with additional details or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper, noting that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the authors should clarify why the method is not as effective in the 1-shot setting. The comment also praises the clarity and well-designed experiments, providing a clear direction for the authors to address the issue with UNIFORM in the 1-shot setting. The explicit request for clarification and the concrete suggestion to address the issue make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"tables\" and the \"1-shot setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in the advantage of UNIFORM over other procedures and the need for a theory to explain its effectiveness in the 1-shot setting. The comment also praises the clarity and well-designed experiments, providing a clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the authors should clarify why the method is not as effective in the 1-shot setting. The comment also praises the clarity and well-designed experiments, providing a positive assessment of the paper. However, the claim about the inconsistency in the advantage of UNIFORM is not fully substantiated by specific examples or detailed reasoning, making it somewhat verifiable. The authors would need to further explore the tables and data to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the authors should clarify why the method is not as effective in the 1-shot setting. Additionally, the comment praises the clarity and well-designed experiments, providing constructive feedback that can help the authors improve their draft. However, the comment could be more helpful if it offered specific suggestions on how to address the issue with UNIFORM in the 1-shot setting or provided examples of how other methods have successfully addressed similar challenges. Overall, the comment is mostly helpful as it highlights a potential weakness and provides actionable feedback on clarity and experimental design.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider the reason why information value is a stronger predictor for dialogue, specifically asking if there is any existing linguistic theory that could explain this phenomenon. The reviewer also suggests that adding this information would strengthen the paper. While the comment implies that the authors should explore this topic, it does not provide explicit instructions on how to do so or what specific linguistic theories to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain this phenomenon. The comment suggests that adding this information would strengthen the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the reason why information value is a stronger predictor for dialogue and suggests that existing linguistic theories could explain this phenomenon. However, the comment does not provide any supporting evidence, references, or logical reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by questioning the reason why information value is a stronger predictor for dialogue and suggests that existing linguistic theories could explain this phenomenon. This feedback is somewhat helpful as it prompts the authors to consider a deeper understanding of the underlying factors driving the results. However, the comment lacks specific guidance on how to explore this topic or what linguistic theories to consider, which limits its utility. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a perceived lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performance, specifically mentioning the extraction of hints for future network architecture design. It explicitly suggests that the authors should spend more time discussing these aspects, such as the biggest takeaways from the found architecture. This feedback provides a clear and concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of AutoML approaches and the potential benefits beyond raw performance, such as extracting hints for future network architecture design. It also specifies the issue by pointing out that the authors did not spend much time discussing these aspects, providing clear guidance on what needs to be addressed. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main reason for using AutoML approaches is not just improving raw performance but also extracting hints for future network architecture design. The reviewer suggests that the authors did not spend enough time discussing these aspects, such as the biggest takeaways from the found architecture. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the importance of these aspects and the potential benefits of discussing them, which may not be immediately clear without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of discussion on the potential benefits of using AutoML approaches beyond raw performance. It suggests that the authors should spend more time discussing these aspects, such as the extraction of hints for future network architecture design. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by addressing the potential benefits of their work. However, the comment could be more helpful if it offered specific examples or suggestions on how to discuss these aspects in more depth. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the paper where T_a(t) is used in Section 3.1 but only defined in Section 4. This is an explicit observation that the authors can directly address by providing the definition in the appropriate section. The comment is clear and concrete, as it specifies the exact issue and suggests a straightforward action to resolve it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the use of T_a(t) in Section 3.1 but only being defined in Section 4. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that T_a(t) is used in Section 3.1 but only defined in Section 4. This is a factual observation that does not require any subjective judgment or opinion. It is a statement of fact that can be verified by the authors themselves, as it is directly observable from the paper. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the paper regarding the use of T_a(t) in Section 3.1 but only being defined in Section 4. This is a clear and actionable observation that the authors can address to improve the consistency and clarity of their work. By pointing out this issue, the comment provides the authors with a specific area to focus on for revision, ensuring that the definition is in the appropriate section. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or completeness of the definition in Section 4. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While the action is implicit, it is clear that the authors need to revise the introduction to make it more concise and include empirical results. The comment provides a specific direction for improvement, but it lacks detailed guidance on how to achieve this concision or what specific empirical results should be included. Therefore, the action is somewhat actionable, as the authors know they need to make changes but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, it does not specify which part of the introduction is too long or where empirical results should be included. The authors can infer that the introduction and empirical results sections are being addressed, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, the comment does not provide any specific examples or reasoning to support why the current introduction is too long or how empirical results could enhance it. Without detailed guidance or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While it identifies a potential area for improvement, it lacks specific guidance on how to achieve this concision or what empirical results should be included. The comment provides a general direction for improvement but does not offer detailed suggestions or examples to help the authors effectively address the issue. As a result, the feedback is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those changes. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a confusion regarding the empirical analysis in Figure 3 and requests additional clarification on the adjustments made to the input series and forecasting target based on the Frequency Stability score. It also asks for an explanation of why these adjustments enhance the model's performance. While the comment provides a clear direction for the authors to provide additional clarification and explanation, it does not specify how to implement these changes or what specific details should be included. The action is explicit but somewhat vague in terms of execution, as the authors know what needs to be addressed but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the confusion regarding the empirical analysis and the adjustments made to the input series and forecasting target based on the Frequency Stability score. The comment also asks for clarification on why these adjustments enhance the model's performance and provides a reference to a related work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the empirical analysis in Figure 3, specifically questioning the adjustments made to the input series and forecasting target based on the Frequency Stability score. The reviewer requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also references a specific work by Liu et al. (2022) to provide context. While the comment identifies a potential issue and seeks clarification, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a starting point for the authors to address the issue but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the empirical analysis presented in Figure 3, noting that the adjustments to the input series and forecasting target based on the Frequency Stability score are not clearly explained. It requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also points out that Equations (9) and (10) have large spacing from the preceding text, which could be improved. While the comment provides clear guidance on what needs to be clarified and improved, it could be more helpful if it offered specific suggestions on how to present this information or what aspects of the analysis are particularly confusing. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the recent related work, CoCoOp, should be compared in the experiments. This is a clear and direct action for the authors to take, as it provides a specific recommendation for inclusion in the experiments. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the recent work \"CoCoOp\" and its relation to the experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of CoCoOp in the experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the recent work \"CoCoOp\" should be compared in the experiments, as it is an extended version of CoOp and was published after the NeurIPS deadline. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that the recent work \"CoCoOp\" is not compared in the experiments. This is a clear and actionable point, as it highlights a gap in the experimental analysis that could enhance the paper\\'s comprehensiveness and relevance. By suggesting the inclusion of CoCoOp, the comment provides a direct and constructive suggestion for improvement. However, it could be more helpful if it offered additional context or rationale for why CoCoOp is important to compare, or if it suggested specific ways to integrate it into the experiments. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, automatic scoring, and where model training is used to optimize the selection modules. While the comment provides a clear and specific action to take, it does not offer detailed guidance on how to improve the figure or what specific elements should be included. The authors are given a general direction but may need to infer the exact steps to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved in the figure, including suggestions for showing the processing pipeline, prompt generation, manual check, demonstration selection, ground truth scores, automatic scoring, and model training. This level of detail provides the authors with clear direction on how to enhance the figure. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, automatic scoring, and model training. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these elements are necessary or how they would enhance the figure. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on how to improve the clarity and presentation of Fig. 1. It suggests adding elements such as prompt generation and manual check, demonstration selection with ground truth scores, automatic scoring, and model training to the figure. This detailed guidance helps the authors understand what aspects of the processing pipeline need to be highlighted and how to present them effectively. By addressing these suggestions, the authors can enhance the clarity and comprehensibility of their figure, which is valuable for improving the overall quality of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of huge inputs for the value and policy function. While the comment implies that the authors should conduct additional experiments, it does not provide explicit instructions on which specific games or complex problems to test. The action is clear but lacks concrete details on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, specifically mentioning that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the author should consider testing ReBeL on games with larger depth to address the issue of huge inputs for the value and policy function. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems, specifically mentioning the issue of huge inputs for the value and policy function. However, the comment lacks specific examples or references to support the claim that these complex problems are necessary for testing ReBeL. Without detailed evidence or reasoning, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the issue without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of huge inputs for the value and policy function. While the comment highlights an important area for improvement, it lacks specific guidance on which complex games or problems to test or how to implement these tests. This limits the comment\\'s helpfulness, as it provides a direction for improvement but does not offer detailed instructions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to remove abbreviations like \"MoCo\" from section headers, as they might not be familiar to readers. This is a clear and direct action that the authors can take to improve the clarity of their draft. The comment provides concrete guidance on what to remove, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of abbreviations like \"MoCo\" in section headers. This provides clear guidance on what the authors need to change to improve the clarity of their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment suggests that abbreviations like \"MoCo\" should not appear in section headers because readers might not know what they mean. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the reader\\'s understanding. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to improve the clarity of the paper. By pointing out that abbreviations like \"MoCo\" should not appear in section headers, the reviewer highlights a potential source of confusion for readers who might not be familiar with the term. This feedback is clear and direct, offering a straightforward way for the authors to enhance the accessibility of their work. However, the comment could be more helpful if it provided additional context or examples of how this change would improve the clarity of the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors could clarify the technical contribution or make the analysis more novel. There is no explicit or implicit action for the authors to take, such as suggesting new analyses or methods to differentiate their work. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are unclear or where the analysis is standard. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need clarification or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide specific examples or detailed feedback on how the authors could clarify the technical contribution or make the analysis more novel. Without actionable suggestions or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not provide specific guidance on what kind of evidence or arguments would be sufficient or how the authors should present them. The action is implicit and somewhat vague, as the authors can infer that they need to provide more substantial evidence or arguments but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper\\'s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not specify which part of the paper discusses this advancement or where the authors should provide additional evidence or arguments. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment is specific in suggesting the need for more substantial evidence or arguments, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s primary contribution is an incremental advancement in efficiency over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s contribution, suggesting that the primary contribution is an incremental advancement in efficiency over the TACTiS approach. It acknowledges the need for more substantial evidence or arguments to establish this as a significant contribution to the field. However, the comment does not provide specific guidance on what kind of evidence or arguments would be sufficient or how the authors might present them. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities is incremental and does not provide a clear direction for improvement. However, the comment does not offer specific guidance on how to address these concerns or what additional aspects could be explored to enhance the novelty of the paper. The lack of explicit suggestions or concrete actions makes it difficult for the authors to know how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, it does not specify which datasets or parts of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas needing attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the novelty could be enhanced. Without clear guidance on what needs to be addressed, the authors cannot effectively improve their draft. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities seems incremental and does not provide a clear direction for improvement. However, the comment lacks specificity and actionable suggestions on how to address these concerns or what additional aspects could be explored to enhance the novelty of the paper. Without specific guidance or examples, the authors may find it challenging to understand and implement the feedback effectively. Therefore, the comment is rated as barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a discussion on this topic, but it does not specify what aspects of the discussion should be included or how it should be structured. As a result, the action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspects of the theoretical guarantee are missing or how the authors should address this issue. The comment is specific in identifying the lack of discussion but lacks detailed guidance on how to improve it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks discussion, specifically the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a relevant point that could enhance the paper\\'s theoretical foundation and provide additional insights to readers. However, the comment does not offer suggestions or guidance on how the authors might address this gap in the discussion. While it highlights an important area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate quantitative measures or what specific metrics should be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to include quantitative measures but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"generated VCEs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a quantitative measure to evaluate the generated VCEs, and notes that evaluation is mainly performed with visual inspection. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by noting the lack of quantitative measures to evaluate the generated VCEs. It highlights that the evaluation is mainly performed with visual inspection, which is a relevant point for the authors to consider. However, the comment does not provide detailed guidance on how to incorporate quantitative measures or what specific metrics should be used. While it points out a weakness, it lacks actionable suggestions or examples that would help the authors address the issue effectively. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the method only provides marginal improvements over baselines, with most improvements within the error bar range. It also notes that the authors claim the method performs better than the baselines, but the high error range suggests that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance of their method. The action is implicit and vague, as the authors are left to infer that they need to improve the performance of their method, but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance of the method compared to baselines, suggesting that the improvements are marginal and within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the high error range suggests otherwise. However, the comment does not specify which part of the paper discusses these claims or where the performance comparisons are made, making it weakly grounded. The comment is specific in its critique of the performance improvements and the high error range, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method provides only marginal improvements over baselines, with most improvements within the error bar range. It also suggests that the authors\\' claims of better performance are not supported by the high error range, implying that the performance differences are not significant. The comment provides some logical reasoning by pointing out the high error range, but it lacks specific examples or references to support the claim that the performance differences are not significant. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the method provides only marginal improvements over baselines, with most improvements within the error bar range. It challenges the authors\\' claim of better performance by pointing out the high error range, suggesting that the performance differences between methods are not very significant. This feedback is valuable as it highlights a potential weakness in the paper\\'s claims and encourages the authors to reconsider their evaluation of the method\\'s performance. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or improve the evaluation of their method. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights issues with the generated videos, specifically noting artifacts and questioning the action recognition performance compared to state-of-the-art methods. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it guide the authors on how to address the issues or improve the quality of the videos. As a result, the comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the generated videos, specifically mentioning artifacts and the action recognition performance on the UCF dataset. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment does provide some specificity by questioning the action recognition performance compared to state-of-the-art methods, but it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generated videos have significant artifacts and questions the action recognition performance compared to state-of-the-art methods. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide evidence or references to substantiate the claims, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the generated videos, noting that they have significant artifacts and questioning the action recognition performance compared to state-of-the-art methods. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or constructive advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a problem but does not offer meaningful assistance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how to make the proposed evaluation set more diverse and representative than the previous method and how to select representative images. However, it does not provide any explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should provide more details or examples, but it does not specify what those details or examples should be. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of diversity and representation in the proposed evaluation set, specifically mentioning the need for more diverse and representative images. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as how to make the evaluation set more diverse and representative, and how to select representative images. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed evaluation set is unclear in terms of diversity and representation, and that the authors need to provide more details on how to select representative images. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without concrete evidence or reasoning, the claim is not verifiable, as it does not provide a clear path for improvement. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the proposed evaluation set, specifically the lack of clarity on how to make it more diverse and representative than the previous method and how to select representative images. This feedback is valuable as it highlights a key area where the authors need to provide more detailed information or examples to ensure the validity and reliability of their evaluation. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues, such as recommending specific criteria or methods for selecting representative images. Overall, the comment is somewhat helpful as it points out a significant gap in the paper but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also suggests providing a brief overview of the original DPO algorithm to help distinguish the modifications proposed in the methods section. These actions are clear and concrete, as they specify exactly what needs to be added to the paper. The authors know exactly how to apply these suggestions to improve the clarity and comprehensibility of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, and suggests providing a brief overview of the original DPO algorithm. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be included to improve the clarity and comprehensibility of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This claim is somewhat verifiable as it logically suggests that a background section would enhance the clarity and comprehensibility of the paper. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting the inclusion of a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This feedback is valuable as it directly addresses the need for a more comprehensive introduction to the RL context, which can significantly improve the clarity and accessibility of the paper. By addressing these points, the authors can enhance the reader\\'s understanding and engagement with their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the method to accommodate continuous language addition. The comment lacks actionable guidance or specific steps for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a potential limitation of the proposed method, specifically the issue of handling continuous addition of new languages due to the limited model capacity. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the method, but without explicit references to sections or details, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may encounter a limitation due to the limited model capacity when users continuously add new languages. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. This is a relevant point that could impact the scalability and practicality of the method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or improve the method to accommodate continuous language addition. Without actionable advice or detailed feedback, the comment offers some insight but does not fully support the authors in improving their draft. Therefore, it is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017). While it does not explicitly instruct the authors to make changes or provide additional context, it implies that the authors should consider the relevance of this term in the context of their work. The action is implicit but clear, as the authors can infer that they need to address this question to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relevance of the term \"interpretable\" to the work of Doshi-Velez and Kim (2017). While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or constructive advice, making it barely helpful for the authors in terms of improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the experiments are limited to MNIST and a single real-world dataset, suggesting that the authors should consider expanding their experiments to include more datasets. However, it does not provide specific guidance on which additional datasets should be considered or how to implement this expansion. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment points out that the experiments are limited to MNIST and a single real-world dataset, but it does not specify which part of the paper this limitation is discussed in. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. However, it is specific in identifying the issue of limited datasets being used for experiments. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to MNIST and a single real-world dataset. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the validity or applicability of the experiments. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a limitation in the experiments, specifically that they are limited to MNIST and a single real-world dataset. This feedback highlights an area where the authors could potentially expand their experiments to include a more diverse set of datasets, which could enhance the generalizability and applicability of their results. However, the comment does not provide specific suggestions on which datasets to include or how to address this limitation. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The comment implies that the authors should provide more information about the parameters and their relationship to the kernel height/width and depth, but it lacks concrete steps or examples to follow. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. The comment provides a clear direction for the authors to address the issue of parameter count and efficiency, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of parameters should be a concern or how it relates to the efficiency improvements. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the S2D structure regarding the number of parameters and suggests that more details are expected regarding the efficiency improvements. It acknowledges that the FLOP is quadratic on the activation side length but points out that the number of parameters could increase due to the depth of the structure. This feedback is somewhat helpful as it highlights an area where the authors could provide more detailed explanations or analysis to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what additional details should be included. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or differentiate their method from [10]. The comment lacks actionable details, such as recommending specific modifications or discussions to be included in the paper. As a result, the authors are left without clear direction on how to respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"approach in [10],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the approach in [10] cannot use the additional information, such as scoring causal predictions and interventional data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comparison or address the concern effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. It questions why [10] cannot use these side information. While the comment identifies a potential issue with the originality of the proposed method, it does not provide specific suggestions or guidance on how the authors might address this concern or differentiate their work from [10]. The feedback lacks actionable advice or detailed analysis, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results from the Atari game are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the interpretability of their results. There is no guidance on whether they should expand the experiment to include more games or baselines, or how they might present their findings more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the results section, specifically the Atari game result being limited to a single game and a single baseline. This observation highlights a potential issue with the interpretability of the results, which is important for the authors to address. However, the comment does not provide specific suggestions or guidance on how to improve the interpretability or expand the experiment to include more games or baselines. While it points out a weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This implies that the model may not be incentivized to use fewer factors, leading to increased computation with more tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to implement a sparsity constraint. The action is implicit and somewhat vague, as the authors can infer that they need to consider adding a sparsity constraint but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"factorized model with an IBP prior,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which leads to increased computation with more tasks. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which leads to increased computation with more tasks. The comment provides a logical reasoning by explaining the consequences of not having a sparsity constraint, but it does not provide specific examples or references to support the claim. The authors might need to infer the impact of this constraint on the model\\'s performance, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This observation highlights a potential limitation of the model, which could lead to increased computation with more tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or implement a sparsity constraint. While it points out a relevant concern, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that the GPC's superior performance is due to the bandit feedback and not the form of the cost function. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be addressed in the paper. The comment is highly actionable as it offers a specific suggestion for improvement, making it easy for the authors to apply the feedback to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comment, which is that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). The comment provides a clear suggestion for improvement by recommending that the authors reiterate the reason for the GPC's superior performance, which is due to the bandit feedback and not the form of the cost function. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation of the simulation study does not provide a favorable comparison between the GPC (benchmark) and BPC (the authors\\' method). It suggests that the GPC performs better due to bandit feedback and not the form of the cost function. The comment provides a logical reasoning by explaining the potential cause of the GPC\\'s superior performance. However, it lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a reasonable explanation but could be further substantiated with additional evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that the GPC\\'s superior performance is due to the bandit feedback and not the form of the cost function. This feedback is clear and actionable, as it provides a concrete suggestion for improvement by directing the authors to clarify their explanation of the results. By addressing this point, the authors can enhance the clarity and comprehensiveness of their presentation, which is valuable for improving the draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep at the time, to provide context. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim. While it implies that the authors should provide more detailed information or examples, it lacks concrete guidance on what specific aspects to address or how to present the information. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks.\" It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in suggesting that quantifying and clarifying the claim could be beneficial. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. This reference provides some context for the claim but does not offer detailed evidence or specific examples to support the assertion that ReLUs do not work well in deep or convolutional networks. The comment is somewhat verifiable, as it provides a logical basis for the claim but lacks detailed evidence or specific examples to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be beneficial. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. This reference provides some context for the claim but does not offer specific guidance or suggestions on how to quantify or clarify the claim. While it points out a potential area for improvement, the comment lacks actionable advice or detailed feedback that would help the authors address the issue. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not provide enough guidance for the authors to fully understand and address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. It implies that the authors should provide more information about the calculation method or clarify the discrepancy between the reported perplexities and the better BLEU scores. While the comment does not explicitly instruct the authors to provide this information, it clearly points out a potential issue that needs to be addressed. Therefore, the comment is mostly actionable, as it provides a clear direction for improvement but lacks explicit instructions.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reported perplexities, which are over 30, and asks for clarification on how they were calculated. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reported perplexities in Figure 1, which are over 30, and suggests that this high perplexity contradicts better BLEU scores. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the overall quality of the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. This is a relevant observation that could impact the interpretation and validity of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their methodology. While it points out a potential problem, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the evaluation should include experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, specifying exactly what additional experiments are needed to improve the draft. The comment is specific and concrete, giving the authors a clear path to enhance their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for additional experiments, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or examples to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is somewhat helpful as it identifies a potential area for improvement in the evaluation section. However, it lacks specific guidance on how to conduct these experiments or what aspects of the evaluation would be enhanced by including them. The comment could be more helpful if it provided suggestions on how to design and implement these experiments, or how they would impact the overall evaluation. As it stands, the feedback provides a general direction for improvement but does not offer detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the authors need to elaborate on the importance of rooted patterns and how they choose the roots. It suggests that a brief discussion is expected or, if non-rooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback provides clear and concrete actions for the authors to take, such as elaborating on the importance of rooted patterns or discussing non-rooted patterns in the supplementary material. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the concept of \"rooted patterns\" and how they are defined, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of elaboration on why rooted patterns are important and how they are chosen. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not elaborate on the importance of rooted patterns or how they choose the roots. It suggests that a brief discussion is expected or, if non-rooted patterns are sufficient, that the discussion should be moved to the supplementary material. The comment provides a logical reasoning for the need to clarify these aspects, but it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors need to provide more detail or clarification. It points out that the concept of rooted patterns is defined in a similar way to orbit counting in GSN, but it does not elaborate on why rooted patterns are important or how they are chosen. The comment suggests that a brief discussion is expected or, if non-rooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and completeness of their explanation. However, it could be more helpful if it provided specific suggestions on how to elaborate on the importance of rooted patterns or how to choose the roots. Overall, the comment is mostly helpful as it directs the authors to a critical area needing further explanation and provides a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more explanations on the consistency between training and inference, specifically mentioning lines 95-97 and 308-310. While the comment implies that the authors should elaborate on the smoothness of neural models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue, which is the lack of explanation regarding the consistency between training and inference due to the smoothness of neural models. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks explanations regarding the consistency between training and inference due to the smoothness of neural models. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it overly emphasizes the consistency between training and inference due to the smoothness of neural models. It suggests that the authors should provide more explanations on this topic, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific examples or guidance on what kind of explanations would be beneficial. Overall, the feedback is somewhat helpful as it points out a potential weakness and offers a direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the authors\\' claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It asks for clarification on whether the proposed model improves with larger word embedding and LSTM parameters. While the comment implies that the authors should provide evidence or experiments to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional experiments or evidence to substantiate their claim. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about superior performance with fewer parameters, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the authors have tested the model with standard parameter settings in the baseline model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. The reviewer requests evidence or experiments to support the claim, indicating a need for further clarification. However, the comment lacks specific examples or references to support the claim or to substantiate the suggestion for additional experiments. This makes the claim somewhat verifiable, as it provides a logical basis for questioning the claim but requires more detailed evidence or reasoning to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the authors\\' claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It questions whether the proposed model actually improves with larger word embedding and LSTM parameters, which is a crucial aspect of the paper\\'s contribution. This feedback is somewhat helpful as it prompts the authors to provide evidence or experiments to substantiate their claim, which could strengthen the paper\\'s argument. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what kind of experiments to conduct. Overall, the comment is somewhat helpful as it points out a potential weakness in the paper but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure the availability of the environment or a good OPE method. The action is implicit and somewhat vague, as the authors can infer that they need to consider these factors but are not given concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the finetuning is mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these hyperparameters are introduced, the comment lacks full grounding. It is specific about the issue of finetuning and the dependence on the environment or OPE method, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of two additional hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim remains unverifiable, as it does not provide sufficient justification for the authors to make improvements. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. This feedback is somewhat helpful as it points out a potential problem that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to ensure the availability of the environment or a good OPE method. Without actionable advice or detailed explanation, the authors may struggle to fully understand and address the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy in the authors\\' approach to regularization, noting that they apply regularization to both LN models and GLMs, while the GLM by Pillow et al. did not crop the image. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. While the comment identifies an issue and provides a suggestion for improvement, it does not offer specific guidance on how to implement this suggestion or what specific features should be reproduced. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"LN model\" and \"GLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the application of regularization, suggesting that the authors should try to reproduce the main features of previous models. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors apply regularization to both LN models and GLMs, which is not consistent with the GLM by Pillow et al. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. However, the comment lacks specific examples or references to support the claim that the GLM by Pillow et al. did not crop the image. Without these details, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the authors\\' approach to regularization, noting that they apply regularization to both LN models and GLMs, while the GLM by Pillow et al. did not crop the image but used L1 regularization for the filters and a low-rank approximation to the spatial filter. The comment suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. While the feedback highlights an important issue, it lacks specific guidance on how to address it or what specific features should be reproduced. The authors are left with a general direction but no detailed steps to follow, making the comment somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the paper should include failure cases and related discussions. While it implies that the authors should add this content, it does not provide specific guidance on how to structure or present these cases or discussions. The action is implicit and somewhat vague, as the authors need to infer that they should include these elements but are not given detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include failure cases and related discussions. However, it does not specify which part of the paper should include these elements, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact areas that need attention. Additionally, the comment lacks specificity regarding what kind of failure cases or discussions should be included, leaving the authors with a general suggestion without detailed guidance. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that including failure cases and related discussions would be beneficial. However, it does not provide any reasoning, examples, or references to support why this addition would be valuable or how it would enhance the paper. Without specific justification or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper should include failure cases and related discussions, which could provide valuable insights into the limitations and robustness of the work. However, it lacks specificity and does not offer guidance on how to structure or present these cases or discussions. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not provide actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that an ablation study on the necessity of the base layer GNN encoding would be helpful. This provides a clear and direct action for the authors to take, which is to conduct an ablation study to understand the role of the base layer GNN encoding in the proposed method. The comment is specific in its request, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"base layer GNN encoding\" in the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the necessity of the base layer GNN encoding and the need for an ablation study. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to understand its role. However, the comment does not provide specific reasoning or evidence to support why the base layer GNN encoding is unnecessary or how an ablation study would benefit the paper. Without detailed justification or examples, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the suggestion without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the necessity of the base layer GNN encoding in the proposed method. It suggests conducting an ablation study to understand the role of this layer and its impact on the overall performance. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to improve their draft by conducting an ablation study. By addressing this point, the authors can enhance the clarity and robustness of their methodology. However, the comment could be more helpful if it included specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a discrepancy in the use of \\u03b4 in equations (10) and (11) and suggests introducing \\u03b4 when (11) is discussed. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve the draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"equation (10)\" and \"equation (11),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistent use of \\u03b4 in equations (10) and (11) and suggests introducing \\u03b4 when (11) is discussed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \\u03b4 is not used in equation (10) but is used in equation (11). This is a factual observation that does not require verification or justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper regarding the inconsistent use of \\u03b4 in equations (10) and (11). It suggests that introducing \\u03b4 when (11) is discussed might improve clarity. This feedback is clear and actionable, as it provides a concrete suggestion for improving the draft by ensuring consistency in the notation used. However, the comment could be more helpful if it explained why this inconsistency is problematic or how it affects the reader\\'s understanding. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explicitly add the upper bounds of counting homomorphisms and potentially elaborate on empirical runtimes. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is specific in detailing what needs to be added and how it could enhance the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the computational complexity of counting homomorphisms, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, providing a specific example of a brief statement made in the paper. The reviewer suggests that the paper should explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. This claim is somewhat verifiable as it provides a specific example of an issue with the discussion of computational complexity, but it lacks detailed reasoning or references to support the need for explicit bounds or elaboration on empirical runtimes. The authors would need to make a significant effort to understand and address the issue, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors have not adequately discussed the computational complexity of counting homomorphisms. It points out that the paper makes brief statements without providing explicit bounds or elaboration on empirical runtimes. The comment suggests that adding these details would be beneficial for the paper. While it highlights an important area for improvement, it does not provide detailed guidance on how to implement these changes or what specific aspects of the computational complexity should be addressed. This limits the comment\\'s helpfulness, as it offers a clear direction but lacks actionable steps. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a typographical error in the first \"f\" in \"we fixed the form of\" and an extra period in a sentence. It also poses a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. While the comment provides specific corrections and a question, it does not offer guidance on how to address the question or improve the paper. The action is clear but lacks detailed instructions on how to implement the corrections or respond to the question. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (108 and 115), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the typographical errors in these lines and raises a question about the baseline MCL with deep learning. The comment provides clear guidance on what needs to be corrected and offers a question for further exploration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual corrections and a question about the baseline MCL with deep learning. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies specific typographical errors in the manuscript, which are important to correct for accuracy. Additionally, it raises a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. This question is relevant and could prompt the authors to provide more detailed explanations or evidence regarding the convergence of their networks. However, the comment could be more helpful if it offered suggestions on how to address the convergence issue or provided examples of best practices. Overall, the feedback is actionable and provides valuable insights, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. The reviewer implies that this comparison could be valuable and provides a clear direction for the authors to consider. However, the comment does not explicitly instruct the authors to conduct this study or specify how to conduct it. While the action is implied, it is not as concrete as it could be, as the authors may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests studying the inference time of the pose estimation method, which is a direct method that does not require detection or keypoint grouping. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a comparison with previous top-down and bottom-up pose estimation methods, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. The reviewer provides a logical reasoning by stating that this comparison could be valuable, as it would demonstrate the efficiency of the method compared to previous top-down and bottom-up pose estimation methods. However, the comment lacks specific examples or references to support the claim that this comparison would be beneficial. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. This is a valuable suggestion as it could provide insight into the efficiency of the method compared to other top-down and bottom-up pose estimation methods. However, the comment lacks specific guidance on how to conduct this study or what aspects of the inference time should be analyzed. While it identifies a potential area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the proof in Theorem A.3, specifically regarding the input x having two indices when it is a vector. It also points out a potential error in the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors can infer that they need to clarify the input x and correct the equation, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential error in the proof regarding the input x having two indices when it is a vector, and it questions the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual observations and questions about the proof in Theorem A.3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue in the proof of Theorem A.3, pointing out that the input x is a vector, not a matrix, and questioning the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This feedback is clear and actionable, as it directs the authors to correct the input type and the equation, which could improve the accuracy and clarity of the proof. However, the comment could be more helpful if it provided additional context or explanation on why this correction is necessary or how it affects the overall understanding of the theorem. Overall, the comment is mostly helpful as it guides the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in section 4.3 and 4.4, questioning the effectiveness of beam search in ensuring the correctness of the results. It suggests that the reviewer is concerned about the reliability of the results, particularly when relationships and entities are replaced. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve the reliability of their results. The feedback lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, the comment is somewhat actionable, as it identifies an area of concern but does not offer clear steps for improvement.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4.3 and 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the effectiveness of beam search in ensuring the correctness of the results, particularly when relationships and entities are replaced. The comment further raises concerns about the reliability of the results and suggests that the reviewer is concerned about the plugged-in entities/relationships being the correct ones. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the effectiveness of beam search in ensuring the correctness of the results, particularly when relationships and entities are replaced. It questions the reliability of the results and suggests that the reviewer is concerned about the plugged-in entities/relationships being the correct ones. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the reviewer\\'s concerns. The lack of detailed evidence or reasoning makes the claim somewhat verifiable, as it requires further elaboration for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the effectiveness of beam search in ensuring the correctness of the results, particularly when relationships and entities are replaced. It questions the reliability of the results and suggests that the reviewer is concerned about the plugged-in entities/relationships being the correct ones. This feedback is valuable as it highlights a potential weakness in the paper\\'s methodology and suggests a direction for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these concerns or improve the reliability of their results. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the claim about evolutional dropout and its limitations in addressing internal covariate shift. It suggests that the authors should explicitly discuss these limitations, particularly regarding batch normalization. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to discuss these limitations or what aspects should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the limitations but may not be entirely sure of the exact details to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about evolutional dropout and its limitations in addressing internal covariate shift. It also specifies the issue with batch normalization, which standardizes the variance and centers the activation. This provides clear guidance on what needs to be addressed in the paper. However, the comment could be more specific by suggesting how the authors should discuss these limitations or what aspects should be emphasized. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, as it can only increase the variance of some low-variance units. The reviewer supports this claim by comparing it to batch normalization, which standardizes the variance and centers the activation. However, the comment lacks specific examples or references to substantiate the claim fully. While it provides a logical reasoning, it could be strengthened with more detailed evidence or examples to fully support the assertion. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the claim about evolutional dropout addressing internal covariate shift. It suggests that the claim is limited because it can only increase the variance of some low-variance units, and it contrasts this with batch normalization, which standardizes the variance and centers the activation. The comment provides a clear and actionable suggestion for the authors to explicitly discuss these limitations in their paper. However, it could be more helpful if it offered specific guidance on how to discuss these limitations or what aspects should be emphasized. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the limitations of FedPCL due to its reliance on pre-trained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pre-trained models. However, the comment does not provide explicit guidance on how the authors should further improve their work or what specific aspects of the framework should be refined. It lacks actionable details, such as suggestions for additional experiments or modifications to the framework. As a result, the authors are left without clear direction on how to enhance their draft based on this feedback. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of FedPCL, which relies heavily on pre-trained models, and how the authors have addressed this limitation by developing a lightweight federated learning framework and integrating pre-trained models. This provides clear guidance on what needs to be improved or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of FedPCL is sensitive to the selection of pre-trained models, which limits its applications to more wide areas. The comment supports this claim by referencing Table 4, which shows the model accuracy is affected by the pre-trained models. However, the comment does not provide further details or examples to fully substantiate the claim, such as specific pre-trained models or detailed analysis of the sensitivity. While the reference to Table 4 provides some support, the comment could be strengthened with additional evidence or reasoning to fully verify the claim. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the limitations of FedPCL due to its reliance on pre-trained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pre-trained models. However, the comment lacks specific suggestions or guidance on how the authors could further improve their work or what aspects of the framework should be refined. It does not provide actionable feedback or detailed insights into potential enhancements, leaving the authors without clear direction on how to enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a limitation but does not offer detailed guidance for improvement, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include tentative attention maps in the qualitative figures to provide a more comprehensive understanding of the attention mechanism. While the comment implies that the authors should add these maps, it does not explicitly instruct them to do so. The action is concrete, as it specifies what additional information should be included, but it is somewhat vague because it does not provide detailed guidance on how to present these maps. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests including tentative attention maps in the qualitative figures, which implies that it relates to the visualization or discussion of the attention mechanism. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as specific figures or sections where the attention mechanism is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of tentative attention maps, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including tentative attention maps in the qualitative figures would be beneficial for understanding the attention mechanism. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be valuable or how it would enhance the understanding of the attention mechanism. Without such justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including tentative attention maps in the qualitative figures would enhance the understanding of the attention mechanism. This feedback is somewhat helpful as it identifies a potential area for improvement in the visualization of the attention mechanism. However, the comment lacks specific guidance on how to present these maps or what aspects of the attention mechanism should be highlighted. While it points out a potential enhancement, it does not provide detailed instructions or examples on how to implement this suggestion, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the author to add more description about the contribution of the paper. This is a clear and direct action, as it specifies what the authors need to do to improve their draft. The comment provides a specific suggestion for enhancing the paper\\'s clarity by adding more details about the contribution. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper this additional description should be added to, nor does it provide any guidance on what specific aspects of the contribution should be elaborated on. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need additional description. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any reasoning, evidence, or examples to support why this additional description is necessary or how it would enhance the paper. Without specific guidance or justification, the claim is not verifiable, as it lacks the necessary information to help the authors understand and address the feedback. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should add more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what aspects of the contribution should be elaborated on or how this additional description would enhance the paper. Without detailed suggestions or examples, the authors may find it challenging to understand and implement the feedback effectively. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit suggestions for improving the paper. First, it recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models. This action is clear and concrete, as it specifies where the information should be placed and how it should be organized. Second, it suggests referencing tricks like normalization or feature scaling in a separate section, which is also a clear and concrete action. Finally, it mentions that the description of the layer-wise attention mechanism is scattered across sections 2.3 and 2.4, providing a specific area for improvement. Overall, the comment is highly actionable as it provides clear and concrete steps for the authors to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections, \"2.3\" and \"2.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as describing the two types of attention for deep VAEs in a separate section and referencing tricks like normalization or feature scaling in a separate section. The comment also suggests reorganizing the description of the layer-wise attention mechanism. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides several suggestions for improvement, including describing the two types of attention for deep VAEs in a separate section, referencing tricks like normalization or feature scaling, and reorganizing the description of the layer-wise attention mechanism. These suggestions are based on logical reasoning and common practices in the field, but they do not include specific examples or references to support the claims. While the suggestions are clear, they lack detailed justification or evidence to fully substantiate the claims. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks the depth and evidence needed for full verifiability.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improving the paper. It recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models, which would help clarify the contributions of the paper. Additionally, it suggests referencing tricks like normalization or feature scaling in a separate section, which could improve the organization and accessibility of the paper. Finally, it points out that the description of the layer-wise attention mechanism is scattered across sections 2.3 and 2.4, suggesting a reorganization to improve clarity. These suggestions are clear and actionable, providing the authors with specific steps to enhance the clarity and organization of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the understanding of Figure 5 or the labels being incorrect. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific steps to take to improve the figure or labels. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper, such as Figure 5, is being addressed. It lacks specificity because it does not provide details on what is unclear or incorrect about the figure or labels. Without explicit references or detailed feedback, the authors cannot effectively identify the issues or make improvements. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that either the reviewer does not understand Figure 5 or the labels are incorrect. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the clarity or accuracy of Figure 5 or the labels used in the figure. However, it does not provide any specific guidance or suggestions on how to address this issue or improve the figure. Without detailed feedback or actionable advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of supervised baselines in the paper and suggests that it is reasonable to assume that full annotation is available for datasets of scale ~100k images. It also notes that even if this is not the case, having an informative baseline would be beneficial to show the performance of self-supervised methods compared to a fully supervised pre-trained network. While the comment implies that the authors should include supervised baselines, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to implement the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the absence of supervised baselines in the paper, specifically mentioning that most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. It suggests that including an informative baseline would be beneficial to show the performance of self-supervised methods compared to a fully supervised pre-trained network. However, the comment does not specify which part of the paper should include this baseline, such as the experimental section or the discussion. While the authors can infer that it relates to the experimental section, the comment lacks full grounding. It is specific about the need for a supervised baseline but does not provide detailed guidance on how to implement this suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the absence of supervised baselines is a significant issue, as most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. The reviewer suggests that including an informative baseline would be beneficial to show the performance of self-supervised methods compared to a fully supervised pre-trained network. This claim is somewhat verifiable as it provides a logical reasoning for the need of a supervised baseline, but it lacks specific examples or references to support the assertion that full annotation is available in practice. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, which are crucial for understanding the performance of self-supervised methods. It logically argues that since most experiments are conducted on datasets of scale ~100k images, it is reasonable to assume that full annotation is available in practice. The comment suggests that including an informative baseline would be beneficial to show the performance of self-supervised methods compared to a fully supervised pre-trained network. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental design and analysis. However, it could be more helpful if it included examples of suitable supervised baselines or detailed guidance on how to implement them. Overall, the comment is mostly helpful as it effectively highlights a critical area for improvement and offers a concrete suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. It also notes that the benchmarks used are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of minimal performance differences or how to update the benchmarks. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of performance differences between methods, noting that they are minimal across evaluations and often less than 1 percentage point. It also mentions that the benchmarks used are outdated and likely saturated, referencing specific works. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the issue of minimal performance differences and the need to update the benchmarks. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point, which may be due to random variation. The reviewer supports this claim by referencing the outdated and likely saturated benchmarks used. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some evidence, it could be strengthened with more detailed analysis or references to specific experiments or studies that support the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but could be more fully substantiated with additional details or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. This observation suggests that the methods may be overfitting or that the benchmarks are saturated. The comment also points out that the benchmarks used are outdated, which could impact the relevance and applicability of the results. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. Providing more detailed advice or examples on how to update the benchmarks or improve the performance evaluation would make the comment more actionable. Therefore, the comment is somewhat helpful, as it identifies a significant weakness but lacks depth in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the method and its applicability, suggesting that it may not be beneficial in certain domains due to deterministic dynamics. It also questions the absence of BEAR from baselines and suggests evaluating the method on non-deterministic domains. While the comment implies that the authors should address these questions and consider evaluating the method on different domains, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the method\\'s effectiveness on deterministic domains like Hopper, suggesting that it may not have much benefit. It also questions the absence of BEAR from baselines and suggests evaluating the method on non-deterministic domains. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the method\\'s applicability and the need for evaluation on non-deterministic domains. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the method\\'s effectiveness on deterministic domains like Hopper, suggesting that it may not have much benefit. It also questions the absence of BEAR from baselines and suggests evaluating the method on non-deterministic domains. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises several questions about the method\\'s effectiveness and applicability, particularly on deterministic domains like Hopper. It suggests that the method may not have much benefit in these domains and questions the absence of BEAR from baselines. Additionally, it recommends evaluating the method on non-deterministic domains to assess its empirical efficacy. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given a direction to consider, but the feedback could be more actionable with concrete steps or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide theoretical justification for why co-training and weight averaging can improve results. While the action is explicit, it lacks concrete guidance on how to present this justification or what specific aspects should be addressed. The authors are left to infer that they need to provide theoretical reasoning, but without detailed instructions on how to do so, the comment remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide theoretical justification for why co-training and weight averaging can improve results. However, it does not specify which part of the paper this justification should be provided in, nor does it provide details on what aspects of the results need justification. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in its request for theoretical justification but lacks grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide theoretical justification for why co-training and weight averaging can improve results. However, it does not provide any specific reasoning or evidence to support this claim. Without detailed explanation or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide theoretical justification for why co-training and weight averaging can improve results. This is a valid point as these techniques are important for performance, and theoretical justification can help the authors better understand and articulate their contributions. However, the comment lacks specific guidance on how to present this justification or what aspects of the results should be emphasized. While it identifies a potential area for improvement, it does not provide detailed instructions or examples on how to achieve it. Therefore, the comment is somewhat helpful, as it points out a need for theoretical justification but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. While the comment provides a clear and explicit action\u2014changing \"X\" to a multiset\u2014it does not offer detailed guidance on how to implement this change or what specific considerations should be taken into account. The action is concrete, but the lack of additional context or explanation makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the change from a set to a multiset in the context of representing graphs with repeated vertex or edge labels. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. The comment provides a logical reasoning based on the need to include multiplicities to ensure an honest representation of the graph. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors may need to further explore the rationale behind the suggestion, which could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the draft. It points out that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. This feedback is clear and constructive, as it directly addresses a potential issue with the paper\\'s representation of graphs. By making this change, the authors can significantly improve the accuracy and clarity of their results. Therefore, the comment is highly helpful, as it offers a clear and actionable path for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors\\' derivation is based on classical learning theory-based bounds, which are not realistic without Bayesian considerations. It suggests that the authors should consider Bayesian-PAC-based bounds to make their derivation more realistic. While the comment implies that the authors should incorporate Bayesian considerations, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to understand the implications of the suggestion and determine how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation, specifically mentioning that it is based on classical learning theory-based bounds. However, it does not specify which part of the paper this critique pertains to, such as a particular section or equation. The authors can infer that it relates to the derivation or theoretical aspects of the paper, but this inference is not direct. The comment also suggests that Bayesian considerations should be taken into account, but it does not provide specific examples or guidance on how to incorporate these considerations. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is under-specific in terms of detailing what needs to be addressed.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors\\' derivation is based on classical learning theory-based bounds, which are not realistic without Bayesian considerations. The reviewer supports this claim by suggesting that Bayesian-PAC-based bounds are more realistic. However, the comment lacks specific examples or references to classical learning theory-based bounds or Bayesian-PAC-based bounds, making it somewhat verifiable. The authors would need to infer the relevance of these concepts and explore them further to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' derivation, noting that it is based on classical learning theory-based bounds that are not realistic without Bayesian considerations. The reviewer suggests that the authors should consider Bayesian-PAC-based bounds to make their derivation more realistic. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting a particular approach to enhance the validity and applicability of the derivation. However, the comment could be more helpful if it included examples or references to Bayesian-PAC-based bounds or explained why these are more realistic. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or offer specific guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details but may not be entirely sure of the exact content or structure of these details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper these details should be added to, nor does it provide specific guidance on what aspects of the method should be elaborated on. While the authors might have an idea of where these details could be added, the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these details are necessary or how they would enhance the understanding of the method. Without such justification, the claim remains unverifiable, as it lacks the necessary information to support its claim. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment identifies areas for improvement, it lacks specific guidance or examples on how to present these details or what aspects of the method should be elaborated on. The feedback is somewhat helpful as it points out a potential gap in the paper, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed method's ability to detect hallucinations in open-ended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer suggests that the method might struggle to detect hallucinations due to the potential for different responses pertaining to different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the method. The action is implicit and somewhat vague, as the authors can infer that they need to consider this issue but are not given detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and the specific issue of detecting hallucinations in open-ended responses, such as the prompt \"introduce a sports celebrity to me.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the problem of detecting hallucinations in open-ended responses and the potential challenge of identifying shared information for consistency checking. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method might struggle to detect hallucinations in open-ended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer provides a logical reasoning by explaining that the sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. However, the comment lacks specific examples or references to support the claim, such as how the method might fail in detecting hallucinations or how it could be improved. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method\\'s ability to detect hallucinations in open-ended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" This highlights a specific challenge in detecting hallucinations due to the potential for different responses pertaining to different individuals, making it difficult to identify shared information for consistency checking. While the comment points out a potential weakness, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve their method. The feedback is somewhat helpful as it alerts the authors to a potential problem but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a real-world context. While the comment does not explicitly instruct the authors to conduct these experiments, it provides a clear direction for action. The authors know that they need to verify the conclusion, but the comment could be more explicit in suggesting specific experiments or methods to conduct these tests. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests verifying the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a real-world context. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need to verify the conclusion, but without explicit references to sections or experiments, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the theoretical findings are unclear in their relation to real-world deep learning models. It provides a specific suggestion to verify the conclusion about label noise and model size on MNIST and CNN. This claim is somewhat verifiable as it logically suggests that verifying these findings in real-world contexts would enhance the paper\\'s credibility. However, the comment lacks detailed reasoning or references to support the claim that these findings are unclear or unverified. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the theoretical findings and their relation to real-world deep learning models. It suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which could provide a valuable contribution to the paper. This feedback is clear and actionable, as it directs the authors to conduct additional experiments that could strengthen the paper\\'s claims. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it points out a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on the paper\\'s organization, writing, and content clarity. It suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, it questions the assumption that \"questions of all the wrong demonstrations fall into the same frequent-error cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. While the comment provides some guidance on potential areas for improvement, it does not offer concrete steps or examples on how to implement these improvements. The authors are left with a general idea of what needs to be addressed but without detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"writing\" and \"content clarity,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the weaknesses, such as the need for a table to compare different CoT prompting methods and the questionable assumption about the frequent-error cluster. Additionally, it raises questions about the selection criteria in section 4.2, providing specific feedback on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is well-organized and the writing is good, but it also identifies areas for improvement. The reviewer suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, the reviewer questions the assumption that \"questions of all the wrong demonstrations fall into the same frequent-error cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. These points are supported by logical reasoning and specific questions, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides both positive and negative feedback. The positive aspect is that the paper is well-organized and the writing is good, which is a clear indication that the authors have done a good job in presenting their work. However, the comment also identifies areas for improvement, specifically suggesting that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, it questions the assumption that \"questions of all the wrong demonstrations fall into the same frequent-error cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. These suggestions are clear and actionable, providing the authors with specific guidance on how to enhance their draft. While the comment could be more detailed in some areas, it offers valuable insights that can help the authors improve their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the probability distribution p(y|Hf(tn)) should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. It also mentions that this assumption is made in the ELBOs later in the paper. This feedback provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to address the issue. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the probability distribution \"p(y|Hf(tn))\" and the assumption that it should be Gaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the need to choose a Gaussian distribution for Kalman Filtering and Smoothing, and the assumption made in the ELBOs. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the probability distribution \"p(y|Hf(tn))\" should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. The comment provides a logical reasoning by stating that this assumption is made in the ELBOs later in the paper. However, it lacks specific references or examples to support the claim that this assumption is necessary or how it affects the analysis. While the reasoning is clear, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of probability distribution for the model, noting that the distribution should be Gaussian to enable Kalman Filtering, Smoothing, and CVI. It also points out that this assumption is already made in the ELBOs later in the paper. This feedback is clear and actionable, as it provides the authors with a specific direction for improvement by suggesting that they ensure the chosen probability distribution is Gaussian. However, the comment could be more helpful if it included suggestions on how to justify or explain the choice of Gaussian distribution or how it affects the analysis. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the use of suboptimally weight decay across all layers is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. It suggests that the lack of reporting cosine similarities for such large weight decay strengths and the ending of plots at a weight decay strength where cosine similarities are still close to optimal is convenient. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The authors are left to infer that they should report cosine similarities for larger weight decay strengths or adjust the plotting range to show the full range of cosine similarities. While the comment identifies an area for improvement, it lacks concrete details on how to implement the suggested changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of suboptimally weight decay across all layers, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of reporting cosine similarities for large weight decay strengths and the convenient ending of plots at a weight decay strength where cosine similarities are still close to optimal. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of suboptimally weight decay across all layers is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. The reviewer supports this claim by pointing out that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides a logical reasoning based on the expected behavior of weight decay and cosine similarities, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar studies that have observed similar effects. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the application of suboptimally weight decay across all layers, which is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. It points out that the lack of reporting cosine similarities for such large weight decay strengths and the convenient ending of plots at a weight decay strength where cosine similarities are still close to optimal. This feedback is clear and actionable, as it highlights a potential weakness in the paper that the authors can address by reporting cosine similarities for larger weight decay strengths or adjusting the plotting range to show the full range of cosine similarities. By providing this guidance, the comment offers valuable insights for improving the draft. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a serious omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. It suggests that this omission could lead to incorrect conclusions by casual readers. The reviewer implies that the authors should fix this issue, but does not provide specific guidance on how to do so. The comment is explicit in identifying the problem but lacks concrete details on how to address it. Therefore, the action is explicit but somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of not explaining that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions. The comment suggests that this must be fixed for publication, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This omission could lead to incorrect conclusions by casual readers. The reviewer suggests that this is a serious issue and implies that it should be addressed before publication. However, the comment does not provide specific examples or references to support the claim that this omission is a significant problem. While the claim is logical and somewhat supported by the mention of unsupervised random forests, it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires more detailed evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a serious omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This is a critical issue that could lead to incorrect conclusions by casual readers. The reviewer suggests that this omission must be fixed before publication, providing a clear and actionable piece of feedback. However, the comment could be more helpful if it offered suggestions on how to effectively communicate this information in the paper or provided examples of how similar omissions have been addressed in other works. Despite this, the comment is mostly helpful as it highlights a significant oversight and directs the authors to make a necessary correction.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of qualitative experiments to demonstrate the validity of the conditional independence model and suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcond-i over HSIC_HOOD. It also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics. The comment provides specific actions for the authors to take, such as providing experimental results and visualization or schematic diagrams. These are explicit and concrete suggestions, giving the authors clear guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of qualitative experiments to demonstrate the validity of the conditional independence model, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for illustrative experimental results to demonstrate the potential benefits of minimizing HSICcond-i over HSIC_HOOD and suggests using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcond-i over HSIC_HOOD. The comment also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. While the comment provides a logical reasoning for the need for additional experiments, it lacks specific examples or references to support the claim. The suggestion to use a toy dataset is a specific action, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, namely the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides a clear and actionable suggestion by recommending the inclusion of illustrative experimental results to demonstrate the potential benefits of minimizing HSICcond-i over HSIC_HOOD. The comment also suggests using a toy dataset to demonstrate the separability of inlier and outlier features, which is a valuable suggestion for improving the paper. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics, which is another area for improvement. While the comment could be more helpful by providing specific examples or guidance on how to conduct these experiments, it still offers valuable insights and actionable advice. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to compare the computational complexity of their proposed method with other methods. This request is clear and provides a specific action for the authors to take, which is to conduct a comparison. However, it does not specify which methods to compare with or how to conduct the comparison, leaving some room for interpretation. The action is explicit but somewhat vague in terms of execution, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"online version of the algorithm\" and the issue of training multiple iterations/epochs with large models and datasets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for a comparison of the computational complexity with other methods, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the proposed method requires more computation than other methods and requests a comparison of computational complexity. However, it does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to address the request effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the computational complexity of the proposed method compared to other methods. It prompts the authors to provide a comparison of computational complexity, which is an important aspect of evaluating the practicality of their approach. However, the comment lacks specific guidance on how to conduct this comparison or which methods to compare with. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \\u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides a clear direction for further analysis, it does not explicitly instruct the authors to conduct this study. The action is implicit but concrete, as it specifies what aspects of the analysis should be explored. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \\u03b1. However, the comment does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The comment is specific in detailing what aspects of the analysis should be explored, such as the roles between \"winners\" and \"cooperators\" and the potential impact of cost on collective return. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \\u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides logical reasoning and examples, it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the suggestion but could be strengthened with additional evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to conduct a systematic analysis of the impact of the cost of incentivization on performance. It offers a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \\u03b1. The comment also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. This feedback is highly valuable as it guides the authors to a specific area for further exploration and analysis, which could significantly enhance the paper. However, the comment could be more helpful if it provided additional details or examples on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is highly helpful as it offers a clear and actionable direction for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It points out a specific example from line 486 where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment provides a clear and explicit action for the authors to take, which is to conduct significance testing to support their claims. This guidance is concrete and leaves no ambiguity about what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out the lack of significance testing to support claims about the differences between methods. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors make significant claims about the differences between methods without conducting significance testing. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment is mostly verifiable as it provides a logical reasoning and a specific example to support the claim. However, it could be strengthened by referencing external works or studies that demonstrate the importance of significance testing in similar contexts. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT-4 significantly boosts translation quality and discourse awareness. The reviewer points out that without proper testing, it is difficult to determine whether these differences are significant. This feedback is clear and actionable, as it directs the authors to conduct significance testing to support their claims. By addressing this issue, the authors can significantly improve the rigor and credibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the approach description in Section 3 is difficult to follow and suggests revising it. It also suggests using the additional page of the camera-ready version to extend the approach description rather than adding more experiments. This provides clear and concrete guidance on what needs to be done to improve the draft. The authors know exactly what changes to make and how to implement them, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the approach description being difficult to follow and suggests revising it. The comment also provides a clear suggestion to extend the approach description using the additional page of the camera-ready version, rather than adding more experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach description in Section 3 is difficult to follow and suggests revising it. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or justification to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approach description in Section 3, noting that it is difficult to follow. It suggests revising the description and provides a clear and actionable suggestion to extend the approach description using the additional page of the camera-ready version. This feedback is valuable as it directs the authors to a specific area needing improvement and offers a concrete way to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional guidance on how to improve the approach description or suggested specific changes to make it more accessible. Overall, the comment is mostly helpful as it effectively points out a weakness and offers a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues with the experimental section: the lack of interpretive insights into why the proposed gyro-structures outperform existing methods and the absence of comparison with other state-of-the-art methods that do not rely on gyro-structures. While the comment highlights these gaps, it does not provide explicit guidance on how to address them. The authors are left to infer that they should include more detailed interpretive insights and comparisons with other methods. The action is implicit and somewhat vague, as it lacks specific suggestions on how to improve the interpretive insights or which methods to compare with. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It also specifies the issues with the related discussion, noting the lack of interpretive insights and the need for comparison with other state-of-the-art methods. The comment further highlights the absence of comparison with methods that do not rely on gyro-structures, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related discussion lacks interpretive insights and that the proposed gyro-structures outperform existing methods. It also notes the absence of comparison with other state-of-the-art methods that do not rely on gyro-structures. While the comment identifies specific gaps in the paper, it does not provide detailed reasoning or examples to support these claims. The lack of specific references or detailed explanations makes it somewhat verifiable, as the authors would need to infer the basis of the claims and potentially conduct additional research to fully understand and address the issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant issues with the experimental section of the paper. First, it points out the lack of interpretive insights into why the proposed gyro-structures outperform existing methods. This feedback is valuable as it highlights an area where the authors need to provide more detailed analysis and explanation to enhance the understanding of their approach. Second, it notes the absence of comparison with other state-of-the-art methods that do not rely on gyro-structures, making it unclear whether the proposed approach actually outperforms simpler or more commonly used techniques. This is a critical observation that could significantly impact the paper\\'s conclusions and impact. By addressing these issues, the authors can significantly improve the clarity and robustness of their work. Therefore, the comment is highly helpful as it provides clear and actionable feedback on areas needing improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. While the comment implies that additional analysis is needed, it does not specify what kind of evidence or analysis is required or how it should be presented. The authors are left to infer that they need to provide more detailed information, but the comment lacks concrete guidance on what exactly is needed. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this analysis should be included in, such as a particular section or figure. The authors can infer that it relates to the discussion or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the need for more evidence or analysis. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, suggesting that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it points out a specific area where the authors can enhance their work by providing additional data or analysis to strengthen their claims. However, the comment could be more helpful if it provided specific suggestions on what kind of evidence or analysis would be beneficial or how it should be presented. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 5 is difficult to comprehend and recommends providing more details about the two baselines presented. It also points out that the authors only study CATER for English-centric datasets, which is a limitation, and suggests extending CATER to other languages in the future. While the comment provides a clear action for the authors to take, it does not specify which details should be added or how to extend CATER to other languages. The action is explicit but lacks concrete guidance on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as its difficulty in comprehension and the need for more details about the two baselines presented. Additionally, it suggests extending CATER to other languages, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 5 is difficult to comprehend and suggests that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for English-centric datasets, which is a limitation, and suggests extending CATER to other languages. While the comment identifies specific issues with the figure and the study\\'s scope, it lacks detailed reasoning or references to support the claim that Figure 5 is difficult to comprehend. The suggestion to extend CATER to other languages is logical but could be strengthened with more detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and suggesting that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for English-centric datasets, which is a limitation, and suggests extending CATER to other languages in the future. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and comprehensibility of the figure and the study\\'s scope. By addressing these points, the authors can enhance the understandability and relevance of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the literature review, specifically regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment implies that the authors should make these improvements, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added (an explicit and comparative analysis of related work), but it is somewhat vague in terms of how to execute this action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"literature review\" and \"GFlowNet for sequence generation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the clarity of the main contribution and the distinction from existing work. The comment provides guidance on how to enhance the literature review by suggesting a more explicit and comparative analysis of related work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the literature review is unclear, particularly regarding the main contribution of the proposed method and its distinction from existing work. The reviewer suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment identifies a potential issue, it lacks specific examples or references to existing work that could clarify the distinction. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the literature review, specifically the lack of clarity regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work, which is crucial for effectively communicating the novelty and significance of the proposed method. This feedback is clear and actionable, as it directs the authors to enhance the literature review section to better support their claims. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct a more comprehensive analysis of related work. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the Gumbel-Softmax/Concrete distribution. However, it does not provide any explicit guidance on how to implement this suggestion or what specific content should be removed from section 3.2. The action is implicit and vague, as the authors are left to infer that they should remove the section but without clear instructions on what to replace it with or how to integrate the information elsewhere. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the Gumbel-Softmax/Concrete distribution. However, it does not specify which part of section 3.2 is problematic or what needs to be addressed. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. Additionally, it lacks specificity regarding what needs to be changed or improved in section 3.2. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that section 3.2 can be eliminated because readers are assumed to be familiar with the Gumbel-Softmax/Concrete distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or how it affects the paper\\'s content or clarity. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the Gumbel-Softmax/Concrete distribution. However, it does not provide any specific reasoning or justification for why this section is unnecessary or how it detracts from the paper. The comment lacks depth and does not offer any suggestions for improvement or alternative content that could be included in section 3.2. As a result, the feedback is barely helpful, as it points out a potential issue but does not guide the authors on how to address it effectively. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the potential influence of regularization effects on the observed improvements in teacher performance. It suggests that proper ablation studies are needed to verify the impact of distillation on teacher performance. While the comment identifies a potential issue, it does not provide explicit guidance on how to conduct these studies or what specific aspects to focus on. The authors are left to infer that they need to conduct ablation studies, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the study of the case where the student distills knowledge to the teacher, which improves the teacher\\'s performance. It raises a concern about the potential influence of regularization effects on the observed improvements, suggesting that proper ablation studies are needed to verify the impact of distillation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to conduct proper ablation studies, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential influence of regularization effects on the observed improvements in teacher performance. It suggests that proper ablation studies are needed to verify the impact of distillation on teacher performance. The comment provides a logical reasoning by pointing out that fine-tuning without early-stopping can lead to high variances, which could affect the results. However, the comment lacks specific examples or references to support the claim about regularization effects or to suggest how to conduct proper ablation studies. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the study, noting that the observed improvements in teacher performance could be due to regularization effects rather than distillation. It suggests that proper ablation studies are needed to verify the impact of distillation on teacher performance. While the comment highlights an important area for consideration, it lacks specific guidance on how to conduct these studies or what aspects to focus on. The authors are left with a general suggestion to conduct ablation studies, but without detailed instructions or examples, the feedback is somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests two specific actions for the authors to take: (i) to include performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility of the framework, and (ii) to include morphologically rich languages like Finnish, Hebrew, etc., and low-resource languages in the experiments. These are explicit actions that the authors can directly implement to improve their draft. The second point is a minor suggestion, but it is still clear and actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of performance on word similarity and sentence translation tasks and the inclusion of morphologically rich languages like Finnish and Hebrew. The comment also mentions a minor point about low-resource languages, providing clear guidance on what needs to be added. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility of the framework. It also recommends including morphologically rich languages like Finnish and Hebrew and low-resource languages in the experiments. These suggestions are based on common practices in the field and are logical, but the comment lacks specific examples or references to support the claim fully. The authors might need to infer the exact impact of these additions on the framework\\'s robustness and effectiveness. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two specific and actionable suggestions for improving the experiments section of the paper. First, it recommends adding performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility and effectiveness of the framework. This is a clear and concrete suggestion that can help the authors demonstrate the robustness and generalizability of their approach. Second, it suggests including morphologically rich languages like Finnish and Hebrew and low-resource languages in the experiments, which could further validate the framework\\'s capabilities. While the second point is a minor suggestion, it is still actionable and can help the authors expand their experiments. Overall, the comment is mostly helpful as it offers detailed and actionable feedback that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of node importance in the 1-shot scenario and notes that the experiment part does not include this setting. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes should be made to include the 1-shot setting. The comment lacks actionable details, such as recommending specific experiments or modifications to the paper, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of node importance in the 1-shot scenario and notes that the experiment part does not include this setting. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its request for the inclusion of the 1-shot setting, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of node importance in the 1-shot scenario and notes that the experiment part does not include this setting. However, it does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the paper\\'s conclusions. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid point about the absence of the 1-shot setting in the experiment part of the paper, noting that related works like RALE have included this setting. This observation highlights a potential gap in the paper\\'s experimental evaluation, which could impact the authors\\' ability to fully assess the effectiveness of their method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional experiments could be conducted to include the 1-shot setting. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the formula in the text, specifically mentioning $\\\\ell_{BCE}$. This is a clear and direct action for the authors to take, as it specifies the exact information that needs to be added. The comment is specific and provides concrete guidance on how to enhance the clarity of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the formula \"\\\\ell_{BCE},\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely providing more details about the formula in the text. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more details about the formula in the text, specifically mentioning $\\\\ell_{BCE}$. However, the comment does not provide any reasoning or evidence to support why this additional detail is necessary or how it would improve the clarity of the paper. Without further explanation or examples, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area for improvement by suggesting that the authors provide more details about the formula in the text, specifically mentioning $\\\\ell_{BCE}$. This feedback is clear and actionable, as it directs the authors to enhance the clarity of their work by including specific details about the formula. However, the comment could be more helpful if it provided examples of what kind of details would be beneficial or explained why these details are important for understanding the formula. Overall, the comment offers a clear direction for improvement, but it could be more comprehensive to fully support the authors in making these changes. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. While the comment implies that additional discussions are needed, it does not provide specific guidance on what aspects of these discussions should be included or how to structure them. The authors are left to infer that they need to expand on the existing discussions, but without concrete instructions on what to focus on or how to implement these changes, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. The authors can infer that it relates to the discussion of LLMs, but this inference is not direct. The comment is specific in its suggestion to include more discussions, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. However, the comment does not provide any supporting evidence, reasoning, or references to justify why LLMs struggle or how to address these issues. Without specific examples, data, or references, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there should be more discussions about why LLMs struggle at fine-grained hard constraints and how to address these problems. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, specifically regarding the limitations and challenges of LLMs. However, the comment lacks specific guidance or suggestions on what aspects of these discussions should be included or how to structure them. While it points out a gap in the paper, it does not provide detailed advice on how to address this issue, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of insight into the rationale behind the need for self-supervised learning on 360 video data with spatial audio. It implies that the authors should provide more detailed explanations or justifications for this approach. However, the comment does not explicitly instruct the authors to add this information or specify what kind of insights are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context but may not be entirely sure of the exact details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results and suggests that while the proposed approach is valuable for self-supervised learning on 360 video data with spatial audio, it lacks insights into why this approach is needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of insight into the rationale behind the need for self-supervised learning on this kind of data. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results suggest the proposed approach is valuable for self-supervised learning on 360 video data with spatial audio but lacks insights into why this approach is needed. The comment provides a logical reasoning by pointing out the absence of detailed explanations for the rationale behind the approach. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors may need to infer the need for more detailed explanations themselves, which could lead to some confusion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the rationale behind the need for self-supervised learning on 360 video data with spatial audio. It highlights that while the experimental results suggest the approach's value, the paper lacks insights into why this approach is necessary. This feedback is somewhat helpful as it points out an area where the authors could provide more context or explanation to enhance the paper\\'s clarity and depth. However, the comment does not offer specific suggestions or guidance on how to address this issue, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the link between IP and the terms/equations should be explained more explicitly and prominently. It also requests that labels be included for subfigures in Figures 3 and 4, rather than just being mentioned in the captions. While the comment provides a clear action to take, it does not specify how to implement these changes or what specific aspects of the link or labels need to be addressed. The authors are left with a general idea of what needs to be done but without detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for labels on subfigures and the need for more explicit explanations of the link between IP and the terms/equations. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the link between IP and the terms/equations could be explained more explicitly and prominently. However, it does not provide any specific examples or reasoning to support why this explanation is necessary or how it could be improved. Additionally, the comment requests the inclusion of labels for subfigures in Figures 3 and 4, but it does not explain why this is important or how it would enhance the clarity of the figures. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the link between IP and the terms/equations should be explained more explicitly and prominently. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity and understanding of their work. Additionally, the comment requests the inclusion of labels for subfigures in Figures 3 and 4, which is a practical suggestion that can improve the presentation of the figures. However, the comment could be more helpful if it provided additional guidance on how to effectively explain the link or suggested specific ways to enhance the clarity of the figures. Overall, the comment is mostly helpful as it offers clear and actionable feedback, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to average their results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on how to enhance the robustness and reliability of their results, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to average results over multiple runs, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that results should be averaged over multiple runs to determine statistical significance. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making changes to their work. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that can help the authors improve the robustness and reliability of their results. By suggesting a specific method for evaluating statistical significance, the comment provides a concrete step for the authors to take in enhancing the quality of their work. However, the comment could be more helpful if it explained why averaging over multiple runs is necessary or how it would impact the interpretation of the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the paper, noting that it only covers the SimCLR case and lacks analysis on the projection head, which is considered important. However, it does not provide explicit guidance on what specific analysis should be conducted or how to address this gap. The authors are left to infer that they need to include analysis on the projection head, but without concrete instructions or examples, the action remains vague. Therefore, this comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the \"projection head,\" which is a critical component of the SimCLR approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only covers the SimCLR case and lacks analysis on the projection head, which is considered important. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why the projection head is crucial or how it relates to the SimCLR case. Without this additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, noting that it only covers the SimCLR case and lacks analysis on the projection head, which is considered important. This feedback is valuable as it highlights a gap in the paper that could be addressed to enhance its comprehensiveness and relevance. However, the comment does not provide specific suggestions or guidance on how to incorporate analysis on the projection head or what aspects of this analysis would be most beneficial. While it points out an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the observations and conclusions should be highlighted in the paper, particularly in the experimental section. This feedback implies that the authors should make the observations and conclusions more prominent or accessible to the reader. However, it does not provide specific guidance on how to achieve this, such as recommending a particular section or method for highlighting the observations. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the comment. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the observations and conclusions are hidden in the experimental section, which is a specific critique. However, it does not explicitly mention which part of the paper this issue is found in, making it weakly grounded. The comment is specific in suggesting that highlighting these observations and conclusions would be beneficial for understanding the trade-offs of annotation effort and training performance. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the observations and conclusions are hidden in the experimental section, implying that they are not clearly highlighted or accessible to the reader. However, the comment does not provide specific examples or detailed reasoning to support this claim. It suggests that highlighting these observations and conclusions would be beneficial, but without further elaboration, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks detailed justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations and conclusions would be beneficial for understanding the trade-offs of annotation effort and corresponding training performance. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by making the observations and conclusions more prominent. However, the comment could be more helpful if it offered specific guidance on how to highlight these sections or what aspects should be emphasized. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This feedback is explicit and provides a clear action for the authors to take, which is to conduct ablation experiments. However, it does not specify which modifications should be tested or how to conduct the experiments, leaving some details to be inferred. While the action is clear, the lack of concrete guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is conducting ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests conducting ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. However, it does not provide any specific examples or references to support the claim that these modifications are necessary or beneficial for model performance. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors conduct ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\\'s validation and demonstration of the model\\'s performance. However, the comment could be more helpful if it included specific examples of the modifications or detailed guidance on how to conduct the ablation experiments. Despite this, the feedback is mostly helpful as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the KDE requiring more data when the classifier space is beyond binary, and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Remark 1\" and \"Zhang et. al.\" (presumably references in the paper), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the KDE requiring more data when the classifier space is beyond binary and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the KDE requiring more data when the classifier space is beyond binary, and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the KDE requiring more data when the classifier space is beyond binary, which is relevant to the methodology and results sections. It raises a question about whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. While the comment highlights an area for potential improvement, it lacks specific guidance or suggestions on how to address this issue or what specific datasets should be considered. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions imply that the authors should investigate these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to explore the impact of capacity on FID and consider potential artifacts in the pipeline, but the comment lacks specific details or suggestions on how to conduct these investigations. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, such as a particular section or experiment. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for information about the impact of capacity and artifacts, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions themselves are not claims but rather requests for clarification or additional information. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that could be valuable for the authors to explore: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. These questions highlight potential areas for further investigation or discussion in the paper. However, the comment lacks specific guidance or suggestions on how to address these questions or what specific aspects of the capacity or artifacts should be examined. While it points out potential areas for improvement, it does not provide detailed or actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the purpose of Proposition B.1 might be to illustrate the classic partitioning principle of K-means, which is a well-known concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the purpose of Proposition B.1 and provide a proof, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues: the blank Appendix A and the unclear purpose of Proposition B.1, suggesting that it might be illustrating a well-known concept in machine learning. The comment also points out the missing \"proof\" for this proposition. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the purpose might be to illustrate the classic partitioning principle of K-means, which is a well-known concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that the purpose is unclear or that the \"proof\" is missing. This makes the claim somewhat verifiable, as the authors would need to further investigate and clarify the purpose and proof themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues in the paper: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the purpose might be to illustrate the classic partitioning principle of K-means, which is a well-known concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. This feedback is clear and actionable, as it directs the authors to clarify the purpose and provide evidence for their claims. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar concepts have been presented in other works. Overall, the comment is mostly helpful as it highlights important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments. The comment is specific about the types of experiments that are missing, giving the authors a concrete understanding of what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing the types of experiments that are missing, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide specific examples or detailed reasoning to support why these experiments are necessary or how they would enhance the paper. Without such evidence or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly points out areas where the paper could be strengthened by including these experiments. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a concern about the use of approximations in the paper, specifically mentioning lines 107-110. It suggests that the authors should expand on the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set only in those lines. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to do so or what additional information should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (107-110) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should expand on the possible vulnerability of the approximations, particularly regarding the assumption of attacks being in the feasible set only in those lines. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of approximations in the paper leaves \"loose ends\" and suggests that the possible vulnerability of these approximations needs to be expanded to reassure readers. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to substantiate the concern about the vulnerability of the approximations. As a result, the claim is somewhat verifiable, as it requires further elaboration to be fully understood and actionable by the authors. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of approximations in the paper, specifically mentioning lines 107-110. It points out that while approximations are necessary, the paper does not adequately address the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set only in those lines. The comment suggests that the authors should expand on this issue to reassure readers that it is not a real concern. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address it. However, it could be more helpful if it included suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses a subjective opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors might address this perception or improve the contribution of their work. There is no explicit or implicit action for the authors to take, such as suggesting alternative approaches or improvements to the model. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the contribution of the paper and the approach of the proposed model, but it does not specify which part of the paper this perception is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution or approach are considered incremental or limited. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to support the assertion, the authors may find it challenging to understand or address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses an opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific reasoning or examples to support this claim or offer suggestions for improvement. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of what aspects of their work need attention or enhancement. As a result, the comment lacks helpfulness, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct a more careful analysis of the model's performance, particularly on \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis, it does not specify exactly how to do so or what additional details should be included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures, which could be helpful. However, the comment does not specify which part of the paper discusses the model's performance or the evaluation procedures, making it weakly grounded. The suggestion to provide more details is specific, but without clear grounding, the authors may struggle to identify where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. However, the comment lacks specific examples or references to support the claim that the model's performance is due to indirect exposure through data curation. Without such evidence or detailed reasoning, the claim is difficult for the authors to verify or address. Therefore, the comment is considered borderline verifiable, as it provides a logical suggestion but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the model's performance on \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It suggests that more careful analysis is needed, particularly for these benchmarks, and recommends providing more details about the evaluation procedures. While the comment highlights an area for improvement, it lacks specific guidance on how to conduct the analysis or what additional details should be included. The feedback is somewhat helpful as it points out a potential weakness but does not offer actionable steps for the authors to address it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the experimental part of the paper, specifically regarding the different metrics used for different OPE methods. It suggests that the authors should provide comments on the differences between the two sets of evaluation methods, as depicted in Figures 4 and 5. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide comments on the differences. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the discrepancy in the evaluation methods used in the two sets of benchmarks and requests an explanation of the differences. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental part of the paper verifies different metrics for different OPE methods but notes a discrepancy in the evaluation methods used in Figures 4 and 5. The reviewer suggests that the authors should provide comments on the differences between the two sets of evaluation methods. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the discrepancy and how it affects the validity of the results. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but requires further elaboration.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the experimental part of the paper, noting that the different metrics used for different OPE methods are not consistent across the two sets of benchmarks presented in Figures 4 and 5. It suggests that the authors should provide comments on the differences between the two sets of evaluation methods. This feedback is clear and actionable, as it points out a potential weakness in the experimental design and offers a specific direction for improvement. By addressing this issue, the authors can enhance the robustness and credibility of their results. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the experimental results, noting that the proposed method does not show an advantage without prior information, but only when using prior knowledge. It suggests that this comparison is unfair because the proposed method requires two separate representation models to be learned for each dataset. The reviewer implies that this additional complexity and cost should be considered. While the comment identifies an issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern or what specific changes should be made to the experimental design. The action is implicit and somewhat vague, as the authors can infer that they need to consider the additional complexity and cost but may not be entirely sure how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not show an advantage without prior information but only when using prior knowledge. This provides clear guidance on what needs to be addressed, namely the fairness of the comparison and the additional complexity and cost required for the proposed method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not show an advantage without prior information but only when using prior knowledge. The reviewer supports this claim by explaining that the comparison is unfair because the proposed method requires two separate representation models to be learned for each dataset, which adds complexity and cost. This reasoning is logical and provides a clear explanation for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar studies that have addressed this issue. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, noting that the proposed method does not show an advantage without prior information but only when using prior knowledge. It highlights that this comparison is unfair because the proposed method requires two separate representation models to be learned for each dataset, which adds complexity and cost. This feedback is valuable as it points out a potential weakness in the experimental design and suggests that the authors consider the additional complexity and cost of their method. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what alternative comparisons could be made to demonstrate the method\\'s effectiveness. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical aspect of their work that needs further consideration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include collaborative games in their experiments to explore how the evaluated methods behave in both collaborative and competitive settings. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to implement this suggestion or what specific collaborative games should be included. The authors are left to infer the details of how to incorporate collaborative games into their experiments, which could be improved with more concrete instructions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, it does not specify which part of the paper this issue pertains to, such as the sections where the experiments are described or the methodology section. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the inclusion of collaborative games, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or necessary. Without such information, the authors may find it challenging to understand the basis of the suggestion and how it could enhance their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by noting the absence of collaborative games in the experiments. It suggests that including such games would be interesting and could provide valuable insights into the behavior of the evaluated methods in both collaborative and competitive settings. This feedback is clear and actionable, as it directs the authors to consider adding a specific element to their experiments that could enhance the understanding and applicability of their work. However, the comment could be more helpful if it provided more detailed guidance on how to implement this suggestion or what specific collaborative games might be relevant. Overall, the comment is mostly helpful as it points out a meaningful area for improvement and offers a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific settings to include or suggesting ways to improve the figures. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of experimental settings for these figures, making them difficult to be convincing. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the absence of experimental settings for figures 1 to 9. This is a critical observation that could impact the credibility and persuasiveness of the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the figures. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the rationale behind the work, specifically regarding the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment identifies a specific area for clarification, it does not provide explicit instructions on how to address this issue or what specific details should be included in the clarification. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the rationale behind the work, specifically the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the proposed method and its potential impact on task knowledge acquisition. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the rationale behind the work is based on the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, as the reasoning is not fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the rationale behind the work, specifically regarding the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment highlights an important area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential gap in the rationale, but it could be more beneficial with additional details or examples on how to improve the clarity of the explanation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the ad-hoc nature of the regularization term and suggests that the lack of theoretical support is a weakness. It also points out that there are alternative statistics, such as the median, that could be used to replace the mean and standard deviation in the regularization. While the comment provides a specific suggestion to consider using the median, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative statistics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the regularization term, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the ad-hoc nature of the regularization term and suggests alternative statistics that could be used to replace the mean and standard deviation. The comment provides a clear direction for improvement by suggesting the use of the median, which is not sensitive to outlier values. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the ad-hoc nature of the regularization term and suggests that the lack of theoretical support is a weakness. It provides a specific suggestion to consider using alternative statistics, such as the median, which is not sensitive to outlier values. This claim is somewhat verifiable as it logically argues for the need for theoretical support and provides a specific alternative. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the ad-hoc nature of the regularization term and the lack of theoretical support. It suggests that the authors consider alternative statistics, such as the median, to replace the mean and standard deviation in the regularization. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the theoretical foundation of the paper. However, the comment could be more helpful if it explained why the median is a better choice or provided additional context on the benefits of using alternative statistics. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct comparisons with existing fairness algorithms in the experimental section. It clearly states the action needed, which is to integrate benchmark comparisons against state-of-the-art fairness algorithms. This provides a concrete and specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of comparisons with existing fairness algorithms. The comment provides a clear and actionable suggestion to integrate benchmark comparisons against state-of-the-art fairness algorithms, which would significantly enhance the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that integrating benchmark comparisons with state-of-the-art fairness algorithms would enhance the paper by providing tangible evidence of the proposed method's performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This claim is somewhat verifiable as it logically suggests that comparisons with existing algorithms would strengthen the paper, but it lacks specific examples or references to existing fairness algorithms or studies that could be used for comparison. The authors would need to infer the specific algorithms to include, which adds a degree of uncertainty. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental section, noting the absence of comparisons with existing fairness algorithms. It suggests that integrating benchmark comparisons against state-of-the-art fairness algorithms would enhance the paper by providing tangible evidence of the proposed method's performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This feedback is clear and actionable, offering a concrete suggestion for improvement that could significantly impact the paper\\'s impact and credibility. However, it could be more helpful if it provided specific examples of existing fairness algorithms that should be compared. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to discuss the iteration cost (computational budget) of their proposed method and to include the iteration cost of all related methods, including baseline methods. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and direct, giving the authors a clear path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the iteration cost should be discussed, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the iteration cost of the proposed method and the iteration cost of all related methods, including baseline methods. This provides clear guidance on what the authors need to include in their discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the iteration cost is a critical aspect to discuss. The authors are left to infer the importance of this discussion themselves, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including a detailed discussion of computational efficiency. By addressing this point, the authors can improve the comprehensiveness and clarity of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed this issue. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It explicitly instructs them to report average results over multiple runs, which is a clear and actionable step. It also suggests discussing the decision boundaries in the toy dataset, which is another actionable point. Additionally, it asks for clarification on what information is in Fig. 9, which is a specific request for more detail. Each of these points is clearly stated and provides concrete guidance on how to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Experimental section\" and specific sections within it, such as \"Sec. 3.1\" and \"Sec. 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as reporting average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims regarding the experimental section, including the need to report average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these suggestions. Therefore, the claims are considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the experimental section, particularly regarding the need to report average results over multiple runs to clarify the results. It also suggests discussing the decision boundaries in the toy dataset and clarifying the information in Fig. 9. These points are clear and offer concrete suggestions for improvement, which can help the authors enhance the clarity and robustness of their experimental results. However, the comment could be more helpful if it provided additional context or examples of how these improvements might be achieved. Overall, the feedback is mostly helpful as it directs the authors toward specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the dimensionality problem or suggestions for potential solutions. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the proposed model, specifically that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the model\\'s dimensionality, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. This is a relevant observation that could impact the applicability and scalability of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate its impact on the model. Without actionable advice or detailed feedback, the authors are left with a clear understanding of the problem but without a path forward for improvement. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide enough guidance for the authors to act on it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of supervised pretraining based on the prediction of homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example of Transformer-M performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the model. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to pretraining and possibly adjust the model\\'s architecture or training process. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"prediction of homo-lumo gap\" and the \"QM9 in downstream experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the Transformer-M model performs poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of homo-lumo gap may lead to negative transfer, as evidenced by Transformer-M\\'s poor performance on most tasks except for homo, lumo, and gap. The reviewer provides an example from QM9 in downstream experiments, which supports the claim. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have observed similar negative transfer effects. Despite this, the claim is mostly verifiable due to the provided example and logical reasoning.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of supervised pretraining based on the prediction of homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example of Transformer-M performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\\'s description of a general-purpose neural network model. This feedback is somewhat helpful as it points out a specific area of concern and suggests that the authors should reconsider their approach to pretraining. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as recommending alternative pretraining methods or suggesting ways to mitigate negative transfer. Overall, the comment is somewhat helpful as it highlights a potential problem but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the authors\\' statement on lines 80-82 regarding the center correlation not being insightful for discriminating model defenses, but then using it in figure 4 A&B. The reviewer questions why the metric was considered useful in one place but not another, or what the authors meant by their statement. This feedback implies that the authors should clarify their reasoning or explanation for using the metric in both contexts. However, it does not provide explicit instructions on how to address this issue, leaving the authors to infer the necessary actions. The comment is somewhat actionable as it identifies a potential inconsistency but lacks concrete guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (80-82) and figures (A&B), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\\' reasoning for using the center correlation metric in figure 4 A&B, despite claiming it is not insightful for discriminating model defenses. This provides clear guidance on what needs to be addressed, namely the inconsistency in the authors\\' reasoning or the clarification of their statement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' statement about the center correlation not being insightful for discriminating model defenses, as it is used in figure 4 A&B. The reviewer expresses confusion about why the metric is considered useful in one context but not another, and seeks clarification on the authors\\' reasoning. This is a request for clarification rather than a subjective claim or opinion, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the authors\\' reasoning regarding the center correlation metric. It points out that the authors claim it is not insightful for discriminating model defenses but then use it in figure 4 A&B. This feedback is valuable as it prompts the authors to clarify their reasoning or explanation for using the metric in both contexts. By addressing this inconsistency, the authors can improve the coherence and credibility of their work. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency or explained why it might be relevant in figure 4 A&B. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the term \"distributional generalization\" may be too strong to accurately represent the empirical phenomenon presented. It points out that the total variation between the test and train distributions of the network's outputs might not be zero, and that this conclusion is difficult to draw from a few test functions where the outputs match. However, the comment does not provide explicit guidance on what term or phrasing would be more appropriate or how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative terms or phrasing to better represent the phenomenon. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it might be too strong to capture the empirical phenomenon presented and suggesting that the total variation between the test and train distributions of the network's outputs might not be zero. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the appropriateness of the term \"distributional generalization\" to describe the phenomenon presented, suggesting that it might be too strong. The reviewer provides a logical reasoning by explaining that the total variation between the test and train distributions of the network's outputs might not be zero, which is a valid point. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore the issue themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the term \"distributional generalization\" used to describe the phenomenon presented in the paper. It points out that the term might be too strong and that the total variation between the test and train distributions of the network's outputs might not be zero, which could lead to a misleading conclusion. The comment provides a clear and actionable suggestion for the authors to reconsider the term and its implications, which could help improve the clarity and accuracy of the paper. However, the comment could be more helpful if it offered specific alternative terms or phrasing that would better capture the phenomenon. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the theoretical contribution as \"ok but not particularly strong\" and points out that it is a weak, unpractical bound. It also notes that the proof does not provide significant mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their draft. It lacks guidance on how to address the issues raised or suggestions for enhancing the theoretical contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the theoretical contribution of the paper, specifically mentioning that it is \"ok but not particularly strong\" and that it is a weak, unpractical bound. It also notes that the proof does not provide significant mathematical novelty. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or result. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issues with the theoretical contribution, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical contribution is \"ok but not particularly strong\" and that it is a weak, unpractical bound. It also notes that the proof does not provide significant mathematical novelty. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the theoretical contribution as \"ok but not particularly strong,\" indicating that it is a weak and unpractical bound. It also notes that the proof lacks significant mathematical novelty. While the comment identifies a potential weakness in the theoretical contribution, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the paper. Without actionable feedback or detailed advice, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as barely helpful, as it points out a weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper. While the comment provides explicit actions to take, such as including ablation and using the same setup as in the DEN paper, it does not specify how to implement these actions. The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to follow. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations 2.1.1\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental evaluation, such as the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. Additionally, it points out the need for a more comprehensive comparison with the DEN paper, including using the same setup. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks ablation for the \"picking\" step and that the comparison on CIFAR is not convincing. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper. The comment provides some logical reasoning by pointing out the need for ablation and a more comprehensive comparison, but it lacks specific examples or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the critique but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper to ensure fairness and correctness. This feedback is clear and actionable, as it provides specific guidance on how to improve the experimental evaluation section. However, it could be more helpful if it included examples of what ablation should entail or how to set up the comparison with the DEN paper. Overall, the comment is mostly helpful as it directs the authors to make significant improvements in their experimental evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use \"above/below diagonal\" instead of \"above/below 45 degree\" to make the plot easier to interpret. While the comment provides a specific suggestion for clarity, it does not offer detailed guidance on how to implement this change or why it is necessary. The action is explicit but somewhat vague, as the authors know they need to make the change but may not be entirely sure of the exact implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"plot\" and suggests a specific change to \"above/below diagonal\" instead of \"above/below 45 degree.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the clarity of the plot labels. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is described as a local property. The reviewer provides a logical reasoning that \"above/below diagonal\" is clearer because it refers to a specific position on the plot, while \"above/below 45 degree\" is ambiguous. However, the comment lacks specific examples or references to support the claim that \"above/below diagonal\" is more intuitive. This makes the claim somewhat verifiable, as the authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion to improve the clarity of the plot by using \"above/below diagonal\" instead of \"above/below 45 degree.\" This feedback is actionable and offers a clear and concise way for the authors to enhance the interpretability of their plot, which is a valuable contribution. However, the comment could be more helpful if it explained why \"above/below diagonal\" is more intuitive or provided examples of how this change might improve the plot. Overall, the comment is mostly helpful as it identifies a specific area for improvement and offers a clear suggestion for enhancing the clarity of the plot.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer implies that the authors might be trying to convey that the sum of the \"optimistic\" hoped-for rewards is close to the expected actual rewards. However, the comment does not provide explicit guidance on how to clarify this point or what specific changes should be made to improve the clarity. While the action is implied, it is not directly stated, and the authors are left to infer the necessary changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines, \"L240\" and \"L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the phrasing and suggesting that the authors might be trying to convey that the sum of the \"optimistic\" hoped-for rewards is close to the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hoped-for rewards is close to the expected actual rewards. However, the comment lacks specific examples or references to support this interpretation, making it somewhat verifiable. The authors would need to infer the intended meaning and potentially revise the phrasing themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the phrasing in lines L240 and L428, questioning what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hoped-for rewards is close to the expected actual rewards. This feedback is somewhat helpful as it points out a potential area for clarification, but it lacks specific guidance or suggestions on how to improve the clarity or accuracy of the phrasing. While it highlights an issue, it does not provide actionable steps for the authors to address it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism over prior task-optimized approaches. It specifically questions whether the model is a prototype approximation to non-linear RNN models that exhibit emergent behavior. The reviewer does not provide explicit guidance on how the authors should address this issue, but the implication is that they should provide a clearer explanation of the relationship between their work and prior task-optimized approaches. While the comment is somewhat vague, it does imply that the authors need to clarify their work to provide a better understanding of its contributions. Therefore, the comment is somewhat actionable, as it points to a potential area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scientific insight provided by the model and formalism over prior task-optimized approaches. The comment highlights a lack of clarity regarding the relationship between the model and non-linear RNN models that exhibit emergent behavior. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the scientific insight provided by the model and formalism over prior task-optimized approaches. It specifically mentions that the model is not shown to be a prototype approximation to non-linear RNN models that exhibit emergent behavior, which is a critical point for understanding the contribution of the work. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to provide additional evidence or reasoning to fully substantiate the claim, such as comparisons with existing models or detailed explanations of the model's relationship to emergent behavior. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically questioning the scientific insight provided by the model and formalism over prior task-optimized approaches. It points out that the model is not shown to be a prototype approximation to non-linear RNN models that exhibit emergent behavior, which raises concerns about the contribution of the work. The comment highlights a critical gap in the explanation of the model's relationship to emergent behavior, suggesting that the authors need to provide a clearer explanation of their work. While the comment identifies a crucial area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. Therefore, the comment is somewhat helpful, as it provides insight into a potential weakness but does not offer detailed guidance on how to resolve it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the construction of ground truths and how the network parts responsible for each part can predict all the keypoints of the pose. It suggests that the offset for every keypoint with respect to the center of the upper part should be included in O_{up}. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the ground truth construction and the network's ability to predict all keypoints. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.2 of the supplementary material,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the ground truths are built and how the network parts responsible for each part can predict all the keypoints of the pose. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the construction of ground truths and how the network parts responsible for each part can predict all the keypoints of the pose. It suggests that the offset for every keypoint with respect to the center of the upper part should be included in O_{up}. However, the comment lacks specific examples or references to support the claim that the current method is insufficient or inaccurate. The reasoning is based on logical reasoning and assumptions, but without concrete evidence or detailed explanations, it is difficult for the authors to fully understand and address the issue. Therefore, the comment is considered somewhat verifiable, as it provides a logical basis for the claim but lacks sufficient evidence or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the construction of ground truths and the network's ability to predict all keypoints of the pose. It questions how the ground truths are built and how the network parts responsible for each part can predict all keypoints. This feedback is somewhat helpful as it points out a potential weakness in the methodology, prompting the authors to clarify their approach and address the issue. However, the comment could be more helpful if it provided specific suggestions on how to improve the ground truth construction or how to address the network's limitations. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the size and readability of figures, the lack of clarity regarding how equation 5 follows from equation 4, the unclear explanation of \\theta^{t+1/2}, and the improper definition of S^{*} and S^{~}. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to improve the readability of figures, clarify the derivation of equation 5, and define S^{*} and S^{~} properly. However, the comment lacks concrete steps or suggestions on how to achieve these improvements, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues with the paper, such as the size and readability of figures, the lack of clarity regarding equation 5, and the definition of S^{*} and S^{~}. However, it does not explicitly mention which sections or figures are affected, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarification of equation 5 and the definition of S^{*} and S^{~}. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the paper, including the size and readability of figures, the lack of clarity regarding equation 5, and the unclear explanation of \\theta^{t+1/2}. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. The authors are left without any guidance on how to address these issues, making it difficult for them to understand the basis of the critique or how to improve their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the small size and unreadability of figures, the lack of clarity regarding the derivation of equation 5, and the unclear explanation of \\theta^{t+1/2}. Additionally, it points out the importance of S^{*} and S^{~} and their improper definition, which is a significant oversight. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to address them, such as recommending improvements to the figures or offering clarifications on the derivation and definitions. This limits the comment\\'s helpfulness, as it provides insight but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to make the texts in legends and axis labels larger, similar to the text size. It also clarifies the confusion between Proposition (1) and Equation 1 and suggests increasing the font size of captions and legends in Figures 2 and 3. These actions are direct and concrete, providing clear guidance on how to improve the draft. The authors know exactly what changes to make, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the legends and axis labels, and the beginning of page 6, where Proposition (1) is discussed. It also provides specific suggestions, such as increasing the font size of captions and legends in Figures 2 and 3, and clarifying the confusion between Proposition (1) and Equation 1. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the texts in legends and axis labels should be larger, similar to the text size, and that there is confusion between Proposition (1) and Equation 1. The comment provides a specific suggestion to clarify the confusion by changing Proposition (1) to Proposition 1. Additionally, it recommends increasing the font size of captions and legends in Figures 2 and 3. This claim is somewhat verifiable as it provides a logical reasoning for the changes, but it lacks detailed justification or examples to fully substantiate the need for these changes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on improving the clarity and readability of the paper. It points out that the texts in legends and axis labels should be larger, similar to the text size, which is a clear and concrete suggestion. Additionally, it clarifies the confusion between Proposition (1) and Equation 1 and recommends changing Proposition (1) to Proposition 1. The comment also suggests increasing the font size of captions and legends in Figures 2 and 3, which is a practical and beneficial suggestion for improving the presentation of the figures. Overall, the comment is highly helpful as it offers clear and actionable guidance for improving the draft, making it easy for the authors to implement the suggested changes.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments. It specifies that this comparison should be made at a particular step of the sampling trajectory, referring to Figure 2 in Journey TRAK. This provides a clear and concrete action for the authors to take, as they are given specific steps to follow in order to enhance their experimental analysis. The comment is highly actionable because it provides a direct and specific request for improvement, ensuring that the authors know exactly what needs to be done to address the feedback.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the counterfactual experiments and suggests a comparison against Journey TRAK, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be added, specifically a comparison against Journey TRAK at a particular step of the sampling trajectory, as shown in Figure 2. This provides clear guidance on what the authors should include in their experiments to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a comparison against Journey TRAK should be included in the counterfactual experiments. The reviewer provides a specific reference to Figure 2 in Journey TRAK, which shows a larger effect of removing high-scoring images according to Journey TRAK compared to CLIP cosine similarity. This provides a logical basis for the claim, as it suggests that including this comparison could enhance the understanding of the results. However, the comment could be strengthened by providing more detailed reasoning or examples from Journey TRAK to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the counterfactual experiments in the paper. It suggests including a comparison against Journey TRAK, which is a relevant work in the field, at a particular step of the sampling trajectory. This feedback is valuable as it offers a clear direction for the authors to enhance their experimental analysis and potentially strengthen their results. By incorporating this comparison, the authors can demonstrate a more comprehensive understanding of their method's performance and its implications. However, the comment could be more helpful if it provided additional context or rationale for why this comparison is important or how it might impact the results. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the use of adaptive convolutions in the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It points out that Table 3 shows ACNN-v3 (all adaptive convolutions) performed worse than ACNN-v2 (adaptive convolutions only in the last layer). The reviewer suggests that the placement of adaptive convolutions is important, but no analysis or comments are provided on this aspect of the technique. While the comment identifies a potential issue, it does not offer specific guidance on how the authors should address this issue or what kind of analysis or comments would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should include analysis or comments on the placement of adaptive convolutions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table-3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the use of adaptive convolutions in the experimental results does not always lead to better performance, as evidenced by the comparison between ACNN-v2 and ACNN-v3. The comment suggests that the placement of adaptive convolutions is important and highlights the need for analysis or comments on this aspect of the technique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that replacing normal convolutions with adaptive convolutions does not always lead to better performance, based on the experimental results. The reviewer provides a specific example from Table 3, where ACNN-v3 (all adaptive convolutions) performed worse than ACNN-v2 (adaptive convolutions only in the last layer). This provides a clear and concrete example to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that support this observation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of adaptive convolutions in the experimental results, noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It provides a specific example from Table 3, where ACNN-v3 (all adaptive convolutions) performed worse than ACNN-v2 (adaptive convolutions only in the last layer). This observation highlights the importance of the placement of adaptive convolutions, suggesting that the authors should analyze or comment on this aspect of the technique. However, the comment could be more helpful if it offered suggestions on how to analyze or comment on this aspect, such as potential factors to consider or methods to evaluate the placement of adaptive convolutions. Overall, the comment provides valuable insights but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of the trade-off and possibly explore ways to mitigate it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"ancestral graphs,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. The comment further raises a question about the information encoded in the ancestral graph compared to the DAGs. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the reduction in search space results in a loss of information. The reasoning is somewhat logical, but the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential trade-off between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, which is a relevant consideration for the authors. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important aspect of the paper, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexity-type results related to not returning NSF. However, it does not provide explicit guidance on how to achieve this improvement or what specific aspects of the theoretical discussions should be addressed. The action is implied and somewhat vague, as the authors are left to infer that they should include sample complexity results but without detailed instructions on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexity-type results related to not returning NSF. However, it does not specify which part of the theoretical discussions needs improvement or where these results should be included. The authors can infer that it relates to the theoretical sections, but the comment lacks full grounding as it does not explicitly mention a specific section or line. The suggestion is specific in terms of what is expected, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexity-type results related to not returning NSF. The reviewer provides a specific expectation, such as \"given confidence levels, what is the sufficient amount of training data points that would not return NSF.\" This suggestion is based on a logical expectation of what could be included in the theoretical discussions, but it lacks specific examples or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a clear direction but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems could benefit from additional sample complexity-type results related to not returning NSF. The reviewer provides a clear expectation by asking for results based on confidence levels and the amount of training data points needed to avoid returning NSF. This feedback is actionable and offers a concrete direction for the authors to enhance their theoretical discussions. However, the comment could be more helpful if it provided examples or references to similar studies or methods that have successfully addressed this issue. Overall, the comment is mostly helpful as it guides the authors toward a specific area for improvement, but it could be more comprehensive with additional examples or references.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the description of the VAD is puzzling and suggests that the authors should clarify what they mean by \"discarding TF bins with a magnitude of less than epsilon.\" It also notes that this approach is not consistent with a VAD, which is supposed to look for speech presence and is unlikely to be defined over frequency. The comment implies that the authors should reconsider their definition and approach to VAD. While the action is implicit, it is clear and provides a direction for the authors to take, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic with the VAD description, namely that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The comment further explains that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the VAD description is puzzling and suggests that the authors are discarding TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The reviewer argues that a VAD should look for speech presence and is unlikely to be defined over frequency. This claim is somewhat verifiable as it provides a logical reasoning for why the current approach might not be appropriate, but it lacks specific examples or references to support the assertion that VADs are typically defined over time rather than frequency. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the description of the VAD, noting that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. It points out that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear and actionable suggestion for improvement. The comment highlights a critical misunderstanding in the paper\\'s approach, which could lead to confusion or inaccurate conclusions. By offering a constructive critique and suggesting a more appropriate definition, the comment is highly helpful in guiding the authors towards a clearer and more accurate presentation of their work. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including a brief discussion on the empirical motivation for a time-varying Q ^ t and S t , as opposed to a fixed one. It provides a specific example of what could be discussed, namely the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is explicit and provides concrete guidance on what the authors should add to their discussion. The action is clear and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"discussion\" and \"Section 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the empirical motivation for a time-varying Q ^ t and S t , and provides an example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including a discussion on the empirical motivation for a time-varying Q ^ t and S t , as opposed to a fixed one. The reviewer provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This suggestion is based on logical reasoning and provides a clear direction for improvement. However, the comment could be strengthened by referencing specific studies or examples to support the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the draft. It highlights the need for a discussion on the empirical motivation for a time-varying Q ^ t and S t , as opposed to a fixed one. The reviewer offers a specific example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is valuable as it guides the authors to include a relevant and potentially insightful discussion in their paper. However, the comment could be more helpful if it provided additional context or references to similar studies that have explored this topic. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the definitions in Table 1, specifically questioning the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. It also mentions that the literature has shown that regression methods do not significantly influence the results. The reviewer suggests that the authors clarify this issue and provides a potential solution by suggesting that direct regression to the center point is sufficient. However, the comment does not explicitly instruct the authors to clarify this issue or provide specific guidance on how to address it. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. The reviewer provides a detailed explanation of the potential confusion regarding the methods and suggests that the authors clarify this issue. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the definitions in Table 1, specifically questioning the differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. The reviewer cites the literature to support their claim that regression methods do not significantly influence the results. However, the comment lacks specific references to the literature or detailed explanations of the differences between the methods. This makes it somewhat verifiable, as the authors would need to conduct further research to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the definitions and differences between anchor-based regression, regression in RepPoints, and one-shot regression in RetinaNet. It highlights a potential confusion regarding the methods and suggests that the authors clarify this issue to strengthen the motivations in their work. The comment is somewhat helpful as it identifies a specific area of concern and provides a direction for improvement. However, it could be more helpful if it offered more detailed guidance on how the authors might clarify these differences or what specific aspects of the definitions need clarification. Overall, the comment provides some insight but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. It also mentions that the experiments lack something to hang on to. However, it does not provide any specific guidance or suggestions on how the authors could improve the clarity or intuition of their presentation. The comment is vague and does not offer any concrete steps for the authors to take to address these issues. As a result, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not specify which parts of the paper are particularly challenging or where the lack of intuition is most apparent. Without specific references to sections, figures, or experiments, the authors cannot confidently determine which parts need attention or improvement. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment suggests that the experiments lack something to hang on to, but it does not specify what this \"something\" is or how it could be improved. Without concrete evidence or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, stating that it is not easy to follow and lacks a clear intuition for how the pieces fit together. It also notes that the experiments lack something to hang on to, which further undermines the paper\\'s clarity and coherence. However, the comment does not provide specific suggestions or guidance on how the authors could improve the presentation or clarify the connections between the different parts of the paper. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network's performance may be improved by training them simultaneously. The reviewer explicitly requests KID/FID metrics for the teacher network, providing a clear and concrete action for the authors to take. This guidance is explicit and specific, leaving no ambiguity about what needs to be done to address the concern. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"student and refinement networks\" and the \"teacher network,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the fairness of the comparison and requests KID/FID metrics for the teacher network. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network's performance may be improved by training them simultaneously. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. It explicitly requests KID/FID metrics for the teacher network, which is a clear and actionable request that can help the authors evaluate and improve their work. However, the comment could be more helpful if it provided additional context or examples of how these metrics could be used to assess the fairness of the comparison. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a concrete action to take, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the refined region vector, specifically questioning whether the attention weight is scaled before being used in the calculation. The reviewer suggests that having a scaling variable before the attention weight might help. While the comment implies that the authors should consider this suggestion, it does not provide explicit instructions or concrete guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding a scaling variable before the attention weight. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the refined region vector and suggests that having a scaling variable before the attention weight might help. The comment provides a clear direction for improvement by asking whether the refined vector scales only the most important regions before global pooling. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. The reviewer suggests that this might only scale the most important regions by a factor of two. The comment is based on logical reasoning and common knowledge about the attention weight and its application in the context of global pooling. However, it lacks specific examples or references to support the claim that having a scaling variable before the attention weight would help. This makes the claim somewhat verifiable, as it provides a logical basis but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. It suggests that this might only scale the most important regions by a factor of two before global pooling. The reviewer poses a question about whether having a scaling variable before the attention weight would help. This feedback is somewhat helpful as it prompts the authors to consider a potential improvement in their methodology. However, it lacks specific suggestions or guidance on how to implement this change or what specific benefits it might offer. To be more helpful, the comment could provide examples or additional reasoning to support the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the LLM's accuracy or how to handle ambiguities in human language. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to goal misspecification in the LLM, particularly when faced with ambiguities in human language. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem of goal misspecification and its consequences, such as failures on the ALFRED benchmark. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the LLM, noting that failures on the ALFRED benchmark often occur due to goal misspecification. It highlights that the LLM does not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This feedback is valuable as it points out a potential weakness in the model\\'s performance, which the authors can address to improve their draft. However, the comment could be more helpful if it provided suggestions on how to mitigate this issue or examples of how other models have successfully handled similar challenges. Despite this, the feedback is mostly helpful as it directs the authors\\' attention to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. It also raises a concern about the difficulty of Sampling-Gaussian to significantly improve iterative frameworks similar to IGEV. While the comment provides a clear direction for the authors to take, it lacks specific guidance on how to conduct the analysis or what specific aspects of the analysis should be focused on. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"improvement of this method over SOTA methods such as IGEV,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether there is no multi-peak distribution problem in iterative optimization schemes similar to IGEV and suggests analyzing the distribution of disparities produced by IGEV compared to other baselines. Additionally, it raises a concern about the difficulty of Sampling-Gaussian to significantly improve iterative frameworks. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the improvement of the method over SOTA methods like IGEV, suggesting that there may be no multi-peak distribution problem in iterative optimization schemes similar to IGEV. The reviewer also suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. The comment is somewhat verifiable as it provides a logical reasoning for the claim but lacks specific examples or references to support the assertion about the distribution of disparities. The suggestion to analyze the disparities is a logical step, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. This feedback is valuable as it guides the authors to conduct a specific analysis that could help them understand and address the issue. Additionally, the comment raises a concern about the difficulty of Sampling-Gaussian to significantly improve iterative frameworks similar to IGEV, prompting the authors to consider this aspect in their work. Overall, the comment is mostly helpful as it offers clear and actionable guidance for improving the draft. However, it could be more comprehensive by providing additional context or examples to support the analysis suggestion. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide model-specific insights by investigating how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It also recommends presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a clear action to take, it does not specify how to conduct this investigation or what specific aspects of the models should be analyzed. The authors are given a general direction but may need to infer the details of how to implement the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Model-Specific Insights\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the investigation into how specific models behave differently when ReGuide is applied and the presentation of differences in false positive rates (FPR) between models with and without ReGuide. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper focuses on generic findings across models and recommends a deeper investigation into how specific models behave differently when ReGuide is applied. The reviewer provides a specific example of GPT-4o and InternVL2, suggesting that differences in false positive rates (FPR) should be presented for a better comparison. This claim is somewhat verifiable as it provides a logical suggestion for enhancing the paper\\'s analysis, but it lacks detailed evidence or references to support the claim that these specific models behave differently. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the current focus on generic findings across models and recommends a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. The comment suggests presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is valuable as it directs the authors to a specific area for improvement, which could enhance the paper\\'s depth and nuance. However, the comment could be more helpful if it provided additional guidance on how to conduct this investigation or what specific aspects of the models should be analyzed. Overall, the comment is mostly helpful as it offers a clear path for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is an explicit request for clarification, providing a clear action for the authors to take. The comment is specific in detailing what needs to be clarified, making it highly actionable. Authors know exactly what needs to be done to improve their draft, ensuring that the action is concrete. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the Fourier modes as numbers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests clarifying whether these modes are real or complex numbers, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests clarifying whether the Fourier modes are real or complex numbers. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would impact the understanding of the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is a specific and actionable piece of feedback that can help the authors improve the clarity and precision of their draft. By addressing this point, the authors can ensure that their explanation is accurate and complete, which is beneficial for both the readers and the authors themselves. However, the comment could be more helpful if it provided additional context or examples to guide the clarification process. Overall, the comment is mostly helpful as it identifies a specific area for improvement, but it could be more comprehensive with additional details. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to correct the labeling of Fig. 1 instead of Fig. 5.1 on line 205. It also provides specific guidance on how to resolve the issue by mentioning the use of the \"\\\\label\" command after the \"\\\\caption\" in LaTeX. This feedback is clear and concrete, as it directly specifies the correction needed and provides a specific method for implementation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the labeling of Fig. 1 instead of Fig. 5.1 and provides guidance on how to resolve the issue by mentioning the use of \"\\\\label\" after \"\\\\caption\" in LaTeX. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction, noting that the label \"Fig. 5.1\" should be changed to \"Fig. 1\" on line 205. It provides a clear and specific instruction on how to correct the error, using the correct label and LaTeX commands. This is a factual observation and does not require verification or justification, making \"No\" the appropriate label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific error in the paper, namely the incorrect labeling of Fig. 1 as Fig. 5.1 on line 205. It provides clear and actionable feedback by instructing the authors to correct the labeling and specify the correct label in LaTeX. This guidance is precise and straightforward, enabling the authors to make a straightforward correction that improves the accuracy and clarity of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notations $h, g$ and $\\\\delta$ are introduced without clear input or output domains, and it suggests that this lack of clarity is similar to the issue with $\\\\delta$. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting specific descriptions or examples to include. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context for these notations, but the comment does not offer concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of notations $h, g$, and $\\\\delta$, noting that their input and output domains are not clearly defined. It suggests that this lack of clarity is similar to the issue with $\\\\delta$. However, the comment does not specify which part of the paper these notations are introduced in, making it weakly grounded. The comment is specific in pointing out the issue with the lack of clarity regarding the input and output domains. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the notations $h, g$, and $\\\\delta$ and suggests that their input and output domains are not well-defined. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of notations $h, g$, and $\\\\delta$, noting that their input and output domains are not clearly defined. It suggests that this lack of clarity is similar to the issue with $\\\\delta$. While the comment highlights a potential problem, it does not provide specific guidance or suggestions on how to address this issue, such as recommending a clearer explanation or examples of the input and output domains. The feedback is somewhat helpful as it points out a potential weakness, but it could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to supplement the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to improve the draft. The comment provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be supplemented, which is the result comparison. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is important or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it explained why this comparison is important or how it might impact the overall understanding of the results. Despite this, the feedback is mostly helpful as it points out a specific area for improvement, which the authors can address to strengthen their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should include results using the GCPG model without pre-trained initializations to clarify the contribution of the task formulation and pre-trained language models. This is a clear and direct action for the authors to take, as it provides a specific step to address the issue of attribution. The comment is specific in detailing what additional results are needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for results using the GCPG model without pre-trained initializations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the contribution due to the task formulation and pre-trained language models. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks ablations, specifically the results without pre-trained language models. The reviewer claims that it is unclear how much performance gain is due to the task formulation and how much is due to pre-trained language models. The suggestion to include results using the GCPG model without pre-trained initializations is a logical request to clarify the contribution of the task formulation. However, the comment does not provide specific examples or references to support the claim that the current results are unclear. This makes the claim somewhat verifiable, as the authors would need to make a logical inference to understand the basis of the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of ablations to clarify the contribution of the task formulation and pre-trained language models. It provides a clear and actionable suggestion by recommending the use of the GCPG model without pre-trained initializations. This feedback is valuable as it guides the authors to conduct additional experiments that can help clarify the impact of their task formulation and the role of pre-trained models. However, the comment could be more helpful if it explained why the current results are unclear or how the additional ablations would enhance the understanding of the paper\\'s contribution. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It suggests adding references next to baseline names in tables, specifically mentioning where to place the citation if it refers to a paper method. Additionally, it points out that $\\\\Omega$ is not explicitly defined in Corollary 1, but notes that it is not difficult to infer what it means. This feedback is clear and provides specific guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"tables\" and \"Corollary 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as adding references next to baseline names in tables and clarifying the definition of $\\\\Omega$ in Corollary 1. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding references next to baseline names in tables and clarifying the definition of $\\\\Omega$ in Corollary 1. While it provides specific guidance on how to improve the paper, it lacks detailed reasoning or references to support the claim that these changes would enhance the clarity or accuracy of the work. The suggestion is somewhat verifiable as it provides a clear direction for improvement, but the lack of detailed justification or examples makes it somewhat challenging for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by recommending the addition of references next to baseline names in tables, which can improve the clarity and transparency of the paper. It also points out a specific area where the paper could be improved, noting that $\\\\Omega$ is not explicitly defined in Corollary 1. This feedback is clear and constructive, offering the authors a concrete way to enhance the clarity and completeness of their work. By addressing these points, the authors can significantly improve the quality and readability of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that it is difficult to understand what the axes are for Figure 1. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the axes should be labeled more clearly or if additional explanations are needed. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve the clarity of the figure. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes in Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is difficult to understand what the axes are for Figure 1. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the clarity of Figure 1, noting that it is difficult to understand what the axes represent. This feedback is somewhat helpful as it points out a clear area for improvement in the paper, which is the labeling and explanation of the axes. However, the comment lacks depth and does not provide suggestions on how to improve the clarity or offer alternative ways to present the data. While it highlights an important issue, it could be more helpful with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider presenting results on ImageNet to enhance the convincingness of their proposed method. While the comment implies that the authors should include these results, it does not provide specific guidance on how to conduct the experiments or what aspects of the results should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should include results on ImageNet to improve the paper\\'s credibility. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that results on ImageNet could be more convincing for the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or the methodology. Without explicit references to sections or specific results, the authors cannot confidently determine which parts need to be addressed. The comment is not grounded and lacks specificity, making it difficult for the authors to understand and act upon the suggestion. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that results on ImageNet could be more convincing for the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to justify why this would be beneficial or how it would enhance the credibility of the method. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that results on ImageNet could be more convincing for the proposed method. However, it does not provide specific guidance on how to achieve this or what aspects of the results on ImageNet would be most impactful. Without detailed suggestions or examples, the authors are left with a general idea of what to consider but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which requires additional computational costs. This implies that the authors should include direct runtime comparisons to demonstrate the efficiency of their proposed approach. The comment is clear and provides a specific action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for direct runtime comparisons with existing methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of implicit differentiation and its potential impact on runtime efficiency, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which requires additional computational costs. The comment suggests that these comparisons are necessary to demonstrate the efficiency of the proposed approach. While the reasoning is logical and provides a clear rationale for the need for runtime comparisons, it lacks specific examples or references to existing methods or studies that could support the claim. This makes the comment somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper, noting the absence of direct runtime comparisons with existing methods. It highlights the importance of these comparisons to demonstrate the efficiency of the proposed approach, which is based on implicit differentiation. This feedback is clear and actionable, as it directs the authors to include these comparisons to strengthen their claims about the efficiency of their method. However, the comment could be more helpful if it provided specific examples of existing methods or suggested ways to conduct the comparisons. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the proposed framework is a simple combination of meta-learning and federated learning and does not see any technical contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of the framework need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed framework for being a simple combination of meta-learning and federated learning, indicating a lack of technical contribution. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment lacks specificity regarding what aspects of the framework are considered simple or lacking in technical contribution. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning, lacking any technical contribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment critiques the proposed framework for being a simple combination of meta-learning and federated learning, indicating a lack of technical contribution. However, it does not provide any specific examples or suggestions for improvement, nor does it explain why the current framework is considered simple or lacking in technical contribution. Without actionable feedback or detailed reasoning, the authors are left without a clear understanding of what aspects of their framework need attention or how to enhance it. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the insufficiency of the contribution and suggests that the authors should further explore how to leverage the connection between complementary and model robustness to improve model robustness. While the comment implies that more insightful findings or solutions should be included, it does not provide specific guidance on what these findings or solutions should be. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their analysis to be more comprehensive. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the contribution of the paper, specifically the connection between complementary and model robustness. It suggests that the authors should explore how to leverage this connection to improve model robustness. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, which is the exploration of how to leverage the connection for model robustness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution is insufficient and suggests that the authors should explore how to leverage the connection between complementary and model robustness to improve model robustness. The comment provides a logical reasoning by pointing out that the conclusion about the relationship between complementary and robustness is intuitive and could be easily obtained. However, the comment lacks specific examples or references to support the claim that the contribution is insufficient or to suggest how to leverage the connection. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern about the contribution of the paper, noting that the study of the connection between complementary and model robustness is insufficient. It suggests that the authors should explore how to leverage this connection to improve model robustness, which is a valuable suggestion for enhancing the paper\\'s contribution. However, the comment lacks specific guidance on how to conduct this exploration or what specific insights or solutions should be considered. While it points out a critical area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the authors should focus on what the differences in representation are between clusters rather than on which clusters are \"best.\" However, it does not provide explicit guidance on how to implement this change or what specific aspects of the representation differences should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should prioritize the differences in representation over the selection of \"best\" clusters. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the focus on which clusters are \"best\" is an odd choice given the motivation of the paper. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this focus is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the representation differences should be prioritized over the selection of \"best\" clusters. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, suggesting that this is an odd choice given the paper\\'s motivation. However, the comment does not provide specific reasoning or evidence to support why this choice is problematic or how it affects the paper\\'s goals. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential inconsistency in the paper\\'s focus, suggesting that the authors should prioritize the differences in representation between clusters rather than which clusters are considered \"best.\" This feedback is somewhat helpful as it identifies an area where the paper might be misaligned with its stated motivation. However, the comment lacks specific guidance or suggestions on how to address this issue or what aspects of the representation differences should be emphasized. While it highlights a potential weakness, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to correct the caption. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the caption for Figure 7, and provides the correct label (\"Edge Dynamics\"). Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the caption for Figure 7, noting that it is incorrect and should be corrected. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific error in the caption for Figure 7, noting that it should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This is a clear and actionable piece of feedback that the authors can easily address to improve the accuracy and clarity of their paper. By correcting this mistake, the authors can enhance the quality of their work and ensure that their figures accurately represent their findings. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of a case study from \"Graph pre-training for AMR parsing and generation\" to illustrate the potential benefits of such an approach. While the comment explicitly states the need for case studies and error studies, it does not provide specific guidance on how to implement them or what aspects to focus on. The action is clear but lacks detailed instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Element-level Graph Pre-training\" and the \"complex structure\" mentioned in the paper, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that case studies and error studies could be beneficial in demonstrating the effectiveness of each proposed component. It provides an example of a case study from \"Graph pre-training for AMR parsing and generation\" to illustrate the potential benefits. However, the comment does not provide specific examples or detailed reasoning to support why case studies and error studies are necessary or how they would enhance the paper. While it offers a logical suggestion, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of case studies and error studies to demonstrate the effectiveness of each proposed component. It highlights the importance of such studies by referencing an example from \"Graph pre-training for AMR parsing and generation,\" which illustrates the potential benefits of including these analyses. This feedback is valuable as it guides the authors on how to enhance the persuasiveness and credibility of their work. However, the comment could be more helpful if it provided specific examples or guidance on what types of case studies or error studies would be most relevant or beneficial. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer requests clarification on the rationale for considering these factors as separate evaluations. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their evaluation criteria. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the traditional DCI framework and questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The comment is specific in its critique of the evaluation criteria and provides a logical explanation of how these factors might be entangled. However, it does not explicitly mention which part of the paper discusses these evaluation criteria, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, but lacks specific examples or references to support the claim. While the reasoning is clear, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, but the comment lacks specific suggestions or guidance on how the authors might address this issue. While it identifies a potential weakness in the paper, it does not offer actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is clear and provides a specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is concrete, as it specifies the need for clarification and provides a direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies what needs to be clarified: the standard deviation after multiple experiments and the improvement brought by SoRA compared to the baseline. The comment provides guidance on how to address this issue by suggesting the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvement brought by the SoRA method is limited due to random fluctuations, suggesting that the standard deviation after multiple experiments is not provided. The comment provides a logical reasoning by pointing out that the improvement may be due to random fluctuations, but it lacks specific examples or references to support this claim. The authors are left to infer the significance of the standard deviation and its impact on the results, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the experimental section of the paper, noting the absence of standard deviation after multiple experiments. It also points out that the improvement brought by the SoRA method is limited, which may be due to random fluctuations. The comment provides clear and actionable feedback by suggesting that the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This guidance is valuable as it helps the authors understand the significance of their results and how to present them more effectively. However, the comment could be more helpful if it offered suggestions on how to address the issue of limited improvement or how to better present the results. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the paper\\'s organization and layout, such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. While the comment provides explicit actions for the authors to take, such as increasing font size and ensuring proper placement, it does not offer detailed guidance on how to address these issues. The authors are left to infer the specific steps needed to improve the organization and layout of their paper. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Figure 1,\" \"Figure 2,\" \"Table 2,\" and \"page 6,\" allowing the authors to accurately identify the areas being addressed. It also specifies the issues with the layout, such as the font size and placement of figures and tables, and the formatting of the top two lines on page 6. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well-organized and that the layout is rushed, providing specific examples such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. These examples are detailed and provide clear justification for the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing additional examples or references to similar issues in other papers, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper\\'s organization and layout, providing detailed examples of formatting errors and inadequacies. It points out the small font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. These detailed observations offer actionable feedback that the authors can use to improve the clarity and professionalism of their paper. However, the comment could be more helpful if it suggested ways to address these issues, such as providing guidance on font size or offering alternative layout suggestions. Overall, the comment is mostly helpful as it provides clear and specific feedback on areas needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not provide specific guidance on how to assess or address these concerns. The authors are left to infer that they need to consider practicality and safety, but without concrete steps or examples on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where these considerations should be addressed. The authors can infer that it relates to the discussion of interventions or the experimental setup, but this inference is not direct. The comment is specific in its suggestion to consider practicality and safety, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why these considerations are necessary or how they would impact the paper\\'s findings. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, suggesting that while the types of interventions included are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. This feedback is valuable as it highlights a critical aspect that the authors may have overlooked, prompting them to consider the practical implications of their work. However, the comment could be more helpful if it provided specific examples or suggestions on how to assess and address these concerns. Overall, the comment is somewhat helpful as it directs the authors\\' attention to an important consideration, but it lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notation \"{\\\\cal P}\" with a subscript is used several times without being defined. This is an explicit action, as it clearly identifies the issue of missing definitions. The authors are given a direct and concrete instruction to define the notation, ensuring they know exactly what needs to be done to address the comment. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"same section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"{\\\\cal P}\" with a subscript being used without being defined. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \"{\\\\cal P}\" with a subscript is used several times without being defined. This is a factual observation that does not require any subjective judgment or opinion. It is a request for clarification or definition, which is a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"{\\\\cal P}\" with a subscript being used without being defined. This is a clear and actionable point, as it directs the authors to clarify the notation to avoid confusion. By addressing this issue, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided suggestions on how to define the notation or examples of where it is used. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It explicitly instructs them to correct \"known\" to \"know\" in line 148 and to define \"gamma_0^{***}\" in line 156. Additionally, it requests clarification on the meaning of the colors used in Figure 1, both in the caption and the text. These actions are clear and specific, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (l148 and l156) and Figure 1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected (correcting \"known\" to \"know\" and defining \"gamma_0^{***}\") and requests clarification on the meaning of colors in Figure 1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual corrections and requests for clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out errors in the manuscript, such as correcting \"known\" to \"know\" and requesting clarification on the definition of \"gamma_0^{***}.\" Additionally, it asks for clarification on the meaning of colors used in Figure 1, both in the caption and the text. This level of detail and specificity helps the authors identify and address specific areas for improvement, making the comment highly helpful. By addressing these issues, the authors can enhance the clarity and accuracy of their manuscript. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" that is not explicitly defined. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or definitions, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"upper faces\" of the convex hull, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for better explanation of the dual subdivision and projection process, as well as the issue with the variable \"p\" not being explicitly defined. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the meaning of \"upper faces\" of the convex hull and the dual subdivision and projection process. It also points out the lack of explicit definition for the variable \"p,\" which has been used extensively throughout the paper. These are factual observations that do not contain subjective claims or opinions. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies several areas of confusion or lack of clarity in the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" that is not explicitly defined. These are important issues that could impact the understanding and interpretation of the paper. The comment suggests that these areas need to be explained better, which is a clear and actionable piece of feedback. However, it could be more helpful if it provided specific suggestions on how to clarify these concepts or offered examples of how they have been addressed in similar works. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific changes they could make to support the integration of images and their augmentations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the idea are questionable or how it could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any supporting evidence, reasoning, or references to justify this skepticism. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses skepticism about the idea that images and their augmentations need to be treated separately, suggesting that they can be interchangeable. However, it does not provide any specific reasoning or evidence to support this claim or offer suggestions for how the authors might address this concern. Without actionable feedback or detailed guidance, the comment does not assist the authors in improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate their proposed method separately from baseline detection or parsing techniques to better support their claim of performance gain. This feedback provides a clear and explicit action for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. The suggestion is concrete, as it specifies the need for separate evaluations and provides a rationale for why this is important. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"generative shape model\" and the \"word parsing model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that it is unclear which component contributes to the performance gain and recommends evaluating the method separately from baseline detection or parsing techniques. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is unclear which component of the proposed method contributes to the performance gain, and suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. The comment provides a logical reasoning by suggesting that the proposed approach follows a detection-parsing paradigm, which implies that evaluating separately would be beneficial. However, the comment lacks specific examples or references to support the claim, such as mentioning which baseline techniques should be used or providing data to substantiate the claim. This makes the claim somewhat verifiable, as it provides a reasonable argument but lacks detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by addressing the issue of component attribution. However, the comment could be more helpful if it offered suggestions on how to conduct these separate evaluations or provided examples of baseline techniques to consider. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could be more interesting if it did not involve manual disentangling and instead demonstrated everything being learned. While the comment implies that the authors should reconsider their approach, it does not provide explicit instructions or concrete steps on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their methodology and potentially revise the paper to include more automated disentangling. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the paper could be more interesting if it did not involve manual disentangling and instead demonstrated everything being learned. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the manual disentangling process in the paper, suggesting that it could be more interesting if the paper did not involve manual disentangling and instead demonstrated everything being learned. However, the comment lacks specific reasoning or evidence to support why manual disentangling is problematic or how automating it would improve the paper. Without detailed justification or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the manual disentangling process in the paper, questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could be more interesting if it demonstrated everything being learned without manual disentangling. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or what alternative approaches could be considered. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of connection between the theoretical analysis and the proposed method, specifically regarding the use of self-attention mechanisms in the context of graph neural networks (GNNs). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to strengthen the connection between the theoretical analysis and the proposed method, or how to enhance the generalization for distant nodes. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the theoretical analysis and the proposed method, specifically mentioning the derivation of PAC-Bayesian bounds for GNNs in the transductive setting and the interplay between training and testing sets. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in detailing the lack of a strong connection between the theoretical analysis and the proposed method, as well as the use of self-attention mechanisms in the context of GNNs. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical analysis does not have a strong connection to the proposed method, which seems to simply adopt the self-attention mechanism from transformers. The reviewer questions how the proposed method enhances generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the connection between the theoretical analysis and the proposed method, specifically regarding the use of self-attention mechanisms in the context of graph neural networks (GNNs). It points out that the proposed method seems to simply adopt the idea of self-attention from transformers and apply it to graphs, without explaining how it enhances generalization for distant nodes. While the comment highlights an area for improvement, it lacks specific suggestions or guidance on how the authors might strengthen the connection between the theoretical analysis and the proposed method. This limits the comment\\'s usefulness in helping the authors make meaningful improvements to their draft. Therefore, the comment is somewhat helpful, as it provides insight into a potential weakness but does not offer actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the method is not clear about its behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether they should provide additional analysis, discuss the implications, or suggest alternative approaches. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Lipschitz Hessian assumption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the method's behavior without the Lipschitz Hessian assumption. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment claims that the method is not clear about its behavior without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area of concern regarding the method\\'s behavior without the Lipschitz Hessian assumption. This is a relevant point that could impact the robustness and generalizability of the method. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific aspects of the method might be affected. While it points out a potential weakness, it does not offer actionable advice or detailed feedback that could help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some of the pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific improvements or clarifications to be made in the presentation of these methods. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (12)\" and \"the presentation of these methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the presentation of these methods is vague and can only be understood after checking the original paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some pieces rely on existing methods, such as equation (12), and that the presentation of these methods is vague. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s originality and clarity. However, the comment lacks specific suggestions or guidance on how the authors might improve the presentation or address the issue of using existing methods. Without actionable advice, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationales behind certain decisions in the experimental setup, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While the comment implies that the authors should provide explanations for these decisions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for these choices. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the main rationales for having a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. This provides clear guidance on what aspects of the experimental setup need clarification or explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the experimental setup, specifically regarding the rationales for having a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the rationales behind certain decisions in the experimental setup, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While it identifies areas that need clarification, it does not provide specific guidance or suggestions on how the authors might address these questions or improve their explanation. The feedback is somewhat helpful as it points out potential areas for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include the results for all four datasets in Table 4, which provides a clear and direct action for the authors to take. The comment is specific in identifying the missing information and offers a concrete step to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the table, namely the results for all four datasets. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 4 is incomplete and should include results for all four datasets. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct and concrete step to improve their draft. By addressing this issue, the authors can enhance the comprehensiveness and accuracy of their results, which is crucial for the credibility and impact of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific guidance or suggestions on how to improve it. There is no explicit or implicit action for the authors to take, such as suggesting ways to clarify or organize the content. Without any actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the writing or presentation is jumbled at times, but it does not specify which parts of the paper are affected or where the jumbled presentation occurs. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the presentation are jumbled or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing or presentation is \"jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanations or references, the authors may find it challenging to understand the basis of the critique or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific examples or guidance on how to improve the clarity or organization of the paper. Without actionable feedback or suggestions, the authors are left without a clear understanding of what aspects of their writing need attention or how to address the issue. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the stability definition needs better justification, particularly regarding the left side, which can be arbitrarily small under some construction of tilde{g}. The reviewer recommends making the left side lower bounded. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to justify the stability definition or how to implement the suggested change. The action is concrete, as it specifies the need for a more reasonable treatment, but the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"stability definition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the justification of the left side of the stability definition, which can be arbitrarily small under some construction of tilde{g}. The comment provides a clear direction for improvement by suggesting a more reasonable treatment, such as making the left side lower bounded. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the stability definition needs better justification, particularly regarding the left side, which can be arbitrarily small under some construction of tilde{g}. The reviewer proposes a more reasonable treatment by making the left side lower bounded. However, the comment lacks specific examples or references to support the claim that the current justification is inadequate. While the suggestion is logical, the lack of detailed justification or evidence makes the claim somewhat verifiable. The authors would need to further explore the issue to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the stability definition, noting that the left side can be arbitrarily small under some construction of tilde{g}. It suggests a more reasonable treatment by making the left side lower bounded. This feedback is clear and actionable, as it provides a concrete direction for improvement by suggesting a specific change to the definition. However, the comment could be more helpful if it included examples or detailed reasoning on why the current justification is insufficient. Overall, the comment is mostly helpful as it guides the authors on how to enhance the clarity and robustness of their definition.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the cruciality of the annealing scheme from the last paragraph in Section 4, particularly when $\\\\alpha$ is not decreased to $0$. The reviewer suggests that this could induce a bias that may outweigh the bias reductions achieved by using IWAE in the first place. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or what specific actions they should take to mitigate the potential bias. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the last paragraph in Section 4, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the cruciality of the annealing scheme when $\\\\alpha$ is not decreased to $0$, suggesting that this could induce a bias that may outweigh the bias reductions achieved by using IWAE. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the cruciality of the annealing scheme from the last paragraph in Section 4, particularly when $\\\\alpha$ is not decreased to $0$. The reviewer suggests that this could induce a bias that may outweigh the bias reductions achieved by using IWAE in the first place. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides a logical basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the cruciality of the annealing scheme from the last paragraph in Section 4, particularly when $\\\\alpha$ is not decreased to $0$. This is an interesting observation that could prompt the authors to reconsider the importance of this aspect in their work. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what potential implications it might have for their results. While it points out a potential issue, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. While the comment implies that the authors should provide a comparison to other methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a computational complexity comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where the computational complexity is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its request for a comparison. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. However, the comment lacks specific examples or references to support the claim about computational complexity or power demand. Without detailed evidence or comparisons, the claim is difficult for the authors to verify and address. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. While the comment identifies a potential area for improvement by suggesting a comparison to other methods, it lacks specific guidance or suggestions on how to address the issue of computational complexity or power demand. The authors are left with a vague idea of what could be improved but are not provided with actionable steps to take. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It explicitly states that these heads are active at the S2 token but do not primarily attend to it, referencing Section 3 of Wang et al., 2023. This provides a clear and concrete action for the authors to correct their statement and ensure accuracy. The comment is explicit and provides specific guidance on how to revise the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific section of the paper, \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the incorrect claim about the attention of these heads and references Section 3 of Wang et al., 2023 to support its assertion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\" is incorrect, citing Section 3 of Wang et al., 2023. This claim is supported by a specific reference to the external work, which provides a clear and verifiable basis for the assertion. The reviewer logically explains the correct behavior of these heads, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It points out that these heads are active at the S2 token but do not primarily attend to it, which is a critical correction to make. The comment is clear and actionable, providing the authors with specific guidance on how to correct their statement to ensure accuracy. By addressing this issue, the authors can improve the clarity and correctness of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not provide any specific guidance or suggestions on how the authors could improve the contribution or make it more novel. The comment lacks actionable details, such as recommending new approaches or improvements to the pipeline. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not specify which part of the paper this assessment is based on, such as the methodology, results, or discussion sections. Without explicit references to specific sections, the authors cannot confidently determine which parts need revision. The comment is specific in its critique of the contribution being incremental, but it lacks grounding as it does not point to a particular part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. It implies that the pipeline is a collection of tricks to improve defense evaluation, which is a somewhat helpful observation. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors could enhance the contribution or make it more novel. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the critique. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the method is not scalable and suggests that a distributed version is needed to accommodate real-world datasets. However, it does not provide explicit guidance on how to develop a distributed version or what specific aspects need to be considered. The action is implied and somewhat vague, as the authors can infer that they need to develop a distributed version but are not given concrete steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the scalability of the method, suggesting that it is not scalable without a distributed version. However, it does not specify which part of the paper discusses the method or where the scalability issue is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the scalability issue but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is not scalable and suggests that a distributed version is needed to accommodate real-world datasets. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the method, suggesting that it may not be suitable for real-world datasets due to the large amount of data typically contained in them. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending a scalable solution or discussing potential modifications to the method. While it points out a potential weakness, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for consideration but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the eta_ri term is not clearly explained as a non-central chi-squared distribution. However, it does not provide any guidance on how the authors should address this issue or what specific steps they should take to clarify this point. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the eta_ri term, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the eta_ri term being a non-central chi-squared distribution. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the eta_ri term being a non-central chi-squared distribution. However, it does not provide any supporting evidence, reasoning, or references to justify why this term should be considered unclear or how it could be clarified. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the eta_ri term being a non-central chi-squared distribution. This is a clear and actionable point that the authors can address to improve the understanding of their work. However, the comment could be more helpful if it provided additional context or examples to help the authors better understand the implications of this clarification. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks depth and detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit feedback on the vagueness of certain RNNs and suggests that the reinforcement learning/agent analogy is out of place. It also points to specific lines in the paper where generalization capabilities are better illustrated. While the comment identifies areas for improvement, it does not provide concrete guidance on how to address the vagueness or suggest specific changes to the analogy or examples. The authors are left with a general idea of what needs to be improved but without detailed instructions on how to implement these improvements. Therefore, the comment is somewhat actionable, as it provides a direction but lacks specificity in execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, \"L15\" and \"L16-18,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue with the vagueness of certain RNNs and the out-of-place nature of the reinforcement learning/agent analogy. The comment provides clear guidance on what needs to be addressed, such as the need to clarify the vagueness and the suggestion to better illustrate generalization capabilities with examples later in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion on certain RNNs is vague and suggests that the reinforcement learning/agent analogy is out of place. The reviewer provides a reference to the literature on natural language inference and the Stanford NLP leaderboard as evidence for the claim about vagueness. However, the comment does not provide specific examples or detailed reasoning to support why the analogy is out of place or how it could be improved. While the reference to external sources adds some verifiability, the comment lacks detailed justification, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the vagueness of certain RNNs and the out-of-place nature of the reinforcement learning/agent analogy. It suggests that the generalization capabilities are better illustrated by examples later in the paper. This feedback is actionable as it points out specific areas that need clarification and improvement, which can help the authors enhance the clarity and coherence of their draft. However, the comment could be more helpful if it provided specific examples or guidance on how to address the vagueness or improve the analogy. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide more detailed analysis or justification for the proposed algorithm, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of difference in terms of StableDiffusion and the need for further discussion, as well as the absence of mathematical or theoretical justification for the proposed Algorithm.1. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. The comment provides some logical reasoning by pointing out the lack of difference in StableDiffusion, but it lacks specific examples or references to support the claim. The absence of detailed evidence or examples makes it somewhat verifiable, as the authors would need to further explore the claim to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the proposed sensitive-layer selection against randomized selection does not make a significant difference in terms of StableDiffusion. It also points out the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues or improve their analysis. The feedback is somewhat helpful as it directs the authors to areas needing further exploration and justification, but it could be more actionable with specific suggestions or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples rather than sets, which is a clear and direct action for the authors to take. The comment provides a specific line number and a concrete suggestion for how to improve the presentation of the triples, making it highly actionable. The authors know exactly what change to make to enhance the clarity of their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presentation of triples as tuples rather than sets. This provides clear guidance on how to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets. However, the comment does not provide any reasoning or evidence to support this claim. It lacks specific examples or references to justify why this change would improve clarity or understanding. As a result, the claim is unverifiable, as it does not provide sufficient justification for the authors to make the suggested change. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to improve the clarity of the paper by recommending that the triples denoted as $(e_1, r, e_2)$ be presented as tuples rather than sets. This feedback is clear and directly addresses a potential source of confusion in the presentation of the data structure, which could enhance the readability and understanding of the paper. However, the comment could be more helpful if it included a rationale or explanation for why this change would improve the clarity or impact of the paper. Overall, the comment is mostly helpful as it provides a concrete suggestion for improvement, but it could be more comprehensive with additional context or reasoning.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of speed analysis in the experiments, specifically noting the absence of comparisons of inference speed between the proposed network and prior work. It suggests that the improvement on inference speed is more interesting than reducing FLOPs. While the comment implies that the authors should include speed comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include speed comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of speed analysis and the comparison of inference speed between the proposed network and prior work. It specifies the issue by pointing out the absence of such comparisons, which allows the authors to identify the part of the paper being addressed. The comment is also specific because it clearly articulates the need for comparisons of inference speed and why this is important. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of speed analysis is a significant issue, as it suggests that the experiments have focused on comparing GFLOPs of different segmentation networks but not on inference speed. The reviewer argues that the improvement in inference speed is more interesting than reducing FLOPs. This claim is somewhat verifiable as it provides a logical reasoning for why the authors should focus on inference speed, but it lacks specific examples or references to support the assertion that the improvement in inference speed is more important. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of speed analysis in the experiments. It points out that while the experiments compare GFLOPs of different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The reviewer suggests that the improvement in inference speed is more interesting than reducing FLOPs, which is a valuable insight for the authors. However, the comment could be more helpful if it provided specific suggestions on how to incorporate speed analysis or examples of how such comparisons might be conducted. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). The reviewer notes that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this scalability problem or suggest specific actions to improve the scalability of the quantization. The authors are left to infer that they need to address this issue, but without concrete steps, the comment remains somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of scalability in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the problem of quantization being a bottleneck for the method, which is crucial for the authors to understand and address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It also notes that even with clustering before, the cost of quantization is high in terms of both N (number of data) and M (dimension). The reviewer further explains that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. While the comment provides logical reasoning and references the paper, it could be strengthened by providing specific examples or references to quantization methods that are known to be scalable. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). This is a significant concern, as it affects the speed of VI and the method's effectiveness in big data/big model settings. The reviewer highlights that the quantization is a bottleneck for the method, which could lead to it losing its purpose. This feedback is valuable as it prompts the authors to address the scalability issue, potentially improving the method's applicability and impact. However, the comment could be more helpful if it provided specific suggestions or examples on how to improve the scalability of the quantization. Overall, the comment is mostly helpful as it identifies a critical weakness and offers a direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to compare their methodology against existing methods, such as contrastive decoding, and to address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more application-oriented venue. The comment provides clear and concrete actions for the authors to take, specifying what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning\" and \"core methodology,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is comparing the effectiveness of the method against existing methods like contrastive decoding and addressing issues mentioned above. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should compare its methodology against existing methods, such as contrastive decoding, and address issues mentioned above. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to existing methods or issues that need to be addressed. This makes the claim somewhat verifiable, as the authors would need to infer the specific details and references themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the paper should compare its methodology against existing methods, such as contrastive decoding, and address issues mentioned above. It also suggests that if the work does not effectively compare with existing methods, it should aim for a more application-oriented venue. This feedback is specific and constructive, guiding the authors on how to enhance the rigor and relevance of their work. However, the comment could be more helpful if it provided examples of specific issues or comparisons to existing methods, which would further empower the authors to make improvements. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. It also points out that the validation experiments are not comprehensive and that the time complexity and efficiency of the computation are not clearly analyzed. Additionally, it suggests that the authors should further elucidate the technical contribution rather than the form of the attack. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what changes are needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues with the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment also lacks specificity in terms of what needs to be addressed regarding the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questioning how it would operate effectively when the dataset is not fully perceptible. It also critiques the validation experiments as not comprehensive and points out that the time complexity and efficiency of the computation are not clearly analyzed. The reviewer expects the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies areas for improvement, it lacks specific examples or references to support the claims, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issues raised, but the feedback provides a clear direction for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. It points out that the algorithm requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. Additionally, it critiques the validation experiments as not comprehensive and suggests that the time complexity and efficiency of the computation are not clearly analyzed. The comment also expects the authors to further elucidate the technical contribution rather than the form of the attack. While the feedback provides clear guidance on areas for improvement, it could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is somewhat helpful as it highlights important areas for improvement, but it lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a statement in the paper that claims every kernel can be described by a feature space parameterized by a neural network, which is not true. The reviewer suggests that the limitation of representing infinite-dimensional RKHSs with neural networks should be made more clear. While the comment identifies a specific issue and provides a direction for improvement, it does not offer concrete guidance on how to clarify this limitation or what specific aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.\" This allows the authors to accurately identify the part of the paper being addressed, which is the discussion of feature spaces and neural networks. The comment is also specific because it clearly specifies what needs to be addressed, namely the limitation of representing infinite-dimensional RKHSs with neural networks. This provides clear guidance on how to improve the clarity of the paper in this section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that every kernel can be described by a feature space parameterized by a neural network, pointing out a limitation with RBF kernels and their infinite-dimensional representation. The reviewer provides a logical reasoning by referencing the fact that RKHS is famously infinite-dimensional, making it impossible for a neural network with finite width to represent it. This logical reasoning supports the claim that the statement is not entirely accurate. However, the comment could be strengthened by providing specific references or examples to substantiate the claim further. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s claim that every kernel can be described by a feature space parameterized by a neural network. It points out a limitation with RBF kernels, noting that the RKHS is famously infinite-dimensional, making it impossible for a neural network with finite width to represent it. The comment suggests that this limitation should be made more clear, providing a clear and actionable suggestion for improvement. By highlighting this issue, the comment helps the authors clarify their claims and avoid misleading statements, which is valuable feedback for enhancing the accuracy and clarity of the paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed method is not well-positioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It suggests that the authors should conduct a thorough literature review to identify other works that use this property. While the comment provides a clear direction for the authors to conduct a literature review, it does not specify which works to focus on or how to integrate the findings into their paper. The action is explicit but somewhat vague in terms of execution, as the authors need to determine which specific works to review and how to incorporate them into their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of originality in the proposed method and the need for a thorough literature review to identify other works that use the same property. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. The reviewer supports this claim by referencing specific works, such as the original denoising score matching objective and score-interpolation, which have used this property. This provides a clear and robust justification for the claim, making it fully verifiable. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known in the literature. It provides specific examples of existing works that use this property, such as the original denoising score matching objective and score-interpolation. This feedback is valuable as it highlights a potential gap in originality and suggests a thorough literature review to address it. However, the comment could be more helpful if it offered suggestions on how to incorporate these references or how to strengthen the originality of the method. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a starting point for addressing it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or improve the handling of autoregressive decoding during the generation phase, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It mentions the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the handling of autoregressive decoding and the potential impact on inference benefits. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It suggests that the use of long token dimensions during training might limit the benefits of inference. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve their method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their work. While it points out a critical area for consideration, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a weakness in the assumption that the Pearson correlation coefficient (PCC) is more relaxed than KL divergence due to its invariance to scale and shift. It suggests that the authors should provide a gradient comparison between KL and PCC to substantiate this claim. This feedback is clear and concrete, as it specifies exactly what needs to be done to address the issue. The authors know exactly how to apply this suggestion to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the assumption that PCC is more relaxed than KL divergence due to its invariance to scale and shift. The comment provides a logical reasoning for why this assumption is not convincing and suggests a gradient comparison between KL and PCC to substantiate the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the assumption that the Pearson correlation coefficient (PCC) is more relaxed than KL divergence due to its invariance to scale and shift. The reviewer provides a logical reasoning by comparing the gradient distribution of KL and PCC, suggesting that KL divergence is stricter than PCC due to its stricter punishment according to its gradient distribution. This reasoning is based on a clear understanding of the gradient distribution and its implications, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the gradient comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a key assumption in the paper regarding the relative relaxation of the Pearson correlation coefficient (PCC) compared to KL divergence. It challenges this assumption by pointing out that the constraint strength of a loss function is defined by its gradient distribution, and provides a logical reasoning for why KL divergence is stricter than PCC. The comment suggests that a gradient comparison between KL and PCC would be necessary to substantiate the claim. This feedback is clear and actionable, as it directs the authors to provide evidence or analysis to support their argument. By addressing this point, the authors can significantly improve the clarity and robustness of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment implies that the authors should provide additional analysis or discussion, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the reproducibility of GPI with noise added and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. The comment also mentions the suitability of the approach for pattern separation tasks and suggests discussing this aspect. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to infer the need for additional analysis or discussion based on the comment alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given direction but not detailed steps on how to improve their draft. Therefore, the comment is somewhat helpful, as it provides insight but could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that if the authors have the resources, they should compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. This is an explicit action that the authors can directly take, as it provides a clear direction for further exploration and comparison. The comment is specific in its request, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, but it does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in its suggestion to compare the two, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison would be valuable or how it would contribute to the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, which could provide valuable insights into the performance of the proposed method. This feedback is actionable and offers a specific direction for further exploration and analysis, potentially enhancing the robustness and generalizability of the results. However, the comment lacks depth and does not explain why this comparison is important or how it might impact the paper\\'s conclusions. To be more helpful, the comment could provide additional context or suggestions on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. While the comment identifies an issue, it does not provide explicit guidance on how to address it or what specific experiments should be conducted. The authors are left to infer that they need to clarify this point, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the resolution of a debate left open in the paper. The comment questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the resolution of a debate left open in the paper and suggests that the distribution cannot be considered a factor in the results. It also asks if experiments disentangle changes in distribution from the removal of information. While the comment raises valid points, it lacks specific examples or references to support the claim that the distribution is a significant factor. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This feedback is somewhat helpful as it points out a potential issue in the paper that the authors may need to address. However, the comment lacks specific guidance or suggestions on how to resolve this issue or what experiments should be conducted. While it highlights an area for improvement, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. The reviewer suggests that directly comparing the results is unfair and recommends reproducing the results using the same setting as the other methods, which have their code released. This feedback provides a clear and explicit action for the authors to take, which is to reproduce the results using the same setting as the other methods. The suggestion is concrete and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of AdamW with cosine lr for training and the comparison of methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that direct comparison is unfair due to the use of different optimizers and recommending that the authors reproduce the results using the same setting as the other methods. This provides clear guidance on what needs to be addressed to improve the fairness of the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that directly comparing methods using different optimizers is unfair, suggesting that reproducing the results using the same setting as the other methods would be more appropriate. The comment provides a logical reasoning by pointing out the use of different optimizers and the availability of code releases for most recent methods. However, it lacks specific examples or references to support the claim that using different optimizers is inherently unfair. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of methods in the paper, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. The reviewer suggests that directly comparing the results is unfair and recommends reproducing the results using the same setting as the other methods, which have their code released. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion to improve the fairness of the comparison. By addressing this issue, the authors can enhance the credibility and validity of their results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects to focus on. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this curiosity pertains to, such as a specific section, table, or figure where this combination is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it identifies an area of interest, it lacks specificity and actionable guidance for the authors. It does not provide details on what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Without this information, the authors may struggle to understand how to address the curiosity or what potential benefits or limitations might arise from such an analysis. Therefore, the comment is somewhat helpful, as it points out an area of interest but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the plots are terrible, providing specific issues with the plot quality. It mentions that the plots are too small, colors are hard to distinguish, axis labels are poorly labeled, and labels are visually similar. The reviewer also points out that these issues are the main presentation of the experimental results, which should be clearer. This feedback is clear and provides concrete actions for the authors to take, such as improving the plot size, color contrast, and label clarity. The comment is highly actionable as it directly instructs the authors on how to enhance the clarity and quality of their plots, ensuring that they are more effective in communicating their results.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"plots\" and provides specific issues with them, such as their size, color contrast, and label clarity. It also mentions the \"main presentation of the experimental results,\" which further reinforces the grounding. The comment is specific because it details the problems with the plots, such as the small size, hard-to-distinguish colors, and unclear labeling. This provides clear guidance on what needs to be addressed to improve the clarity and quality of the plots. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the plots are terrible, with issues such as small size, hard-to-distinguish colors, unclear labeling, and visually similar labels. The reviewer provides specific examples of these issues, such as pink vs red, s-dropout(tr) vs e-dropout(tr), and poorly labeled error. These examples provide a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to similar issues in the literature, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on the quality of the plots, which are the main presentation of the experimental results. It identifies several issues with the plots, such as their small size, hard-to-distinguish colors, unclear labeling, and visually similar labels. By pointing out these problems, the reviewer highlights areas where the authors can improve the clarity and effectiveness of their plots, which is crucial for effectively communicating their findings. The comment is clear and direct, offering a clear path for the authors to enhance the quality of their work. Therefore, it aligns with a score of 5, indicating that the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to address the issue of low performance gains. As a result, the comment lacks actionability, leaving the authors without any direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance gains of the paper, specifically mentioning that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not specify which metrics or parts of the paper this analysis is based on, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the performance gains, but it lacks grounding as it does not reference specific sections or metrics. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a specific issue with the performance gains of the paper, noting that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). This is a clear and actionable observation that can guide the authors in understanding the limitations of their work. However, the comment could be more helpful if it provided suggestions on how to improve the performance gains or addressed potential sources of variability in the results. Overall, the comment is somewhat helpful as it identifies a specific area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a series of questions about the impact of the information about incorrect and corrected phrases and the type of mistake on the feedback network. It also asks about the performance without and with each of these two types of information and the performance with just natural language feedback. While the questions imply that the authors should analyze and present this information, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this analysis and present the results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"information about incorrect phrase / corrected phrase and the information about the type of the mistake,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the impact of this information on the feedback network and the performance without and with each of these two types of information. Additionally, it asks about the performance with just natural language feedback. This level of detail provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a series of questions about the impact of certain types of information on the feedback network. It does not make any subjective claims or judgments that require verification. The questions are factual and seek clarification, making them purely descriptive and not requiring verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a series of questions about the impact of certain types of information on the feedback network, specifically asking about the performance without and with each of two types of information and the performance with just natural language feedback. This is a thoughtful and insightful question that could prompt the authors to conduct additional analyses and provide more detailed information about the effectiveness of their feedback network. However, the comment does not offer specific suggestions or guidance on how to conduct these analyses or what specific aspects to focus on. While it points out a potential area for improvement, it lacks actionable advice, making it somewhat helpful but not fully comprehensive. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with Table 1, noting that it does not show standard deviations. It suggests that this omission would make the submission stronger if the experiments were more extensive. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting which experiments should be included or how to present the standard deviations. The action is implied and somewhat vague, as the authors can infer that they need to include standard deviations but may not be entirely sure of the specifics. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of standard deviations in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 does not show standard deviations, which would make the submission stronger if the experiments were more extensive. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this omission is significant or how it affects the overall strength of the submission. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 1, noting that it does not show standard deviations. This is a clear and actionable point that could significantly improve the paper by including this information. However, the comment could be more helpful if it provided suggestions on how to present the standard deviations or which experiments should be included to enhance the submission. While it highlights an important area for improvement, the feedback is somewhat limited in its guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. However, it does not provide explicit guidance or suggestions on how the authors should address this question or improve their draft. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific tables (1, 2, and 3) and the addition of parameters in LinearTop and NLTop, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning whether there is still a performance boost if a better Unary baseline is used, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. The comment references external work ([14]) to support the claim that a different neural network might be better, but it does not provide specific details or evidence to substantiate the claim. The reasoning is somewhat logical, but the lack of detailed justification or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. It references external work to support the claim that a different neural network might be better, providing some context for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential area for further exploration, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit suggestions for improving the structure of the paper and highlights specific sections that require multiple readings. It suggests reorganizing the structure from introduction to method to experiments, which is a clear and concrete action for the authors to take. Additionally, it points out the importance of the IEM in Fig 3 and recommends focusing on it, providing a specific area for improvement. The comment also suggests improving the visualization of Fig 7 and Fig., offering specific guidance on how to enhance the figures. Overall, the comment is highly actionable as it provides clear and detailed instructions on how to improve the paper\\'s structure and presentation.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as the \"introduction,\" \"method,\" and \"experiments,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear suggestions for improvement, such as reorganizing the structure and focusing on the IEM in Fig 3. The comment also suggests improving the visualization of Fig 7 and Fig., providing detailed guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is hard to follow and suggests improving the structure by reorganizing the sections from introduction to method to experiments. It also highlights the importance of the IEM in Fig 3 and recommends focusing on it. Additionally, it suggests improving the visualization of Fig 7 and Fig. The comment provides logical reasoning by suggesting a structural change to enhance the clarity of the paper. However, it lacks specific examples or references to support the claim about the IEM or the visualization of Fig 7 and Fig. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the suggestions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the structure and organization of the paper, suggesting improvements such as reorganizing the sections from introduction to method to experiments. It also highlights the importance of the IEM in Fig 3, recommending that the authors focus on it. Additionally, it suggests improving the visualization of Fig 7 and Fig., which is a clear and constructive suggestion. The comment is mostly helpful as it offers detailed guidance on how to enhance the clarity and organization of the paper, making it easier for the authors to understand and follow. However, it could be more helpful if it provided additional suggestions or examples on how to improve the visualization or how to better integrate the IEM into the paper. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback implies that the authors should expand their discussion of related work to include a comparison with their own work. While the action is implicit, it is clear that the authors need to provide a more comprehensive discussion of related work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. However, it does not specify which part of the paper this discussion should be included in, such as the introduction, literature review, or results section. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a more detailed discussion of related work, but without explicit references to sections or elements, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This claim is somewhat verifiable as it provides a logical reasoning for expanding the discussion of related work. However, it lacks specific examples or references to support the claim that the current discussion is insufficient. The authors would need to infer the specific aspects of the related work that should be discussed and the differences to the presented work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, specifically the inclusion of a more comprehensive discussion of related work. However, the comment lacks specific guidance on how to structure this discussion or what aspects of the related work should be highlighted. While it points out a potential weakness, it does not provide detailed suggestions on how to address it, making it somewhat helpful but not fully actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be expanded to include attacks on other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should consider conducting experiments on these additional tasks, it does not provide specific guidance on how to implement these changes or what specific architectures or tasks should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper these experiments should be added to or which specific architectures or tasks should be considered. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment is not specific about what aspects of the experiments should be expanded or how they should be conducted. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends expanding them to include attacks on other architectures and classification tasks. However, the comment does not provide any supporting evidence, examples, or references to justify why this expansion is necessary or how it would benefit the paper. Without additional context or reasoning, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. This is a valuable suggestion as it could provide a broader understanding of the applicability and effectiveness of the proposed method. However, the comment lacks specificity and does not offer guidance on which architectures or tasks should be considered or how to implement these changes. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment requests information about the final used learning rates for the deep models, particularly for CIFAR-10 and CIFAR-100. It highlights the concern that the authors only tested four different learning rates and suggests that if the optimal learning rate for the baseline was outside the tested interval, it could affect the results. While the comment explicitly states what information is missing and why it is important, it does not provide specific guidance on how to address this issue. The authors are left to infer that they should include this information in their paper, but the action is not explicitly stated. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"deep models\" and \"CIFAR-10 and CIFAR-100,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what information is missing\u2014the final used learning rates for the deep models\u2014and why it is important for the authors to include this information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the authors\\' experimental setup, specifically mentioning that they only tested four different learning rates for the deep models, particularly CIFAR-10 and CIFAR-100. The reviewer suggests that if the optimal learning rate for the baseline was outside the tested interval, it could affect the results. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the potential impact of the learning rate choice on the results, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the authors only tested four different learning rates for the deep models, particularly CIFAR-10 and CIFAR-100. It highlights the potential problem that if the optimal learning rate for the baseline was outside the tested interval, it could affect the results. This feedback is clear and actionable, as it prompts the authors to consider whether their results are robust and whether additional testing is needed to ensure the validity of their findings. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional learning rates to test or discussing the implications of this limitation. Overall, the comment is mostly helpful as it points out a critical aspect of the experimental setup that the authors should consider, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might make locality-biased models more effective. However, it does not provide specific guidance or suggestions on how the authors should address this concern or explain their choice. The comment lacks explicit instructions or concrete details on what the authors should do to improve their draft. As a result, the authors are left without a clear understanding of what actions to take to address the reviewer\\'s concerns. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might make locality-biased models more effective. However, it does not specify which part of the paper this concern is based on, such as a particular section or experiment where the transformer is used. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the transformer without locality bias, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might make locality-biased models more effective. The reviewer provides a logical reasoning based on the nature of transformers and the speed of information propagation, but it lacks specific examples or references to support the claim. The comment is somewhat verifiable, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might make locality-biased models more effective. It prompts the authors to explain why the transformer without locality bias is still a viable option in their context. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this concern or provide a more comprehensive justification for their choice. The feedback is somewhat helpful as it points out an area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the output from the algorithm depends on the order in which the data is processed and suggests that this should be clarified. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to clarify this point. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the order of data processing. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the output from the algorithm depends on the order in which the data is processed and recommends clarifying this point. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of the algorithm's dependence on data order, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the output from the algorithm depends on the order in which the data is processed, suggesting that this should be clarified. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the algorithm's output, suggesting that it depends on the order in which the data is processed. This is a clear and actionable point that the authors should address to improve the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify this aspect or offered examples of how other studies have addressed similar issues. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a trade-off between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\\'s utility, it could deter their adoption. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to mitigate the potential impact. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the potential impact of their mitigation strategies on performance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the mitigation strategies aimed at reducing memorization and questions their impact on the overall performance of the model. It suggests that there might be a trade-off between reducing a particular behavior and maintaining high performance, and points out that significant impairment of the model\\'s utility could deter adoption. However, the comment does not specify which part of the paper discusses these mitigation strategies, making it weakly grounded. The comment is specific in its concern about the potential impact on performance, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a trade-off between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\\'s utility, it could deter their adoption. However, the comment lacks specific examples or references to support the claim about the potential impact on performance. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a logical argument but lacks the necessary substantiation to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the mitigation strategies, suggesting that their impact on overall performance might not be fully understood. It raises a concern about a trade-off between reducing a particular behavior and maintaining high performance, and points out that significant impairment of the model\\'s utility could deter adoption. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or what specific mitigation strategies could be explored. The feedback is somewhat helpful as it prompts the authors to consider the potential impact of their mitigation strategies, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the reason for using 6-fold cross-validation in the experiments. It points out that other papers in the field did not use cross-validation, which raises questions about its necessity. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the rationale behind the cross-validation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clear explanation for the use of cross-validation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of 6-fold cross-validation and the comparison with other papers that did not use it. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of clarity regarding the reason for using 6-fold cross-validation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reason for using 6-fold cross-validation is unclear because other papers in the field did not use it. However, the comment does not provide any supporting evidence or references to substantiate this claim. Without specific examples or detailed reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the reason for using 6-fold cross-validation. It points out that other papers in the field did not use this validation method, which raises questions about its necessity. This feedback is somewhat helpful as it highlights an area where the authors need to provide more detailed explanation or justification for their methodology. However, the comment could be more helpful if it suggested ways to address this issue, such as explaining the rationale behind the choice of cross-validation or providing a comparison with other validation methods. Overall, the comment provides some insight but lacks actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more in-depth analysis are needed to justify the claims in the paper. While the comment implies that the authors should conduct additional experiments or analysis, it does not provide explicit instructions on how to do so. The action is clear but somewhat vague, as the authors know they need to conduct additional experiments but may not be entirely sure of the specifics. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in the table, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment suggests that additional experiments or more in-depth analysis are needed to justify the claims in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three and there is no consistent trend in the results. The comment suggests that additional experiments or more in-depth analysis are necessary to justify the claims in the paper. This claim is somewhat verifiable as it provides a logical reasoning for the need for additional experiments, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments themselves to fully understand the issue and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more in-depth analysis are necessary to justify the claims in the paper. This feedback is clear and actionable, as it points out a critical weakness in the paper\\'s results and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to conduct these additional experiments or what aspects of the analysis should be expanded. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the paper presents an effective engineering method for ReC but notes that the proposed framework incorporates combinatorial and heuristic aspects. It specifically points out the Non-Ambiguous Query Generation procedure, which relies on a sophisticated filtering template. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information about the heuristic components, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the heuristic components. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Non-Ambiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the impact of the heuristic components, such as the sophisticated filtering template. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents an effective engineering method for ReC but notes that the framework incorporates combinatorial and heuristic aspects, specifically mentioning the Non-Ambiguous Query Generation procedure. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential area for clarification, it lacks specific examples or references to support the claim that these heuristic components are problematic or unclear. The reasoning is somewhat verifiable, as it points out a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the proposed framework incorporates combinatorial and heuristic aspects, specifically mentioning the Non-Ambiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components, which is a valuable point for improving the paper. However, the comment could be more helpful if it provided specific suggestions on how to clarify these aspects or what aspects of the heuristic components should be emphasized. While it highlights an important area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the feasibility of training the proposed method without using camera information, specifically mentioning Line 223 and the \"knowledge of CAD model correspondences.\" It raises concerns about how ray marching can be performed without knowing the viewpoint and the origin of the ray. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to provide more information or clarification regarding the use of camera information and ray marching. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of training the proposed method without using camera information, particularly regarding the \"knowledge of CAD model correspondences.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the feasibility of training the proposed method without using camera information, specifically mentioning \"Line 223\" and the \"knowledge of CAD model correspondences.\" The comment raises logical concerns about how ray marching can be performed without knowing the viewpoint and the origin of the ray. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that camera information is necessary for training. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the feasibility of training the proposed method without using camera information, specifically questioning the \"knowledge of CAD model correspondences\" mentioned in Line 223. It highlights the importance of camera information for ray marching and understanding the origin of the ray. While the comment identifies a potential weakness in the methodology, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is somewhat helpful as it points out a potential problem but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically mentioning the need for a detailed comparison of time complexity and competitiveness with prior art. While the comment implies that the authors should include such a comparison, it does not provide explicit instructions on how to conduct it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact details of what is expected. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what aspects of the comparison should be addressed. The authors can infer that it relates to the discussion or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a particular comparison to be made. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, the comment does not provide specific examples or references to prior work that should be compared, nor does it explain why this comparison is necessary or how it would enhance the paper. Without detailed guidance or evidence, the claim is not fully verifiable, as it lacks the necessary support to substantiate the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. This feedback is somewhat helpful as it identifies an area where the paper could be improved by providing a more comprehensive comparison with existing work. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but without detailed steps to follow. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not offer actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper discusses ODA as a method for solving the MOIP problem but does not clearly explain how the presented method improves performance and computation speed over ODA. However, it does not provide specific guidance on how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ODA\" and \"MOIP problem,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not clearly explain how the presented method improves performance and computation speed over ODA. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not clearly explain how the presented method improves performance and computation speed over ODA, which is a method for solving the MOIP problem. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it does not clearly explain how the presented method improves performance and computation speed over ODA, which is a method for solving the MOIP problem. This feedback is somewhat helpful as it points out a gap in the paper\\'s explanation, but it lacks depth and does not provide specific suggestions or examples on how the authors might address this issue. While it highlights an area for improvement, the comment could be more helpful with additional guidance or examples. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with some figures, particularly Figure 4, where the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This feedback implies that the authors should provide additional explanations or labels to make the figure more self-explanatory. However, the comment does not explicitly instruct the authors to add these explanations or labels, leaving the action somewhat implicit. While the authors can infer that they need to make these changes, the comment lacks concrete guidance on how to implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, specifically the lines \"No adapt or Finetune\" being covered by other lines without additional explanation. This provides clear guidance on what needs to be addressed to improve the figure\\'s clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some figures are not self-explanatory, specifically mentioning Figure 4 where lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This claim is somewhat verifiable as it provides a specific example of an issue with the figure, allowing the authors to understand the problem. However, the comment lacks detailed reasoning or examples of how the figures could be improved, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with some figures, particularly Figure 4, where lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This feedback is clear and actionable, as it directs the authors to provide additional explanations or labels to make the figures more self-explanatory. By addressing this issue, the authors can improve the clarity and accessibility of their figures, which is crucial for effectively communicating their research findings. However, the comment could be more helpful if it offered suggestions on how to improve the figures or provided examples of what additional explanations might be needed. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the sampling method used to obtain different initializations x_0, noting that this sampling is important for convergence to the optimum. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the evaluation. The comment suggests that the sampling should be evaluated more thoroughly, but it does not specify which benchmarks should be used or how the evaluation should be conducted. The lack of concrete details makes it difficult for the authors to know exactly how to implement the suggested improvement. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sampling performed to obtain different initializations x_0, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this sampling is important for convergence to the optimum but is not evaluated thoroughly on the proposed benchmarks, except for Table 1 in the supplementary. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sampling method used to obtain different initializations x_0 is important for convergence to the optimum, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the sampling is not evaluated thoroughly on the proposed benchmarks, except for Table 1 in the supplementary, where it is compared to sampling from a uniform distribution. However, this reference alone does not provide sufficient justification for the claim, as it lacks detailed analysis or comparison to other sampling methods. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the sampling method used to obtain different initializations x_0, noting that this sampling is important for convergence to the optimum. However, it points out that this aspect has not been evaluated thoroughly on the proposed benchmarks, except for a comparison in Table 1 of the supplementary. While the comment highlights an area for improvement, it lacks specific guidance on how the authors should address this issue or what additional experiments could be conducted to evaluate the sampling method more thoroughly. The feedback is somewhat helpful as it directs the authors to consider a more comprehensive evaluation, but it could be more actionable with additional suggestions or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions the authors\\' choice of comparison, the focus on computational cost, and the relevance of this aspect in a practical scenario. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors are left to infer that they need to provide a more detailed explanation or discussion of these points, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it points out areas that need attention but does not offer detailed guidance on how to improve the draft.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and references specific papers, \"[9]\" and \"16,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the logic of the comparisons, the focus on computational cost, and the relevance of this aspect in a practical scenario. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. The reviewer questions the authors\\' choice of comparison, the focus on computational cost, and the relevance of this aspect in a practical scenario. However, the comment lacks specific examples or detailed reasoning to support these questions, making it somewhat verifiable. The authors would need to further explore the rationale behind the comparisons and the relevance of the computational cost to fully understand and address the reviewer\\'s concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several pertinent questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions the authors\\' choice of comparison, the focus on computational cost, and the relevance of this aspect in a practical scenario. The comment highlights a potential inconsistency in the paper\\'s presentation and suggests that the authors should provide a more detailed explanation or discussion of these points. While the comment identifies areas that need clarification, it does not offer specific suggestions or guidance on how the authors might address these issues. Therefore, the comment is somewhat helpful, as it points out areas that need attention but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the low-resource regime. While the comment explicitly states the need for additional experiments, it does not provide specific guidance on which datasets to use or how to conduct these experiments. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results, but this inference is not direct. The comment is specific in suggesting additional experiments and encouraging experiments on the full dataset, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to justify why additional experiments are necessary or how they would improve the evaluation. The claim is based on a general suggestion, but without specific examples or detailed justification, it lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the low-resource regime. This feedback is clear and actionable, as it directly instructs the authors to expand their experimental scope and improve the comprehensiveness of their evaluation. However, the comment could be more helpful if it provided specific suggestions on which datasets to include or how to conduct these experiments. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the paper regarding the generic argument task and the random argument task, specifically questioning how they prove the authors\\' claims. It also mentions that the dataset transformation and experimental setup feel cumbersome and unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve clarity. The action is implicit and vague, as the authors are left to infer that they need to clarify the tasks and experimental setup. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity in the generic argument task and the random argument task, as well as the cumbersomeness of the dataset transformation and experimental setup. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the proof of the authors\\' claims and the clarity of the experimental setup. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generic argument task and the random argument task are unclear and that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without specific references or detailed explanations, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient evidence or justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the generic argument task and the random argument task, as well as the cumbersomeness of the dataset transformation and experimental setup. It highlights that the authors\\' claims are not clearly supported by the tasks and experimental setup, which could lead to confusion and misunderstanding. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their work. While it points out a critical area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison between the PL condition used in the paper and the PL conditions proposed in a specific arXiv paper. While this question implies that the authors should address the comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific paper \"Global Convergence of Arbitrary-Block Gradient Methods for Generalized Polyak-\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multi-stage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. The comment is clear and concrete, as it specifies exactly what needs to be added and how it should be presented. This provides the authors with a direct and specific action to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the idea of jointly discovering, hallucinating, and adapting, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on the impact of additional parameters and computational effort due to the multi-stage training and multiple discriminators. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of discussion on the impact of additional parameters and computational effort due to the multi-stage training and multiple discriminators. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multi-stage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. This feedback is clear and actionable, as it points out a critical area that needs attention and suggests a specific improvement to enhance the paper\\'s comprehensiveness and rigor. However, the comment could be more helpful if it provided additional guidance on how to conduct this analysis or what specific aspects to consider. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, it does not provide specific guidance on how the authors should address this issue or what theoretical evidence should be presented. The comment implies that the authors should provide more detailed analysis or theoretical justification, but it does not offer concrete steps or examples of what this might entail. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of the correlation between dataset size and the Frobenius norm and singular values, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of theoretical evidence for the correlation and the need for more detailed analysis across different model architectures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is underwhelming and lacks theoretical evidence. It highlights the need for more detailed analysis and theoretical justification to support the trend observed. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional evidence could be presented. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leaking is likely due to its policy being obtained through supervised training on ImageNet. It also questions the authors\\' conclusion in L114 about the pretraining dataset matching the target dataset in terms of object or scene centricity, and whether this could be a setback for SSL algorithms. The comment implies that the authors should consider these issues and potentially address them in their paper. However, it does not provide explicit instructions or concrete steps for how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should consider these points and potentially revise their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the use of AutoAugment as a stronger augmentation strategy and the authors\\' conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity. The comment further raises questions about the implications for SSL algorithms and whether combining datasets could lead to better representations. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leaking is likely due to its policy being obtained through supervised training on ImageNet. The reviewer questions the authors\\' conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity, and whether this could be a setback for SSL algorithms. The comment is mostly verifiable as it provides logical reasoning and questions that prompt the authors to consider the implications of their findings. However, it could be strengthened by referencing specific studies or examples that support the claim about information leaking or the potential impact on SSL algorithms. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leaking is likely due to its policy being obtained through supervised training on ImageNet. It also questions the authors\\' conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity, and whether this could be a setback for SSL algorithms. The comment prompts the authors to consider the implications of their findings and whether combining datasets could lead to better representations. While the comment identifies important issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. Therefore, it is somewhat helpful, as it provides insight into potential weaknesses but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be interesting but not necessary to explore how the model works with tabular data, specifically by considering each attribute dimension as a modality. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore tabular data but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this exploration could be discussed. The authors can infer that it relates to the model evaluation or methodology sections, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding as it does not explicitly mention where in the paper this should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality, would be interesting but not necessary. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this exploration would be beneficial or necessary. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be interesting but not necessary to explore how the model works with tabular data, specifically by considering each attribute dimension as a modality. This feedback is somewhat helpful as it identifies a potential area for further exploration or comparison, which could enhance the paper\\'s contribution. However, the comment lacks specific guidance or suggestions on how to implement this exploration or what specific aspects of tabular data should be considered. While it points out a potential area for improvement, it does not provide detailed instructions or examples, making it somewhat helpful but not fully actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more analysis on the multilingual alignment of entity representations, specifically recommending visualizations or case studies for different types of languages. It also raises a question about the alignment of entities from low-resourced languages with high-resourced ones. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific visualizations or case studies should be included. The action is concrete but somewhat vague in terms of execution, as the authors need to determine the specific aspects of multilingual alignment to focus on and how to present the results. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the language-agnostic characters of entity representations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more analysis on the multilingual alignment of entity representations, including visualizations or case studies for different languages. The comment also raises a question about the alignment of entities from low-resourced languages with high-resourced ones. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks analysis on the alignment of entity representations, particularly in multilingual contexts. It recommends adding more analysis, including visualizations or case studies, for different types of languages. The comment also raises a question about the alignment of entities from low-resourced languages with high-resourced ones. While the suggestion for additional analysis is logical, the comment lacks specific examples or references to support the claim that the current analysis is insufficient. This makes the claim somewhat verifiable, as the authors would need to further develop the rationale themselves to fully address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper regarding the analysis of language-agnostic characters in entity representations. It suggests that the authors should add more analysis on the multilingual alignment of entity representations, including visualizations or case studies for different types of languages. Additionally, it raises a question about the alignment of entities from low-resourced languages with high-resourced ones. This feedback is clear and actionable, providing the authors with specific areas to focus on to improve their draft. However, it could be more helpful if it included examples or detailed guidance on how to conduct the additional analysis or visualizations. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This provides a clear and explicit action for the authors to take, which is to include additional details on using attention in an appendix. The suggestion is concrete, as it specifies the exact location where the additional information should be included, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, it does not specify which part of the paper discusses attention or where the additional appendix should be placed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional details on using attention, but without clear grounding, it is difficult for the authors to effectively address the suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why additional details on attention are necessary or how they would benefit the paper. Without such justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper by adding more details on a particular aspect. However, the comment could be more helpful if it included specific questions or areas where the authors could elaborate on the use of attention. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. While it identifies specific issues, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to check for duplicates and ensure the correct publication venues and years are included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the references list, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of duplicates and missing publication venues/years, providing clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. However, it does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to verify and address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues with the references list, noting that it contains duplicates and that the publication venues and/or publication years of many of the papers are missing. This feedback is clear and actionable, as it directs the authors to verify and correct their references list to ensure accuracy and completeness. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending a specific method for verifying duplicates or suggesting ways to locate missing publication details. Overall, the comment is somewhat helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. It suggests that the authors should analyze and compare their theoretical results to those of other comparable methods. This feedback provides a clear and concrete action for the authors to take, which is to clarify the error bound and compare their results with others in the field. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound in Theorem 1 and the need for analysis and comparison with other comparable methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. The comment suggests that the authors should analyze and compare their theoretical results with those of other comparable methods. While the comment identifies a potential issue with the clarity of the theoretical analysis, it does not provide specific examples or references to support the claim that the error bound is unclear. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and that the authors need to analyze and compare their results with other comparable methods. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the authors clarify the error bound and benchmark their results against others in the field. By addressing these points, the authors can enhance the clarity and rigor of their theoretical analysis, which is crucial for the credibility and impact of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and points out that the pseudo-code of the proposed method is missing. It also references external works that may be relevant to understanding the performance difference. However, the comment does not provide explicit instructions or suggestions on how the authors should address this issue or what specific aspects of the pseudo-code should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include the missing pseudo-code and possibly explore the performance difference between explicit and implicit methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"locomotion tasks\" and the \"proposed method,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the performance difference between explicit and implicit methods and points out the missing pseudo-code of the proposed method. Additionally, it references external works that may be relevant to understanding the performance difference. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and mentions the missing pseudo-code of the proposed method. It references external works by S\u00f8ren Asmussen and Peter W Glynn and P. Florence et al., which could provide some basis for the claim. However, the comment lacks detailed reasoning or specific examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment could be strengthened by providing more detailed analysis or examples to fully justify the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the performance of explicit methods compared to implicit methods on locomotion tasks, which is an important aspect of the paper. It also points out the missing pseudo-code of the proposed method, which is a critical detail that should be included for clarity and reproducibility. Additionally, the comment references external works by S\u00f8ren Asmussen and Peter W Glynn and P. Florence et al., which could provide valuable insights into the topic. However, the comment could be more helpful if it offered suggestions on how to address the missing pseudo-code or provided more detailed guidance on the comparison between explicit and implicit methods. Overall, the comment is somewhat helpful as it identifies a critical issue and provides some context, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the use of low-resource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. It also mentions the method R3F and suggests that the authors should consider using it to maintain the generalization ability of the model. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the R3F method should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should explore the R3F method and consider its applicability to their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of low-resource language pairs to finetune the multilingual model and mentions the method R3F. It suggests that the improvement of 0.8 in some low-resource language translations is insignificant in practical terms. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The suggestion to consider the R3F method is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of low-resource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. The reviewer supports this claim by referencing the method R3F, which is known to maintain generalization ability. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a reference to a relevant work, the explanation is somewhat vague, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of low-resource language pairs to finetune the multilingual model, suggesting that the improvement of 0.8 is insignificant in practical terms. It also mentions the method R3F as a potential solution to maintain the generalization ability of the model. While the comment provides some insight into the limitations of the current approach, it lacks specific guidance on how to address the issue or implement the R3F method. The feedback is somewhat helpful as it points out a potential weakness but does not offer detailed suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific reason for the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. While the comment implies that the authors should address this issue by providing a rationale or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for the choice of Gaussian noise. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, which is the section where the authors discuss the model\\'s ability to work well for various image noise types. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises a question about the choice of Gaussian noise in the experiments and asks for a particular reason for this choice. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of Gaussian noise in the experiments, suggesting that there might be a particular reason for this choice. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. This is a valid point that could help the authors clarify their methodology and provide a more comprehensive evaluation of their model. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or provide a rationale for the choice of Gaussian noise. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should visualize the effect of increasing dimensionality on the performance of existing PU learning methods. This is a clear and concrete action for the authors to take, as it provides a specific direction for improving their draft. The comment is specific in detailing what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the performance of existing PU learning methods as the dimensionality of the data increases. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the visualization of this effect. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors visualize the effect of increasing dimensionality on the performance of existing PU learning methods. This is a clear and actionable suggestion that can significantly enhance the paper\\'s research motivation and credibility. By providing a concrete direction for visualizing this effect, the comment offers valuable guidance for the authors to improve their draft. However, the comment could be more helpful if it included specific examples or suggestions on how to visualize this effect. Overall, the comment is mostly helpful as it provides a clear and actionable direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While the comment implies that the authors should consider moving this information to the supplementary materials, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider moving the information to the supplementary materials. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific, as it clearly identifies a potential improvement by recommending the inclusion of supplementary materials. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. The comment lacks specificity and does not offer a detailed explanation or references to support the claim. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While it provides a specific suggestion for improvement, it lacks depth and does not explain why this change would be beneficial or how it would enhance the paper. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more actionable and detailed to fully assist the authors in making the necessary changes. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea of speaker-listener communication from a teachability perspective, referencing external work. Additionally, it points out that the differences in figures seem too small and suggests checking for useful communication. While the comment provides some guidance on how to simplify the results and improve clarity, it lacks explicit instructions on how to implement these suggestions. The authors are given a general direction but may need to infer the specific actions to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea of speaker-listener communication from a teachability perspective, referencing external work. Additionally, it points out that the differences in figures seem too small and suggests checking for useful communication. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the results or discussion sections. The comment is specific in suggesting improvements and referencing external work, making it fully grounded. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the result descriptions are needlessly convoluted and suggests that the authors consider a related idea of speaker-listener communication from a teachability perspective. The reviewer provides a specific reference to external work, which supports the claim by suggesting that the authors should check for useful communication. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to follow up on the suggestion to understand its full implications and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the complexity and clarity of the result descriptions, suggesting that they are needlessly convoluted. It provides a specific suggestion to consider a related idea of speaker-listener communication from a teachability perspective, referencing external work. This feedback is actionable as it offers a clear direction for the authors to improve the clarity and simplicity of their results. Additionally, the comment points out that the differences in figures seem too small and suggests checking for useful communication. While the comment could be more helpful by providing more detailed guidance on how to implement these suggestions, it still offers valuable insights for the authors to enhance their draft. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the approximation error should be mathematically characterized, which provides a clear and direct action for the authors to take. The comment is specific in detailing what needs to be done, namely, providing a mathematical characterization of the approximation error. This guidance is concrete, as it specifies the exact improvement needed, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the approximation error, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing a mathematical characterization of the approximation error. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approximation error is ambiguous and suggests providing a mathematical characterization. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the current definition is unclear or how a mathematical characterization would improve clarity. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approximation error definition, noting that it is ambiguous without additional context. It suggests providing a mathematical characterization to clarify the concept. This feedback is clear and actionable, as it directs the authors to make a specific improvement to enhance the clarity and precision of their work. However, the comment could be more helpful if it included examples or additional guidance on how to mathematically characterize the approximation error. Overall, the comment is mostly helpful as it effectively points out a potential area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific line (ln. 180--182) where Corollar 10 is discussed, and it highlights a potential issue with the claim that uncertainty sampling is not minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ln. 180--182,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made in this section, namely that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific line in the paper where a claim is made about uncertainty sampling and its relationship to minimizing the expected convex surrogate. It points out that the claim is based on Corollar 10, which only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss. This feedback is valuable as it highlights a potential misconception in the paper and suggests that the authors should clarify or rephrase their claim to ensure accuracy. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific changes should be made to the draft. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. While the comment identifies a specific issue with the model dynamics, it does not provide explicit guidance on how to address this problem or suggest alternative approaches. The action is implicit and somewhat vague, as the authors can infer that they need to consider ways to improve the dynamics and complexity of the model. However, without concrete suggestions or examples, the comment lacks clarity and is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed model\" and the \"evolution model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the model dynamics, noting that the model produces only one node changing cluster per time step and that the evolution model is simplistic, with no other edges changing except those associated with the 1 node changing cluster. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. The comment provides logical reasoning by explaining the consequences of the reassignment probability and the simplicity of the evolution model. However, it lacks specific examples or references to support the claim that this is a significant issue or how it affects the overall performance of the model. Therefore, the comment is somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed model, noting that it produces only one node changing cluster per time step on average due to the reassignment probability being 1/n. This results in slow dynamics, as the model can only change one node at a time. Additionally, the comment points out that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. This feedback is valuable as it highlights a potential limitation in the model\\'s dynamics and complexity, which the authors can address to improve their draft. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as proposing alternative models or methods for improving the dynamics. Overall, the comment is mostly helpful as it identifies a critical area for improvement but lacks detailed guidance on how to achieve it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that there are missing details about the division to train and test sets, including numbers and the method of division (random or other considerations). It clearly instructs the authors to add these details, providing a direct action for improvement. The comment is specific and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for details about the division to train and test sets, including numbers and the method of division. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added, such as details about the division method and numbers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are missing details about the division to train and test sets, including numbers and the method of division. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the details about the division to train and test sets, including numbers and the method of division. It clearly instructs the authors to add these details, which are crucial for transparency and reproducibility. By providing a direct and actionable suggestion, the comment offers valuable guidance for improving the clarity and robustness of the paper. However, it could be more helpful if it provided additional context or examples on how to present these details effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the need for human labor in building text descriptions and the potential scalability issue with long-text inputs. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for how to address the human labor issue or how to improve scalability. The comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of human labor in building text descriptions and the scalability of the framework with long-text inputs. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for human labor and the scalability issue, but it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two claims: the need for human labor in building text descriptions and the potential scalability issue with long-text inputs. The first claim is based on the observation that text descriptions still require human labor, which is a factual observation. However, the second claim about scalability is less verifiable, as it lacks specific examples or references to support the assertion that long-text inputs restrict scalability. The comment could be strengthened by providing more detailed reasoning or evidence to substantiate the claim about scalability. Therefore, the comment is somewhat verifiable, as it provides some support but lacks full justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues: the need for human labor in building text descriptions and the potential scalability issue with long-text inputs. It acknowledges the complexity of determining the optimal textual format for policy learning, which varies across tasks and models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the scalability of their framework. While it highlights important areas for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out potential weaknesses but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance improvement of the proposed methods is not significant, as evidenced by the figure 3, and recommends using tables to show the key improvements more intuitively and in detail. While the comment provides a clear action\u2014using tables to present the key improvements\u2014it does not specify which tables should be used or how to present them. The authors are left to infer the details of implementing this suggestion, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods is not significant, as evidenced by the figure, and suggests using tables to show the key improvements more intuitively and in detail. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance improvement of the proposed methods is not significant, based on the figure 3. However, it does not provide specific details or data to support this claim, such as comparisons to other methods or baselines. The suggestion to use tables to present the key improvements is a logical suggestion, but without detailed evidence or examples, the claim remains somewhat verifiable. The authors would need to make a significant effort to verify the claim themselves, as the comment lacks the necessary evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the performance improvement of the proposed methods appears not to be significant, as evidenced by figure 3. It suggests using tables to present the key improvements more intuitively and in detail. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of results. However, the comment could be more helpful if it included specific examples of how the tables should be structured or what aspects should be highlighted. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the experimental validation, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to provide more detailed information about the optimization strategy and consider related works, but the comment lacks specific instructions on how to implement these improvements. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer concrete steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental validation\" and \"shallow networks\" being considered, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental validation, such as the lack of description of the optimization strategy and the consideration of layer redundancy in the context of network pruning. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental validation is not convincing, specifically mentioning the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. The reviewer also points out a minor issue with positioning with respect to related works, such as layer redundancy in the context of network pruning. While the comment provides some evidence by referencing a specific work on network pruning, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to further explore the issue and provide more detailed explanations to fully address the critique. Therefore, the comment is somewhat verifiable, as it provides some evidence but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the experimental validation section, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how to address them. The authors are left with a general understanding of the issues but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not provide any guidance on how the authors might prove these results or what specific theoretical aspects should be explored. The action is implicit and vague, as the authors are left to infer that they need to provide theoretical evidence or results to support their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the lack of theoretical results, but it is not grounded as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or what theoretical results could be explored. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors can provide more evidence to prove or disprove it. While the comment implies that the authors should provide evidence to support or refute the hypothesis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence to substantiate the hypothesis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. However, it does not specify which part of the paper this hypothesis pertains to, making it weakly grounded. The comment is specific in suggesting that the human test results might support the hypothesis but questions whether the authors can provide more evidence to prove or disprove it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. While the comment provides a logical reasoning for the hypothesis, it lacks specific examples or references to support the claim. The suggestion for additional evidence is a clear indication of what the authors could do to improve the draft, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a hypothesis about the two parts of the paper, suggesting that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. This feedback is somewhat helpful as it identifies a potential area for further exploration and evidence gathering. However, it lacks specific guidance on how the authors might gather or present this evidence, which could make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the model was only tested on a single supporting fact dataset for the bAbI task. It implies that the authors should consider testing the model on other tasks in the bAbI dataset. However, the comment does not provide explicit instructions or concrete guidance on how to address this issue, such as suggesting specific tasks to test or recommending additional datasets. The action is implicit and somewhat vague, as the authors can infer that they need to test the model on more tasks but may not be entirely sure which ones to prioritize. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"bAbI\" and \"Task 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the model was only tested on a single supporting fact dataset for Task 1. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the model testing for bAbI. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the model testing for bAbI, specifically asking whether the model was only tested on a single supporting fact dataset for Task 1. This is a relevant point that could impact the validity and generalizability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what additional testing might be needed. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should improve Section 3.2 by providing more illustrations and examples. This feedback is clear and direct, giving the authors a specific action to take to enhance the clarity and comprehensiveness of their draft. The comment provides a concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more illustrations and examples in Section 3.2 to improve clarity. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it is difficult to follow Section 3.2, implying that the content is unclear or lacks clarity. However, the comment does not provide specific examples or detailed reasoning to support this claim. It suggests that the authors might improve the section by adding more illustrations and examples, but this is not a fully developed argument. The lack of detailed justification or examples makes the claim somewhat verifiable, as it provides a direction for improvement but lacks the necessary evidence or explanation to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It suggests that the authors might improve the section by providing more illustrations and examples, which could enhance its clarity and comprehensiveness. While the comment highlights a potential area for improvement, it lacks detailed guidance or specific examples of what kind of illustrations or examples would be beneficial. This limits the comment\\'s helpfulness, as it provides a general direction but does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the technical contribution is limited, suggesting that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any specific guidance or suggestions on how the authors could improve their technical contribution or what aspects of the typical model could be leveraged to enhance their work. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical contribution is limited and does not provide a specific part of the paper where this issue is addressed. It mentions the cross-domain recommendation setting, but without further context or detailed explanation, the authors may struggle to identify the exact section or aspect of the paper that needs improvement. The comment lacks specificity in detailing what is considered typical or how the technical contribution could be enhanced. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution is limited and does not provide a significant extension based on a typical model for the cross-domain recommendation setting. However, it lacks specific examples, comparisons, or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical contribution of the paper is limited, specifically noting that there is no significant technical contribution or extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any specific examples, comparisons, or suggestions for improvement. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of what aspects of their work need to be addressed or how to enhance their technical contribution. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. While the comment explicitly states the action to take, it lacks concrete guidance on how to implement this suggestion or what specific fully-supervised baselines should be included. The authors are left with a clear direction but without detailed instructions on how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding fully-supervised baselines for small models in Table 1 to understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the addition of fully-supervised baselines but lacks grounding as it does not explicitly mention the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or how it would contribute to the understanding of the gap. Without such justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. This is a clear and actionable suggestion that could provide valuable insights into the performance of the models. However, the comment could be more helpful if it explained why this addition is necessary or how it would impact the understanding of the gap. Despite this, the suggestion is a useful direction for the authors to consider, making the comment mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically asking about the time required to calculate the hypervolume of different regions in each step of LaMOO. It also mentions that the computation of hypervolume could be time-consuming, especially for problems with many objectives. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete suggestions on how to improve the time complexity or optimize the algorithm. The action is implicit and somewhat vague, as the authors need to infer that they should address the time complexity issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the time complexity of the proposed algorithm, particularly the repeated calculation of hypervolume for promising region selection. The comment raises a concern about the practicality of LaMOO for problems with many objectives, which is a clear and specific issue to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in LaMOO could be time-consuming, especially for problems with many objectives. While the comment identifies a potential issue, it lacks specific examples or references to substantiate the claim that the time complexity is a problem. The authors are left to infer the potential impact on the practicality of the algorithm, which requires further elaboration to be fully verifiable. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the concern but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in LaMOO could be time-consuming, especially for problems with many objectives. This is an important consideration for the practicality of the algorithm, as it could impact the feasibility of using LaMOO for certain types of problems. The comment prompts the authors to consider this aspect of their algorithm and potentially explore ways to optimize the time complexity. However, the comment could be more helpful if it provided specific suggestions or examples of how to address this issue. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance on how to implement it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the dataset used in the experiments is small but suggests that results on larger datasets like ImageNet would be more convincing. However, it also states that this is a minor issue and does not affect the overall quality of the paper. The comment implies that the authors should consider running experiments on larger datasets, but it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider running experiments on larger datasets, but the comment lacks detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of the dataset being small, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the suggestion to include results on larger datasets like ImageNet, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the dataset used in the experiments is small and suggests that results on larger datasets like ImageNet would be more convincing. However, the comment does not provide any supporting evidence, reasoning, or references to justify why larger datasets are necessary or how they would impact the paper\\'s conclusions. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to be considered fully verifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the dataset used in the experiments is small and suggests that results on larger datasets like ImageNet would be more convincing. However, it also states that this is a minor issue and does not affect the overall quality of the paper. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address the issue of dataset size. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, as well as the generic and vague title. It suggests being honest and direct in the critique and provides a specific example of what \"brittle convergence properties\" means. Additionally, it mentions that DeepRL methods are widely adopted and suggests considering the landscape 10 years ago. While the comment provides some guidance on what to address, it lacks concrete details on how to implement these suggestions. The authors are given a general direction but may need to infer the specific actions to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues, including the limitations of evolutionary methods, the generic and vague title, and the need for more detailed discussion on leveraging state, reactiveness, and learning during an episode. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting that the title is too generic and vague and that the authors should be more precise in their critique. It also asks for clarification on the term \"brittle convergence properties\" and provides an example of DeepRL methods being widely adopted. Overall, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point makes several claims, including that the paper discusses limitations of evolutionary methods, the title is too generic and vague, and that DeepRL methods are widely adopted. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The mention of \"brittle convergence properties\" is not explained, and the suggestion to be more precise in critiques is not accompanied by examples or detailed guidance. The comment also suggests considering the landscape 10 years ago, but this does not contribute to the verifiability of the claims. Overall, the comment lacks sufficient evidence or reasoning to support its claims, making them unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, which could enhance the paper\\'s contribution. It also points out that the title is too generic and vague, suggesting that being more precise in the critique would be beneficial. Additionally, the reviewer questions the term \"brittle convergence properties\" and provides an example of DeepRL methods being widely adopted. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending specific topics for discussion or providing examples of how to improve the title. While it highlights important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image, and how the edges are handled in areas where depth discontinuities occur. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The authors know they need to provide more information about the synthesis process, but the comment lacks specific suggestions on how to improve the explanation or what details should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks about how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas with depth discontinuities. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing what needs to be addressed, providing clear guidance on what aspects of the synthesis process are unclear. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. While the questions are valid, they do not provide specific examples or references to support the claim that these aspects are unclear or lacking in the paper. The comment lacks detailed reasoning or evidence to substantiate the need for clarification, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. These questions highlight areas where the paper could be improved by providing more detailed explanations of the methodology. However, the comment does not offer specific suggestions or guidance on how the authors might address these issues, such as recommending additional experiments or clarifications. While it identifies important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims a unique contribution regarding the number of points and apriori knowledge needed for its algorithm, but it suggests that empirical justification would be beneficial. However, it does not provide specific guidance on how to conduct this empirical justification or what kind of evidence would be sufficient. The action is implicit and somewhat vague, as the authors can infer that they need to provide empirical evidence but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first claimed contribution\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper lacks empirical justification for the claim about the number of points and apriori knowledge needed for the algorithm. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s first contribution is unique because it does not require as many points or apriori knowledge about dimensions of subspaces. However, the comment suggests that empirical justification would be beneficial. While the claim is logical, it lacks specific examples or references to support the assertion that empirical justification is necessary. The reasoning is somewhat verifiable, as it provides a general idea of what could be improved, but it does not offer detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of empirical justification for the claim about the algorithm\\'s unique contribution. It suggests that providing empirical evidence would strengthen the paper\\'s argument. However, the comment does not provide specific guidance on how to conduct this empirical justification or what kind of evidence would be sufficient. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, it highlights that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. While the comment identifies issues with novelty and similarity, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should improve the novelty and differentiate their approach from existing work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"specific components of the approach,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the novelty of the approach, noting that the weak predictors used are not novel and that the sampling strategy is similar to epsilon-greedy and BRP-NAS. The comment provides specific examples of the predictors and the similarity to existing work, such as MLP, Regression Tree, and Random Forest. Additionally, it highlights the similarity in results with BRP-NAS, as shown in Table 2 in Appendix C. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. The reviewer also notes that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, the reviewer states that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. The comment provides specific references to existing works, such as [2,3,7], which supports the claim that the components are not novel. However, the comment could be strengthened by providing more detailed comparisons or additional references to further substantiate the claim. Overall, the claim is mostly verifiable, as it is supported by specific references and logical reasoning.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the approach, noting that the specific components, such as the weak predictors used (MLP, Regression Tree, or Random Forest), have been used for NAS performance prediction before. It also points out that the sampling strategy is similar to epsilon-greedy and the same as that in BRP-NAS. Additionally, it highlights that the results of the proposed WeakNAS are almost the same as BRP-NAS, as shown in Table 2 in Appendix C. This feedback is somewhat helpful as it provides clear and actionable information about the lack of novelty in the approach. However, it could be more helpful if it offered suggestions on how the authors might differentiate their approach or address these concerns. Overall, the comment provides valuable insights but lacks depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al. 2015) and suggests that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and provides a concrete action for the authors to take, which is to include a discussion on the comparison with RMED. The comment is specific in detailing what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed S1DB-ED algorithm\" and \"RMED (Komiyama et al. 2015),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the novelty of the algorithm and the need for a discussion on the comparison with RMED. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the novelty of the proposed S1DB-ED algorithm, noting that it is too similar to RMED (Komiyama et al. 2015). It suggests that the paper needs to provide a sufficient discussion on the comparison with RMED to justify its novelty. This feedback is clear and actionable, as it directs the authors to include a discussion on the comparison with RMED to enhance the novelty of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify what aspects of the previous work should be discussed or how the authors should incorporate this discussion into their paper. The comment lacks explicit guidance or concrete suggestions on how to address this issue, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection where the discussion should be included. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this issue. The comment is specific in identifying the need for a comprehensive discussion of previous work, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which previous works should be discussed or how this omission affects the paper\\'s contribution. Without specific examples or references to previous works, the claim lacks verifiability. The authors would need to infer the importance of including a comprehensive discussion of previous work, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a significant gap in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is a critical observation that could significantly impact the paper\\'s contribution and credibility. However, the comment lacks specific guidance on what aspects of previous work should be discussed or how this discussion could be integrated into the paper. Without actionable suggestions or examples, the authors are left with a general understanding of the issue but without clear direction on how to address it. Therefore, the comment is somewhat helpful, as it points out a significant weakness but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the OT sample selection process, specifically whether it runs once or iteratively, and suggests that more details and a flow chart would be helpful. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment implies that the authors should provide more details and a flow chart, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more details and a flow chart. However, the comment does provide a clear direction for improvement by highlighting the need for more detailed explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2.4.3\" and \"equation (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the OT sample selection process, suggesting that more details and a flow chart would be helpful. The comment also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the OT sample selection process, suggesting that more details and a flow chart would be beneficial for clarity. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that these details are necessary or how they would enhance the clarity of the paper. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as the authors would need to infer the importance of these details themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential gap in the clarity of the paper regarding the OT sample selection process, specifically questioning whether it runs iteratively or only once. It suggests that more details and a flow chart would be beneficial for readers to understand the process. Additionally, it asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. This feedback is clear and actionable, as it provides specific suggestions for improving the clarity and comprehensibility of the paper. By addressing these points, the authors can enhance the reader\\'s understanding of the methodology and its execution. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper regarding the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix, asking why these methods are not included in the experiments and how they compare to ConBO. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include experiments with continuous tasks and consider including entropy methods in the experiments. The action is concrete but somewhat vague, as it lacks detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion on how KG handles the continuous task setting, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of experiments with continuous tasks and questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix. The comment further asks how these methods compare to ConBO. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix and asks how these methods compare to ConBO. While the comment identifies a potential gap in the experimental setup, it lacks specific examples or references to support the claim that these methods should be included in the experiments. The reasoning is somewhat verifiable, as it highlights a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix and asks how these methods compare to ConBO. This feedback is clear and actionable, as it prompts the authors to address the omission of continuous tasks in their experiments and to consider including entropy methods for conditional optimization in the main text. By providing specific questions and suggestions, the comment offers valuable guidance for improving the paper. However, it could be more helpful if it provided examples of how these experiments might be conducted or how they could be integrated into the existing framework. Overall, the comment is mostly helpful, as it effectively directs the authors to address a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a comparison of GCG with other LLMs could be included, as it demonstrated the transferability of its approach. Additionally, it points out a minor issue with the jailbreaking percentage for certain LLMs. While the comment implies that the authors should include this comparison and address the jailbreaking issue, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specifics of what needs to be done to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GCG\" and \"LLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison with other LLMs and the issue of low jailbreaking percentages for certain LLMs. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a comparison with other LLMs could be included, as it demonstrated the transferability of GCG's approach. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this comparison is necessary or how it would benefit the paper. The mention of a low jailbreaking percentage for certain LLMs is also not further elaborated on. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the inclusion of a comparison with other LLMs, which could demonstrate the transferability of GCG's approach. This is a clear and actionable piece of feedback that could enhance the paper\\'s contribution and relevance. Additionally, the comment points out a minor issue with the jailbreaking percentage for certain LLMs, which could be addressed to improve the paper\\'s thoroughness. However, the comment could be more helpful if it provided additional context or examples of how such a comparison might be conducted or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers clear and actionable guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the authors\\' explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. While it acknowledges the novelty of the approach, it explicitly requests a more detailed explanation to better understand the difference. This feedback is clear and provides a specific action for the authors to take, which is to provide a more detailed explanation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction of unsupervised feature selection from a diffusion perspective, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a more detailed explanation of the difference between similarity and exit times in nature. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. The reviewer acknowledges the novelty of the approach but expresses difficulty in understanding the distinction. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the explanation is unclear. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses a need for a more detailed explanation to better understand the distinction. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s explanation, prompting the authors to provide a clearer explanation. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of how the distinction might be clarified. Overall, the comment is somewhat helpful as it directs the authors to a specific area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. While it implies that the authors should address this limitation, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to the question. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the limitations of the framework, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the framework is limited in this way. Without such information, the authors may find it challenging to address the question or understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. This is a relevant point that could help the authors identify potential areas for improvement or expansion in their work. However, the comment lacks specific guidance or suggestions on how to address this limitation or what specific aspects of the framework might need improvement. While it points out an important area for consideration, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the calculation of precision/recall/F1-score for a 4-class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should include these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these metrics and AUC results. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the calculation of precision/recall/F1-score for a 4-class classification of breast density and the reporting of AUC results for breast cancer detection. It also specifies the need for sensitivity and specificity at different operating points for model performance comparisons. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual questions about the calculation of precision/recall/F1-score and the reporting of AUC results. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the calculation and reporting of metrics for a 4-class classification of breast density and breast cancer detection. It suggests that providing AUC results with sensitivity and specificity at different operating points could be more informative for comparisons. This feedback is clear and actionable, as it directs the authors to include specific metrics that could enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it provided examples of how these metrics are typically reported or suggested specific ways to present them. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and comprehensiveness of their results.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the creation of the dataset is optional and that the Kialo dataset, which is well-studied in the community, provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner and that the authors\\' dataset can be considered extra data to learn from. While the comment implies that the authors should consider using the Kialo dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should use the Kialo dataset rather than being directly told to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is well-studied in the community. It also notes that the Kialo dataset provides pairs of short claims and their counters, and that it is cleaner than the dataset created by the authors. However, the comment does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The suggestion to use the Kialo dataset is specific, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the creation of the dataset is optional and that the Kialo dataset, which is well-studied in the community, provides pairs of short claims and their counters. The reviewer also notes that the Kialo dataset is cleaner and that the authors\\' dataset can be considered extra data to learn from. This claim is somewhat verifiable as it provides a logical reasoning for why the Kialo dataset might be a better option, but it lacks specific examples or references to support the claim fully. The authors would need to make an effort to verify the claim themselves by exploring the Kialo dataset or similar resources. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the creation of the dataset is optional and that the Kialo dataset, which is well-studied in the community, provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner and that the authors\\' dataset can be considered extra data to learn from. This feedback is somewhat helpful as it points out an alternative dataset that could be used for comparison, which could potentially improve the paper. However, the comment lacks specific guidance on how to incorporate the Kialo dataset or why it might be beneficial for the authors to use it. Additionally, it does not provide suggestions on how to evaluate or analyze the Kialo dataset, which would be beneficial for the authors to improve their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the use of Transformer in the paper, noting that it is no longer novel in the field and that the authors' modification (cross-layer) does not bring significant insight. The reviewer also questions the significance of the self-cross attention improvement in the ablation study, suggesting that it is limited (<1%). However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific modifications should be made to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the novelty and impact of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Transformer\" and \"cross-layer,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the modification does not bring much insight and that the self-cross attention improvement is limited. Additionally, it provides specific examples from the ablation study (table 4 and 5) to support the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of Transformer in the paper is not novel and that the authors' modification (cross-layer) does not bring significant insight. The reviewer supports this claim by referencing the widespread adoption of Transformer in NLP and vision tasks, which suggests that the modification is not innovative. Additionally, the reviewer points out that the self-cross attention improvement is limited (<1%), further supporting the claim that the modification does not bring significant improvements. The comment is mostly verifiable as it provides logical reasoning and specific examples from the ablation study to substantiate the claim. However, it could be strengthened by referencing specific studies or literature that support the claim about the widespread adoption of Transformer. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a critical analysis of the paper\\'s use of Transformer, noting that it is no longer novel in the field and that the authors\\' modification (cross-layer) does not bring significant insight. The reviewer also questions the significance of the self-cross attention improvement, suggesting that it is limited (<1%). This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s contribution, but it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. While it identifies areas for improvement, the comment could be more helpful by providing actionable advice or examples of how the authors might enhance their work. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more tasks and sequential results. However, the comment does provide a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the limited number of tasks and suggesting that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, specifically the limited number of tasks. It suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. This feedback is somewhat helpful as it points out an area for improvement, but it lacks depth and does not provide specific guidance on how to implement this change or what additional information should be included. The authors are given a direction to consider, but the comment could be more helpful with additional details or suggestions. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and concrete action for the authors to take, specifying exactly what additional tasks they should include in their experiments. The comment is specific and actionable, giving the authors a direct path to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, specifically mentioning \"sentence similarity tasks and open domain QA tasks.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited and suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. The comment provides a logical reasoning by pointing out that these tasks are common in the NLP field and could enhance the scope of the experiments. However, the comment lacks specific examples or references to support the claim that these tasks are necessary or how they would improve the experiments. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, specifically noting that the authors only conduct evaluations on sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing a specific direction for the authors to expand their experiments and enhance the scope of their work. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their evaluation. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include the prompt in the appendix or supplement, providing a clear action for the authors to take. Additionally, it suggests that the abstract might be difficult to understand and recommends rephrasing it. However, the comment does not specify which lines in the abstract are problematic or how to improve the clarity. The feedback on Figure 2 is also vague, as it lacks specific guidance on how to address the issue of unclear interpretation and labeled y-axes. Overall, the comment is mostly actionable as it provides explicit actions but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the appendix or supplement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the appendix or supplement and provides a suggestion for improving the clarity of the abstract. The comment also mentions specific issues with Figure 2, such as the unclear interpretation and lack of labeled y-axes, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the prompt should be included in the appendix or supplement, providing a clear and actionable suggestion for improvement. However, the comment does not provide any supporting evidence or reasoning to justify why this is necessary or how it would enhance the paper. Additionally, the comment about the abstract being difficult to understand and recommending rephrasing lacks specific examples or detailed guidance. Similarly, the comment about Figure 2 is vague, as it does not specify what is unclear or how to address the issue of labeled y-axes. Overall, the comment lacks sufficient justification and evidence to be fully verifiable, making it difficult for the authors to understand and act upon the suggestions. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides two main pieces of feedback. First, it suggests that the prompt should be included in the appendix or supplement, which is a clear and actionable suggestion for improving the paper\\'s clarity and accessibility. This feedback is valuable as it helps the authors ensure that important information is readily available to readers. Second, the comment identifies specific issues with the abstract, noting that lines 016-019 are difficult to understand and recommends rephrasing. This feedback is also somewhat helpful as it points out a potential area for improvement in the paper\\'s clarity. However, the comment could be more helpful if it provided specific suggestions on how to rephrase the abstract to improve clarity. Overall, the comment is mostly helpful as it offers actionable feedback on two important aspects of the paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. While the comment raises a valid point, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify their motivation. The authors are left to infer that they need to provide a clearer explanation or justification for their choice, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this analysis is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity in detailing what needs to be clarified or improved regarding the motivation for analyzing only the last convolutional layer. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the motivation for analyzing only the last convolutional layer, specifically questioning why numerosity would not appear in earlier layers. This is an important point that could impact the clarity and justification of the paper\\'s analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide a clearer explanation. While it identifies a potential weakness, it does not offer actionable steps or examples for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the parameter S remains a problem, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps the authors should consider to improve the parameter setting. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the issue of setting the parameter S, but it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the parameter S setting is problematic or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The comment states that \"How to set the parameter S remains a problem,\" but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific issue with the parameter S, indicating that it remains a problem. However, it does not provide any guidance or suggestions on how to address this issue or improve the parameter setting. Without actionable feedback or detailed insights, the authors are left without a clear path forward to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. While the comment implies that the authors should consider conducting a human evaluation, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The authors are left to infer that they should consider conducting a human evaluation, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper discusses the evaluation metrics or the caption generation process, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to include human evaluation, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this suggestion and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback highlights a potential weakness in the paper\\'s evaluation methodology and provides a clear direction for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects of the caption generation process should be evaluated by humans. While it identifies an area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but requires further elaboration to be fully actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while the introduction claims that shape constraints do not require tuning a free parameter, the choice of employing a convex or concave constraint, and an increasing/decreasing constraint, can be considered a hyperparameter that needs to be chosen or tuned. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to apply the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that shape constraints do not require tuning a free parameter. The comment points out that the choice of convex or concave constraints and increasing/decreasing constraints can be considered hyperparameters that need to be chosen or tuned. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction statement about shape constraints not requiring tuning is technically true but misleading. The reviewer provides a logical reasoning by pointing out that the choice of convex or concave constraints and increasing/decreasing constraints can be considered hyperparameters that need to be chosen or tuned. This reasoning is based on a logical interpretation of the claim and the distinction between constraints and hyperparameters, making the claim somewhat verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim that these choices should be considered hyperparameters. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential misconception in the introduction regarding the claim that shape constraints do not require tuning a free parameter. It points out that the choice of convex or concave constraints, and increasing or decreasing constraints, can be considered hyperparameters that need to be chosen or tuned. This feedback is valuable as it highlights a specific area where the authors may need to clarify or correct their claims, ensuring that their work is accurate and clear. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present the hyperparameters in a more accurate manner. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It highlights a specific assumption (Assumption 4.1) that indicates $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be trivially adapted with straightforward modifications following Modification 1 in Appendix C. This provides a clear and concrete action for the authors to take, which is to reconsider the theoretical proof and potentially revise it to enhance its rigor and novelty. The comment is explicit and provides detailed guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical proof for convergence, noting that it lacks novelty and rigor due to the trivial adaptation following Modification 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical proof for convergence appears trivial and lacks novelty and rigor. It supports this claim by pointing out that Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer also suggests that the convergence proof can be trivially adapted with straightforward modifications following Modification 1 in Appendix C. This reasoning is somewhat verifiable as it provides a logical explanation for the claim, but it lacks specific examples or references to support the claim fully. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It points out that Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be trivially adapted with straightforward modifications following Modification 1 in Appendix C. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By addressing this issue, the authors can enhance the rigor and novelty of their theoretical proof, which is crucial for the credibility of their work. However, the comment could be more helpful if it offered suggestions on how to improve the rigor and novelty of the proof. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the experimental setup borrowed from [2] is only semi-real because it involves artificially created multi-node seed cascades by merging single-node seed cascades. This provides a clear and direct action for the authors to take, which is to mention this fact clearly in their paper. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental setup borrowed from [2], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, namely that it is only semi-real due to the artificial creation of multi-node seed cascades by merging single-node seed cascades. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup borrowed from [2] is only semi-real because it involves artificially created multi-node seed cascades by merging single-node seed cascades. This claim is somewhat verifiable as it provides a logical reasoning for the classification, based on the description of the experimental setup. However, the comment lacks specific examples or references to [2] to fully substantiate the claim. Providing more detailed evidence or references would strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that it is only semi-real due to the artificial creation of multi-node seed cascades by merging single-node seed cascades. This is a clear and actionable point that the authors should address to ensure the validity and credibility of their results. By mentioning this issue clearly, the authors can improve the transparency and accuracy of their experimental setup. However, the comment could be more helpful if it provided suggestions on how to clarify this point in the paper or offered additional context on the implications of this setup. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues: the limited scope of datasets and models used in the study and the lack of assessment of other important biases and datasets. It also points out the absence of assessments on state-of-the-art generative models like GPT. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should expand their dataset and model selection and include assessments on additional biases and models like GPT. However, the comment lacks concrete suggestions on how to implement these changes or what specific biases and models should be included. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitations of the datasets and models used in the study, specifically mentioning the bias benchmarks and the absence of assessments on state-of-the-art generative models like GPT. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the limitations of the dataset and model selection and the need for additional assessments. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the datasets and models used in the study are limited and that the bias benchmarks only assess gender, race, and religion. It also mentions the absence of assessments on state-of-the-art generative models like GPT. While the comment identifies specific limitations, it lacks detailed justification or examples to fully substantiate the claim. The authors would need to infer the importance of these assessments and the potential impact on the study\\'s conclusions. Therefore, the comment is somewhat verifiable, as it provides some basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the study, noting that the datasets and models used are limited and that the bias benchmarks only assess gender, race, and religion. It also points out the absence of assessments on state-of-the-art generative models like GPT. This feedback is valuable as it highlights areas where the study could be expanded to include a broader range of biases and models, which would enhance its scope and relevance. However, the comment could be more helpful if it provided specific suggestions on how to address these limitations, such as recommending additional datasets or models to consider. Overall, the comment is mostly helpful as it directs the authors\\' attention to important areas for improvement, but it lacks detailed guidance on execution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a contradiction between two statements regarding the multi-env model: one stating a performance loss and another claiming knowledge sharing leads to outperformance. The reviewer requests clarification, indicating that the authors need to address this contradiction. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to clarify the contradiction or what aspects of the statements are confusing. The authors are left to infer that they need to provide a clearer explanation or resolution to the contradiction. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statements about the multi-env model, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of contradiction between the two statements regarding the model's performance and knowledge sharing. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the contradiction between two statements regarding the multi-env model: one stating a performance loss and another claiming knowledge sharing leads to outperformance. The reviewer requests clarification, indicating that the authors need to address this contradiction. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim of contradiction. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a contradiction in the paper regarding the performance of the multi-env model. It points out that the model is stated to have an inevitable performance loss but also outperforms the single-env model due to knowledge sharing. This contradiction highlights a potential inconsistency in the paper that needs clarification. The comment is somewhat helpful as it prompts the authors to clarify this contradiction, which could be an important aspect of their work. However, it could be more helpful if it provided suggestions on how to address the contradiction or offered additional context to better understand the implications. Overall, the comment is somewhat helpful as it directs the authors to a critical area needing clarification.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the method's sensitivity to hyperparameters, suggesting that careful hyperparameter search is necessary to find the proper value of $\\\\alpha$ for a new problem. However, it does not provide explicit guidance on how to perform this search or what specific steps to take. The action is implied, as the authors can infer that they need to conduct a hyperparameter search, but it remains vague without concrete details on how to execute this task. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the sensitivity of the method to hyperparameters, specifically mentioning the need to perform a careful hyperparameter search to find the proper value of $\\\\alpha$ for a new problem. However, it does not specify which part of the paper discusses the method or the hyperparameter search, making it weakly grounded. The comment is specific in detailing the issue of hyperparameter sensitivity and the need for careful search, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is sensitive to hyperparameters, requiring a careful hyperparameter search to find the proper value of $\\\\alpha$ for a new problem. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method, noting its sensitivity to hyperparameters and the need for careful hyperparameter search to find the proper value of $\\\\alpha$ for a new problem. This feedback is somewhat helpful as it highlights a potential limitation of the method that the authors may need to address. However, the comment lacks specific guidance on how to conduct the hyperparameter search or what specific aspects of the method are sensitive to hyperparameters. While it points out an area for improvement, it does not provide detailed suggestions or examples to help the authors address the issue effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or a citation to the metrics. This feedback is explicit, as it clearly states what the authors need to do to improve their draft: either provide an explanation or a citation to the metrics used. The action is concrete, as it specifies exactly what the authors need to do to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"description of the metrics,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an explanation or a citation of the metrics used in the paper. This provides clear guidance on how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of the metrics is limited and suggests that an explanation or citation of the metrics would be beneficial. However, the comment does not provide specific examples or detailed reasoning to support why the current description is insufficient or how an explanation or citation would improve the paper. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically the lack of an explanation or citation for the metrics used. This is a relevant point, as it highlights an area where the authors could enhance the clarity and transparency of their work. However, the comment does not provide specific suggestions on how to address this issue, such as recommending particular metrics to use or explaining their significance. While it points out a potential weakness, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies issues with Figure 3, including the unclear workflow and captions, as well as the confusing representation of communication modes on the left side. This provides clear and direct guidance on what needs to be improved, namely the clarity and comprehensibility of the figure. The authors are given specific actions to take, such as revising the captions and the representation of communication modes, to enhance the figure\\'s understandability. The feedback is concrete and provides concrete steps for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions and the confusing representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as the representation of communication modes on the left side. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks specific references or examples to clarify the issues, making it difficult for the authors to address the feedback effectively. Therefore, the claim is considered borderline verifiable, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific issues with Figure 3, noting that the workflow and captions are unclear and the representation of communication modes on the left side is confusing. This feedback is actionable as it provides the authors with a clear understanding of what needs to be improved in the figure. By addressing these issues, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar figures have been effectively presented. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the term \"learned [MASK] embedding\" is unclear in the SSL pre-training stage of the proposed method. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this term or what specific actions they should take to address this issue. The comment lacks actionable details, such as recommending a definition or clarification of the term, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SSL pre-training stage\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"learned [MASK] embedding,\" which is unclear in the context of SSL pre-training. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"learned [MASK] embedding\" is unclear in the SSL pre-training stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to clarify the issue or suggest how the authors might address it. Without additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the term \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. This is a clear and actionable point that can help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as offering alternative terms or explaining the context in which the term is used. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the reported results are partially derivative, as they extend to hyper-networks results that have already been presented for standard networks in the literature. However, it does not provide specific guidance on how the authors should address this issue or what changes they should make to improve the originality of their work. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the reported results are partially derivative, as they extend to hyper-networks results that have already been presented for standard networks in the literature. However, it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in identifying the issue of derivative results, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the reported results are partially derivative, as they extend to hyper-networks results that have already been presented for standard networks in the literature. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient support to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the originality of the reported results, suggesting that they are partially derivative as they extend to hyper-networks results that have already been presented for standard networks in the literature. This feedback highlights a potential weakness in the paper, as it may not present novel insights or contributions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the originality of their work. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not provide sufficient guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks motivation for the applications of the fast label aggregation algorithms in a streaming setting. It highlights that all the datasets used in the empirical analysis are static, which is a concern for the paper's usefulness. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting specific ways to motivate the problem or providing examples of streaming applications that could benefit from such algorithms. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger rationale for the problem's relevance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the objective of the paper, which is to design fast label aggregation algorithms for a streaming setting. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of motivation for the problem and the use of static datasets in the empirical analysis. The comment provides clear guidance on what needs to be addressed, namely the need to motivate the problem and consider streaming applications. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It notes that all the datasets used in the empirical analysis are static, which is a concern for the paper's usefulness. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the lack of motivation is problematic. Without additional context or evidence, the claim remains somewhat verifiable, as it requires the authors to infer the importance of motivating the problem. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It points out that all the datasets used in the empirical analysis are static, which is a concern for the paper's usefulness. This feedback is valuable as it highlights a critical area for improvement, namely the need to provide a stronger rationale for the problem being addressed. However, the comment could be more helpful if it suggested specific ways to motivate the problem or provided examples of streaming applications that could benefit from such algorithms. Overall, the comment is somewhat helpful as it directs the authors to a crucial area for improvement, but it lacks detailed guidance on how to address the issue.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the scope of the study, noting that it appears to focus on injecting a CoT-based approach to small-scale language models. The reviewer suggests that if this is not the case, additional relevant CoT baselines for in-context learning of large language models should be included in Tables 2 and 3. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to add these baselines or specify how to do so. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2 and 3\" and \"Question A,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional relevant CoT baselines for in-context learning of large language models. This provides clear guidance on what the authors need to address to improve their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the scope of the study is under-specified and suggests that the work focuses on injecting a CoT-based approach to small-scale language models. The reviewer provides a specific observation that additional relevant CoT baselines for in-context learning of large language models (such as text-003 and ChatGPT) are missing in Tables 2 and 3. This claim is somewhat verifiable as it provides a logical reasoning for the need to include these baselines, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the scope of the study, noting that it appears to focus on injecting a CoT-based approach to small-scale language models. The reviewer suggests that if this is not the case, additional relevant CoT baselines for in-context learning of large language models (such as text-003 and ChatGPT) should be included in Tables 2 and 3. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance the scope and comprehensiveness of their study. By addressing this point, the authors can ensure that their work is more comprehensive and relevant to the field. However, the comment could be more helpful if it included specific examples or references to relevant CoT baselines. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their study.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment explicitly states that Figure 3 is difficult to read, providing a clear action for the authors to take. However, it does not specify what aspects of the figure are challenging to read or how the authors might improve the figure to make it more readable. While the action is explicit, the lack of concrete details on how to address the issue makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, stating that it is difficult to read anything on the figure. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment claims that \"Figure 3 is very hard to read anything on the figure.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with Figure 3, stating that it is difficult to read anything on the figure. This feedback is clear and actionable, as it directs the authors to address a specific visual aspect of their work that may impact the readability and comprehension of their findings. However, the comment could be more helpful if it provided suggestions on how to improve the figure, such as recommending adjustments to the figure size, font, or color scheme. Overall, the comment is somewhat helpful as it points out a clear issue but lacks detailed guidance on how to resolve it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific aspects of the connection should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. While it identifies a potential area for further exploration or discussion, it does not provide any actionable feedback or suggestions for the authors to address this question or improve their draft. The comment lacks depth and specificity, leaving the authors without clear guidance on how to proceed. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about whether the GAT is trained with the whole model and suggests that the text needs to be reviewed by an English native speaker to improve clarity. While the comment implies that the authors should review the text for clarity, it does not provide specific guidance on how to achieve this or what aspects of the text need to be revised. The action is implicit and somewhat vague, as the authors can infer that they need to review the text but may not be entirely sure of the exact changes required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"245,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be reviewed: the training of the GAT with the whole model and the need for clarity in some sentences. This provides clear guidance on what aspects of the paper need attention. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and a request for clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the training of the GAT with the whole model, which is a relevant point for clarity. It also suggests that some sentences need to be rewritten for improved clarity. While the comment identifies areas that require attention, it lacks specific guidance or suggestions on how to address these issues. The authors are given a general direction but are not provided with actionable steps or detailed feedback on how to improve the clarity of their writing. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and questions the justification behind using an SGD learning rate of ~0.1. While the comment provides a specific action to take regarding the parameter `lambda`, it does not offer guidance on how to address the issue with the SGD learning rate or what the justification should be. The action is explicit but lacks concrete details on how to implement the change or justify the learning rate. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes two claims: first, that replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` is problematic, and second, that the justification for using an SGD learning rate of ~0.1 is unclear. The first claim is somewhat verifiable as it points out a potential issue with the parameter choice, but it lacks specific reasoning or examples to fully substantiate the claim. The second claim is also somewhat verifiable, as it questions the justification for the learning rate but does not provide detailed reasoning or references to support the claim. Overall, the comment is somewhat verifiable, as it highlights areas for improvement but lacks detailed evidence or references to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. It points out that the justification for these choices is unclear, which is a valuable observation that can help the authors improve their draft. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered alternative justifications for the parameter choices. While it highlights areas for improvement, the feedback is somewhat limited in its guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly encourages the authors to conduct error analysis and provide detailed explanations of the model's performance under different scenarios. This guidance is clear and specific, giving the authors a direct action to take. The comment also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the importance of error analysis and its role in evaluating model performance and identifying potential issues. It also encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. This provides clear guidance on what needs to be addressed, making the comment fully grounded. The comment is specific because it details the importance of error analysis and its role in guiding subsequent improvements and expansions of the ERC research. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. This claim is somewhat verifiable as it logically supports the importance of error analysis in the context of model evaluation and improvement. However, the comment lacks specific examples or references to substantiate the claim fully. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of error analysis in evaluating model performance and identifying potential issues, and encourages the authors to conduct such analysis and provide detailed explanations of the model\\'s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their draft by incorporating error analysis, which can aid in guiding subsequent improvements and expansions of the ERC research. However, the comment could be more helpful if it included specific examples or suggestions on how to conduct the error analysis or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pre-trained model on synthetic data. While the comment provides a general direction for analysis and potential improvements, it does not offer specific guidance on how to conduct the analysis or what aspects to focus on. The authors are left to infer the details of how to implement these suggestions, making the action implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pre-trained model on synthetic data. However, the comment does not specify which part of the paper should include this analysis or discussion, nor does it provide detailed guidance on how to conduct the analysis or what aspects to focus on. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the need for analysis and discussion on the domain gap. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pre-trained model on synthetic data. While the comment provides a logical basis for the suggestion, it lacks specific examples or references to support the claim about the domain gap or the value of finetuning on synthetic data. This makes the claim somewhat verifiable, as it provides a general direction but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to analyze the domain gap and discuss the gap between datasets. It highlights the potential value of the approach if it can finetune a pre-trained model on synthetic data. This feedback is valuable as it directs the authors to consider an important aspect of their work that could enhance its impact and relevance. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct the analysis or what aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scalability of the model, specifically noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, like 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment implies that the authors should consider this issue, it does not provide explicit instructions or concrete steps on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider scalability and performance trade-offs. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 (a)\" and the issue of scalability, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the performance degradation with the growth of the maximum number of identities, suggesting that the capacity should be set to a small number like 10. The comment further questions whether the authors have considered how to scale up without compromising performance. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of the model degrades as the maximum number of identities grows, suggesting that the capacity should be set to a small number like 10. The reviewer provides a specific example from Table 3 (a) to support this claim. However, the comment lacks detailed reasoning or references to explain why this specific capacity threshold is necessary or how it affects performance. While the claim is based on a specific observation, it could be strengthened with more detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides some support but lacks full clarity and depth.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the scalability of the model, noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, like 10, to address this issue. The comment also raises a valid question about how to scale up without compromising performance, prompting the authors to consider this aspect of their work. While the comment provides a clear and actionable suggestion, it could be more helpful if it offered additional insights or examples on how to achieve scalability while maintaining performance. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and encourages them to consider scalability in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim their work as preliminary but question the NLP-specific aspects of their approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of their approach should be revised to better align with an NLP-specific focus. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim made by the authors regarding their work being preliminary and discusses the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the lack of NLP-specific aspects in the approach, but without explicit references to sections or details, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim made by the authors that their work is preliminary, specifically regarding the application of LLP to NLP tasks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\\'s concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the claim made by the authors that their work is preliminary, specifically regarding the application of LLP to NLP tasks. It points out that the approach does not appear to have any NLP-specific aspects, which is a valid observation. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their approach to better align with an NLP-specific focus. Without detailed guidance or examples, the authors are left without a clear path forward, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that at least one NCE-based method should be included for comparison. It provides a specific reference to a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This guidance is clear and concrete, as it specifies the exact action the authors need to take by including a specific method for comparison. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including at least one NCE-based method for comparison, referencing a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper should include this comparison or which section would benefit from it. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding as it does not explicitly mention the sections. The suggestion is specific, as it clearly identifies the need for a comparison with NCE-based methods. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that at least one NCE-based method should be included for comparison. It references a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This reference provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how NCE-based methods could enhance the comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that at least one NCE-based method should be included for comparison. It references a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is somewhat helpful as it provides a clear direction for the authors to consider adding a relevant comparison. However, the comment could be more helpful if it explained why this comparison is important or how it would enhance the paper\\'s contribution. While it points to a potential area for improvement, the authors are left to determine the exact impact and relevance of including an NCE-based method. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiment section could be improved by conducting significance tests on the human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a clear direction for improvement, it does not specify which specific tests should be conducted or how to conduct them. Additionally, it does not mention which recent LLMs should be compared. While the action is explicit, the lack of concrete details on how to implement the suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the experiment section, specifically recommending the use of significance tests on human evaluation results and comparing the proposed method with recent LLMs. However, it does not specify which part of the experiment section needs improvement or which specific LLMs should be compared. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting improvements, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment section could be improved by conducting significance tests on human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these changes would significantly enhance the experiment section. The absence of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and implement the suggested improvements.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experiment section, specifically suggesting the use of significance tests on human evaluation results and comparing the proposed method with recent LLMs. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experiment section. However, the comment could be more helpful if it included examples of which tests should be conducted or which LLMs should be compared. Despite this, the feedback is mostly helpful as it directs the authors to specific areas for improvement, which can significantly enhance the quality of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to discuss a previous work on joint error for UDA, specifically mentioning \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019. It also suggests that the authors should illustrate the relationship between this work and their proposed method, as well as highlight why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the joint error for UDA and references a specific work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the relationship between the proposed method and the previous work, and why the proposed method is better. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' claim about the lack of research on joint error for UDA is incorrect, as it has already been studied in a previous work. The reviewer supports this claim by referencing \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019, which provides a specific example of a previous study on this topic. This reference provides a clear and concrete basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or comparison between the proposed method and the existing work. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific claim made by the authors regarding the lack of research on joint error for UDA. It challenges this claim by pointing out that the problem of arbitrarily increased joint error has already been studied in previous works, specifically mentioning \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019. The comment suggests that the authors should discuss this work and its relationship to their proposed method, as well as highlight why their method is better. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by addressing the existing literature and justifying their method\\'s novelty. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superiority of the proposed method may be due to the larger-scale datasets. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors can infer that they should consider the impact of dataset size on performance and potentially adjust the comparison with SOTA methods. However, the comment lacks concrete steps or suggestions on how to conduct this adjustment or what specific aspects of the comparison should be revised. Therefore, the comment is somewhat actionable, as it highlights an area for consideration but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison with state-of-the-art (SOTA) methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This provides clear guidance on what needs to be addressed, namely the fairness of the comparison with SOTA methods. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison with state-of-the-art (SOTA) methods may be unfair due to the difference in dataset size. The reviewer provides a logical reasoning by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This observation highlights a potential issue with the comparison, suggesting that the superiority of the proposed method may be due to the larger-scale datasets. However, the comment lacks specific examples or references to existing methods or datasets to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the proposed method with state-of-the-art (SOTA) methods. It points out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This observation highlights a potential bias in the comparison, as the larger dataset may contribute to the superiority of the proposed method. The comment suggests that the superiority may be due to the larger-scale datasets, which is a relevant consideration for the authors. However, the comment could be more helpful by providing specific suggestions on how to address this issue, such as adjusting the comparison or discussing the implications of dataset size on performance. Overall, the comment is somewhat helpful as it identifies a critical area for consideration but lacks detailed guidance on how to improve the draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It also notes the absence of a discussion on the research gap, such as why existing methods cannot be applied. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the research gap should be discussed. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification for the need of a new curriculum learning method and address the research gap, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the need for designing a new curriculum learning method for text graphs is not justified, as existing methods cannot be applied. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It points out the absence of a discussion on the research gap, such as why existing methods cannot be applied. This feedback is somewhat helpful as it highlights a potential gap in the paper that the authors should address to strengthen their argument. However, the comment could be more helpful if it provided suggestions on how to address this gap or what specific aspects of the research gap should be discussed. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion for the authors to use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of using the simplest n-gram features. This is an explicit and concrete action that the authors can take to improve their draft. The comment clearly specifies what needs to be done and how it can be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest n-gram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular approach to address the domain adaptation problem, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest n-gram features. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, based on the common use of these models in domain adaptation tasks in the NLP field. However, the comment lacks specific examples or references to support the claim fully, such as studies or experiments that demonstrate the effectiveness of these models in domain adaptation. This makes the claim somewhat verifiable, as it provides a reasonable basis but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It recommends using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest n-gram features. This feedback is clear and offers a concrete way for the authors to enhance their methodology and improve the robustness of their results. By following this advice, the authors can potentially overcome domain-shift issues and provide a more robust evaluation of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment identifies an area for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed analysis or clarification in their ablation study. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed method, which comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology and results sections where the method and its performance are discussed. The comment is specific in its critique of the ablation study, but it lacks grounding as it does not point to a specific part of the paper where the issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method comprises several complicated modules and has more parameters than the baselines, which raises questions about whether the main performance gain is due to a specific module or the increased number of parameters. The reviewer suggests that the current version of the ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or detailed reasoning to support the claim that the current ablation study is insufficient. While the reviewer highlights a potential issue, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters, and points out that the current version of the ablation study does not provide definitive answers to these questions. This feedback is somewhat helpful as it highlights an area where the authors could improve their analysis and provide more detailed explanations of the method's performance. However, the comment could be more helpful if it suggested specific ways to address the identified issues or provided examples of how other studies have handled similar questions. Overall, the comment provides some insight but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of explanation in the paper regarding the two quantities mentioned in lines 196-197. It explicitly asks for more clarification on why the two quantities are different and how they capture the difference in learning settings. This feedback provides a clear and direct action for the authors to take, which is to provide additional explanation in these lines. The comment is specific and concrete, giving the authors a clear idea of what needs to be addressed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l 196-7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation regarding the two quantities and their relationship to learning settings. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the explanation provided in lines 196-197, asking for more clarification on why the two quantities are different and how they capture the difference in learning settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this explanation is necessary or how it would impact the paper\\'s understanding. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper where more explanation is needed, specifically regarding the two quantities mentioned in lines 196-197. It asks for clarification on why the two quantities are different and how they capture the difference in learning settings. While the comment highlights an important area for improvement, it does not provide detailed guidance or suggestions on how to address this issue. The authors are given a clear direction to provide more explanation, but the comment could be more helpful with additional context or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a clear and direct request, providing the authors with a specific action to take. The comment is specific in detailing what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to discuss the sensitivity of fixed tuning parameters in the model, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the strengths and weaknesses of these parameters. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it prompts the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a relevant and important aspect to consider, as it could impact the robustness and generalizability of the model. However, the comment lacks specific guidance or examples on how to approach this discussion or what aspects to focus on. While it identifies a potential area for improvement, it does not provide detailed instructions or suggestions for the authors to enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed framework should be tested with different policy gradient approaches and provides a specific question about the number of random seeds used for learning the policies (DDPO and IPPG). While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment results. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in its request for information about the random seeds used, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they would impact the framework\\'s performance. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the suggestion or the importance of addressing these points. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). This feedback is somewhat helpful as it identifies a potential area for further exploration and experimentation, which could enhance the robustness and generalizability of the framework. However, the comment lacks depth and does not provide specific guidance on how to implement these changes or what specific policy gradient approaches should be considered. While it points out a potential area for improvement, it does not offer detailed suggestions or examples, making it somewhat helpful but not comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. While it implies that the authors should expand their analysis, it does not provide specific guidance on which datasets or tasks to include or how to conduct the additional evaluations. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should evaluate on more datasets and tasks to strengthen the results and conclusions. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting that the analysis should be expanded, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would be stronger if it evaluated on more datasets and tasks. This is a logical suggestion based on the idea that broader applicability and generalizability can strengthen the results and conclusions. However, the comment lacks specific examples or references to support why this is necessary or how it would impact the paper\\'s conclusions. Without detailed reasoning or evidence, the claim is somewhat verifiable, as it provides a logical basis but lacks the necessary depth to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. This is a valid point as it could provide a broader perspective on the applicability and generalizability of the findings. However, the comment lacks specific guidance on which datasets or tasks to consider, how to conduct the additional evaluations, or what aspects of the analysis should be expanded. While it identifies a potential area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific areas where the writing could be improved, providing examples of unclear or difficult-to-interpret definitions. It explicitly asks for clarification on the \"relevant\" auxiliary model weights in definition 2.1. This feedback is clear and provides concrete guidance on what needs to be addressed to improve the clarity of the writing. The authors know exactly what needs to be done to enhance the clarity of their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the \"relevant\" auxiliary model weights in definition 2.1. This provides clear guidance on what needs to be improved in the writing. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the writing in specific sections, such as definition 2.1. It provides examples of unclear or difficult-to-interpret definitions, which is a logical observation. However, the comment does not offer specific examples or references to support the claim that the writing is unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks detailed justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific areas where the writing could be improved, providing examples of unclear or difficult-to-interpret definitions. This feedback is actionable and constructive, as it points out specific parts of the paper that need clarification. By addressing these issues, the authors can enhance the clarity and accessibility of their work, which is valuable for improving the overall quality of the draft. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the definitions or provided examples of clearer explanations. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the robustness of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It suggests that the use of U-LiRA [1] is recommended. However, the comment does not provide explicit instructions on how to address this concern or implement the suggested use of U-LiRA. While the authors can infer that they should consider using U-LiRA, the comment lacks concrete guidance on how to integrate it into their work. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and raises concerns about the robustness of MIA testing for privacy guarantees. It also suggests using U-LiRA [1] as a recommendation. However, the comment does not specify which part of the paper discusses the use of MIA testing or where the recommendation for U-LiRA should be integrated. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the issue with MIA testing and the recommendation for U-LiRA, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness is not robust enough for privacy guarantees. It suggests that the use of U-LiRA [1] is recommended. The comment provides a logical reasoning by pointing out the potential limitations of MIA testing and the need for a more robust approach. However, it lacks specific examples or references to support the claim about the robustness of MIA testing or the effectiveness of U-LiRA. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It raises a valid concern about the robustness of MIA testing for privacy guarantees, which is an important consideration for the paper\\'s contributions. The comment suggests using U-LiRA [1] as a more robust alternative, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful if it explained why MIA testing is not robust or how U-LiRA might address these concerns. Overall, the comment provides valuable insight into a potential weakness and offers a constructive suggestion for improvement, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting them in the \"language of kernel interpolation/smoothing.\" However, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they need to address the applicability of their considerations to kernel regression and consider presenting them in the context of kernel interpolation/smoothing, but the comment lacks specific guidance on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting them in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that the considerations should be applicable to kernel regression and that they could be presented in the context of kernel interpolation/smoothing. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting them in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this applicability should be considered or how it would be relevant. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression, suggesting that they could also be presented in the \"language of kernel interpolation/smoothing.\" While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue. It does not offer actionable steps or detailed reasoning for why this applicability should be considered or how it could be presented. As a result, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. It explicitly asks if it is possible to conduct such a comparison. The comment provides a clear and direct action for the authors to take, which is to conduct a quantitative comparison on the final outputs. This guidance is explicit and concrete, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the quantitative evaluation results, noting that they only reflect middle outputs and suggesting a comparison with final outputs. The comment further questions whether a quantitative comparison on the final outputs is possible, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. The comment provides a logical reasoning by pointing out that the current evaluation does not fully demonstrate ModelAngelo\\'s superiority to competitors. However, it lacks specific examples or references to support the claim that the current evaluation is insufficient. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that a quantitative comparison on the final outputs would be more convincing in demonstrating ModelAngelo\\'s superiority to competitors. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it could be more helpful if it offered additional guidance on how to conduct such a comparison or provided examples of how it might be done. Overall, the comment is mostly helpful as it points out a critical area for improvement and provides a clear direction for the authors to enhance their evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that adding more details to the paper and/or supplementary information would be beneficial. Additionally, it recommends including error bars and/or p-values when statistical inferences are made. While the comment provides specific actions to take, such as adding more details and including error bars, it does not explicitly instruct the authors on how to implement these changes. The action is concrete but somewhat vague in terms of execution, as the authors need to determine which specific details to include and how to present them. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"simulation or experiment-based evidence\" and \"fig. 2,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues with the explanations, the lack of detailed procedures, and the confusion regarding \"sample count\" in fig. 2. Additionally, it provides specific suggestions for improvement, such as adding more details to the paper and including error bars or p-values when statistical inferences are made. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the explanations in the paper are qualitative and that the procedures are described minimally or not at all, with some figures being confusing. The reviewer suggests that adding more details and supplementary information would be beneficial. Additionally, the comment recommends including error bars and/or p-values when statistical inferences are made. While the comment identifies specific issues with the paper, it lacks detailed examples or references to support the claim about the qualitative nature of the explanations or the confusion in the figures. The suggestion to include error bars and p-values is logical, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that adding more details to the paper and/or supplementary information would be beneficial. Additionally, it recommends including error bars and/or p-values when statistical inferences are made. These points are clear and actionable, providing the authors with specific guidance on how to improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided examples of what kind of details or clarifications would be beneficial. Overall, the feedback is mostly helpful as it directs the authors toward significant improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add supportive references for the claims made in the paper, specifically mentioning Lines 55-64. It highlights that many of the factors mentioned have been discussed in existing studies, providing a clear action for the authors to take. The comment is explicit and concrete, as it specifies the exact section and the need for references, giving the authors a direct and specific action to take. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 55-64,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to add supportive references for the claims made in the paper. The comment provides a detailed example of the factors that have been discussed in existing studies, which helps the authors understand the need for referencing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some claims may be inspired from existing studies and suggests that it is critical to add supportive references. The reviewer provides a specific example by referencing Lines 55-64, where the factors discussed have been discussed in existing studies. This reference provides a clear and specific example of the need for referencing, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific studies that address these factors. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, noting that some claims may be inspired by existing studies and suggesting that it is necessary to provide supportive references. It provides a specific example by referencing Lines 55-64, where the factors discussed have been discussed in existing studies. This feedback is clear and actionable, as it directs the authors to include references to support their claims. By addressing this issue, the authors can enhance the credibility and originality of their work. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate these references or suggested specific studies to consider. Overall, the comment is mostly helpful as it highlights a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. This feedback implies that the authors should include this information in their paper to enhance its clarity and usefulness to the community. However, the comment does not provide specific guidance on how to present these settings or what aspects should be included. While the action is implied, it is not as concrete as it could be, as the authors are left to infer the exact details of what is expected. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting that providing these settings would help the community by providing a single review of advances in this area. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. This claim is somewhat verifiable as it provides a logical reasoning for improvement, suggesting that such a comparison would enhance the paper\\'s clarity and usefulness to the community. However, the comment lacks specific examples or references to prior work that have successfully implemented this approach, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and usefulness of their work. By including these settings, the authors could provide a single review of advances in the area, which would benefit the community. However, the comment could be more helpful if it included examples of how these settings were used in prior work or provided guidance on how to present them effectively. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an unclear aspect of the paper regarding the presentation of specific examples of biases and prediction shifts, noting that while the authors mention the possibility of bias, they do not provide sufficient information on how general these situations are. However, the comment does not explicitly instruct the authors on how to address this issue or what specific information should be included to clarify the generalizability of these examples. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or examples to address the concern, but the comment lacks concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the generalizability of the examples of biases and prediction shifts presented in these sections. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents specific examples of biases and prediction shifts but does not provide sufficient information on their generalizability. The comment suggests that while the authors mention the possibility of bias, they do not clarify how general these situations are. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique to address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the presentation of examples of biases and prediction shifts in sections 3.2 and Theorem 1. It points out that while the authors mention the possibility of bias, they do not provide sufficient information on how general these situations are. This feedback is somewhat helpful as it highlights a potential gap in the paper\\'s explanation, but it lacks specific suggestions or guidance on how the authors might address this issue. The comment could be more helpful if it provided examples of what additional information or context would be beneficial to include. Therefore, it is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that adding a few more datasets would be beneficial, particularly in terms of cross-task transferability. While the comment implies that the authors should consider adding more datasets, it does not provide specific guidance on which datasets to include or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors need to infer that they should add more datasets but are not given concrete details on which datasets to include or how to integrate them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that adding a few more datasets, particularly concerning cross-task transferability, would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on cross-task transferability. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need to be revised. The comment is specific in suggesting the addition of datasets, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that adding a few more datasets, particularly concerning cross-task transferability, would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or how it would impact the analysis. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that adding a few more datasets, particularly concerning cross-task transferability, would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets to include or how they would enhance the analysis. The feedback is somewhat helpful as it points out a potential gap in the paper, but it does not offer actionable steps for the authors to address this suggestion. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks are somewhat standard and implies that the authors could have included more unique tasks to showcase the diversity of images/plots. It provides an example of interleaved image-text tasks, such as question answering from images, as a potential area for improvement. While the comment implies that the authors should consider these tasks, it does not explicitly instruct them to do so or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should consider these tasks but may not be entirely sure how to integrate them into their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the tasks are somewhat standard, such as figure captioning and matching figures/sub-figures to appropriate captions. It also mentions the potential for unique tasks that could showcase the diversity of images/plots, such as interleaved image-text tasks like question answering from images. However, the comment does not specify which part of the paper these tasks should be added to or how they would be integrated. While the authors might have an idea of where these tasks could fit, the comment lacks explicit grounding. It is specific about the need for unique tasks but does not provide detailed guidance on how to implement them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks are somewhat standard, such as figure captioning and matching figures/sub-figures to appropriate captions. It also implies that the tasks could be more unique and diverse, such as interleaved image-text tasks like question answering from images. The comment provides a logical reasoning for why the tasks could be more diverse and suggests specific examples of tasks that could be considered. However, it lacks specific examples or references to support the claim that these tasks would be beneficial or how they would enhance the paper. Therefore, the comment is somewhat verifiable, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the tasks are somewhat standard, such as figure captioning and matching figures/sub-figures to appropriate captions. It implies that the authors could have included more unique tasks to showcase the diversity of images/plots, such as interleaved image-text tasks like question answering from images. This feedback is somewhat helpful as it points out a potential area for improvement by suggesting the inclusion of more diverse tasks. However, the comment lacks specific guidance on how to implement these tasks or what specific aspects of the dataset could be leveraged for this purpose. While it provides a general direction, it does not offer detailed steps or examples to help the authors fully understand and address the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify whether there is any additional novel effort in the 3D Gaussians generation section, which is currently following the previous work, Luciddreamer. This is a clear and direct request for the authors to provide additional information or context to differentiate their work from the existing literature. The action is explicit and concrete, as it specifies what the authors need to address to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely whether there is any additional novel effort in this section. This provides clear guidance on what the authors need to clarify or improve in their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the section on 3D Gaussians generation is merely following previous work, specifically Luciddreamer. However, it does not provide any evidence, reasoning, or examples to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific section of the paper, Sec. 3.1, where the authors appear to be following previous work, Luciddreamer, without adding any additional novel effort. This feedback is clear and actionable, as it prompts the authors to clarify whether there is any additional novelty or innovation in this part of the paper. By addressing this point, the authors can enhance the originality and impact of their work. However, the comment could be more helpful if it provided suggestions on how to differentiate their work from the existing literature or what specific aspects could be improved. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the tractability of MMD DRO compared to other methods like phi-divergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude and that the nonnegative constraint on the distribution is dropped, requiring further approximation. Additionally, the comment notes that assuming the loss function \\ell_f belongs to the RKHS is restrictive. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should improve the tractability and rigor of their results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the crude upper bound in the theorem and the assumption of the loss function \\ell_f belonging to the RKHS. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that MMD DRO does not enjoy a tractable exact equivalent reformulation, which is a severe drawback. The reviewer supports this claim by pointing out that the upper bound provided in Theorem 3.1 is crude, as it drops the nonnegative constraint on the distribution, and that further approximation is still needed. Additionally, the reviewer critiques the assumption that the loss function \\ell_f belongs to the RKHS, which is already pointed out by the authors. The comment provides logical reasoning and specific examples to support the claim, making it mostly verifiable. However, it could be strengthened by referencing specific literature or examples to further substantiate the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the tractability of MMD DRO compared to other methods like phi-divergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude, as it drops the nonnegative constraint on the distribution, and that further approximation is still needed even for a simple kernel ridge regression problem. Additionally, the comment critiques the assumption that the loss function \\ell_f belongs to the RKHS, which is already pointed out by the authors. While the comment highlights specific weaknesses in the paper, it lacks actionable suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it provides insight into potential areas for improvement, but it could be more beneficial with additional suggestions or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the relevance of the framework to non-convex losses and non-norm type defenses, and it seeks clarification on the implications of the non-vanishing duality gap and difficulty of maximization over non-norm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not provide explicit instructions, they imply that the authors should address these issues in their paper. The action is implicit but concrete, as it guides the authors to provide clarification or analysis regarding the framework's applicability and potential limitations. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises questions about the relevance of the framework to non-convex losses and non-norm type defenses, and it specifically references the \"non-vanishing duality gap\" and the difficulty of maximization over non-norm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the comment does not explicitly mention a specific section or line in the paper, the authors can infer that it relates to the theoretical aspects of the framework or the applicability to non-convex losses. The comment is specific in its inquiry about the framework's relevance and potential limitations. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the relevance of the framework to non-convex losses and non-norm type defenses, and it seeks clarification on the implications of the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints. The reviewer also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not present claims, they imply that the authors should provide more detailed explanations or justifications regarding the framework's applicability and limitations. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the questions. Therefore, the comment is somewhat verifiable, as it provides a basis for the authors to address the concerns but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the relevance of the framework to non-convex losses and non-norm type defenses, and it seeks clarification on the implications of the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. These questions prompt the authors to consider the limitations and applicability of their framework in different contexts, which could lead to valuable insights and improvements in the paper. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions or what aspects of the framework should be further explored. Overall, the comment is somewhat helpful as it prompts the authors to consider important aspects of their framework but lacks detailed guidance on how to address the questions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is clear but lacks concrete details on how to execute the experiment, such as which specific features to select or how to evaluate the results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it would impact the results. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This is a clear and actionable suggestion that could potentially improve the paper by providing additional insights into the performance of the baselines. However, the comment lacks depth and does not explain why this approach might be beneficial or how it could be implemented effectively. While it provides a direction for further exploration, it could be more helpful with additional guidance or rationale. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the paper lacks detail, specifically regarding the techniques used and the reproducibility of the results. It highlights the importance of understanding the sparsification process, the landmark generation, and the number of landmarks used. Additionally, it questions how to achieve shape invariance. While the comment provides a clear list of specific questions that need to be addressed, it does not offer explicit guidance on how to implement these improvements. The authors are left with a clear understanding of what needs to be added but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the techniques and the reproducibility of the results. It provides detailed questions about the sparsification process, landmark generation, and number of landmarks used, as well as how to achieve shape invariance. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be clarified or improved in each area. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of detail in the paper regarding the techniques used and the reproducibility of the results. It highlights specific areas that are unclear, such as the sparsification process, landmark generation, and number of landmarks used. The reviewer also questions how to achieve shape invariance. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support the claims. This makes the comment somewhat verifiable, as it points out areas that need clarification but lacks the depth and evidence needed for full verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper lacks detail and clarity, particularly regarding the techniques used and the reproducibility of the results. It highlights specific questions that need to be addressed, such as the sparsification process, landmark generation, and number of landmarks used. The comment also questions how to achieve shape invariance and provides a detailed list of questions that, if answered, could significantly improve the clarity and reproducibility of the paper. This level of detail and specificity offers the authors clear guidance on what needs to be addressed to improve their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to reorganize the Appendix H section, which is difficult to follow. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve the draft. The comment is specific about the issue of difficulty in following the section, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Appendix H section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, which is that it is difficult to follow. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Appendix H section is difficult to follow. However, it does not provide any specific examples or reasoning to support this claim, nor does it offer suggestions for improvement or alternative organization. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow. This feedback is clear and actionable, as it directs the authors to reorganize the section to improve its clarity and accessibility. However, the comment could be more helpful if it provided suggestions on how to reorganize the section or what specific changes might improve its readability. Overall, the comment is somewhat helpful as it points out a clear area for improvement but lacks detailed guidance on execution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the reproducibility of the paper, noting that while the pseudocode is provided in the supplementary material, it does not provide enough detail for actual reproduction. The reviewer suggests that more technical details, such as the number of units in the RNN implementation, are missing. This feedback implies that the authors should include more detailed descriptions of the technical aspects of their work to improve reproducibility. However, the comment does not explicitly instruct the authors to add these details, leaving it somewhat vague. While the action is implied, the authors can infer that they need to provide more technical information, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the supplementary material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with reproducibility, such as the lack of technical details like the number of units in the RNN implementation. This provides clear guidance on what needs to be addressed to improve reproducibility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not written to be reproduced, as it lacks technical details necessary for reproduction. The reviewer provides a specific example of the lack of details about the RNN implementation, such as the number of units. This claim is somewhat verifiable as it highlights a gap in the paper\\'s reproducibility, but it could be strengthened by providing more detailed examples or references to similar works that require such technical details. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the reproducibility of the paper, noting that while the pseudocode is provided in the supplementary material, it does not provide enough detail for actual reproduction. The reviewer highlights specific areas that are missing, such as technical details about the RNN implementation, which are necessary for reproducing the work. This feedback is clear and actionable, as it points out specific gaps in the paper that need to be addressed to improve its reproducibility. However, the comment could be more helpful if it suggested ways to address these gaps or provided examples of how similar details have been presented in other works. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Figure 1 would be stronger if it included error bars or more random trials to potentially reduce random fluctuations in the results. While the comment implies that the authors should consider adding these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add error bars or more trials to improve the figure. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. This provides clear guidance on how to improve the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure 1 would be stronger with the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. However, the comment does not provide any specific reasoning or evidence to support why error bars or more trials would be beneficial. It lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in Figure 1, suggesting that the inclusion of error bars or more random trials could strengthen the figure by potentially reducing random fluctuations in the results. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the figure\\'s robustness and clarity. However, the comment could be more helpful if it explained why error bars or additional trials are beneficial or how they might impact the interpretation of the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. It also references external works that discuss context-aware robust fine-tuning, fine-tuning impact on foundation models, and robust fine-tuning of zero-shot models. While the comment provides explicit actions, it does not specify how to implement these suggestions or what specific details should be included in the introduction or Figure 1. The authors are given clear guidance on what needs to be added but lack detailed instructions on how to execute these actions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"related work section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely providing a brief introduction to energy models in the related work section and clarifying the correspondence between different learning rates and steps in Figure 1. The comment also references external works, which provides additional context and specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. The reviewer references external works to support their claim, such as \"Context-aware robust fine-tuning,\" \"Fine-tuning can cripple your foundation model; preserving features may be the solution,\" and \"Robust fine-tuning of zero-shot models.\" These references provide a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or examples of how these references support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include a brief introduction to energy models in the related work section and clarify the correspondence between different learning rates and steps in Figure 1. It also references external works that discuss context-aware robust fine-tuning, fine-tuning impact on foundation models, and robust fine-tuning of zero-shot models. This feedback is clear and offers a concrete direction for improvement, helping the authors enhance the clarity and completeness of their draft. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate these references into the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the utility-based approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to mitigate the risk of premature evictions. The comment lacks concrete details or suggestions on how to improve the approach or validate its effectiveness. As a result, the authors are left without clear direction on how to apply this feedback to enhance their draft. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the utility-based approach used in FIITED, specifically the potential for biases due to temporary high utility scores for recent chunks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue of premature evictions due to temporary high utility scores. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential for biases in the utility-based approach used in FIITED, specifically the risk of premature evictions due to temporary high utility scores for recent chunks. While the comment identifies a potential issue, it lacks specific examples or references to substantiate the claim. The reasoning is based on logical reasoning and common knowledge about the potential for biases in utility-based approaches, but it does not provide detailed evidence or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a logical argument but lacks the depth and specificity needed for full verifiability.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the utility-based approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. This is a valuable observation that could lead to premature evictions of other valuable chunks. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate the risk of biases. While it points out a relevant concern, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an important area for consideration but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the first paragraph of the Introduction is not central to the paper and provides little valuable information. It suggests that the focus on DNNs is not relevant to the paper's core focus on detecting drift types and magnitude. The comment implies that the authors should reconsider the content and relevance of this paragraph, but it does not provide specific guidance on how to revise it or what alternative content could be included. The action is implicit and somewhat vague, as the authors need to infer the exact changes required to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic: the lack of mention of drift in the introduction, which is central to the paper\\'s focus. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is not central to the paper and provides little valuable information. This claim is somewhat verifiable as it logically argues that the introduction of DNNs is not directly relevant to the paper\\'s focus on detecting drift types and magnitude. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors may need to infer the relevance of the DNN introduction themselves, which could lead to some confusion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the paper\\'s core focus. This feedback is clear and actionable, as it suggests that the authors should reconsider the relevance and content of this paragraph to ensure it aligns with the paper\\'s central theme. By addressing this issue, the authors can improve the clarity and focus of their introduction, making the paper more effective for its intended audience. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the paper lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to include quantitative experiments and comparisons, as well as detailed explanations of the algorithms, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer specific steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the methodology and the experimental section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of quantitative experiments and comparisons with other algorithms, as well as the need for more detailed explanations of the presented ones. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the lack of quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones, makes it unclear what the exact performance of the framework and its individual parts are compared to other solutions. The comment provides a logical reasoning for the need for more detailed information, but it does not include specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It points out that while the framework yields promising visual stimuli results, it lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. This feedback is valuable as it highlights a critical area for improvement in the paper, specifically the need for more comprehensive and quantitative evaluations. However, the comment could be more helpful if it provided specific suggestions on how to address these gaps, such as which experiments to conduct or how to present the results more effectively. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they should consider to improve the clarity of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its concern about the model\\'s ability to generate novel knowledge or testable hypotheses, but without clear grounding, it lacks actionable guidance for the authors. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a valid concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it lacks specificity and actionable guidance for the authors to address this issue. Without detailed feedback or suggestions on how to improve the clarity or how to demonstrate the model\\'s capabilities, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a simplified version of Theorem 2 could be presented for the general audience, similar to Theorem 1. This implies that the authors should consider creating a simplified version of Theorem 2 to make it more accessible to readers. However, the comment does not provide specific guidance on how to achieve this simplification or what aspects of Theorem 2 are particularly challenging for the general audience. While the action is implied, it lacks concrete details on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests presenting a simplified version of Theorem 2, similar to Theorem 1, for the general audience. However, it does not specify which part of the paper contains Theorem 2 or where the simplified version should be placed. The authors can infer that it relates to the section containing the theorem, but this inference is not direct. The comment is specific in suggesting a potential simplification, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a simplified version of Theorem 2 could be presented, similar to Theorem 1, to make it more accessible to the general audience. However, the comment does not provide any reasoning, examples, or references to support why Theorem 2 is difficult to understand or how a simplified version would improve clarity. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that a simplified version of Theorem 2 could be presented, similar to Theorem 1, to make it more accessible to the general audience. This feedback is somewhat helpful as it identifies a potential issue with the clarity of the theorem and provides a suggestion for improvement. However, the comment lacks specific guidance on how to simplify the theorem or what aspects of Theorem 2 are particularly challenging for the general audience. While it points out a potential area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of their model. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to implement this suggestion or what aspects of the model might be affected by the change in resolution. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine how to conduct them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by using a larger image resolution, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or how it would impact the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. This is a valuable suggestion that could provide insights into how the model might perform with different image resolutions. However, the comment lacks depth and does not explain why this change might be beneficial or how it could impact the results. Additionally, it does not offer specific guidance on how to implement this suggestion or what aspects of the model might be affected by the change in resolution. While the suggestion is somewhat helpful, it could be more actionable and comprehensive with additional details. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map element-wise by H_psi. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the calculation of the keypoint mask averaged feature vector, providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the calculation of the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the calculation of the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map element-wise by H_psi. While this question may be relevant to the authors, it does not provide any guidance or suggestions for improvement. It lacks actionable feedback or context that would help the authors understand how to address the issue or improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use styles (e.g., dashed lines) or add color to make it easier to distinguish between the different curves in Figure 2. This feedback provides a clear and concrete action for the authors to take, specifying exactly what changes are needed to improve the figure. The suggestion is explicit and provides a specific direction for improvement, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the difficulty in distinguishing between the different curves and suggests using styles or adding color to improve clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the curves in Figure 2 are difficult to distinguish, and it provides a specific suggestion to use styles or add color to improve clarity. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the current presentation is unclear or how the proposed changes would improve it. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on Figure 2, noting that the different curves are difficult to distinguish. It suggests using styles or adding color to improve clarity. This feedback is clear and offers a concrete suggestion for improvement, which can help the authors enhance the visual presentation of their data. However, the comment could be more helpful if it provided additional context or examples of how other figures have effectively used styles or colors to improve clarity. Despite this, the feedback is mostly helpful as it guides the authors toward a specific action that can improve the figure. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends that the authors tone down the introduction and not refer to the task as \"language learning.\" It suggests that the task is more accurately described as a feedback-driven QA in the form of a dialog. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be changed in the introduction. The comment is highly actionable as it gives a direct and specific instruction on how to revise the introduction to better align with the actual nature of the task.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"claims made in the introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the overstatement of the task as \"language learning\" and the suggestion to tone down the introduction. The comment provides a clear and detailed critique of the introduction, which is helpful for the authors to understand and address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the claims made in the introduction are far from what has been achieved by the tasks and models, and suggests that the authors should tone down the introduction and not refer to it as \"language learning.\" The reviewer provides a logical reasoning by pointing out that the task is more accurately described as a feedback-driven QA in the form of a dialog. However, the comment lacks specific examples or references to support the claim that the task is significantly different from language learning. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the introduction of the paper, noting that the claims made are far from what has been achieved by the tasks and models. It suggests that the authors should tone down the introduction and not refer to it as \"language learning,\" as it is more accurately described as a feedback-driven QA in the form of a dialog. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the introduction. By addressing this issue, the authors can better align their paper with the reality of the task and enhance the clarity of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific evidence or arguments would be needed to convince the reviewer. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem of inaccuracy in neural ODEs and the need for convincing analytical or empirical evidence to support the claim. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the central contribution of the paper, which is based on modeling weight evolution using ODEs, is not convincing due to the issue of neural ODEs being inaccurate while recomputing activations. The reviewer questions the originality of this contribution and suggests that a previous paper may have already reported this issue. However, the comment lacks specific references or detailed reasoning to support the claim that the issue is not original or that the paper does not provide convincing evidence. This makes the claim somewhat verifiable, as it provides some basis but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper's central contribution, which is based on modeling weight evolution using ODEs. It questions the originality of this contribution and points out that a previous paper may have already reported the issue of neural ODEs being inaccurate while recomputing activations. The comment highlights the need for convincing analytical or empirical evidence to support the claim. While it raises an important concern, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their argument. The feedback is somewhat helpful as it points out a potential weakness but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While the comment implies that the authors should add this information, it does not explicitly instruct them to do so or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include this detail. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section, figure, or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting what needs to be mentioned, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not provide any supporting evidence, reasoning, or examples to justify why this mention is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While it identifies a potential area for clarification, it lacks specificity and does not provide guidance on how to address this issue or why it is important. The feedback is somewhat helpful as it points out a potential gap in the explanation, but it does not offer actionable steps or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it notes that this paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment implies that the authors should focus on the collaborative ranking results to derive the lower bound results, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to apply the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of proving lower bounds for round complexity in the context of batched ranking problems. It suggests that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. However, the comment does not specify which part of the paper discusses the lower bound results or the collaborative ranking results, making it weakly grounded. The comment is specific in detailing what the authors need to address, namely, the derivation of lower bound results from collaborative ranking results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it suggests that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. The comment provides a logical reasoning for why the lower bound results are easier to derive from collaborative ranking, but it lacks specific examples or references to support this claim. While the reasoning is somewhat valid, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it suggests that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. This feedback highlights a potential area for improvement by suggesting that the authors should focus on the collaborative ranking results to derive the lower bound results. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions on how to effectively utilize the collaborative ranking results or provided examples of how other papers have addressed this issue. Overall, the comment is somewhat helpful as it points out a potential weakness and offers a direction for improvement, but it lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. While the comment implies that the authors should consider using more advanced prompting techniques, it does not provide specific guidance on how to implement this suggestion or what specific prompts might be effective. The action is implicit and somewhat vague, as the authors need to infer the need for more advanced prompting techniques and how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the prompting technique used in the study, suggesting that it is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. The suggestion to use carefully curated prompts is specific, but without clear grounding, the authors may struggle to identify the exact section that needs improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim somewhat verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the study, specifically the basic nature of the prompting technique used and its failure to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment highlights an important area for improvement, it lacks specific guidance on how to implement this suggestion or what criteria should be used to curate prompts. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed instructions on how to address it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that additional experiments on larger datasets would be beneficial but acknowledges the potential issue of compute. It also thanks the authors for their response and provides a positive assessment of how well the concerns were addressed. However, the comment does not explicitly instruct the authors to conduct these additional experiments or provide guidance on how to manage the compute issue. The action is implicit and somewhat vague, as the authors can infer that they should consider conducting additional experiments but are not given specific steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on larger datasets, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. The authors can infer that it relates to the experimental setup, but this inference is not direct. The comment also acknowledges the issue of compute and thanks the authors for their response, but does not provide further details or specificity regarding the compute issue. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting additional experiments and acknowledging the compute issue. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting additional experiments on larger datasets, which is a suggestion for improvement. However, it acknowledges the potential issue of compute and notes that maintaining probabilities might become an issue at large batch sizes. The comment does not provide specific reasoning or evidence to support why maintaining probabilities might be an issue or how it could be addressed. The authors are left with a suggestion but without detailed guidance or justification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on larger datasets, which could provide valuable insights into the model's performance and robustness. However, it acknowledges the potential issue of compute and notes that maintaining probabilities might become an issue at large batch sizes. While the comment identifies a potential limitation, it does not provide specific guidance or suggestions on how to address the compute issue or how to manage the probabilities. The authors are left with a clear direction for improvement but without detailed guidance on how to achieve it. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance of the model on REC and RES is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance or suggestions for potential improvements. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the performance of the model on REC and RES being behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. This claim is supported by references to external works, which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or specific metrics to support the claim further. As it stands, the claim is mostly verifiable due to the inclusion of references, but it could be more robust with additional evidence or explanation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights a significant issue with the performance of the model on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This feedback is valuable as it identifies a clear area for improvement, allowing the authors to address the issue and potentially improve their results. However, the comment could be more helpful if it provided suggestions on how to improve the performance or offered guidance on potential strategies for catching up with more recent models. Despite this, the feedback is mostly helpful as it directs the authors\\' attention to a critical area needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the term \"evidence\" might be too strong and recommends a more appropriate wording, such as \"Fig.\" This implies that the authors should revise the language in the paper to be more precise and accurate. However, the comment does not provide specific guidance on how to rephrase the term or what alternative wording would be more appropriate. While the action is implicit, it is clear that the authors need to adjust the language, but the lack of concrete details makes the comment somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific figure (Fig. 5) and suggests that the term \"evidence\" might be too strong. However, it does not specify which part of the figure or the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting a more appropriate term, such as \"Fig.\" This provides some guidance on what needs to be addressed, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the term \"evidence\" might be too strong in describing the figure (Fig. 5) and recommends using a more appropriate term, such as \"Fig.\" This is a suggestion for clarification rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential issue with the language used in describing a figure, suggesting that the term \"evidence\" might be too strong. It provides a specific recommendation to use a more appropriate term, such as \"Fig.\" This feedback is somewhat helpful as it points out a potential inaccuracy in the language used, which could be clarified to improve the clarity and precision of the paper. However, the comment could be more helpful if it explained why \"evidence\" might be inappropriate or provided additional context on how to use \"Fig.\" to convey the intended meaning. Overall, the comment is somewhat helpful as it directs the authors to a specific area for clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed video storyboarding approach lacks novelty, as it relies heavily on frame-wise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation instead of cross-attention. While the comment identifies a specific area of concern, it does not provide explicit guidance on how the authors should address this issue or improve the novelty of their approach. The action is implicit and somewhat vague, as the authors can infer that they need to explore ways to enhance the innovation of their method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed video storyboarding approach\" and \"frame-wise SDSA,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty in the approach, noting that it relies heavily on frame-wise SDSA and that the only notable difference is the mask source. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed video storyboarding approach lacks novelty, as it relies heavily on frame-wise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation rather than cross-attention. This claim is somewhat verifiable as it provides a specific comparison to ConsiStory, which is a well-known approach, and highlights the difference in the mask source. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it relies heavily on frame-wise SDSA, which is similar to the approach used in ConsiStory. The reviewer highlights the only notable difference as the mask source, which uses CLIPseg and OTSU segmentation rather than cross-attention. This feedback is somewhat helpful as it points out a specific area where the paper could be improved by exploring more innovative approaches or techniques. However, the comment lacks detailed suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. To be more helpful, the comment could provide specific suggestions or examples of alternative methods that could be considered. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. It also proposes an interesting comparison with previous approaches on few-shot classification in such datasets. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take in order to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, and proposes a comparison with previous approaches on few-shot classification in such datasets. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a comparison with previous approaches and providing a context for the relevance of the method. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The suggestion to compare the method with previous approaches on few-shot classification in such datasets is a logical one, but without additional context or justification, the claim remains somewhat verifiable. The authors may find it challenging to understand the basis of the suggestion without further elaboration. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, which is a valuable observation. It also proposes an interesting comparison with previous approaches on few-shot classification in such datasets. This feedback provides a clear direction for the authors to consider, offering a potential area for improvement and a specific comparison to make. However, the comment could be more helpful if it included specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a relevant context and provides a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or specify how this explanation should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add an explanation of the bounds. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper discusses the bounds or where the explanation should be added. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the bounds need explanation or how they should be presented. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this additional explanation is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to effectively explain the bounds or what aspects should be clarified. The comment is somewhat helpful as it points out a potential weakness, but it does not offer actionable advice or detailed suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the explanation for the implementation of kernels with OpenAI\\'s Triton is unnecessary due to well-known engineering improvements. However, it does not provide any guidance on how the authors should revise or clarify this explanation. The comment lacks explicit instructions or concrete details on what changes should be made, leaving the authors uncertain about how to address the feedback. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the explanation for the implementation of kernels with OpenAI\\'s Triton is unnecessary due to well-known engineering improvements. However, it does not specify which part of the paper this explanation is provided in, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the explanation are considered unnecessary or how the authors might improve it. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the explanation for the implementation of kernels with OpenAI\\'s Triton is unnecessary due to well-known engineering improvements. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the explanation for the implementation of kernels with OpenAI\\'s Triton is unnecessary due to well-known engineering improvements. However, it does not provide any specific guidance or suggestions on how the authors might revise or clarify this explanation to make it more relevant or beneficial to the readers. Without actionable feedback or detailed reasoning, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the zero-shot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability. The reviewer also points out that the manipulation scenario might be challenging due to the complexity of the tasks. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the transferability and complexity of the tasks but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the zero-shot nature of the work and the transferability of the policy, suggesting that the difficulty of the source and target tasks might limit the transferability. It also provides specific examples of the manipulation scenario, such as the 3-prong task with clockwise and counterclockwise rotations, and the 4-prong task, which could be used to clarify the target task. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the transferability and the complexity of the tasks, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the zero-shot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to support this claim. The reviewer also points out that the policy transfer might be challenging due to the complexity of the tasks. However, the comment lacks specific references or detailed reasoning to fully substantiate these claims. While it provides some evidence and examples, it could be strengthened by including more detailed explanations or references to support the argument. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the zero-shot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to illustrate this point. The reviewer also points out that the policy transfer might be challenging due to the complexity of the tasks. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or clarify their work. While it identifies potential weaknesses and areas for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights important areas for consideration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on a small backbone ResNet-50. It suggests that the method might not perform well on larger backbone models like Swin-B or Swin-L. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or improve their method. The action is implicit and somewhat vague, as the authors need to infer that they should test the method on larger backbone models to validate its effectiveness. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on a small backbone ResNet-50. It suggests that the method might not perform well on larger backbone models like Swin-B or Swin-L. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the results and evaluation of the proposed method. The authors can infer that it pertains to the discussion of results or experimental setup. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method achieves only a small improvement of about 1% on a small backbone ResNet-50, suggesting that the relative gains are not very strong. The reviewer also questions whether the method would perform well on larger backbone models like Swin-B or Swin-L. The comment provides some logical reasoning by pointing out that the proposed method introduces global pooling, which could make it easier to improve a smaller backbone. However, it lacks specific examples or references to support the claim about the performance on larger backbone models. This makes the claim somewhat verifiable, as it provides some reasoning but requires further elaboration to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the proposed method, noting that the relative gains are only about 1% on a small backbone ResNet-50. It suggests that the method might not perform well on larger backbone models like Swin-B or Swin-L. While the comment highlights a concern, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their method. The feedback is somewhat helpful as it points out a potential limitation, but it lacks actionable advice or detailed insights that could help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fully-connected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve their analysis or what specific aspects of the neural network analysis need attention. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fully-connected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. However, it does not specify which part of the paper this critique is based on, such as sections 3.2 or 3.3, making it weakly grounded. The comment is specific in detailing the issue with the analysis of neural networks, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis of neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks by only considering wide fully-connected neural networks. The comment provides some reasoning by referencing the existing NTK theorem and the trivial extension from linear models to wide fully-connected neural networks. However, it lacks specific examples or references to support the claim that the work bypasses the core problem. This makes the claim somewhat verifiable, as it provides some reasoning but requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fully-connected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. It points out that the analysis only considers easy wide fully-connected neural networks, which is a relevant observation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable feedback or constructive advice, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task (5, 6, and 4). It suggests that having such a small number might not be sufficient, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a specific suggestion to consider using more datasets to ensure rigor. However, the comment does not provide explicit guidance on how to increase the number of datasets or which datasets should be used. While the action is implied, it lacks concrete details on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the rigor of the evaluation, specifically the number of datasets used for each task (5, 6, and 4). It suggests that having such a limited number might not be sufficient, particularly if some datasets are too large for all algorithms to be used. The comment provides a specific suggestion to consider using more datasets to ensure rigor. However, it does not explicitly mention which part of the paper this issue pertains to, such as the methodology or results sections. While the authors can infer that it relates to the evaluation section, the comment lacks full grounding. It is specific about the issue of limited datasets, but it does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the rigor of the evaluation, suggesting that the limited number of datasets for each task (5, 6, and 4) might not be sufficient. The reviewer provides a logical reasoning by pointing out that some datasets might be too large for all algorithms to be used, which could affect the evaluation's thoroughness. However, the comment lacks specific examples or references to support the claim that the datasets are insufficient. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the rigor of the evaluation, given the limited number of datasets for each task (5, 6, and 4). It suggests that having such a small number might not be sufficient, particularly if some datasets are too large for all algorithms to be used. The comment provides a specific suggestion to consider using more datasets to ensure rigor. Additionally, it acknowledges the authors\\' detailed reply and the provision of a repository and online platform for reproducing the experiments. The feedback is mostly helpful as it identifies a potential weakness in the evaluation and offers a clear and actionable suggestion for improvement. However, it could be more helpful if it provided additional guidance on which datasets should be considered or how to select them. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a constructive suggestion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of results with larger models like ResNet101/152, which is a specific action for the authors to take. However, it does not provide guidance on how to conduct these experiments or what specific aspects to focus on. The comment implies that the authors should include results with larger models, but it lacks concrete details on how to implement this action. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of ResNet models on imageNet classification, specifically mentioning ResNet50/34/18 and noting the absence of results with larger models like ResNet101/152. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in identifying the issue of not including results with larger models, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no results with larger models like ResNet101/152, but it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to previous studies or benchmarks, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of results with larger models like ResNet101/152. This feedback is clear and actionable, as it directs the authors to include results with these models to provide a more comprehensive evaluation of their work. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it highlights a critical area for improvement but lacks detailed guidance on execution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confusion in the paper regarding the use of terms like \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what specific changes should be made to clarify the terms. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the multi-fidelity framework and sequential design for learning quantities, specifically mentioning a reference to Assessing Fire Safety using Complex Numerical Models with a Bayesian Multi-fidelity Approach (Stroh et al., 2017). This provides full grounding as it clearly identifies the part of the paper being addressed. The comment also specifies the issue of confusion regarding the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the terms \"relatively inexpensive\" and \"expensive to evaluate\" are confusing, as they appear in different parts of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these terms are confusing or how they could be clarified. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper regarding the terms \"relatively inexpensive\" and \"expensive to evaluate\" used in different parts of the document. This is a clear and actionable observation that can help the authors clarify their language and improve the coherence of their writing. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific changes or clarifications to be made in the text. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance on how to achieve it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the method addresses sparse reward problems and questions whether it can solve sparse-reward tasks as well as other methods (Qmix). However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, or suggesting ways to improve the method's performance in sparse-reward scenarios. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the method and the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the method addresses sparse reward problems and whether it can solve sparse-reward tasks as well as other methods (Qmix). The comment provides a clear direction for improvement by asking for clarification on the method's performance in sparse-reward scenarios. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the method\\'s ability to address sparse reward problems and suggests that the experiments do not support this claim. The reviewer provides a logical reasoning by comparing the proposed method to dense reward signals and sub-task-specific rewards, which could be seen as a way to address sparse reward issues. However, the comment lacks specific examples or references to support the claim that the method does not address sparse reward problems effectively. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the method\\'s ability to address sparse reward problems effectively, based on the experiments presented. It suggests that the proposed method requires sub-task-specific rewards, which is similar to dense reward signals, and questions whether it can solve sparse-reward tasks as well as other methods (Qmix). The comment also includes minor comments that suggest specific areas for improvement. However, the feedback lacks detailed guidance or suggestions on how the authors might address these issues or improve their method. While it identifies potential weaknesses, the comment could be more helpful by providing actionable steps or examples to enhance the draft. Therefore, it is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the curated AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN had access to the data during training for a fair comparison. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"curated AH36M dataset\" and the need for clarification on whether it is used for training. It also raises questions about whether other methods like HMR and SPIN had access to the AH36M data during training for a fair comparison. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods like HMR and SPIN had access to the data during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the fairness of the comparison. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the use of the curated AH36M dataset for training and whether other methods like HMR and SPIN had access to the data during training for a fair comparison. This is a clear and actionable point that could help the authors clarify their methodology and ensure a fair comparison with other approaches. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional information should be included in the paper. Overall, the comment is mostly helpful as it identifies a critical area for clarification and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific guidance on how to address these issues or what aspects of the proof or discussion are confusing. It lacks concrete details on how to improve the clarity or depth of the paper. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies specific issues with the proof of the main results, suggesting that there are confusing mistakes. However, it does not specify which part of the proof is confusing or where the mistakes are located. Additionally, it mentions the lack of a detailed discussion and comparison with previous work, but again does not specify which sections or aspects are missing. The comment also suggests that the paper lacks new insights, but does not provide specific examples or details to support this claim. Overall, the comment is not grounded and lacks specificity, making it difficult for the authors to understand and address the issues. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there are confusing mistakes in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of specific examples or references makes the claim unverifiable, as it does not provide sufficient evidence or justification to support the claims. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed guidance on how to address these issues or what aspects of the proof or discussion are confusing. Without actionable feedback or suggestions for improvement, the authors are left without clear direction on how to enhance their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique and does not offer constructive feedback for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses several issues related to the motivation, experimental results, and comparison of the proposed model. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment does provide some specificity by mentioning the addition of CAT and GAN, which could be used to guide the authors in identifying the relevant sections. Overall, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in detailing the issues. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for using an adversarial network is unclear and that the experimental results are unfair. It also suggests that the proposed model is equipped with newly-added CAT and GAN, which is a larger model than others. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or detailed explanations to substantiate the claims, making it difficult for the authors to understand and address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network and the unfairness of the experimental results. It also points out that the proposed model is equipped with newly-added CAT and GAN, which could be considered a significant difference from other models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their work. While it highlights areas for improvement, the feedback lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to compare their captioning experiment results to the official COOC leader board on the blind test set, which is a clear and concrete action. It also suggests that the paper should compare to other approaches that have been evaluated on the blind challenge set, providing a specific example of [5,17] and mentioning that several other approaches have been proposed since then. This feedback is detailed and provides specific guidance on how to improve the paper by including comparisons to official test sets and other relevant works. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the captioning experiment, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to compare results to the official COOC leader board on the blind test set and to include comparisons to other approaches that have been evaluated on the blind challenge set. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the captioning experiment should be compared to the official COOC leader board on the blind test set, which is a specific suggestion for improvement. The reviewer provides a reference to the official COOC leader board and examples of other works that have been evaluated on the blind challenge set, such as [5,17]. This provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would enhance the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on how the authors can improve their captioning experiment. It points out that the paper currently compares to related work only on some not official test set or dev set, which is not ideal for demonstrating the final results. The reviewer suggests that the paper should compare to the official COOC leader board on the blind test set, which is a widely recognized benchmark in the field. Additionally, the comment suggests that the paper should include comparisons to other approaches that have been evaluated on the blind challenge set, such as [5,17], which would enhance the paper\\'s credibility and relevance. This feedback is clear and constructive, offering the authors a clear path to improve their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the reliability of the results or what specific steps to take to validate them. As a result, the authors are left without clear direction on how to improve the draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, particularly the MSE being significantly smaller than the MAE, which raises concerns about their validity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results and highlights a potential weakness in the paper. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the reliability of their experimental results. Without specific advice or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a problem but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their work. The comment lacks actionable details, such as recommending ways to differentiate the methodology or suggesting alternative approaches to enhance its originality. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique is based on, such as specific sections or methods where the extension is evident. Without explicit references to sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or references to existing methods to substantiate this claim. Without detailed comparisons or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might differentiate their work or enhance its originality. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the critique or improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific techniques or approaches to incorporate adversarial loss or explaining why it is necessary. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where this is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the adversarial loss are missing or how it could be incorporated. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is no adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting the absence of adversarial loss to ensure that perturbed data is similar to authentic data. This is a relevant point that could impact the validity of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or incorporate adversarial loss. Without actionable advice or detailed explanation, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a specific line (L248) where the term \"wrong\" is used and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is highly actionable as it offers a direct and specific suggestion for clarification, making it easy for the authors to implement the suggested changes.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of \"wrong\" and the use of terms like \"good\" and \"bad\" explanations. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of the term \"wrong\" in a specific context and suggests that the authors clarify what is meant by \"good\" and \"bad\" explanations before using these concepts. While the comment identifies a potential issue with the clarity of the paper, it does not provide specific examples or references to support the claim that the use of these terms is unclear. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as the authors may find it challenging to fully understand and address the issue without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly regarding the use of terms like \"good\" and \"bad\" explanations. It points out that the paper gets into some nuance regarding these concepts at L255 but suggests that clarification is needed before using these terms. This feedback is clear and actionable, as it directs the authors to provide additional context or explanation to ensure that their concepts are well-understood by the reader. By addressing this issue, the authors can improve the clarity and coherence of their paper, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the sample-by-sample optimization process. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific methods for tuning hyperparameters or discussing potential strategies for managing variation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of hyperparameters that need to be tuned, specifically mentioning step size, N, and $\\\\delta t$. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential variation in optimal hyperparameters due to the sample-by-sample optimization process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the sample-by-sample optimization process. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the optimization process, specifically the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the sample-by-sample basis. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or mitigate the potential variation. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a concern but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The reviewer is open to changing their rating based on feedback from the authors and comments from other reviewers. While the comment implies that the authors should provide additional analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific analysis required. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the issue of limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion for additional analysis, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The comment provides a logical reasoning by pointing out the limited comparison and the need for additional analysis to justify the results. However, it lacks specific examples or references to support the claim that the results violate the motivation. This makes the claim somewhat verifiable, as it provides a reasonable basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. This feedback is clear and actionable, as it points out a specific area where the authors need to improve their work. However, the comment could be more helpful if it provided specific suggestions on what kind of analysis would be beneficial or how to address the issue of inferior results. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It explicitly states that the current experimental comparison only compares ELF (the author\\'s method) with the baseline without MVF, which does not prove that the schema searched by ELF is better than the schema in MVF. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison with the image classification result of MVF to demonstrate the superiority of their method. The comment is concrete and provides a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental demonstration of the contribution points\" and the \"experimental comparison between ELF (the author\\'s method) and the baseline without Mid Vision Feedback (MVF),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: a comparison with the image classification result of Mid Vision Feedback (MVF) to prove the superiority of the schema searched by ELF. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The comment highlights a gap in the experimental setup, which is the lack of a comparison with the image classification result of MVF. However, the comment does not provide specific examples or references to support the claim that this comparison is necessary or how it would impact the evaluation of the contribution points. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of this comparison themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it points out a critical area where the paper lacks evidence to support its claims. By suggesting a comparison with the image classification result of MVF, the comment provides a concrete suggestion for the authors to enhance their experimental setup and demonstrate the superiority of their method. This feedback is valuable as it guides the authors to include a crucial comparison that could strengthen their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should add more content on this topic. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors can infer that it relates to the dataset analysis or discussion, but the comment lacks full grounding. It is specific in suggesting what needs to be addressed, but without explicit references, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they could be addressed. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is clear and actionable, as it points out a gap in the paper that could enhance its depth and relevance. However, the comment could be more helpful if it provided examples or detailed suggestions on how to address this issue, such as which types of activities should be covered or how they could be integrated into the existing analysis. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for expansion and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should use different notation to avoid confusion between the dimensionality of points and the dilation factor. This is a clear and direct action for the authors to take, as it provides a specific recommendation for improving the clarity of their paper. The comment is concrete, as it specifies the need for different notation, and it is also somewhat vague in that it does not provide detailed guidance on what specific notation should be used. Overall, the comment is highly actionable, as it clearly instructs the authors on how to improve the clarity of their paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"D\" to represent both dimensionality and dilation factor, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of different notation to avoid confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the use of \"D\" to represent both dimensionality and dilation factor can cause confusion. However, it does not provide any supporting evidence or examples to substantiate this claim. The comment lacks specific reasoning or references to justify why using different notation would be beneficial or how it would clarify the paper. As a result, the claim is unverifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of \"D\" to represent both dimensionality and dilation factor, suggesting that it can cause confusion. This is a clear and actionable suggestion that can help improve the clarity and readability of the paper. However, the comment could be more helpful if it provided examples of alternative notations or explained why the current notation is problematic. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, which can enhance the clarity and accessibility of their work. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the concept of \"state\" and questions the equivalence of \"elements\" to \"states\" or \"actions\" in a specific section of the paper. While the comment identifies an area that needs clarification, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to provide more elaboration on the concept of state and its relationship to elements or actions. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 186-line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the concept of \"state\" and its relationship to \"elements\" or \"actions.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the concept of \"state\" and its relationship to \"elements\" or \"actions.\" It suggests that more elaboration is needed. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the concept of state is unclear or how it should be clarified. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the concept of \"state\" and its relationship to \"elements\" or \"actions.\" It questions the equivalence of these terms and suggests that more elaboration is needed. This feedback is somewhat helpful as it points out a potential area of confusion that the authors should address to improve the clarity of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the concept or examples of how it might be misunderstood. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the Jaccard index as a potential metric. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the Jaccard index as a potential metric. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table where the results are presented. The authors can infer that it relates to the results or discussion section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a comparison using the Jaccard index. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the Jaccard index as a potential metric. However, the comment does not provide any reasoning or evidence to support why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the Jaccard index as a potential metric. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a specific method for evaluating the support of the proposed solution. However, the comment lacks depth and does not provide detailed guidance on how to implement this comparison or why it is important. Additionally, it does not address other aspects of the paper, such as clarity or coherence. While it points out a potential improvement, the feedback could be more comprehensive and actionable with additional explanation and context. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific observation regarding the behavior of a generator equipped with a standard R-GCN as a discriminator, noting that it tends to collapse after around 20 iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address this issue. While it implies that the authors should investigate and explain the reason behind the difference, it lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the tendency of a generator equipped with a standard R-GCN as a discriminator to collapse after around 20 iterations, while the proposed module does not. The comment suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, it does not provide specific suggestions on how to address this issue or what aspects of the proposed module should be explored. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a generator equipped with a standard R-GCN as a discriminator tends to collapse after around 20 iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment lacks specific examples, detailed explanations, or references to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some basis but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific observation regarding the behavior of a generator equipped with a standard R-GCN as a discriminator, noting that it tends to collapse after around 20 iterations, while the proposed module does not. This observation is important as it highlights a potential difference between the proposed method and previous ones, which could be crucial to understanding the mechanism of the proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out an area for improvement, it does not offer actionable steps or detailed analysis, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the originality of the paper, noting similarities to a previous study. It implies that the authors should address this issue by either explaining how their work differs from the previous study or demonstrating novel contributions. However, the comment does not provide specific guidance on how to do this, such as suggesting ways to differentiate the work or highlighting areas where novelty is present. The action is implicit and somewhat vague, as the authors need to infer that they should address the originality concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the originality of the paper, specifically mentioning a previous study, \"How Do Nonlinear Transformers Learn and Generalize in In-Context Learning.\" This provides some grounding by referencing a specific work, allowing the authors to identify the part of the paper being addressed. However, the comment does not specify what aspects of the paper are similar to the previous study or how the authors can address the originality concerns. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper's originality is questionable due to similarities with a previous study. However, it does not provide specific examples or detailed comparisons to substantiate this claim. The mention of the previous study, \"How Do Nonlinear Transformers Learn and Generalize in In-Context Learning,\" is not accompanied by a discussion of how the two works are similar or how the current paper introduces novel contributions. This lack of detailed evidence or comparison makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the originality concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the paper, noting similarities to a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this concern or differentiate their work from the previous study. The feedback is somewhat helpful as it points out a potential problem but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any explicit or implicit suggestions on how the authors should clarify these comparisons or what specific aspects need to be addressed. There is no guidance on whether additional explanations or examples are needed, nor is there a recommendation for how to present the comparisons more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the theoretical comparisons to adaptive learning of GPRGNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the theoretical comparisons to adaptive learning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the theoretical comparisons to adaptive learning of GPRGNN. It points out that the comparisons are not clear, which is a critical issue for understanding the paper\\'s contributions and implications. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify these comparisons or what aspects need to be addressed. While it highlights an important area for improvement, the feedback is incomplete and does not fully support the authors in making the necessary changes. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks actionable details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the sufficiency of using only yes/no responses to measure object hallucination. It highlights that a simple yes response does not necessarily indicate comprehension of the object in the image, as the model may still produce incorrect objects when performing other tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the measurement. The action is implicit and somewhat vague, as the authors can infer that they need to consider alternative methods for measuring object hallucination, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment where this measurement is used. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the methodology but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the sufficiency of using only yes/no responses to measure object hallucination, suggesting that a simple yes response does not necessarily indicate comprehension of the object in the image. The reviewer provides a logical reasoning by explaining that the model may still produce incorrect objects when undertaking other tasks. However, the comment lacks specific examples or references to support the claim that a simple yes/no response is insufficient. This makes the claim somewhat verifiable, as the authors would need to further explore the issue themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. It points out that the model may still produce incorrect objects when undertaking other tasks. This feedback is somewhat helpful as it identifies a potential limitation in the methodology and encourages the authors to consider alternative ways to measure object hallucination. However, the comment could be more helpful if it provided specific suggestions or examples of alternative methods to consider. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the very-long-term forecasting task is of limited practical significance and that the discussion requires improvement. It provides a specific action for the authors to take, which is to conduct experiments on more datasets and train the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback is explicit and provides concrete steps for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of the very-long-term forecasting task being of limited practical significance and suggests that the discussion requires improvement. However, it does not specify which part of the paper discusses this task or the specific aspects that need improvement. The authors can infer that it relates to the discussion section, but the comment lacks full grounding as it does not explicitly mention the section. Additionally, while it suggests conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon, it does not provide detailed guidance on how to implement these improvements. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the very-long-term forecasting task is of limited practical significance and suggests that the discussion requires improvement. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the authors may find it challenging to understand and respond to the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper regarding the practical significance of the very-long-term forecasting task and suggests that the discussion requires improvement. It provides a specific action for the authors to take, which is to conduct experiments on more datasets and train the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback is clear and actionable, offering a concrete way for the authors to enhance the discussion section of their paper. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects of the discussion need improvement. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of experiments and explanation regarding the different queries used in spatio-temporal representation, specifically spatial, temporal, and summary. It suggests that this is a key difference between the work and VideoChatGPT and other works. The reviewer implies that the authors should include experiments and explanation to address this gap. While the comment does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to conduct them, it clearly identifies an area for improvement and suggests a direction for the authors to take. Therefore, the comment is somewhat actionable, as it provides a clear but implicit action for the authors to follow.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Experiments - Ablation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of experiments and explanation regarding the different queries used in spatio-temporal representation, specifically spatial, temporal, and summary. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absence of experiments and explanation regarding the different queries used in spatio-temporal representation is a missing component. The reviewer suggests that this is a key difference between the work and VideoChatGPT and other works. However, the comment lacks specific examples or references to support the claim that these queries are crucial or how they contribute to the work\\'s significance. Without detailed justification or evidence, the claim remains somewhat verifiable, as it provides a general suggestion but lacks the necessary depth to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of experiments and explanation regarding the different queries used in spatio-temporal representation. It highlights the importance of these queries as a key difference between the work and VideoChatGPT and other works. The comment suggests that the authors should include experiments and explanation to address this gap, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it points out a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. The comment implies that the authors should provide more details about the innovative aspects of their model, but it does not offer concrete steps or examples of what these details should include. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not specify which part of the paper discusses the FRM, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for more details on the innovative aspects of the FRM, but it is not grounded as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation. It suggests that the innovative aspects should be detailed, but it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. While the comment highlights a potential weakness, it lacks actionable advice or examples that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider the potential social impacts of their work, such as increased automation and the risks from dual use. While the comment does not explicitly instruct the authors to include these aspects in their paper, it provides a clear direction for improvement by highlighting areas that could be explored. The action is implicit but concrete, as it specifies the potential social impacts that should be addressed. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential social impacts of the work, such as increased automation and dual use risks. The comment provides a clear direction for improvement by suggesting that the authors should consider these aspects. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not consider the potential negative social impacts of their work, specifically mentioning increased automation and dual use risks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides a general idea but lacks the necessary detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the lack of consideration of the social impacts of the work, specifically increased automation and dual use risks. While the reviewer acknowledges that the work is unlikely to have significant negative social impacts, they suggest that the authors could address this aspect by discussing the social impacts. This feedback is somewhat helpful as it points out a relevant area for consideration, but it lacks specific guidance or examples on how the authors might address these potential impacts. The comment could be more helpful if it provided suggestions on how to integrate these considerations into the paper. Overall, the comment is somewhat helpful as it directs the authors to a relevant area for improvement but does not fully support them in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a specific reorganization of the sections, proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This provides a clear and concrete action for the authors to take, as it offers a specific way to restructure the sections to improve clarity and coherence. The comment is explicit in its suggestion and provides a concrete implementation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 and Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests a specific reorganization of these sections, proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Sections 3 and 4 are redundant and proposes a specific reorganization to improve clarity. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the sections are redundant or how the suggested reorganization would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential redundancy in Sections 3 and 4, suggesting that reorganizing these sections could improve clarity. It provides a specific and actionable suggestion by proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This feedback is clear and offers a concrete way for the authors to enhance the organization and flow of their paper, which could improve the overall readability and coherence. However, the comment could be more helpful if it explained why the current organization is redundant or how the suggested reorganization would benefit the paper. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" It suggests that the authors should provide more details to establish a connection between these concepts. However, the comment does not specify what kind of details are needed or how to present them, leaving the authors to infer the necessary actions. While the comment identifies an area for improvement, it lacks concrete guidance on how to address the issue, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the connection between these concepts and the zero-shot learning effectiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zero-shot learning effectiveness.\" It points out that this lack of clarity is due to poor clarity in the paper. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or establish a connection between these concepts. While it highlights an area for improvement, the feedback lacks depth and actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notation \\hat v\\_{t} seems strange and questions its use. It suggests that the notation is confusing because it is used elsewhere for empirical estimates, but here it refers to something else. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to clarify the notation. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation but are not given specific steps to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L434,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \\hat v\\_{t}, explaining that it seems strange and confusing because it is used elsewhere for empirical estimates. The comment provides a clear direction for the authors to address the issue by suggesting that the notation should be clarified or revised. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the notation \\hat v\\_{t} on L434, suggesting that it is strange and confusing because it is used elsewhere for empirical estimates. However, the comment does not provide any specific reasoning or examples to support why this notation is confusing or how it differs from its standard use elsewhere. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the notation used in the paper, specifically the use of \\hat v\\_{t} on L434. It points out that this notation seems strange and confusing because it is used elsewhere for empirical estimates, which is not what it refers to in this context. This feedback is somewhat helpful as it highlights a potential source of confusion for readers and suggests that the notation should be clarified or revised. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what alternative notation might be more appropriate. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these analyses to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"strong empirical results\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the potential contribution of finding out the reasons behind the empirical results through theoretical analyses or experiments. However, the comment lacks specificity regarding what kind of theoretical analyses or experiments would be needed to address the questions raised. Therefore, this comment is fully grounded and under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. The comment provides a logical reasoning for why these analyses could be beneficial, but it lacks specific examples or references to support the claim that these analyses are missing in the paper. This makes the claim somewhat verifiable, as the authors would need to infer the need for these analyses based on the comment alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. This feedback is somewhat helpful as it points out a gap in the paper that could enhance its contribution and rigor. However, the comment lacks specific guidance on how to conduct these analyses or what specific aspects to focus on. While it highlights an area for improvement, the lack of detailed suggestions limits its utility for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for a citation regarding the k-max problem, which is a clear and direct action for the authors to take. The comment provides a specific request for additional information, ensuring that the authors know exactly what is expected of them. The action is concrete, as it specifies the need for a citation, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly asks for a citation regarding the k-max problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a citation regarding the k-max problem. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for a citation regarding the k-max problem. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual request for additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area where additional information or clarification is needed. By asking for a citation regarding the k-max problem, the reviewer prompts the authors to provide more context or references to support their claims. This feedback is actionable and can help the authors enhance the comprehensiveness and credibility of their work. However, the comment could be more helpful if it provided more detailed guidance on how to address the issue or suggested specific sources to consider. Overall, the comment is somewhat helpful as it directs the authors to a specific area for improvement but lacks depth and detailed suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback implies that the authors should provide more detailed information about the estimation process and the model\\'s reliability. However, the comment does not explicitly instruct the authors to include this information, nor does it provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to add more details but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of information on how the function for the optimal sequence length was estimated and how reliable the model is expected to be. This provides clear guidance on what the authors need to include in their paper to improve it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is no information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback is clear and actionable, as it points out a gap in the paper that the authors need to address to provide a more comprehensive understanding of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the applicability or what specific steps to take to mitigate the assumptions. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the applicability of the methods to real-world problems, specifically mentioning the assumptions about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the assumptions made and their impact on applicability. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the applicability of the methods, specifically noting that strong assumptions are made about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. This feedback highlights a potential weakness in the paper that could impact its relevance and practicality. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the applicability of their methods. While it points out a relevant concern, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a discrepancy in the language used in Figure L006, specifically noting that \"thousands\" is not accurate. It suggests a possible correction by adding \"on the subword level.\" This feedback is clear and provides a direct action for the authors to take, which is to revise the language in the figure to be more accurate. The suggestion is concrete, as it specifies the exact change needed to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the language used in the figure and suggests a possible correction by adding \"on the subword level.\" This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the figure caption, \"thousands,\" is not accurate. However, it does not provide any supporting evidence or reasoning to substantiate this claim. The comment suggests a possible correction by adding \"on the subword level,\" but without further explanation or examples, it lacks verifiability. The authors may find it challenging to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the language used in Figure L006, noting that the term \"thousands\" is not accurate. It suggests a possible correction by adding \"on the subword level,\" which could improve the accuracy of the figure. This feedback is clear and actionable, as it provides a direct suggestion for the authors to consider when revising their draft. However, the comment could be more helpful if it explained why \"thousands\" is not accurate or how the suggested correction would enhance the figure\\'s clarity. Overall, the comment is mostly helpful as it points out a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions for improvement. It notes that several hyperparameters, such as regularization, are not explicitly mentioned and asks for clarification on why the y-value in the latent path figures is always 0 at x=0. The reviewer also expresses interest in further analysis of the model, specifically mentioning interpolations as a potential area for exploration. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestions are somewhat vague and lack detailed guidance, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig 3\" and \"regularization,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues by questioning the y-value at x=0 in the latent path figures and expressing interest in further analysis of the model. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the absence of certain hyperparameters, such as regularization, and the y-value at x=0 in the latent path figures. It also expresses interest in further analysis of the model. While the comment identifies areas for clarification and potential improvements, it lacks specific examples or references to support the claim that these issues are problematic or require attention. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some basis for the claim but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the absence of certain hyperparameters, such as regularization, and the y-value at x=0 in the latent path figures. It also expresses interest in further analysis of the model, specifically mentioning interpolations as a potential area for exploration. While the comment highlights important issues, it lacks specific guidance or suggestions on how to address these concerns or improve the paper. The authors are given direction but not detailed steps on how to implement the suggested improvements. Therefore, the comment is somewhat helpful, as it provides insight into potential weaknesses but could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It specifically points out that the exact contributions need to be written more clearly in the Introduction and that the material supporting the main contributions is in the appendix rather than the main sections. While the comment provides a clear indication of what needs to be addressed, it does not offer specific guidance on how to improve the clarity of the contributions or suggest ways to integrate the material into the main sections. The action is explicit but somewhat vague in terms of execution, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"deep-rag algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for clearer contributions in the Introduction and the placement of supporting material in the main sections versus the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. The reviewer provides specific examples, such as Figure 1 and the deep-rag algorithm, to support this claim. However, the comment lacks detailed reasoning or references to substantiate why this is a significant issue or how it affects the paper\\'s clarity or impact. While the examples are helpful, the lack of detailed justification makes the claim somewhat verifiable, as the authors may need to infer the full extent of the problem and how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It provides specific examples, such as Figure 1 and the deep-rag algorithm, to illustrate the problem and suggests that the exact contributions need to be written more clearly in the Introduction. Additionally, it points out that the material supporting the main contributions is in the appendix rather than the main sections. This feedback is clear and actionable, as it directs the authors to improve the clarity and organization of their paper by integrating the necessary information into the main sections. However, the comment could be more helpful if it provided suggestions on how to effectively integrate this material into the main sections. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers specific guidance on how to address it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the effect of rounding core tensors on the full tensor error and seeks clarification on whether there is an error bound in terms of epsilon. While the comment identifies a potential area for improvement, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should provide more information on the theoretical aspects of the approximation error, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it points out a potential area for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the rounding of core tensors to smaller ranks with a given accuracy by clustering values or imposing some error decision epsilon. This allows the authors to accurately identify the relevant section. The comment is also specific because it asks for clarification on the effect of rounding on the full tensor error and seeks information on any error bound in terms of epsilon. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical aspects of rounding core tensors and the effect on the full tensor error. It seeks clarification on whether there is an error bound in terms of epsilon. While the comment identifies a potential area for improvement, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The authors are left to infer the need for clarification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors discuss the rounding of core tensors to smaller ranks with a given accuracy. It raises a question about the effect of this rounding on the full tensor error and seeks clarification on whether there is an error bound in terms of epsilon. This feedback is valuable as it prompts the authors to consider the theoretical aspects of their method and provides a clear direction for further exploration and explanation. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other studies have approached similar questions. Overall, the comment is mostly helpful as it guides the authors toward a deeper understanding of their method and its implications.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. While the comment implies that the authors should add results on the generative setting, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"visual dialog,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on the generative setting in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. The reviewer suggests that the authors should include results on the generative setting as well. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. This feedback is clear and actionable, as it directs the authors to address a gap in their experimental evaluation. However, the comment could be more helpful if it provided additional context or examples on how to conduct the analysis on the generative setting. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify what kind of evidence or examples would be sufficient or how they should be presented. The comment lacks explicit guidance on how to implement this suggestion, leaving the authors uncertain about the exact actions to take. As a result, the comment is vague and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or example that needs improvement. The comment is not grounded, as it does not specify where in the paper this issue is addressed. Additionally, it lacks specificity as it does not provide details on what kind of evidence or examples would be sufficient to convince the reader. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without concrete evidence or reasoning, the claim is unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. While it identifies a potential weakness in the paper, it lacks specificity and does not provide guidance on what kind of evidence or examples would be sufficient to address this concern. The comment is somewhat helpful as it points out an area for improvement, but it does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive and detailed.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to explore the effectiveness of the approach for other language families. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the effectiveness of the proposed approach for other language families, which is a clear and specific point. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of unknown effectiveness, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area of concern regarding the effectiveness of the proposed approach for other language families. It highlights a gap in the paper that needs to be addressed, which is important for the authors to consider. However, the comment lacks depth and does not provide specific suggestions or guidance on how to explore or demonstrate the effectiveness of the approach for other language families. While it points out a relevant issue, it does not offer actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or methods to ensure privacy protection. As a result, the authors are left without a clear understanding of what steps to take to improve their draft in this area. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of analysis on the security (protection of privacy) of the proposed framework. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection where the analysis should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue of security analysis, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a significant gap in the paper, noting that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. This is a critical oversight that could impact the overall robustness and trustworthiness of the work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending particular analyses or methods to ensure privacy protection. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the form of p should be described near line 135, as it is assumed to be a Gaussian distribution. This provides a clear and direct action for the authors to take, which is to explicitly state the form of p in their draft. The comment also references the reviewer\\'s previous comment, which adds context and clarity. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the form of p is not explicitly stated and assumes it to be a Gaussian distribution. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the form of p should be described near line 135, as it is assumed to be a Gaussian distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or necessary. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary justification for the authors to understand and address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the form of p is not explicitly stated near line 135, despite being assumed to be a Gaussian distribution. This feedback is clear and actionable, as it directs the authors to explicitly state the form of p in their draft. By addressing this point, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. While it implies that the authors should expand on these differences, it does not explicitly instruct them to do so or provide specific guidance on how to approach this enhancement. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed descriptions of the differences. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not specify which parts of the related work section are lacking in detail or which works are not described adequately. Without explicit references to specific sections or works, the authors cannot confidently determine which parts need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not provide specific examples or references to the works that are lacking in detail, making it difficult for the authors to understand which aspects need improvement. The claim is based on a general observation without specific examples or evidence, making it challenging for the authors to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the related work section, specifically noting that some related works are named but not described in sufficient detail. This feedback is somewhat helpful as it points out a specific area where the authors could enhance their work, providing a clear direction for improvement. However, the comment lacks specific examples or guidance on how to address this issue, such as which works are lacking in detail or how to improve the descriptions. While it highlights an area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to explain what type of understanding is gained by looking at the PPP maps. This is a clear and direct request for clarification, providing the authors with a specific action to take. The comment is concrete because it specifies the exact information that needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors state the importance of reliable PPP metrics for understanding PPP effects in different tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for an explanation of what type of understanding is gained by looking at the PPP maps, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the authors\\' explanation regarding the understanding gained from looking at PPP maps. It suggests that while the importance of reliable PPP metrics is mentioned, the article lacks explicit explanation or understanding of this concept. The comment is somewhat verifiable as it logically points out a gap in the explanation but does not provide specific examples or references to support the claim. The authors may need to provide more detailed explanations to fully address the reviewer\\'s concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the understanding gained from looking at PPP maps. It points out that while the authors mention the importance of reliable PPP metrics, they do not provide an explicit explanation or understanding of this concept. The comment is somewhat helpful as it highlights a specific area for improvement, namely the need for a more detailed explanation of the concept. However, it lacks depth and does not provide specific suggestions or examples on how the authors might address this issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the authors have not compared their methods with other state-of-the-art methods for span-related tasks, such as SpanBERT. This implies that the authors should include such comparisons to enhance the credibility of their work. The action is clear and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparison with state-of-the-art methods for span-related tasks, such as SpanBERT. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with other state-of-the-art methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have not compared their methods with other state-of-the-art methods for span-related tasks, such as SpanBERT, which affects the credibility of their work. However, the comment does not provide specific examples or references to these state-of-the-art methods or explain how the absence of comparison affects the credibility. This lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the significance of the comparison themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors have not provided sufficient evidence for the credibility of their work. It points out the lack of comparison with state-of-the-art methods for span-related tasks, such as SpanBERT, which is a relevant benchmark for evaluating the effectiveness of the proposed methods. This feedback is clear and actionable, as it directs the authors to include such comparisons to enhance the credibility of their work. However, the comment could be more helpful if it provided examples of how these comparisons could be conducted or what specific aspects to focus on. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the discussion regarding the regret and the proof of the method achieving T^{1/2} regret. It raises a question about whether the prediction error over the entire horizon T cannot be sublinear. While the comment identifies an issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to clarify or correct the discussion, but the comment lacks concrete steps on how to do so. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 32 - 37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the discussion regarding the regret and the proof of the method achieving T^{1/2} regret. The comment clearly specifies what needs to be addressed, namely, whether the prediction error over the entire horizon T cannot be sublinear. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the discussion regarding the regret and the proof of the method achieving T^{1/2} regret. It points out a potential discrepancy in the discussion, asking whether the prediction error over the entire horizon T cannot be sublinear. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the prediction error cannot be sublinear. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the discussion regarding the regret and the proof of the method achieving T^{1/2} regret. It points out a potential issue in the logic of the discussion, questioning whether the prediction error over the entire horizon T cannot be sublinear. This feedback is somewhat helpful as it highlights a specific area where the authors need to clarify or correct their discussion. However, the comment could be more helpful if it provided suggestions on how to address the discrepancy or offered guidance on how to clarify the discussion. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing attention, but it lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the details of the forward-prediction model are not well explained, particularly in Figure 2(b), and suggests that the figure should be redrawn to better represent the schematic. It also mentions that the connection between the text and the figure, as well as the equations, is difficult to understand. This provides clear and concrete actions for the authors to take, such as redrawing the figure and improving the explanations in the text. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2(b)\" and \"the forward-prediction model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the lack of a clear schematic representation in Figure 2(b) and the difficulty in connecting the text and equations with the figure. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the details of the forward-prediction model are not well explained, particularly in Figure 2(b), and suggests that the figure should be redrawn to better represent the schematic. The reviewer provides a specific example of the figure not showing the schematic representation and notes the difficulty in connecting the text and equations with the figure. This provides a clear and concrete basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing additional details or references to similar issues in other works, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clear explanation and representation of the forward-prediction model in Figure 2(b). It points out that the figure does not provide a schematic representation of the model, making it difficult for readers to understand the concept. The comment suggests that the figure should be redrawn to better illustrate the model. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that can help the authors enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional guidance on how to improve the explanation or suggested alternative ways to present the model. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The reviewer also questions the authors\\' choice of baseline and suggests they should provide a stronger baseline to prove the usefulness of FP. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger baseline and consider the impact of rewardless actions on RBI. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RBI\" and \"Task 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that RBI only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The comment suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone and questions the authors\\' choice of baseline. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The comment suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the significance of the issue and the potential impact on the results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. This is a significant observation that could impact the performance and effectiveness of the model. The comment suggests that this could be a factor contributing to the superiority of FP + RBI over RBI alone. Additionally, it questions the authors\\' choice of baseline and recommends providing a stronger baseline to prove the usefulness of FP. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. Therefore, it is somewhat helpful, as it points out potential weaknesses but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the multi-scale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer suggests that the only benefit is the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the statement, it does not provide explicit guidance on how the authors should address this misleading aspect. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the time scales involved and possibly revise the statement to be more accurate. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"multi-scale statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, explaining that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The comment further suggests that the only benefit is the reduction of gradient path by the slow RNN. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the multi-scale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer supports this claim by explaining the distinction between physical and logical time scales and suggesting that the only benefit is the reduction of gradient path by the slow RNN. This reasoning is logical and provides a clear explanation, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the distinction between physical and logical time scales. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential misleading aspect in the paper regarding the multi-scale statement. It points out that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and understanding of the work. However, the comment could be more helpful if it provided suggestions on how the authors might clarify this aspect or address the misleading statement. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing clarification, but it lacks detailed guidance on how to improve it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these issues, but without specific guidance on how to do so, the action remains vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment does specify what needs to be addressed, such as the need for a discussion on limitations and a comparison with reinforcement learning. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the baseline methods are weak and not state-of-the-art, and that there is no discussion of limitations. It suggests that the paper should discuss the similarity and difference with reinforcement learning and provide a comparison to RL settings. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that the baseline methods are weak or that there is no discussion of limitations. The suggestion for a comparison with reinforcement learning is logical, but the lack of specific examples or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. It suggests a direction for the conclusion by discussing the similarity and difference with RL settings and the generalizability of the results. While the comment highlights important areas for improvement, it does not provide specific guidance or examples on how to address these issues. The authors are left with a general idea of what needs to be improved but without detailed steps or suggestions on how to implement these improvements. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify the distinction between the expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. While the comment implies that the authors should make this distinction clearer upfront, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction, but it is concrete in that it provides a clear direction for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. The comment provides a clear direction for improvement by suggesting that the distinction should be made clearer upfront. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the expected performance under observation noise is typically used for evaluation because the decision-maker is interested in the true objective function and the noise is assumed to be noise (misleading, not representative). The reviewer suggests that in the current paper, the decision-maker does care about the noise, and the objective function of interest is the stochastic noisy function. The comment provides a logical reasoning for the distinction between the two scenarios, but it lacks specific examples or references to support the claim that the current paper's approach is misleading. Therefore, the claim is somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s approach to evaluation, noting that the expected performance under observation noise is typically used because the decision-maker is interested in the true objective function and the noise is assumed to be noise. However, in the current paper, the decision-maker is interested in the stochastic noisy function, which is a different objective. The comment suggests that the distinction between these two should be clarified upfront to avoid misleading the reader. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to clarify this distinction or provided examples of how other papers have addressed similar issues. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. It also proposes a minor point about optimizing the inference part of the model by keeping the generative model fixed and parameterizing it as either SIG-VAE or VGAE to compare the representations. While the comment provides a clear action to take regarding the VGAE implementation, it lacks specific guidance on how to implement the suggested comparison with SIG-VAE or VGAE. The minor point about optimizing the inference part is also mentioned but not further elaborated on. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"VGAE with a vamp prior\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential benefits of the generative model and the inference part of the model. The comment provides a clear suggestion to run VGAE with a vamp prior to better match the doubly stochastic construction and offers a minor point about optimizing the inference part of the model. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. This claim is somewhat verifiable as it provides a logical reasoning for the potential benefits of the generative model and inference part of the model. However, the comment lacks specific examples or references to support the claim, such as explaining how the vamp prior would improve the model or providing data or studies that demonstrate its effectiveness. Additionally, the minor point about optimizing the inference part of the model is mentioned but not fully developed. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides a logical basis for the claim but lacks detailed evidence or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. The first part suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which could help inform whether the benefits are coming from a better generative model or better inference due to doubly-semi implicit variational inference. This is a clear and actionable suggestion that could significantly impact the authors\\' understanding and interpretation of their results. The second part is a minor point about optimizing the inference part of the model by keeping the generative model fixed and parameterizing it as either SIG-VAE or VGAE to compare the representations. While this suggestion is relevant, it is not as actionable as the first part and lacks detailed guidance on how to implement this comparison. Overall, the comment is mostly helpful as it provides valuable insights and suggestions for improving the draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the good performance of the method, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to enhance the novelty or contribution of their work. The action is implicit and vague, as the authors are left to infer that they need to improve the novelty or contribution of their work, but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance of the method, specifically mentioning Table 2, and acknowledges the novelty and contribution of the work. However, it does not specify which part of the paper discusses the novelty or contribution, making it weakly grounded. The comment does specify that the main contribution is a new network design inspired by prior work for sound source localization, which provides some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method\\'s performance is good, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment lacks specific examples or references to support the claim that the method is incremental or lacks novelty. Without detailed evidence or reasoning, the authors may find it challenging to address the critique effectively. Therefore, the claim is considered borderline verifiable, as it provides some context but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the good performance of the method, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. While the comment identifies a potential issue with the novelty and contribution of the work, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening, but questions whether it is fully required. The reviewer suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the importance of long-range dependencies in their paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the importance of learning long-range dependencies for powerful predictors, particularly in the context of semantic segmentation. The comment suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The comment suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. However, the comment lacks specific examples or references to support the claim that learning long-range dependencies is not always necessary. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the importance of learning long-range dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The reviewer suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. This feedback is somewhat helpful as it prompts the authors to consider the importance of long-range dependencies in their work and to provide a more nuanced discussion on this topic. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what aspects of the discussion should be included. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The feedback is somewhat actionable as it highlights a potential weakness but lacks concrete steps for the authors to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Corollaries 1, 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the definition of $e_l$ and pointing out the exponential dependence on the diameter $M$ of the domain of data. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the definition of $e_l$ in Equation (3) and questions the exponential dependence on the diameter $M$ of the domain of data in the theoretical results. It also notes that the dependence on $M$ affects the constant factor of the required feature size, as demonstrated by Figure 1. While the comment provides some logical reasoning by pointing out the exponential dependence on $M$, it lacks specific examples or references to support the claim that this dependence affects the performance. The authors would need to further explore the implications of this dependence to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks detailed evidence or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, questioning the definition of $e_l$ in Equation (3) and pointing out the exponential dependence on the diameter $M$ of the domain of data in the theoretical results. It also notes that this dependence affects the constant factor of the required feature size, as demonstrated by Figure 1. This feedback is valuable as it highlights a potential weakness in the theoretical results and suggests that the authors should address this issue to strengthen their work. However, the comment could be more helpful if it provided specific suggestions on how to address this weakness or what aspects of the theoretical results need further clarification or validation. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the long-range modeling ability of DGNs, suggesting that it could be due to oversmoothing, another phenomenon observed in the context of very deep graph networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to improve the modeling ability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the long-range modeling ability of DGNs and suggests that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. However, it does not specify which part of the paper discusses the long-range modeling ability or oversmoothing, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of oversmoothing but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modeling ability of DGNs is due to oversquashing and vanishing/exploding gradients, but also suggests that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. The comment provides a reference to a specific work, \"Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning, In AAAI\\u002718,\" which supports the claim about oversmoothing. This reference provides a logical basis for the claim and adds some verifiability to the suggestion. However, the comment could be strengthened by providing more detailed explanations or examples of how oversmoothing affects the modeling ability. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the long-range modeling ability of DGNs, suggesting that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. While the comment provides a reference to a specific work that discusses oversmoothing, it does not offer detailed guidance or suggestions on how the authors might address this issue or improve their modeling ability. The feedback is somewhat helpful as it points out a potential problem but lacks actionable advice or specific steps for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether there is a demonstration or result related to the model collapsing less than other methods. It also asks about the specific observation of gradients becoming 0 and collapsing, mentioning line 159. While the comment implies that the authors should provide evidence or examples to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or examples to address the reviewer\\'s concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a demonstration or result related to the model collapsing less than other methods, and it raises questions about the common occurrence of gradients becoming 0 and collapsing. This provides clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the demonstration or results related to the model collapsing less than other methods. It specifically mentions line 159, where the authors mention gradients becoming 0 and collapsing. This feedback is somewhat helpful as it prompts the authors to provide evidence or examples to support their claim, which could strengthen the paper\\'s argument. However, the comment lacks depth and does not offer specific suggestions on how to address the issue or what kind of evidence would be beneficial. While it points out a potential area for improvement, it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify the formulation or what aspects are unclear. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper these issues are found in. Without explicit references to sections or examples, the authors cannot confidently determine where to focus their revisions. The comment is specific in identifying the issue of unclear problem formulation, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim. Without specific references or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide guidance on how to improve the clarity or what aspects of the formulation are unclear. Without actionable suggestions or examples, the authors are left without a clear path to address the issue. Therefore, the comment is not helpful, as it does not offer constructive feedback for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests conducting experiments with different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This provides a clear and concrete action for the authors to take, as it specifies the exact models to include in the experiments and the purpose of doing so. The comment is specific and directs the authors on how to enhance their draft by including additional experiments. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting experiments with different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This provides a clear direction for the authors to expand their experimental scope. However, the comment does not specify which part of the paper should include these experiments, such as the results or methodology sections. While the authors can infer that it relates to the experimental section, the comment lacks full grounding as it does not explicitly mention the section. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks experiments on different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This claim is somewhat verifiable as it provides a logical reasoning for why conducting such experiments could be beneficial. However, it lacks specific examples or detailed justification for why these particular models are important or how they would enhance the study. The suggestion is based on a general understanding of the importance of diverse experiments, but it could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\\'s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directs the authors to expand their experimental scope and includes specific models to consider. By addressing this suggestion, the authors can enhance the robustness and comprehensiveness of their study. However, the comment could be more helpful if it provided additional context or rationale for why these specific models are important or how they might impact the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or what specific steps to consider for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the method are limited to fine-tuning or how this limitation could be addressed. Without clear guidance on what needs to be improved or expanded, the authors may find it challenging to understand and act upon the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a limitation in the method, suggesting that it only works for generative models that can be fine-tuned as an in/outpainting model. While this observation highlights a potential weakness, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this limitation or what specific aspects of the method need to be revised or expanded. Without actionable advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a perceived weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not align with the title or the author\\'s imagined process. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the connections. The comment lacks actionable details, such as recommending specific modifications or suggesting alternative approaches. As a result, the authors are left without a clear understanding of how to improve their draft in this area. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first part and the second part of the paper, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the perceived weakness in the connections between the curve finding and FGE, and it provides a rationale for this observation. However, the comment lacks specificity regarding what needs to be addressed or improved in these connections. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the connections between the curve finding and FGE are weak, based on the author\\'s interpretation of the first part and the title. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The comment suggests that the process described in the first part does not align with the imagined process, but it does not provide specific examples or references to substantiate this claim. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not align with the title or the author\\'s imagined process. It points out that the process described is computationally demanding and could lead to confusion. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the connections between the two parts. While it highlights an area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it offers insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results for linear scalarization + Concorde, which is a known SOTA heuristic-based solver, to provide a better comparison with the learning-based solvers. This feedback is explicit and provides a clear action for the authors to take, as it specifies the need for including these results in the paper. The comment is concrete, as it directly instructs the authors on what to add to their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and \"Pareto front\" from Figure 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of results for linear scalarization + Concorde to provide a better comparison with the learning-based solvers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the learning-based solvers are better than the heuristic-based solvers, but it suggests that for the single objective TSP, the SOTA heuristic-solver (e.g., Concorde) usually has the best performance. The comment provides a logical reasoning by referencing the experimental results and the non-convexity of the Pareto front, which supports the claim that linear scalarization + Concorde should be included for a better comparison. However, the comment could be strengthened by providing specific examples or references to the experimental results that support the claim. Overall, the claim is mostly verifiable, as it is based on logical reasoning and a reference to a specific solver, but it could be further substantiated with additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It points out that the learning-based solvers are better than the heuristic-based solvers, but for the single objective TSP, the SOTA heuristic-solver (e.g., Concorde) usually has the best performance. The comment suggests that the authors should include results for linear scalarization + Concorde to provide a better comparison with the learning-based solvers. This feedback is valuable as it directs the authors to include a relevant comparison that could enhance the paper\\'s contribution. However, the comment could be more helpful if it explained why this comparison is important or how it might impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use generalized Voronoi graphs, semantic maps, or pose graphs for exploration. While the comment implies that the authors should provide a comparison or discussion of their method with these existing methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of their method in relation to these existing methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"generalized Voronoi graph or semantic maps,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion of the proposed method in relation to existing methods that use similar concepts for exploration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer supports this claim by referencing existing methods, such as graph-based SLAM and curiosity-driven exploration, which use similar concepts. This provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific methods, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas presented are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. It suggests that the paper should discuss the proposed method in relation to these existing methods, which could enhance its originality and contribution. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific examples or references to these existing methods, which would guide the authors in their comparison and discussion. Overall, the comment is mostly helpful as it highlights an area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental setup, tasks, and other details should be moved back into the main text from the appendix to improve interpretability. It also recommends moving some background information from Section 2 to the appendix. While the comment provides a clear action\u2014moving details back into the main text and reorganizing the appendix\u2014it does not specify which details should be moved or how to structure the reorganization. The authors are left to infer which details are most important to include in the main text and how to integrate them. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, tasks, and other details being moved to the appendix, making it difficult to interpret the paper. It suggests moving some of these details back into the main text and reorganizing the appendix. However, the comment does not specify which details should be moved or how they should be integrated into the main text. This lack of specificity makes it challenging for the authors to identify the exact parts of the paper that need revision. Therefore, the comment is weakly grounded because it does not specify the exact sections or details being addressed, and it is not specific in detailing what needs to be changed. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the experimental setup, tasks, and other details are moved to the appendix, making it difficult to interpret the paper. The reviewer recommends moving some of these details back into the main text and suggests reorganizing the appendix. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the interpretability or clarity of the paper. The suggestion is based on a general observation, but without further explanation or evidence, it lacks verifiability. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, tasks, and other details being moved to the appendix, making it difficult for readers to interpret the paper. It suggests moving some of these details back into the main text and reorganizing the appendix. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accessibility of the paper. However, the comment could be more helpful if it offered specific examples of which details should be moved or how to structure the reorganization. Overall, the comment is mostly helpful as it guides the authors on how to enhance the interpretability and readability of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that providing glosses in Figure 2 would be helpful. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the figure. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing glosses in Figure 2, which implies that it is referring to a specific figure in the paper. However, it does not explicitly mention the figure, making it weakly grounded. The comment is specific in suggesting what needs to be added, which is the provision of glosses. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests providing glosses in Figure 2, which is a request for clarification or additional information. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that providing glosses in Figure 2 would be helpful. This feedback is specific and actionable, as it directly addresses a potential issue with the clarity of the figure. By suggesting the inclusion of glosses, the reviewer provides a clear and concrete suggestion for improving the draft. However, the comment could be more helpful if it explained why glosses are necessary or how they would enhance the figure\\'s clarity. Overall, the comment is mostly helpful as it offers a specific and actionable improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the term \"Memb\" is mentioned as the previous state-of-the-art but there is no reference provided. This implies that the authors should include a reference to the work that introduced or used \"Memb\" in their paper. However, the comment does not specify which work or where the reference should be added, leaving the authors with a vague understanding of what needs to be done. The action is explicit in identifying the need for a reference, but it lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions \"Memb\" as the previous state-of-the-art, but it does not specify which part of the paper this reference is mentioned in. This makes it difficult for the authors to pinpoint the exact section that needs attention. However, the comment does specify the issue of not providing a reference, which is clear and specific. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"Memb\" is mentioned as the previous state-of-the-art but no reference is provided. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the term \"Memb\" is mentioned as the previous state-of-the-art but no reference is provided. This is a clear and actionable point, as it highlights a potential gap in the paper\\'s literature review or citation. By addressing this issue, the authors can ensure that their work is properly contextualized and supported by relevant references. However, the comment could be more helpful if it provided suggestions on how to include the missing reference or what specific works should be cited. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the choice of grouping for quantization, specifically questioning why per-tensor and per-channel grouping is used instead of finer grouping. However, it does not provide any explicit or implicit suggestions for how the authors might address this question or what specific changes they should consider. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of grouping for quantization, specifically questioning why per-tensor and per-channel grouping is used instead of finer grouping. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this choice is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the quantization choice are being questioned or how the authors might address these concerns. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the choice of grouping for quantization, specifically questioning why per-tensor and per-channel grouping is used instead of finer grouping. However, it does not provide any supporting evidence, reasoning, or references to justify why finer grouping might be preferable. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the choice of grouping for quantization, specifically questioning why per-tensor and per-channel grouping is used instead of finer grouping. While it identifies a potential area for improvement, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what specific benefits finer grouping might offer. The comment is somewhat helpful as it prompts the authors to consider a different approach, but it could be more beneficial with additional context or suggestions for improvement. Therefore, it aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It explicitly recommends conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback provides a clear and concrete action for the authors to take, as it specifies the exact aspect to investigate and offers a specific direction for further analysis. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this analysis could be conducted. The authors can infer that it relates to the model evaluation or results section, but this inference is not direct. The comment is specific in suggesting a particular aspect to investigate, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the study. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable, as it does not provide sufficient justification for the authors to act on it.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests studying the impact of the ratio of unseen classes on the performance of the model. It provides a specific direction for further analysis by recommending conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback is actionable and constructive, as it offers a clear and concrete suggestion for the authors to enhance their study. However, the comment could be more helpful if it provided additional context or examples of how this analysis could be conducted or what specific aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. While the comment implies that the authors should provide an explanation or rationale for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification or explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these architectures are discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its inquiry, it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the inquiry or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of using GRU for the Pyramid and LSTM for the sequential part, questioning whether the combination of these architectures is a reason for the improvements. This is a valuable point as it prompts the authors to consider the rationale behind their choice of models and whether it is a significant factor in their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered insights into potential alternatives or comparisons. While it identifies a critical area for consideration, it lacks depth and actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the definition of \"active vertices\" in a specific line of the paper. While it identifies a potential issue with the clarity of the definition, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the definition, but it lacks concrete instructions or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \"active vertices\" and seeks clarification on how it is defined in this context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the definition of \"active vertices\" in a specific line of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the definition of \"active vertices\" in a specific line of the paper, which is a clear and actionable point. By asking for clarification on the definition, the reviewer prompts the authors to provide more detailed explanations or definitions to ensure that their work is clear and understandable. This feedback is valuable as it helps the authors improve the clarity and comprehensibility of their draft, which is an important aspect of scientific communication. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the paper\\'s claims and the limitations it discusses. It points out that the theory is not mentioned as a limitation in the main text, despite being applicable to the model. The reviewer suggests that the authors should address this issue by explicitly mentioning the theoretical limitation in the main text. Additionally, the comment suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general, which could be a valuable addition to the paper. While the comment provides clear and concrete actions for the authors to take, it does not specify how to elaborate on the negative societal impact. Overall, the comment is mostly actionable as it provides explicit guidance on what needs to be addressed and expanded upon, but it could be more detailed in its instructions for elaboration.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"vagueness of unspecified 'structural assumptions'\" in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the theoretical limitation is not mentioned in the main text and suggesting that the authors should address this gap. Additionally, it provides a specific suggestion to elaborate on the potential negative societal impact of graph neural networks in general. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not mention the theoretical limitation of its theory being applicable to the used model, despite the vagueness of unspecified \"structural assumptions\" in the appendix. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and should elaborate on the potential negative societal impact of these networks. The comment provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion about the current use of graph neural networks in industry. Additionally, the suggestion to elaborate on the negative societal impact is somewhat vague, as it does not specify what aspects should be elaborated on. Therefore, the claim is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the theoretical limitation of the theory being applicable to the used model is not mentioned in the main text. It points out that the vagueness of unspecified \"structural assumptions\" in the appendix makes it difficult for readers to find this limitation. The comment also suggests that the authors underestimate the current use of graph neural networks in industry and should elaborate on the potential negative societal impact of these networks. This feedback is clear and actionable, as it provides specific guidance on what the authors need to address to improve their draft. By suggesting a more detailed discussion of the negative societal impact, the comment offers a constructive way for the authors to enhance their paper. Therefore, it is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"epsilon-greedy\" in the context of training, indicating what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"epsilon-greedy\" in the context of training. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"epsilon-greedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. This question highlights a potential area of confusion or misunderstanding in the paper, which could be clarified to enhance the readers\\' comprehension. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the method or what specific aspects need attention. The authors are left without any direction on how to address the comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where this combination is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in detailing the combination of GCN and normalizing flow, but without grounding, it lacks actionable guidance for the authors. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, it does not provide any specific insights or suggestions for improvement. The comment lacks actionable feedback or detailed analysis, leaving the authors without a clear understanding of how to address the critique or enhance their work. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to ensure that both heads are affected. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the affected layers, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). This is a clear observation that could be relevant for the authors to address, as it highlights a potential imbalance in the paper\\'s focus. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific changes could be made to ensure a more balanced presentation. While it points out a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide explicit guidance on what specific part of the framework is vital or how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the importance of the framework in the context of weakly supervised learning. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspect of the framework is vital or how it contributes to the use of CLIP. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. However, it does not provide any supporting evidence, reasoning, or references to justify why this part is crucial or how it distinguishes the paper from other related work. Without such information, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the discussion. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the weakness in the analogy between HOI analysis and Harmonic analysis, noting that there is only a limited basis for forming an HOI. It also questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. While the comment identifies areas of concern, it does not provide explicit guidance on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the basis for HOI and the connection to Fourier analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the analogy between HOI analysis and Harmonic analysis, noting that the link is weak. It also questions the connection between the decomposition/integration steps and Fourier analysis. However, it does not specify which part of the paper discusses these analyses, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its critique of the analogy and the connection to Fourier analysis, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, and questions the connection between the decomposition/integration steps and Fourier analysis. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or detailed explanations to substantiate the critique, making it difficult for the authors to understand and address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a weakness in the analogy between HOI analysis and Harmonic analysis, noting that the link is limited. It also questions the connection between the decomposition/integration steps and Fourier analysis, which is a significant concern. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the analogy. While it points out areas for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators. However, it also acknowledges that most existing ML accelerators use bit-parallel fixed-point numbers, which could restrict the implications of the proposed methodology. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or explore its implications further. The action is implicit and somewhat vague, as the authors can infer that they might need to consider the impact of this limitation on the applicability of their methodology. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the potential limitation of the proposed methodology, specifically regarding the performance gains of dynamic precision control during training on bit-serial accelerators. It also mentions the use of bit-parallel fixed-point numbers by most existing ML accelerators, which could restrict the implications of the proposed methodology. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the applicability of the methodology to existing accelerators. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators, which is a specific observation about the applicability of the proposed methodology. However, the comment lacks supporting evidence or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered borderline verifiable, as it provides a logical reasoning but lacks sufficient evidence or references to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bit-serial accelerators. This is a relevant observation that could impact the applicability and generalizability of the methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore its implications further. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the focus distance shown in Figure 8, noting that it only includes 1m and 5m, which are both present in the training data. The reviewer asks whether the focus distance extends beyond these examples and whether it generalizes well. While the comment implies that the authors should consider including additional focus distances, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the focus distance range. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the focus distance shown in the figure, suggesting that it should include other distances beyond those present in the training data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the focus distance shown in Figure 8, noting that it only includes 1m and 5m, which are both present in the training data. The reviewer suggests that the focus distance should be expanded to include other distances, implying that it may not generalize well. However, the comment lacks specific examples or references to support the claim that other distances are necessary or how they would impact the generalizability. This makes the claim somewhat verifiable, as it provides a logical suggestion but lacks detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 8, noting that it only shows focus distances of 1m and 5m, which are both present in the training data. It raises a valid question about whether the focus distance extends beyond these examples and whether it generalizes well. This feedback is somewhat helpful as it prompts the authors to consider whether their results are robust across a broader range of focus distances. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional focus distances to test or discussing the implications of this limitation. Overall, the comment is somewhat helpful as it points out a potential weakness but lacks detailed guidance on how to resolve it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instance-specific and content includes information that can be transferred among groups. The comment also raises a question about the authors\\' understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a clear direction for the authors to consider broadening their definition of content and style, it does not offer specific guidance on how to implement this suggestion. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors\\' neural application and provides specific examples from Gabbay & Hosehn (2018) to illustrate the broader definition of content and style. It also raises a question about the authors\\' understanding of the term \"style\" in their model, which adds specificity to the comment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider defining content and style more broadly, providing an example from Gabbay & Hosehn (2018) where style is instance-specific and content includes information that can be transferred among groups. The comment also raises a question about the authors\\' understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a logical reasoning for broadening the definition of content and style, it lacks specific references or examples to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to consider broadening their definition of content and style, particularly in the context of their neural application. It offers an example from Gabbay & Hosehn (2018) to illustrate how style is instance-specific and content includes information that can be transferred among groups. Additionally, the comment raises a pertinent question about the authors\\' understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. This feedback is valuable as it prompts the authors to reconsider their terminology and potentially enhance the clarity and applicability of their work. However, the comment could be more helpful if it provided specific guidance on how to apply this broader definition or how to address the question about the temporal dynamic structure. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. It provides examples of the variance difference in the proposed approach compared to existing methods, such as Q-BERT, Q8BERT, BinaryBERT, and FullyBinaryBert. While the comment identifies areas that need further explanation, it does not explicitly instruct the authors on how to improve the analysis or provide specific guidance on how to address the issues. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations and comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of vit quantification, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the analysis could be explained in depth, particularly regarding the information distortion and the quantization of MHSA. The comment provides specific examples of the variance difference in the proposed approach compared to existing methods, such as Q-BERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. The reviewer provides examples of the variance difference in the proposed approach compared to existing methods, such as Q-BERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This provides a logical and well-supported argument, as it references specific examples to illustrate the issue. However, the comment could be strengthened by referencing specific lines or figures in the paper where these issues are discussed, which would make the claim fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the analysis of vit quantification. It points out that the paper argues that a direct quantization method leads to information distortion, but does not provide a detailed explanation or comparison with existing methods. The reviewer also highlights the quantization of MHSA, which introduces a large loss of precision, as a concern that has been observed in transformer quantization in NLP. The comment suggests that the authors should provide a more in-depth explanation of these issues, including comparisons with existing methods. This feedback is clear and actionable, guiding the authors to enhance the depth and clarity of their analysis. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a main weakness of the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed X-transformation seems similar to STN, and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to include comparisons to STN and provide more detailed explanations of the novelty of their approach. However, the comment lacks concrete suggestions on how to conduct these comparisons or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the paper, namely the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It mentions the proposed X-transformation and its similarity to STN, as well as the use of STN in PointNet. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these topics are discussed. The comment is specific in detailing what needs to be addressed, such as the need for comparisons to STN and the need for more detailed explanations of the novelty of the proposed approach. Therefore, this comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical novelty of the work is limited due to its similarity to spatial transformer networks (STN) and the absence of comparisons to STN. The reviewer supports this claim by pointing out that the proposed X-transformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, the reviewer notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment provides some logical reasoning and references to existing works, it lacks specific examples or detailed comparisons to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed X-transformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper, which is important for demonstrating the novelty of the work. The comment provides clear and actionable feedback by highlighting areas where the authors need to improve their work, such as including comparisons to STN and providing more detailed explanations of the novelty of their approach. This feedback is valuable for the authors to enhance the originality and impact of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit corrections to specific lines in the paper, indicating that the authors should mention \"|Y_t - Y_{t-1}| \\leq c_t almost surely\" at line 384 and correct \"\\\\mu_t\" to \"\\\\tilde \\\\mu_t\" at line 431. These corrections are direct and concrete, as they specify exactly what needs to be changed in the text. The authors know exactly what actions to take to address these issues, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines, \"L384\" and \"L431,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely, the mention of \"|Y_t - Y_{t-1}|\" and the correction of \"\\\\mu_t\" to \"\\\\tilde \\\\mu_t.\" This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of corrections to specific lines in the paper, which are factual statements. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out errors in the text, specifically mentioning that \"|Y_t - Y_{t-1}|\" should be corrected to \"|Y_t - Y_{t-1}| \\leq c_t almost surely\" at line 384 and that \"\\\\mu_t\" should be corrected to \"\\\\tilde \\\\mu_t\" at line 431. This feedback is clear and direct, allowing the authors to make precise corrections to their draft. By addressing these errors, the authors can improve the accuracy and clarity of their paper. Therefore, the comment is highly helpful, as it provides clear guidance for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a confusion regarding the reward in Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. It provides references to external works that might help clarify the issue, such as [1] and [2], which are articles on the topic of reinforcement learning. However, the comment does not explicitly instruct the authors to include these references or provide specific guidance on how to clarify the reward or network model. While the action is implied, it is not as direct as it could be, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of confusion regarding the reward and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. The references provided, such as [1] and [2], could be helpful in clarifying the issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of Eq. 12, specifically questioning where the reward comes from and whether one of the r_i is taken from Eq. 11. The reviewer suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment identifies a potential issue with the clarity of the equations, it lacks specific examples or detailed reasoning to fully substantiate the claim. The references provided could be helpful in understanding the context, but the comment itself does not provide enough evidence or detailed reasoning to fully verify the claim. Therefore, the comment is somewhat verifiable, as it highlights an area for improvement but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Eq. 12, noting that the reward source is not clearly explained and questioning whether one of the r_i is taken from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment highlights a potential area for improvement, it does not provide detailed guidance on how to address the issue or suggest specific ways to clarify the equations. The references provided could be helpful, but the comment itself lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It explicitly instructs them to correct the labeling of \"Fig.7\" to \"Fig.12\" in Supp. Page 31 and to attach each theorem and corollary to its corresponding proof link. Additionally, it highlights the primary concerns of motivation, methodology soundness, and experiment persuasion, which the authors should address to improve the paper. The comment is clear and provides concrete steps for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of incorrect labeling of \"Fig.7\" as \"Fig.12\" and suggests attaching each theorem and corollary to its corresponding proof link. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the labeling of \"Fig.7\" as \"Fig.12\" in Supp. Page 31 and suggests attaching each theorem and corollary to its corresponding proof link. The reviewer provides a logical reasoning by explaining that this would make it easier for readers to follow the paper. However, the comment lacks specific examples or references to support the claim about the importance of attaching theorems and corollaries to their proofs. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions to improve the clarity and accessibility of the paper. It points out a specific error in the labeling of \"Fig.7\" as \"Fig.12\" in Supp. Page 31 and suggests attaching each theorem and corollary to its corresponding proof link. This feedback is clear and direct, offering a concrete way for the authors to enhance the readability and comprehensibility of their work. Additionally, the comment acknowledges the paper\\'s strengths, such as its novelty, clear theoretical guarantees, and convincing empirical results. However, it also highlights areas for improvement, such as addressing concerns about motivation, methodology soundness, and experiment persuasion. Overall, the comment is mostly helpful as it provides actionable guidance and constructive feedback, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the definition and implementation of certain concepts in the paper. It specifically asks about the determiner missing in Section 3, the action verbs used, and the \"action frames\" mentioned later in the paper. While the questions are clear and specific, they do not provide explicit guidance on how the authors should address these issues. The authors can infer that they need to clarify the missing determiner, explain the action verbs, and provide more information on \"action frames,\" but the comment lacks concrete details on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3\" and \"306ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by asking about the determiner missing in Section 3, the action verbs used, and the \"action frames\" mentioned later in the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the definition and implementation of certain concepts in the paper, such as the missing determiner in Section 3 and the action verbs used. It also asks about the \"action frames\" mentioned later in the paper and how they are chosen. While the questions are clear and provide a direction for improvement, the comment lacks specific guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need clarification, but it could be more beneficial if it offered actionable steps or examples to improve the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a minor issue with the spelling of \"Empiically\" on line 32 of page 1, suggesting it should be corrected to \"Empirically.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, as it specifies the exact change needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the spelling of \"Empiically\" on line 32, suggesting it should be corrected to \"Empirically.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the spelling of a word in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor issue with the spelling of \"Empiically\" on line 32 of page 1, suggesting it should be corrected to \"Empirically.\" This is a clear and actionable suggestion that can help improve the accuracy and consistency of the paper. However, the comment does not provide any context or explanation as to why this correction is necessary or how it might impact the overall quality of the paper. While it is a helpful suggestion, it could be more beneficial if it included additional guidance or reasoning. Therefore, the comment is rated as somewhat helpful, as it provides a specific correction but lacks depth and context.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. It also points out that the framework seems not to be limited to raw-level selection, as evidenced by the discussion in Section 4. The comment provides a clear direction for improvement by recommending the inclusion of representation learning in the feature selection process. This feedback is explicit and concrete, as it specifies exactly what needs to be done to enhance the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167-174, Sec. 4,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue with the proposed invariant learning module, suggesting that it could be improved by considering representation learning. Additionally, it provides a specific suggestion for improvement by recommending the inclusion of representation learning in the feature selection process. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. The reviewer provides a logical reasoning by pointing out that the framework seems not to be limited to raw-level selection, as evidenced by the discussion in Section 4. However, the comment lacks specific examples or references to the appendix or Section 4 to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable, as it requires further elaboration to fully support the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the proposed invariant learning module by suggesting that it could be enhanced by considering representation learning. It points out that the framework seems not to be limited to raw-level selection, as evidenced by the discussion in Section 4, and suggests that the feature selection process could be further improved by incorporating representation learning. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their work. However, the comment could be more helpful if it offered additional guidance on how to integrate representation learning into the invariant learning module or provided examples of how this could be done. Overall, the comment is mostly helpful as it effectively identifies a potential area for improvement and offers a concrete suggestion for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some details are missing, specifically mentioning the design of rewards as an example. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific steps to clarify the reward design or suggesting ways to improve the explanation. As a result, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the design of rewards, which is a clear and specific point. However, it does not explicitly mention which part of the paper discusses the rewards, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of understanding of how the rewards are designed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some details are missing,\" specifically mentioning the design of rewards as an example. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, specifically the design of rewards. It points out that the authors need to provide more details on how to design these rewards, which is a crucial aspect of the paper. However, the comment does not offer any suggestions or guidance on how to improve the explanation or design of the rewards. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the generalizability of a model to different numbers of entities, referencing Figure 3 of INs as an example. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider generalizing their model to different entity counts, but it lacks concrete steps or detailed advice on how to achieve this. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a concern about the generalizability of a model to different numbers of entities, referencing Figure 3 of INs as an example. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the model's generalizability, as it highlights the issue of fixed entity numbers and references a specific figure. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of entities is fixed and that it is unclear how to generalize a model to different numbers of entities, referencing Figure 3 of INs as an example. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the generalizability of the model to different numbers of entities, specifically mentioning Figure 3 of INs as an example. This is a relevant point that could impact the applicability and robustness of the model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the generalizability of their model. While it points out a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the incremental improvement to the K-NN based MT approach and the large engineering and execution effort required. It also mentions that the experimental design is good. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest improvements, offer guidance on how to address the weakness, or provide specific feedback on the execution effort or experimental design. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"double edge point,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the incremental improvement to the K-NN based MT approach and the large engineering and execution effort required, backed by good experimental design. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the incremental improvement to the K-NN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. However, it also points out that the novelty is limited, and the execution effort surpasses the novelty. The reviewer mentions that this weakness is a little nitpicking, but it becomes more significant if there is no code release after the revision process. The comment is somewhat verifiable as it provides a logical reasoning for the weakness but lacks specific examples or references to substantiate the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the incremental improvement to the K-NN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. It also points out that the novelty is limited, and the execution effort surpasses the novelty. However, the comment suggests that this weakness is a little nitpicking, especially considering that execution (replicability) beats idea (novelty). The reviewer highlights that this weakness becomes more significant if there is no code release after the revision process. While the comment identifies a potential weakness, it lacks specific suggestions or guidance on how the authors might address this issue or improve the novelty of their approach. Therefore, the comment is somewhat helpful, as it provides insight into a potential weakness but does not offer actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and highlights the importance of runtime as a limitation for ML-based emulators of climate model parametrizations. The comment is concrete, as it specifies the need for runtime discussion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Prithvi WxC\" emulator, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the runtime of Prithvi WxC and its potential limitations for applications. This provides clear guidance on what aspect of the emulator needs attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count, as it is a limitation for ML-based emulators of climate model parametrizations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why runtime is a critical issue or how it affects the applicability of the emulator. Without additional context or examples, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the runtime of Prithvi WxC should be discussed, given its large parameter count. This is a clear and actionable suggestion that could help the authors address a potential limitation of their emulator in the context of ML-based climate model parametrizations. By discussing the runtime, the authors can provide valuable insights into the practicality and applicability of their emulator, which could enhance the overall quality and usefulness of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have discussed runtime limitations in similar contexts. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the idea is not enough and that the new metric and method are straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or make the method less straightforward. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the idea is not enough and that the new metric and method are straightforward. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which parts need attention or improvement. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the idea is not enough and that the new metric and method are straightforward. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the novelty of the idea is not enough and that the new metric and method are straightforward. However, it does not provide specific examples or detailed reasoning to support this claim. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of what aspects of their work need to be addressed or enhanced. The comment lacks depth and does not offer constructive guidance, making it not helpful at all. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine where to address this issue. Additionally, the comment lacks specificity regarding what aspects of the framing are problematic or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or guidance on how the framing could be improved to better convey the actual contribution of the work. Without actionable suggestions or detailed feedback, the authors are left without a clear understanding of what changes to make to enhance the clarity of their paper. Therefore, the comment is not helpful as it lacks specificity and actionable advice, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. While the comment provides a clear direction for improvement, it does not specify which steps should be taken or how to implement the changes. The authors are given a general idea of what needs to be improved but are left to determine the exact details of execution. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks concrete guidance on how to implement the suggested improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the model description is discussed. The authors can infer that it relates to the model description or methodology sections, but this inference is not direct. The comment is specific in suggesting improvements, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the understanding of the model. The suggestion is based on general logic but lacks the necessary evidence or examples to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides a logical basis but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be presented in separate steps for better understanding. It also recommends reducing the number of symbols and using a notation table, which could enhance the clarity of the description. While the comment provides actionable suggestions, it lacks depth and does not explain why these changes would be beneficial or how they would impact the overall understanding of the model. The authors are given a clear direction for improvement but could benefit from more detailed guidance on how to implement these changes effectively. Therefore, the comment is somewhat helpful, as it provides a starting point for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the quality of paraphrases generated for training data, specifically noting that the paraphrases need to be sufficiently different from the original sentences. It suggests that this impacts the subsequent steps in the process, as the model relies heavily on the quality of these paraphrases. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve the quality of the paraphrases. While the action is implied, it is not detailed enough for the authors to know exactly how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the process of generating paraphrases for training data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear paraphrases and how this impacts the subsequent steps in the process. The comment provides a clear rationale for the concern, explaining the importance of the quality of these paraphrases and how it affects the final training data. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paraphrases generated for training data are unclear and impact the subsequent steps in the process. The reviewer provides a logical reasoning by explaining that if the paraphrases are not sufficiently different from the original sentences, the quality of the final training data will be low, leading to a low number of pairs added to the new training data. This reasoning is based on a clear understanding of the process and the importance of paraphrase quality. However, the comment could be strengthened by providing specific examples or references to similar studies that have faced similar issues. Despite this, the claim is mostly verifiable, as it provides a clear rationale for the concern.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with the quality of paraphrases generated for training data, noting that the paraphrases need to be sufficiently different from the original sentences. This is crucial because the model relies heavily on the quality of these paraphrases, and if they are not sufficiently different, the final training data will be of low quality, leading to a low number of pairs added to the new training data. The comment provides a clear and actionable suggestion for improvement, highlighting the importance of ensuring that the paraphrases are sufficiently different from the original sentences. However, it could be more helpful if it offered specific guidance on how to achieve this goal or provided examples of what constitutes a sufficiently different paraphrase. Overall, the comment is mostly helpful as it identifies a significant issue and provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggests that another color or a larger font might help in highlighting the human-identified rationales better. While the comment provides a clear and concrete suggestion for improving the figure, it does not explicitly instruct the authors on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider changing the font or color to enhance readability. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the human-identified rationales better. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that identifying rationales for more complicated NLP tasks like machine translation is not a simple problem, and that the paper is well-organized and easy to follow. The comment suggests that Figure 2 is cluttered and that the \"bold\" text is hard to see, proposing a solution of using another color or a larger font to enhance readability. While the comment provides a logical reasoning for the issue with Figure 2, it lacks specific examples or references to support the claim about the complexity of identifying rationales for NLP tasks. The suggestion to improve the figure is somewhat verifiable, as it provides a clear rationale but could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the human-identified rationales better. This feedback is clear and actionable, as it provides a concrete suggestion for improving the figure\\'s readability. However, the comment could be more helpful if it explained why the current font or color is problematic or offered additional suggestions for alternative colors or font sizes. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, which can enhance the clarity and accessibility of their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should verify the effectiveness and universality of the Flipped-QA framework beyond LLM-based models, specifically mentioning HiTeA and InternVideo as examples. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment somewhat actionable. The authors can infer that they need to conduct additional experiments to verify the framework\\'s effectiveness and universality, but the comment lacks concrete details on how to implement this action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Flipped-QA framework, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to verify the effectiveness and universality of the framework beyond LLM-based models. The comment provides a clear direction for the authors to expand their experimental evaluation to include non-LLM-based models like HiTeA and InternVideo. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Flipped-QA framework is a general framework for various generative VideoQA models but is only applied to LLM-based models. The reviewer suggests that verifying its effectiveness and universality to non-LLM-based models like HiTeA and InternVideo would be beneficial. While the comment provides a logical reasoning for the need to expand the application of the framework, it lacks specific examples or references to support the claim that other models are not effectively utilizing the framework. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper, specifically the narrow application of the Flipped-QA framework to LLM-based models. It suggests that verifying the effectiveness and universality of the framework to non-LLM-based models like HiTeA and InternVideo would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental evaluation and demonstrate the generalizability of their framework. By addressing this suggestion, the authors can enhance the robustness and applicability of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not provide any specific guidance or suggestions on how to improve the writing. The authors are left without any concrete steps or examples to follow in order to enhance their draft. As a result, the comment lacks actionability, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not specify which parts of the paper are particularly challenging to understand or where the writing could be improved. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the writing could be improved, indicating that it was difficult to understand the main idea and theoretical analysis of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to identify the exact areas that need improvement. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the writing could be improved, indicating that it was difficult to understand the main idea and theoretical analysis of the paper. However, it does not provide specific examples or guidance on how to improve the writing, such as suggesting clearer explanations or more accessible language. Without actionable feedback or detailed suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential issue but lacks depth and specificity in its guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address these concerns to improve the paper. However, it does not provide specific guidance on how to address these concerns or what aspects of the method should be improved. The mention of existing methods and references to Clopper-Pearson intervals and Gaussian elimination suggest that the authors should provide more detailed explanations or comparisons to these methods. However, the comment lacks concrete steps or suggestions on how to enhance the theoretical novelty or address the concerns. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the methodology and its theoretical novelty, specifically mentioning the combination of existing methods like Clopper-Pearson intervals and Gaussian elimination. However, it does not specify which part of the paper this critique is based on, such as the methodology or theoretical sections. The authors can infer that it relates to the methodology or theoretical aspects, but this inference is not as direct as it could be. The comment is specific in detailing the concerns about the lack of theoretical novelty, but it lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer provides references to Clopper-Pearson intervals and Gaussian elimination, suggesting that the method is not original. However, the comment does not provide detailed reasoning or examples to support why these existing methods are insufficient or how the proposed method could be improved. The references are provided as a basis for the claim, but the lack of detailed justification or explanation makes the claim somewhat verifiable. The authors would need to further explore and address the concerns raised by the reviewer to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern about the novelty of the proposed method, noting that it primarily builds upon existing methods like Clopper-Pearson intervals and Gaussian elimination. This is a critical observation that could impact the paper\\'s impact and originality. However, the comment lacks specific guidance on how the authors might address this concern or what aspects of the method could be improved to demonstrate greater originality. While it points out a potential weakness, it does not provide actionable advice or suggestions for improvement, making it somewhat helpful. The authors are left with a general understanding of the issue but without clear steps to resolve it, which limits its utility. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific actions they should take to improve their draft. The comment lacks explicit or implicit actions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the concatenation of text elements, but without explicit references to sections or figures, the authors cannot confidently determine where this question fits into the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about whether the text input can be concatenated by the four text elements of an object. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the concatenation of text elements, specifically asking whether the four text elements of an object can be concatenated. While this question may prompt the authors to consider the feasibility or limitations of their approach, it does not provide any guidance or suggestions on how to address this issue or improve the draft. The comment lacks actionable feedback or context, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide a stronger motivation for why the topic is important. However, it does not specify what kind of motivation is needed or how the authors should present it. The comment lacks explicit guidance on how to address this issue, leaving the authors uncertain about what specific actions to take. As a result, the action is implicit and vague, making it difficult for the authors to know how to implement the suggested improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not specify which part of the paper this issue pertains to, such as the introduction, literature review, or results section. Without explicit references to sections or specific elements, the authors cannot confidently determine where to focus their revisions. Additionally, the comment lacks specificity regarding what kind of motivation is needed or how it should be presented. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to achieve this motivation or what kind of motivation would be effective. Without actionable advice or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it points out an area for improvement but does not offer sufficient guidance for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the abstract sentence in lines 12-17 is cumbersome and could be made clearer. However, it does not provide any guidance on how to achieve this clarity or what specific changes should be made to the sentence. The action is implicit and vague, as the authors are left to infer that they need to revise the sentence but without detailed instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract sentence in lines 12-17, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the sentence is cumbersome and could be made clearer. This provides clear guidance on what the authors need to improve. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract sentence in lines 12-17 is cumbersome and could be made clearer. However, the comment does not provide any specific reasoning or examples to support this claim. It lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract sentence in lines 12-17, noting that it is cumbersome and could be made clearer. While the comment highlights a potential problem, it does not provide detailed guidance or suggestions on how to improve the clarity of the sentence. The authors are left to infer that they need to revise the sentence, but without specific instructions or examples, the feedback lacks depth and actionability. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the comparisons made between the domain-specific model and zero-shot single-image 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative comparisons that might be more fair. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their comparisons, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the domain-specific model being trained on Pix3D and the experiments being conducted on Pix3D, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the comparisons to zero-shot single-image 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparisons between the domain-specific model and zero-shot single-image 3D reconstruction models are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparisons made between the domain-specific model and zero-shot single-image 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This feedback highlights a potential bias in the experimental setup that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or suggest alternative comparisons that might be more fair. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the claim that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance. It also points out that Table 5 shows a trade-off between head and tail categories but notes that similar trade-offs have not been fully investigated for the baselines. The reviewer suggests that the authors should explore this further and potentially improve the baselines by changing hyperparameters. Additionally, the reviewer encourages the authors to continue this line of work for future submissions. While the comment provides explicit actions to take, such as investigating the trade-offs and improving the baselines, it lacks specific guidance on how to implement these changes. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Decouple [Kang et al.],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the comparison to Decouple [Kang et al.] and suggests exploring the trade-off between head and tail categories for the baselines. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance, and it provides a specific example of this by referencing Table 5. Additionally, it suggests that similar trade-offs have not been fully investigated for the baselines, specifically mentioning the potential for Decouple [Kang et al.] to improve tail accuracy while decreasing head accuracy. This claim is supported by logical reasoning and specific examples, making it mostly verifiable. However, the comment could be strengthened by providing more detailed evidence or references to support the claim about the trade-offs for the baselines. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights a trade-off between head and tail categories that has not been fully explored for the baselines, specifically suggesting that changing hyperparameters in Decouple [Kang et al.] could significantly improve tail accuracy while slightly decreasing head accuracy. This feedback is valuable as it points out a critical weakness in the paper and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to investigate these trade-offs or how to improve the baselines. Overall, the comment is mostly helpful as it identifies a significant area for improvement and encourages the authors to continue this line of work for future submissions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. While the suggestion is clear, it lacks specific guidance on how to conduct these experiments or what specific aspects of the C2D method should be tested on these datasets. The authors are left to infer that they should conduct additional experiments, but without detailed instructions on how to do so, the action remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting the need for additional experiments but lacks grounding as it does not explicitly mention which part of the paper should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the method. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This is a clear and actionable suggestion that could enhance the robustness and generalizability of the method. However, the comment lacks specific guidance on which aspects of the C2D method should be tested or how these experiments should be designed. While it points to a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but requires further elaboration to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the specific choice of $\\\\lambda_t$ in the proposed E2W algorithm and the implications of not including the exploration parameter $\\\\epsilon$. It also questions the use of $\\\\sum_a N(s, a)$ for $\\\\lambda_s$ in Equation (7), but not $N(s, a)$. These questions imply that the authors should provide a rationale or explanation for these choices, but they do not offer explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they need to provide a detailed explanation or rationale for their choices. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed E2W algorithm\" and \"Equation (7),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the intuition behind the specific choice of $\\\\lambda_t$ and the use of $\\\\sum_a N(s, a)$ for $\\\\lambda_s$ in Equation (7). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the specific choice of $\\\\lambda_t$ in the proposed E2W algorithm and the implications of not including the exploration parameter $\\\\epsilon$. It also questions the use of $\\\\sum_a N(s, a)$ for $\\\\lambda_s$ in Equation (7), but not $N(s, a)$. These questions are based on logical reasoning and do not require external references or evidence to support the claim. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment raises important questions about the specific choice of parameters in the proposed E2W algorithm, particularly the use of $\\\\lambda_t$ and the implications of not including the exploration parameter $\\\\epsilon$. It also questions the use of $\\\\sum_a N(s, a)$ for $\\\\lambda_s$ in Equation (7), but not $N(s, a)$. These questions prompt the authors to provide a deeper understanding of the rationale behind these choices and their implications. While the comment identifies areas for improvement, it could be more helpful if it offered suggestions on how to address these questions or provide examples of alternative approaches. Overall, the comment is somewhat helpful as it highlights important areas for clarification and improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the evaluation, specifically the reliance on only four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for more datasets, but it is somewhat vague in terms of how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" and \"4 OCR QA datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, which is the limited use of only four OCR QA datasets and the need for more scenarios like the LLaVA benchmark in ablation studies. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is limited and relies on only four OCR QA datasets, which may be unreliable. The reviewer supports this claim by referencing the authors\\' admission in Fig 4(5) and suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. This reference provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or detailed reasoning on why the LLaVA benchmark is important or how it would enhance the evaluation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation section, specifically the reliance on only four OCR QA datasets. It suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. This feedback is clear and actionable, as it provides a specific suggestion for expanding the evaluation to include additional datasets. By doing so, the authors can enhance the robustness and comprehensiveness of their evaluation. However, the comment could be more helpful if it explained why the LLaVA benchmark is particularly important or how it would impact the evaluation. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify that pi is a function from R^m to \\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\u03b4\\"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models' learning and whether simpler tasks would suffice. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the clarity of their visual reasoning tasks. The feedback lacks specific actions or concrete steps for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models' learning and whether simpler tasks would suffice. However, the comment does not specify which part of the paper these tasks are discussed in, making it weakly grounded. The comment is specific in its critique of the tasks and the need for proof that more complex tasks are necessary. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models' learning and whether simpler tasks would suffice. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or examples, the authors may find it challenging to address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the interpretation of the models' learning and whether simpler tasks would suffice. The comment also asks for proof that more complex tasks are necessary. While the feedback identifies potential issues with the paper\\'s approach, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the clarity of their visual reasoning tasks. The comment provides some insight into potential weaknesses but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of weak supervision could be improved by addressing the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors' generation, suggesting that the authors' embeddings are initialized by averaging artificial tweets. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should improve the realism of the evaluation and generation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"weak supervision\" and the \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the generation process, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the realism of the evaluated tweets and the generation process, suggesting that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. The reviewer also points out that the authors' embeddings are initialized by averaging artificial tweets, which further undermines the realism. These claims are based on logical reasoning and observations about the nature of the prompt and the generation process. However, the comment lacks specific examples or references to support the claim that the evaluation is unrealistic. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation process. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors' generation, suggesting that the authors' embeddings are initialized by averaging artificial tweets. This feedback is valuable as it highlights areas where the authors could improve the realism and credibility of their evaluation. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of how to make the evaluation more realistic. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of essential visualization of intermediate processes and comparisons, which is a clear actionable point. However, it does not provide specific guidance on what visualizations or comparisons are missing or how they should be presented. The authors are left to infer that they need to include visualizations and comparisons, but without concrete details on what is expected, the comment remains somewhat vague. Therefore, the comment is somewhat actionable, as it points out an area for improvement but lacks specific guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of essential visualization of intermediate processes and comparisons, which is a specific issue related to the presentation of the paper. However, it does not specify which parts of the paper should include these visualizations or comparisons, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the need for visualization and comparison, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, namely the lack of essential visualization of intermediate processes and comparisons. This is a clear and actionable point that the authors can address to enhance the clarity and comprehensiveness of their work. However, the comment does not provide specific guidance on what types of visualizations or comparisons are missing or how they could be incorporated into the paper. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical area for enhancement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. However, it does not provide any guidance on how the authors should address this issue or what specific changes need to be made to ensure compliance with the stated condition. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Definition 1\" and \"expected counterfactual,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This is a clear and actionable point that the authors can address to improve the accuracy and validity of their work. However, the comment lacks depth and does not provide suggestions on how to resolve the issue or what specific changes need to be made. While it highlights a critical area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the importance of the result and references external work that suggests that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimension-free, which could affect the significance of the result. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address these concerns or what specific changes should be made to improve the paper. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the iteration complexity in Theorem 3 is no longer dimension-free, which is a clear concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimension-free, which could affect the significance of the result. However, the comment lacks specific examples or detailed reasoning to support the claim that the result is not surprising or significant. While it references external work, the lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to further explore the implications themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimension-free, which could affect the significance of the result. While the comment identifies potential weaknesses in the paper, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the paper. The feedback is somewhat helpful as it highlights areas for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action, providing the authors with a specific task to accomplish. The comment is specific in detailing where the results should be included, making it highly actionable. Authors know exactly what needs to be done to address the feedback.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included, namely \"keypoint detection results.\" This provides clear guidance on what the authors need to address in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is clear and actionable, as it directly instructs the authors to include keypoint detection results in the experiments section. This feedback is specific and provides a concrete step for the authors to improve their draft, ensuring that the results are presented in a more comprehensive manner. However, the comment could be more helpful if it explained why keypoint detection results are important or how they might enhance the understanding of the experiments. Despite this, the feedback is mostly helpful as it guides the authors on how to improve the presentation of their results.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This explicit action provides a clear direction for the authors to take, as it specifies a specific comparison to be made. The comment is concrete, as it directly instructs the authors on what to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison with existing models, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific comparison that could enhance the paper by comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is actionable and provides a clear direction for the authors to improve their draft by including a comparison that could strengthen the paper\\'s contribution. However, the comment could be more helpful if it explained why this comparison is important or how it would benefit the paper. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. It also mentions minor problems, but does not provide further details or suggestions for improvement. The comment implies that the authors should clarify this aspect of their methodology, but it lacks explicit guidance on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the grid search process but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"grid search of learning rate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking whether the grid search is performed on the validation set, providing clear guidance on what needs to be clarified. However, the comment does not provide specific suggestions or examples on how to improve the clarity or methodology. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point consists of a question asking about the grid search for learning rate, specifically whether it is performed on the validation set. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. This is a relevant point that could impact the robustness and generalizability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for clarification, it does not offer actionable advice or detailed feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or that the term \"discourse\" is being used inappropriately. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify or adjust their terminology. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" However, the comment lacks any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" This is a relevant point that could impact the interpretation and analysis of the data. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their terminology. While it points out a potential problem, it does not offer actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they need to consider diversity but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. However, it does not provide any supporting evidence, reasoning, or references to justify why this diversity is important or how it might impact the results. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. This is a relevant and insightful point that could prompt the authors to consider the broader implications of their findings and ensure that their work is inclusive and applicable to diverse populations. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional analyses or discussions. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality. It suggests that there is still room for improvement in the result quality. However, it does not provide specific guidance on how to achieve this improvement or what aspects of the output need to be addressed. The comment lacks concrete actions or suggestions for the authors to take, leaving them without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the output quality of the paper, comparing it to recent GAN works and suggesting that there is still room for improvement. However, it does not specify which part of the paper discusses the output quality, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the output quality but lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality. The reviewer suggests that there is still room for improvement in result quality. However, the comment lacks specific examples or references to recent GAN works that have achieved higher quality, making it somewhat verifiable. The authors would need to infer the specific examples or references themselves to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality. It suggests that there is still room for improvement in the result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment does not provide specific suggestions or guidance on how the authors might improve the output quality or what aspects of the paper need attention. While it identifies a potential area for improvement, the feedback lacks actionable details, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their work. It lacks concrete details on what specific changes or improvements are needed, leaving the authors uncertain about how to proceed. Therefore, the comment is somewhat actionable, as it identifies areas of concern but does not offer detailed instructions on how to address them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"soft labels is essentially on top of CRM and Cross entropy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the use of subpar hyperparameters and the results being impressive but potentially misleading due to the use of subpar hyperparameters. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the concerns or how to address them. The lack of detailed justification or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is somewhat helpful as it points out areas of potential concern, but it could be more beneficial if it provided actionable advice or examples of how to improve the analysis. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the simple/traditional experiment for unseen characters is a good idea but is presented as an afterthought. It implies that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for non-Chinese speakers. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific translations to include. The action is concrete but somewhat vague in terms of execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more evaluation on classifying unseen words and the addition of translations to Figure 6 for non-Chinese speakers. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the simple/traditional experiment for unseen characters is presented as an afterthought and that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for non-Chinese speakers. While the comment identifies a potential issue with the presentation of the experiment, it lacks specific examples or references to support the claim that the current presentation is inadequate. The suggestion to include translations is somewhat vague, as it does not specify which translations should be included or how they would enhance the figure. Therefore, the claim is somewhat verifiable, as it provides a logical basis but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the presentation of the simple/traditional experiment for unseen characters, noting that it is presented as an afterthought. It suggests that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also provides a specific suggestion to add translations to Figure 6 for non-Chinese speakers. This feedback is clear and actionable, as it directs the authors to consider expanding their evaluation to include unseen words and to enhance the accessibility of their figures for a broader audience. However, the comment could be more helpful if it provided additional guidance on how to conduct the evaluation or suggested specific approaches for incorporating translations. Overall, the comment is mostly helpful as it offers valuable insights and suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of images provided in the VioT dataset is small, which may impact the validity of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should increase the number of images, provide additional data, or justify the current number of images. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the VioT dataset, specifically mentioning the number of images provided in each of the four categories. This provides full grounding as it allows the authors to accurately identify the part of the paper being discussed. However, the comment lacks specificity as it does not detail what aspect of the dataset or the approach is problematic. It suggests that the number of images is small, but without further explanation or suggestions, the authors may struggle to understand how to address this issue. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the number of images in the VioT dataset is small, which may impact the validity of the approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of images is insufficient. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the VioT dataset, noting that the number of images provided is small. This observation highlights a potential limitation in the study, which could impact the validity of the approach. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue, such as suggesting ways to increase the number of images or explaining why the current number is insufficient. Without detailed feedback or suggestions, the authors are left without a clear path forward, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting an ablation study of the number of layers versus performance, which could be interesting. However, it does not provide explicit instructions or concrete guidance on how to implement this suggestion. The authors are left to infer that they should consider conducting such a study, but without specific details on how to structure it or what aspects to focus on, the action remains vague. Therefore, the comment is somewhat actionable, as it implies an action but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study of the number of layers versus performance, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment where this analysis could be conducted. Without explicit references to sections or experiments, the authors cannot confidently determine the exact part of the paper that needs revision. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests conducting an ablation study of the number of layers versus performance, which is a suggestion for improvement. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this study would be beneficial or how it would contribute to the paper. Without such information, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting an ablation study of the number of layers versus performance, which could be an interesting addition to the paper. However, it lacks specificity and does not provide detailed guidance on how to conduct this study or what aspects to focus on. The authors are left with a general suggestion but without actionable steps to follow. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not fully support the authors in making that improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed, and provides examples of what could be improved, such as explaining the colors in Fig. 2. Additionally, the reviewer mentions that Fig. 1 and 2 did not contribute much to their understanding, and that they had to read the text multiple times. While the comment provides some guidance on what needs to be improved, it lacks concrete details on how to implement these changes. The authors are given a general idea of what needs to be addressed, but the specific steps for improvement are not fully articulated. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig. 1 and 2\" and \"figure captions,\" allowing the authors to accurately identify the areas being addressed. It also specifies the issues with the paper, such as the difficulty in following the mathematical derivations and the lack of explanations in the figure captions. The comment provides clear guidance on what needs to be addressed, such as the need for more intuitive explanations and additional legends. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also mentions that figure captions are lacking and require additional explanations and legends. The reviewer provides specific examples, such as the need to explain the colors in Fig. 2, which adds some level of verifiability to the claim. However, the comment lacks detailed reasoning or references to support the claim that the paper is hard to follow or the need for more intuitive explanations. While the examples provide some evidence, the overall claim could be strengthened with more detailed justification or references to similar works. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It provides examples of what could be improved, such as the need for more intuitive explanations and additional legends. The comment also highlights that Fig. 1 and 2 did not contribute much to the understanding, and that the authors had to read the text multiple times. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and accessibility of their paper. However, it could be more helpful if it offered suggestions on how to improve the mathematical derivations or provided examples of how to make the figures more intuitive. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the sensitivity of empirical results to hyperparameter choices, emphasizing the potential impact on the method's effectiveness. It explicitly states that resolving this issue is crucial and suggests that the authors should consider this point. However, the comment does not provide specific guidance on how to address this issue, such as recommending particular analyses or experiments to validate the hyperparameters. While the action is implied, it lacks concrete details on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"hyperparameter choices\" and the \"empirical results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of sensitivity to hyperparameter choices and the potential impact on the method\\'s effectiveness. The comment highlights the importance of resolving this issue and suggests that it could affect the overall rating of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, suggesting that wrong choices could undermine the method\\'s effectiveness. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to substantiate the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, as the comment does not provide enough guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the sensitivity of empirical results to hyperparameter choices. It highlights the potential impact of incorrect choices on the effectiveness of the method, which is a crucial consideration for the authors. The comment explicitly states that resolving this issue is crucial and suggests that it could affect the overall rating of the paper. While it does not provide specific suggestions on how to address this issue, it points out a significant area for improvement that could significantly impact the paper\\'s outcome. Therefore, the comment is mostly helpful, as it directs the authors\\' attention to a critical area that requires further exploration and resolution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. While the comment implies that the authors should provide a more detailed explanation of their method's novelty, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the novelty and contribution, as it highlights the need for a more detailed explanation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work is similar to existing attack methods on a surrogate model, suggesting that the novelty and contribution of the proposed method are not adequately addressed. However, the comment does not provide specific examples or references to existing methods, making it difficult for the authors to understand the exact nature of the similarity. Without detailed comparisons or references, the claim lacks verifiability, as it relies on a general observation without specific evidence or reasoning. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it is similar to existing attack methods on a surrogate model. It suggests that the authors need to further claim the novelty and contribution of their method to differentiate it from existing work. While the comment highlights an important area for improvement, it lacks specific guidance on how the authors might effectively demonstrate the novelty and contribution of their method. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed suggestions for improvement, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the text in Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. Additionally, it provides references for the missing gradient symbol and suggests that the authors should include them. These points are explicit and provide concrete actions for the authors to take, such as increasing the font size of the text in Table 1 and adding the missing gradient symbol in Algorithm 1. The references also offer guidance on where to find the necessary information. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the text size in Table 1 and the missing gradient symbol in Algorithm 1. Additionally, it provides references for the missing gradient symbol, which is helpful for the authors to understand and address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and observations about the paper, such as the font size of Table 1 and the missing gradient symbol in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the font size of Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. It also provides references for the missing gradient symbol, which is helpful for the authors to address the issue. However, the comment could be more helpful if it offered suggestions on how to improve the font size or provided guidance on how to include the missing symbol. Overall, the comment is somewhat helpful as it points out specific areas for improvement but lacks detailed guidance or suggestions for resolution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use the bracketed arguments in \\citep to render Wright et al. (1934; Figure 1) more naturally. However, it does not provide explicit instructions on how to implement this suggestion or what specific changes are needed. The mention of hyperref suggests that the authors may need to consider how this change affects the rendering process, but this is not explicitly stated. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to apply the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should use the bracketed arguments in \\citep to render Wright et al. (1934; Figure 1) more naturally. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The mention of hyperref suggests that the authors should consider how this change affects the rendering process, but this is not enough to fully ground the comment. The comment is specific in suggesting a potential improvement but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should use the bracketed arguments in \\citep to render Wright et al. (1934; Figure 1) more naturally. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or how it would improve the rendering process. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific improvement to the rendering of a citation, specifically Wright et al. (1934; Figure 1), by using the bracketed arguments in \\citep. However, it does not provide any context or explanation for why this change might be beneficial or how it would affect the rendering process. The mention of hyperref suggests that the authors should consider the impact on the rendering, but this is not enough to guide the authors in making the suggested change. The comment identifies a potential improvement but lacks depth and actionable guidance, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their discussion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed discussion on computational aspects and address the practical limitations of their methods. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It specifically mentions the appendix and the algorithm's requirement to solve several LPs in high dimensions, which is not easily calculable. The comment also points out that the experiments are performed on small datasets. However, it does not explicitly mention which part of the paper discusses computational aspects or where the appendix is located, making it weakly grounded. The comment is specific in detailing the issues with the computational aspects and the experiments, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not discuss computational aspects in detail and questions the practical usefulness of their proposed methods for high dimensions. The reviewer supports this claim by pointing out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This provides a logical reasoning for the claim, but it could be strengthened by referencing specific calculations or examples to illustrate the practical limitations. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the discussion of computational aspects and the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This feedback is valuable as it highlights a critical area for improvement in the paper, particularly regarding the scalability and practicality of the proposed methods. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these issues or improve the discussion of computational aspects. Overall, the comment is mostly helpful as it directs the authors to a crucial area for enhancement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies specific errors in the equations and provides clear guidance on how to correct them. It specifies that the '+' sign after \\nu_j should be a '-' sign, and that there should be a '-' sign before \\sum_{j=1}^m in the definition of B under Line 503. Additionally, it suggests changing the '-' sign after \\nu_j to a '+' sign in Line 504. These are direct and concrete actions that the authors can take to improve their draft. The comment is highly actionable as it provides explicit instructions on how to correct the errors, making it easy for the authors to apply the changes.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues with the equations, such as the incorrect signs and the need for a '+' sign in one place and a '-' sign in another. This level of detail provides clear guidance on what needs to be corrected, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual claims about the equations in the paper, specifically suggesting corrections to the signs in the equations. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies specific errors in the equations, providing clear and actionable guidance on how to correct them. By pointing out the incorrect signs in the equations, the comment helps the authors ensure that their mathematical expressions are accurate and consistent. Additionally, it offers minor comments on the presentation of the equations, which further enhances the clarity and professionalism of the paper. Overall, the feedback is detailed and constructive, empowering the authors to make significant improvements to their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between the residual blocks. It suggests that if not, a deeper ResNet with parameter sharing could be a potential baseline for comparison. While the comment implies that the authors should consider this baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider this baseline. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the ResNet shares parameters between the residual blocks, and it suggests a potential baseline for comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about whether the ResNet in the experiments shares parameters between the residual blocks. It suggests that if not, a deeper ResNet with parameter sharing could be a potential baseline for comparison. However, the comment lacks any supporting evidence, reasoning, or references to justify why this comparison would be meaningful or beneficial. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the ResNet used in the experiments, asking whether it shares parameters between the residual blocks. This is a relevant point that could impact the validity and comparability of the results. The comment also suggests a potential baseline for comparison, which could be beneficial for the authors to consider. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to address the issue or implement the proposed baseline. While it identifies a potential area for improvement, it could be more helpful with additional context or actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a major issue with the motivation section, specifically regarding the cross-encoder architecture. It notes that the architecture is not ignoring cross-entity comparison but instead attends to all candidates at once, which may not be as fine-grained as expected. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the motivation section or what specific changes should be made to clarify the architecture. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the motivation section, particularly regarding the cross-encoder architecture. It points out that the architecture is not ignoring cross-entity comparison but instead attends to all candidates at once, which may not be as fine-grained as expected. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the motivation section, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation section is poorly motivated, specifically regarding the cross-encoder architecture. The reviewer argues that the architecture is not ignoring cross-entity comparison but instead attends to all candidates at once, which may not be as fine-grained as expected. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim is not fully verifiable, as it relies on a general understanding of the architecture without specific examples or references. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the motivation section of the paper, specifically regarding the cross-encoder architecture. It points out that the architecture is not ignoring cross-entity comparison but instead attends to all candidates at once, which may not be as fine-grained as expected. This feedback is valuable as it highlights a potential weakness in the paper\\'s rationale, which could impact the clarity and effectiveness of the proposed method. However, the comment could be more helpful if it provided suggestions on how to address this issue or improve the motivation section. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a critical area for improvement, but it lacks detailed guidance on how to address the issue.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or improve their design choice. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to justify the decision. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, the comment lacks specific reasoning or evidence to support why this choice is problematic or how it might impact the paper\\'s results or analysis. Without detailed justification or examples, the claim remains somewhat verifiable, as the authors may find it challenging to understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. This feedback highlights a potential issue with the methodology, prompting the authors to reconsider their approach. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the design choice. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work uses an outdated GNN model and method, which affects the performance of the framework. It also mentions that the baseline algorithms/methods are also outdated. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue, such as suggesting modern alternatives or updating the methods. Without actionable guidance, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of an outdated GNN model and method, which affects the performance of the framework. However, it does not specify which part of the paper discusses the GNN model or the baseline algorithms/methods, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the GNN model or baseline algorithms/methods are outdated or how they could be improved. Without clear guidance on what needs to be addressed, the authors may struggle to effectively address the critique. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work uses an outdated GNN model and method, which impacts the performance of the framework. However, the comment does not provide specific examples or references to support this claim, nor does it explain how the use of outdated methods affects the performance. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the work, noting that it uses an outdated GNN model and method, which impacts the performance of the framework. This is a critical observation that could significantly affect the paper\\'s credibility and relevance. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue, such as suggesting modern alternatives or updating the methods. Without detailed feedback or constructive advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as barely helpful, as it highlights a significant weakness but does not offer actionable guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how the proposed method produces the type of explanation mentioned in Figure 1. It suggests that additional ad-hoc post-analysis might be required to extract shared motifs to explain a set of instances. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it or what specific steps the authors should take to improve the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations or examples to clarify the process. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding how the proposed method produces the type of explanation mentioned in the figure. The comment suggests that additional ad-hoc post-analysis might be required to extract shared motifs, and it implies that this analysis might be easier with the proposed method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the explanation in Figure 1 is unclear and suggests that additional ad-hoc post-analysis might be required to extract shared motifs. The reviewer provides a quote from Line 48 to support this claim, which suggests that the analysis might be easier with the proposed method but still requires additional effort. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the quote provides some context, it does not fully address the issue of clarity or the necessity of additional analysis. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1, noting that the explanation provided is unclear and suggests that additional ad-hoc post-analysis might be required to extract shared motifs. It references Line 48 to provide context and implies that the proposed method might make this analysis easier but still requires additional effort. While the comment highlights a potential weakness in the explanation, it does not offer specific suggestions or guidance on how to address this issue or improve the clarity of the figure. The feedback is somewhat helpful as it points out a specific area for improvement, but it lacks actionable advice or detailed guidance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The comment provides two ways to strengthen the experiment: by either using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. While the comment provides some guidance on how to address the issue, it lacks specific instructions on how to implement these suggestions. The action is explicit but somewhat vague, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, which relies on pseudo feature importance due to the unavailability of true feature importance. The comment provides specific guidance on how to strengthen the experiment by suggesting two ways: using a different method to estimate true feature importance or providing a more detailed explanation of the perturbation value. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment relies on pseudo feature importance due to the unavailability of true feature importance. It suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The reviewer provides a logical reasoning by explaining the potential issue with the experiment's reliance on pseudo feature importance and suggests ways to strengthen it. However, the comment lacks specific examples or references to Proposition 3.2 or the perturbation value, which would enhance the verifiability. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests two ways to strengthen the experiment: by using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. This feedback is clear and actionable, as it offers specific suggestions for improving the experiment\\'s reliability and credibility. By addressing these points, the authors can enhance the robustness and trustworthiness of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that non-convexity may not be an issue for the SGD to converge if the function Z has certain properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific properties of Z should be considered or how to address the potential issue of non-convexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ln. 182--184,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it specifies the issue of non-convexity and suggests that it may not be a problem if the function Z has certain properties. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that non-convexity may not be an issue for the SGD to converge if the function Z has certain properties. However, the comment lacks any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific line in the paper (ln. 182--184) and suggests that non-convexity may not be an issue for the SGD to converge if the function Z has certain properties. While this feedback highlights a potential issue, it lacks depth and does not provide specific guidance or examples of what properties of Z would be beneficial for convergence. The comment could be more helpful if it offered suggestions on how to explore or test these properties or provided references to relevant literature. As it stands, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of model comparison, confusing sections, missing citations, and unreferenced notation. While it points out specific areas that need attention, it does not provide explicit instructions or concrete guidance on how to address these issues. The authors are left to infer that they need to compare models, clarify confusing sections, and correct missing citations and notation. The feedback is somewhat actionable as it highlights areas for improvement, but it lacks detailed guidance on how to implement these changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"several sections\" and \"Line 99, section 3.1,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the lack of model comparison, confusing sections, missing citations, and unreferenced notation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors did not compare any models other than GPT2, which is a factual observation. It also mentions that several sections are confusing and points out specific missing citations and unreferenced notation. However, the comment lacks detailed reasoning or examples to support why these issues are problematic or how they impact the paper\\'s overall quality. The absence of specific examples or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some evidence but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the lack of model comparison, confusing sections, missing citations, and unreferenced notation. It highlights specific areas that need attention, such as the need to compare models and clarify confusing sections. However, the comment does not provide detailed guidance or suggestions on how to address these issues, such as which models should be compared or how to clarify the confusing sections. While it points out areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides some direction but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). While it does not explicitly instruct the authors to make a change or provide additional information, it does prompt them to clarify a specific aspect of their work. The action is implicit, as the authors need to infer that they should provide an explanation or clarification, but it is concrete because it points to a specific part of the paper that requires attention. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (2),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the meaning of \"$:\\sigma_t^2=\\alpha_t-\\alpha_t^2$\" in Equation (2), which could be a significant oversight or misunderstanding in the paper. While it does not provide any suggestions or guidance on how to address this issue, it does prompt the authors to clarify a potentially important aspect of their work. However, without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as somewhat helpful, as it identifies a potential issue but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies specific lines in the SuppMat that should be moved from red to green. This provides clear and direct instructions for the authors to follow, ensuring they know exactly what changes to make. The action is concrete, as it specifies the exact lines and their corresponding SuppMat sections, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the SuppMat, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the exact lines that need to be moved from red to green, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements about the SuppMat, specifically mentioning lines that should be moved from red to green. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific lines in the SuppMat that should be moved from red to green, providing clear and actionable feedback. This guidance is valuable as it helps the authors ensure that their SuppMat is accurate and up-to-date. However, the comment could be more helpful if it explained why these lines are important or how they contribute to the overall understanding of the paper. Despite this, the feedback is mostly helpful as it directs the authors to make a specific correction that can improve the clarity and accuracy of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a more comprehensive and data-intensive analysis would significantly improve the paper. However, it does not provide specific guidance on how to conduct this analysis or what aspects should be included. The comment implies that the authors should consider expanding their analysis, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, leaving the authors uncertain about how to implement the suggested improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a more comprehensive and data-intensive analysis would significantly improve the paper. However, it does not specify which part of the paper this analysis should be applied to, nor does it provide details on what aspects should be included or how the analysis should be conducted. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need improvement. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that a more comprehensive and data-intensive analysis would significantly improve the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would enhance the paper. The comment lacks specificity and does not offer a clear path for the authors to follow, making it difficult for them to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that a more comprehensive and data-intensive analysis would significantly improve the paper. However, it does not provide specific guidance on what aspects of the analysis should be expanded or how to conduct it. The comment acknowledges the limitations of the paper's length but does not offer actionable steps for the authors to take. Without detailed suggestions or examples, the feedback lacks depth and specificity, making it barely helpful. Therefore, the comment aligns with a score of 2, as it provides some insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the lack of proper experimental settings and the absence of code. While it points out the importance of result reproducibility, it does not provide specific guidance on how to address these issues. The authors are left to infer that they need to include detailed experimental settings and provide the code, but the comment lacks concrete steps or examples on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental settings\" and the absence of \"code,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for proper experimental settings and the provision of code to ensure result reproducibility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental settings are not mentioned properly and that the result reproducibility is critical. It also notes the absence of code, which is a significant concern. However, the comment does not provide specific examples or detailed reasoning to support why the experimental settings are not mentioned or how the lack of code affects result reproducibility. This makes the claim somewhat verifiable, as the authors would need to infer the importance of these issues and potentially conduct additional research to fully understand the impact. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the experimental settings and the absence of code, which affects the reproducibility of results. It highlights the importance of providing detailed experimental settings and code to ensure the reliability of the findings. However, the comment does not offer specific suggestions or guidance on how to address these issues, such as recommending particular experimental settings or code sharing practices. While it points out a significant problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the lack of a proper comparison against online learning approaches and reinforcement learning (RL). It suggests that the authors should clarify why online learning cannot be used, particularly in relation to retraining cost. The reviewer questions how to compare retraining cost with the incremental updates in online learning and why it is discarded. Additionally, the comment raises challenges in including retraining cost in the evaluation. While the comment provides a clear direction for the authors to address these issues, it does not offer specific guidance on how to implement these changes or what specific aspects to focus on. The action is explicit but somewhat vague in terms of execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors mention that online learning formulation overlooks key practical considerations. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it details the issues with the comparison against online learning approaches and reinforcement learning, suggesting that the authors should clarify why online learning cannot be used and how to compare retraining cost. It also raises questions about the challenges of including retraining cost in the evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several claims about the paper, including the lack of a proper comparison against online learning approaches and reinforcement learning, and the need to clarify why online learning cannot be used. The reviewer questions the exclusion of retraining cost and suggests that it should be included in the evaluation. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issues raised, as the comment does not provide detailed reasoning or evidence to substantiate the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several critical issues with the paper, including the lack of a proper comparison against online learning approaches and reinforcement learning. It suggests that the authors should clarify why online learning cannot be used and how to compare retraining cost with the incremental updates in online learning. The comment also raises questions about the challenges of including retraining cost in the evaluation. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is mostly helpful as it highlights important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should cite works related to meta-learning and distinguish their approaches from those already cited. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a clear direction for the authors to expand their literature review and improve the connection between their work and existing research, it does not specify how to implement these suggestions. The action is explicit but lacks concrete details on how to execute it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that there is a deeper tie to meta-learning and that the authors should cite related works and distinguish their approaches. It also mentions the work on RL for architecture search and optimizers, which should be linked to continual learning. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting that the authors should cite and distinguish related works, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there is a deeper tie to meta-learning and that the authors should cite related works and distinguish their approaches. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a logical reasoning for these suggestions, it lacks specific examples or references to support the claim that these works should be cited or linked. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to identify and integrate these references themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to expand their literature review and distinguish their work from related approaches in the field of meta-learning. It highlights the importance of citing and discussing related works, particularly those on RL for architecture search and optimizers, which could be directly applied to continual learning. This feedback is valuable as it guides the authors to strengthen their literature review and connection to existing research, thereby improving the comprehensiveness and originality of their work. However, the comment could be more helpful if it provided specific examples or references to the related works that should be cited or discussed. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was auto-generated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better reflect real-life situations. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these alternatives. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of lexical and syntactic diversity in the teacher feedback, assuming it was auto-generated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better reflect real-life situations. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results sections. While the authors might have an idea of where this feedback is relevant, it is not explicitly grounded. The comment is specific in suggesting alternative approaches to improve the diversity of teacher feedback, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was auto-generated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better reflect real-life situations. However, the comment does not provide any supporting evidence, examples, or references to justify why this diversity is important or how it would improve the paper. Without additional context or explanation, the claim remains somewhat verifiable, as the authors would need to infer the importance of this suggestion on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the diversity of teacher feedback, assuming it was auto-generated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better reflect real-life situations. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for the authors to explore. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how other studies have addressed this issue. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. While the comment implies that the authors should include a summary of the supplementary experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a summary of the supplementary experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, it does not specify which part of the main text should be revised or where the summary should be placed. The authors can infer that it relates to the sections discussing the experiments or results, but this inference is not direct. The comment is specific in suggesting the need for a summary of the supplementary experiments, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. This feedback is somewhat helpful as it identifies a potential gap in the paper\\'s presentation, which could enhance the clarity and comprehensiveness of the main text. However, the comment lacks specific guidance on how to effectively summarize the supplementary experiments or what aspects of the results should be highlighted. While it points out an area for improvement, it does not provide detailed suggestions or examples, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct a comprehensive comparison with the works mentioned, GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encode-decoder architecture. The reviewer provides specific references to these works, making it clear what needs to be done. Additionally, the comment mentions that the societal impact is shown on the last page of the manuscript, which is not relevant to the action being requested. Therefore, the action is explicit and concrete, as the authors know exactly what needs to be done to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, \"GFF[1]\" and \"EfficientFCN[2],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comprehensive comparison with these works, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encode-decoder architecture. The reviewer suggests a comprehensive comparison with these works. However, the comment does not provide specific details or examples of how these works compare to the current paper, nor does it offer a rationale for why a comparison is necessary. While the references are provided, the lack of detailed justification or explanation makes the claim somewhat verifiable, as the authors would need to conduct their own research to understand the relevance and potential benefits of the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encode-decoder architecture. The reviewer encourages the authors to conduct a comprehensive comparison with these works, which is a valuable suggestion for improving the paper. Additionally, the comment notes that the societal impact is discussed on the last page of the manuscript, providing a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the feedback is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the slight improvement reported in Table 6 and Table 7 and the claim that experimental results prove the effectiveness of the proposed prompts. However, it does not provide any guidance on how the authors should address this issue or what specific actions they should take to support their claim. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the slight improvement reported in these tables and the claim about the effectiveness of the proposed prompts. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the slight improvement reported in Table 6 and Table 7 does not support the claim that experimental results prove the effectiveness of the proposed prompts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the slight improvement reported in Table 6 and Table 7 and the claim that experimental results prove the effectiveness of the proposed prompts. This is a critical observation that could impact the validity of the authors\\' claims. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental design to better support their claims. Without actionable feedback or specific advice, the authors are left without a clear path forward. Therefore, the comment is rated as barely helpful, as it points out a potential problem but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". While the comment implies that these comparisons could provide valuable insights, it does not explicitly instruct the authors to conduct these comparisons or explain why they are necessary. The action is implicit and somewhat vague, as the authors need to infer the importance of these comparisons and determine how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". However, it does not specify which part of the paper these comparisons should be included in, making it weakly grounded. The comment is specific in suggesting the need for these comparisons, as it clearly identifies the potential benefits of including them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". However, the comment does not provide any justification or explanation for why these comparisons are necessary or how they would benefit the paper. Without additional context or reasoning, the authors may find it challenging to understand the relevance of these comparisons. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the performance of the paper with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This feedback is somewhat helpful as it provides a clear direction for the authors to consider in terms of benchmarking their work against existing methods. However, the comment lacks depth and does not explain why these comparisons are important or how they would enhance the paper. Additionally, it does not offer specific guidance on how to conduct these comparisons or what aspects to focus on. While it provides a starting point, the feedback could be more comprehensive and actionable with additional details. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the analysis, specifically the alignment of features at different spatial locations to the same channel. It suggests that there could be many different designs for this analysis, such as experiments or analysis with different sampling intervals and sample sizes. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made. The authors are left to infer that they need to explore different designs or variations, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. However, it does not specify which part of the paper this analysis is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment does provide a specific suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes, which adds some level of specificity. However, without explicit references to sections or figures, the comment remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis of Cycle FC align features at different spatial locations to the same channel is insufficient. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. It highlights the need for exploring different designs, such as experiments or analysis with different sampling intervals and sample sizes. While the comment points out a potential weakness, it lacks specific guidance or suggestions on how to address this issue or what specific designs should be considered. The feedback is somewhat helpful as it directs the authors to consider alternative approaches, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the practical performance of the proposed algorithms, specifically mentioning Algorithm 1 and its reliance on Vandermonde matrices. It highlights the potential numerical instability and ill-conditioning issues, particularly for large $n$ and small $\\\\alpha$. The reviewer suggests that the paper would be more convincing if the authors provided experimental results for the proposed algorithms. While the comment implies that the authors should conduct experiments to address the concern, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the need for experimental results and determine how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"Vandermonde matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the numerical instability and ill-conditioning of Algorithm 1, particularly for large $n$ and small $\\\\alpha$. The comment suggests that the paper would be more convincing with experimental results, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practical performance of the proposed algorithms, specifically mentioning the use of Vandermonde matrices and their potential numerical instability and ill-conditioning. The reviewer supports this claim by referencing the known issues with Vandermonde matrices, particularly for large $n$ and small $\\\\alpha$. This provides a logical basis for the concern, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to studies that have encountered similar issues. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific concern about the practical performance of the proposed algorithms, particularly the use of Vandermonde matrices. It highlights the potential numerical instability and ill-conditioning issues, which could lead to algorithm failure in practice, especially for moderate-sized $n$. The comment suggests that providing experimental results would enhance the paper\\'s credibility. While the comment effectively points out a potential weakness, it could be more helpful if it offered suggestions on how to address this concern or what specific experiments could be conducted to validate the algorithms\\' performance. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of standard deviations in the paper, which raises concerns about the validity of the results. It suggests that the authors should include standard deviations to provide more transparency and confidence in their findings. While the comment explicitly states the action needed (displaying standard deviations), it does not provide specific guidance on how to present these deviations or what aspects to focus on. The action is clear but lacks concrete details on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of standard deviations in the paper, which raises concerns about the validity of the results. However, it does not specify which part of the paper this issue pertains to, such as specific sections or tables where standard deviations should be displayed. This makes it difficult for the authors to pinpoint the exact location of the issue. While the comment is specific in identifying the absence of standard deviations, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the absence of standard deviations in the paper raises concerns about the validity of the results. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to similar studies that have included standard deviations, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting the absence of standard deviations. This is a critical observation that could impact the validity and reliability of the results. However, the comment does not provide specific guidance on how to address this issue or what aspects of the results might be affected by the lack of standard deviations. While it highlights a potential problem, it lacks actionable advice or suggestions for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide explicit guidance or suggestions on how to achieve this extension. The comment implies that the authors should consider broadening the scope of their work, but it lacks concrete steps or detailed advice on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the specificity of the setting, suggesting that the approach could be extended to more general settings. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the setting and its suggestion for broadening the scope, but without clear references to specific sections or elements, the authors may struggle to identify where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide any supporting evidence, reasoning, or references to justify why the current setting is specific or how it could be broadened. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their work. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid point about the specificity of the setting, suggesting that the approach could be extended to more general settings. It questions the need for a specific generative model and episodic problem structure, which are currently limiting the applicability of the work. However, the comment lacks specific suggestions or guidance on how to broaden the scope of the approach or what aspects should be considered for generalization. While it identifies a potential area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a limitation but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the feature extractor used for dimensionality of each region, specifically asking about the feature extractor used in line 201. This is an explicit question that directly asks for clarification, providing a clear action for the authors to take. However, it does not offer specific guidance on how to address the issue or what information should be included in the response. The action is explicit but somewhat vague in terms of detail, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the feature extractor used for dimensionality, providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the feature extractor used for dimensionality in line 201. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the feature extractor used for dimensionality in line 201. This is a clear and actionable request for clarification, as it prompts the authors to provide more information about their methodology. By addressing this question, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it offered suggestions on how to present this information or provided context on why this detail is important. Overall, the comment is somewhat helpful as it directs the authors to a specific area for clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While it implies that the authors should include these details, it does not explicitly instruct them to do so or provide specific guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should include these details but may not be entirely sure how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not specify which part of the paper this information should be included in, nor does it provide details on what specific aspects of the computation, algorithm, or implementation should be highlighted. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would enhance the paper. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what details should be included or how they could be presented. Without further elaboration or examples, the authors may find it challenging to understand the exact nature of the feedback and how to address it. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the choice of p < 0.4 in Algorithm 1, indicating that the reviewer is seeking clarification or explanation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific information they should include in their response. The action is implicit and vague, as the authors are left to infer that they need to provide a detailed explanation or justification for their choice. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the choice of p < 0.4 in Algorithm 1, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the choice of p < 0.4 in Algorithm 1, indicating a potential area for clarification or explanation. While it highlights a specific aspect of the paper that may need further elaboration, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. It specifically mentions the need to clarify why there are negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This feedback provides clear and concrete actions for the authors to take, such as adding explanations or analysis for these figures. The comment is highly actionable as it directly instructs the authors on what needs to be done to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanations or analysis for Figures 1, 2, and 3. The comment provides detailed guidance on what needs to be clarified, such as the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. The reviewer suggests that the authors need to clarify why there are negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This claim is somewhat verifiable as it logically points out the need for additional analysis or explanation, but it lacks specific examples or references to support the claim. The authors would need to infer the need for clarification themselves, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. It highlights the need for clarification regarding the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This feedback is clear and actionable, as it directs the authors to provide necessary explanations and analysis for the figures. By addressing these points, the authors can improve the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided specific suggestions on how to present these explanations or analysis, such as what aspects should be emphasized or how they might be integrated into the existing text. Overall, the comment is mostly helpful as it effectively guides the authors on how to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not provide specific guidance on how to improve the clarity or what aspects of the motivation should be emphasized. The comment lacks concrete details or suggestions on how to enhance the explanation, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for a clearer explanation of the motivation, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, specifically the clarity of the motivation behind applying CMD in federated learning. It suggests that the motivation could benefit from a more explicit demonstration or explanation. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to enhance the clarity or what aspects of the motivation should be emphasized. This limits the comment\\'s usefulness, as it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. While the comment implies that the authors should provide more analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more analysis and comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not specify which sections or parts of the paper should include this analysis or comparison, making it somewhat specific. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that there is insufficient analysis of the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. The comment provides a logical reasoning by suggesting that such comparisons would clarify the unique advantages of the method. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the claim, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of analysis regarding the effectiveness of data augmentation methods. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing, would clarify the unique advantages of the method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and comparison sections. However, the comment could be more helpful if it offered examples or guidance on how to conduct these comparisons. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement and provides a clear path for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is concrete, as it specifies what the authors should do, but it is somewhat vague because it does not provide detailed guidance on how to conduct the ablation study or what specific aspects to focus on. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an ablation study and providing examples of alternative approaches, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. The comment provides a logical reasoning by suggesting alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, it lacks specific examples or references to support the claim that these alternative approaches would be beneficial. The suggestion is somewhat verifiable, as it provides a logical basis for the claim but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is actionable and offers a clear direction for the authors to improve their draft by conducting an ablation study to better understand the impact of each component. However, the comment could be more helpful if it provided additional guidance on how to design and conduct the ablation study, such as which components to focus on or how to interpret the results. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the model's performance should be evaluated. The comment lacks explicit instructions or concrete details on how to apply the information, leaving the authors uncertain about what actions to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the model's performance should be evaluated or how it relates to the paper\\'s content. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an area of interest, it does not provide any guidance or suggestions on how the authors might address this question or what aspects of the model\\'s performance should be evaluated. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It suggests that RLCD (or RLCD-Rescore) may not be able to scale to larger language models that are better at differentiating responses near the decision boundary. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific steps they should consider to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the shrinking advantage of RLCD over RLAIF as the model size increases, and it raises a question about whether RLCD can scale to larger language models. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases, and it questions whether RLCD can scale to larger language models. However, the comment lacks specific examples, data, or references to support this claim. Without additional evidence or detailed reasoning, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It raises a question about whether RLCD (or RLCD-Rescore) can scale to larger language models that are better at differentiating responses near the decision boundary. While the comment highlights an important aspect of the comparison, it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input, and questions whether there is a solution to address this issue. While the comment identifies a potential problem, it does not provide explicit guidance or suggestions on how the authors might address the scalability issue or improve the practical contribution of their paper. The authors are left to infer that they need to consider scalability, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed NC measure, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scalability of the method when applied to large datasets like ImageNet, and suggests that the practical contribution of the paper could be significantly reduced if a solution is not found. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. The reviewer questions whether there is a solution to address this issue, suggesting that the practical contribution of the paper could be significantly reduced if not. However, the comment lacks specific examples or references to support the claim that the method cannot be applied to large datasets like ImageNet. Without such evidence or detailed reasoning, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It raises a valid concern about the practicality of applying this method to large datasets like ImageNet. The comment suggests that if no solution is found to address the scalability issue, the paper's practical contribution could be significantly reduced. This feedback is somewhat helpful as it highlights an important area for improvement, but it lacks specific suggestions or guidance on how the authors might address the scalability issue. While it points out a potential weakness, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct a quantitative analysis on the computational gains, specifically mentioning GPU hours, memory usage, or training time. This provides a clear and concrete action for the authors to take, as it specifies the exact measurements they should include to substantiate their claims of computational benefits. The comment is highly actionable as it gives precise guidance on how to improve the draft by including quantitative analysis.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for quantitative analysis on GPU hours, memory usage, or training time to substantiate the computational benefits. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks specific measurements or comparisons to substantiate the computational benefits of replacing the MAE model with a CNN-based data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This claim is somewhat verifiable as it logically suggests that quantitative analysis would strengthen the paper\\'s claims, but it lacks specific examples or references to similar studies that have used such analyses. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of quantitative analysis on the computational gains. It suggests that including measurements such as GPU hours, memory usage, or training time would provide stronger evidence to substantiate the computational benefits claimed in the paper. This feedback is clear and actionable, as it directs the authors to conduct a quantitative analysis that would enhance the credibility and robustness of their findings. However, the comment could be more helpful if it provided examples of how such analyses have been conducted in similar studies or offered guidance on how to conduct them effectively. Overall, the comment is mostly helpful as it effectively points out a gap in the paper and provides a concrete suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the time for COLMAP and scene-by-scene fine-tuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not provide explicit guidance on how the authors should incorporate this consideration into their analysis or what specific changes should be made to account for this time. The action is implied and somewhat vague, as the authors can infer that they need to consider the time aspect but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the time for COLMAP and scene-by-scene fine-tuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this time consideration should be addressed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a consideration for the time aspect, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the time for COLMAP and scene-by-scene fine-tuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this time consideration is important or how it affects the efficiency of the method. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the efficiency of the method, specifically the time required for COLMAP and scene-by-scene fine-tuning. This is a relevant point that could impact the practicality and applicability of the method in certain scenarios. However, the comment lacks specific guidance or suggestions on how the authors should address this issue, such as recommending alternative methods or techniques for improving efficiency. While it points out a potential weakness, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the \"filter manifold network\" (FMN) and its scalability with the number of filter parameters. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. Additionally, it questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these questions, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it implies actions but does not provide detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the scalability of the FMN with larger input and output channels, and it suggests experimenting with other architectures. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. The reviewer also questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the current discussion is insufficient. The authors are left to infer the need for more analysis and discussion, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It raises important questions about the scalability of the FMN with larger input and output channels, suggesting that the authors should experiment with other architectures and explore the impact of adaptive convolutions on the number of filter parameters. Additionally, it questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. This feedback is clear and actionable, providing the authors with specific areas to focus on to improve their draft. However, it could be more helpful if it offered suggestions on how to address these questions or provided examples of alternative architectures to consider. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform and suggesting that comparisons to UNets are necessary. While the comment identifies a potential issue with the model, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should make comparisons to UNets, but the comment lacks specific instructions on how to conduct these comparisons or what aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed CoNO model\" and the \"complex UNet part after the fractional transform,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the contribution of the UNet part and suggests comparisons to UNets, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the contribution of the UNet part in the CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the claimed performance boost. The reviewer references external works, such as Raonic et al and Gupta et al, to support their claim about the strong performance of UNets on regular gridded domains. This provides a logical basis for the claim, but the comment could be strengthened by providing more detailed comparisons or examples from the referenced works. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform. It suggests that the authors should make comparisons to UNets, as they have shown strong performance on regular gridded domains. The comment provides a logical basis for the suggestion by referencing external works, such as Raonic et al and Gupta et al, which support the importance of UNets in this context. However, the comment could be more helpful by offering specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is somewhat helpful as it highlights a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It also suggests that a comparison of computation complexity should be included in the experiment part. While the comment identifies a specific issue with the computational complexity, it does not provide explicit guidance on how to address it or suggest ways to reduce the computational burden. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison of computation complexity in the experiment section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"the calculation of all the flipped previous layer output into the current layer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of computation complexity in the experiment part. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. The comment suggests that a comparison of computation complexity should be included in the experiment part. While the claim is based on logical reasoning and specific observations about the algorithm, it lacks detailed evidence or references to support the assertion that the PSA method requires more computation. This makes the claim somewhat verifiable, as the authors would need to further investigate and substantiate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the computational complexity of the proposed PSA method compared to baselines, noting that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, as it directs the authors to include a specific comparison in their experiment section. However, it could be more helpful if it provided guidance on how to conduct this comparison or suggested specific metrics to use. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should analyze the contribution of each factor (noise and exponential moving average) separately and compare them to the \\Pi model, which captures only the noise part. This feedback provides a clear and explicit action for the authors to take, as it specifies the need for a detailed analysis of each factor and their contributions. The comment also suggests a specific comparison to the \\Pi model, which adds further guidance on how to conduct the analysis. Therefore, the comment is highly actionable, as it clearly instructs the authors on how to improve their draft by providing detailed analysis and comparison.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed model\" and the \"two factors\" that contribute to its benefits, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the analysis of the contribution of each factor separately and the comparison with the \\Pi model. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It suggests that it would be beneficial to analyze the contribution of each factor separately and compare them to the \\Pi model, which captures only the noise part. The comment provides a logical reasoning for this suggestion by highlighting the potential gain from analyzing each factor independently. However, it lacks specific examples or references to support the claim that analyzing each factor would provide significant insights. Therefore, the claim is somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It identifies a specific area for further analysis, namely the contribution of each factor (noise and exponential moving average) separately and how they compare to the \\Pi model. This feedback is valuable as it prompts the authors to conduct a detailed analysis that could lead to a deeper understanding of the model's strengths and limitations. By addressing this suggestion, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct the analysis or suggested potential metrics or methods to use. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific feedback on the font size and suggests improvements, such as making the words in the grey box larger, increasing the size of V_mem, Th_i, and U_i^t, and using a larger font for the \"CTRL\" long form explanation. Additionally, it points out the lack of details comparison with other state-of-the-art Transformer designs, suggesting a \"table\" manner to emphasize the data for readers. While the comment provides explicit actions and concrete details on how to implement these improvements, it could be more helpful if it offered suggestions on how to present the data comparison in a more effective way. Overall, the comment is mostly actionable as it provides clear guidance on what needs to be addressed, but it could be more detailed in its suggestions for improvement.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures, such as \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the font size, the \"CTRL\" long form explanation, and the lack of details comparison with other state-of-the-art Transformer designs. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims about the font size, the \"CTRL\" long form explanation, and the lack of details comparison with other state-of-the-art Transformer designs. While the comment provides specific examples of issues with the figures, such as font size and the \"CTRL\" long form explanation, it lacks detailed reasoning or references to support why these issues are problematic or how they impact the paper\\'s overall quality. The suggestion to use a \"table\" manner for data comparison is somewhat vague, as it does not provide guidance on how to effectively present this information. Overall, the comment is somewhat verifiable, as it identifies specific issues but lacks detailed justification or references to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the figures, suggesting improvements such as increasing the font size of certain words and labels, and offering a more detailed explanation for the \"CTRL\" long form. It also points out the lack of details comparison with other state-of-the-art Transformer designs, which could be addressed by presenting a \"table\" manner to emphasize the data. This feedback is clear and provides the authors with concrete steps to enhance the clarity and comprehensiveness of their figures and comparisons. However, the comment could be more helpful if it offered suggestions on how to present the data comparison in a more effective way or provided additional context on why this comparison is important. Overall, the comment is mostly helpful as it identifies specific areas for improvement and provides actionable guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent's behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or what specific steps to take to improve the results. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of reporting results after a significant amount of training has occurred, suggesting that the agent's behavior during learning is also important. It raises a concern about the early stages of training, where the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the training process and the potential impact on the agent's behavior, but without clear grounding, the authors cannot effectively address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent's behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a logical observation but lacks specific examples or references to support the claim. The comment is somewhat verifiable as it provides a reasonable basis for the critique but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the reporting of results after a significant amount of training has occurred, suggesting that the agent's behavior during learning is equally important. It speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a thought-provoking observation that could prompt the authors to reconsider their approach to training and evaluation. However, the comment lacks specific suggestions or guidance on how to address this issue or what aspects of the training process might be improved. While it identifies a potential area for improvement, the lack of actionable feedback limits its usefulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests that the authors rewrite the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This is a clear and direct action for the authors to take, as it provides a specific line and page number for them to address. The comment also indicates that the current sentence is unclear, which further guides the authors on what changes are needed to improve the clarity. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"P. 5, p. 3, l.\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This provides clear guidance on what the authors need to do to improve the clarity of their writing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification and a specific suggestion to rewrite a sentence. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" by requesting a rewrite. This is a clear and actionable suggestion that can help the authors improve the readability and understanding of their paper. However, the comment could be more helpful if it provided additional guidance on how to rewrite the sentence or what aspects of the original sentence were confusing. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing improvement, which can enhance the clarity and accessibility of their work. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the approach taken for handling documents in DocRED, specifically asking whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. While the comment identifies a potential gap in the manuscript, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information on their approach but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DocRED\" and \"the documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the consideration of documents as an entire sentence and how the model handles concepts involving multiple entity mentions referring to the same entity. This provides clear guidance on what needs to be addressed in the manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the approach taken for handling documents in DocRED, specifically asking whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is missing from the manuscript. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the manuscript that is missing information, specifically regarding the handling of documents in DocRED and how the model deals with concepts involving multiple entity mentions referring to the same entity. This is a clear and actionable point that can help the authors improve their draft by providing more detailed information on their approach. However, the comment could be more helpful if it offered suggestions on how to address this gap or provided examples of how similar approaches have been handled in the literature. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the contribution of the paper is marginal because the methods used in different stages are well-designed and demonstrated. It also implies that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived marginality or how to improve the contribution. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contribution of the paper is marginal because the methods used in different stages are well-designed and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as the methods or the stage where they are used. This lack of specificity makes it difficult for the authors to identify the exact sections that need improvement or clarification. Additionally, the comment does not provide specific guidance on how to address the perceived marginality or what changes could be made to enhance the contribution. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the paper is marginal because the methods used in different stages are well-designed and demonstrated. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific methods or stages where the methods are demonstrated, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the contribution of the paper is marginal, as the methods used in different stages are well-designed and demonstrated. It also implies that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. While the comment identifies a potential weakness in the contribution, it lacks specificity and actionable suggestions for improvement. It does not provide guidance on how the authors might address the perceived marginality or enhance the contribution. As a result, the comment is somewhat helpful, as it points out a potential issue but does not offer detailed feedback for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. While the comment identifies a potential issue with the clarity of the main contribution, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the motivations for PBSD and its contribution to the paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study\" and the \"DSCL part,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the clarity of the main contribution, particularly regarding the motivations for PBSD beyond improving the discriminative representation on tail classes. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. This claim is somewhat verifiable as it highlights a potential inconsistency in the paper\\'s focus, but it lacks specific examples or references to support the argument. The authors would need to further explore and clarify the motivations for PBSD to address this concern effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. This feedback is somewhat helpful as it points out a potential inconsistency in the paper\\'s focus, which could be clarified to enhance the coherence and impact of the contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as by providing additional context or examples. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the tester for the spread parameter, specifically asking if it yields an (\\\\epsilon,\\\\delta)-identity tester. It also questions how it handles specific cases, such as when \\\\phi = \\\\phi_0 but dK(\\\\pi_0, \\\\pi) is large. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete suggestions on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2,\" likely referring to a specific section or figure in the paper. It also specifies the issue by questioning whether the tester for the spread parameter yields an (\\\\epsilon,\\\\delta)-identity tester and how it handles specific cases, such as when \\\\phi = \\\\phi_0 but dK(\\\\pi_0, \\\\pi) is large. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the tester for the spread parameter, specifically asking if it yields an (\\\\epsilon,\\\\delta)-identity tester. The reviewer provides a specific example of a scenario where the tester might not work as expected, involving a case where \\\\phi = \\\\phi_0 but dK(\\\\pi_0, \\\\pi) is large. This question highlights a potential issue with the tester\\'s applicability, but it does not provide a detailed explanation or evidence to support the claim that the tester does not yield an (\\\\epsilon,\\\\delta)-identity tester. The lack of explicit reasoning or references makes the claim somewhat verifiable, as the authors would need to further explore and address the issue themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the tester for the spread parameter, questioning whether it yields an (\\\\epsilon,\\\\delta)-identity tester. It also provides an example of a scenario where the tester might not work as expected, involving a case where \\\\phi = \\\\phi_0 but dK(\\\\pi_0, \\\\pi) is large. This feedback is somewhat helpful as it identifies a potential issue with the tester\\'s applicability and provides a concrete example to guide the authors in understanding and addressing the problem. However, the comment could be more helpful if it offered suggestions on how to resolve this issue or provided additional context or examples to support the claim. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. While the comment implies that the authors should consider including more details about these experiments in the main text, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they should provide more information but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment appreciates the inclusion of a comprehensive Appendix and acknowledges the additional detail it provides. However, it does not specify which part of the paper the Appendix is attached to, making it weakly grounded. The comment also mentions the Brusselator as an example of an additional experiment, but it does not specify which part of the Appendix this experiment is discussed in. This lack of specificity makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This statement is a factual observation about the reviewer\\'s experience and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment appreciates the inclusion of a comprehensive Appendix and acknowledges the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This feedback highlights a potential limitation in the paper, as it suggests that the main text may not fully cover all aspects of the work. While the comment identifies a weakness, it does not provide specific suggestions or guidance on how to address this issue, such as recommending which experiments should be included in the main text or how to prioritize the most important findings. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the authors\\' claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. The reviewer implies that the description could be misleading if the two methods are not the same. However, the comment does not provide explicit guidance on how the authors should clarify this distinction or what specific changes should be made to the description. While the action is implied, it is not concrete, as the authors are left to infer the necessary steps to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"step 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\\' claim of using active learning and asks for clarification on whether the \"active learning pipeline\" method is the same as traditional active learning. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' claim of using active learning in step 2, specifically asking whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. The reviewer provides a logical reasoning by pointing out that the description could be misleading if the two methods are not the same. However, the comment lacks specific examples or references to support the claim that the methods are different. This makes the claim somewhat verifiable, as the authors would need to further investigate and clarify the distinction themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the authors\\' claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. This is an important clarification that could impact the readers\\' understanding of the methodology and its applicability. The comment prompts the authors to clarify this distinction, which is crucial for ensuring the accuracy and clarity of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the distinction or examples of how the two methods differ. Overall, the comment is mostly helpful as it identifies a critical area for clarification and prompts the authors to take action, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the distribution should be clarified, how it should be clarified, or what specific aspects of the distribution are unclear. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not specify which part of the paper discusses the dataset or where the distribution should be clarified. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the distribution are unclear or how they could be clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, namely the lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of the distribution. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method is limited in its application to supervised training due to the requirement for annotated labels for learning semantic tokens. It proposes an alternative approach using a self-supervised pretraining approach without annotations. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so or provide specific guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of the proposed method in requiring annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests an alternative approach using a self-supervised pretraining approach without annotations. However, the comment does not specify which part of the paper discusses the method or where the limitation is discussed, making it weakly grounded. The suggestion to consider a self-supervised approach is specific, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is limited in its application to supervised training due to the requirement for annotated labels for learning semantic tokens. It suggests an alternative approach using a self-supervised pretraining approach without annotations. While the comment provides a logical reasoning for the limitation and suggests an alternative, it lacks specific examples or references to support the claim that a self-supervised approach would be more appealing. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed method, specifically the requirement for annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests an alternative approach using a self-supervised pretraining approach without annotations, which could be more appealing. This feedback is clear and actionable, as it points out a potential weakness in the methodology and provides a specific suggestion for improvement. However, the comment could be more helpful if it included examples or detailed reasoning on why a self-supervised approach might be more effective. Overall, the comment is mostly helpful as it guides the authors toward a potential improvement in their methodology.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these additional experiments to fully demonstrate the scalability of their method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to demonstrate scalability on more challenging tasks, but without explicit references to sections or figures, the authors may struggle to identify where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that most continuous control experiments are performed on simple and low-dimensional tasks, such as cartpole or mountain car, and that it is important to demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. The claim is somewhat verifiable as it logically argues that demonstrating scalability on more complex tasks is important. However, it lacks specific examples or references to support the claim that these tasks are indeed more challenging or how LFF could be applied to them. Providing such examples or references would strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the current experimental setup, noting that most continuous control experiments are performed on simple and low-dimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of the LFF method, it is important to show its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental setup and demonstrate the broader applicability of their method. However, the comment could be more helpful if it offered suggestions on how to conduct these additional experiments or what specific aspects of the LFF method should be emphasized in these more complex tasks. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the abstract should include a specific measurement, such as \"attain greater expressivity, as measured by the change in linear regions in output space after [citation], instead of just \"attain greater expressivity.\" Additionally, it recommends including learning curves for all experiments in an appendix. While the comment provides explicit actions, it does not specify which experiments should include learning curves or how to present them. The authors are given clear guidance on what to add to the abstract and an appendix, but the execution of these actions is not detailed. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be changed in the abstract, suggesting a specific measurement to include and recommending the inclusion of learning curves in an appendix. This level of detail provides clear direction for the authors to make improvements. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests changes to the abstract, specifically recommending a specific measurement to include and recommending the inclusion of learning curves in an appendix. The comment provides a logical reasoning for these suggestions, suggesting that the current abstract lacks specificity and could benefit from more detailed information. However, it does not provide specific references or examples to support the claim that the current abstract is lacking in detail. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the suggestions but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the abstract, suggesting that it should include a specific measurement to support the claim of \"attaining greater expressivity.\" This suggestion is clear and offers a concrete way to enhance the clarity and rigor of the abstract. Additionally, the comment recommends including learning curves for all experiments in an appendix, which is a helpful suggestion for providing additional insights and context. However, the comment could be more helpful if it explained why learning curves are important or how they could be presented. Overall, the feedback is mostly helpful as it guides the authors on how to improve the clarity and comprehensiveness of their abstract and appendix.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the paper\\'s motivation and application, specifically questioning the need for domain adaptation and the usefulness of the proposed method. It suggests that demonstrating the methodology on actual tasks involving domain adaptation would be beneficial. While the comment implies that the authors should provide examples of how their method could be applied in practice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples of practical applications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results of mapping one RGB image to another RGB image with a different style, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the motivation and usefulness of the proposed method, suggesting that demonstrating its application on actual tasks involving domain adaptation would be beneficial. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the motivation and usefulness of the paper, suggesting that the proposed method is unclear in its application and does not demonstrate its utility on actual tasks involving domain adaptation. The comment provides a logical reasoning by pointing out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily justify the need for domain adaptation. However, the comment lacks specific examples or references to support the claim that demonstrating the methodology on actual tasks would be beneficial. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically questioning the motivation and usefulness of the proposed method. It points out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily justify the need for domain adaptation. The comment suggests that demonstrating the methodology on actual tasks involving domain adaptation would be beneficial, such as adapting a model trained on a synthetic dataset to a real dataset. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the paper\\'s clarity and relevance. However, it could be more helpful if it included examples of such tasks or detailed guidance on how to implement them. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a concrete suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper regards MULT as the only deep learning-based baseline that considers cross-sensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should consider other baselines or update their references to more recent works. As a result, the authors are left without a clear direction on how to address this issue. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific works, \"MISA,\" \"M2FNet,\" and \"MM-DFN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper regards MULT as the only deep learning-based baseline that considers cross-sensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper regards MULT as the only deep learning-based baseline that considers cross-sensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This claim is somewhat verifiable as it provides a specific reference to MULT and its publication year, which supports the assertion that it is outdated. However, the comment lacks detailed reasoning or examples to fully substantiate why MULT is considered out of fashion or how it impacts the current work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it regards MULT as the only deep learning-based baseline that considers cross-sensory interaction, but points out that MULT was proposed in 2019 and is therefore out of fashion. This feedback is somewhat helpful as it highlights an area where the paper may be outdated and suggests that the authors consider more recent works. However, the comment lacks specific suggestions on how to address this issue or what alternative baselines could be considered. While it provides some insight, it could be more helpful with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a major issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks for all models and the omission of tensor completion results for fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be done to improve the clarity and fairness of the comparisons. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. It also provides specific guidance on how to address this issue by suggesting that the authors compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison against other models in the experiments is unclear and that the value of the used ranks is omitted, making it difficult to conduct a fair comparison. The reviewer suggests that the authors should compare tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This claim is somewhat verifiable as it provides a logical reasoning for the need for a fair comparison and suggests a method to achieve it. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. It provides a clear and actionable suggestion by recommending that the authors compare tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback is valuable as it guides the authors on how to improve the clarity and fairness of their experimental comparison, making it highly helpful. Therefore, the comment is rated as 5: Highly Helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include ATA in the comparison under the leave one out setting in Table 2. This is a clear and direct action for the authors to take, as it provides a specific recommendation to enhance the comparison by including ATA. The comment also references the results in Table 1, which further guides the authors on where to make the change. The action is concrete and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of ATA in the comparison under the leave one out setting. This provides clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method should be compared to ATA in addition to \"+LFP\" under the leave one out setting in Table 2. The claim is based on the assumption that ATA is better than FP according to the results in Table 1. However, the comment does not provide specific evidence or references to support this claim, such as detailed comparisons or specific results from Table 1. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to make a significant effort to verify the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+\"LFP\" under the leave one out setting. It suggests that including ATA in the comparison would be more convincing, as ATA is reportedly better than FP according to the results in Table 1. This feedback is clear and actionable, providing the authors with a direct suggestion to enhance the comparison and improve the clarity of their results. By addressing this point, the authors can strengthen their analysis and make their findings more robust. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the normalization module, noting that it appears different in the two versions but is described as the same in the text. It suggests that a standardization of the pictograms is needed, particularly in the figures. The reviewer also points out some confusion in Fig. 4 regarding the chosen symbols overlapping. Additionally, there are minor issues with the text, specifically mentioning a confusion on page 4 after equation. While the comment identifies areas for improvement, it does not provide explicit guidance on how to standardize the pictograms or address the confusion in the figures. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"normalization module\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the normalization module, noting that it appears different in the two versions but is described as the same in the text. Additionally, it points out the confusion in Fig. 4 regarding the chosen symbols overlapping. The comment also mentions minor issues with the text, such as confusion on page 4 after equation. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the normalization module appears different in the two versions but is described as the same in the text. It suggests that a standardization of the pictograms is needed, particularly in the figures. The reviewer also points out some confusion in Fig. 4 regarding the chosen symbols overlapping. While the comment identifies specific issues with the normalization module and the figures, it lacks detailed reasoning or references to support the claim that the normalization module appears different in the two versions. The suggestion for standardization is logical, but the lack of specific examples or detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the normalization module, noting that it appears different in the two versions but is described as the same in the text. This is a clear and actionable point that the authors can address to improve the consistency and clarity of their work. Additionally, the comment suggests that standardization of the pictograms is needed, particularly in the figures, which is a valuable suggestion for enhancing the visual representation of the system. The reviewer also points out some confusion in Fig. 4 regarding the chosen symbols overlapping, which is a minor but relevant issue. However, the comment could be more helpful if it provided specific guidance on how to standardize the pictograms or addressed the confusion in Fig. 4. Overall, the comment is mostly helpful as it identifies key areas for improvement and provides actionable feedback.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the authors\\' claims and the theoretical part of the paper. It highlights that the authors claim that only parts of subdivision splines are useful for decision boundaries, but the theoretical part lacks details on how the proposed algorithm removes these splines. The reviewer questions whether the algorithm requires extra computation cost for space partitioning. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this discrepancy or what additional details should be included in the theoretical part. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations of the algorithm and its computational requirements. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the observation and the goal of pruning, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detail in the theoretical part regarding the proposed algorithm for removing subdivision splines and the potential extra computation cost. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim made by the authors regarding the observation that only parts of subdivision splines are useful for decision boundaries. It points out that the theoretical part lacks details on how the proposed algorithm removes these splines, and it raises a concern about the potential extra computation cost for space partitioning. The comment is somewhat verifiable as it highlights a gap in the paper\\'s explanation and seeks clarification on the algorithm\\'s computational requirements. However, it does not provide specific examples or references to support the claim or the need for additional details. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the authors\\' claims and the theoretical part of the paper. It points out that the authors claim that only parts of subdivision splines are useful for decision boundaries, but the theoretical part lacks details on how the proposed algorithm removes these splines. The reviewer also questions whether the algorithm requires extra computation cost for space partitioning. This feedback is somewhat helpful as it highlights a gap in the paper that the authors need to address to provide a more complete understanding of their work. However, the comment could be more helpful if it offered specific suggestions on how to address this discrepancy or what additional details should be included in the theoretical part. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that W1 and W2 are not defined, and it speculates that they might denote the Encoder and Decoder networks. It also mentions that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and directs the authors to define these terms, which is a concrete action for them to take. The comment is highly actionable as it provides specific guidance on what needs to be clarified or defined in the paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W1 and W2\" and \"W and V,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that these terms are not defined, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"W1 and W2 are not defined\" and speculates that they might denote the Encoder and Decoder networks. It also mentions that \"W and V are not defined\" and provides specific references to page 3, line A4, and equation 3. This claim is somewhat verifiable as it points out specific sections where the terms are not defined, providing some basis for the assertion. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that W1 and W2 are not defined and speculating that they might denote the Encoder and Decoder networks. It also points out that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and actionable, as it directs the authors to clarify these terms and their definitions. By addressing this issue, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it offered suggestions on how to define these terms or provided examples of how they might be used in the context of the paper. Overall, the comment is mostly helpful as it effectively guides the authors in improving the clarity of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. It suggests that a better comparison should be considered. While the comment implies that the authors should reconsider their comparison, it does not provide specific guidance on how to improve the comparison or what alternative baselines should be used. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison with baselines, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the comparison, stating that it is unfair due to the lack of prior knowledge of users or language embedding computation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of baselines, noting that the lack of prior knowledge of users or language embedding computation may unfairly skew the results. This is a valuable observation that could lead to a more robust and fair comparison. However, the comment does not provide specific suggestions on how to address this issue or what alternative baselines could be considered. While it highlights an important area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions and points of confusion regarding the output-side layers, Figure 4, and the Pixel-shuffle operation. It asks for clarification on whether the pixel-shuffle operation is used in the super-resolution field and why the dimensionality remains the same after upsampling in Figure 2(b). Additionally, it points out the lack of discussion on potential negative societal impacts. While the comment identifies areas that need clarification and potential improvements, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify these points in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several specific issues, including the lack of clarity in the output-side layers, the unclear illustration of Figure 4, and the presentation of Pixel-shuffle details. It also questions the use of pixel-shuffle in the super-resolution field and the dimensionality after upsampling in Figure 2(b). However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in detailing what needs to be clarified or addressed, such as the use of pixel-shuffle and the dimensionality issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and observations about the paper, including the lack of clarity in the output-side layers, the unclear illustration of Figure 4, and the presentation of Pixel-shuffle details. It also questions the use of pixel-shuffle in the super-resolution field and the dimensionality after upsampling in Figure 2(b). However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate these claims. The authors are left to infer the basis of these questions, which makes the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas of confusion and potential improvement in the paper. It questions the lack of clarity in the output-side layers and the illustration of Figure 4, which could benefit from more detailed explanations. Additionally, it points out the absence of discussion on the potential negative societal impacts of the work. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how to address them. The authors are left with a general understanding of the issues but may need to infer the exact steps to take. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification or analysis regarding the behavior of negative chips and the potential impact of the alternating process. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the behavior of negative chips and the potential impact of the alternating process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also inquires whether this alternating process could help improve performance. This feedback is valuable as it prompts the authors to clarify their methodology and potentially explore avenues for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or improve their work. Overall, the comment is somewhat helpful as it directs the authors to consider an important aspect of their methodology but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should evaluate their proposed approach on both new and old patients. While the comment implies that the authors should conduct this evaluation, it does not provide specific guidance on how to do so or what aspects of the evaluation should be prioritized. The action is implicit and somewhat vague, as the authors need to infer the details of the evaluation themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or experiment. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for an evaluation on new and old patients, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should evaluate their proposed approach on both new and old patients. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a relevant and actionable suggestion. However, it lacks depth and does not provide specific guidance on how to conduct this evaluation or what aspects of the approach should be tested on each patient group. While the comment identifies a potential area for improvement, it does not offer detailed instructions or examples to help the authors effectively implement this suggestion. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights an issue with the experimental methodology, specifically regarding the use of the 300W-LP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use this dataset in their training. The reviewer questions whether 300W-LP is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This comment implies that the authors should clarify the use of the 300W-LP dataset in their experiments and address the potential bias. However, it does not explicitly instruct the authors to do so, leaving the action somewhat implicit. The authors can infer that they need to clarify the dataset usage, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental methodology, specifically the use of the 300W-LP dataset. It also specifies the issue by questioning whether the dataset is used in all experiments or just some, and whether it provides an unfair advantage to the proposed method. This level of detail allows the authors to identify the exact part of the paper being addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the experimental methodology, specifically questioning the use of the 300W-LP dataset. The reviewer points out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300W-LP dataset in their training. The comment suggests that if 300W-LP is used in all experiments, it could provide an unfair advantage to the proposed method. This claim is somewhat verifiable as it highlights a potential issue with the experimental setup, but it lacks specific examples or references to support the claim that 300W-LP provides an unfair advantage. The authors would need to further investigate and substantiate this claim to fully address the reviewer\\'s concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental methodology, specifically regarding the use of the 300W-LP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300W-LP dataset in their training. This raises a concern about potential bias and fairness in the experiments. The comment questions whether 300W-LP is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This feedback is clear and actionable, as it prompts the authors to clarify the dataset usage and address potential issues with fairness and bias. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or what additional information should be included in the paper. Overall, the comment is mostly helpful as it highlights a critical aspect of the experimental methodology that the authors need to address.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the technique should be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying potential issues with the novelty of the technique, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any evidence, examples, or references to support this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. While it identifies a potential issue with the novelty of the technique, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve the novelty of their work. The comment is somewhat helpful as it points out a potential weakness, but it does not offer actionable advice or detailed feedback for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the authors\\' understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It also points out that the authors\\' formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the formulation. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider their assumptions about the observations and their aggregation process. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the integral in Equation (1)\" and references specific works, \"Law et al., NeurIPS\\'18\" and \"4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the authors\\' formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the integral in Equation (1) corresponds to the bag observation model in [Law et al., NeurIPS\\'18] or the spatial aggregation process in [4]. The reviewer provides references to these works, which supports the claim by referencing established models and processes. However, the comment lacks detailed explanation or analysis of why these references are relevant to the current work or how they impact the authors\\' understanding of their formulation. While the references provide some context, the comment could be strengthened by further elaboration on the implications of these references for the authors\\' work. Therefore, the comment is somewhat verifiable, as it provides some support but lacks detailed justification or explanation.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It points out that the authors\\' formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. The comment provides a clear and actionable suggestion for the authors to reconsider their assumptions about the observations and their aggregation process. By highlighting this potential weakness, the comment offers valuable guidance for improving the clarity and accuracy of the paper. However, it could be more helpful if it provided specific examples or references to similar works that have addressed these issues, which would enhance the authors\\' understanding and action. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks in-depth analysis and suggests that the authors should provide an explanation for the observed inverse scaling over compute. This feedback is clear and provides a direct action for the authors to take, which is to include an analysis of the training dynamics. The comment is specific in its request for an explanation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of in-depth analysis and suggests that the authors should provide an explanation for the observed inverse scaling over compute. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely an explanation of the training dynamics. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks in-depth analysis and suggests that the authors should provide an explanation for the observed inverse scaling over compute. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would enhance the paper. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of in-depth analysis and suggesting that the authors provide an explanation for the observed inverse scaling over compute. This feedback is clear and actionable, as it points out a specific area where the paper could be strengthened by including a deeper analysis. However, the comment could be more helpful if it provided examples or suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of mathematical definition for certain architectural details, specifically mentioning multi-head attention. It also questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer. The reviewer implies that a formal definition would be beneficial for readers to understand the architecture. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide a formal definition, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"multi-head attention,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definition for architectural details, such as multi-head attention, and questions the purpose of a split arrow in Figure 2. The comment further specifies that a formal definition would be beneficial for readers to understand the architecture. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of mathematical definition for certain architectural details, specifically mentioning multi-head attention. It questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer. The reviewer assumes that these are the inputs for the attention layer, namely query, keys, and values. The comment suggests that a formal definition would be beneficial for readers to understand the architecture. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that a formal definition is necessary. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the lack of mathematical definition for certain architectural details, such as multi-head attention, and questions the purpose of a split arrow in Figure 2. It also seeks clarification on the inputs for the attention layer and whether the same vectors are used for keys and values. The comment implies that a formal definition of these concepts would be beneficial for readers to understand the architecture. While the comment highlights areas for improvement, it does not provide detailed suggestions or examples on how to address these issues. The authors are left to infer that they need to provide a formal definition, but the feedback lacks comprehensive guidance. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the assumption that each individual's data is iid drawn from the same distribution, which is necessary for the result of the proposed algorithm to work. It questions how the \\sqrt{m} argument in Section 5.1 and Theorem 6 can be applied to prove Theorem 7 if this assumption is not met. The reviewer finds this assumption unjustifiable due to the differences in users' preferred emojis. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or justify the assumption, but the comment lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1\" and \"Theorem 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the assumption that each individual's data is iid drawn from the same distribution, questioning how the \\sqrt{m} argument in Section 5.1 and Theorem 6 can be applied if this assumption is not met. The comment further explains why the assumption is unjustifiable due to the differences in users' preferred emojis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the assumption that each individual's data is iid drawn from the same distribution, which is necessary for the result of the proposed algorithm to work. The reviewer claims that this assumption is unjustifiable due to the differences in users' preferred emojis. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore the reasoning behind the assumption and its implications to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumption that each individual's data is iid drawn from the same distribution, which is necessary for the result of the proposed algorithm to work. It questions how the \\sqrt{m} argument in Section 5.1 and Theorem 6 can be applied if this assumption is not met, and points out that such an assumption is unjustifiable due to the differences in users' preferred emojis. This feedback is somewhat helpful as it highlights a critical assumption in the paper and suggests that it may not be valid in practice. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or justify the assumption in their work. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. While the comment implies that the authors should modify their experimental setup, it does not provide explicit instructions on how to implement this change or what specific tasks to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. The authors can infer that it relates to the latter part, but this inference is not direct. The comment is specific in suggesting a potential improvement by comparing with a reinforcement learning algorithm baseline, but it lacks grounding as it does not pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the setting with a fixed policy is a subset of reinforcement learning and proposes a comparison with a reinforcement learning algorithm baseline. However, the comment lacks specific examples or references to support the claim that tasks can become more complicated or how this would impact the policy. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a comparison with a more advanced learning framework. However, the comment lacks specific guidance on how to implement this suggestion or what specific tasks to consider. While it points out a potential enhancement, it does not provide detailed instructions or examples, making it somewhat helpful but not fully actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the comprehensiveness of the experimental analyses and the method itself, noting that the focus is primarily on the presentation of results. It suggests that the authors should provide more detailed analyses of the method and its performance, particularly in light of the baseline's underperformance. While the comment implies that the authors should include more detailed analyses, it does not specify exactly what aspects need to be addressed or how to conduct these analyses. The action is implicit and somewhat vague, as the authors need to infer the specific details of what is expected. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"majority of the experiments\" and the \"analyses of the method itself and the experimental outcomes,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the analyses are not comprehensive enough and questioning the extent to which the performance improvement can be attributed to the authors\\' claim. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments focus on the presentation of results and that the analyses of the method and experimental outcomes are not comprehensive enough. It suggests that the authors\\' method underperforms the baseline in some instances, which raises questions about the extent to which the performance improvement can be attributed to the authors\\' claim. The comment provides some logical reasoning by pointing out the potential limitations of the method and its claims, but it lacks specific examples or references to support the claim about the baseline performance. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the majority of the experiments focus on the presentation of results rather than comprehensive analyses of the method and experimental outcomes. It highlights the underperformance of the authors\\' method compared to the baseline, which raises questions about the extent to which the performance improvement can be attributed to the authors\\' claim. This feedback is valuable as it points out a critical area for improvement in the paper, specifically the need for more detailed analyses and explanations of the method and its performance. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or what aspects of the method should be further explored. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper's focus on explaining multi-task models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to broaden the scope of the paper or what specific aspects of multi-task models should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper\\'s focus on explaining multi-task models limits its applicability. However, it does not specify which part of the paper this issue is related to, such as specific sections or examples where the focus on multi-task models is discussed. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the multi-task models are problematic or how they could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper\\'s focus on multi-task models limits its applicability. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper\\'s focus on multi-task models limits its applicability, which is a valid point. However, it does not provide any specific suggestions or guidance on how the authors might broaden the scope of their work or address this limitation. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential issue but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. It suggests that VR-MARINA and DASHA-MVR, mentioned in these papers, could be relevant to the current work. The reviewer provides a specific question about the Assumption 2 and the rate of QSGD in the stochastic regime, implying that the authors should consider these papers for further analysis. While the comment does not explicitly instruct the authors to include these papers, the action is implicit and concrete, as it clearly identifies the need for additional analysis and provides a specific direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"next section\" and the \"Literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of relevant papers, [1] and [2], and suggests that VR-MARINA and DASHA-MVR could be relevant to the current work. The comment provides a clear direction for the authors to consider these papers and address the Assumption 2 and QSGD rate in the stochastic regime. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. The reviewer provides a specific example of VR-MARINA and DASHA-MVR, which are mentioned in these papers, and suggests that they could be relevant to the current work. The reviewer also poses a question about the Assumption 2 and the rate of QSGD in the stochastic regime. This claim is mostly verifiable as it provides specific references and examples to support the argument. However, it could be strengthened by including more detailed comparisons or analysis of these papers\\' relevance to the current work. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the literature review, noting that it ignores several relevant papers. It provides specific references to [1] and [2], which could be relevant to the current work, and suggests that VR-MARINA and DASHA-MVR, mentioned in these papers, could be relevant to the Assumption 2 and the rate of QSGD in the stochastic regime. This feedback is clear and actionable, as it directs the authors to consider these papers for further analysis and potential integration into their work. By addressing this issue, the authors can enhance the comprehensiveness and relevance of their literature review. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific guidance or suggestions on how the authors could improve the presentation to make it more understandable. There is no explicit or implicit action for the authors to take, such as recommending changes to the structure, organization, or content of the paper. Without actionable advice, the authors are left without a clear path to follow to enhance the clarity of their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the presentation of the paper is hard to follow, but it does not specify which part of the paper is particularly challenging to understand. Without explicit references to sections, figures, or other elements of the paper, the authors cannot confidently determine which parts need improvement. Additionally, the comment lacks specificity regarding what aspects of the presentation are confusing or how they could be clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or justification, the authors are left without a clear understanding of what aspects of the presentation are problematic or how they could be improved. As a result, the claim is unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment states that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific feedback or suggestions on how the authors could improve the presentation to make it more accessible or understandable. Without actionable guidance or detailed insights into what aspects of the presentation are confusing or unclear, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, as it lacks any constructive feedback that could assist the authors in improving their work.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: whether the authors have any additional insights into modest performance gains on Clothing1M and how the algorithm performs on other real-world datasets like WebVision, evaluated by DivideMix. While these questions imply that the authors should provide additional information or analysis, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more insights or data. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions about the performance of the algorithm on Clothing1M and WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for additional insights or performance evaluations on specific datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions asking for additional insights and performance evaluations on specific datasets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that could help the authors gain additional insights into the performance of their algorithm on real-world datasets. By asking about modest performance gains on Clothing1M and the algorithm's performance on WebVision, evaluated by DivideMix, the reviewer encourages the authors to provide more detailed evaluations or analysis of their work. However, the comment lacks specific guidance or suggestions on how to address these questions or what additional insights would be beneficial. While it points out areas for potential improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies areas for further exploration but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests more detailed information about the compared models, specifically mentioning the KVAE, DMM, and DVBF. It highlights the differences with KVAE and suggests that the authors provide more details about the computation requirements of the models compared in Table 1. This feedback is clear and concrete, giving the authors specific actions to take to improve their draft. The comment is highly actionable as it directly instructs the authors on what information to include and how to present it, making it easy for them to apply the suggestions.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"compared models\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what additional information is needed, such as the computation requirements of the models compared in Table 1. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the detailed presentation of the compared models, specifically mentioning the KVAE, DMM, and DVBF. The reviewer acknowledges some understanding of the differences with KVAE but requests more detailed information about the compared models. The comment provides a logical reasoning for the need for more detailed information, noting that KVAE is simpler due to linear state space transitions but requires the computation of time-dependent LGSSM parameters \\xce\\xb3. However, the comment lacks specific examples or references to support the claim that the other models are more complex or require different computations. This makes the claim somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by requesting more detailed information about the compared models, particularly the KVAE, DMM, and DVBF. It highlights the differences with KVAE and suggests that the authors provide more detailed information about the computation requirements of the models compared in Table 1. This feedback is clear and actionable, as it guides the authors on what additional information is needed to enhance the clarity and comprehensiveness of their paper. By addressing these points, the authors can improve the understanding and comparison of their work with other models in the field. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct additional experiments on different LLMs like LLaMA and Falcon as benchmark baselines. While the comment implies that more experiments are needed, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on different LLMs like LLaMA and Falcon as benchmark baselines. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results discussion. The authors can infer that it relates to the experimental results or methodology, but this inference is not direct. The comment is specific in suggesting the need for additional experiments but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments on different LLMs like LLaMA and Falcon are needed as benchmark baselines. However, it does not provide any supporting evidence, reasoning, or references to justify why these specific LLMs are necessary or how they would impact the results. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the experimental setup by suggesting that more experiments on different LLMs like LLaMA and Falcon are needed as benchmark baselines. This feedback is somewhat helpful as it points out an area where the authors could enhance their work by including additional comparisons. However, the comment lacks specific guidance on how to conduct these experiments or what specific aspects to focus on, such as the impact of different LLMs on the results. While it provides a direction for improvement, it could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant gap in the paper, noting that it does not describe the hyperparameters used by each defense nor how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. While the comment identifies a clear area for improvement, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they need to include this information, but the lack of concrete guidance on how to do so makes the action implicit. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of description regarding the hyperparameters used by each defense and how those hyperparameters are derived. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. It is also specific because it clearly specifies what needs to be addressed, namely the description of hyperparameters and their derivation. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. The reviewer suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the importance of including this information and might find it challenging to understand the exact implications without additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that it lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific guidance on how to implement this optimization or how to present the results. Overall, the comment is mostly helpful as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical results do not have immediate practical implications, but acknowledges that this is understandable given the novelty of the work. It also expresses a desire for more practical takeaways for practitioners, specifically mentioning the idea of querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate this suggestion or what specific aspects of the paper should be revised to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they should focus on making their results more practical and actionable. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical results and their practical implications, suggesting that the paper could provide more take-away points for practitioners. It mentions a specific take-away point regarding querying a cluster proportionally to the square root of its size, but does not specify which part of the paper this relates to. The authors can infer that it pertains to the theoretical results or methodology sections, but this inference is not direct. The comment is specific in its suggestion for practical takeaways but lacks grounding as it does not explicitly mention which part of the paper it addresses. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical results do not have immediate practical implications, which is somewhat verifiable. The reviewer acknowledges the novelty of the work but suggests that more practical takeaways should be provided. The comment provides a specific example of a take-away point, which is the idea of querying a cluster proportionally to the square root of its size. However, the reviewer does not provide a detailed explanation or evidence to support why this take-away point is not novel or how it could be improved. The lack of detailed justification or references makes the claim somewhat verifiable, as it provides some support but not enough to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the theoretical results do not have immediate practical implications. It acknowledges the novelty of the work but suggests that more practical takeaways should be provided for practitioners. The comment provides a specific example of a take-away point, which is the idea of querying a cluster proportionally to the square root of its size. However, it does not clarify whether this finding is novel or how it could be further developed. While the comment highlights an area for improvement, it lacks depth and does not offer detailed guidance on how to address the issue or what specific aspects of the paper should be revised to enhance its practical relevance. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide actionable steps for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. While the comment identifies a specific area of concern, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide additional information or clarification regarding the purpose of separators. However, the comment lacks concrete details on what specific information is needed or how to present it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the purpose of separators and what additional information they provide beyond T/I/O. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. However, it does not provide any supporting evidence, reasoning, or examples to justify why the separators are necessary or what additional information they might offer. Without such justification, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. This feedback is somewhat helpful as it identifies a potential gap in the paper that could be clarified or expanded upon. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information would be beneficial. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. While it implies that the authors should consider alternative approaches, it does not explicitly instruct them to do so or provide specific guidance on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative pooling strategies. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. It does not present an opinion, judgment, or suggestion that requires verification. It is a request for clarification and does not contain subjective claims or assertions. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This is a thought-provoking observation that could lead to a deeper understanding of the methodology and its implications. However, the comment lacks specific guidance or suggestions on how to explore alternative pooling strategies or what specific aspects of mean pooling might be problematic. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison of the real search cost in terms of GPU days. The comment is specific and provides concrete guidance on how to enhance the table, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison of the real search cost in terms of GPU days. This provides clear guidance on what aspect of the table needs improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the table. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback is somewhat helpful as it identifies a potential area for improvement in the table, which could provide more comprehensive information for readers. However, the comment lacks depth and does not explain why this comparison is important or how it would enhance the understanding of the results. To be more helpful, the comment could provide additional context or examples of how this comparison could be implemented. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training details of the VQGAN model, specifically inquiring whether it is pre-trained or only trained on a subset of images from the Computer Vision Figures dataset. While the comment implies that the authors should provide more information about the training process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the training details but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"VQGAN\" and \"Computer Vision Figures dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the training details of the VQGAN model, specifically inquiring whether it is pre-trained or only trained on a subset of images from the dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the training details of the VQGAN model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the training details of the VQGAN model, specifically inquiring whether it is pre-trained or only trained on a subset of images from the Computer Vision Figures dataset. This is a relevant point as it pertains to the methodology and transparency of the study. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include works such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and compare them to their work conceptually. Additionally, it recommends discussing how their work differs from other chatbox research works, such as [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). These suggestions provide clear and explicit actions for the authors to take, including identifying relevant works and discussing their differences. The comment is concrete and provides specific guidance on how to enhance the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including works such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and discussing how their work differs from other chatbox research works, such as [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). However, it does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the inclusion of these works and the need for a discussion on differences, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include specific works, such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. The comment also recommends discussing how their work differs from other chatbox research works. While the suggestion is based on logical reasoning and common knowledge about the importance of including relevant works, it lacks specific examples or detailed justification for why these works are particularly relevant or how they differ from others. This makes the claim somewhat verifiable, as it provides a general direction but lacks detailed evidence or references to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include relevant works, such as [] Li, Xiujun, et al. \"End-to-end task-completion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. It also recommends discussing how their work differs from other chatbox research works. This feedback is mostly helpful as it guides the authors on how to enhance their draft by incorporating relevant references and discussing their unique contributions. However, it could be more helpful if it provided additional context or examples of how these works differ from the current paper. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed methods, DualIS and DualDIS, in terms of their generic applicability on cross-model retrieval tasks, specifically mentioning the minor improvements in MSVD (Table 3). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the methods or what specific aspects of the methods need to be addressed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS,\" allowing the authors to accurately identify the specific methods being discussed. It also specifies the issue by pointing out that the methods are not generic on some cross-model retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some cross-model retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. However, the comment does not provide specific details or examples of these tasks or the performance improvements, making it difficult for the authors to understand the basis of the claim. Without additional context or references, the claim lacks sufficient evidence or justification to be fully verifiable. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed methods, DualIS and DualDIS, by pointing out that they are not generic on some cross-model retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This feedback is somewhat helpful as it highlights an area where the methods may not be as effective as expected, providing the authors with a specific issue to address. However, the comment could be more helpful if it offered suggestions on how to improve the methods or addressed the issue of generic applicability. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. However, the comment does not provide explicit instructions on how to implement this alternative method or why it might be preferable. While the suggestion is clear, it lacks concrete guidance on how to execute it, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. However, the comment does not specify which part of the paper this critique is based on, such as the experimental section or the methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an alternative method, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the experimental strengths of the approach, specifically the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. This claim is somewhat verifiable as it provides a logical reasoning for the alternative method, but it lacks specific examples or references to support the claim that running vanilla Adam would be sufficient. The authors would need to further explore the implications and potential benefits of the alternative method to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. This feedback is somewhat helpful as it identifies a potential weakness in the experimental setup and offers a suggestion for improvement. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the alternative method. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to establish this relationship or what specific steps to take to improve the study. As a result, the authors are left without any clear direction on how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the study, namely the lack of establishment of the relationship between the top selected patches and the disease. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this relationship should be discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in identifying the issue of incomplete study, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the study, noting that the relationship between the top selected patches and the disease is not yet established. This is a critical point that could impact the validity and reliability of the study. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or what steps they could take to establish this relationship. Without actionable advice or detailed feedback, the authors are left with a clear area for improvement but without a clear path forward. Therefore, the comment is somewhat helpful, as it points out a critical weakness but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a typographical error in the phrase \"for 'in-between' uncertainty\" by noting that the first quotation mark should be a forward mark rather than a backward mark. This is a clear and concrete action for the authors to take, as they are provided with specific guidance on how to correct the error. The comment is highly actionable as it directly instructs the authors on what to change to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"for 'in-between' uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the typographical error, noting that the first quotation mark should be a forward mark rather than a backward mark. This provides clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about a typographical error in the paper, specifically noting that the first quotation mark in the phrase \"for 'in-between' uncertainty\" should be a forward mark rather than a backward mark. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific typographical error in the paper, namely the placement of the quotation marks in the phrase \"for 'in-between' uncertainty.\" This is a minor but important detail that can enhance the professionalism and clarity of the paper. By pointing out this error, the comment provides actionable feedback that the authors can easily address to improve the quality of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the performance of FedSP in Tables 1 and 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting improvements or additional analyses. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance of FedSP is not the best in these tables on some datasets. However, it does not provide detailed guidance on what specific aspects of FedSP are not performing well or how the authors might address this issue. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the performance of FedSP is not the best in Tables 1 and 2 on some datasets. However, it does not provide any specific data, comparisons, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the performance of FedSP in Tables 1 and 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it lacks specificity and actionable guidance on how the authors might address this issue or improve the performance. Without detailed feedback or suggestions on how to improve the performance or what aspects of FedSP are not performing well, the comment does not provide meaningful assistance to the authors. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the clarity of certain aspects in the paper, specifically asking for more explicit explanations. It suggests that the authors should clarify what Omega is and provide more explicit information about the OMD family of algorithms. Additionally, it asks for clarification on the link function and the theorem used for the regret guarantee. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations, but the guidance is somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the clarity of certain aspects, such as the definition of Omega and the OMD family of algorithms, and requests more explicit information about the link function and the theorem used for the regret guarantee. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper could be improved by requesting more explicit explanations. It asks for clarification on the definition of Omega and the OMD family of algorithms, as well as the link function and the theorem used for the regret guarantee. By pointing out these gaps in the paper, the comment provides actionable feedback that can help the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar concepts have been explained in other works. Overall, the comment is mostly helpful as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific aspect of the models being learned directly from pixels without a Markovian state. However, it does not provide any guidance or suggestions on how the authors should address this issue or improve their work. There is no explicit or implicit action for the authors to take, nor is there any indication of what the implications of this observation might be. As a result, the comment lacks actionability and does not provide any direction for the authors to follow. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"the models are learned directly from pixels without a Markovian state,\" which suggests that the models are not Markovian. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the models being learned directly from pixels without a Markovian state, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this observation or how it affects the paper\\'s conclusions. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific aspect of the models being learned directly from pixels without a Markovian state, which could be a potential issue or limitation. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or context, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically using the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and explicit action. The comment is specific in identifying the need for references and provides a concrete direction for the authors to take. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"sequence example\" and \"Example 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the use of the Hamming distance over entire parts of the sequence as a scoring loss, which is a specific practice in the context of CRF. The comment suggests providing references for this approach, which is a clear and specific request for additional information. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the use of the Hamming distance over entire parts of the sequence as a scoring loss in the context of CRF, suggesting that this is a \"common\" practice. The reviewer acknowledges that they are not familiar with this approach and asks for references to support it. While the comment identifies a potential gap in the paper, it lacks specific references or examples to substantiate the claim that this is a \"common\" practice. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to find and integrate references to fully address the reviewer\\'s concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically using the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and actionable suggestion. By addressing this point, the authors can enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided specific references or examples of works that use this approach. Overall, the comment is mostly helpful as it identifies a potential gap in the paper and offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment provides a clear action to take, it lacks specific guidance on how to implement these changes or what specific metrics should be included. The authors are given a general direction but may need to infer the details of execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the evaluation or metrics sections. The suggestion to change the name and mention metrics is specific, but the lack of grounding in the original text makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also recommends mentioning the metrics along with the datasets or in the captions of the tables. This suggestion is based on the claim that \"evaluation\" can have a more general meaning and that most, if not all, of the metrics are well-known and used as standard practice. However, the comment lacks specific examples or references to support the claim that the metrics are well-known and standard practice. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to change the name of the \"Evaluation\" element to \"Metrics,\" which is a clear and concise improvement. It also recommends removing the corresponding sections and mentioning the metrics along with the datasets or in the captions of the tables. This suggestion is based on the rationale that \"evaluation\" can have a more general meaning and that most, if not all, of the metrics are well-known and used as standard practice. By making these changes, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided examples of specific metrics to include or explained why these changes would enhance the paper\\'s clarity. Overall, the comment is mostly helpful as it offers clear and actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. However, it does not provide specific guidance on how to do so or what aspects of the dataset should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their exploration of the dataset but without detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper should have more exploration or what aspects of the dataset should be highlighted. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this exploration is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. However, it lacks specificity and does not provide guidance on how to incorporate this exploration or what aspects of the dataset should be highlighted. Without actionable advice or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, making it difficult to characterize the improvement as remarkable. While the comment provides a specific suggestion to use more objective terms, it does not offer concrete guidance on what terms to use or how to present the improvement in a more objective manner. The action is implicit and somewhat vague, as the authors need to infer the specific terms to use and the exact way to present the improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"axes\" and \"squished,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement and points out that the axes are squished, making it difficult to characterize the improvement as remarkable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the term \"remarkable\" is subjective and that the axes are squished, making it difficult to characterize the accuracy improvement as remarkable. However, the comment does not provide any supporting evidence, reasoning, or references to justify why \"remarkable\" is inappropriate or how the squished axes affect the interpretation of the improvement. Without additional context or examples, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, making it difficult to characterize the improvement as remarkable. This feedback is actionable and constructive, as it offers a clear direction for the authors to improve the clarity and precision of their language. By addressing these points, the authors can enhance the credibility and objectivity of their claims. However, the comment could be more helpful if it provided examples of alternative, objective terms to use or explained why \"remarkable\" is not appropriate. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could benefit from using longer video sequences, such as 16 frames, to address issues with inconsistent motion, changing color, or object disappearing over time. It also mentions that running the LSTM over many time steps could be interesting. While the comment implies that the authors should consider these changes, it does not provide explicit instructions or concrete details on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the synthesized results for UCF-101, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with inconsistent motion, changing color, or object disappearing over time and suggests using longer video sequences. Additionally, it provides a positive assessment of the paper, noting its interesting idea and extensive experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the synthesized results for UCF-101 exhibit inconsistent motion, changing color, or object disappearing over time. It suggests that using longer video sequences, such as 16 frames, could address these issues. The comment provides a logical reasoning by pointing out specific problems with the synthesized results and suggests a potential solution. However, it lacks specific examples or references to support the claim about the synthesized results, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but could be improved with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a positive assessment of the paper, noting its interesting idea and extensive experiments. It also identifies specific issues with the synthesized results, such as inconsistent motion, changing color, or object disappearing over time. The comment suggests that using longer video sequences, such as 16 frames, could address these issues. While the feedback is clear and actionable, it could be more helpful if it provided specific examples or guidance on how to implement the suggested changes. Overall, the comment is mostly helpful as it highlights areas for improvement and offers a direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment states a fact about the limitations of pruning techniques on GPUs, which is not an actionable statement. It does not provide any guidance or suggestions for the authors to address this issue or improve their draft. As a result, the comment lacks actionability and is not helpful for the authors to make any changes to their work. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses. It is a general statement about the limitations of pruning techniques on GPUs, which does not provide any context or reference to a specific section, table, or figure in the paper. As a result, the comment is not grounded and lacks specificity, making it difficult for the authors to understand what needs to be addressed or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point states a fact about the limitations of pruning techniques on GPUs, which is a general observation. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is a factual statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment provides a factual observation about the limitations of pruning techniques on GPUs, which is relevant but not actionable. It does not offer any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or constructive criticism, the comment does not help the authors improve their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with [5] being unfair because [5] is designed for a more complex problem. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the evaluation. The comment lacks actionable details, such as suggesting alternative evaluation methods or providing specific examples of how the comparison could be improved. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the numerical evaluation and the comparison with [5], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is not fair due to the complexity of the problem. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with [5] being unfair. The reviewer supports this claim by explaining that [5] is designed for a more complex problem, specifically mentioning the absence of knowledge of camera pose parameters. This provides a logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to the complex problem addressed by [5], which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is unfair due to the complexity of the problem addressed by [5]. This feedback is valuable as it highlights a potential weakness in the evaluation, which could impact the credibility of the results. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as by suggesting alternative evaluation methods or explaining why the comparison with [5] is unfair. Despite this, the comment still offers a clear direction for improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors studied the effect of using numbers of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that having a 32-bit logit might improve robustness against a more powerful adversary. While the comment implies that the authors should consider this experiment, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this experiment to strengthen their paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"PGD attack\" and the \"32-bit logit,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about whether the study of numbers of bits in logits helps against a larger epsilon in the PGD attack, suggesting that this experiment could strengthen the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about whether the study of numbers of bits in logits helps against a larger epsilon in the PGD attack. It suggests that having a 32-bit logit might improve robustness against a more powerful adversary. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to fully understand or address the suggestion. The reasoning is based on intuition and common sense, but without detailed justification or examples, it is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the study of numbers of bits in logits and their effect on robustness against a larger epsilon in the PGD attack. It suggests that having a 32-bit logit might improve robustness against a more powerful adversary. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this experiment or what specific aspects to focus on. The feedback is somewhat helpful as it points out a potential area for enhancement, but it could be more actionable and detailed to fully support the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the impact of the method on insurance costs for men and women. While it does not explicitly instruct the authors to provide this information, the question implies that the authors should include this analysis in their paper. The action is implicit but concrete, as the authors can infer that they need to include this information to address the reviewer\\'s concern. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment poses a question about the impact of the method on insurance costs for men and women, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this information should be addressed. Additionally, the comment lacks specificity regarding what aspects of the insurance costs should be analyzed or how the method affects them. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the impact of the method on insurance costs for men and women. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking information about the method\\'s practical application. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a specific question about the impact of the method on insurance costs for men and women. This is a relevant and important question that could help the authors understand the practical implications of their work. However, the comment does not provide any context or explanation about why this information is important or how it could be incorporated into the paper. While it identifies a potential area for improvement, it lacks depth and actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, specifically mentioning a reference to Foester et al. (NIPS 2016) as an example. This provides a clear and concrete action for the authors to take, as they are given a specific area to address and a reference to guide their understanding. The comment is highly actionable because it clearly identifies what needs to be clarified and provides a concrete example to follow.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"meta solvers\" and the \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the difference between the meta solvers and centralized RL, and provides a reference to Foester et al. (NIPS 2016) to guide the authors in understanding this difference. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the meta solvers are centralized controllers, and suggests that the authors should clarify the difference between them and centralized RL. The reviewer provides a reference to Foester et al. (NIPS 2016) to support this claim. However, the comment lacks detailed explanation or analysis of why the meta solvers are considered centralized controllers, making it somewhat verifiable. The reference to Foester et al. provides some support, but the authors would need to further explore the context and implications of the claim to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper regarding the classification of the meta solvers as centralized controllers. It suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al. (NIPS 2016) as an example of centralized RL, which is a clear and actionable suggestion for the authors to consider. This feedback is mostly helpful as it guides the authors to clarify a key aspect of their work, which could enhance the understanding and clarity of their paper. However, it could be more helpful if it provided additional context or examples to further support the authors in their clarification efforts. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October, suggesting that the authors should consider this issue in their paper. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider the availability of papers on arxiv. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of splitting papers according to their publication years on the ACL anthology, noting that many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October. However, the comment does not specify which part of the paper discusses the splitting of papers, making it weakly grounded. The comment is specific in pointing out the issue of papers being available on arxiv before being published in the ACL anthology. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. The reviewer provides an example of the BERT paper being available on arxiv in October, which supports the claim. However, the comment could be strengthened by providing more examples or detailed reasoning on why this issue is significant. As it stands, the claim is somewhat verifiable, as it relies on a specific example but lacks comprehensive evidence or detailed explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s methodology, noting that it splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. This is a relevant observation that could impact the paper\\'s credibility and relevance. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should consider providing examples to explain the concept of M_T, which is defined over the probabilities of atomic events. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific in its request for examples, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of M_T and the notation used, and suggests providing examples to clarify the concept. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the definition of M_T is over the probabilities of atomic events and that the notation is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definition of M_T, noting that it is defined over the probabilities of atomic events and that the notation is not clear. It suggests that the authors consider providing examples to clarify this concept. While the comment highlights a potential area for improvement, it does not provide detailed guidance on how to present these examples or what specific aspects of the notation should be clarified. This limits the comment\\'s helpfulness, as it points out an issue but does not fully support the authors in addressing it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises two concerns: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they need to clarify the use of \u03b2 and the difference between QRS and RS, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the proposed relaxation of rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. The comment provides a clear direction for improvement by suggesting that the authors clarify the use of \u03b2 and the difference between QRS and RS. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the use of an arbitrary parameter \u03b2 in rejection sampling and questions the lack of clarity regarding the difference between QRS and RS in Algorithm 1. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the authors should have used Importance sampling instead of rejection sampling. Additionally, the comment lacks specific examples or detailed explanations to support the claim about the difference between QRS and RS. As a result, the claim is not verifiable, making it difficult for the authors to understand and address the critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need attention, but it could be more beneficial if it offered actionable steps or examples to improve the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the observed performance enhancements are modest and implies that there is room for further refinement in the future. However, it does not provide specific guidance on how to achieve this refinement or what aspects of the paper need improvement. The action is implicit and vague, as the authors are left to infer that they need to make improvements but without clear direction on what those improvements should be. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not specify which part of the paper this observation pertains to, such as specific sections, experiments, or results. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the performance enhancements are considered modest or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of this observation and how it relates to their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the observed performance enhancements are modest, indicating that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what aspects of the paper need improvement. Without actionable feedback or detailed insights, the authors are left without a clear path forward to enhance their work. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide references for two specific passages in Section 3.2, lines 230-234 and 234-235, and to clarify what \"MLP\" refers to in Figure 2. These are clear and direct actions that the authors can take to improve their draft. Additionally, the comment highlights a missing reference, which is also actionable. The feedback is concrete and specific, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in Section 3.2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the references for two passages and the clarification of \"MLP\" in Figure 2. This level of detail provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for references and clarifications, which are factual in nature and do not contain subjective claims or opinions. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying specific lines in Section 3.2 that lack references and asking for clarification on \"MLP\" in Figure 2. This guidance is clear and directs the authors to specific areas that need attention, ensuring that the paper is well-referenced and clear. Additionally, the comment highlights a missing reference, which is important for the paper\\'s completeness. Overall, the comment is highly helpful as it offers concrete steps for improvement, making it fully comprehensive and beneficial for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the cause of this similarity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or improve the experimental results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental results on the last two datasets, specifically mentioning the performance being similar to IRM. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the experimental results, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method. However, it does not provide any specific evidence, reasoning, or examples to support this claim. The mention of \"IRM\" is not sufficient to substantiate the claim, as it does not explain why the performance is similar to IRM or how this relates to the issues mentioned above. Without detailed justification or references, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their experimental results. Without detailed guidance or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a potential weakness but does not offer sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment implies that the authors should provide a clearer explanation or rationale for this distinction, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the distinction but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of detecting both entities in the example and asking for clarification on the difference between detecting both entities and just detecting the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment identifies a potential area of confusion or misunderstanding in the paper, it does not provide specific guidance or suggestions on how to address this issue. The authors are left with a vague understanding of what needs to be clarified, which limits the comment\\'s helpfulness. Therefore, the comment is rated as somewhat helpful, as it points out an area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that there is no empirical validation and suggests including experiments to validate the bounds. This provides a clear and direct action for the authors to take, which is to conduct experiments to validate the bounds. The comment is specific in its request for empirical validation and offers a concrete direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the lack of empirical validation, which provides full grounding as it allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting the inclusion of experiments to validate the bounds. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is no empirical validation and suggests including experiments to validate the bounds. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of empirical validation for the bounds. It suggests that including experiments to validate the bounds would be beneficial. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending the inclusion of empirical validation. However, the comment could be more helpful if it offered examples of what types of experiments might be appropriate or how to design them. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. However, it does not provide any explicit guidance or suggestions on how the authors should address this confusion or clarify their terminology. The action is implicit and vague, as the authors are left to infer that they need to reconsider their terminology. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the phrase \"non-sequential information such as chunks,\" suggesting that the term \"chunks\" might be considered sequential information. This provides clear guidance on what needs to be clarified or revised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification regarding the phrase \"non-sequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the phrase \"non-sequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. This question highlights a potential confusion in the terminology used, which could impact the clarity and understanding of the paper. While the comment identifies a specific area of concern, it does not provide any guidance or suggestions on how the authors might clarify or address this issue. The feedback is somewhat helpful as it points out a potential problem, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a discrepancy between equation 9 and figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. While the comment identifies a potential issue, it does not provide explicit instructions on how to address it or what specific changes should be made to the figure or the methodology. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the figure and possibly use bilinear sampling. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions, and suggesting that bilinear sampling might provide better results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions. The reviewer suggests that the figure is misleading and proposes an alternative method, bilinear sampling, as a potential solution. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim about the misleading nature of Figure 1. The suggestion to use bilinear sampling is logical but could be strengthened with more detailed explanation or references. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between equation 9 and Figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. This feedback is somewhat helpful as it points out a potential issue with the figure and provides a suggestion for improvement. However, the comment could be more helpful if it offered more detailed guidance on how to address the discrepancy or why bilinear sampling might be a better approach. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the upper bound in Theorem 1, which seems correct but contains an exception. The reviewer asks how to explain this exception, implying that the authors should provide an explanation or clarification. However, the comment does not explicitly instruct the authors to do so, nor does it offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the upper bound in Theorem 1 and asks for clarification on how to explain an exception. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the correctness of Theorem 1 and an observation about an exception. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the correctness of Theorem 1 and points out an exception regarding a separate node with 0 neighbors. This question highlights a potential issue in the paper that the authors may need to address. However, the comment does not provide specific guidance or suggestions on how to address this issue or explain the exception. While it identifies a potential weakness, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). It suggests that the idea, co-attention mechanism, and architecture of the paper are similar to those in the previous papers. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to enhance the novelty of their work. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the two papers (Xing and Tsang, 2022a, b), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and comparing the paper to the mentioned papers, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The comment provides a specific comparison with the papers, noting that the idea, co-attention mechanism, and architecture of the paper are similar to those in the previous works. This comparison provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific sections of the papers that support the comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it lacks technical novelty and is similar to two mentioned papers (Xing and Tsang, 2022a, b). It provides a specific comparison with the papers, highlighting the similarities in the idea, co-attention mechanism, and architecture. This feedback is somewhat helpful as it points out an area where the paper could be improved by differentiating itself from existing work. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or enhance the novelty of their work. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early down-sampling layers. It suggests that this observation should be revised or deleted from the discussion. However, the comment does not provide explicit instructions on how to revise or delete the content. The action is implicit and somewhat vague, as the authors need to infer that they should revise or delete the content. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, noting that the training time reduction is less drastic than the parameter reduction due to the computation of gradients for early down-sampling layers. The comment suggests that this observation should be revised or deleted from the discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the training time reduction is less drastic than the parameter reduction because most gradients are still computed for early down-sampling layers. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion on training time reduction and parameter reduction. It points out that the training time reduction is less drastic than the parameter reduction because most gradients are still computed for early down-sampling layers. This observation is relevant and could be a source of confusion or misinterpretation in the discussion. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the discussion. While it highlights a potential problem, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the problem being discussed is specific to binding affinity prediction or applies to other downstream tasks. It implies that the authors should provide a justification for why the problem is specific to binding affinity prediction. However, the comment does not explicitly instruct the authors to provide this justification or specify how it should be presented. While the action is implied, it is not concrete, as the authors are left to infer what additional information is needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the problem to other downstream tasks or whether it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a justification or explanation of why the problem is specific to binding affinity prediction. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the applicability of a problem to other downstream tasks or its specificity to binding affinity prediction. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of a problem to other downstream tasks or its specificity to binding affinity prediction. This is a relevant point that could prompt the authors to clarify the scope and limitations of their work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information would be beneficial. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPT-generated rumors are similar to natural rumors in terms of difficulty to detect. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific analyses or solutions could be proposed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the handling of rumors generated by GPT, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the need for further analysis or solutions regarding the challenges of detecting rumors generated by GPT, and it questions the rationale behind why GPT-generated rumors are similar to natural rumors. The comment provides a clear direction for the authors to consider, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind why GPT-generated rumors are similar to natural rumors in terms of difficulty to detect. It suggests that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor, but the experimental result shows the opposite. The comment provides a logical reasoning by questioning the experimental result and suggesting that the rationale might be flawed. However, it lacks specific examples or references to support the claim that GPT-generated rumors are easier to detect than natural rumors. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires further analysis or solutions, namely the handling of rumors generated by GPT. It questions the rationale behind why GPT-generated rumors are similar to natural rumors in terms of difficulty to detect, suggesting that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor. The comment highlights a gap in the analysis and provides a clear direction for the authors to consider. However, it could be more helpful if it offered suggestions on how to address this issue or what specific analyses could be conducted to clarify the rationale. Overall, the comment is mostly helpful as it points out a critical area for improvement and provides a direction for the authors to explore, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical contribution or what specific changes should be made to Section 4. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, stating that it is limited and not about a formal and principled solution but rather about heuristics. This provides clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the technical contribution of the paper, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. This feedback highlights an area where the paper could be improved by providing a more comprehensive and rigorous approach to the technical contribution. However, the comment lacks specific suggestions or guidance on how to address this issue or what aspects of the heuristics should be improved. While it points out a potential weakness, it does not offer actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. This feedback is specific and concrete, as it instructs the authors to adjust the font size to make it more readable. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a factual observation about the font size in Figure 6, which does not contain any subjective claims, opinions, or suggestions. It is a descriptive statement that requires no verification or justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment is somewhat helpful as it identifies a specific issue with the font size in Figure 6, which could impact readability. However, it does not provide any suggestions or guidance on how to address this issue, such as recommending a specific font size or discussing potential consequences of the small font. While it points out a potential problem, the lack of actionable advice limits its usefulness for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the probability mass function (PMF) is not being fully utilized in the experimental setting and recommends considering various PMFs for each learner class. It also mentions that the quasi-uniform distribution used in MixBoost is dependent on a single parameter and suggests that individual consideration of each learner class would add depth to the experimental setting. However, the comment does not provide specific guidance on how to implement this suggestion or which PMFs to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"probability mass function\" and the \"MixBoost\" setting, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the use of a quasi-uniform distribution and suggests considering various probability mass functions for each learner class. This provides clear guidance on what needs to be addressed in the experimental setting. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the probability mass function is \"practically unexploited\" in the experimental setting, specifically mentioning the use of a quasi-uniform distribution in MixBoost. The reviewer suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that a quasi-uniform distribution is not ideal. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setting, noting that the probability mass function is practically unexploited in the MixBoost setting. It suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. While the comment highlights a potential area for improvement, it lacks specific guidance on how to implement this suggestion or which probability mass functions to consider. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed instructions on how to address it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this issue, provide additional context, or clarify their methodology. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how the authors should address this concern. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to understand and act upon the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is unfair. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a valid question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. This is an important point that could impact the interpretation and comparison of results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the missing references, specifically mentioning [a], which is relevant to the topic of the paper. It suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. However, the comment does not provide explicit instructions on how to incorporate these references or discuss the connections. While the authors can infer that they need to include these references and discuss the connections, the lack of concrete guidance on how to do so makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the missing references and the need to discuss connections with [a], which uses supervised learning in QBF solving. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper is missing relevant references, specifically mentioning [a], which uses supervised learning in QBF solving. The reviewer provides a specific reference to support the claim that this work is relevant to the paper\\'s topic. However, the comment lacks detailed reasoning or explanation about why this reference is crucial or how it relates to the paper\\'s content. While the reference is provided, the lack of detailed justification makes the claim somewhat verifiable, as the authors would need to explore the connection themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue by pointing out the missing references, specifically mentioning [a], which is relevant to the topic of the paper. It suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. This feedback is clear and actionable, as it directs the authors to include relevant references and explore potential connections with the existing literature. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these references or discuss the connections effectively. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider whether the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It also suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide specific guidance on how to do so or what specific alternative relationships to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the training process and the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests exploring alternative relationships and provides a reference to a related work for further consideration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss is replaced by other relationships. The reviewer supports this claim by referencing a related work, Navon et al. (2020), which explores the Pareto Front with hypernetworks. This reference provides a basis for the claim, suggesting that the authors should consider alternative relationships. However, the comment could be strengthened by providing more detailed reasoning or examples of how these alternative relationships might be explored. Therefore, the comment is somewhat verifiable, as it provides a reference but lacks full justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the training process that could be improved by exploring alternative relationships between the degree of a single-task predictor participation and the weight of the corresponding task loss. It suggests that this could lead to a continuous parameterization of the Pareto Front. The comment also references a related work, Navon et al. (2020), which could provide a starting point for the authors to consider alternative relationships. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions or examples of alternative relationships to explore. Overall, the comment is mostly helpful as it highlights a potential area for improvement and provides a reference for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the comparison in terms of computation cost or running time. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific aspects of the computation cost or running time should be compared, nor is there any suggestion for how the authors might address this issue. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the computation cost or running time should be compared or how the authors might address this issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the comparison in terms of computation cost or running time, but it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment poses a question about the comparison in terms of computation cost or running time, which could be an important aspect of the paper. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or what aspects of the computation cost or running time should be compared. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms, such as Hogwild. While the comment provides a specific suggestion for improvement, it lacks concrete guidance on how to implement this change or what specific aspects of the paper need to be revised to address this issue. The authors are left with a general idea of what to do but without detailed instructions on how to execute the action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second paragraph, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, suggesting that the examples chosen do not convincingly demonstrate the need for inter-process communication and recommending a focus on problems where the loss function does not decompose as the sum of sample losses. The comment provides a clear direction for improvement by suggesting a focus on Hogwild and other ERM-based distributed algorithms. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the examples chosen in the paper do not convincingly demonstrate the need for inter-process communication, particularly in the second paragraph where sampling-based Bayesian methods are mentioned. The reviewer suggests that the paper's results are irrelevant in this context and recommends focusing on problems where the loss function does not decompose as the sum of sample losses. The comment provides a logical reasoning for the claim by pointing out the specific examples and suggesting a different focus. However, it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the critique but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction, noting that the examples chosen do not convincingly demonstrate the need for inter-process communication. It suggests that the paper's results are irrelevant in this context, particularly in the second paragraph where sampling-based Bayesian methods are mentioned. The reviewer provides a specific recommendation to focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms, such as Hogwild. This feedback is clear and actionable, offering a concrete direction for improvement by suggesting a different focus for the paper. However, it could be more helpful if it provided additional context or examples of how the authors might apply this suggestion to their work. Overall, the comment is mostly helpful as it guides the authors toward a more focused and relevant approach for their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address these concerns or improve the paper in response. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the privacy preservation issue and the example of traffic signal control, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. However, the comment lacks any supporting evidence, reasoning, or references to substantiate these claims. Without detailed justification or examples, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. While the comment identifies a potential weakness in the paper\\'s argument, it lacks specific guidance or suggestions on how the authors might address this issue or improve the paper. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of fairness in the comparison between CPEF and PMEF in Figure 3, noting that PMEF lacks a pre-training module. It suggests that to ensure fairness, the authors should compare CPEF with another pre-trained model, such as ExpertBert, to showcase the advantage of the innovative pre-training module design of CPEF. This feedback provides a clear and explicit action for the authors to take, specifying which model to compare and why. The suggestion is concrete, as it directly instructs the authors on how to improve the fairness and clarity of their comparison. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529-lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of fairness in the comparison between CPEF and PMEF. The comment provides a clear suggestion to compare CPEF with another pre-trained model, such as ExpertBert, to ensure fairness and highlight the advantages of the innovative pre-training module design of CPEF. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between CPEF and PMEF is unfair due to the lack of a pre-training module in PMEF. The reviewer suggests that to ensure fairness, the authors should compare CPEF with another pre-trained model, such as ExpertBert. This claim is somewhat verifiable as it logically argues that a fair comparison should include models with similar pre-training capabilities. However, the comment lacks specific examples or references to support the claim that ExpertBert is a suitable alternative for comparison. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the fairness of the comparison between CPEF and PMEF in Figure 3. It points out that PMEF lacks a pre-training module, which makes the comparison unfair. The reviewer provides a clear and actionable suggestion to ensure fairness by recommending a comparison with another pre-trained model, such as ExpertBert. This feedback is valuable as it guides the authors to make a necessary adjustment to their experimental design to ensure a fair comparison. By addressing this issue, the authors can enhance the validity and credibility of their results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This provides a clear and direct action for the authors to take, which is to verify and potentially fix the links. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"footnotes 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the hyperlinks not working, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the hyperlinks for footnotes 3 and 4 do not work. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable piece of feedback that the authors can address to improve the quality of their paper. By pointing out this issue, the reviewer helps the authors ensure that their references are functional and accessible to readers. However, the comment could be more helpful if it provided additional guidance on how to verify the links or suggested ways to troubleshoot the problem. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is explicit and provides concrete details on what changes need to be made, making it highly actionable. The authors know exactly what needs to be done to improve the clarity of their discussion and figure.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests revising the discussion, particularly in the modeling section, which is not clear enough. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out that the figure may be misleading, suggesting that the Label Embeddings are the output of the encoder. This provides full grounding as it explicitly mentions the sections and elements that need attention, allowing the authors to accurately identify the parts of the paper that need revision. The comment is also specific in detailing what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples of areas that need improvement, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure may be misleading, suggesting that the Label Embeddings are the output of the encoder. This feedback is mostly verifiable as it provides logical reasoning and specific examples to support the claim. However, it could be strengthened by referencing external works or providing more detailed explanations to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the clarity of the discussion in the modeling section. It suggests revising the architecture section to better formalize the architecture and clarify the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is clear and constructive, offering the authors a concrete path to improve the clarity and accuracy of their discussion. By addressing these points, the authors can enhance the comprehensibility and effectiveness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the description of the neural network is difficult to understand and recommends starting the section with the final paragraph that clarifies it. While the comment provides a specific suggestion to improve the clarity of the section, it does not offer detailed guidance on how to achieve this clarity or what specific changes should be made to the description. The action is implicit and somewhat vague, as the authors need to infer that they should start the section with the clarifying paragraph. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"528,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the neural network, suggesting that it is hard to understand and recommending starting the section with the final paragraph that clarifies it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of the neural network is hard to understand and suggests starting the section with the final paragraph that clarifies it. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the description of the neural network, noting that it is hard to understand. It suggests starting the section with the final paragraph that clarifies the description, which provides a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to improve the clarity of the description or provided examples of what aspects are difficult to understand. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks depth and detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the model and suggests exploring attention-based encoder-decoder training as an alternative. While it implies that the authors should consider this option, it does not provide explicit instructions or concrete steps on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative approach. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the model and suggests exploring attention-based encoder-decoder training as an alternative. However, it does not specify which part of the paper this limitation or suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an alternative approach, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of the model and suggests exploring attention-based encoder-decoder training as an alternative. However, it does not provide any supporting evidence, reasoning, or references to justify why the current approach is limited or how attention-based training might be beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the model and suggests exploring attention-based encoder-decoder training as an alternative. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples on how to implement this change or what benefits it might offer. The comment is somewhat helpful as it points out a potential direction for improvement, but it does not offer actionable steps or detailed reasoning to support the suggestion. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what changes should be made to the tables. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 (line 247-252),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the division of tables into three types and suggesting that one type (the column header) should work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any supporting evidence, reasoning, or references to justify why this division is problematic or how it could be improved. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any actionable feedback or suggestions for improvement. Without further explanation or guidance, the authors are left without a clear understanding of what changes, if any, should be made to address this concern. As a result, the comment lacks helpfulness, leaving the authors without direction on how to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. It provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment does not explicitly instruct the authors to use these methods or provide guidance on how to integrate them into their work. While the suggestion is clear, the lack of explicit instructions or detailed guidance on implementation makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"attack methods\" and \"toy setting with classification tasks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper does not consider other classical attack methods in NLP and suggests using examples from specific papers. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment lacks detailed reasoning or references to support why these methods are considered more effective or why the current methods are inadequate. This makes the claim somewhat verifiable, as the authors would need to further explore the rationale behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the attack methods used are naive and that the paper does not consider other classical attack methods in NLP. The reviewer provides specific examples of alternative methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix, which could be considered. This feedback is clear and actionable, as it points out a gap in the paper\\'s analysis and offers concrete suggestions for improvement. However, the comment could be more helpful if it provided additional context or rationale for why these alternative methods are more effective or relevant to the paper\\'s focus. Overall, the comment is mostly helpful as it directs the authors to consider alternative approaches and provides a starting point for enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the impact of mitigation methods or suggestions for improving image quality. As a result, the authors are left without any clear direction on how to improve their draft in response to this comment. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the impact of mitigation methods on the image generation capabilities of diffusion models, suggesting that this could lead to lower image quality. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the mitigation methods affecting image quality. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, which could lead to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their mitigation methods. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance on how to address these concerns or what specific steps the authors should take to mitigate these risks. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper this concern is related to, such as specific sections or experiments where this issue might arise. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specific guidance on how to address these concerns or what steps to take to mitigate the risks. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references to studies or literature that demonstrate similar issues or offer suggestions on how to address them. As a result, the claim is somewhat verifiable, as it provides a logical concern but lacks the necessary evidence or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. While the comment identifies a critical issue, it lacks specific guidance or suggestions on how the authors might address this concern or mitigate the risks. The feedback is somewhat helpful as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes they should make to their draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise about the dominance of function words over content words in a Japanese sentence. However, the comment lacks specificity regarding what aspect of the dominance is surprising or how it might impact the paper. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it lacks any actionable feedback or suggestions for improvement. Without further explanation or context, the authors are left without a clear understanding of what aspect of this observation is relevant to their work or how it might impact their analysis. As a result, the comment does not provide any meaningful guidance for the authors to enhance their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that using the average of multiple k-means objectives with different seeds as a baseline is not ideal and recommends using the minimum k-means objective over multiple seeds instead. The reviewer provides a rationale by referencing two external sources, [1] and [2], which discuss the properties of k-means clustering and its applicability to different datasets. This explicit suggestion and the inclusion of references provide clear guidance on what the authors should consider as a more reasonable baseline. The action is explicit and concrete, as it specifies the change needed and offers concrete evidence to support the claim. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that using the average of multiple k-means objectives with different seeds as a baseline is not ideal and recommends using the minimum k-means objective over multiple seeds instead. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this baseline is used. The comment does provide references to external works, which could help the authors identify the relevant section, but without explicit mention, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using the average of multiple k-means objectives with different seeds as a baseline is not ideal and recommends using the minimum k-means objective over multiple seeds instead. The reviewer provides a rationale by referencing two external sources, [1] and [2], which discuss the properties of k-means clustering and its applicability to different datasets. This provides a logical basis for the claim, as it suggests that using the minimum k-means objective is more reasonable. However, the comment could be strengthened by providing more detailed explanations or examples of how this change would improve the analysis. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks comprehensive justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a minor suggestion to improve the paper by recommending the use of the minimum k-means objective over multiple seeds as a baseline instead of the average of multiple k-means objectives. The reviewer supports this suggestion by referencing two external sources, [1] and [2], which discuss the properties of k-means clustering and its applicability to different datasets. This feedback is clear and actionable, as it offers a specific improvement that could enhance the robustness and accuracy of the analysis. However, the comment could be more helpful if it explained why the average of multiple k-means objectives is not ideal or how the minimum k-means objective would be beneficial. Overall, the comment is mostly helpful as it provides a concrete suggestion for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. While the comment implies that the authors should clarify these differences, it does not provide specific guidance on how to do so or what aspects of the task should be clarified. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to clarify the differences against Argument Mining/Discussion Summarization, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the task described in the paper is closer to Argument Mining rather than Summarization. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks detailed justification or examples to clarify the basis of this assertion, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. While the comment identifies a potential issue with the task classification, it lacks specific guidance on how to clarify these differences or what aspects of the task should be emphasized. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. It points out that the training regularization term (H) requires temperature calibration, but temperature calibration is applied after training. The reviewer asks the authors to clarify this point, which is a clear and explicit action. Additionally, the comment suggests that reducing entropy may make the predictions more confident, which is counter to the paper's motivation to calibrate the networks. This feedback is concrete and provides specific guidance on what the authors need to address to clarify their work. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 155-160,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the relationship between temperature calibration and uncertainty calibration, particularly in the context of the regularization term H. The comment further clarifies the issue by questioning the application of temperature calibration after training. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. The reviewer questions whether temperature calibration is required for both uncertainty calibration and the regularization term H, as stated in lines 155-160. The comment suggests that this is confusing because the training regularization term (H) requires temperature calibration, yet temperature calibration is applied after training. The reviewer also points out that reducing entropy may make the predictions more confident, which is counter to the paper's motivation to calibrate the networks. The comment provides a logical reasoning and a specific observation, making it mostly verifiable. However, it could be strengthened by providing references or examples to support the claim about the impact of reducing entropy on confidence. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant confusion regarding the relationship between temperature calibration and uncertainty calibration, particularly in the context of the regularization term H. It points out that the training regularization term (H) requires temperature calibration, yet temperature calibration is applied after training. This is a critical clarification that the authors need to address to ensure their work is clear and consistent. Additionally, the comment highlights an inconsistency in the paper's motivation, noting that reducing entropy may make predictions more confident, which contradicts the calibration goals. The feedback is clear and actionable, providing the authors with specific guidance on how to clarify their work and address the identified issues. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of an important reference, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. It also highlights the importance of discussing similarities and differences with Lista and placing the paper in appropriate context. While the comment identifies the missing reference and the need for contextualization, it does not provide specific guidance on how to integrate these elements into the paper. The action is clear but lacks detailed instructions on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the missing reference, \"Lista,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the importance of discussing similarities and differences with the reference and placing the paper in appropriate context. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an important reference is missing, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. The reviewer suggests that the paper should discuss similarities and differences with \"Lista\" and place itself in appropriate context. While the comment identifies the missing reference, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of discussing similarities and differences, and the contextualization of the paper. Therefore, the comment is somewhat verifiable, as it provides a clear direction but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically the absence of an important reference, \"Lista,\" which is relevant to the idea of unrolling. It highlights the importance of discussing similarities and differences with \"Lista\" and placing the paper in appropriate context. This feedback is clear and actionable, as it directs the authors to include a missing reference and provide a more comprehensive discussion of their work in relation to existing literature. However, the comment could be more helpful if it offered specific suggestions on how to integrate these elements into the paper or provided examples of how similarities and differences might be discussed. Overall, the comment is mostly helpful as it effectively points out a critical oversight and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the linear program in Theorem 3 needs to be explained more intuitively. It acknowledges that this is a main theorem but suggests that providing an explanation of the objective and constraints in (3) would be beneficial for the reader. This feedback is clear and provides a concrete action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of the objective and constraints in (3) of the linear program. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the linear program in Theorem 3 needs to be explained more intuitively. While it acknowledges that this is a main theorem, it does not provide specific reasoning or examples to support why the explanation is necessary or how it would benefit the reader. The comment lacks detailed justification or references to common practices or standards, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need to provide a more intuitive explanation of the linear program in Theorem 3. It acknowledges that this is a main theorem but emphasizes the importance of explaining the objective and constraints in (3) to enhance the reader\\'s understanding. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work that could enhance its clarity and accessibility. However, the comment could be more helpful if it included specific suggestions on how to present this explanation or examples of how similar concepts have been explained in other works. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the FLOT cost matrix in Algorithm 1 is not defined, which is a clear and explicit action for the authors to take. The comment provides a specific issue to address, indicating that the cost matrix should be defined. However, it does not offer guidance on how to define it or provide examples of what such a definition might look like. While the action is explicit, the lack of concrete details on implementation makes the comment somewhat vague. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"FLOT cost matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of a definition for the FLOT cost matrix in Algorithm 1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their work. However, the comment lacks depth and does not provide suggestions on how to define the matrix or what implications this might have for the paper. While it highlights an important area for improvement, it could be more helpful with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the convergence of the bound in Theorem 2, Eq. (30), and compares it to a similar bound in a reference work. It suggests that the authors should prove whether the second term in Eq. (30) also converges to 0. The comment is explicit in its request for the authors to address this question, providing a clear action for the authors to take. However, it does not specify how to prove the convergence, leaving some ambiguity. Therefore, the comment is mostly actionable, as it provides a direct action but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 2, Eq. (30)\" and \"the bound in [Grunewalder et al, 2010], Eq. (27)\", allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the convergence of the bound in Theorem 2, Eq. (30), and suggests that the authors should prove whether the second term in Eq. (30) also converges to 0. The comment provides a clear direction for improvement by asking for a proof, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the convergence of a bound in Theorem 2, Eq. (30), and compares it to a similar bound in a reference work. The reviewer suggests that the authors should prove whether the second term in Eq. (30) also converges to 0. While the comment identifies a potential issue, it lacks specific reasoning or evidence to support the claim that the bound in Theorem 2 does not converge to 0. The suggestion to prove the convergence is logical, but without additional context or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the convergence of a bound in Theorem 2, Eq. (30), and compares it to a similar bound in a reference work. It suggests that the authors should prove whether the second term in Eq. (30) also converges to 0. While the comment identifies a potential weakness in the paper, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a specific area for improvement, but it could be more beneficial if it included suggestions on how to prove the convergence or examples of similar proofs. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions and points of confusion regarding the algorithm, specifically regarding the use of \"avg\" and the meaning of \"j'\" and \"i'\". While it identifies areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take to address these issues. The authors are left to infer that they need to clarify these points, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the use of \"avg\" and the meaning of \"j'\" and \"i'\". This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity of Algorithm 2, specifically regarding the use of \"avg\" and the meaning of \"j'\" and \"i'\". It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification and does not make a claim that needs justification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies several areas of confusion and potential improvement in the paper, specifically regarding the clarity of Algorithm 2 and the use of \"avg.\" It points out that \"j'\" and \"i'\" are not defined, which could be important for understanding the algorithm. The comment acknowledges the authors\\' response and expresses a desire to keep the initial scores. However, it does not provide specific suggestions or guidance on how to clarify these points or improve the algorithm. While it highlights areas that need attention, the feedback lacks depth and actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on the definition of the sparsity of the residual term and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. It also recommends showing the advantages of the proposed method compared to existing methods. While the comment provides clear and specific actions for the authors to take, it does not offer detailed guidance on how to present this evidence or what specific aspects to focus on. The authors are given a clear direction but may need to infer the exact steps to follow. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"specific definition of the sparsity of the residual term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the definition and suggests providing evidence to support the sparsity assumption across various noisy cases. Additionally, it recommends comparing the proposed method with existing methods to show its advantages. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It suggests that the authors should provide evidence to support the sparsity assumption across various noisy cases and compare the proposed method with existing methods to show its advantages. While the comment identifies a potential issue with the clarity of the definition, it lacks specific examples or references to support the claim that the sparsity assumption is not well-founded. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to address the issue effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the definition of the sparsity of the residual term in the paper. It suggests that the authors provide evidence to support the sparsity assumption across various noisy cases and recommends comparing the proposed method with existing methods to show its advantages. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and robustness of their work. By addressing these points, the authors can enhance the understanding and credibility of their method. However, the comment could be more helpful if it provided specific examples or references to existing methods that could be used for comparison. Overall, the comment is mostly helpful as it effectively directs the authors to improve the clarity and substance of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to the terminology. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the term \"connectivity,\" explaining that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the term \"connectivity,\" noting that it is misleading as it does not refer to the structural connections between the brain and body. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and precision of the terminology. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or what alternative terminology might be more appropriate. While it points out a relevant concern, it does not offer actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what aspects are missing or how to address these issues. The authors are left to infer that they need to improve the clarity, quality, novelty, and reproducibility of their work, but without concrete suggestions or examples, they may struggle to know exactly what changes to make. The comment is vague and lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are missing these details, making it difficult for the authors to pinpoint the exact sections that need improvement. Additionally, the comment references \"Clarity, Quality, Novelty And Reproducibility,\" but does not provide specific examples or details from these sections. This lack of specificity and grounding makes it challenging for the authors to understand and address the issues effectively. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas where the paper is lacking, including clarity, quality, novelty, and reproducibility. However, it does not provide specific examples or detailed feedback on what aspects of these categories are missing or how they could be improved. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or suggestions, the authors are left without actionable guidance on how to address these issues. The comment lacks depth and specificity, making it barely helpful for the authors in improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit guidance on what the authors should do to improve their draft. It suggests that the authors should study the essentialness of using an orthogonal matrix weight for the local window MLP, which is not currently presented. This feedback is clear and concrete, as it specifies the need for further exploration and validation of the orthogonal matrix weight. The authors know exactly what needs to be done to address this point, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the importance of studying the essentialness of using an orthogonal matrix weight for the local window MLP. The comment provides a clear direction for the authors to improve their draft by suggesting that they should explore the validity of using an orthogonal matrix weight. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Step 2 and Step 3 are important for validating the essentialness of using an orthogonal matrix weight for the local window MLP. The reviewer suggests that Step 2 can be done regardless of the weight matrix, and Step 3 is crucial for orthogonal weight matrices. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors may find it challenging to fully understand and address the claims without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that needs improvement, namely the lack of exploration into the essentialness of using an orthogonal matrix weight for the local window MLP. It suggests that Step 2, which involves the transpose of the matrix, can be done regardless of the weight matrix, and that Step 3 is crucial for orthogonal weight matrices. The comment highlights the importance of studying the validity of using an orthogonal matrix weight, which is not currently presented in the paper. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft. However, it could be more helpful if it included specific suggestions or examples of how to conduct this study. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 4-5. It does not provide any explicit or implicit actions for the authors to take, such as suggesting further analysis or experiments to address the issue. The comment lacks guidance on how the authors might investigate or resolve the drop in accuracy. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the drop in accuracy after a certain order around 4-5 and asks if it is due to overfitting. This provides clear guidance on what needs to be addressed in the paper, namely the explanation of the drop in accuracy. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification regarding the drop in accuracy in Figure 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 4-5. It does not provide any analysis or suggestions for the authors to address this issue, leaving them without actionable feedback or guidance on how to improve their draft. The comment is vague and lacks depth, making it barely helpful for the authors in understanding and addressing the issue. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the models and datasets used are too toy-like and recommends using CIFAR100, ResNet 34 or 50, and ViT-tiny or small. It also asks if there are foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\\'s score. While the comment provides specific recommendations for datasets and models, it lacks concrete guidance on how to implement these changes or what specific aspects of the language tasks should be addressed. The action is explicit but somewhat vague, as the authors know what changes to make but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the models and datasets, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the need for CIFAR100, ResNet 34 or 50, and ViT-tiny or small, and raises questions about language tasks. However, the comment does not provide specific guidance on how to address these issues or what aspects of the language tasks should be considered. Therefore, it is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the models and datasets used are \"toy-like\" and suggests that the authors should consider using CIFAR100, ResNet 34 or 50, and ViT-tiny or small. The reviewer also asks about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\\'s score. While the comment provides a logical reasoning for the need for more diverse datasets and models, it lacks specific examples or references to support the claim that the current models are too toy-like. The suggestion to use CIFAR100 is a specific example, but the comment could be strengthened by providing more detailed reasoning or examples. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks sufficient evidence or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the models and datasets used in the paper, noting that they are too toy-like and suggesting the inclusion of more challenging datasets like CIFAR100, ResNet 34 or 50, and ViT-tiny or small. It also raises a question about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\\'s score. While the comment provides clear and actionable feedback on improving the dataset and model selection, it could be more helpful if it offered specific guidance on how to address the language task challenges or provided examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful as it directs the authors to make significant improvements in their work, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of natural ablation studies, specifically mentioning the impact of pretraining on scratchGAN. It suggests that this is a crucial baseline to include, especially given the central argument against pretraining. The comment also includes minor comments and questions, such as the need for more discussion on the results. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to implement these changes or what specific aspects of the ablation studies should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of natural ablation studies, specifically mentioning scratchGAN and the need for a baseline with pretraining. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a baseline with pretraining and the need for more discussion on the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that some natural ablation studies are missing, specifically mentioning the impact of pretraining on scratchGAN. The reviewer claims that this is a crucial baseline to include, as it relates to the central argument against pretraining. However, the comment lacks specific examples or detailed reasoning to support why this baseline is crucial or how it would impact the central argument. The suggestion is somewhat verifiable, as it provides a direction for improvement but requires more detailed justification to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of natural ablation studies, particularly the impact of pretraining on scratchGAN. This is a crucial baseline that could strengthen the paper\\'s argument against pretraining. Additionally, the comment includes minor comments and questions, such as the need for more discussion on the results. While the comment provides actionable feedback, it could be more helpful if it offered specific guidance on how to conduct these ablation studies or what aspects of the results should be discussed. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides some additional suggestions for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. It also points out that the authors pad the shorter sequence by replicating its last state to compare both trajectories, which could lead to an increase in the distance with T and favor longer trajectories. The reviewer suggests that these decisions should be explained in the paper to avoid readers needing to check the code. The comment provides clear and concrete actions for the authors to take, ensuring that they know exactly what needs to be addressed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the handling of comparisons between episodes with different lengths and the use of padding to compare trajectories. The comment provides a detailed explanation of the issue and suggests that the authors should explain these decisions in the paper to avoid readers needing to check the code. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. The reviewer provides specific observations, such as the use of padding to compare trajectories and the lack of a normalization factor of 1/T, which could lead to an increase in distance with T and favor longer trajectories. These observations are supported by logical reasoning and specific examples from the code, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or references to similar issues in the literature. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific issue with the paper regarding the handling of comparisons between episodes with different lengths in the equation between lines 282 and 283. It points out that the authors pad the shorter sequence by replicating its last state, which could lead to an increase in distance with T and favor longer trajectories. The reviewer suggests that these decisions should be explained in the paper to avoid readers needing to check the code. This feedback is clear and actionable, providing the authors with a concrete step to improve their draft by clarifying their methodology. By addressing this issue, the authors can enhance the clarity and transparency of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential oversight in the experiment, noting that the Vision Transformer was not considered and questioning its applicability to larger image datasets like ImageNet. It also raises a question about the pruning strategy in self-attention layers. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they should consider including the Vision Transformer and address the pruning strategy question, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiment, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of the Vision Transformer model and raises questions about its applicability to larger datasets like ImageNet. The comment also questions the pruning strategy in self-attention layers, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment did not consider the Vision Transformer, which is an important SOTA model in image classification. It also questions whether such a technique would still work for larger datasets like ImageNet. The comment suggests that the pruning strategy in self-attention layers might differ. While the comment identifies a potential oversight, it lacks specific examples or references to support the claim that the Vision Transformer is an important model. The suggestion to consider it is logical, but the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential oversight in the experiment by noting the absence of the Vision Transformer, an important SOTA model in image classification. It raises a question about the applicability of the technique to larger datasets like ImageNet and questions the pruning strategy in self-attention layers. While the comment highlights important areas for consideration, it lacks specific suggestions or guidance on how to address these issues. The authors are given a clear direction to consider the Vision Transformer and its potential impact, but the feedback could be more actionable with additional details or examples. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of comparison against baselines and notes that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. It suggests that this is a widely-understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison (or codesearch). While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include comparisons against baselines, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide specific steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the lack of comparison against baselines and the need for architecture-agnostic similarity comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparison against baselines and that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. The reviewer supports this claim by referencing the widely-understood nature of binary analysis applications and the existence of architecture-agnostic similarity comparison (or codesearch) in many papers. This provides a logical basis for the claim, but the comment could be strengthened by providing specific examples or references to these papers. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of comparison against baselines and the limited scope of the functionality similarity comparison study. It highlights that this is a widely-understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison (or codesearch). This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific suggestions on how to address this gap, such as which baselines to consider or how to implement the suggested architecture-agnostic similarity comparison. Overall, the comment is mostly helpful as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention that the preprocessing in SI 6.5 is identical to that in Mnih et al. [7], but the evaluation is slightly different due to the absence of human starts. This feedback provides a clear and direct action for the authors to take, ensuring they are aware of the need to clarify this point in their paper. The comment is specific and concrete, giving the authors a clear idea of what to include in their draft to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to mention that the preprocessing is identical to that in Mnih et al. [7], despite the evaluation being slightly different due to the absence of human starts. This provides clear guidance on what the authors need to include in their paper to clarify this point. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in SI 6.5 is slightly different from that in Mnih et al. [7] due to the absence of human starts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the evaluation in SI 6.5 is slightly different from that in Mnih et al. [7] due to the absence of human starts. This feedback is clear and actionable, as it directs the authors to clarify this point in their paper. By mentioning the source of the preprocessing, the authors can ensure that they are transparent about the evaluation process and its differences from the original work. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining the implications of the evaluation differences or suggesting ways to improve clarity. Overall, the comment is mostly helpful as it directs the authors to a specific area for clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the figures, including the size of the text, the clarity of the inputs and outputs, and the self-contained nature of the captions. While it points out these problems, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to improve the readability and clarity of the figures, but the comment lacks concrete suggestions or examples on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the figures, such as the small text size, unclear inputs and outputs, and the lack of self-contained captions. This provides clear guidance on what needs to be addressed to improve the clarity and readability of the figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the figures in question are difficult to parse due to small text size, unclear inputs and outputs, and lack of self-contained captions. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support why these elements are problematic or how they impact the clarity of the figures. The lack of specific examples or references makes it difficult for the authors to understand and address the issues effectively. Therefore, the claim is somewhat verifiable, as it provides some basis but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the figures in the paper, noting that the texts in the figures are too small, the inputs and outputs are not clearly explained, and the captions are not self-contained. It also points out the difficulty in linking the figures to the main text. This feedback is clear and actionable, as it provides the authors with a concrete understanding of what needs to be improved in terms of figure clarity and readability. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending font size adjustments or providing examples of how to improve the figure captions. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims advantages over previous work in terms of efficiency but does not provide any metrics to substantiate these claims. This implies that the authors need to include metrics or comparisons to demonstrate the efficiency of their proposed method. While the action is explicit in requiring the inclusion of metrics, it is somewhat vague in detailing which metrics should be used or how they should be presented. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss advantages over previous work in terms of efficiency. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of metrics to demonstrate the efficiency of the proposed method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method. However, it does not provide any supporting evidence or examples to substantiate this claim. Without specific metrics or comparisons to previous work, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, noting that while the authors claim advantages over previous work in terms of efficiency, they do not provide any metrics to substantiate these claims. This is a significant oversight, as metrics are essential to demonstrate the effectiveness of the proposed method. The comment is clear and actionable, as it directly instructs the authors to include metrics to support their claims. However, it could be more helpful if it provided specific suggestions on which metrics to use or how to present them effectively. Overall, the comment is mostly helpful as it highlights a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to expand the contribution or what specific aspects of the paper could be strengthened. As a result, the authors are left without any clear direction on how to address the reviewer\\'s concerns. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention or improvement. The comment is specific in identifying the issue of limited contribution, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment lacks specific examples or detailed reasoning to support why the contribution is considered limited. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it acknowledges that this is an important factor but still considers the contribution limited. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors could enhance the contribution or address the issue of overfitting. Without actionable feedback or detailed insights, the authors may find it challenging to improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide enough detail for the authors to effectively address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the state-space, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment provides clear and direct actions, it does not specify how to implement these changes or what specific details should be included. The authors are left to infer the exact steps to take, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as providing more details about the state-space, whether it is finite or continuous, and the actions involved. The comment also questions the space in which theta lies and suggests that the authors should be precise in their explanations. This level of detail provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for more details about the state-space, whether it is finite or continuous, and the actions involved. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a lack of detail in the paper, specifically asking for more information about the state-space, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment highlights areas where the paper could be more detailed, it does not provide specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it points out potential gaps in the paper, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the method's effectiveness on general reasoning tasks or suggestions for potential improvements. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method are not effective on general reasoning tasks or how they could be improved. Without clear guidance on where to focus the revision or what changes are needed, the authors are left without a clear path for action. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential weakness in the method's effectiveness on general reasoning tasks compared to mathematical reasoning. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the method\\'s performance. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The reviewer also mentions that the authors acknowledge this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the proof technique and its applicability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Appendix A,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The comment further specifies that this issue is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof technique in Appendix A relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. The reviewer provides a specific reference to Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. This reference provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. This is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment highlights a potential weakness in the paper, it does not provide actionable suggestions or guidance on how the authors might address this issue or improve the proof technique. The feedback is somewhat helpful as it points out a specific area for improvement, but it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. It also proposes using a conditional framework based on GDSS, as suggested in recent work [2]. While the comment provides a clear action to take, it lacks specific guidance on how to implement this suggestion or what aspects of the conditional framework should be considered. The authors are left with a general idea of what to do but without detailed instructions on how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison of the continuous diffusion model (e.g., GDSS) as a baseline in Table 3 and the suggestion to use a conditional framework based on GDSS. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. The reviewer provides a logical reasoning by pointing out that the continuous diffusion model should be considered as a baseline for the conditional generation task. However, the comment lacks specific examples or references to support the claim that GDSS does not explicitly present a conditional framework. This makes the claim somewhat verifiable, as the authors would need to further explore the rationale themselves to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to compare the continuous diffusion model (e.g., GDSS) as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. It also suggests using a conditional framework based on GDSS, as proposed in recent work [2]. This feedback is valuable as it directs the authors to a specific area for improvement and provides a concrete suggestion for enhancing the comparison in their study. However, the comment could be more helpful if it included specific examples or references to the conditional framework or detailed guidance on how to implement this suggestion. Overall, the comment is mostly helpful as it offers clear and actionable advice, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection. The reviewer provides a rationale for this suggestion, stating that LiDAR-based segmentation is the best choice due to its ability to learn accurate locations and poses, especially in benchmarks using IoU-based metrics like KITTI and Waymo. However, the comment does not provide explicit instructions or concrete steps on how to implement this change or what specific aspects of the current approach need to be adjusted. While the suggestion is clear, the lack of detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this change could be implemented. The comment also lacks specificity regarding why LiDAR-based segmentation is considered the best choice or how it would improve the paper. Without explicit references or detailed reasoning, the authors cannot confidently determine which parts of the paper need revision. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that LiDAR-based segmentation is a better choice for the downstream task than object detection, based on the reviewer\\'s personal belief. The comment provides a rationale for this opinion by stating that LiDAR-based segmentation can learn accurate locations and poses, especially in benchmarks using IoU-based metrics like KITTI and Waymo. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the reasoning is logical, it could be strengthened with more detailed evidence or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the suggestion but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a personal opinion on the choice of downstream task, suggesting that LiDAR-based segmentation is a better option than object detection. The reviewer provides a rationale for this suggestion by stating that LiDAR-based segmentation can learn accurate locations and poses, especially in benchmarks using IoU-based metrics like KITTI and Waymo. However, the comment lacks specific guidance or suggestions on how the authors might implement this change or what aspects of their current approach might be improved by using LiDAR-based segmentation. While the feedback provides a direction for improvement, it does not offer actionable steps or detailed reasoning, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential contradiction between the objective of Equation (12) and the Inverse Proportionality Principle (IPO). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this contradiction or suggestions for clarifying the issue. Without actionable advice or steps, the authors are left without a clear understanding of what changes, if any, are needed to resolve this issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the objective of Equation (12) and its potential contradiction with the Inverse Proportionality Principle (IPO). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the contradiction and suggesting a potential resolution, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the objective of Equation (12) is in contradiction with the Inverse Proportionality Principle (IPO). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential contradiction between the objective of Equation (12) and the Inverse Proportionality Principle (IPO). This is a critical observation that could impact the validity and applicability of the work. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or clarify the contradiction. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to resolving it. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. While the comment explicitly states the action to take, it lacks concrete guidance on how to implement this change or why it is necessary. The authors are left to infer that they should make this change to enhance clarity, but without specific instructions or examples, the action remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of \"t\" in the kernel and the suggestion to replace it with the size of T to improve clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. However, the comment does not provide any reasoning or evidence to support why \"t\" is unclear or why replacing it with the size of T would improve clarity. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific improvement to the clarity of the histogram intersection kernel by recommending the replacement of \"t\" with the size of T. This feedback is actionable and provides a clear direction for the authors to enhance the readability and understanding of their work. However, the comment could be more helpful if it explained why \"t\" is unclear or why the suggested change would improve clarity. Despite this, the suggestion is valuable and offers a straightforward way for the authors to improve their draft, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating ever-growing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the adaptation capacity. The comment lacks actionable details, such as recommending specific experiments or modifications to the model architecture. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the adaptation capacity of the proposed visual memory in accommodating ever-growing concepts, specifically questioning whether the image encoder can produce meaningful embeddings for new concepts. However, it does not specify which part of the paper this concern is discussed in, making it weakly grounded. The comment is specific in its questioning of the adaptation capacity for different types of concepts, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating ever-growing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, the comment lacks specific examples or references to support the claim that the adaptation capacity might be an issue for certain types of concepts. Without detailed evidence or reasoning, the claim remains somewhat verifiable, as it provides a logical basis but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the adaptation capacity of the proposed visual memory when accommodating ever-growing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. While the comment identifies a potential weakness in the model\\'s ability to adapt to new concepts, it lacks specific suggestions or guidance on how the authors might address this concern or improve the adaptation capacity. The feedback is somewhat helpful as it points out a potential issue but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should include a comparison against state-of-the-art loss functions commonly used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This is a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment provides a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a comparison against state-of-the-art loss functions commonly used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. However, it does not specify which part of the paper this comparison should be added to, such as the results or discussion sections. The authors can infer that it relates to the experimental evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting what needs to be added. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions commonly used in face/iris verification. This claim is somewhat verifiable as it provides a logical suggestion for enhancing the paper\\'s contribution by including a comparison with established methods. However, the comment lacks specific examples or references to these state-of-the-art loss functions, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should include a comparison against state-of-the-art loss functions commonly used in face/iris verification. This is a clear and actionable suggestion that could significantly enhance the paper\\'s contribution by demonstrating the effectiveness of the proposed method against established benchmarks. By including this comparison, the authors can provide a more robust evaluation of their work and potentially improve its impact. However, the comment could be more helpful if it specified which loss functions should be included or provided examples of how they might be used in the comparison. Overall, the comment is mostly helpful as it offers a concrete direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take, such as giving the EF and D2 transcription norms, correcting specific phrases in the text, and addressing issues with repeated words in a table. Additionally, it points out a discrepancy in the DOI number and the link behind the title. These actions are clear and specific, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines and tables in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the phrasing in lines 029 and 188, the repeated words in Table 3, and the discrepancy in the DOI number. The comment provides clear guidance on what needs to be corrected or clarified, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of technical corrections and observations, such as correcting phrasing, addressing repeated words, and pointing out discrepancies in the DOI number. These are factual statements that do not involve subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a mix of technical corrections and observations, which can be beneficial for the authors in improving the clarity and accuracy of their work. It points out specific errors in phrasing and formatting, such as correcting \"lightweight\" to \"in a lightweight\" and \"PLN\" to \"NLP.\" Additionally, it highlights a discrepancy in the DOI number and the link behind the title, which could be confusing for readers. However, the comment lacks broader context or suggestions for improvement beyond these specific corrections. While it identifies some areas for enhancement, it does not provide a comprehensive overview of the paper\\'s strengths or weaknesses. Therefore, the comment is somewhat helpful, as it offers actionable feedback but could be more comprehensive to be highly helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the notation used in the paper, including the lack of definitions for M and N and the small font size in Figure 1. It provides a specific suggestion to spell out F.L.T.R in Figure 4 and recommends cross-referencing notation and figures to avoid confusion. While the comment does not explicitly instruct the authors to make these changes, the suggestions are clear and actionable, providing concrete steps for the authors to improve the clarity and readability of their paper. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as spelling out F.L.T.R in Figure 4 and making the text larger. The comment also suggests cross-referencing notation and figures to avoid confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation is confusing and suggests spelling out F.L.T.R in Figure 4. It also mentions that the font size in Figure 1 is too small to see and recommends cross-referencing notation and figures. While the comment identifies specific issues with the notation and figure presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to cross-reference notation and figures is a logical step, but the comment could be strengthened with more detailed justification or examples. Therefore, the claim is somewhat verifiable, as it provides some support but lacks comprehensive evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including confusing notation and font size in figures. It provides specific suggestions for improvement, such as spelling out F.L.T.R in Figure 4 and making the text larger in Figure 1. Additionally, it recommends cross-referencing notation and figures to avoid confusion. These suggestions are clear and actionable, offering the authors a concrete path to enhance the clarity and readability of their draft. However, the comment could be more helpful if it provided additional guidance on how to address the confusion in the notation or why it is important to cross-reference figures. Overall, the comment is mostly helpful as it effectively directs the authors to specific areas for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. While the comment identifies an issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should clarify or rename the variable to avoid confusion. The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm1\" and \"Phase 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2, suggesting that this might be confusing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using \"$p$\" to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2 might be confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it points out a specific issue that could be clarified or addressed to improve the clarity of the paper. However, the comment could be more helpful if it provided suggestions on how to clarify or rename the variable to avoid confusion. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from a more detailed mathematical formulation, particularly in the appendix, to enhance the understanding of the approach. It also points out that the figure is confusing and recommends adding text labels to clarify its purpose and align it with the main contribution of the paper, which is improvements on the WiC task. The comment provides specific suggestions for reworking the figure to better align with the WiC task, offering actionable steps for the authors to improve their draft. The explicit nature of these suggestions and the concrete guidance on how to implement them make the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"high-level description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for a more detailed mathematical formulation in the appendix and the confusion caused by the figure, including the need for text labels and better alignment with the main contribution of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the high-level description and figure could benefit from a more detailed (e.g., mathematical) formulation and that the figure is confusing due to its abstract nature and lack of alignment with the main contribution of the paper. The reviewer provides specific suggestions, such as adding text labels and aligning the figure with the WiC task, to improve clarity and understanding. These suggestions are based on logical reasoning and specific observations, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to similar works that have successfully addressed similar issues. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the paper\\'s presentation, suggesting that the high-level description could benefit from a more detailed mathematical formulation, particularly in the appendix. It also points out that the figure is confusing and recommends adding text labels to clarify its purpose and better align it with the main contribution of the paper, which is improvements on the WiC task. The comment offers a clear and constructive suggestion for reworking the figure to better serve its intended purpose, making it highly helpful for the authors to enhance the clarity and effectiveness of their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide specific guidance on which tasks should be included or how they should be conducted. The action is implicit, as the authors can infer that they should consider including additional benchmarking tasks, but it lacks concrete details on what those tasks should be or how to implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not specify which parts of the paper should include these tasks or which specific benchmarking tasks should be considered. Without explicit references to sections, figures, or specific benchmarking tasks, the authors cannot confidently determine which parts of the paper need revision. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide specific examples or guidance on which tasks should be included or how they could enhance the paper. Without detailed suggestions or examples, the authors are left with a general recommendation but no clear path for implementation. This limits the comment\\'s usefulness in helping the authors improve their draft. Therefore, the comment is rated as barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on the comparison results between YOSO and linformer in terms of iteration-wise convergence and accuracy in downstream tasks. It also suggests that an explanation should be provided to analyze the difference in performance. The feedback is clear and provides specific actions for the authors to take, such as including the steps vs PPL of linformer with YOSO in Figure 4 and analyzing the performance difference. The comment is concrete and provides detailed guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experiments: YOSO takes linformer as baselines,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the lack of comparison results between YOSO and linformer in terms of iteration-wise convergence and accuracy in downstream tasks. The comment also suggests an explanation for the difference in performance between YOSO and linformer. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the lack of comparison results between YOSO and linformer in terms of iteration-wise convergence and accuracy in downstream tasks. It suggests that linformer demonstrates better performance in these tasks, and asks for an explanation of this difference. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to make a significant effort to verify the claim themselves, as the comment lacks detailed evidence or reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the pre-training experiment part does not provide steps vs PPL of linformer with YOSO in Figure 4. It also questions the comparison result of YOSO with linformer on iteration-wise convergence and suggests an explanation for the difference in performance between the two models. Additionally, it points out that linformer demonstrates better accuracy in downstream tasks such as SST-2. The comment provides clear and actionable feedback by asking for specific comparisons and explanations, which can help the authors improve the clarity and depth of their experimental results. However, it could be more helpful if it offered suggestions on how to present these comparisons or what specific aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward enhancing their experimental analysis and explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. While it identifies the issue, it does not provide explicit guidance on how the authors should address this discrepancy. The comment lacks concrete suggestions or actions for the authors to take, such as suggesting a correction or clarification in the abstract or text. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract and the text, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract statement about requiring the proposal distribution to upper bound the target everywhere is not true, as the authors themselves clarify in the text. However, the comment does not provide specific references or examples from the text to support this claim, making it difficult for the authors to verify the accuracy of the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This is a critical issue that could impact the validity of the paper\\'s claims. However, the comment does not provide specific guidance or suggestions on how the authors might address this discrepancy or clarify the text. While it points out a potential problem, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an important issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a confusion regarding the name \"PointNet\" in Figure 1, noting that it is not mentioned in the paper and that there is another paper with the same name. The reviewer suggests that the authors should clarify this issue by referring to the correct paper or providing a footnote. This feedback is explicit and provides concrete guidance on how to address the confusion. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"PointNet,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reference to \"PointNet\" in Figure 1, noting that it is confusing because it does not appear in the paper and there is another paper with the same name. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that referring to \"PointNet\" in Figure 1 is confusing because it does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference to the correct paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" which supports the claim by providing a clear example of the correct reference. This makes the claim mostly verifiable, as it provides a logical basis for the confusion and offers a solution to clarify the reference. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, noting that it is confusing because it does not appear in the paper and there is another paper with the same name. This feedback is clear and actionable, as it provides the authors with a concrete example of a potential confusion and suggests a solution by referencing the correct paper. By addressing this issue, the authors can improve the clarity and accuracy of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to avoid similar confusions in future work. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the policy gradient and the phrases in question. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. However, the comment does not specify which part of the paper these issues are located in, making it weakly grounded. The comment is specific in detailing what needs to be clarified or addressed, but without explicit references to sections or lines, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and observations about the policy gradient in Equation 6 and its relation to the optimal problem. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, seeking clarification or explanation. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect to ensure that the policy gradient is indeed solving the optimal problem. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification and potential improvements, it does not provide specific guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it highlights areas that need attention, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. While it does not explicitly instruct the authors to make a specific change or provide guidance on how to address this question, it does prompt the authors to consider the implications of these assumptions and the potential differences between them. The action is implicit but concrete, as the authors can infer that they need to explore the implications of these assumptions and potentially make a change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these assumptions are discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its inquiry about the difference between these distributions, it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm, seeking clarification on the difference between these distributions. While it identifies a potential area of confusion or misunderstanding, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or constructive advice, making it barely helpful for the authors in terms of improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to discuss the limitations of freezing the partitioning in the first iteration, which seems like a risky choice. This feedback is clear and provides a specific action for the authors to take, which is to address the limitations of this choice. The comment is concrete because it specifies the need for a discussion on the limitations, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the risky choice of freezing the partitioning in the first iteration and the need to discuss the limitations of this choice. This provides clear guidance on what the authors need to address in this section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. However, the comment does not provide specific reasoning or examples to support this claim. It lacks detailed justification or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of freezing the partitioning in the first iteration, noting that it may be a risky choice that assumes strong coverage of the initial data. It suggests that the authors should discuss the limitations of this choice, which is a valuable point for the authors to consider. However, the comment could be more helpful if it provided additional context or examples to support the claim about the risks involved. While it highlights an important area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the intent of Section 5.2, indicating that the authors need to clarify or provide more context for this section. However, it does not offer any specific guidance or suggestions on how to address this issue. The action is implicit and vague, as the authors are left to infer that they need to provide more information or clarification about the section. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the intent of this section, indicating that the authors need to clarify or provide more context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the intent of Section 5.2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the intent of Section 5.2, indicating that the authors need to clarify or provide more context for this section. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The comment is somewhat helpful as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. It acknowledges that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not provide specific guidance on what aspects need clarification or how to clarify them. It lacks concrete suggestions or examples of what the authors should focus on to improve the clarity of their approach. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights that many aspects of the approach need clarification and expresses concern about the interaction between knowledge about objects and verbs. It mentions that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not specify which parts of the paper need clarification or provide detailed comments. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in identifying the need for clarification but lacks grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that many aspects of the approach need clarification and expresses concern about the interaction between knowledge about objects and verbs. It suggests that the paper lacks a clear explanation of the overall approach and its benefits, diving into technical details too quickly. However, the comment does not provide specific examples or detailed reasoning to support these claims. The lack of specificity and detailed evidence makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas where the paper needs clarification, particularly regarding the interaction between knowledge about objects and verbs in the approach. It expresses concern about the lack of a clear explanation of the overall approach and its benefits, noting that the paper dives into technical details too quickly without providing a comprehensive understanding. While the comment highlights important areas for improvement, it does not offer specific suggestions or guidance on how to clarify these aspects. The authors are left with a general sense of what needs to be addressed but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\\'s level of access, capabilities, and the defender\\'s available resources. It also recommends including this information in a dedicated section to enhance clarity. This feedback provides clear and concrete actions for the authors to take, such as creating a new section or expanding the existing one to address the clarity issues. The explicit nature of the suggestion and the detailed guidance on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, including the attacker\\'s level of access, capabilities, and the defender\\'s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\\'s level of access, capabilities, and the defender\\'s available resources. This claim is somewhat verifiable as it logically suggests that such clarification would enhance the clarity of the paper, particularly around the assumed white-box access to the victim model. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires further clarification, namely the threat model. It suggests that the authors should define the assumed threat model more explicitly, including the attacker\\'s level of access, capabilities, and the defender\\'s available resources. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity of their work. By suggesting a dedicated section for this information, the reviewer offers a practical way to improve the paper\\'s organization and presentation. However, the comment could be more helpful if it included specific examples or references to similar works that have successfully addressed this issue. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests an explanation for the decision to use early stopping only based on link prediction accuracy. It does not provide suggestions for alternative explanations or methods to consider. The action is clear and concrete, as the authors know exactly what needs to be addressed: providing an explanation for the decision. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely an explanation for the decision to use early stopping only based on link prediction accuracy. The comment provides a clear direction for improvement by asking for an explanation of why not to average with type accuracy. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the decision to use early stopping only based on link prediction accuracy, suggesting that an explanation is needed. However, it does not provide any reasoning or evidence to support why this decision might be problematic or inadequate. Without additional context or examples, the claim lacks verifiability, as it does not provide a clear basis for the authors to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires further explanation, namely the decision to use early stopping only based on link prediction accuracy. It suggests that an explanation is needed, such as why not to average with type accuracy. This feedback is clear and actionable, as it directs the authors to provide a rationale for their choice, which could enhance the clarity and transparency of their methodology. However, the comment could be more helpful if it provided additional context or examples of alternative methods that could be considered. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and justification of their methodology.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the paper\\'s statement about class-imbalanced tasks in the few-shot learning setting. It explicitly asks the authors to provide concrete details on how to set a reasonable class-imbalanced task, given the few examples available for each class. This request is clear and specific, providing the authors with a direct action to take in order to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"sampling class-imbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how to set a reasonable class-imbalanced task in the few-shot learning setting, given the limited number of examples per class. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement \"sampling class-imbalanced tasks\" in the context of few-shot learning, where each class has only a few examples. The reviewer asks for concrete details on how to set a reasonable class-imbalanced task in this setting. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s statement about class-imbalanced tasks in the few-shot learning setting. It questions how to set a reasonable class-imbalanced task given the limited number of examples per class. The comment is somewhat helpful as it prompts the authors to provide concrete details on how they address this issue, which is an important aspect of their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to set a reasonable class-imbalanced task. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the chat-gpt baseline is rudimentary and recommends testing a few-shot approach. It also proposes including discourse relation information in the prompts, potentially in a Chain-of-Thought style approach. While the comment provides a clear action to test a few-shot approach and includes a suggestion for enhancing the baseline, it lacks specific guidance on how to implement these changes or what specific aspects of the few-shot approach should be tested. The action is explicit but somewhat vague in terms of execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the chat-gpt baseline, suggesting that it is rudimentary and recommends testing a few-shot approach. It also proposes including discourse relation information in the prompts, potentially in a Chain-of-Thought style approach. However, the comment does not specify which part of the paper discusses the chat-gpt baseline or the few-shot approach, making it weakly grounded. The suggestion to include discourse relation information is specific, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the chat-gpt baseline is \"very rudimentary\" and suggests testing a few-shot approach. It also proposes including discourse relation information in the prompts, potentially in a Chain-of-Thought style approach. While the comment provides a logical reasoning for the need to test a few-shot approach and includes a suggestion for enhancing the baseline, it lacks specific examples or references to support the claim that the chat-gpt baseline is \"very rudimentary.\" This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the chat-gpt baseline, suggesting that it is \"very rudimentary\" and recommends testing a few-shot approach. It also proposes including discourse relation information in the prompts, potentially in a Chain-of-Thought style approach. This feedback is clear and actionable, as it provides a concrete suggestion for improving the baseline and enhancing the evaluation of the paper. However, the comment could be more helpful if it explained why the few-shot approach is beneficial or how the inclusion of discourse relation information would enhance the baseline. Despite this, the feedback is mostly helpful as it directs the authors to consider these improvements, making it rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning lines 238-239. It points out that the authors only state that they estimate a layer's sensitivity by pruning, but do not provide details on how the actual pruning was done. The comment implies that the authors should provide more information on the pruning process to clarify the methodology. While the action is implicit, it is clear and concrete, as it specifies the need for more detailed information on the pruning process. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 238-239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail on how the ground truth of sensitivity is achieved and the need for more information on the pruning process. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved, specifically mentioning lines 238-239. The reviewer suggests that the authors should provide more information on the pruning process to clarify the methodology. However, the comment lacks specific examples or references to support the claim that the current explanation is insufficient. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary evidence or justification to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved. It points out that the current explanation, which mentions pruning, lacks details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to provide more information on a crucial aspect of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies specific parts of the text that could be written more clearly, such as line 97 regarding proper rotation matrices and line 105-106 regarding the matrix being non positive semidefinite. It provides clear and concrete actions for the authors to take, such as explicitly explaining the concepts in these sections. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the text, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be clarified, such as the definition of a proper rotation matrix and the problem of the matrix being non positive semidefinite. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for clarification regarding specific terms and concepts in the text. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific parts of the text that could be written more clearly, providing actionable feedback for the authors. By pointing out the lack of clarity in lines 97 and 105-106, the comment guides the authors to explicitly explain the concepts of proper rotation matrices and the problem of the matrix being non positive semidefinite. This detailed feedback is valuable as it helps the authors improve the clarity and comprehensibility of their draft, which is essential for effective communication of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It provides a specific example of the activation-pooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is explicit and provides a concrete suggestion for how the authors might improve their draft by changing the terminology. The action is clear and specific, leaving no ambiguity about what the authors need to do to address the comment. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The comment also references the activation-pooling operator introduced by Cohen and Shashua, which helps clarify the suggestion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The reviewer provides a specific example of the activation-pooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This reference provides a logical basis for the suggestion, making the claim somewhat verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It offers a clear and actionable piece of feedback by providing a concrete example of the activation-pooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is valuable as it helps the authors improve the clarity and consistency of their terminology, potentially enhancing the readability and comprehensibility of their paper. However, the comment could be more helpful if it explained why this change might be beneficial or how it would impact the overall understanding of the paper. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors consider shrinking the captions of Fig. 1 and Fig. 2 to leave more space for their methods or related work. This is a clear and direct action that the authors can take to improve the presentation of their figures. The comment provides a specific suggestion for how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 1\" and \"Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they should be shrunk to leave more space for the authors\\' methods or related work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the captions of Fig. 1 and Fig. 2 have large overlaps with the content, and it provides a specific suggestion to shrink the captions to leave more space for the authors\\' methods or related work. This claim is somewhat verifiable as it logically suggests a way to improve the presentation of the figures, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to experiment with different caption sizes to determine the optimal size for their purposes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the captions of Fig. 1 and Fig. 2, noting that they have large overlaps with the content. It provides a clear and actionable suggestion to shrink the captions to leave more space for the authors\\' methods or related work. This feedback is valuable as it directs the authors to a specific area that could be improved, offering a concrete way to enhance the clarity and presentation of their figures. However, the comment could be more helpful if it included examples of how the captions could be revised or if it explained why this change would be beneficial. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. While the comment implies that the authors should consider including Vidgen et al, 2021, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add this work as a benchmark. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. However, the comment does not provide specific reasoning or evidence to support why Vidgen et al, 2021, should be included as a benchmark. The absence of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the importance of including Vidgen et al, 2021, based on the suggestion alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This feedback is somewhat helpful as it points out a potential oversight in the paper and provides a direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to incorporate Vidgen et al, 2021, or provided examples of similar studies that could be included. Overall, the comment is somewhat helpful as it highlights an area for improvement but lacks depth and actionable suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to present the results comparing standard- vs. evolutional dropout on shallow models as a mean over many runs (at least 10) and ideally with error-bars. It also points out that the plotted curves are from single runs and might be subject to significant fluctuations. Additionally, it suggests that the models are small, so there is no excuse for not providing statistics. The comment provides clear and concrete actions for the authors to take, specifying the exact changes needed to improve the presentation of their results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results comparing standard- vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting the results as a mean over many runs (at least 10) with error-bars, and it points out that the plotted curves are from single runs and might be subject to significant fluctuations. Additionally, it suggests that the models are small, so there is no excuse for not providing statistics. This provides clear guidance on how to improve the presentation of the results. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with error-bars. The reviewer supports this claim by pointing out that the plotted curves are from single runs, which could be subject to significant fluctuations. Additionally, the reviewer suggests that the models are small, so there is no excuse for not providing statistics. This reasoning is logical and based on common knowledge about statistical analysis and model size. However, the comment could be strengthened by providing specific references or examples to support the claim about fluctuations and the need for statistics. Overall, the claim is mostly verifiable, as it is supported by logical reasoning and common knowledge, but it could be further substantiated with additional references or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback on the presentation of results comparing standard- vs. evolutional dropout on shallow models. It suggests that the results should be presented as a mean over many runs (at least 10) with error-bars, which is a standard practice in statistical analysis. This suggestion is based on the observation that the plotted curves are from single runs, which could be subject to significant fluctuations. Additionally, the comment points out that the models are small, so there is no excuse for not providing statistics. This feedback is valuable as it helps the authors improve the robustness and reliability of their results by ensuring that they are presented in a more rigorous manner. However, the comment could be more helpful if it provided additional guidance on how to implement these changes or suggested specific methods for conducting the multiple runs. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for improving the presentation of results.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, which is a specific solver. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the draft. The authors are left to infer that they need to improve the approach's universality and adaptability, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the proposed approach for learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, a specific solver. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where these aspects are discussed. The comment is specific in detailing what needs to be addressed, such as the need for universality and adaptability. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, a specific solver. The comment provides logical reasoning by comparing the proposed approach to current operator learning methods, which are more universal and do not need to be adapted to specific PDEs. However, the comment lacks specific examples or references to support the claim that the proposed approach is limited in its universality. Therefore, the comment is somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the proposed approach, noting that it is merely learning a surrogate model for solving linear/linearized systems arising in FEM. It highlights the need for careful choice of basis functions and meshes and points out that the approach heavily relies on FEniCS, a specific solver. The comment suggests that current operator learning methods are more universal and do not need to be adapted to specific PDEs. While the comment provides a clear critique of the proposed approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve the universality of their approach. The feedback is somewhat helpful as it points out a potential weakness but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to improve the clarity of the experimental setup. The comment is specific and provides concrete guidance on how to implement the suggested improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the impact of different versions of the experimental environment on training and inference speed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This claim is somewhat verifiable as it logically suggests that different versions of the experimental environment could impact training and inference speed. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of providing this information themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about the experimental environment, including the CUDA and PyTorch versions. This feedback is clear and actionable, as it directly addresses a potential issue with the clarity and reproducibility of the experimental setup. By providing this information, the authors can ensure that their work is more robust and easily replicable. However, the comment could be more helpful if it included suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve the clarity and transparency of their experimental setup.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the authors\\' judgement about the lack of immediate societal impact and the difficulty in controlling multiple aspects of variation with precision due to the use of fully realistic datasets. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how the authors might address the issue of controlling variation or how to improve the societal impact assessment. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of controlling multiple aspects of variation with precision due to the use of fully realistic datasets, and it agrees with the authors\\' judgement about the lack of immediate societal impact. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the difficulty in controlling variation and the lack of immediate societal impact, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using fully realistic datasets makes it difficult to control multiple aspects of variation with precision, and it agrees with the authors\\' judgement about the lack of immediate societal impact. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the authors\\' judgement about the lack of immediate societal impact and the difficulty in controlling multiple aspects of variation with precision due to the use of fully realistic datasets. However, it does not provide any specific suggestions or guidance on how the authors might address these issues or improve their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific paragraph (L156-166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and suggests that the authors clarify the concept of bandit algorithms and the figure. The comment provides explicit guidance on what needs to be clarified and improved, offering concrete suggestions for the authors to enhance the clarity of their draft. Therefore, the comment is highly actionable, as it clearly instructs the authors on how to enhance the comprehensibility of their work.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paragraph number (L156-166), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the paragraph, including the difficulty in understanding the content and the vagueness of the figure description. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paragraph is difficult to understand, particularly regarding the Gittins strategy and the figure. The reviewer suggests that the description is vague and provides examples of unclear phrases, such as \"Dashed lines indicate that the agent can plan ahead...\". However, the comment lacks specific references or detailed explanations to support the claim that the description is unclear or vague. While the reviewer provides some examples, the lack of detailed reasoning or examples from the literature makes the claim somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, which aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific paragraph (L156-166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and suggests that the authors clarify the concept of bandit algorithms and the figure. The comment provides actionable feedback by highlighting specific areas that need improvement, which can help the authors enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to clarify the content or provided examples of clearer explanations. Overall, the comment is mostly helpful as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled F-measure scores (LF1) (including ROOT arcs)\" was used in a previous work. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and actionable, giving the authors a clear path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (078-079 and 08) and the expression \"labelled F-measure scores (LF1) (including ROOT arcs),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the evaluation metric to clarify the scale of the improvement and for comparability with other works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It references a previous work, Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez (2020), where a similar expression was used. This claim is somewhat verifiable as it provides a logical reasoning for why clarifying the evaluation metric is important and references a specific example to support the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how this clarification would enhance the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled F-measure scores (LF1) (including ROOT arcs)\" was used in a previous work, which is relevant to the current paper. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their results section. By addressing these points, the authors can improve the transparency and reproducibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should study the behavior of the model under higher noise levels, as the standard deviation of the noise in the simulation study is stated as 3 but appears to be too low based on observations. While the comment implies that the authors should conduct additional simulations with higher noise levels, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional simulations to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the noise standard deviation being too low and suggests studying the model's behavior under higher noise levels. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the standard deviation of the noise in the simulation study is too low, based on observations compared to the true trajectories. However, the comment does not provide specific evidence or examples to support this claim, such as data or observations that would substantiate the assertion. Without such details, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or reasoning to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the standard deviation of the noise in the simulation study, suggesting that it may be too low based on observations compared to the true trajectories. It recommends studying the behavior of the model under higher noise levels. While the comment highlights a specific area for improvement, it lacks detailed guidance or suggestions on how to conduct the additional simulations or what specific aspects to focus on. This limits the comment\\'s helpfulness, as it provides a direction but not comprehensive guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the bounds having o(1) terms and suggests that this could limit the applications of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps the authors should consider to ensure the applicability of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the bounds of the approach, specifically mentioning the o(1) terms and the improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper discusses these bounds, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspects of the bounds are problematic or how they might limit the applications of the approach. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the bounds of the approach have o(1) terms and that this could limit the applications of the approach. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the bounds of the approach, noting that they have o(1) terms and improve over previously known results for arbitrarily long inputs. However, it does not provide specific guidance on how this might limit the applications of the approach or what steps the authors could take to address this concern. While the comment highlights a potential limitation, it lacks actionable advice or suggestions for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects of DVP performance should be examined. As a result, the authors are left without any clear direction on how to address this interest. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not specify which part of the paper this interest pertains to, such as a specific section or experiment. Without explicit references to sections or experiments, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of DVP performance should be examined or how the results should be interpreted. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses interest in seeing how DVP performs on videos with different lengths. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual statement about the authors\\' interest in exploring a particular aspect of their work. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it lacks any specific guidance or suggestions on how the authors might explore this aspect or what aspects of DVP performance should be examined. Without actionable feedback or detailed instructions, the comment does not provide meaningful assistance to the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. It acknowledges that the clarification is provided in the conclusion but does not specify how the authors should address this issue. The comment lacks explicit guidance on how to clarify the target or what specific changes should be made to improve the clarity. As a result, the authors are left without clear instructions on how to improve the draft in this area. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. However, it does not specify which part of the paper this confusion arises from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does not provide specific guidance on how to address this issue, such as suggesting where the clarification should be added or what aspects of the paper are unclear. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. The reviewer acknowledges that the clarification is provided in the conclusion but does not provide any supporting evidence or reasoning to justify this confusion. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the confusion and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about the target of the paper, specifically whether it focuses on single-token cloze queries or multi-token ones. It acknowledges that the clarification is provided in the conclusion but does not specify how this affects the paper\\'s focus or what aspects of the paper are unclear. The comment lacks actionable feedback or suggestions for improvement, leaving the authors without guidance on how to address the confusion or enhance the clarity of their work. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to evaluate the approximation error in the proposed training objective by calculating the actual KL-divergence and checking whether it approaches zero. It provides a clear and concrete action for the authors to take, specifying the exact calculation that needs to be performed. This level of detail makes the comment highly actionable, as the authors know exactly what steps to take to address the issue. Therefore, the comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely evaluating the approximation error in the proposed training objective by calculating the actual KL-divergence and checking whether it approaches zero. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed training objective has ignored the KL-divergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KL-divergence and checking whether it approaches zero. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the results. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed training objective, noting that it has ignored the KL-divergence term in equation (3). It provides a clear and actionable suggestion by asking the authors to evaluate the approximation error by calculating the actual KL-divergence and checking whether it approaches zero. This feedback is valuable as it directs the authors to a specific area that needs attention and provides a concrete step for improvement. However, the comment could be more helpful if it explained why this evaluation is important or how it might impact the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not provide explicit guidance on how to address these issues or what specific changes should be made to improve the connection or depth of the analysis. The comment implies that the authors should make improvements, but it lacks concrete details on how to implement these changes. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not specify which part of Section 2 is lacking a connection or how the theoretical analysis could be improved. The authors can infer that the comment relates to the theoretical analysis and its connection to the methodology section, but this inference is not direct. The comment is specific in identifying the issue of a lack of connection and the need for more depth in the theoretical analysis, but it is not grounded as it does not explicitly mention the sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or references, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the connection between Section 2 and the methodology section, noting that the theoretical analysis appears simplistic and closely related to a specific reference. This feedback is somewhat helpful as it points out a potential weakness in the paper, but it lacks specific suggestions or guidance on how to address this issue. The authors are given a direction to improve the depth and connection of their theoretical analysis, but the comment does not provide detailed advice or examples on how to achieve this. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should further discuss the situations in which the losses help, particularly in specular areas. While the comment implies that the authors should provide more details about the effectiveness of the losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the effectiveness of the losses in specific situations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing the situations in which the losses help, particularly in specular areas. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a particular area for further discussion, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the losses discussed in the paper might be particularly helpful in specular areas. However, it does not provide any evidence, examples, or references to support this claim. The comment lacks specific reasoning or data to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors further discuss the situations in which the losses help, particularly in specular areas. This feedback is somewhat helpful as it identifies a potential area for improvement by encouraging the authors to provide more detailed information about the effectiveness of their losses. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the losses should be discussed in more detail. While it points out a potential gap in the paper, it does not offer actionable steps for the authors to address this issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses doubt about the paper's current strength for the ICLR conference, but it does not provide any specific guidance or suggestions on how the authors might improve their draft to meet the standards of the conference. There is no explicit or implicit action for the authors to take, nor are there any concrete details on what aspects of the paper need improvement. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment does not specify which part of the paper is being addressed, making it not grounded. It also lacks specificity as it does not provide details on what aspects of the paper are insufficient for the ICLR conference or how the authors might improve their draft to meet those standards. Without clear guidance or references to specific sections, the comment does not offer actionable feedback for the authors to enhance their paper. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is \"doubtful\" for the ICLR conference, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the criteria or standards expected for the ICLR conference, the authors are left without a clear understanding of what needs to be improved or how to address the concern. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses doubt about the paper\\'s current strength for the ICLR conference, but it does not provide any specific feedback or suggestions on how the authors might improve their draft to meet the standards of the conference. Without actionable guidance or detailed insights into what aspects of the paper are insufficient, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks clarity regarding its major contributions, specifically mentioning that analyzing previous work does not constitute a contribution. However, it does not provide any explicit or implicit suggestions on how the authors might clarify or enhance their contributions. There is no guidance on what aspects of the paper should be emphasized or how the authors might present their contributions more effectively. As a result, the comment is unactionable, as it does not offer any actionable steps for the authors to take to improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"major contributions\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the paper\\'s contributions and the misconception that analyzing previous work constitutes a contribution. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding its major contributions, specifically mentioning that analyzing previous work does not constitute a contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the major contributions are unclear and that analyzing previous work does not constitute a contribution. This is a critical observation that can help the authors clarify their contributions and ensure that their work is properly positioned in the literature. However, the comment lacks specific guidance on how the authors might address this issue, such as suggesting ways to present their contributions more effectively or highlighting specific aspects of the analysis that are novel or innovative. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also mentions that the answer is difficult to find in reference [30]. This provides a clear and concrete action for the authors to take, which is to clarify the definition and usage of n_t in the algorithm. The comment is specific and provides a direct path for the authors to follow in order to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the \"appropriate number\" in line 225 and notes that the answer is difficult to find in reference [30]. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of \"appropriate number\" in Algorithm 2, specifically in line 225, and notes that it is difficult to find the answer in reference [30]. This claim is somewhat verifiable as it highlights a potential issue with the clarity of the algorithm, but it lacks specific examples or references to the exact phrases or sections that need clarification. The reviewer could provide more detailed guidance on how to clarify the \"appropriate number\" or suggest alternative phrasing, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also points out that the answer is difficult to find in reference [30]. This feedback is clear and actionable, as it directs the authors to clarify the definition and usage of n_t in the algorithm. By addressing this issue, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the explanation or offered additional context on the importance of n_t. Overall, the comment is mostly helpful as it effectively guides the authors on a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be publicly available. While the comment implies that the authors should make the code available, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make the code available to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not specify which part of the paper this issue pertains to, such as the results section or the methodology. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in its request for the code to be publicly available, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are difficult to reproduce or why the code should be made publicly available. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the difficulty in reproducing the results and questions the availability of the code. While it identifies a potential issue with the reproducibility of the work, it does not provide specific guidance or suggestions on how the authors might address this concern or improve the reproducibility of their results. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a potential problem but does not offer detailed guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the claims about the mixing time being better in practice are not adequately supported by the experiments. It suggests that the evidence provided is limited, which is a clear indication that the authors need to provide more robust data or analysis to substantiate their claims. However, the comment does not specify what additional evidence or analysis would be needed or how to present it. While the action is implicit, it is clear that the authors need to address this issue, but the lack of concrete guidance on how to do so makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claims about the mixing time being better in practice, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of sufficient evidence to support the claims about the mixing time. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the claims about the mixing time being better in practice are not sufficiently supported by the experiments. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specific evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the claims about the mixing time being better in practice, noting that the evidence provided is limited. This is a critical observation that highlights a gap in the paper\\'s experimental support, which is crucial for practitioners to understand the practical implications of the claims. However, the comment does not provide specific suggestions on how to address this issue or what additional evidence might be needed. While it points out a critical area for improvement, it lacks actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider this extension and determine how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to extend the protected feature to a vector form, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. This is a somewhat helpful suggestion as it points out a potential area for improvement in the paper. However, the comment lacks depth and does not provide specific guidance on how to implement this extension or what benefits it might bring. Without further explanation or examples, the authors may find it challenging to fully understand and act upon the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that the reviewer should denote the vector representations of the words in the equation and whether they are L2-normalized. Additionally, it asks for clarification on whether the nearest neighbor examples are computed using cosine or dot-product. These questions are direct and specific, providing clear guidance on how the authors can improve their draft. The action is explicit and the authors know exactly what needs to be done to address the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223\" and \"following ones,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including denoting the vector representations of the words, whether the vectors are L2-normalized, and the method used for computing nearest neighbor examples. This level of detail provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about specific aspects of the paper, such as the notation used for vector representations and the method for computing nearest neighbor examples. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies specific areas for clarification and improvement in the paper. It points out that the notation for vector representations of words is not clearly defined and suggests that the authors denote these somehow. Additionally, it asks whether the vectors are L2-normalized and whether the nearest neighbor examples are computed using cosine or dot-product. These questions provide the authors with actionable steps to improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to denote the vector representations or provided examples of how this could be done. Overall, the feedback is valuable but could be more comprehensive with additional guidance. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should run experiments multiple times and report statistics, as a way to address the reproducibility issue in deep RL. It references a recent paper that discusses the importance of reproducibility in deep RL and suggests that the authors should consider this community effort. While the comment provides a clear action to take, it does not specify how many times the experiments should be run or what specific statistics should be reported. The authors are given a general direction but may need to infer the exact details of implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that experiments should be run multiple times and that statistics should be reported to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL. However, the comment does not specify which part of the paper this issue pertains to, such as the experimental section or the discussion on reproducibility. While the authors might infer that it relates to the experimental results or methodology, the comment lacks explicit grounding. It is specific about the need for multiple experiments and statistics, but without clear grounding, it is weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that experiments should be run multiple times to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL and suggests that the authors should consider this community effort. While the comment provides a reference to an external source, it lacks detailed reasoning or specific examples of how running multiple experiments would improve reproducibility. The suggestion is somewhat verifiable, as it provides a logical basis but requires more detailed explanation or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with deep RL, specifically the reproducibility of their results and the significance of their improvements. It suggests that experiments should be run multiple times and that statistics should be reported to address this issue. The comment references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL, providing a relevant external reference to support the suggestion. While the comment highlights a significant area for improvement, it could be more helpful by offering specific guidance on how to implement these changes or what metrics to use for reporting statistics. Overall, the comment provides valuable insight into a critical aspect of the paper and offers actionable suggestions, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to check Figure 2, Line 433, and Line 468 for minor issues with the ending punctuation of equations. It also explicitly states that they should ensure consistency in the punctuation. This feedback provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be corrected. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2, Line 433, and Line 468,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the ending punctuation of equations, instructing the authors to ensure consistency in the punctuation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the ending punctuation of equations in Figure 2, Line 433, and Line 468. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the punctuation of equations in Figure 2, Line 433, and Line 468. It provides clear and actionable feedback by instructing the authors to ensure consistency in the ending punctuation of equations. This is a minor but important detail that can enhance the clarity and professionalism of the paper. However, the comment could be more helpful if it explained why this consistency is important or provided examples of how it affects the overall presentation. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to differentiate the method or what specific aspects could be improved to enhance the technical contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not specify which part of the paper discusses $kNN-ECD$ or $kNN-MT$, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the similarity should be addressed or how the authors could differentiate their method. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, the comment does not provide any specific examples, comparisons, or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the method proposed in the paper, $kNN-ECD$, is similar to $kNN-MT$, which limits the technical contribution of the paper. However, it does not provide any specific guidance or suggestions on how the authors could differentiate their method or what aspects of the similarity should be addressed. Without actionable feedback or detailed reasoning, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct real-world experiments to support the phenomenon occurring in these figures. This feedback implies that the authors should conduct additional experiments to validate their method, providing a clear action for the authors to take. However, the comment does not specify which experiments should be conducted or how to conduct them, leaving some details vague. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks concrete guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially, and suggests conducting real-world experiments to support the phenomenon occurring in these figures. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct real-world experiments to support the phenomenon occurring in these figures. This claim is somewhat verifiable as it logically suggests that real-world experiments could provide additional validation for the method. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct real-world experiments to support the phenomenon occurring in these figures. This feedback is valuable as it highlights a potential gap in the paper\\'s validation and provides a clear direction for the authors to enhance the robustness of their method. However, the comment could be more helpful if it offered specific suggestions on how to conduct these real-world experiments or what aspects of the phenomenon should be evaluated. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance the credibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the authors did not clarify the number of parameters used in each approach in Section B.3. This is a clear and direct request for additional information, providing the authors with a specific action to take. The comment is explicit and concrete, as it specifies the exact part of the paper that needs clarification and the exact information that is missing. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the number of parameters used in each approach. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a request for clarification regarding the number of parameters used in each approach in Section B.3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the lack of clarity regarding the number of parameters used in each approach in Section B.3. This feedback is clear and actionable, as it directs the authors to provide additional information that would improve the clarity and comprehensibility of their work. By addressing this point, the authors can enhance the transparency and accessibility of their methodology, which is crucial for effective communication of their findings. Therefore, the comment is rated as mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This provides a clear and direct action for the authors to take, which is to include these elements in their draft to enhance understanding. The suggestion is concrete, as it specifies exactly what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding an example and a figure to help explain the definition of uniform shattering. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the definition is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of an example and a figure, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any reasoning or evidence to support why this addition would be beneficial or how it would enhance the understanding of the concept. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to determine the necessity or impact of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing visual aids to enhance understanding. However, the comment lacks depth and does not explain why examples or figures would be beneficial or how they could be integrated into the paper. While it points out a potential improvement, it does not offer detailed guidance or suggestions on how to implement this change. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semi-supervised learning. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve the novelty of their method. The comment lacks actionable details, such as recommending ways to differentiate the method or suggesting alternative approaches to enhance its originality. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semi-supervised learning. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspect of the method is considered common or how it could be improved to enhance its novelty. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed transductive method is not novel because it is related to a common approach in semi-supervised learning, specifically self-training methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semi-supervised learning, specifically self-training methods. While it identifies a potential issue with the novelty of the method, it lacks specificity and actionable guidance on how the authors might address this concern or differentiate their approach. The comment does not provide suggestions for improving the novelty or clarifying the method's unique contributions. As a result, the feedback is not helpful, as it does not offer constructive advice for improvement. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the assumption among classes not being practical, but it does not provide any explicit or implicit actions for the authors to take. It mentions that the formulation or definition is trivial but suggests that the focus should be on optimization and theoretical property analysis for potential insights. However, without specific guidance or suggestions on how to address this issue, the authors are left without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the assumption among classes and suggests that the formulation or definition is trivial, but highlights the importance of optimization and theoretical property analysis for potential insights. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and the potential value of optimization and theoretical analysis, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption among classes is not practical, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the formulation or definition is trivial, but it lacks specific examples or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumption among classes, suggesting that it may not be practical. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve their work. The comment mentions the importance of optimization and theoretical property analysis, but it lacks depth and actionable advice. Without detailed feedback or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation results in Table 1 are based on only three trials for each case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the evaluation or the claims made in the paper. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the statistical significance of their results and potentially revise their claims accordingly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation results, noting that the three trials per case are not statistically significant and that the deviations reported are not meaningful. The comment further explains why this is problematic, suggesting that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation results in Table 1 are based on only three trials per case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense. The comment provides a logical reasoning by explaining the statistical significance of the trials and the implications for the claims made in the paper. However, it lacks specific examples or references to support the claim about statistical significance, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but could benefit from more detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation results presented in Table 1, noting that the three trials per case are not statistically significant. This observation is crucial, as it highlights a potential flaw in the methodology that could undermine the validity of the results. The comment also points out that the deviations reported are often zero, which further questions the significance of the results. Additionally, it critiques the claim that \"our performance is at least two standard deviations better than the next best baseline,\" suggesting that this statement is not supported by the data. This feedback is clear and actionable, as it prompts the authors to reconsider their evaluation methodology and potentially revise their claims based on the statistical significance of their results. Therefore, the comment is highly helpful, as it provides a clear direction for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide specific guidance on which papers should be included or how to improve the depth of the feature comparison. The authors are left to infer that they need to include these papers, but without concrete instructions or examples, the action remains vague. Therefore, this comment is somewhat actionable, as it identifies an issue but lacks detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the feature comparison with prior work, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the shallowness of the comparison and the absence of two relevant papers. This provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide specific details about which papers are missing or how they would enhance the comparison. Without these details, the authors may struggle to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable due to the lack of specific examples or references to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the shallow depth of the feature comparison with prior work. It points out the absence of two relevant papers, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided the names or titles of the missing papers or suggested ways to incorporate them into the comparison. Despite this, the feedback is still valuable as it directs the authors to a specific area for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims of equivalence without verification. While the comment provides a specific suggestion for improvement, it does not offer concrete guidance on how to apply this suggestion or what specific changes should be made to the wording or claims. The authors are left to infer that they should be more cautious in their usage of the word \"equivalent,\" but without detailed instructions on how to implement this change, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it suggests a more cautious usage of the word \"equivalent\" and advises caution when making claims without verification. This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims without verification. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the usage of the word \"equivalent\" in the paper, suggesting that the authors should be more cautious in their claims and provide verification for any equivalence claims. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accuracy of the paper. However, the comment could be more helpful if it offered examples of how the authors might verify equivalence or provided guidance on how to use the word \"equivalent\" more effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a lack of understanding regarding the effectiveness of the multi-view clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests that there is a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed analysis of the views. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of the multi-view clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its critique of the lack of detailed analysis and the need for more comprehensive evaluation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the multi-view clustering approach is not effective and that the paraphrase similarity view dominates over other views. The reviewer provides some support for this claim by mentioning that the paraphrase similarity view performs significantly better than the others, but this is not enough to fully substantiate the claim. The comment suggests that a more detailed analysis of the differences and similarities between the views is needed, but it does not provide specific examples or references to support this claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the effectiveness of the multi-view clustering approach, specifically the dominance of the paraphrase similarity view over other views. It highlights the need for a more detailed analysis of the differences and similarities between the views, suggesting that this would help draw solid conclusions about their usefulness. While the comment points out a critical area for improvement, it lacks specific suggestions or guidance on how to conduct the analysis or what aspects should be considered. This limits the comment\\'s helpfulness, as it provides a general direction but does not offer actionable steps for the authors to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This implies that the authors should provide a more detailed explanation of the architecture in their paper. However, the comment does not specify which parts of the paper need more detail or how to present the architecture information. While the action is implied, it is not explicitly stated, and the lack of concrete guidance makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear explanation of the architecture and the reliance on external work for details. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This suggests that the paper lacks self-containment. However, the comment does not provide specific examples or references to the architecture or the external work, making it difficult for the authors to understand the exact issue and address it. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the specifics of the issue themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained and that the authors rely on external work for details. This lack of self-containment makes the paper less accessible to readers who may not be familiar with the referenced work. The comment provides a clear and actionable suggestion for improvement, encouraging the authors to include more detailed explanations of the architecture in their paper. However, it could be more helpful if it offered specific guidance on how to present this information or what aspects should be emphasized. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out an inconsistency in the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback provides a clear and direct action for the authors to take, which is to ensure consistency in the typesetting of these terms. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"BertScore\" and \"BLEURT,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistent typesetting of these terms throughout the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"BertScore\" and \"BLEURT\" are inconsistently typeset throughout the paper, suggesting that maintaining consistency would be beneficial. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the clarity or readability of the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback is clear and actionable, as it points out a specific area where the authors can improve the clarity and consistency of their work. By addressing this issue, the authors can enhance the readability and professionalism of their paper. However, the comment could be more helpful if it provided examples of how the inconsistency affects the paper or suggested alternative ways to maintain consistency. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback implies that the authors should include these results to support their claims about model size and performance. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. While the action is implied, it is not as clear as it could be, as the authors may not be entirely sure of the exact details or format required for these results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or analysis sections, but this inference is not direct. The comment is specific in suggesting the need for detailed results on Wikipedia, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is unreasonable to expect that increasing the model size would hurt performance, as recent work by Ni et al. demonstrates that scaling laws apply to dense retrieval models. The reviewer supports this claim by referencing a specific paper, which provides some initial evidence for the claim. However, the comment lacks detailed explanation or analysis of why the scaling law applies to dense retrieval models or how it relates to the specific model being discussed. This makes the claim somewhat verifiable, as it provides a reference but lacks comprehensive justification or explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' claims regarding the impact of model size on performance. It suggests that the authors should provide detailed preliminary experimental results on Wikipedia to support their claims, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback is clear and actionable, as it provides a specific direction for the authors to address the critique by including detailed experimental results. However, the comment could be more helpful if it offered suggestions on how to design and interpret these experiments, or if it provided examples of how similar studies have been conducted. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific weaknesses in the presentation quality of the paper, such as the figures, tables, and the management of figures and tables. It provides a list of examples, including the use of a \"Dataset\" column in tables that is not informative, the management of Figure 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. While the comment highlights these issues, it does not provide explicit guidance on how to address them or suggest specific improvements. The authors are left to infer that they need to improve the presentation quality, but without detailed instructions or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures and tables, such as Figs 1&2, Table 1, and Table 2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with these figures and tables, such as the use of a \"Dataset\" column in tables that is not informative, the management of Fig 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation quality of the paper is a weakness, specifically mentioning examples such as Figs 1&2, the use of a \"-\" for the method, the \"Dataset\" columns in tables, the management of Fig 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. These examples provide a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed explanations or references to similar issues in high-quality publications like NeurIPS. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific weaknesses in the presentation quality of the paper, such as the use of a \"Dataset\" column in tables that is not informative, the management of Figures 3 and 2, and the use of a \"*\" in Table 1 without indication of its meaning. It provides a detailed list of examples, which is helpful in guiding the authors on what aspects of their presentation need improvement. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar issues have been resolved in high-quality publications. Overall, the comment is somewhat helpful as it highlights areas for improvement but lacks detailed guidance on how to achieve them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include related experiments to demonstrate the utility of the information axis tool. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment somewhat actionable. The authors can infer that they need to conduct additional experiments, but the lack of explicit instruction makes it somewhat vague.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the conclusion or discussion, but this inference is not direct. The comment is specific in suggesting the need for related experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not provide any specific examples or references to support this claim. The comment is based on a logical assumption that additional experiments would be beneficial, but it lacks the necessary evidence or reasoning to fully substantiate the claim. As a result, the comment is considered borderline verifiable, as it provides a suggestion but lacks the necessary detail to be fully convincing.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting that the authors include additional experiments to validate their claims. However, the comment lacks specific guidance on what kind of experiments would be beneficial or how they should be conducted. While it points out a potential gap in the paper, it does not provide detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they could take to investigate it further. As a result, the comment lacks actionability and does not provide any direction for the authors to improve their draft. Therefore, it is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide any context or details about the current setup or the Greek language. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the Greek language might be causing issues or how the authors might address them. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for information about whether other multilingual pretraining setups also struggle with Greek. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. While it raises an interesting question, it does not provide any actionable feedback or suggestions for the authors to address this issue or improve their work. Without further context or guidance, the authors may find it challenging to understand how this information could be relevant to their paper or how to incorporate it into their analysis. Therefore, the comment is rated as barely helpful, as it identifies a potential area of interest but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the text in lines 293-295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" The reviewer implies that the authors should clarify this point to improve clarity. However, the comment does not provide specific guidance on how to clarify this point or what aspects need to be addressed. While the action is implicit, it is clear that the authors need to make changes to improve the clarity of the text. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 293-295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement \"we manually observed the generated examples and find the results acceptable.\" This provides clear guidance on what aspect of the text is unclear and needs improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text in lines 293-295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text in lines 293-295, noting that it makes a particular point unclear. It points out that the statement \"we manually observed the generated examples and find the results acceptable\" is difficult for readers to understand and evaluate. While the comment highlights an area for improvement, it does not provide detailed guidance or suggestions on how to clarify the text or what specific aspects need clarification. This limits the comment\\'s helpfulness, as it offers some insight but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a significant issue with the organization and clarity of the proof, noting that it is difficult to follow and lacks clean logic. It specifically points out a problem in Lemma 3, questioning whether the result holds for any polynomial function $P(\\\\gamma)$. While the comment highlights a clear area for improvement, it does not provide explicit guidance on how to reorganize the proof or improve its clarity. The authors are left to infer that they need to address the issue, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof organization, noting that it is not well-organized and lacks clean logic, making it difficult to follow. The comment further specifies the problem in Lemma 3, questioning whether the result holds for any polynomial function $P(\\\\gamma)$. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof is \"extremely not well organized\" and lacks clean logic, making it difficult to follow and verify the correctness of the proof. The reviewer provides a specific example by questioning the applicability of the result in Lemma 3 to any polynomial function $P(\\\\gamma)$. This claim is somewhat verifiable as it highlights a specific issue with the proof organization and provides an example of a problematic aspect. However, it could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the organization and clarity of the proof, noting that it is difficult to follow and lacks clean logic. It provides a specific example by questioning the applicability of the result in Lemma 3 to any polynomial function $P(\\\\gamma)$. This feedback is valuable as it highlights a critical area for improvement in the draft, which could enhance the rigor and accessibility of the proof. However, the comment could be more helpful if it offered suggestions on how to improve the organization or clarity of the proof. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and provides a clear example of a problematic aspect.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment somewhat actionable. The authors can infer that they need to conduct experiments on real-world datasets, but the lack of explicit instruction means the action is not as direct as it could be.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. However, it does not specify which part of the paper discusses the synthetic versus real-world datasets or the out-of-distribution setting. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this suggestion fits, the comment lacks full grounding. It is specific about the need for real-world datasets but does not provide detailed guidance on how to implement this change. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic datasets, particularly for the out-of-distribution setting. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper's experimental setup. However, the comment lacks specific guidance on how to conduct these experiments or what aspects of the synthetic datasets might be limiting the paper\\'s conclusions. While it points out a potential issue, it does not provide detailed suggestions or examples to help the authors address it effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207-210) regarding the single image case. However, it does not provide explicit guidance on what specific aspects of the explanation are unclear or how they could be clarified. The comment implies that the authors should clarify these parts, but it lacks concrete instructions or examples of what needs to be improved. As a result, the authors are left with a vague understanding of what changes are needed to make the explanation clearer. Therefore, this comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on how to achieve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the last paragraph of Section 3 (lines 207-210), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the explanations are vague and provides a specific example of the last paragraph in Section 3. This level of detail helps the authors understand what needs to be clarified or improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207-210) regarding the single image case. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the vagueness and how it affects the clarity of the explanation. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the explanations in the paper, particularly in the last paragraph of Section 3 (lines 207-210) regarding the single image case. This feedback is valuable as it points out a specific area where the authors can improve the clarity and comprehensibility of their explanations. However, the comment could be more helpful if it provided suggestions on how to clarify these vague explanations or examples of how they could be improved. Despite this, the comment still offers a clear direction for the authors to enhance the clarity of their work, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, it does not provide explicit instructions or concrete steps on how to extend the analysis to multiple trucks and drones. The authors are left to infer that they should consider this extension, but without specific guidance on how to implement it, the action remains vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or discussion sections. The authors cannot confidently determine which part of the paper needs to be addressed, making this comment weakly grounded. The suggestion is specific in terms of what the authors should consider, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. This feedback is somewhat helpful as it points out a potential area for expansion that could enhance the practicality and relevance of the work. However, the comment lacks specific guidance or suggestions on how to implement this change or what specific benefits it might bring. While it identifies a potential improvement, it does not provide detailed instructions or examples to help the authors effectively address the issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the proposed approach to pretraining is not novel since it follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit suggestions for how the authors could make their approach more novel or differentiate it from ELECTRA. There is no guidance on potential modifications, alternative approaches, or additional features that could be added to enhance the novelty. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the proposed approach to pretraining, specifically mentioning that it follows the strategies used in ELECTRA. However, it does not specify which part of the paper discusses this approach, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the novelty, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed approach to pretraining lacks novelty because it follows the strategies used in ELECTRA. However, the comment does not provide any specific examples or references to the strategies used in ELECTRA, nor does it explain how the proposed approach is similar or dissimilar to those used in ELECTRA. Without detailed comparisons or references, the claim lacks sufficient evidence or justification to be considered fully verifiable. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some support but requires more detailed evidence or reasoning to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment points out a potential issue with the novelty of the proposed approach to pretraining, noting that it follows the strategies used in ELECTRA. While this observation highlights a limitation, it does not provide specific suggestions or guidance on how the authors might differentiate their approach or enhance its novelty. The comment lacks actionable feedback or constructive advice, leaving the authors without clear direction on how to address the issue. Therefore, it is rated as barely helpful, as it identifies a weakness but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of motivation or need for the Newton algorithm in section 4, suggesting that it is a 1-dimensional line search on a convex function. It also points out that even a basic bisecting line search will converge linearly, questioning the impact of quadratic convergence on run-time. The reviewer suggests that experiments along these lines would help motivate the need for the analysis/algorithm. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is concrete but inferred, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of motivation or need for the Newton algorithm and the suggestion to conduct experiments to motivate the analysis/algorithm. The comment provides a clear direction for improvement by suggesting experiments that could help justify the use of the Newton algorithm. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the need for the Newton algorithm in section 4, suggesting that it is a 1-dimensional line search on a convex function and that even a basic bisecting line search will converge linearly. The reviewer argues that while quadratic convergence is better than linear convergence, the impact on run-time is unclear. The comment suggests conducting experiments to motivate the need for the analysis/algorithm. This claim is somewhat verifiable as it provides a logical reasoning for questioning the necessity of the Newton algorithm, but it lacks specific examples or references to support the argument about the impact on run-time. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of motivation or need for the Newton algorithm in section 4, suggesting that it is a 1-dimensional line search on a convex function. It questions the significance of the analysis/algorithm, noting that even a basic bisecting line search will converge linearly. The reviewer suggests that experiments along these lines would help motivate the need for the analysis/algorithm. While the comment highlights a potential weakness in the paper, it does not provide specific guidance on how to address this issue or what experiments to conduct. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks detailed suggestions or actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiom-specific and that the results appear to indicate that \"better NMT systems are also better at idiomatic translations.\" However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. It lacks concrete steps or detailed advice on how to make the methods more idiom-specific or how to improve the results. As a result, the authors are left without clear direction on how to apply this feedback to enhance their draft. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proposed upweighing and KNN methods\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the methods appear to be similar for idiomatic and random data, suggesting that the results indicate that \"better NMT systems are also better at idiomatic translations.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed upweighing and KNN methods are not idiom-specific, as the impact on idiomatic and random data appears similar. The reviewer supports this claim by referencing Figure 3, which presumably shows the results of the methods on different language and score combinations. However, the comment lacks specific details or examples from the figure to fully substantiate the claim. While the reference to Figure 3 provides some context, the comment could be strengthened by including more detailed analysis or specific observations from the figure. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks comprehensive evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiom-specific and that the results appear to indicate that \"better NMT systems are also better at idiomatic translations.\" This feedback highlights a potential weakness in the methodology and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to address this issue, such as proposing alternative methods or suggesting ways to make the methods more idiom-specific. While it identifies a critical area for improvement, the lack of actionable guidance limits its usefulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the volume calculation and the number of biases, suggesting that the authors should clarify the volume and the number of biases. It also mentions that the authors want to have several kernels but only found a hyper-parameter for feed-forward models in section 3.4. The reviewer implies that the current setup is confusing and suggests that the authors should address this issue. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to implement these changes or what aspects of the volume and biases need clarification. The action is explicit but somewhat vague, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the volume calculation and the number of biases, suggesting that the authors should clarify the volume and the number of biases. Additionally, it points out the confusion regarding the number of biases and the fact that the authors want to have several kernels but only found a hyper-parameter for feed-forward models in section 3.4. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the volume should be WxHx1 and that the bias is a scalar, based on the authors\\' belief. The reviewer questions the number of biases, noting that the authors want to have several kernels but only found a hyper-parameter for feed-forward models in section 3.4. The comment suggests that the current setup is confusing, as the number of biases does not align with the authors\\' intent. However, the comment lacks specific examples or references to support the claim that the volume and biases are incorrect. The reasoning is based on logical deduction and inference, but without concrete evidence or examples, the claim is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the volume calculation and the number of biases, suggesting that the volume should be WxHx1 and the bias is a scalar. It points out that the authors want to have several kernels but only found a hyper-parameter for feed-forward models in section 3.4, which is confusing. This feedback is somewhat helpful as it highlights a potential issue with the paper\\'s mathematical representation, which could be clarified for readers. However, the comment lacks specific suggestions on how to address this issue or improve the clarity of the volume and biases. While it provides some insight, it could be more helpful with additional guidance or examples. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with Equation 8, specifically that subtracting s from the dynamic information in the LSTM module could result in the loss of some dynamic information. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the equation. The comment lacks actionable details, such as suggesting alternative approaches or methods to mitigate the loss of dynamic information. As a result, the authors are left without a clear understanding of how to proceed with this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the equation, noting that subtracting s from the dynamic information could result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that subtracting s from the dynamic information in Equation 8 could result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with Equation 8, specifically noting that subtracting s from the dynamic information in the LSTM module could result in the loss of some dynamic information. This is a valuable observation that could help the authors improve the accuracy and completeness of their model. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending alternative approaches or methods to mitigate the loss of dynamic information. While it points out a relevant concern, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses two questions about the impact of the number of MC samples and the network structure on performance. While it does not explicitly instruct the authors to conduct experiments or provide specific guidance on how to address these questions, the questions themselves are clear and actionable. The authors can infer that they need to conduct experiments to investigate the effect of these factors on performance and potentially include this analysis in their paper. Therefore, the comment is somewhat actionable, as it provides a clear direction for the authors to follow but lacks explicit instructions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions about the impact of the number of MC samples and the network structure on performance, but it does not specify which part of the paper these questions pertain to. The authors may infer that it relates to the experimental section, but this inference is not direct. The comment is specific in its request for empirical evidence and analysis, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions asking for empirical evidence and analysis regarding the impact of the number of MC samples and the network structure on performance. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two important questions about the impact of the number of MC samples and the network structure on performance, prompting the authors to conduct empirical investigations. By asking for empirical evidence and analysis, the comment highlights areas where the authors could enhance their work by providing more detailed explanations and results. However, the comment does not offer specific guidance or suggestions on how to conduct these experiments or what specific aspects of the network structure should be examined. While it points out a potential gap in the paper, it lacks detailed guidance, making it somewhat helpful but not fully comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the smoothed GT shapes should be shown in Figures 3 and 5 to enhance the understanding of the reconstruction quality. This is a clear and direct action for the authors to take, as it provides a specific request for visual clarity. The comment also mentions a minor concern, which could be addressed by providing additional context or explanation. Overall, the action is explicit and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in its suggestion to include the smoothed GT shapes, but without full grounding, the authors may struggle to identify the exact figures being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the understanding. The comment lacks specificity and does not provide a clear rationale for the suggestion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific improvement by recommending the inclusion of smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. This feedback is clear and actionable, as it provides a concrete step for the authors to take in order to improve the clarity and comprehensibility of their figures. However, the comment could be more helpful if it explained why this addition is important or how it would benefit the reader. Overall, the suggestion is valuable but could be more comprehensive with additional context or explanation. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC, particularly in the language and vision tasks used for evaluation. It notes that while there is a comparison of training loss and a comparison of the rank of possible solutions, there is no direct comparison of test accuracy. The comment implies that the authors should include direct comparisons of test accuracy to demonstrate the improvement over the baseline. However, it does not explicitly instruct the authors to conduct these comparisons, leaving the action implicit. The comment is somewhat actionable as it provides a clear direction for improvement but lacks concrete guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"prior approach PRANC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of direct comparisons with PRANC in the language and vision tasks used to evaluate the proposed approach. The comment provides a clear direction for improvement by suggesting the inclusion of direct comparisons of test accuracy. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are no direct comparisons with the prior approach PRANC in the language or vision tasks used to evaluate the proposed approach. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. The comment suggests that without such comparisons, it is unclear if the proposed approach is an improvement over the baseline that it directly modifies. This claim is somewhat verifiable as it logically points out the need for direct comparisons to substantiate the claims of improvement. However, it lacks specific examples or references to similar studies that might provide a more robust basis for the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation of the proposed approach, noting the lack of direct comparisons with the prior approach PRANC in the language or vision tasks used to assess the proposed approach. It highlights the importance of including such comparisons to demonstrate the improvement over the baseline that is directly modified by the authors. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to conduct these comparisons or what metrics to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the generalizability of the method to other domains and questions the selection of 21 event types from Freebase. It explicitly asks for clarification on how these event types are selected and what the coverage is on the 33 event types in the ACE data. This provides clear and direct actions for the authors to take, such as explaining the selection process and providing more details on the coverage. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2 line 262,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the selection of 21 event types from Freebase and asking about their coverage on the 33 event types in the ACE data. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the method to other domains, specifically questioning the selection of 21 event types from Freebase and their coverage on the 33 event types in the ACE data. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this selection process might be problematic or how it affects the generalizability of the method. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be fully substantiated. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the method to other domains, specifically questioning the selection of 21 event types from Freebase and their coverage on the 33 event types in the ACE data. This is an important point that could impact the applicability and robustness of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the generalizability of their work. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen the evaluation of the language modeling capability. While the comment implies that these tasks should be included, it does not explicitly instruct the authors to do so. The action is clear but not stated directly, making the comment somewhat actionable. The authors can infer that they need to include additional tasks to demonstrate the language modeling capability, but the comment lacks concrete details on which tasks to include or how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the language modeling capability is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of tasks like language modeling, machine translation, or text summarization to strengthen the evaluation of the language modeling capability. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not conduct experiments on generation tasks that require a well-performing language model, specifically mentioning word similarity and SquAD in section 5.3. The reviewer suggests that these tasks do not adequately reflect the language modeling capability. However, the comment lacks specific examples or references to other tasks that could be used to demonstrate the language modeling capability. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the experiments on word similarity and SquAD in section 5.3 do not adequately reflect the language modeling capability. It suggests that the authors should include additional tasks like language modeling, machine translation, or text summarization to strengthen this part of the paper. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their evaluation of the language modeling capability. However, the comment could be more helpful if it included specific examples or references to similar studies that have used these tasks to demonstrate language modeling capabilities. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notations of $\\\\hat{Y}$ and $Y$ are used in a mixed way in Section 2. However, it does not provide any explicit guidance or suggestions on how to resolve this issue. The authors are left to infer that they need to clarify or standardize the usage of these notations, but without specific instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the mixed usage of notations $\\\\hat{Y}$ and $Y$, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notations of $\\\\hat{Y}$ and $Y$ are used in a mixed way in Section 2. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the usage of notations in Section 2, noting that the notations of $\\\\hat{Y}$ and $Y$ are used in a mixed way. This feedback is somewhat helpful as it points out a potential source of confusion in the paper, which could be clarified or standardized. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the clarity of the notations. While it highlights a potential area for improvement, it does not offer actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to cite and discuss important references for domain adaptation in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for references and discussions on domain adaptation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, namely references and discussions on domain adaptation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks important references for domain adaptation. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact references that are missing. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of important references for domain adaptation. It explicitly instructs the authors to cite and discuss these references in the revised manuscript. This feedback is clear and actionable, providing the authors with a direct and specific way to enhance the paper\\'s comprehensiveness and relevance. By addressing this issue, the authors can significantly improve the quality and depth of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks a question about whether EMA-weighting is used for other baseline models in Table 3, specifically mentioning \"Supervised,\" \\\\Pi, etc. This question seeks clarification on whether all models being compared are using EMA benefits, which is a clear and direct request for information. The authors know exactly what needs to be clarified and how to address the comment by providing this information. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a clear question about whether EMA-weighting is used for other baseline models, such as \"Supervised,\" \\\\Pi, etc., and suggests that this information would be necessary for a fair comparison. This provides a clear direction for the authors to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the use of EMA-weighting for other baseline models in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area of concern regarding the use of EMA-weighting for other baseline models in Table 3. By asking whether EMA-weighting is used for these models, the comment prompts the authors to clarify whether all models being compared are using EMA benefits, which is crucial for a fair comparison. This feedback is actionable and provides a clear direction for the authors to address, ensuring that the draft is more transparent and comprehensive. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific models should be included. Overall, the comment is mostly helpful as it effectively guides the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps to take. It lacks concrete details on how to verify the suspicion or improve the model. As a result, the authors are left without clear instructions on how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the hyperparameters and the potential issue with the model\\'s performance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the suspicion. As a result, the claim is somewhat verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. This is a relevant observation that could impact the validity of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or verify the suspicion. It does not provide actionable steps or detailed feedback on how to improve the presentation or analysis of the results. As a result, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide any specific details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. The comment lacks explicit guidance or concrete steps for the authors to take, leaving them without a clear understanding of what needs to be addressed or how to address it. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"w.r.t. to corpora and datasets,\" indicating that it pertains to the experimental setup. However, it does not specify which part of the paper this pertains to, such as a particular section or table where these aspects are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects are unclear or poorly motivated, making it difficult for the authors to understand the exact issues that need to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"some aspects of the experimental setup were unclear or poorly motivated,\" specifically regarding corpora and datasets. However, the comment does not provide any specific examples or details about what is unclear or poorly motivated, making it difficult for the authors to understand the exact issues that need to be addressed. Without specific examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that some aspects regarding corpora and datasets are unclear or poorly motivated. However, it does not provide any details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. Without specific guidance or actionable feedback, the authors are left without a clear understanding of what needs to be addressed or how to address it. Therefore, the comment is barely helpful, as it points out a potential weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the proposed method does not show significant improvement over existing RL methods, but it does not provide any specific guidance or suggestions on how the authors could address this issue. There is no explicit or implicit action for the authors to take, such as suggesting ways to improve the method or providing examples of existing RL methods that could be compared. Without actionable advice or detailed feedback, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed method does not show significant improvement over existing RL methods, but it does not specify which part of the paper discusses this improvement or where the comparison is made. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is not grounded and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method does not show significant improvement over existing RL methods. However, it does not provide any specific examples, comparisons, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the proposed method does not show significant improvement over existing RL methods, which is a critical observation that could impact the paper\\'s contribution. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the method\\'s performance. Without actionable feedback or detailed insights into what aspects of the method need improvement, the authors are left without a clear path forward. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the model size. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"size of the model\" and the \"hourglass modules,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of the model size to competing approaches and the details on the size of each hourglass module. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the paper\\'s analysis or conclusions. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters, noting that the authors do not provide details on the size of each hourglass module. This feedback is clear and actionable, as it prompts the authors to include this information in their paper. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details to include. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their work that needs clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a mistake in the dimensions of the projection matrices, noting that they should be written as $A_i \\in \\mathbb{R}^{d_i \\\\times m_i}$ instead of $A_i \\in \\mathbb{R}^{m_i \\\\times d_i}$. The reviewer acknowledges that they might be incorrect and suggests that the authors verify this. The comment provides a clear and explicit action for the authors to take, which is to correct the dimensions of the projection matrices. The action is concrete, as it specifies the exact change needed, and the authors know exactly what to do to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the dimensions of the projection matrices, noting that they should be written as $A_i \\in \\mathbb{R}^{d_i \\\\times m_i}$ instead of $A_i \\in \\mathbb{R}^{m_i \\\\times d_i}$. This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the dimensions of the projection matrices are incorrect, specifically that they should be written as $A_i \\in \\mathbb{R}^{d_i \\\\times m_i}$ instead of $A_i \\in \\mathbb{R}^{m_i \\\\times d_i}$. The reviewer acknowledges that they might be incorrect and suggests the authors verify this. However, the comment lacks supporting evidence or references to justify the claim or provide examples of how this error affects the paper. Without additional context or explanation, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the issue without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific mistake in the dimensions of the projection matrices, noting that they should be written as $A_i \\in \\mathbb{R}^{d_i \\\\times m_i}$ instead of $A_i \\in \\mathbb{R}^{m_i \\\\times d_i}$. This is a clear and actionable suggestion that can help the authors correct a potential error in their work. However, the comment could be more helpful if it provided additional context or explanation about why this mistake might occur or how it affects the overall understanding of the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing correction, which can significantly impact the clarity and accuracy of their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the claim about treating climate emulation as a diagnostic-type prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, it does not provide explicit guidance on how the authors should address this issue or clarify their claim. The comment lacks concrete suggestions on how to improve the clarity or accuracy of the claim, leaving the authors uncertain about what specific actions to take. As a result, the comment is vague and lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about treating climate emulation as a diagnostic-type prediction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that prior work, such as ClimateBench or ClimateSet, already does this, providing clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' claim about treating climate emulation as a diagnostic-type prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, the comment does not provide specific examples or references to these works, nor does it explain how the authors\\' claim differs from what has already been done. Without detailed evidence or reasoning, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential misleading claim in the paper regarding the novelty of treating climate emulation as a diagnostic-type prediction. It points out that prior work, such as ClimateBench or ClimateSet, already does this, which could undermine the authors\\' argument. This feedback is somewhat helpful as it highlights a potential weakness in the paper\\'s claims, but it lacks specific suggestions on how the authors might address this issue or clarify their contribution. While it provides some insight, it could be more helpful with additional guidance on how to improve the clarity or accuracy of the claim. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"metric learning theory\" and \"generalization theory of neural networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed metric perspective analysis does not yield better results compared to previous theoretical results, and that the part of metric learning does not seem to work. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, the comment lacks specific references to the theoretical works mentioned, such as Bartlett et al. (2017), which would provide context and support for the claim. Without these references, the authors may find it challenging to verify the claim or understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the metric learning theory is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. This feedback highlights a potential weakness in the paper and suggests that the authors should reconsider their approach. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the analysis. While it points out a potential problem, it does not provide actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it directs the authors\\' attention to a specific area for improvement but does not fully support them in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should move some visual results from the supplementary to the main paper. It also points out that there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The reviewer suggests condensing the illustration of the proposed network architecture from three figures to two, and using the extra space for visual results. This feedback provides clear and concrete actions for the authors to take, such as selecting specific visual results to include and condensing the figures. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the main paper and the supplementary material, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that some visual results should be moved from the supplementary to the main paper, and it provides a specific suggestion to condense the illustration of the proposed network architecture from three figures to two. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that visual results should be moved from the supplementary to the main paper, as there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The comment provides a logical reasoning by pointing out the lack of visual results in the main paper and suggesting that condensing the illustration of the proposed network architecture could make room for visual results. However, the comment lacks specific examples or references to support the claim that visual results are necessary or how they would enhance the paper. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should move some visual results from the supplementary to the main paper. It highlights the lack of visual results on crowd density estimation, which is the main experiment of the paper, and recommends condensing the illustration of the proposed network architecture from three figures to two. This suggestion is clear and constructive, as it offers a concrete way for the authors to improve the presentation and clarity of their work. By addressing these points, the authors can enhance the reader\\'s understanding and engagement with their research. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should change the notation, provide additional clarification, or suggest an alternative notation. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems, which is confusing. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the confusion caused by using the same notation for different concepts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is confusing or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper regarding the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and actionable observation that can help the authors clarify their notation and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending alternative notations or explaining the context in which these terms are used. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the test example is crucially different, specifically asking if the patient in Figure 8 is \"British\" and whether the American corpus can detect this difference. While the comment implies that the authors should consider this issue, it does not provide explicit guidance on how to address it or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect in their analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the crucial differences in test examples, specifically mentioning the patient in Figure 8 and the use of an American corpus to explain it. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors can infer that it relates to the analysis or results section, but this inference is not direct. The comment is specific in its question about detecting crucial differences with corpus residual value, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the detection of crucial differences in test examples, specifically mentioning the patient in Figure 8 and the use of an American corpus to explain it. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it could be addressed. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a thought-provoking question about the detection of crucial differences in test examples, specifically mentioning the patient in Figure 8 and the use of an American corpus to explain it. This question highlights a potential issue with the analysis and prompts the authors to consider whether the corpus residual value can detect such differences. While the comment does not provide specific suggestions or guidance on how to address this issue, it does encourage the authors to reconsider their analysis and potentially improve the robustness of their results. Therefore, the comment is somewhat helpful, as it prompts the authors to consider an important aspect of their analysis that could enhance the quality of their work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP for their testbed. It provides a rationale for this suggestion, noting that WebQuestions would be more intuitive and straightforward for the task at hand, and could facilitate direct comparison with mainstream QA research. While the comment explicitly states the action to take, it does not provide specific guidance on how to implement this change or what additional considerations might be necessary. The action is clear but lacks detailed instructions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"WebQuestionsSP\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of dataset, suggesting that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP for their testbed. The reviewer provides a logical reasoning by explaining that WebQuestions would be more intuitive and straightforward for the task at hand, and could facilitate direct comparison with mainstream QA research. However, the comment lacks specific references or examples to support the claim that WebQuestions is more suitable for the task. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable, as it requires further elaboration to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to consider using a more popular dataset, WebQuestions, instead of WebQuestionsSP for their testbed. It offers a logical reasoning that using WebQuestions would be more intuitive and straightforward, and could facilitate direct comparison with mainstream QA research. This feedback is valuable as it encourages the authors to make a change that could enhance the clarity and relevance of their work. However, the comment could be more helpful if it provided specific examples or references to support the claim that WebQuestions is a better choice. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the need for making claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity, and that any potential training speed increases or cost savings must be demonstrated. While the comment implies that the authors should provide evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or examples to address the reviewer\\'s concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It mentions that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment does not specify which part of the paper these claims are made in, nor does it provide details on what specific evidence or demonstrations are needed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the claims and the need for evidence, but without explicit references to sections or examples, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. The reviewer provides a logical reasoning by pointing out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment lacks specific examples or references to support the claim that sparsity is not beneficial. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. While the comment identifies a potential weakness in the paper\\'s claims, it does not provide specific suggestions or guidance on how the authors might address this issue or present evidence to support their claims. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks actionable advice or detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the novelty of their work. There is no guidance on how to differentiate their design or what aspects could be improved to enhance novelty. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of novelty, specifically mentioning that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what aspect of novelty is lacking, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the novelty of the paper, specifically noting that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. While this feedback highlights a potential weakness, it lacks specificity and actionable suggestions on how the authors might address this issue or differentiate their work. Without detailed guidance or examples, the authors may struggle to understand how to improve the novelty of their design or what aspects could be further developed. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide enough direction for the authors to make significant improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should include analysis or results on other datasets, specifically mentioning ImageNet derivatives. It highlights the importance of verifying the effectiveness of the framework on these datasets and suggests that these results should be presented in the main paper. This feedback provides a clear and concrete action for the authors to take, making it highly actionable. The authors know exactly what additional results are needed and how to present them in the main paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for analysis or results on other datasets, specifically ImageNet derivatives. This allows the authors to accurately identify the part of the paper being addressed, which is the discussion of datasets and results. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on ImageNet-1k or ImageNet-100. This provides clear guidance on what additional analysis is needed to strengthen the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks analysis or results on other datasets, specifically ImageNet derivatives. It highlights the importance of verifying the effectiveness of the framework on these datasets and recommends presenting these results in the main paper. However, the comment does not provide specific examples or references to support why these datasets are important or how they would impact the paper\\'s conclusions. While the suggestion is logical, the lack of detailed justification or evidence makes it somewhat verifiable. The authors would need to make a significant effort to understand and address the suggestion, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of analysis or results on other datasets, specifically ImageNet derivatives. It highlights the importance of verifying the effectiveness of the framework on these datasets and suggests that these results should be presented in the main paper. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by including additional analyses or results. However, the comment could be more helpful if it offered specific guidance on how to present these results or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the model design, specifically mentioning that the architecture and learning details are fragmented or missing. It provides a clear suggestion for the authors to address this issue by either providing a plot of model illustration, pseudo-code table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the lesser-known nature of Neurochaos Learning. The explicit action and concrete details on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"model design\" and \"model architecture and learning details,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the fragmented or missing details of the model design, and provides a concrete suggestion to address this issue by providing a plot, pseudo-code table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the lesser-known nature of Neurochaos Learning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model design is unclear due to fragmented or missing details, specifically mentioning the importance of demonstrating integrated details to facilitate reproducibility. The comment suggests providing a plot, pseudo-code table, or code repository to address this issue. However, the comment lacks specific examples or references to support the claim that the model design is unclear or that Neurochaos Learning is not well-known. This makes the claim somewhat verifiable, as the authors would need to infer the importance of these details and the need for demonstration themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides a clear and actionable suggestion for the authors to address this issue by either providing a plot of model illustration, pseudo-code table, or code repository. This feedback is valuable as it guides the authors on how to improve the clarity and reproducibility of their work. However, the comment could be more helpful if it explained why these details are important or provided examples of how they could be presented. Overall, the comment is mostly helpful as it effectively directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be clearer to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is explicit and provides a clear action for the authors to take, which is to update the paper to reflect the correct usage of these models. The suggestion is concrete, as it specifies the exact change needed to be made, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Abstract\" and \"Introduction sections,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy between how BigFive and MBTI are described in the abstract and introduction sections as models to be extended, versus their usage as datasets in the experiments. The comment provides a clear suggestion to rectify this discrepancy by stating the models as datasets throughout the paper, unless there is a specific reason to extend the explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that BigFive and MBTI are stated as models to be extended in the abstract and introduction sections, while they are used as datasets in the experiments. The reviewer suggests that it would be clearer to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. The comment is somewhat verifiable as it logically points out a discrepancy in the paper\\'s presentation, but it lacks specific examples or references to support the claim that the models are not models but datasets. This makes the claim somewhat verifiable, as the authors would need to make a logical deduction to understand the issue and address it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be clearer to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is clear and actionable, as it provides a specific and straightforward suggestion for improving the paper\\'s clarity and consistency. By addressing this issue, the authors can enhance the readability and coherence of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include rejection rates or consider misclassifications as rejections in their experiments. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific suggestion for how to present the results, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rejection rate\" and \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of rejection rates or the consideration of misclassifications as rejections in the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rejection rate is not shown in any experiments and suggests that one could view a misclassification as a rejection. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is an issue or how it affects the paper\\'s conclusions. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the rejection rate is not shown in any experiments. It suggests that one could view a misclassification as a rejection, and recommends including rejection rates or considering misclassifications as rejections in the results. This feedback is clear and actionable, as it provides a direct suggestion for how the authors can improve their draft by including this information. However, the comment could be more helpful if it explained why this information is important or how it would enhance the paper\\'s conclusions. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify the generalization gaps in their work, specifically regarding the fine-tuning step in DIMES, and provide a comparison of DIMES with other methods on TSP100. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation and comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific issue of generalization to the TSP instances, particularly the fine-tuning step in DIMES. It also specifies what needs to be clarified, namely, the difference between DIMES and other methods on TSP100 in-distribution testing performance with/without meta-learning. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the generalization gaps in their work, specifically regarding the fine-tuning step in DIMES, and provide a comparison of DIMES with other methods on TSP100. While the comment identifies a potential issue with the generalization of DIMES, it lacks specific examples or references to support the claim that these gaps need clarification. The suggestion to compare DIMES with other methods is logical but not fully substantiated. Therefore, the claim is somewhat verifiable, as it provides a direction for improvement but lacks detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the generalization of the fine-tuning step in DIMES and suggests that the authors clarify the difference between DIMES and other methods on TSP100 in-distribution testing performance with/without meta-learning. This feedback is clear and actionable, as it provides a specific area for improvement and offers a direction for comparison with other methods. By addressing these points, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This provides clear and direct actions for the authors to take, ensuring they know exactly what information is needed to improve their draft. The request for the hyperparameters is specific, and the mention of reproducibility highlights the importance of sharing these details. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what information is needed to improve the reproducibility of the results. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for information, specifically asking for the final thresholds used for the results and the full set of hyperparameters. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a normal statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement by requesting the final thresholds used for the results and the full set of hyperparameters. This information is crucial for reproducibility and understanding the methodology. By providing this detail, the authors can enhance the transparency and reliability of their work. However, the comment could be more helpful if it explained why sharing these details is important or provided suggestions on how to present them effectively. Overall, the feedback is actionable and valuable, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential inconsistency in the authors\\' claim regarding the readability of RC datasets and its impact on question difficulty. However, it does not provide any explicit or implicit actions for the authors to take. The comment implies that the authors should clarify their methodology or consider alternative methods for answer detection, but it does not specify how to do so or what specific changes should be made. Without concrete guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the potential inconsistency in the authors\\' claim and suggesting that it depends on the method/features used for answer detection. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. It suggests that the authors\\' claim is dependent on the method/features used for answer detection, specifically mentioning POS/dependency parse features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the authors\\' claim regarding the readability of RC datasets and its impact on question difficulty. It points out that the authors\\' conclusion may depend on the method or features used for answer detection, specifically mentioning POS/dependency parse features. This feedback is somewhat helpful as it highlights a potential weakness in the authors\\' argument and suggests a direction for clarification or further exploration. However, the comment could be more helpful if it provided specific suggestions on how to address this inconsistency or how to better substantiate the claim. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment explicitly instructs the authors to optimize Figure 1 to use less whitespace, providing a clear and direct action for the authors to take. This guidance is specific and concrete, as it specifies the exact area that needs improvement and offers a specific improvement suggestion. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the optimization of Figure 1 to use less whitespace. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment suggests optimizing Figure 1 to use less whitespace. However, it does not provide any reasoning, evidence, or examples to support why this optimization is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment provides a specific and actionable suggestion to optimize Figure 1 by using less whitespace. This feedback is clear and direct, offering the authors a concrete way to improve the visual presentation of their data. However, the comment could be more helpful if it provided additional context or examples of how to achieve this optimization, such as suggesting alternative layouts or techniques. Despite this, the comment still offers valuable guidance that can help the authors enhance the clarity and readability of their figure. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. While the comment implies that the authors should conduct some form of analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or analysis to support their claims. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"morphological variants\" and the \"morphfitting results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support their claims. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support their claims. However, the comment does not provide any specific examples or references to support the claim that the morphological space is not meaningful. Without such evidence or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support their claims. It specifically questions whether the morphological variants are meaningfully clustered and whether the morphfitting results in a more meaningful space. This feedback is somewhat helpful as it prompts the authors to consider the significance of their results and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might conduct such an analysis or what kind of evidence would be most compelling. Overall, the comment provides a valuable direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing quality of the paper needs improvement, specifically noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should focus on improving the writing quality and expanding the related work section, but the comment lacks concrete details on how to achieve these improvements. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in identifying areas for improvement, such as the uneven distribution of space and the missing related work sections. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment lacks specific examples or references to support the claim that the writing is uneven or incomplete. Without detailed evidence or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it provides some indication but lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing quality of the paper, noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. This feedback is somewhat helpful as it highlights areas where the paper could be improved in terms of balance and comprehensiveness. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending which sections to prioritize or which additional related work to include. While it provides some direction, the lack of detailed advice limits its utility for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific line (Line 140) and raises a concern about the first column of Qo being replaced by vo to form P\\'o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to resolve it. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their assumptions and possibly revise the paper accordingly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the replacement of the first column of Qo by vo to form P\\'o, which results in the first state not being reachable anymore. The comment further assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first column of Qo is replaced by vo to form P\\'o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment lacks specific reasoning or evidence to support these claims, such as detailed explanations or references to relevant literature. This makes the claim somewhat verifiable, as the authors would need to infer the basis of the claim and potentially conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the first column of Qo is replaced by vo to form P\\'o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. While the comment highlights a potential problem, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what alternative assumptions might be considered. The feedback is somewhat helpful as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of the recurrent model, suggesting that the sequential relationship might be easier to model. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these areas to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment does not specify which part of the paper discusses FLOPs or inference time, making it weakly grounded. The suggestion to explore accuracy or specific properties is specific, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment lacks specific examples or references to support the claim that exploring accuracy or specific properties would lead to improvements. The suggestion is logical but lacks detailed justification or evidence, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for the authors to explore if there are improvements in accuracy or specific properties if they did not find improvements in FLOPs or inference time. It offers an example of the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is actionable and provides a clear direction for the authors to consider when evaluating their results. However, the comment could be more helpful if it included specific examples or references to support the claim about the sequential relationship. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings was tested. While it implies that the authors should address this assumption, it does not explicitly instruct them to do so. The comment is somewhat actionable because it provides a clear direction for the authors to consider testing this assumption, but it lacks concrete guidance on how to conduct the test or what specific aspects to focus on. Therefore, the authors can infer that they need to test the assumption but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the assumption that d_e are good replacements for entity embeddings, suggesting that this assumption should be tested. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its request for testing the assumption, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the assumption that d_e are good replacements for entity embeddings, suggesting that this assumption should be tested. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or how it might impact the paper\\'s conclusions. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the assumption that d_e are good replacements for entity embeddings, suggesting that this assumption should be tested. This is a valuable point as it highlights a potential weakness in the paper\\'s reasoning or assumptions. However, the comment lacks specific guidance on how to test this assumption or what aspects of the paper should be revised based on the test results. While it identifies an important area for consideration, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the components of the \"scoring function\" and the different threshold values/ranges. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included to clarify the methodology. The action is implicit and vague, as the authors are left to infer that they need to provide more information about the scoring function and threshold values. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"scoring function\" and the different components and threshold values/ranges, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the components and threshold values/ranges. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"scoring function\" and different threshold values/ranges are unclear. However, it does not provide any specific examples or detailed reasoning to support this claim. The comment lacks supporting evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the components of the \"scoring function\" and the different threshold values/ranges. It highlights a lack of clarity in the methodology, which is an important aspect for readers to understand. However, the comment does not provide specific suggestions or guidance on how the authors might clarify these aspects in their paper. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the table or what specific changes could be made to enhance the information presented. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the factors in a table do not effectively convey more messages than pure text, and there is no additional information. However, it does not specify which table or part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the table\\'s effectiveness, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific issue with the table, suggesting that the factors included do not effectively convey more messages than pure text. It highlights the lack of additional information and implies that the table is not contributing to the overall understanding of the paper. However, the comment does not provide any actionable suggestions or guidance on how the authors might improve the table or what specific changes could be made to enhance its utility. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the simulation should be considered. The comment lacks actionable details, such as recommending ways to categorize or analyze the different physical interactions, or suggesting ways to improve the simulation. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what kind of physical interactions are being considered or how they might impact the simulation. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual question seeking clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, which could be a relevant consideration for the authors. However, it lacks depth and does not provide any context or guidance on how this information might impact the paper or what specific aspects of the simulation should be considered. Without further explanation or suggestions, the authors are left without actionable feedback or direction on how to address this question. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a significant issue with the paper\\'s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. The comment provides explicit actions for the authors to take: to include more datasets with categorical features and to employ one hot encoding for the dataset with categorical features. These actions are concrete and specific, giving the authors clear guidance on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Model Comparison\" and the \"wide range\" of datasets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of datasets, noting that only one dataset has categorical features and that the authors do not employ one hot encoding for this dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model comparison is inadequate due to the selection of datasets, which only includes one with categorical features. The reviewer supports this claim by explaining that categorical features are generally more challenging for deep learning and that the lack of one hot encoding for this dataset could negatively affect performance. This reasoning is logical and based on common knowledge, providing a clear rationale for the claim. However, the comment could be strengthened by referencing specific studies or examples that support the assertion about categorical features and one hot encoding. Despite this, the claim is mostly verifiable, as it provides a solid foundation for the authors to address the issue.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve their model comparison by including more datasets with categorical features and employing one hot encoding for the dataset with categorical features. By addressing these points, the authors can significantly enhance the robustness and credibility of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data, or even some sets in UCI. While the comment identifies a potential issue with the choice of datasets, it does not provide explicit guidance on how to address this issue or what specific datasets would be better options. The authors are left to infer that they should consider alternative datasets, but the comment lacks concrete suggestions or examples of suitable datasets. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the choice of two unpopular IoT datasets for benchmarking is a strange choice, as the datasets are not widely followed or used. The reviewer supports this claim by referencing the specific datasets and their publication dates, which provides some context for the unpopularity of these datasets. However, the comment lacks specific examples or references to alternative datasets that would be more suitable for benchmarking. While the reasoning is logical and based on factual information, the lack of detailed examples or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the choice of datasets for benchmarking, specifically the two unpopular IoT datasets mentioned. It provides a logical reasoning for why these choices might be considered unusual, as they are relatively recent but not widely followed, and one of them is quite old. The comment suggests that there should have been better options, such as wearable health or mobile activity recognition data, or even some sets in UCI. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for the authors to consider alternative datasets. However, the comment could be more helpful if it offered specific suggestions or examples of alternative datasets that would be more suitable for benchmarking. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the authors\\' approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"pruning\" and \"distributed settings,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential need to find global top Q values of the metric over the average of gradients, which could impact acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients. This is a logical claim based on the observation that pruning is often used with large networks and that distributed settings are common for training. However, the comment lacks specific examples or references to support the claim that finding global top Q values is necessary to avoid breaking acceleration techniques like quantization and sparsification. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. This feedback is valuable as it highlights a potential gap in the authors\\' discussion of pruning and its implications on distributed settings. However, the comment could be more helpful if it provided specific examples or references to support the claim about the impact on acceleration techniques. Overall, the comment is somewhat helpful as it directs the authors\\' attention to an important aspect of their work that requires further consideration.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether some subfigures in Figures 1 and 2 have been swapped by mistake. While it implies that the authors should check the figures and potentially correct any errors, it does not provide explicit instructions on how to do so or what specific subfigures might be affected. The action is implicit and somewhat vague, as the authors need to infer that they should verify the figures themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about whether some subfigures have been swapped by mistake, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking whether some subfigures in Figures 1 and 2 have been swapped by mistake. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the possibility of subfigures in Figures 1 and 2 being swapped by mistake. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or verify the accuracy of the figures. The comment lacks actionable feedback or detailed analysis, making it somewhat helpful as it points out a potential problem but does not assist the authors in resolving it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the improvement in sensitivity provided by the dropout probe and its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also points out the potential risk of false positives due to the increased sensitivity. The reviewer suggests that this should be a substantial part of the discussion. While the comment implies that the authors should address this issue in their discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the potential risks of false positives. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"dropout probe\" and its ability to improve sensitivity, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential risk of false positives due to the increased sensitivity. This provides clear guidance on what needs to be addressed in the discussion. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the dropout probe improves sensitivity and identifies a causal role for syntactic representations that previous approaches might have missed. However, the comment suggests that this improvement also increases the risk of false positives, which is a valid concern. The reviewer provides a logical reasoning by pointing out that all other things being equal, one should consider this risk. However, the comment lacks specific examples or references to support the claim about the potential for false positives. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant improvement in sensitivity provided by the dropout probe, which allows it to find a causal role for syntactic representations that previous approaches might have missed. However, it also points out a potential risk of false positives due to the increased sensitivity. This is a valuable observation that could lead to a substantial part of the discussion. The comment highlights an important aspect of the paper that the authors should consider, but it does not provide specific guidance on how to address the risk of false positives or how to incorporate this discussion into the paper. While it offers a clear direction for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim a regret bound for the proposed mini-batch method but do not provide it in the supplementary material. The reviewer explicitly states that they could not find the regret bound in the supplementary, which implies that the authors should include it. However, the comment does not provide specific guidance on how to present the regret bound or where it should be located in the paper. While the action is clear, the lack of detailed instructions on implementation makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed mini-batch method being cast to the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the regret bound is not provided in the supplementary material and references a specific work for comparison. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors claim a regret bound for the proposed mini-batch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support the claim. This reference provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors claim a regret bound for the proposed mini-batch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support their claim. This feedback is clear and actionable, as it directs the authors to include the missing regret bound in the supplementary material. However, the comment could be more helpful if it provided additional guidance on how to present the regret bound or why it is important for the paper. Overall, the comment is mostly helpful as it highlights a critical oversight in the paper, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the paper formatting does not follow the NeurIPS formatting style, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that by fixing the paper style, the authors could gain some space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, such as adjusting the formatting style to conform to the NeurIPS guidelines and reorganizing the content accordingly. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper formatting, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the formatting, such as the font size of the abstract and the bottom page margins, and suggests that these issues could be addressed by following the NeurIPS formatting style. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper formatting is off, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that following the NeurIPS formatting style could improve the paper. While the comment identifies specific formatting issues, it lacks detailed reasoning or references to justify why the current formatting is problematic or how following NeurIPS guidelines would improve the paper. This makes the claim somewhat verifiable, as the authors would need to make an effort to understand and address the issues themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It points out specific formatting issues, such as the font size of the abstract and the bottom page margins, and suggests that by following the NeurIPS style, the authors could gain some space and include the NLP experiments in the main body of the paper. This feedback is clear and actionable, providing the authors with a concrete step to improve the formatting and organization of their paper. However, it could be more helpful if it included suggestions on how to implement the NeurIPS style or examples of how other papers have successfully followed this format. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not discuss or compare exploration methods in RL literature, specifically mentioning count-based methods and intrinsic motivations (RND and ICM). However, it does not provide any explicit guidance on how the authors should address this issue. The comment implies that the authors should include a discussion or comparison of these methods, but it lacks concrete instructions on how to structure this discussion or what specific aspects to cover. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on these methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion and comparison of these methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, specifically mentioning count-based methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact methods being referred to. Without detailed explanations or references, the claim is not fully verifiable, as it relies on general knowledge of RL literature. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that it does not discuss or compare exploration methods in RL literature, specifically mentioning count-based methods and intrinsic motivations (RND, ICM). This is a critical oversight, as these methods are widely used and relevant to the field. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as which methods to discuss or how to structure the comparison. While it points out a significant gap in the paper, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it implies that the authors should make the annotations larger, it does not provide specific guidance on how to achieve this or what size would be appropriate. The action is implicit and somewhat vague, as the authors need to infer that they should make the annotations larger but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the enlargement of annotations for better visibility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the annotations in Figure 4 could be enlarged for better visibility. However, it does not provide any supporting evidence, reasoning, or examples to justify why the annotations are currently too small or how enlarging them would improve visibility. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it provides a specific suggestion for improvement, it lacks depth and does not explain why the current annotations are too small or how enlarging them would impact the figure\\'s readability. The comment could be more helpful if it included additional context or examples to guide the authors on how to implement this suggestion effectively. As it stands, the feedback is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific changes should be made to improve the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 26-27,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the claim regarding the existence of multiple entities in both sentences and documents, including relation classification. The comment provides a clear critique of the claim and suggests that the authors should clarify or reconsider their statement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only document-level RE or joint entity and relation extraction.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. This is a relevant observation that could impact the validity of the paper\\'s claims. However, the comment lacks specificity and does not provide any guidance on how the authors might address this issue or what changes could be made to improve the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with Figure 4, noting that one of the labels on the color bar should say \"worse\" instead of \"better.\" This comment provides a clear and direct action for the authors to take, ensuring that the label is corrected. The action is concrete, as it specifies exactly what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, noting that one of the labels should say \"worse\" instead of \"better.\" This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about a specific figure, Figure 4, noting that one of the labels on the color bar is incorrect. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that one of the labels on the color bar is incorrect. This is a clear and actionable piece of feedback that the authors can easily address to improve the accuracy and clarity of their visual presentation. By pointing out this mistake, the comment helps the authors ensure that their figures accurately represent their data and findings. However, the comment could be more helpful if it provided additional context or suggestions on how to improve the figure or its interpretation. Overall, the comment is mostly helpful as it directs the authors to a specific area for correction, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a specific error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely, changing \"training/validation/test\" to \"training/validation/test sets.\" This provides clear guidance on how to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual correction, noting a typographical error in the text. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific typographical error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and actionable suggestion that can help the authors improve the accuracy and clarity of their draft. By addressing this error, the authors can ensure that their manuscript is more precise and professional in its presentation. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the paper, but it does not provide explicit or implicit actions for the authors to take. It asks for clarification on the inference process and the coefficient of the p(L, E | X) term in line 307, but it does not instruct the authors on how to address these questions or provide guidance on how to improve the clarity of the writing. The comment also mentions missing hyperparameter details and suggests that ablation studies may not be well-tuned, but it does not provide specific suggestions for improvement. Overall, the comment lacks actionable guidance, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises several questions and concerns about the paper, but it does not specify which part of the paper these issues pertain to. It mentions \"line 307\" and \"hyperparameter details,\" but these references are not explicit enough to allow the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity in detailing what is missing or unclear about the inference process, the coefficient of the p(L, E | X) term, or the writing style. Without clear guidance on what needs to be addressed, the authors cannot effectively improve their draft. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises several questions and concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the clarity of the writing. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the claims made. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the clarity of the writing. It questions whether inference is slowed down drastically and whether there is a way to only perform inference. Additionally, it points out missing hyperparameter details and suggests that ablation studies may not be well-tuned. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the clarity of their writing. While it identifies areas for improvement, the feedback is not actionable and does not provide detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the definition of the quantile is confusing and recommends adding extra brackets around the term or defining the bracketed term separately if space allows. This provides a clear and explicit action for the authors to take, which is to clarify the definition by adding brackets or defining the bracketed term. The comment is specific and provides concrete guidance on how to improve the clarity of the definition. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to clarify the definition by adding extra brackets or defining the bracketed term separately if space allows. This level of detail provides the authors with clear guidance on how to improve the clarity of the definition. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the definition of the quantile is confusing and provides a specific suggestion to clarify it by adding extra brackets or defining the bracketed term separately. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks detailed explanation or examples to fully substantiate the claim. The authors might need to infer the exact impact of the suggested changes, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the definition of the quantile, which is described as \"a little confusing.\" It provides a clear and actionable suggestion to improve the clarity of the definition by adding extra brackets or defining the bracketed term separately if space allows. This feedback is valuable as it directly addresses a potential source of confusion and offers a concrete way to enhance the clarity of the paper. However, the comment could be more helpful if it explained why the current definition is confusing or provided additional context on how the suggested changes would improve the clarity. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model mentioned in Line 152 is no longer state-of-the-art and recommends replacing it with a phrase like \"very high performing model\" or similar. This feedback is explicit and provides a clear action for the authors to take, specifying the exact change needed to update the text. The suggestion is concrete, as it provides a specific alternative phrase to use, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the outdated nature of the model mentioned and the suggestion to replace it with a more current description. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the model mentioned in Line 152 is no longer state-of-the-art and recommends replacing it with a phrase like \"very high performing model\" or similar. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the model mentioned in Line 152 is no longer state-of-the-art. It provides a clear and actionable suggestion to replace the outdated reference with a more appropriate description, such as \"very high performing model\" or similar. This feedback is valuable as it helps the authors maintain the accuracy and relevance of their work by updating the reference to a more current model. However, the comment could be more helpful if it included a rationale or explanation for why the original reference is no longer relevant. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is identified as the main weakness of the method. However, the comment does not provide any guidance on how the authors should address this issue or suggest specific actions to improve the performance. The authors are left without any concrete steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed compression\" and \"PQ,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the proposed compression performs worse than PQ when a small code length is allowed, which is the main weakness of the method. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment does not provide any supporting evidence, comparisons, or references to substantiate this claim. Without additional details or justification, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is considered the main weakness of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the performance of their method. Without actionable feedback or detailed insights, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as barely helpful, as it points out a problem but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including inappropriate subjective statements, the need for proofs and references to support claims, and the labor-intensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multi-scale features and suggests that models with skip connections could be considered implicit multi-scale methods. The comment explicitly instructs the authors to provide a detailed explanation to verify these statements. While the action is clear, it is somewhat vague in terms of how to present the explanation, as it does not specify the exact format or content of the explanation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues with the paper, including the appropriateness of subjective statements, the need for proofs and references, and the labor-intensive nature of designing effective architectures. It also mentions the uncertainty regarding when to fuse multi-scale features and suggests that models with skip connections could be considered implicit multi-scale methods. However, the comment does not specify which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for proofs and references, and the need for a detailed explanation of the statements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims and suggestions, including the need for proofs and references to support subjective statements, the labor-intensive nature of designing effective architectures, and the uncertainty regarding when to fuse multi-scale features. The reviewer also suggests that models with skip connections could be considered implicit multi-scale methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or examples makes the claims somewhat verifiable, as the authors would need to make a significant effort to understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the appropriateness of subjective statements, the need for proofs and references to support claims, and the labor-intensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multi-scale features and suggests that models with skip connections could be considered implicit multi-scale methods. The comment provides clear and actionable feedback by suggesting that the authors should provide detailed explanations to verify these statements and address the issues raised. This guidance is valuable for the authors to improve their draft, making the comment mostly helpful. However, it could be more comprehensive by offering specific examples or suggestions on how to present the explanations. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how the proposed method compares with prior art. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so or offer guidance on how to conduct this comparison. The action is implicit and somewhat vague, as the authors can infer that they need to address this issue but may not be entirely sure of the specifics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the comparison with prior art is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison with prior art. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about how the proposed method compares with prior art. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the comparison of the proposed method with prior art. While it highlights an important area for clarification, it does not provide any guidance or suggestions on how the authors might address this comparison or what specific aspects should be considered. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as barely helpful, as it identifies an area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the analysis could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that the authors should explore potential biases in different languages/nationalities and consider whether there are interesting observations to be made. While the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so, it does offer a clear direction for improvement. The action is implicit but concrete, as the authors can infer that they need to expand their analysis to include more detailed observations. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the analysis could be more detailed by exploring potential biases in different languages/nationalities and whether there are interesting observations to be made. This provides clear guidance on what the authors could address to improve their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the analysis could be more detailed, specifically mentioning the \"language/nationality\" section and noting the inclusion of 20 different types. The reviewer expresses curiosity about potential biases and interesting observations that could be made. However, the comment lacks specific examples or references to support the claim that such biases exist or that they would be interesting to explore. Without detailed evidence or examples, the claim is somewhat verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the analysis section, suggesting that the authors could explore potential biases and interesting observations in the \"language/nationality\" data. It highlights the inclusion of 20 different types and implies that there could be interesting insights to be gained by comparing these. While the comment does not provide detailed guidance on how to conduct this analysis or what specific observations might be relevant, it does offer a clear direction for the authors to enhance their draft. This feedback is mostly helpful as it points out a potential area for enriching the analysis, but it could be more actionable with additional suggestions or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, it does not provide explicit guidance or suggestions on what other properties could be considered or how to incorporate them into the approach. The action is implicit and somewhat vague, as the authors need to infer that they should explore other feature properties and consider how they might impact the approach design. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this discussion might be relevant. The authors can infer that it relates to the methodology or approach sections, but this inference is not direct. The comment is specific in its suggestion to consider other properties, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is the case or how it would impact the approach design. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a relevant question about the use of other properties of features in addition to norm, suggesting that this could be necessary and helpful for the approach design. This is a valuable point that could prompt the authors to consider alternative feature properties that could enhance their methodology. However, the comment lacks specific suggestions or examples of other properties that could be explored, which limits its helpfulness. While it prompts the authors to consider a broader range of feature properties, it does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the conservation properties of learning F^\\dagger in the context of physics-related continuous PDEs. It suggests that the authors should consider whether it is possible to train F^\\dagger such that certain conservation properties are maintained. The reviewer also asks for numerical illustrations to demonstrate the conservation properties in Hamiltonian systems. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete steps for how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"solvers' algorithms\" and \"learning F^\\dagger,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by asking about the conservation properties of learning F^\\dagger in the context of physics-related continuous PDEs and whether it is possible to train it to maintain certain properties. The comment is specific in its request for numerical illustrations to demonstrate the conservation properties in Hamiltonian systems. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the conservation properties of learning F^\\dagger in the context of physics-related continuous PDEs. It suggests that solvers' algorithms can maintain certain mathematical properties, such as not losing mass or charge, and asks if it is possible to train F^\\dagger to maintain similar properties. The reviewer also requests numerical illustrations to demonstrate the conservation properties in Hamiltonian systems. While the comment poses valid questions, it lacks specific examples or references to support the claim that solvers' algorithms maintain these properties. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the conservation properties of learning F^\\dagger in the context of physics-related continuous PDEs. It suggests that solvers' algorithms can maintain certain mathematical properties, such as not losing mass or charge, and asks if it is possible to train F^\\dagger to maintain similar properties. The reviewer also requests numerical illustrations to demonstrate the conservation properties in Hamiltonian systems. This feedback is valuable as it prompts the authors to consider the conservation properties of their method and provides a clear direction for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to address these questions or what kind of numerical illustrations would be most informative. Overall, the comment is mostly helpful as it guides the authors toward a deeper understanding of their method\\'s properties and potential applications.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. However, it does not provide explicit guidance on how to address these weaknesses or suggest specific changes. The authors are left to infer that they should make changes to the method, but without detailed instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific weaknesses in the method, such as the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the use of two SIRENs and the contribution in the signed distance function. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without detailed explanations or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. It questions the necessity of using two SIRENs for f and d and suggests that the d should be a simpler network. While the comment highlights areas for improvement, it lacks specific guidance or suggestions on how to address these weaknesses. The authors are left with a general understanding of the issues but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the RQ1 mentioned in the paper is redundant and does not provide additional information. It also proposes an alternative analysis, which is to examine the effect of explicit hate information on implicit hate speech detection performance and vice versa, and its impact on RQ2 and RQ3 t-sne plots. The reviewer provides a reference to a similar analysis in another paper, which could guide the authors in conducting their own analysis. The comment is explicit in suggesting a specific action\u2014analyzing the effect of explicit hate information on implicit hate speech detection performance\u2014and provides a concrete example of how this analysis could be conducted. However, it does not specify how to implement the analysis or what specific metrics should be used. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RQ1\" and \"RQ2\" and \"RQ3 t-sne plots,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the redundancy of RQ1 and the suggestion to analyze the effect of explicit hate information on implicit hate speech detection performance and vice versa, as well as its impact on RQ2 and RQ3 t-sne plots. The reference to a similar analysis in another paper provides additional guidance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the RQ1 mentioned in the paper is redundant and does not provide additional information. It suggests an alternative analysis involving the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 t-sne plots. The reviewer provides a reference to a similar analysis in another paper, which supports the claim by offering a concrete example of how this analysis could be conducted. This reference provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the reference to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential redundancy in the RQ1 mentioned in the paper and suggests an alternative analysis that could provide valuable insights. It proposes analyzing the effect of explicit hate information on implicit hate speech detection performance and vice versa, and its impact on RQ2 and RQ3 t-sne plots. This feedback is clear and actionable, as it provides a specific direction for the authors to explore and potentially enhance their analysis. By suggesting a new angle for analysis, the comment offers a constructive way for the authors to improve their draft. However, it could be more helpful if it provided additional guidance on how to conduct this analysis or what specific metrics or methods should be used. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not provide any specific guidance on which tasks should be discussed or how to address this expectation. The action is implicit and vague, as the authors are left to infer that they need to expand their discussion on the importance of PE in tasks beyond link prediction. Without concrete instructions or examples, the authors may find it challenging to know how to implement this suggestion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or discussion where this topic could be addressed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in suggesting that the paper should discuss tasks beyond link prediction where PE is important, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this expectation is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. While it identifies a potential area for expansion, it lacks specificity and does not provide any guidance on which tasks or aspects of PE should be discussed. The comment is vague and does not offer actionable advice or examples, leaving the authors without clear direction on how to address this suggestion. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and specificity to be fully beneficial for the authors.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the difference between the authors\\' work and other works focusing on semantic face editing. While it implies that the authors should provide a comparison or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this point. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the difference between the authors\\' work and other works focusing on semantic face editing. However, it does not specify which part of the paper this comparison should be made, nor does it provide details on what aspects of the work need to be compared. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the difference between the authors\\' work and other works focusing on semantic face editing. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a valid point by asking the authors to elaborate on the difference between their work and other works focusing on semantic face editing. This is a constructive suggestion that could help the authors better position their contribution in the context of existing research. However, the comment lacks specific guidance on how to address this difference or what aspects of the work should be compared. While it identifies an important area for improvement, it does not provide detailed instructions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a potential improvement in the evaluation of the quality of the set of policies, specifically by using the minimum over the set of test MDPs rather than the summation. This feedback provides a clear and explicit action for the authors to consider, as it offers a specific alternative approach to evaluating the performance of the policies. The comment is concrete in its suggestion and provides a clear rationale for the change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the intuitive goal of finding a set of policies that contains an optimal policy for every test MDP in S_{test}. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for the suggested change in evaluation, explaining the potential issue with the summation approach and suggesting the use of the minimum instead. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a potential improvement in the evaluation of the set of policies by using the minimum over the set of test MDPs rather than the summation. The reviewer provides a logical reasoning for this suggestion, explaining that the summation might lead to selecting a subset of policies that are good for most MDPs but poor for the remaining ones, which could be hidden by the summation but highlighted by the minimum. This reasoning is based on a clear understanding of the evaluation process and the potential consequences of the current approach, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar approaches in the literature to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed and actionable suggestion for improving the evaluation of the set of policies. It highlights a potential issue with the current approach, which is that the summation might lead to selecting a subset of policies that are good for most MDPs but poor for the remaining ones. The reviewer suggests using the minimum over the set of test MDPs instead, which would better capture the performance of the policies in the worst-case scenario. This feedback is clear and constructive, offering a specific and meaningful improvement that could enhance the quality of the paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to reduce the use of footnotes and move important content into the main body of the paper. It provides a specific example by suggesting moving details around parameter settings to the appendix. This feedback is clear and concrete, giving the authors a direct action to take to improve the draft. The suggestion to move content to the appendix is also detailed, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of footnotes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of excessive use of footnotes and suggests moving important content into the main body of the paper. The comment provides a specific example by suggesting moving details around parameter settings to the appendix. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that footnotes are used excessively in the paper, which is distracting. It suggests that much of the content is important and should be moved into the main body of the paper. The reviewer provides a specific example by suggesting moving details around parameter settings to the appendix. This suggestion is based on a logical observation that footnotes are not necessary for the main content of the paper. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that footnotes are used excessively and distracting from the main content. It suggests that much of the important content should be moved into the main body of the paper. The comment provides a specific example by suggesting moving details around parameter settings to the appendix. This feedback is clear and actionable, offering a concrete suggestion for improvement that can help streamline the paper and enhance its readability. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate the content into the main body of the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the inclusion of zero-shot generation results in the paper is somewhat unusual and raises a question about its relevance. However, it does not provide explicit guidance on whether the authors should remove these results or explain their inclusion. The comment lacks concrete instructions on how to address this issue, leaving the authors uncertain about how to proceed. Therefore, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the inclusion of zero-shot generation results in the paper is somewhat unusual and raises a question about its relevance. However, it does not specify which part of the paper this discussion should be included in, such as the results or discussion sections. The authors can infer that it relates to the experimental results or methodology, but this inference is not direct. The comment is specific in its critique of the inclusion of zero-shot generation results but lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the inclusion of zero-shot generation results in the paper is somewhat unusual and raises a question about its relevance. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed justification or examples to explain why the inclusion of zero-shot generation results is unusual or why it might not be relevant. As a result, the claim is not verifiable, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the inclusion of zero-shot generation results in the paper, suggesting that it might be somewhat unusual and questioning its relevance. While it acknowledges the interest of the experiments, it points out that the inclusion of zero-shot generation results might not be directly related to the main focus of the paper. The comment provides a clear suggestion for improvement by recommending a discussion about the inclusion of these results. However, it could be more helpful if it offered specific reasons why the inclusion of zero-shot generation results might be less relevant or if it provided suggestions on how to better integrate them into the paper. Overall, the comment is somewhat helpful as it highlights an area for improvement but lacks depth and specific guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a minor issue with Figure 3, specifically noting that \"OAA\" is not referenced in the body text and suggesting that there might be more content in the appendix that is missing. The reviewer also mentions that the caption might be out of date. While the comment identifies a specific issue, it does not provide explicit guidance on how to address it, such as suggesting where to add the missing reference or how to update the caption. The action is implicit and somewhat vague, as the authors need to infer that they should review and update the figure and its caption. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that \"OAA\" is not referenced in the body text and suggesting that there might be more content in the appendix that is missing. Additionally, it points out that the caption might be out of date. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"OAA\" is not referenced in the body text of Figure 3 and suggests that there might be more content in the appendix that is missing. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a minor issue with Figure 3, specifically noting that \"OAA\" is not referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment highlights a specific problem, it lacks depth and does not provide actionable guidance on how to address the issue or improve the figure. The authors are informed of the issue but are not given detailed instructions on how to resolve it. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify in the introduction that the proposed solution is a fix of [12], rather than a new PIC approach. It provides a specific suggestion to make this clarification by mentioning the reference in lines 29-30. The action is clear and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (29-30) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the clarification of whether the proposed solution is a fix of [12] or a new PIC approach. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors need to clarify in the introduction that the proposed solution is a fix of [12], rather than a new PIC approach. The reviewer supports this claim by referencing specific lines in the paper (29-30) where the proposed solution is introduced as a new PIC approach. This provides a clear and specific example of the issue, making the claim mostly verifiable. However, the comment could be strengthened by referencing [12] directly or providing more context on why this clarification is important. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific issue with the introduction of the paper, namely, the lack of clarity regarding whether the proposed solution is a fix of [12] or a new PIC approach. By pointing out the confusion in lines 29-30, the reviewer provides clear guidance on how the authors can improve the clarity of their introduction. This feedback is actionable and constructive, as it directs the authors to make a precise and necessary correction that can enhance the readability and understanding of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference [2]. However, it does not provide explicit instructions or suggestions on how the authors should address this question or investigate the impact of the GS module on the effective receptive field. The comment lacks concrete guidance on what specific analyses or experiments the authors should conduct to answer this question. As a result, the authors are left without clear direction on how to proceed with this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"GS module\" and suggests that the effective receptive field can be computed from a reference [2]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks a question about the effectiveness of the GS module and suggests that the authors investigate how the effective receptive field changed after applying it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the effectiveness of the GS module in propagating context information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference [2]. This is an interesting point that could lead to further exploration and analysis. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might investigate or address this question. While it points out a potential area for improvement, it does not offer actionable steps or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the objective for the LSTM part is the same for pre-training and finetuning, and that the authors may add another head to the network computing the value functions for the states during the finetuning stage. While the comment provides a clear action\u2014adding another head to the network\u2014it does not specify how to implement this addition or what specific changes are needed in the code or methodology. The authors are left with a general idea of what to do but without detailed guidance on execution. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the objective for the LSTM part is the same for pre-training and finetuning, and that the authors may add another head to the network during the finetuning stage. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the LSTM is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential change in the objective and the addition of another head, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the objective for the LSTM part is the same for pre-training and finetuning, and that the authors may add another head to the network during the finetuning stage. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the objective of the LSTM part, suggesting that it is the same for pre-training and finetuning. It also provides a specific suggestion for improvement, recommending the addition of another head to the network during the finetuning stage to compute the value functions for the states. This feedback is clear and actionable, as it points out a potential weakness and offers a concrete suggestion for improvement. However, it could be more helpful if it provided additional context or examples on how this change would impact the results or methodology. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind combining G4RL with HRAC and asks if G4RL requires HRAC's regularization in the latent space. While the comment implies that the authors should provide an explanation or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the question but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"HRAC-G4RL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC's regularization in the latent space. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC's regularization in the latent space. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind combining G4RL with HRAC and asks if G4RL requires HRAC's regularization in the latent space. This is a relevant question that could help the authors understand the basis of their method and its potential limitations. However, the comment does not provide any suggestions or guidance on how the authors might address this question or improve their explanation. While it points out a potential area for clarification, it lacks actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should acknowledge some of the older works related to supervised, multilingual systems. While the comment implies that the authors should include this acknowledgment, it does not provide specific guidance on which works to mention or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works related to supervised, multilingual systems, providing clear guidance on what needs to be addressed in this section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should acknowledge older works related to supervised, multilingual systems. However, it does not provide specific examples or references to these older works, nor does it explain why acknowledging them is important. Without additional context or reasoning, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should acknowledge older works related to supervised, multilingual systems. While it identifies a potential gap in the literature review, it does not provide specific examples of older works to consider or explain why acknowledging them would be beneficial. The comment is somewhat helpful as it points out an area for improvement, but it lacks depth and actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the results in Table 2, specifically the linear-/exponential-decay sampling, and suggests that it may underperform uniform sampling. The reviewer points out that if the predictor is accurate on the good subregion, increasing the sampling probability for top-performing architectures should lead to better performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their results. The suggestion is implied and lacks concrete details, making it somewhat actionable. The authors can infer that they need to reconsider their sampling strategy, but the comment does not offer specific steps or examples on how to implement this change.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the results in Table 2, particularly the linear-/exponential-decay sampling, and suggests that it may underperform uniform sampling. The comment further explains the potential reason for this underperformance, based on the authors\\' argument about the predictor\\'s accuracy in the good subregion. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the results in Table 2, specifically the linear-/exponential-decay sampling, and suggests that it may underperform uniform sampling. The reviewer provides a logical reasoning by pointing out that if the predictor is accurate in the good subregion, increasing the sampling probability for top-performing architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is close. This reasoning is based on a logical assumption and provides a plausible explanation for the potential underperformance. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the results in Table 2, specifically the linear-/exponential-decay sampling, and suggests that it may underperform uniform sampling. The reviewer provides a logical reasoning by pointing out that if the predictor is accurate in the good subregion, increasing the sampling probability for top-performing architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is close. This feedback is somewhat helpful as it highlights a potential issue with the results and suggests a possible explanation for the observed underperformance. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or improve their results. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the time complexity of the proposed method, including the use of an item-oriented autoencoder, the elementwise function, and the number of hidden units. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the time complexity. The comment lacks concrete details on how to implement these improvements, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the elementwise function, and the number of hidden units. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with time complexity, such as the number of users associated with a typical item, the elementwise function, and the number of hidden units. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time complexity of the proposed method is high due to the use of an item-oriented autoencoder, the elementwise function, and the number of hidden units. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks references or examples to substantiate the assertion that the time complexity is high, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some evidence but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the proposed method, specifically noting the use of an item-oriented autoencoder, the elementwise function, and the number of hidden units. While it highlights these factors as contributing to the high time complexity, it does not provide specific suggestions or guidance on how the authors might address or mitigate this issue. The comment lacks actionable advice or detailed analysis, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the figures would be clearer if they explicitly mention \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a specific action for the authors to take, which is to add this information to the figures to enhance clarity. The comment is explicit and provides concrete guidance on how to implement the suggested change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that many of the figures would be clearer if they mentioned \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, it does not specify which figures or sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting what needs to be clarified, namely the types of autoencoders used in the figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the figures would be clearer if they mentioned \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the figures. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that many of the figures would be more clear if they explicitly mention \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is somewhat helpful as it identifies a specific area for improvement in the clarity of the figures, which could enhance the readers\\' understanding of the content. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why it is important. Additionally, it does not address other aspects of the paper, such as the content or methodology. Therefore, the comment is somewhat helpful, as it points out a specific area for improvement but lacks comprehensive guidance for the authors.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison with a NeRF-based method, specifically mentioning the recent Zero-1-to-3 and point-e. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides explicit actions to include comparisons and question the relevance, it lacks concrete details on how to implement these suggestions. The authors are given a clear direction but may need to infer the specifics of how to conduct these comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including comparisons with NeRF-based methods, specifically mentioning Zero-1-to-3 and point-e. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment does not specify which part of the paper these comparisons should be included in or how the relevance of the occlusion experiment should be addressed. While the authors can infer that the suggestions relate to the experimental section, the comment lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with NeRF-based methods, specifically mentioning Zero-1-to-3 and point-e, is missing. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment lacks specific examples or detailed reasoning to support these claims. The mention of Zero-1-to-3 and point-e provides some context, but the lack of detailed justification or evidence makes the claim somewhat verifiable. The authors would need to further explore the relevance and applicability of these comparisons to fully understand and address the reviewer\\'s concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting the inclusion of comparisons with NeRF-based methods, such as Zero-1-to-3 and point-e. This suggestion is clear and can help the authors enhance the comprehensiveness and relevance of their evaluation. Additionally, the comment questions the relevance of the occlusion experiment, which could be a critical area for improvement. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these comparisons or why the occlusion experiment is not relevant. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a brief explanation of \"multi-aspect\" would be helpful and questions the subscripts s and t in Figure 1, suggesting they should be 1 and 2. While the comment implies that the authors should provide an explanation and clarify the subscripts, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation and clarify the subscripts. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 14, 47,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a brief explanation of \"multi-aspect\" and questions the subscripts s and t in Figure 1, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a brief explanation of \"multi-aspect\" would be helpful and questions the subscripts s and t in Figure 1. However, it does not provide any supporting evidence, reasoning, or references to justify why an explanation is necessary or why the subscripts should be changed. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement, namely the need for a brief explanation of the term \"multi-aspect\" and the questionable subscripts s and t in Figure 1. While it provides clear guidance on what needs to be addressed, it lacks depth and does not offer detailed suggestions or examples on how to improve the explanation or clarify the subscripts. The feedback is somewhat helpful as it points out specific areas for improvement, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It explicitly requests a more detailed analysis of these aspects. While the comment identifies areas for improvement, it does not provide specific guidance on how to conduct the analysis or what aspects should be emphasized. The authors are left to infer that they need to provide more detailed information, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p,\" which likely refers to a specific parameter or value used in the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and seek clarification, making them purely descriptive. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis of these aspects, which could significantly enhance the paper\\'s clarity and rigor. However, the comment lacks specific guidance on how to conduct the analysis or what aspects should be emphasized. While it identifies areas for improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out potential weaknesses but does not fully support the authors in addressing them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This is a clear and direct request for additional details that the authors can easily address by providing the requested information. The action is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what information is needed, providing clear guidance on what needs to be added to the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for additional information about the computational requirements and runtime of the experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it prompts the authors to provide additional information about the computational requirements and runtime of the experiments. This is important as it can help the authors understand the feasibility and scalability of their work. However, the comment could be more helpful if it provided specific suggestions on how to present this information or what aspects to focus on. Despite this, the feedback is clear and actionable, guiding the authors to enhance the transparency and reproducibility of their work. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors only apply the meta sampler in a decoupled way, specifically when the features are fixed. It also requests more discussion on this aspect and asks for clarification on when the authors start applying the meta sampler. While the comment implies that the authors should provide more information on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more discussion and clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"meta sampler\" and the \"linear classifier,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on whether the meta sampler is applied in a decoupled way and requests more discussion on this topic. Additionally, it asks for clarification on when the meta sampler is applied, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It highlights a potential area for clarification and improvement in the paper, which could enhance the understanding of the methodology and its implementation. However, the comment does not provide detailed guidance or suggestions on how to address this issue or what specific aspects of the discussion should be expanded upon. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and encourages them to follow a cited AAAI paper on fairness-aware metrics like Equality Odds (EO). While the comment provides a clear action to take, it lacks specific guidance on how to conduct these experiments or what aspects of the AAAI paper should be followed. The authors are given a direction but not detailed instructions on how to implement the suggested changes. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of a vanilla metric and suggests conducting more experiments on datasets like COMPAS and Drug Consumption. It also references a specific AAAI paper, which provides clear guidance on what aspects of the paper should be addressed. However, the comment lacks specificity regarding what aspects of the vanilla metric or the suggested experiments should be improved or how the authors should conduct them. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and mentions a specific AAAI paper for reference. However, the comment does not provide any specific reasoning or evidence to support why these additional experiments are necessary or how they would improve the paper. The mention of the AAAI paper is a reference but does not provide detailed justification for the suggestion. Therefore, the claim is somewhat verifiable, as it lacks sufficient explanation or evidence to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors use their own vanilla metric and lack related fairness-aware metrics like Equality Odds (EO). It suggests conducting more experiments on datasets like COMPAS and Drug Consumption, and references a specific AAAI paper for guidance. While the comment provides a clear direction for improvement, it lacks detailed guidance on how to conduct these experiments or what aspects of the AAAI paper should be followed. This limits the comment\\'s helpfulness, as it offers actionable advice but does not provide comprehensive guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to either state the content as a remark or move it to a Discussion section or remove it altogether. This provides a clear and direct action for the authors to take, ensuring that the content is either revised or removed as needed. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107-114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the content seems speculative or overly opinionated and suggests it should be stated as a remark, moved to a Discussion section, or removed. This provides clear guidance on how to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"L107-114 seems speculative or overly opinionated.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific section of the paper (L107-114) as potentially speculative or overly opinionated. It suggests that this content should be stated as a remark, moved to a Discussion section, or removed. This feedback is clear and actionable, providing the authors with a concrete direction to address the issue. By suggesting a specific approach to handling the content, the comment offers valuable guidance on how to improve the clarity and objectivity of the paper. However, it could be more helpful if it provided additional context or examples to support the claim of speculation or overly opinionated content. Overall, the comment is mostly helpful as it effectively directs the authors to a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is concrete, as it specifies the baselines to consider, but it is somewhat vague because it does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the evaluation or experimental sections, but this inference is not direct. The comment is specific in suggesting the inclusion of these baselines, but it lacks grounding as it does not explicitly mention the sections where these changes should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these baselines are relevant or how they would impact the evaluation. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks depth and does not provide specific guidance on how to implement this suggestion or why these baselines are particularly relevant. While it points out a potential enhancement, it could be more helpful if it included more detailed instructions or justification for the inclusion of these baselines. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies two missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model's performance, and the use of different hyperparameter sets per dataset. It suggests that providing insights into the value of h and its robustness across different neighborhood sizes is essential. Additionally, it questions the use of different hyperparameter sets per dataset and suggests that authors provide insights into how performance varies with a constant set of parameters. The comment is clear and provides specific actions for the authors to take, such as conducting an analysis of h and its influence on performance, and standardizing hyperparameter sets across datasets. The explicit nature of the suggestions and the concrete details on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model's performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for an analysis of the robustness of the method with respect to different neighborhood sizes and the use of different hyperparameter sets per dataset. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the value of neighborhood size h and its influence on the model's performance are missing elements in the paper. It suggests that this is a key parameter of the proposed strategy and that providing insights into its value and robustness is essential. The comment also questions the use of different hyperparameter sets per dataset, suggesting that standardizing these parameters would be ideal. While the comment provides a logical reasoning for the importance of these elements, it lacks specific examples or references to support the claim that these are indeed missing or essential. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two important missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model's performance, and the use of different hyperparameter sets per dataset. It suggests that providing insights into the value of h and its robustness across different neighborhood sizes is essential, as this is a key parameter of the proposed strategy. Additionally, it questions the use of different hyperparameter sets per dataset, suggesting that standardizing these parameters would be ideal. The comment is clear and actionable, offering specific suggestions for improvement that can help the authors enhance the clarity and robustness of their work. By addressing these points, the authors can significantly improve the comprehensiveness and effectiveness of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model's ability to construct higher-order interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment implies that the authors should consider these questions and potentially address them in their paper, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these aspects of the model. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model's ability to construct higher-order interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the model's performance or analysis. The comment is specific in its inquiry about the impact of missing modalities and the potential for leveraging additional modalities. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the impact of imperfect multimodal data on the model, specifically asking whether missing modalities affect the model's ability to construct higher-order interactions and polynomial tensors. The comment does not make a claim or express an opinion but rather seeks clarification or additional information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model's ability to construct higher-order interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. This feedback is valuable as it prompts the authors to consider a critical aspect of their model's robustness and generalizability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or explore the impact of missing modalities. Overall, the comment is somewhat helpful as it directs the authors to consider an important aspect of their model but lacks detailed guidance on how to implement the suggested exploration.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It provides a specific example of how this could be done by showing the frequency of these words in the dataset. The comment is explicit in its request for additional data analysis, providing concrete guidance on what the authors should do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. The comment provides a specific example of how this could be done, making it clear and actionable. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. The reviewer provides a specific example of how this could be done, which is to show the frequency of these words in the dataset. This suggestion is based on logical reasoning and common knowledge about the nature of datasets and data analysis. However, the comment lacks references or detailed justification for why this analysis is necessary or how it would enhance the paper. Therefore, the claim is somewhat verifiable, as it provides a logical suggestion but lacks comprehensive evidence or detailed explanation.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by requesting the inclusion of statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It offers a clear example of how this could be done, which is to show the frequency of these words in the dataset. This feedback is actionable and can help the authors enhance the clarity and depth of their analysis. However, the comment could be more helpful if it explained why this analysis is important or how it would contribute to the paper\\'s overall contribution. Therefore, the comment is rated as somewhat helpful, as it provides a clear direction for improvement but lacks depth and explanation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not verified the stability of the OGE-Aug on out-of-distribution (OOD) benchmarks, specifically mentioning DrugOOD. It suggests that the authors should verify the stability of their model on this benchmark, which is a clear and explicit action. However, the comment does not provide specific guidance on how to conduct this verification or what metrics to use. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"OGE-Aug\" and \"DrugOOD\" datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of verification of the stability of the OGE-Aug on OOD benchmarks, such as DrugOOD. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have not verified the stability of the OGE-Aug on out-of-distribution (OOD) benchmarks, specifically mentioning DrugOOD. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors have not verified the stability of the OGE-Aug on out-of-distribution (OOD) benchmarks, such as DrugOOD. This is a relevant point as it highlights a potential gap in the experimental evaluation, which could impact the generalizability and robustness of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific tests or analyses could be conducted to verify the stability of the model on OOD datasets. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors consider freezing some layers of the model while only training a few layers or using parameter-efficient methods like LoRA. These suggestions are explicit and provide clear actions for the authors to take, such as considering these methods for experimental comparison. The comment also specifies the potential benefits of these approaches, making it clear what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests considering freezing some layers of the model or using parameter-efficient methods like LoRA for experimental comparison. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the model training or parameter efficiency sections, but this inference is not direct. The comment is specific in suggesting alternative methods to consider, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering alternative methods like freezing some layers or using LoRA for parameter-efficient methods. However, it does not provide any supporting evidence, examples, or references to justify why these methods are relevant or beneficial. The claim is based on logical reasoning but lacks specific examples or detailed justification, making it somewhat verifiable. The authors would need to make a significant effort to understand and implement these suggestions, which is why the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests considering alternative methods for parameter-efficient model training, such as freezing some layers or using LoRA. This feedback is actionable and provides a clear direction for the authors to explore and potentially improve their experimental setup. By suggesting these methods, the reviewer highlights a potential area for enhancement that could lead to a more comprehensive and valuable comparison. However, the comment could be more helpful if it included specific examples or references to these methods, which would guide the authors more directly in implementing these suggestions. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be more detailed to be fully comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to expand the related work section and compare their work to strong baselines that use coordinates. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"related work section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need to expand this section and compare it to strong baselines that use coordinates. This level of detail provides full grounding and specificity, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests expanding the related work section and comparing it to strong baselines that use coordinates. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for expanding the related work section, specifically recommending the inclusion of a comparison to strong baselines that use coordinates. This feedback is valuable as it directs the authors to a specific area where their work could be strengthened by providing a more comprehensive analysis. However, the comment could be more helpful if it included examples of what specific comparisons should be made or how the authors might approach this analysis. Overall, the comment is mostly helpful as it identifies a clear area for improvement but could be more detailed to fully support the authors in enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the experiments should be expanded to include multiple seed experiments, which would provide a more robust evaluation. This suggestion is clear and concrete, as it specifies the exact action the authors need to take to improve their draft. The comment provides a specific direction for enhancing the evaluation of the proposed method, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Single Seed Experiments\" and suggests expanding the experiments to include multiple seeds. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for multiple seed experiments to provide a more robust evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experiments are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. This claim is somewhat verifiable as it logically argues that multiple seed experiments would offer a more comprehensive assessment. However, it lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s experiments, specifically the use of a single seed for training. It suggests that multiple seed experiments would provide a more robust evaluation of the proposed method. This feedback is clear and actionable, as it directly suggests an improvement that could enhance the paper\\'s contribution. By addressing this issue, the authors can better demonstrate the significance of their findings and the impact of the proposed method. However, the comment could be more helpful if it provided specific guidance on how to conduct multiple seed experiments or why they are necessary. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, asking for clarification on the motivation behind this choice. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their choice. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, indicating a lack of clarity in the motivation behind this choice. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the motivation behind the choice, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, suggesting that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It highlights a potential lack of clarity in the paper regarding the rationale behind this choice. While the comment identifies an area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue or clarify their motivation. The feedback is somewhat helpful as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the proposed method, noting that an entire multi-GPU setup is required for optimizations, making it less accessible for many potential users. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more accessible or suggestions for alternative approaches. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the proposed method, noting that an entire multi-GPU setup is required for optimizations, which makes it less accessible for many potential users. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how this requirement affects the accessibility of the method. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method requires an entire multi-GPU setup for optimizations, making it less accessible for many potential users. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the accessibility of the method. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the proposed method, noting that an entire multi-GPU setup is required for optimizations, which could limit its accessibility for many potential users. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or suggesting ways to make the method more accessible. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the missing citation for the public skip-gram data set in L425. This provides a clear and direct action for the authors to take, as they are explicitly instructed to include the missing citation. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing citation for the public skip-gram data set. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing citation for the public skip-gram data set in L425. However, it does not provide any supporting evidence, reasoning, or references to justify why this citation is necessary or how it relates to the paper\\'s content. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of the missing citation. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the missing citation for the public skip-gram data set in L425. This is a clear and actionable point that the authors can address to improve the accuracy and completeness of their work. By providing this feedback, the reviewer helps the authors ensure that their paper is properly cited and referenced, which is crucial for academic integrity and credibility. However, the comment could be more helpful if it included suggestions on how to properly cite the data set or why it is important to include it. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref-[2] as a baseline. It provides a clear and explicit action for the authors to take, which is to compare their system with another that captures semantics. The comment also suggests using Ref-[2] as a baseline, which provides concrete guidance on how to implement the suggested comparison. However, it does not specify which aspects of the current system should be compared or how to evaluate the performance of the new system. While the action is explicit, the lack of detailed guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the current system with another system that also captures semantics, potentially using Ref-[2] as a baseline. However, it does not specify which part of the paper this comparison should be made in, such as a specific section or experiment. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not direct. The comment is specific in suggesting a potential baseline and providing a reference, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the current system with another system that also captures semantics, potentially using Ref-[2] as a baseline. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary information to support the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref-[2] as a baseline for comparison. This feedback is somewhat helpful as it provides a specific suggestion for improving the evaluation of the current system by including a baseline comparison. However, the comment could be more helpful if it explained why Ref-[2] is a suitable baseline or how the authors might choose other relevant references. Additionally, the comment could be more actionable by offering guidance on which aspects of the current system should be compared or how to evaluate the performance of the new system. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the quantitative results are not clear, specifically questioning what data is used for training, validating, and testing. This implies that the authors need to clarify or provide more information about the data used in their experiments. However, the comment does not explicitly instruct the authors to do so, nor does it offer specific guidance on how to present this information. While the action is implied, it is not stated directly, making the comment somewhat actionable. The authors can infer that they need to provide more details about the data used, but the lack of concrete instructions makes this somewhat vague. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the quantitative results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the data used for training, validating, and testing. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the quantitative results, specifically asking about the data used for training, validating, and testing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the results are unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the quantitative results, specifically questioning what data is used for training, validating, and testing. This feedback is valuable as it highlights a potential weakness in the paper that could impact the reproducibility and credibility of the results. However, the comment lacks depth and does not provide suggestions on how to address this issue or what specific data sources might be relevant. While it points out a critical area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the model\\'s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not provide specific guidance on how the authors should address these issues or what steps to take to improve the model. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the model\\'s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of model failure and suggesting potential reasons, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the model\\'s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the model is failing. Without such evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the model\\'s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. It prompts the authors to consider whether there are specific issues with the dataset or the model that could be causing this failure. While the comment identifies a potential problem, it lacks specific suggestions or guidance on how the authors might address this issue or improve their model. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment requests that the authors provide a rationale for why their SE framework can help improve the system and how it does so. It suggests that the authors should not just present their achievements but also explain why and how they managed to achieve them. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not explicitly instruct the authors to use this reference or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of their approach and its benefits. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4\" and \"2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a rationale and explanation of how the SE framework can help improve the system. The reference to [1] Luo, et al. provides additional context and guidance on what kind of explanation is expected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale and explanation behind the SE framework\\'s ability to improve the system. It suggests that the authors should provide a detailed explanation of how the framework works and why it is effective. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not provide specific examples or detailed reasoning from the referenced work to support the claim. While the reference offers a starting point, the comment lacks sufficient evidence or detailed justification to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but requires more detailed evidence or reasoning to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of a clear rationale or explanation for why the SE framework can help improve the system. It suggests that the authors should not just present their achievements but also provide a detailed explanation of why and how they managed to achieve them. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. This reference could be useful for the authors to consider in their response. However, the comment does not provide specific guidance on how to address this issue or what aspects of the framework should be explained. While it highlights a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or what specific steps to take to improve the generalization of the system. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion that the system should be able to generalize to more views, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it could be addressed. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. While it identifies a potential weakness in the approach, it lacks specificity and does not provide actionable guidance or suggestions on how to address this limitation. The comment is somewhat helpful as it points out an area for improvement, but it does not offer detailed feedback or suggestions for enhancing the generalization of the system. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. It notes that these metrics are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative metrics that could be more suitable. The action is implicit and somewhat vague, as the authors can infer that they need to consider the applicability of their metrics in different settings but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the metrics used for evaluating continual learning, loss after switch, and recovery time after switch, which are key aspects of the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with these metrics, namely that they are not applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metrics used for evaluating continual learning are not applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This claim is somewhat verifiable as it provides a logical reasoning based on the nature of the metrics and their applicability to specific scenarios. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. It points out that these metrics are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This feedback is valuable as it highlights a potential weakness in the paper\\'s methodology and suggests that the authors should consider the applicability of their metrics in different contexts. However, the comment could be more helpful if it provided suggestions on how to address this limitation or offered alternative metrics that might be more suitable. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the user decoder's use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. While the comment identifies an area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should clarify this aspect of their work, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"user decoder\" and \"agent decoder,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the user decoder only uses information up to time step t and does not consider information from all time steps. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind the user decoder's use of information from only time step t and not from all time steps. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the paper\\'s overall contribution. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the user decoder's use of information from the agent decoder, specifically questioning why it only uses information up to time step t and does not consider information from all time steps. This feedback identifies a potential area of confusion or inconsistency in the paper, prompting the authors to clarify their methodology. However, the comment lacks depth and does not provide specific suggestions or examples on how the authors might address this issue or what aspects of the methodology might be improved. While it points out a potential weakness, it does not offer actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the missing discussion on arbitrary hyperparameter \u03b3, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear and direct action for the authors to take, which is to include this discussion in their paper. The comment also highlights the importance of this discussion for readers to understand the practical aspects of the work. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion on \"arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set the hyperparameter in practice and the sensitivity analysis of this hyperparameter. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion on arbitrary hyperparameter \u03b3 is missing, including how to set it in practice and analyzing its sensitivity. This claim is somewhat verifiable as it highlights a specific omission in the paper, which could be a significant issue for readers. However, the comment lacks detailed reasoning or examples to fully substantiate the importance of this discussion or how it would enhance the paper. Providing more context or examples would strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, namely the lack of discussion on the arbitrary hyperparameter \u03b3, including how to set it in practice and analyzing its sensitivity. This is a critical point that could impact the clarity and practical applicability of the work. By pointing out this missing discussion, the comment provides clear and actionable feedback for the authors to address. However, the comment could be more helpful if it offered suggestions on how to incorporate this discussion or what specific aspects of the sensitivity analysis should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider a controlled baseline that ablates heads at different locations in the model to address the confounding factor of head location in the induction and FV heads. This feedback provides a clear and explicit action for the authors to take, which is to implement a controlled baseline that can help isolate the impact of head location on ICL performance. The suggestion is concrete and provides a specific direction for the authors to follow, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the difference in ICL performance when ablating induction heads versus FV heads could be due to the confounding factor of head location within the model. It suggests that a controlled baseline should be considered to isolate the impact of head location. However, the comment does not specify which part of the paper discusses the induction and FV heads or where the controlled baseline should be implemented. While the authors might have an idea of where these elements are discussed, the comment lacks full grounding as it does not explicitly mention sections or figures. The suggestion is specific, as it provides a clear direction for addressing the issue, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be due to the confounding factor of head location within the model. The reviewer proposes a controlled baseline that ablates heads at different locations in the model to isolate the impact of head location. However, the comment lacks specific examples or references to support the claim that head location is a significant confounding factor. While the suggestion is logical, it requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable hypothesis but lacks the necessary evidence to fully support it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confounding factor in the difference in ICL performance when ablating induction heads versus FV heads, suggesting that the location of these heads within the model could be a contributing factor. It provides a clear and actionable suggestion by recommending the inclusion of a controlled baseline that ablates heads at different locations in the model. This feedback is valuable as it offers a specific direction for the authors to address the issue and improve their draft. However, the comment could be more helpful if it provided additional context or examples of how this controlled baseline might be implemented or what specific locations should be considered. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that a section on synonym identification is missing under similarity measurement, which would describe how the multiple-choice task is approached. This provides a clear and direct action for the authors to take, which is to add the missing section. The comment is specific and provides concrete guidance on what needs to be included, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section on similarity measurement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a section on synonym identification that describes how the multiple-choice task is approached. This provides clear guidance on what needs to be added to the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiple-choice task is approached. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, namely the absence of a section on synonym identification under similarity measurement. This feedback is clear and actionable, as it directs the authors to add a missing section that would provide important context and explanation for the multiple-choice task. By addressing this gap, the authors can enhance the clarity and completeness of their paper. However, the comment could be more helpful if it offered suggestions on how to structure or present this section, or if it highlighted the importance of including this information. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the Methodology section, particularly regarding the model architecture description and notation. It points out inconsistencies in the notation, such as the introduction of $v^p_{t-1}$ in the description but not in the equations, and the use of labels ($l_0$, $l_{t-1}$) that may give the impression of a sequence of tokens being generated as the label. The comment provides a clear and concrete action for the authors to take, which is to clarify and standardize the notation used in the Methodology section. This guidance is explicit and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Methodology section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the model architecture description and notation, such as the introduction of $v^p_{t-1}$ in the description but not in the equations, and the use of inconsistent notation for labels ($l_0$, $l_{t-1}$). This provides clear guidance on what needs to be addressed in the Methodology section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Methodology section is difficult to follow due to confusing notation and inconsistencies. It provides specific examples, such as the introduction of $v^p_{t-1}$ in the description but not in the equations, and the use of inconsistent notation for labels ($l_0$, $l_{t-1}$). These examples are logical and provide clear justification for the claim, making the comment mostly verifiable. However, the comment could be strengthened by referencing specific sections or equations where these issues occur, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific issues with the Methodology section, particularly regarding the model architecture description and notation. It points out inconsistencies in the notation, such as the introduction of $v^p_{t-1}$ in the description but not in the equations, and the use of labels ($l_0$, $l_{t-1}$) that may give the impression of a sequence of tokens being generated as the label. This feedback is clear and actionable, as it directs the authors to clarify and standardize the notation used in the Methodology section. By addressing these issues, the authors can improve the clarity and comprehensibility of their work, making the comment highly helpful. Therefore, it deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the action is implicit, it is concrete because it specifies what needs to be added (an overview of the workflow and the model). This provides the authors with a clear direction on how to enhance their draft, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, nor does it provide details on what aspects of the workflow and model should be covered. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in suggesting the need for an overview but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning or examples to support why this overview is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. This feedback is somewhat helpful as it identifies a potential area for improvement in presenting the key components of the paper. However, the comment lacks specific guidance on what aspects of the workflow and model should be covered or how this overview should be structured. While it points out a need for clarity, it does not provide detailed suggestions or examples to help the authors effectively implement this feedback. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It also mentions that this information cannot be computed accurately without the same runtime as required for ridge regression. The reviewer suggests that this issue is not discussed in the paper and raises a similar concern regarding the surrogate sketch. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to discuss this issue but are not given clear instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to know the statistical dimension d_lambda of the design matrix A, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue of not being able to compute this dimension accurately without the same runtime as required for ridge regression, and raises a similar concern regarding the surrogate sketch. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the debiasing approach requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without the same runtime as required for ridge regression. The reviewer suggests that this issue is not discussed in the paper and raises a similar concern regarding the surrogate sketch. The claim is somewhat verifiable as it provides a logical reasoning for the need to compute d_lambda and the potential impact on the approach. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It points out that this information cannot be computed accurately without the same runtime as required for ridge regression, which could lead to bias and potentially defeat the purpose of the approach. The comment also notes that this issue is not discussed in the paper, which is a significant oversight. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or discuss it in the paper. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to redefine Figure 3 as the expected quantities are scalars but shown as a vector. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is highly actionable as it clearly specifies what needs to be done to address the issue.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, redefining the figure to accurately represent the expected quantities as scalars. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the figure should be redefined as the expected quantities are scalars but shown as a vector. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the clarity or accuracy of the figure. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific issue with Figure 3, noting that the expected quantities are scalars but shown as a vector. This feedback is clear and actionable, as it directs the authors to redefine the figure to accurately represent the expected quantities. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining why the current representation is misleading or offering guidance on how to present the data more effectively. Overall, the comment is valuable but could be more comprehensive with additional details. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance on how to improve the experiment setup or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions on how to enhance the experiment setup, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not specify which part of the paper this issue pertains to, such as the specific sections or experiments where the ablations are discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what questions arise or how the experiment setup could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the ablations deserve better experiment setup due to the many questions that arise. However, it does not provide any specific examples, reasoning, or evidence to support why the ablations need better setup or what questions are being raised. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific examples or details about the questions that are being raised or how the experiment setup could be improved. Without this information, the authors are left without actionable guidance on how to address the issue. The comment identifies a potential area for improvement but lacks depth and specificity, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. While the comment implies that the authors should conduct additional experiments, it does not specify which experiments to conduct or how to conduct them. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the argument about the proposed models being particularly useful for learning representations for low-frequency words, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of empirical evidence to test the hypothesis and suggests exploring this aspect further. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed models are particularly useful for learning representations for low-frequency words but lacks empirical evidence to support this claim. The reviewer suggests that it would be interesting to explore this aspect further, implying that the absence of empirical evidence is a significant issue. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of the empirical evidence themselves, which could be challenging without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. This feedback is clear and actionable, as it points out a specific area where the paper could be strengthened with additional evidence. However, the comment could be more helpful if it provided suggestions on which experiments or data sets to use for this empirical evaluation. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should study the importance of the global feature by comparing it with different resolutions of voxel features. It specifically mentions that the resolution of the 3D voxel should be considered and that the study should be included in Sec4.2. The comment provides a clear and explicit action for the authors to take, which is to conduct a comparative analysis of the global feature with different voxel resolutions. This guidance is concrete and provides a specific direction for the authors to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the study of the global feature and its resolution, and suggests comparing it with different resolutions of voxel features. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the resolution of the 3D voxel and its potential impact on the network. It suggests that studying the importance of the global feature by comparing it with different resolutions of voxel features would be more convincing. While the comment provides a logical reasoning for the need to consider the resolution, it lacks specific examples or references to support the claim that the resolution introduces unnecessary overhead. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to study the importance of the global feature by comparing it with different resolutions of voxel features. It highlights the potential issue of high computational and memory cost associated with voxel-like features and suggests that studying the resolution of the 3D voxel could be beneficial. The comment is specific in its guidance, providing a concrete direction for the authors to improve their draft. By addressing this feedback, the authors can enhance the clarity and robustness of their study. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of an error analysis on the movie dataset and highlights the need for clarity on the cases where the model fails. This provides a clear and direct action for the authors to take, which is to include an error analysis in their draft. The comment is specific and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely an error analysis on the movie dataset, and why it is important for other researchers to understand the cases where the model fails. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the paper\\'s contribution. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this omission. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the absence of an error analysis on the movie dataset. It highlights the importance of including this analysis for other researchers who may continue this work. However, the comment does not provide specific guidance on how to conduct the error analysis or what aspects should be covered. While it points out a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer recommends exploring development set trends with respect to these hyperparameters. While the comment implies that the authors should investigate these trends, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these trends. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in seeing trends in the table, particularly regarding the behavior of PM+CL compared to PM or CL alone. The comment suggests exploring development set trends with respect to these hyperparameters, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer suggests exploring development set trends with respect to these hyperparameters. However, the comment lacks specific examples or detailed reasoning to support why these trends are important or how they could be explored. Without additional context or evidence, the claim is somewhat verifiable, as it requires the authors to infer the significance of the trends and how to investigate them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting that it is difficult to see trends in the data, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer suggests exploring development set trends with respect to these hyperparameters, which could provide valuable insights into the behavior of the models. This feedback is clear and actionable, as it directs the authors to investigate a specific area that could enhance the understanding and interpretation of their results. However, the comment could be more helpful if it included suggestions on how to explore these trends or what specific analyses might be useful. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of Figure 5, noting that there are many lines on top of each other, making it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added or clarified, but it is somewhat vague in terms of how to implement these changes. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the difficulty in understanding the figure due to the overlapping lines and suggests reporting additional metrics like flops or model size to provide a more concrete understanding of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is difficult to understand Figure 5 due to the overlapping lines and suggests that the authors could report additional metrics like flops or model size to provide a more concrete understanding of the results. However, the comment does not provide specific examples or detailed reasoning to support why the current presentation is unclear or how the suggested metrics would improve clarity. While the suggestion is logical, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Figure 5, noting that the overlapping lines make it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensiveness of their figures and metrics reporting. However, the comment could be more helpful if it provided specific guidance on how to present these additional metrics or how to improve the figure\\'s clarity. Overall, the comment is mostly helpful as it offers concrete suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or provide any guidance on how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the \"questions section below,\" which implies that it is referring to a specific part of the paper. However, without explicit mention of a section or page number, the authors cannot confidently determine the exact part of the paper being addressed. The comment also lacks specificity as it does not detail what specific details are missing or how they should be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that \"some details of the proposed method are missing,\" but it does not specify which details are missing or provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references, the authors may find it challenging to identify and address the missing details. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide any further explanation or guidance on what these missing details are or how they might be addressed. Without specific examples or suggestions, the authors are left without actionable feedback to improve their draft. Therefore, the comment is barely helpful, as it points out a potential weakness but lacks depth and specificity in its guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends simplifying the description and explaining the architecture and computations better. It also suggests reducing Figure 7, Section 8, and specific lines (39-64) to gain more space. These explicit actions provide clear guidance on what the authors need to do to improve the draft. The suggestions are concrete, as they specify which parts of the paper should be simplified and reduced, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of the paper being too dense and difficult to follow, suggesting that it needs simplification and better explanation of the architecture and computations. It provides specific examples of sections and lines that could be reduced to gain more space. However, it does not explicitly mention which sections or lines should be reduced, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as simplifying the description and explaining the architecture and computations better. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to understand the concepts and contributions. It suggests simplifying the description and explaining the architecture and computations better. The comment provides specific examples of sections and lines that could be reduced to gain more space. This claim is somewhat verifiable as it offers a logical reasoning for simplifying the paper, but it lacks detailed justification or references to support the claim that the paper is too dense. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it is too dense and difficult to follow. It suggests simplifying the description and explaining the architecture and computations better, which is a crucial recommendation for improving the clarity and accessibility of the paper. The comment provides specific examples of sections and lines that could be reduced to gain more space, offering actionable guidance for the authors. However, the comment could be more helpful if it provided additional suggestions on how to simplify the description or explained why the current description is too complex. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation on over-smoothing should include a comparison with the EIGNN model under standard settings on real-world datasets, specifically in relation to variants that focus on dealing with over-smoothing, such as GCNII. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is concrete, as it specifies the type of comparison to be made, but it is somewhat vague in terms of how to implement it. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests a specific comparison to be made regarding the evaluation of over-smoothing, particularly with respect to the EIGNN model and variants that focus on dealing with over-smoothing, such as GCNII. However, it does not specify which part of the paper this evaluation is currently included in, making it weakly grounded. The comment is specific in suggesting a particular comparison to be made, but without explicit references to sections or figures, the authors may struggle to identify the exact location of the evaluation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation on over-smoothing should include a comparison with the EIGNN model under standard settings on real-world datasets, specifically in relation to variants that focus on dealing with over-smoothing, such as GCNII. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the evaluation. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific comparison that could be made in the evaluation of over-smoothing, specifically by comparing the EIGNN model with variants that focus on dealing with over-smoothing, such as GCNII. This feedback is actionable as it provides a clear direction for the authors to enhance their evaluation by including a comparison that could offer insights into the performance of the EIGNN model under standard settings on real-world datasets. However, the comment could be more helpful if it provided additional context or examples of how this comparison might be conducted or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically how to use multiple prompts in the test stage. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to add a separate section or subsection to introduce the inference strategy, but the comment lacks concrete details on what this section should include or how to implement it. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"approach method\" and the \"inference strategy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of a separate part or subsection to introduce the inference strategy, particularly the use of multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically how to use multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of a separate part or subsection to introduce the inference strategy, particularly the use of multiple prompts in the test stage. This feedback is clear and actionable, as it points out a critical area that needs attention in the paper. However, the comment could be more helpful if it provided suggestions on how to address this gap, such as recommending a specific section or subsection to include this information. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that Figure 4 is confusing and notes that the columns are not explained in the text or caption. This provides a clear and direct action for the authors to take, which is to clarify the meaning of the columns in the figure and its caption. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that the columns are not explained in the text or caption. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment claims that Figure 4 is confusing and points out that the columns are not explained in the text or caption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that it is confusing and that the columns are not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns and provide additional explanations in the text or caption. By addressing this issue, the authors can improve the clarity and accessibility of their figure, which is valuable for enhancing the overall quality of their draft. However, the comment could be more helpful if it offered suggestions on how to clarify the columns or provided examples of how similar figures have been effectively explained. Despite this, the feedback is mostly helpful as it effectively guides the authors on a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiment results could be discussed more, specifically questioning whether the MaxGapTop2UCB algorithm is better than others based on the Streetview experiment. It also points out the lack of clarity regarding the real-world applications of the problem setting and the computational complexity of the proposed algorithms. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific aspects should be discussed in the paper. The authors are left to infer that they need to provide more detailed discussions and address the computational complexity, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Streetview experiment\" and the \"real-world applications of this new problem setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the conclusion from the Streetview experiment and asking about the computational complexity of the proposed algorithms in the context of ranking problems. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the conclusions drawn from the Streetview experiment and the real-world applications of the problem setting. It suggests that the authors should discuss the results more and questions whether MaxGapTop2UCB is better than other algorithms. The reviewer also points out the complexity of the proposed algorithms in the context of ranking problems, which is a valid concern. However, the comment lacks specific examples or references to support the claim about the complexity or the need for more discussion on the results. This makes the claim somewhat verifiable, as it provides some reasoning but requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable critique of the paper, identifying areas where the authors could improve the discussion and clarity of their results. It questions the conclusion drawn from the Streetview experiment and suggests that the authors should discuss the results more thoroughly. Additionally, it points out the lack of clarity regarding the real-world applications of the problem setting and the computational complexity of the proposed algorithms in the context of ranking problems. While the comment highlights important areas for improvement, it could be more helpful if it provided specific suggestions on how to address these issues or what aspects of the discussion should be expanded upon. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and depth of their analysis and discussion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the low results obtained using only ML in the ablation experiments and suggests that more explanations are needed. However, it does not provide specific guidance on what kind of explanations are needed or how the authors might address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the low results obtained using only ML in the ablation experiments and suggests that more explanations are needed. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for more explanations, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the low results obtained using only ML in the ablation experiments and suggests that more explanations are needed. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the low results obtained using only ML in the ablation experiments and suggests that more explanations are needed. While it identifies a potential issue with the results, it lacks specificity and does not provide actionable guidance on what kind of explanations might be needed or how the authors might address this issue. The comment is somewhat helpful as it points out a potential area for improvement, but it does not offer detailed suggestions or examples to help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. However, it does not provide explicit guidance on how to include ablation analysis or what specific components should be analyzed. The action is implicit and somewhat vague, as the authors are left to infer that they need to include ablation analysis but without clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of ablation analysis in the main paper, which makes it difficult to pinpoint the source of the small performance gain. However, it does not specify which part of the paper lacks this analysis, such as the specific sections or experiments where it should be included. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in identifying the issue of lacking ablation analysis, but without explicit references to sections or experiments, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of ablation analysis, which makes it difficult to pinpoint the source of the small performance gain. This is a critical observation that could significantly impact the authors\\' understanding of their work and its implications. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which components should be analyzed or how to conduct the ablation analysis. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical issue but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any guidance or suggestions on how the authors should address this observation or what implications it might have for their work. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2,\" which likely refers to a specific figure or table in the paper. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not detail what aspect of the noise rate of similarity labels compared to class labels is problematic or how it affects the paper. Without additional context or suggestions for improvement, the authors may find it challenging to address the issue effectively. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand or verify the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any actionable feedback or suggestions for the authors to address this observation or how it might impact their work. Without additional context or guidance, the authors are left without a clear understanding of how to proceed or what improvements could be made. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the verification of the hypothesis, specifically noting that the experiment is not well-designed. It suggests that the base model should be trained on the original dataset along with the adversarial set to better highlight the impact of the augmented adversarial examples. This feedback provides a clear and explicit action for the authors to take, which is to modify the experimental design to include the comparison between the original dataset and the mixture. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the verification of the hypothesis through an experiment that compares the base model trained on the original dataset with that trained on the mixture of original and adversarial examples. This provides clear guidance on how to improve the experimental design to better highlight the impact of the augmented adversarial examples. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the hypothesis is interesting but not well-verified by the designed experiment. It references Section 3.1 to support this claim, specifically mentioning that models in conventional methods are trained on the original training set in addition to the generated adversarial examples, while the base model is trained on the adversarial set only. The reviewer suggests that comparing the model trained on the original dataset with that trained on the mixture would highlight the impact of the augmented adversarial examples. This claim is somewhat verifiable as it provides a logical reasoning for the need to compare the models, but it lacks specific examples or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the verification of the hypothesis, specifically noting that the experiment is not well-designed. It points out that the base model is trained on the adversarial set only, while conventional methods train on the original training set in addition to the generated adversarial examples. The comment suggests that comparing the model trained on the original dataset with that trained on the mixture would highlight the impact of the augmented adversarial examples. This feedback is clear and actionable, providing the authors with a specific and direct way to improve the experimental design and make the hypothesis more convincing. By addressing this issue, the authors can enhance the credibility and robustness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. There is no guidance on what aspects of the experiments are lacking or how they could be improved. Without explicit or implicit suggestions for improvement, the authors are left without a clear understanding of what changes are needed to enhance the credibility of their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the CNN experiments, but it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. It also lacks specificity as it does not detail what aspects of the experiments are not convincing or how they could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This makes the claim unverifiable, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment states that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without further explanation or guidance, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This lack of actionable feedback makes the comment not helpful at all, as it does not assist the authors in enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the results for model (3) (Chung et al. 2016) for Cs-En in Table 1 are not reported in the paper and suggests that if the authors computed these results themselves, they should mention it. This provides a clear and direct action for the authors to take, ensuring that they either report the results from the original paper or acknowledge their self-computation. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"model (3) (Chung et al. 2016) for Cs-En,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the results were taken from the original paper or computed by the authors themselves. This provides clear guidance on what needs to be corrected or clarified in the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for model (3) (Chung et al. 2016) for Cs-En in Table 1 are not reported in the paper, suggesting that the authors should mention if they computed these results themselves. The comment is somewhat verifiable as it provides a specific reference to the original paper, which could help the authors verify the claim. However, the comment lacks detailed reasoning or explanation about why the results should be reported or how they might impact the paper. The authors would need to make a significant effort to verify the claim, which is not fully supported by the current information. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the results for model (3) (Chung et al. 2016) for Cs-En in Table 1 are not reported in the paper. It suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, as it provides a direct and specific suggestion for improvement. By pointing out the missing information and suggesting a way to address it, the comment offers valuable guidance for the authors to enhance the accuracy and completeness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer implies that discussing how to design prompts effectively is crucial. However, the comment does not provide specific guidance on how to achieve this or what aspects of prompt design should be emphasized. The action is implicit and somewhat vague, as the authors can infer that they need to focus on prompt design but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. However, it does not specify which part of the paper discusses these prompting methods or where the authors should focus their attention. The authors can infer that it relates to sections discussing prompt design, but this inference is not direct. The comment is specific in its suggestion to discuss prompt design effectively, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer argues that different prompts may result in varying performance outcomes, emphasizing the importance of discussing how to design prompts effectively. However, the comment lacks specific examples or references to support the claim that different prompts lead to varying performance outcomes. This makes the claim somewhat verifiable, as the authors would need to infer the importance of prompt design and the potential impact on performance outcomes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts may result in varying performance outcomes. This feedback is clear and actionable, as it directs the authors to focus on a critical aspect of their work that could significantly impact its impact and effectiveness. However, the comment could be more helpful if it provided specific suggestions or examples of effective prompt design strategies. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their results with state-of-the-art (SoTA) approaches, specifically mentioning HateXplain models. While the comment implies that the authors should include such comparisons, it does not provide explicit instructions or detailed guidance on how to conduct these comparisons or what specific aspects to focus on. The action is clear but somewhat vague, as the authors know they need to compare their results but may not be entirely sure of the exact steps to take. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests comparing the results with state-of-the-art (SoTA) approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this comparison should be included in, such as the results or discussion sections. The authors can infer that it relates to the results or evaluation sections, but this inference is not direct. The comment is specific in suggesting a comparison with SoTA approaches, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the results with state-of-the-art (SoTA) approaches, specifically mentioning HateXplain models. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific improvement by recommending the authors compare their results with state-of-the-art (SoTA) approaches, specifically mentioning HateXplain models. This feedback is actionable as it provides a clear direction for enhancing the paper by demonstrating the relevance and impact of the proposed method in the context of existing work. However, the comment could be more helpful if it included additional guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a clear area for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the rationale behind using freezing but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of freezing in MLS selection and questions the rationale behind it. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in questioning the use of freezing and suggesting an alternative approach, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. However, the comment lacks specific reasoning or evidence to support why the current approach is ineffective or why an adaptive method would be more beneficial. Without detailed justification or examples, the claim remains somewhat verifiable, as the authors may find it challenging to understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid question about the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. This feedback highlights a potential area for improvement in the paper, prompting the authors to reconsider their approach. However, the comment lacks specific guidance or suggestions on how to implement this change or what specific adaptive method might be more suitable. While it identifies a potential weakness, it does not provide actionable steps for the authors to address it. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This feedback is explicit, as it clearly instructs the authors to include a detailed plan in their future work. However, it does not specify what aspects of the limitations should be addressed or how the plan should be structured, leaving some room for interpretation. While the action is clear, the comment could be more concrete by providing specific guidance on what aspects of the limitations should be addressed or how the plan should be structured. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not specify which limitations are being referred to or where in the paper these limitations are discussed. This makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what aspects of the limitations should be addressed or how the authors should plan to address them. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, the comment does not provide any specific examples, reasoning, or references to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim is not verifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically the lack of a detailed plan on how the authors plan to address the limitations mentioned. While it highlights an area for improvement, it does not provide specific guidance or suggestions on how the authors might develop a more detailed plan. The comment is somewhat helpful as it points out a potential gap in the paper, but it lacks actionable advice or detailed guidance on how to address the issue. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should perform a similar analysis on the proposed knowledge-CLIP model as done in existing work that combines text and KGs. This feedback implies that the authors should conduct an experiment to test the robustness of their model in handling negation or changes in entities in the text. While the comment does not explicitly instruct the authors to perform this analysis, it provides a clear direction for further investigation. The action is explicit and concrete, as it specifies the type of analysis to be conducted, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed knowledge-CLIP model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting an analysis similar to existing work that combines text and KGs, providing a clear direction for improvement. This feedback is detailed and actionable, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed knowledge-CLIP model should be evaluated in a similar manner as existing work that combines text and KGs. It references an external work, providing a specific example of a closely-related analysis that could be applied to the proposed model. This reference provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to conduct an analysis on the proposed knowledge-CLIP model, similar to existing work that combines text and KGs. It references an external work that has performed closely-related analyses, such as adding negation or changing entities in text to test the robustness of the KG-augmented method. This feedback is valuable as it encourages the authors to explore and validate their model's robustness in a specific context. By following this suggestion, the authors can enhance the rigor and comprehensiveness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of p m in the numerator and p c in the denominator in Eq. 3, and questions the reason for this choice. It also suggests that the authors consider adding the variance for further improvement and recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides explicit actions for the authors to take, such as clarifying the reason for the choice and considering adding variance. Additionally, it offers specific guidance on how to improve the draft by suggesting a change in notation. The actions are concrete and detailed, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Alg. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of p m in the numerator and p c in the denominator, suggesting that the authors clarify the reason for this choice. Additionally, it recommends adding the variance for further improvement and suggests using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of p m in the numerator and p c in the denominator in Eq. 3, questioning the reason for this choice. It suggests that the authors consider adding the variance for further improvement and recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides logical reasoning by suggesting that using \u03bc g instead of \u03bc f would be consistent with the equation. However, it lacks specific examples or references to support the claim that using variance would improve the results. Therefore, the comment is somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper regarding the use of p m in the numerator and p c in the denominator in Eq. 3. It questions the reason for this choice and suggests that the authors consider adding the variance for further improvement. Additionally, it recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. This feedback is clear and actionable, as it provides specific guidance on how to clarify the notation and improve the paper. By addressing these points, the authors can enhance the clarity and coherence of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide a more comprehensive discussion about the computational complexity of the proposal and raises a question about whether the approach becomes prohibitive in certain settings. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed discussion and address the computational cost issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"additional cost\" and the \"computational complexity of the proposal,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the computational cost and its potential impact on the approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the computational cost of the proposed approach and questions whether it becomes prohibitive in certain settings. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the computational cost of the proposed approach. It suggests that the paper should provide a more comprehensive discussion about the computational complexity and raises a question about whether the approach becomes prohibitive in certain settings. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how to address the computational cost issue or what aspects of the approach might be problematic. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify how novel values in the test set are handled for clarity. This is a direct and concrete action, as it specifies exactly what needs to be addressed. The authors know exactly what information is missing and how to provide it, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how novel values in the test set are handled. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment suggests that the authors clarify how novel values in the test set are handled for clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area where clarity is needed, specifically regarding how novel values in the test set are handled. By pointing out this gap, the comment provides the authors with a clear direction for improving the draft. However, the comment could be more helpful if it offered suggestions on how to clarify this aspect or provided examples of how other studies handle similar issues. While it highlights an important area for improvement, the feedback could be more comprehensive to be fully beneficial. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that similar methods have already been proposed for multi-task learning and were not discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a discussion of related work or a comparison with existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Similar methods have already been proposed for multi-task learning and has not been discussed in this paper [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on similar methods for multi-task learning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar methods have already been proposed for multi-task learning and were not discussed in the paper. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper regarding the discussion of similar methods for multi-task learning. It points out that similar methods have already been proposed and were not discussed in the paper. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or incorporate related work into their discussion. Without actionable feedback or detailed advice, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is rated as barely helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison in their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FedMITR,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the amount of computation required for FedMITR compared to other methods, indicating a potential area for improvement or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper\\'s conclusions. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment poses a question about the amount of computation required for FedMITR compared to other methods, suggesting that this might be an area for comparison. While it highlights a potential weakness or area for improvement, it does not provide specific guidance or suggestions on how to address this issue. The comment is somewhat helpful as it points out a potential gap in the paper, but it lacks depth and actionable advice that could help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it unclear whether this suggestion is being implemented. The comment provides a specific action\u2014using a generic external knowledge base\u2014but lacks concrete guidance on how to implement it or address the confusion in the writing. The authors are left with a clear action but without detailed instructions on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests avoiding \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, it acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment references \"1) and 2)\" and Figure 3, it does not specify which parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting the use of a generic external knowledge base, but without detailed guidance on how to address the confusion in the writing, it remains under-specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using a generic external knowledge base (as shown in Figure 3) can avoid \"1) and 2)\" and that the writing is confusing. However, the comment lacks specific examples or detailed reasoning to support the claim that the external knowledge base would be beneficial or how it would address the confusion in the writing. Without additional context or evidence, the authors may find it challenging to understand and implement the suggestion. Therefore, the claim is considered borderline verifiable, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment provides a specific actionable suggestion, it lacks depth and does not offer detailed guidance on how to effectively implement the external knowledge base or address the confusion in the writing. The feedback is somewhat helpful as it points out a potential solution but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of the choice, and whether other influential losses have been considered. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The comment implies that the authors should provide more detailed information about their methodology, but it does not specify exactly what aspects need to be clarified or how to implement the changes. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of this choice, and whether other influential losses have been considered. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the questions are specific, the lack of grounding in the comment makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for clarification about the methodology used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also asks whether other influential losses have been considered, such as replacing the min with a mean or NDCG. These questions are relevant and could prompt the authors to reconsider their methodology and potentially improve the robustness and generalizability of their results. However, the comment lacks specific guidance or suggestions on how to address these issues, such as recommending specific experiments or modifications to the methodology. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of in-depth analysis on experimental results, specifically questioning why improvements are limited on one dataset and significant on another. This provides a clear and direct action for the authors to take, which is to conduct a more detailed analysis of the experimental results. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for an in-depth analysis of the experimental results, particularly regarding the improvements of models on the offense detection dataset and the coarse stereotype set. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the limited improvements of models on the offense detection dataset and the significant improvements on the coarse stereotype set. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of in-depth analysis on experimental results. It points out that the improvements of models are limited on one dataset and significant on another, which is a critical observation that could lead to a deeper understanding of the results. By highlighting this issue, the comment provides the authors with a clear direction for enhancing the analysis and interpretation of their experimental findings. However, the comment could be more helpful if it offered suggestions on how to conduct the in-depth analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests several actions for the authors to take, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. It also mentions that the current method may not work due to the small number of conv layers. However, the comment does not provide specific guidance on how to implement these changes or what specific modifications to the method should be made. The action is implicit and somewhat vague, as the authors need to infer the details of how to apply the suggestions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the method of training on labeled data and incorporating input mask explanation annotations, as well as the use of modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. It also mentions the skepticism about the proposed method's effectiveness, given the history of similar interventions failing. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing the changes needed, such as the number of examples and the use of specific baselines. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed method may not work due to the small number of conv layers and the use of older baselines like Resnet50 or DenseNet121. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the skepticism. The suggestion to use modern baselines is logical, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several suggestions for improving the proposed method, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. These are actionable and specific improvements that could enhance the robustness and effectiveness of the method. However, the comment also expresses skepticism about the method's potential success, given the history of similar interventions failing. This skepticism is based on the reviewer\\'s opinion and not on objective evidence or reasoning, which limits the overall helpfulness of the comment. While the suggestions are valuable, the authors may need to address the skepticism by providing additional evidence or rationale to support their approach. Therefore, the comment is somewhat helpful, as it provides actionable suggestions but lacks depth in addressing the skepticism.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method. This implies that the authors should make a comparable effort to optimize the baseline as they do for their proposed method. However, the comment does not provide specific guidance on how to achieve this or what steps to take to ensure a fair comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction of multiple hyperparameters and the extensive hyperparameter search, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the importance of ensuring that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment highlights the extensive hyperparameter search, it lacks specific examples or references to support the claim that this is necessary. The reasoning is based on a general assumption that a fair comparison requires equal optimization efforts, but it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks specific evidence or references to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the extensive hyperparameter search and the need to ensure that the baseline is fully tuned with the same resources as the proposed method. This is a relevant point that could impact the fairness and validity of the comparison between the baseline and the proposed method. However, the comment lacks specific guidance or suggestions on how to achieve this goal, such as recommending specific steps or techniques for tuning the baseline. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. Additionally, it notes that the equation mentioned does not resemble perplexity but instead appears to be cross-entropy. While the comment provides explicit guidance on what needs to be corrected, it does not offer specific suggestions on how to revise the definition or equation to ensure accuracy. The action is clear but lacks concrete details on how to implement the correction, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is incorrect about the definition of perplexity and the equation mentioned, providing clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. The reviewer also notes that the equation mentioned does not resemble perplexity but instead appears to be cross-entropy. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific error in the paper regarding the definition of perplexity and the equation mentioned. It points out that the definition provided is incorrect and suggests that it should be replaced with the correct definition. Additionally, it notes that the equation does not resemble perplexity but instead appears to be cross-entropy. This feedback is clear and actionable, as it directs the authors to correct a critical aspect of their work that could impact the understanding and interpretation of their results. However, the comment could be more helpful if it provided additional context or examples of the correct definition or equation. Overall, the comment is mostly helpful as it effectively guides the authors in improving the accuracy and clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should clarify the condition in Proposition 6.1, which appears to be strong, by comparing it with the condition in Section 4 (correct model case). This feedback provides a clear and concrete action for the authors to take, as it specifies the exact part of the paper that needs clarification and offers a specific comparison to be made. The comment is highly actionable because it provides a direct and specific direction for improvement, ensuring that the authors know exactly what needs to be done to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Proposition 6.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the condition \\eta \\ge C_0 and its comparison with the signal-to-noise ratio \\eta. The comment provides a clear direction for improvement by suggesting a comparison with the correct model case in Section 4. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the condition in Proposition 6.1, suggesting that it may be too strong given the typical signal-to-noise ratio. The reviewer provides a logical reasoning by pointing out that \\eta is typically a small value, which supports the claim that the condition is not typical. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable, as it requires more detailed justification to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the condition in Proposition 6.1, suggesting that it may be too strong given the typical signal-to-noise ratio. It provides a clear and actionable suggestion for the authors to clarify this condition and compare it with the signal-to-noise ratio in Section 4 (correct model case). This feedback is valuable as it prompts the authors to address a potential weakness in their argument, which could enhance the clarity and robustness of their work. However, the comment could be more helpful if it included specific examples or references to support the claim about the typical signal-to-noise ratio. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add more baselines of graph contrastive learning and test them on common datasets. This is a clear and direct action for the authors to take, as it specifies the exact improvement needed and provides a concrete direction for testing. The comment is specific and provides a concrete action for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"graph classification task\" and the \"compared baseline,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the missing baselines, such as MVGRL[4] and gpt-gnn[5], and suggests adding more baselines of graph contrastive learning and testing them on common datasets. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline for the graph classification task is insufficient, specifically mentioning the absence of MVGRL[4] and gpt-gnn[5]. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. It suggests adding more baselines of graph contrastive learning and testing them on common datasets, but without further explanation or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the insufficiency of the baseline for the graph classification task. It points out the absence of certain baselines, such as MVGRL[4] and gpt-gnn[5], and suggests that the authors should add more baselines of graph contrastive learning and test them on common datasets. This feedback is clear and actionable, as it provides a concrete direction for improvement by suggesting the inclusion of additional baselines and testing on common datasets. However, the comment could be more helpful if it explained why these specific baselines are important or how they might impact the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern with the evaluation of the proposed strategies, specifically mentioning the need to test the defense against an adversarial attack. It suggests that the defense should be evaluated against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. However, the comment does not provide specific guidance on how to implement this evaluation or what specific aspects of the defense should be tested. The action is implicit and somewhat vague, as the authors need to infer the details of how to conduct the evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation of the proposed strategies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern about the defense against an adversarial attack, including the need to evaluate the defense against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of the proposed strategies is insufficient, specifically mentioning the need to test the defense against an adversarial attack. The comment provides a logical reasoning by highlighting the potential vulnerability of the defense against an adaptive attack against their edge map-based defense strategies. However, the comment lacks specific examples or references to support the claim that an adversary could optimize the perturbation to successfully attack the model. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern with the evaluation of the proposed strategies, specifically highlighting the need to test the defense against an adversarial attack. It points out that the current defense strategy considers purifying the input image before passing it to the model, but it does not address the potential vulnerability of the defense against an adaptive attack against their edge map-based defense strategies. The comment suggests that the defense should be evaluated against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. This feedback is clear and actionable, providing the authors with a specific direction for improving the evaluation section of their paper. However, it could be more helpful if it included examples or references to similar studies or attacks that have successfully exploited such vulnerabilities. Overall, the comment is mostly helpful as it guides the authors toward a critical area for improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to make the legends for tables 1, 2, and 3 longer and clarify whether the numbers are percent errors or percent correct. This feedback provides clear and direct guidance on what changes need to be made to improve the clarity of the tables. The action is explicit and concrete, as it specifies exactly what needs to be done to enhance the legends. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the legends for these tables, and it provides guidance on what should be clarified, such as whether the numbers are percent errors or percent correct. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a factual observation that does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a clear and direct suggestion that can help improve the clarity and accuracy of the tables, which is valuable for the authors. However, the comment could be more helpful if it provided examples of what additional information might be included in the legends or how to clarify the numbers. Overall, the comment is mostly helpful as it identifies a specific area for improvement and offers a concrete direction for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the experimental results lack standard deviations, making it difficult to assess the significance of the results. This is a clear and direct action for the authors to take, as it instructs them to include standard deviations in their results. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014the inclusion of standard deviations\u2014and why this is important for assessing the significance of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results lack standard deviations, making it difficult to assess the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why standard deviations are necessary or how their absence affects the interpretation of the results. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting the absence of standard deviations. This is a clear and actionable point that the authors can address to improve the clarity and significance of their findings. By including standard deviations, the authors can provide more robust and reliable evidence for their conclusions. However, the comment could be more helpful if it offered suggestions on how to present these deviations or explained their importance in the context of the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the provided analysis seems weak in light of theoretical work on sampling and particle-based optimization methods. It specifically mentions the absence of information on the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space). While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the solution and discretization, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the provided analysis\" and \"the theoretical work on sampling and particle-based optimization methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the analysis, such as the absence of information on the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the provided analysis is \"somewhat weak\" due to the absence of information on the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space). This claim is somewhat verifiable as it references theoretical work on sampling and particle-based optimization methods, which provides a basis for the expectation of detailed analysis. However, the comment lacks specific references to that theoretical work or examples of what kind of information is missing, making it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the provided analysis is considered weak, namely the absence of information on the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization (in time and space). This feedback is clear and actionable, as it points out specific gaps in the analysis that need to be addressed. By highlighting these areas, the comment provides the authors with a clear direction for improving the draft, ensuring that the theoretical foundations are more robustly established. However, the comment could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar issues have been addressed in related works. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the quality of generated images by the proposed method is limited, particularly in terms of realism. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the quality of the generated images or suggestions for enhancing their realism. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they need to make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the quality of generated images by the proposed method, specifically mentioning that the realism of the results is limited. However, it does not specify which part of the paper or supplemental material is being referred to, making it weakly grounded. The comment is specific in detailing the issue of limited realism in the generated images, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the quality of generated images by the proposed method is limited, particularly in terms of realism. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or comparisons to other methods or standards that could substantiate the claim. Without such evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the quality of generated images by the proposed method, particularly in terms of realism. It highlights that while good continuous control is achieved, the realism of the generated results is limited. This feedback is somewhat helpful as it points out an area for improvement, but it lacks specific suggestions or guidance on how to address the issue. The authors are informed of a potential weakness but are not provided with actionable steps to improve the quality of the generated images or enhance their realism. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to describe the size and elements of G, which is the graph used in the DGCN model. It also suggests adding the dimensions of G, X, and W to provide a better understanding of the model. These actions are clear and concrete, as they specify exactly what needs to be added or clarified in the paper. The authors know exactly what steps to take to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of G, the size and elements of G, and the dimensions of G, X, and W. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the construction of G, the graph used in the DGCN model. It suggests that the size and elements of G should be described, and the dimensions of G, X, and W should be added to provide a better understanding of the model. This is a request for additional information rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where additional clarity is needed, specifically regarding the construction of G, the graph used in the DGCN model. It suggests that the size and elements of G should be described, and the dimensions of G, X, and W should be added to provide a better understanding of the model. This feedback is clear and actionable, as it directs the authors to enhance the clarity and comprehensiveness of their explanation. By addressing these points, the authors can improve the readability and accessibility of their work, making the comment mostly helpful. However, it could be more helpful if it provided examples or additional context on how these elements are relevant to the model or its performance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (A-B-A and B-A-B) with two separate standard backpropagation processes. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest how the authors should address this discrepancy or improve their draft. As a result, the authors are left without any guidance on how to respond to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 559-560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (A-B-A and B-A-B) with two separate standard backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement regarding Cycle Consistency loss is not entirely true, as it can iterate between two phases of the reconstructions (A-B-A and B-A-B) with two separate standard backpropagation processes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the paper regarding the Cycle Consistency loss, specifically noting that it can iterate between two phases of the reconstructions (A-B-A and B-A-B) with two separate standard backpropagation processes. This is a clear and actionable point that the authors can address to improve the accuracy and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to clarify or correct the discrepancy. Overall, the comment is mostly helpful as it points out a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the term \"hyper-spectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer suggests that the authors should clarify or replace the term with a more appropriate one. While the comment provides a clear suggestion for improvement, it does not offer specific guidance on how to address the issue, such as recommending alternative terms or explaining the context in which the term is used. The action is explicit but somewhat vague, as the authors know they need to clarify the term but may not be entirely sure how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"hyper-spectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it is confusing and not standard in the field of hyperspectral imaging. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"hyper-spectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer provides a definition of hyperspectral imaging to support the claim, which is a logical and clear explanation. However, the comment could be strengthened by referencing specific sources or literature that establish the standard terminology in the field. Despite this, the claim is mostly verifiable due to the logical reasoning and the provided definition.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper by pointing out that the term \"hyper-spectral\" is not a standard term in the field of hyperspectral imaging. It provides a clear and concise explanation of what hyperspectral imaging is, which helps the authors understand the issue and make a correction. The comment is actionable, as it directly suggests that the authors should clarify or replace the term with a more appropriate one. This feedback is valuable as it helps the authors improve the clarity and accuracy of their work. However, the comment could be more helpful if it included specific suggestions for alternative terms or provided examples of how the term has been used inaccurately. Overall, the comment is mostly helpful as it effectively guides the authors in making a necessary correction.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also mentions that the concept of peak in Figure 5 is not described. While the comment provides explicit actions to take, such as revisiting the energy concept and clarifying the peak concept, it does not specify how to implement these actions or what specific details should be included in the refreshed explanation. The authors are given clear guidance on what needs to be addressed, but the execution of these actions is somewhat vague. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the concept of energy should be refreshed in Section 5.2 and providing a possible interpretation of high energy on a character. Additionally, it points out the lack of description for the concept of peak in Figure 5. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the concept of energy is mentioned for the first time in Section 3.1 and that it should be refreshed in Section 5.2, where it is used several times. The reviewer also questions the interpretation of high energy on a character, suggesting it might indicate that the current morpheme should be split at that point. Additionally, the reviewer points out that the concept of peak in Figure 5 is not described. While the comment provides a logical suggestion for clarifying the energy concept, it lacks specific examples or references to support the claim that the current explanation is insufficient. This makes the claim somewhat verifiable, as the authors would need to make a logical deduction to understand the need for clarification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also points out that the concept of peak in Figure 5 is not described, which is a clear area for improvement. This feedback is detailed and constructive, offering the authors a clear path to enhance the clarity and comprehensibility of their draft. By addressing these points, the authors can significantly improve the readability and understanding of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. It specifically mentions that ablation studies in Sections 3 and 4 demonstrate the effectiveness of each component, but the comment implies that a more detailed explanation is needed. While the action is implicit, it is concrete because it specifies what additional information is needed (e.g., how the performance of combining the Linformer and window attention in Big Bird is improved). Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"1), 2) and 3) mentioned above,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the contribution of each component to the final performance improvements. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. While it mentions ablation studies in Sections 3 and 4, it does not provide specific examples or detailed reasoning to support why this additional information is necessary. The claim is somewhat verifiable as it highlights a potential gap in the paper, but it lacks the necessary evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about how each component contributes to the final performance improvements. It references ablation studies in Sections 3 and 4, which are mentioned above, and implies that a more detailed explanation is needed. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by explaining the contributions of each component. However, the comment could be more helpful if it offered specific examples or guidance on how to present this information. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific gaps in the paper regarding the details of the models, particularly the grammar over kernels and the probabilities associated with it. It explicitly asks for clarification on how the grammar is applied in practice, how inference is performed, and what the hypothesis space of kernels consists of. This feedback provides clear and concrete actions for the authors to take, such as expanding on the explanation of the grammar over kernels and the probabilities associated with it. The comment is explicit and provides detailed guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the grammar over kernels\" and \"probabilities associated with the grammar,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail in explaining the grammar over kernels and how inference is performed. The comment provides a clear direction for improvement by asking for more detailed explanations of these concepts. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the lack of detail in the explanation of the grammar over kernels and the probabilities associated with it, which makes it difficult to understand how the approach is applied in practice. The reviewer suggests that there might be probabilities associated with the grammar that define a hypothesis space of kernels, and questions how inference is performed. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to make a significant effort to understand and address the issue, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors have not provided sufficient detail, namely the explanation of the grammar over kernels and the probabilities associated with it. It points out that this lack of detail makes it difficult to understand how the approach is applied in practice. The comment raises important questions about the hypothesis space of kernels and inference, prompting the authors to clarify these aspects of their work. While the comment highlights a critical area for improvement, it could be more helpful if it provided suggestions on how to address these gaps or offered examples of how similar concepts have been explained in other works. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the role of visual information, verify the effectiveness of the ablation study, and ensure that the experiment results are significant. The lack of concrete steps or suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 10\" and \"w/o perception module and w perception,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the ablation study, the lack of verification, and the questionable significance of the experiment results due to the sample size. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the role of visual information is unknown, questioning the effectiveness of the ablation study and the significance of the experiment results due to the sample size. The comment provides some support by mentioning that the w/o perception module and w perception exhibit similar performance, which suggests that the perception module might not be necessary. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the effectiveness of the ablation study or the significance of the experiment results. This makes the claim somewhat verifiable, as it provides some evidence but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. It highlights specific concerns, such as the performance of the w/o perception module and w perception, and the implementation detail of w/o perception. While the comment provides some insight into potential weaknesses, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need attention, but it could be more beneficial with additional guidance or examples on how to improve the draft. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This implies that the authors should include references to these works to provide a more comprehensive comparison. The comment is explicit in its request for inclusion of these references, making it clear and actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the end of Section 4.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of references to previous works on Lasso screening, such as Ren et al. (2017), and suggests including these references for a more comprehensive comparison. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This claim is somewhat verifiable as it highlights a potential omission in the paper\\'s literature review, but it lacks specific references to the works that should be included. The reviewer provides a specific example of a relevant work, which would strengthen the claim. However, the comment does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This feedback is clear and actionable, as it points out a gap in the literature review that the authors should address to provide a more comprehensive analysis. By including these references, the authors can enhance the credibility and depth of their work. However, the comment could be more helpful if it suggested how to integrate these references into the existing text or provided additional guidance on how to conduct a more thorough comparison. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the documentation. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed information about the hyperparameters. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the model, noting that many components have hyperparameters that are not fully provided. However, it does not specify which components or hyperparameters are in question, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors should improve the documentation. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the model, noting that many components have hyperparameters that are not fully provided. This is a relevant observation that could impact the reproducibility and clarity of the paper. However, the comment lacks depth and does not provide actionable guidance or suggestions on how the authors might address this issue, such as recommending specific improvements or providing examples of how to better document the hyperparameters. As a result, the comment is somewhat helpful, as it points out a potential problem but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR-10 of 3%p but does not clarify what \"%p\" stands for. This feedback implies that the authors should clarify the meaning of \"%p\" in their notation. However, it does not provide specific guidance on how to address this issue, such as suggesting a definition or explanation to be added. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the notation, but it is still clear enough to guide the authors in making a change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"notation for results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out that the paper claims an improvement for CIFAR-10 of 3%p but does not clarify what \"%p\" stands for. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR-10 of 3%p but does not clarify what \"%p\" stands for. This claim is somewhat verifiable as it highlights a specific issue with the notation, but it lacks detailed explanation or examples to fully substantiate the claim. The authors might need to infer that \"%p\" is a percentage symbol, but the comment does not provide enough context or reasoning to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, specifically the claim of an improvement for CIFAR-10 of 3%p without clarifying what \"%p\" stands for. This feedback is clear and actionable, as it directs the authors to provide a clear explanation or definition of the notation to improve the clarity of their results. By addressing this issue, the authors can enhance the readability and comprehensibility of their paper, making it more accessible to both reviewers and readers. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. Additionally, it recommends showing some failure cases and analyzing the limitations. While the comment provides a clear direction for improvement, it does not specify which specific qualitative results or failure cases should be included or how to present them. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. However, the comment does not specify which part of the paper these results should be included in, nor does it provide detailed guidance on how to present them. While the authors might have an idea of where these results could be added, the lack of explicit grounding makes it difficult for them to pinpoint the exact sections that need revision. The suggestion is specific in terms of what is needed, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that including these results would be beneficial. The absence of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the value of these additions themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of qualitative results, possibly with zoomed-in views, for cases where previous methods failed but were successful with the proposed method. It also suggests showing some failure cases and analyzing the limitations. This feedback is valuable as it offers a concrete way for the authors to enhance the presentation of their results, which could help demonstrate the effectiveness of their method. However, the comment could be more helpful if it provided specific examples of what qualitative results or failure cases should be included, or if it offered guidance on how to present these results effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text, not human reading comprehension. This feedback provides a clear and explicit action for the authors to take, which is to clarify the title to avoid confusion. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the ambiguity in the title regarding whether it refers to human or machine comprehension. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text, not human reading comprehension. The comment provides a logical reasoning by explaining the common understanding of \"reading comprehension\" and \"readability\" in the context of human reading. However, it lacks specific examples or references to support the claim that the title is ambiguous. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the title of the paper, suggesting that it is ambiguous and may refer to human reading comprehension rather than machine comprehension of text. It provides a clear and actionable suggestion to clarify the title to avoid confusion. This feedback is valuable as it helps the authors ensure their title accurately reflects the focus of their work, which is important for clarity and effective communication. However, the comment could be more helpful if it offered additional guidance on how to clarify the title or suggested alternative wording. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific claim made by the authors on line 238, which is incorrect according to the Central Limit Theorem (CLT). It highlights that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment explicitly identifies the issue with the claim and provides a clear explanation of why it is incorrect. However, it does not offer any guidance on how the authors should address this issue or suggest alternative statements to correct the claim. The action is explicit but lacks concrete details on how to implement the correction, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made by the authors regarding the Central Limit Theorem (CLT) and why it is incorrect. The comment provides a detailed explanation of why the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim made by the authors regarding the Central Limit Theorem (CLT) and its applicability to a finite linear combination of random variables. The reviewer provides a detailed explanation of why the claim is incorrect, citing specific aspects of the CLT that do not hold in a non-asymptotic regime. This logical reasoning and reference to the CLT makes the claim fully verifiable, as it provides a clear and robust basis for the critique. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific claim made by the authors regarding the Central Limit Theorem (CLT) and its applicability to a finite linear combination of random variables. It points out that the CLT does not guarantee Gaussianity in a non-asymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it provides the authors with a precise understanding of the inaccuracy in their claim and offers guidance on how to correct it. By addressing this issue, the authors can improve the accuracy and credibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors need to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific area to focus on, making it highly actionable. The authors know exactly what needs to be done to address the reviewer\\'s concern, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the time complexity of the proposed policies mentioned in Section 4. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should analyze the time complexity of the proposed policies mentioned in Section 4. However, it does not provide any supporting evidence, reasoning, or examples to justify why this analysis is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area for improvement by suggesting that the authors analyze the time complexity of the proposed policies mentioned in Section 4. This feedback is clear and actionable, as it directs the authors to a specific part of the paper where additional analysis could enhance the understanding and evaluation of the proposed policies. However, the comment could be more helpful if it provided additional context or examples on how to conduct this analysis or what aspects of time complexity should be considered. Overall, the comment offers a clear direction for improvement, but it could be more comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make. The comment lacks concrete suggestions or detailed instructions on how to improve the evaluation, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the evaluation is discussed, the comment lacks full grounding. It is specific in its critique of the use of an automatic metric, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of an automatic metric (TSS) in the human evaluation, suggesting that it weakens the convincingness of human evaluation. However, the comment does not provide any supporting evidence, reasoning, or references to justify why an automatic metric is less convincing than a human metric. Without such justification, the claim remains unverifiable, as it lacks the necessary information to support the claim. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. This feedback highlights a potential weakness in the evaluation methodology, which could impact the credibility of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what alternative human metrics could be used. While it identifies a potential problem, it lacks depth and actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would be strengthened by including experiments across more diverse domains, specifically mentioning those in TD-MPC 2. While the comment implies that the authors should expand their experiments to include more diverse domains, it does not provide explicit instructions on how to do so or which specific domains to consider. The action is implicit and somewhat vague, as the authors need to infer the need for more diverse experiments and determine which domains to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments prove the point made by the authors and recommends expanding the experiments to include more diverse domains, specifically mentioning those in TD-MPC 2. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of more diverse domains, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments prove the authors\\' point effectively but recommends expanding the experiments to include more diverse domains, specifically mentioning those in TD-MPC 2. This claim is somewhat verifiable as it provides a logical reasoning for expanding the experiments to enhance the paper\\'s impact. However, it lacks specific examples or detailed justification for why these additional domains are necessary or how they would contribute to the paper. The suggestion is somewhat supported by the mention of TD-MPC 2, but further elaboration would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the experiments effectively prove the authors\\' point but recommends expanding the experiments to include more diverse domains, specifically mentioning those in TD-MPC 2. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of additional experiments to enhance the paper\\'s impact. However, the comment lacks specific guidance on how to implement this suggestion or which domains to consider, making it somewhat helpful but not fully actionable. The authors are given a direction but need more detailed guidance to fully understand and execute the suggested improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should show confidence intervals and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. The comment provides explicit actions for the authors to take, such as including confidence intervals and expanding the evaluation to more datasets. However, it does not specify which datasets should be used or how to calculate the confidence intervals. While the actions are clear, the lack of detailed guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of confidence intervals for results and the limited evaluation on two datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of not showing confidence intervals and the need to evaluate on more datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. The reviewer supports this claim by referencing external works that discuss the importance of confidence intervals and the need for more datasets to evaluate robustness. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of confidence intervals or by explaining why the two datasets used are insufficient. Despite this, the claim is mostly verifiable due to the references to external works, which provide a solid foundation for the critique.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should include confidence intervals to demonstrate statistical significance and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the robustness and credibility of their results. However, the comment could be more helpful if it offered suggestions on how to calculate confidence intervals or which datasets to consider. Overall, the comment is mostly helpful as it effectively directs the authors toward improving their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on what specific aspects of the interpretability tax should be evaluated or how the evaluation should be conducted. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this issue. Additionally, the comment lacks specificity regarding what aspects of the interpretability tax should be evaluated or how it should be measured. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area where the paper could be improved, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. This is a relevant point that could enhance the paper\\'s comprehensiveness and depth. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending particular metrics or analyses to include. While it points out a potential weakness, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main contribution of the paper is not in proposing novel techniques but rather in demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. The authors are left without guidance on how to address this feedback or what specific changes could be made to enhance the novelty or contribution of their work. As a result, the comment lacks actionability, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the simplicity of the LUQ design and the standard nature of the approaches presented in Section 5, suggesting that the main contribution is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not specify which part of the paper this discussion pertains to, such as the sections on the LUQ design or the approaches presented in Section 5. The comment lacks grounding as it does not specify where in the paper these issues are discussed, making it difficult for the authors to identify and address the feedback. Additionally, the comment is not specific about what needs to be improved or how the authors could enhance the contribution of their work. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the LUQ design is straightforward and that the approaches in Section 5 are standard and explored in previous literature. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim unverifiable, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the straightforward nature of the LUQ design and the standard approaches presented in Section 5, suggesting that the main contribution of the paper is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not provide specific suggestions or guidance on how the authors could enhance the novelty or contribution of their work. The comment lacks actionable feedback or constructive advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it implies that the authors should provide evidence or analysis of the training stability, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide training losses to address the concern. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for training losses, but without clear grounding, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The authors are left to infer that they should provide evidence or analysis of the training stability, but without detailed instructions or examples, the comment does not fully support the authors in improving their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer actionable steps for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability as being the same concept. The reviewer suggests that these are actually different perspectives on applying stronger constraints for samples with higher popularity. While the comment identifies a potential issue with the paper\\'s claims, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claims about the strength of the proposed BC loss. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper overclaims the strength of the proposed BC loss by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability as the same concept. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability are the same concept. The reviewer provides a logical reasoning by explaining that these elements are different perspectives on applying stronger constraints for samples with higher popularity. However, the comment lacks specific examples or references to support the claim that these elements are indeed the same concept. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s theoretical analysis, specifically the overclaiming of the strength of the proposed BC loss. It points out that the paper claims the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability as separate concepts, but they are actually the same concept from different viewpoints. This feedback is somewhat helpful as it highlights a potential misrepresentation in the paper\\'s claims, which could be clarified or revised for greater accuracy. However, the comment lacks specific suggestions on how the authors might address this issue or improve the clarity of their theoretical analysis. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also points out that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. The reviewer suggests that these arena-based evaluation systems may not solve the problems of current score-based evaluation systems. While the comment identifies potential issues, it does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to improve the evaluation. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the relevance and effectiveness of their method in the context of score-based evaluation systems. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also mentions the framework FFAEVAL and similar frameworks like Chatbot Arena, suggesting that these systems may not be suitable for evaluating a single dialogue system. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the relevance and effectiveness of the proposed method in the context of score-based evaluation systems. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. The reviewer provides logical reasoning by explaining that these arena-based evaluation systems may not solve the problems of current score-based evaluation systems. However, the comment lacks specific examples or references to support the claim that these frameworks are not effective for evaluating single dialogue systems. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important concerns about the relevance of the proposed method to the authors\\' motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also points out that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. This feedback is valuable as it highlights a potential limitation in the applicability of the proposed method, which the authors should consider when evaluating their work. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these concerns or what alternative evaluation methods might be more appropriate. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. The reviewer suggests that this could result in unfair comparisons. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their training approach or provide additional context to justify the running speed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RegMixup\" and \"training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed and unfair comparisons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. The reviewer supports this claim by referencing the authors\\' claim of a 1.5x slower running speed. However, the comment does not provide specific examples or references to other methods or studies that could substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. This is a relevant observation that could impact the fairness of comparisons with other methods. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the running speed. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to clarify whether they meant to write \"t_R^m\" or \"t_R^{m-1}\" in an unnumbered equation. It also requests clarification on the definition of \"t_R^m\" if it is used subsequently, as its meaning is unclear. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to address the issue. The explicit nature of the request and the concrete guidance on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l81-82,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of whether \"t_R^m\" or \"t_R^{m-1}\" is intended in an unnumbered equation and the definition of \"t_R^m\" if it is used subsequently. This provides clear guidance on what needs to be clarified or corrected in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the notation \"t_R^m\" in an unnumbered equation. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific issue with the notation \"t_R^m\" in an unnumbered equation. It points out that the meaning of this notation is unclear and requests clarification or definition if it is used subsequently. This feedback is actionable as it directs the authors to provide clarity on a potentially confusing aspect of their work, which could improve the readability and comprehension of their manuscript. However, the comment could be more helpful if it suggested how to clarify the notation or provided examples of how it might be used. Overall, the comment is valuable in guiding the authors to improve the clarity of their work, but it could be more comprehensive with additional suggestions. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the use of focal loss in regression tasks and suggests that the authors may not have considered the differences between classification and regression tasks. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to consider the implications of using focal loss in regression tasks and potentially adjust their approach accordingly. The action is implicit and somewhat vague, as it lacks concrete steps for implementation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of focal loss in regression tasks and suggests that the authors may not have considered the differences between classification and regression tasks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the use of focal loss in regression tasks and the potential implications for accuracy. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of focal loss in regression tasks and suggests that it may not be appropriate due to its tendency to lower gradients on easy samples. The reviewer provides a logical reasoning that this could lead to inaccurate results in regression tasks. However, the comment lacks specific examples or references to support the claim that focal loss is not suitable for regression tasks. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its tendency to lower gradients on easy samples. This is a valid point that could impact the accuracy of the regression task. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or consider alternative methods. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful but not comprehensive in its feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of scalability should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of scalability should be considered or how the authors might address this question. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it could impact the practicality and applicability of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to verify whether the improvements of the proposed model over the RL without feedback model are statistically significant. This is a clear and direct action for the authors to take, as it provides a specific task to ensure the robustness of their findings. The comment is concrete in its request for statistical verification, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the verification of the improvements of the proposed model over the RL without feedback model. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed model's improvements over the RL without feedback model are not statistically significant, specifically mentioning the comparison between rows 3 and 4 in Table 6. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the proposed model's improvements over the RL without feedback model, noting that the improvements are not statistically significant as evidenced by the comparison between rows 3 and 4 in Table 6. The comment suggests that the authors verify if these improvements are statistically significant, providing a clear and actionable piece of feedback. This guidance is valuable as it directs the authors to a specific area that needs further investigation, ensuring that their findings are robust and reliable. However, the comment could be more helpful if it included additional context or examples of how to conduct the statistical verification. Overall, the comment is mostly helpful as it effectively points out a potential weakness and offers a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about relaxing the need to visit all ball-action pairs with each iteration and suggests exploring partial coverage. However, it does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they should consider relaxing the requirement or exploring partial coverage, but without specific instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"in continuation to the above remark,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how to relax the need to visit all ball-action pairs with each iteration and explores the possibility of partial coverage. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about relaxing the need to visit all ball-action pairs with each iteration and explores the possibility of partial coverage. While it raises an interesting point, it lacks specific guidance or suggestions on how to address this issue or what specific assumptions might be needed. The authors are left with a general direction to consider but without actionable steps or detailed advice. Therefore, the comment is somewhat helpful, as it provides a starting point for the authors to consider but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTa-base instead of BERT. While it does not explicitly instruct the authors to use RoBERTa-base, the implication is clear that they should consider this option. The comment is somewhat actionable as it provides a concrete suggestion for improvement but lacks explicit guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"encoder\" and compares it to \"RoBERTa-base,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the observed improvement could be achieved with a better encoder, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTa-base instead of BERT. However, it does not provide any supporting evidence, reasoning, or references to justify why RoBERTa-base might be a better choice. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the potential improvement in the observed results with a better encoder, specifically mentioning RoBERTa-base as an alternative to BERT. While it does not provide specific guidance or suggestions for improvement, it does prompt the authors to consider alternative encoders that could enhance their results. This feedback is somewhat helpful as it points out a potential area for exploration, but it lacks depth and actionable steps for the authors to follow. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This is an explicit action, as it clearly specifies the need for additional datasets to be included in the paper. However, the comment does not provide specific guidance on which datasets should be used or how to integrate them into the paper. While the action is clear, the lack of concrete details on implementation makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results discussion. The authors can infer that it relates to the evaluation or results sections, but this inference is not direct. The comment is specific in suggesting the inclusion of additional datasets, but it lacks grounding as it does not explicitly mention which part of the paper should include this information. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed technique should be evaluated on more datasets, specifically mentioning XNLI and XTREME, to demonstrate its generalizability to tasks with different levels of reasoning requirements. However, the comment does not provide any supporting evidence or reasoning to justify why these datasets are particularly relevant or how they would impact the evaluation of the technique. Without additional context or explanation, the claim remains somewhat verifiable, as the authors may find it challenging to understand the significance of these datasets without further elaboration.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This feedback is somewhat helpful as it identifies a specific area for improvement by recommending additional datasets to test the technique. However, the comment lacks depth and does not provide specific guidance on how to integrate these datasets or what specific aspects of the technique should be tested on these datasets. While it points out a potential area for improvement, the lack of detailed suggestions limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the choice of baseline methods could be improved, specifically recommending Ref-NeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. While the comment provides specific examples of potential baselines, it does not explicitly instruct the authors to use these methods or explain how to incorporate them into their evaluation. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the choice of baseline methods could be improved, specifically recommending Ref-NeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. However, it does not specify which part of the paper these suggestions pertain to, such as the methodology or results sections. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting potential baselines. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the choice of baseline methods could be improved by comparing with other existing methods, such as Ref-NeRF and MipNerf. While the comment provides specific examples of potential baselines, it lacks detailed reasoning or evidence to support why these particular methods would be beneficial or how they would enhance the evaluation. The suggestion is based on general knowledge of existing methods, but without further explanation or justification, it remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the choice of baseline methods could be improved by comparing with other existing methods, such as Ref-NeRF and MipNerf. This suggestion is based on the authors\\' need to evaluate the appearance decomposition part and larger outdoor scenes, respectively. By providing these examples, the reviewer helps the authors identify potential baselines that could enhance their evaluation and improve the robustness of their results. However, the comment could be more helpful if it explained why these specific methods were chosen or how they would contribute to the evaluation. Overall, the comment is mostly helpful as it offers a clear direction for improvement but could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" While the action is implicit, it is clear that the authors need to provide a method for achieving fair policy learning without negatively impacting the predictive model\\'s performance. However, the comment does not specify how to achieve this or what specific steps to take, leaving some ambiguity. Therefore, the comment is somewhat actionable, as it provides a direction but lacks concrete guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for a demonstration of fair policy learning without negatively impacting performance, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it could be achieved. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" This feedback is somewhat helpful as it identifies a potential weakness in the paper, specifically the impact of the proposed method on the predictive model\\'s performance. However, the comment lacks specific guidance or examples on how to achieve this balance or what specific steps the authors should take to address this issue. While it points out an area for improvement, it does not provide detailed instructions or suggestions for improvement, making it somewhat helpful but not fully actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. This provides a clear and direct action for the authors to take, specifying where the details should be added and what needs to be included. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of implementation details of the proposed methods. This provides clear guidance on what the authors need to include in the implementation details section to address the reviewer\\'s concerns. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the lack of implementation details of the proposed methods, which is a critical aspect of the paper. It suggests that these details should be included in Section 4.1, providing a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to a specific area where their draft could be strengthened, ensuring that the implementation details are transparent and accessible to readers. However, the comment could be more helpful if it offered additional guidance on what specific details should be included or how they could be presented effectively. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of empirical evaluation and comparison with other methods, indicating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. It suggests that the authors should provide empirical evaluation and comparisons with other methods to clarify the practical value of their contribution. The comment is explicit in its request for empirical evaluation and comparison, providing concrete guidance on what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that there is no practical value demonstrated and that the theoretical contributions may be significant but not adequately presented. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks empirical evaluation and comparison with other methods, which is a subjective claim. The reviewer supports this claim by stating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. However, the comment does not provide specific examples or references to support the claim that the theoretical contributions are significant or that the lack of empirical evaluation is a significant issue. This makes the claim somewhat verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting the lack of empirical evaluation and comparison with other methods. It highlights that the theoretical contributions may be significant but are not adequately demonstrated in the paper, making it unclear what the practical value of the contribution could be. The comment suggests that even a theoretical paper should attempt to argue for its significance, and it concludes that the current submission is not suitable for publication at NeurIPS. This feedback is clear and actionable, providing the authors with a specific direction to enhance the empirical evaluation and comparison sections of their paper. However, it could be more helpful if it offered suggestions on how to conduct the empirical evaluation or what specific comparisons should be made. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that in the manuscript, P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. This feedback implies that the authors should clarify the use of P in these instances to avoid confusion. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a change in notation or clarifying the context in which P is used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the clarity of their manuscript. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the manuscript, including \"P mostly represents a probability but sometimes for a cumulative distribution function (e.g., Eqs. (3) and (4) and L44, all in Appendix), which leads to confusion.\" This allows the authors to accurately identify the parts of the manuscript being addressed. The comment is also specific because it clearly specifies the issue of using P for both probability and cumulative distribution functions, which leads to confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that in the manuscript, P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. This claim is somewhat verifiable as it provides a specific example (P used in Eqs. (3) and (4) and L44) to illustrate the confusion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why this confusion is problematic or how it affects the understanding of the manuscript. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. This feedback is clear and actionable, as it directs the authors to clarify the use of P in their manuscript to avoid confusion. By addressing this issue, the authors can improve the clarity and readability of their work, making the comment mostly helpful. However, it could be more helpful if it provided suggestions on how to clarify the use of P or offered examples of how to differentiate between probability and cumulative distribution functions. Overall, the comment is mostly helpful as it effectively points out a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRM-RL. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or explore more general tasks. The authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRM-RL. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the paper\\'s applicability to more general tasks, but it lacks grounding as it does not identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is limited in its application to navigation problems and suggests that combining RL and planning has already been discussed in PRM-RL. However, the comment does not provide specific references or examples from PRM-RL to substantiate this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s applicability to general tasks beyond navigation problems, noting that combining RL and planning has already been discussed in PRM-RL. It suggests that the paper could explore more general tasks, which is a valid point. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their work to include more general tasks. While it points out an area for improvement, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider whether all feature spaces are well-suited for 1-NN and warns that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also recommends standardizing feature dimensions to avoid this issue. While the comment provides a clear action\u2014to evaluate the suitability of feature spaces and standardize dimensions\u2014it does not offer specific guidance on how to conduct this evaluation or what metrics to use. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suitability of feature spaces for 1-NN and the potential issue with non-spherical Gaussian feature spaces. The comment provides a clear direction for improvement by suggesting standardizing feature dimensions to avoid performance issues. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the suitability of feature spaces for 1-NN and suggests that non-spherical Gaussian feature spaces may perform poorly. The comment provides a logical reasoning by explaining that standardizing feature dimensions can avoid this issue. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, as the reasoning is not as robust as it could be. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, specifically the suitability of feature spaces for 1-NN. It points out that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment suggests a potential solution by recommending standardizing feature dimensions to avoid this issue. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it included examples or additional guidance on how to standardize feature dimensions effectively. Overall, the comment is mostly helpful as it highlights a critical aspect of the paper that needs attention, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but finds it less convincing and points out specific issues with the setting. However, the comment does not provide explicit guidance on how to define the contrastive gap or what specific aspects of the example should be addressed. While the authors can infer that they need to provide a formal definition, the comment lacks concrete details on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is central to the work, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the definition of the contrastive gap is unclear and that an example was provided but found less convincing. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed \"contrastive gap\" is unclearly defined, despite being central to the work. It acknowledges that an example was provided but finds it less convincing, citing specific issues with the setting. However, the comment lacks detailed reasoning or references to support why the example is less convincing or how the definition could be improved. This makes the claim somewhat verifiable, as it provides some basis but requires further elaboration for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but finds it less convincing, providing a detailed critique of the setting. This feedback is valuable as it highlights a key area for improvement, prompting the authors to clarify and strengthen the definition of the contrastive gap. However, the comment could be more helpful if it offered specific suggestions on how to improve the example or provided additional guidance on defining the concept. Overall, the comment is mostly helpful as it directs the authors to a crucial area for enhancement, but it could be more actionable with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the language used in section 3.1, lines 143 and 154, regarding the reward system in a Markov decision process (MDP). It suggests that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. While the comment identifies specific lines and issues, it does not provide explicit guidance on how to clarify the description or what changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description, but it is concrete in that it points to specific lines that need attention. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1, line 143\" and \"line 154,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inaccuracy of the statement regarding rewards in standard MDP formulations and suggests clarifying the description of each action. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. While the comment identifies specific lines and issues, it lacks detailed reasoning or references to standard MDP formulations or examples to fully substantiate the claim. This makes the claim somewhat verifiable, as the authors would need to further explore the topic to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the language used in section 3.1, lines 143 and 154, regarding the reward system in a Markov decision process (MDP). It points out that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. This feedback is somewhat helpful as it highlights a potential misconception in the paper and provides a specific area for clarification. However, the comment could be more helpful if it offered suggestions on how to clarify the description or provided examples of standard MDP formulations. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing improvement, but it lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include other baselines, such as those mentioned in related work [29, 5, 6]. It also mentions that the authors have addressed the reviewer's weakness points and that all unclear parts have been answered. The reviewer provides a specific suggestion to include the explanation of why the chosen baseline makes the most sense. However, the comment does not explicitly instruct the authors to add this explanation or provide guidance on how to integrate it into the paper. While the action is implied, it is not as concrete as it could be, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including other baselines, such as those mentioned in related work [29, 5, 6]. It also mentions that the authors have addressed the reviewer\\'s weakness points and that all unclear parts have been answered. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional baselines and providing a rationale for why they are relevant. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that other baselines should be included, such as those mentioned in related work [29, 5, 6]. However, it does not provide any specific reasoning or evidence to support why these baselines are necessary or how they would enhance the study. The comment also mentions that the authors have addressed the reviewer\\'s weakness points and that all unclear parts have been answered, but it does not elaborate on these responses. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the importance of including these baselines and the rationale behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include other baselines, such as those mentioned in related work [29, 5, 6]. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks specific guidance on how to integrate these baselines into the paper or why they are particularly relevant. While it points out a potential enhancement, it does not provide detailed instructions or examples on how to implement this suggestion. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the meaning of \\u03b4 in the statement of Lemma 5. While it does not explicitly instruct the authors to clarify this term, it implies that the authors should provide a definition or explanation of \\u03b4 to improve the clarity of the paper. The action is implicit but concrete, as the authors can infer that they need to address this issue to enhance the understanding of their work. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \\u03b4 in the statement of Lemma 5. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the meaning of \\u03b4 in the statement of Lemma 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the meaning of \\u03b4 in the statement of Lemma 5. While it identifies a potential area of confusion, it does not provide any guidance or suggestions for clarification or improvement. The comment lacks actionable feedback or context that would help the authors understand how to address this issue or improve the clarity of their work. As a result, it offers limited value to the authors in terms of enhancing the draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the uniform setting of \\u03b1_m in line 113, noting that this implies the contributions from all modalities are the same. It suggests that dynamically weighting the modalities is important, as demonstrated in multimodal fusion works. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider dynamically weighting the modalities. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the uniform setting of \\u03b1_m and suggests that dynamically weighting the modalities is important in multimodal fusion. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that setting \\u03b1_m uniformly to 1/M implies that the contributions from all modalities are the same, which is not accurate. The reviewer supports this claim by referencing works in multimodal fusion that demonstrate the importance of dynamically weighting modalities. This reference provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to these works, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the uniform setting of \\u03b1_m in line 113, noting that it implies the contributions from all modalities are the same. It suggests that dynamically weighting the modalities is important, as demonstrated in multimodal fusion works. This feedback is somewhat helpful as it points out a potential weakness in the paper and provides a direction for improvement. However, the comment could be more helpful if it offered specific examples or references to multimodal fusion works that demonstrate the importance of weighting modalities. As it stands, the authors are left with a general suggestion to explore this further, which may not be immediately actionable without additional guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. However, it does not provide any guidance on how the authors should address this issue or suggest alternative phrasing that might be clearer. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the pervasive use of the phrase \"to meet\" and how it is difficult to understand. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the pervasive use of the phrase \"to meet\" in the paper is difficult to understand. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. This feedback is clear and actionable, as it points out a specific area where the language could be improved for clarity. However, the comment could be more helpful if it provided suggestions for alternative phrasing or clarified the intended meaning of the phrase. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. This is a clear and explicit observation that the authors can easily address by correcting the labeling in both the text and the figure. The action is concrete, as it specifies the exact labeling that needs to be changed, and the authors know exactly what to do to make the correction. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the discrepancy between the labeling of the task loss in the text and the figure, providing clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. This is a factual observation that does not require any subjective interpretation or opinion. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. This is a clear and actionable observation that the authors can address to ensure consistency in their presentation. However, the comment does not provide any suggestions or guidance on how to resolve this issue or why it might be important to do so. While it points out a specific error, it lacks depth and does not offer additional insights or context that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of the method should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the network depth is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the method\\'s limitations should be addressed or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking about the limitations of the method, specifically regarding the depth of the network in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. This is a relevant point that could prompt the authors to consider the depth of their network and its implications for the method\\'s effectiveness. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the method should be considered. While it points out a potential area for improvement, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the work should be evaluated in machine translation, which is seen as a more convincing approach due to its lower uncertainty per word. While the comment implies that the authors should consider this evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider machine translation as an additional evaluation method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the work should be evaluated in machine translation, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work only uses answer generation and summarization, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the proposed method in machine translation would be more convincing due to its lower uncertainty per word. This claim is somewhat verifiable as it provides a logical reasoning for why machine translation might be a more appropriate evaluation method. However, it lacks specific examples or references to support the claim that machine translation is indeed a more convincing approach. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation, which exhibits lower uncertainties per word, would be more convincing. This feedback is somewhat helpful as it points out a potential weakness in the evaluation approach and suggests an alternative method for demonstrating the effectiveness of the proposed method. However, the comment could be more helpful if it provided specific examples or references to support the claim that machine translation is a more appropriate evaluation method. Overall, the comment offers a clear direction for improvement but lacks depth and detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the dropout method used in the paper, specifically asking about the dropping rate and the number of masks generated. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"dropout\" and \"multiple stochastic masks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the dropout method used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the dropout method used in the paper, specifically asking about the dropping rate and the number of masks generated. This feedback is valuable as it prompts the authors to clarify and provide more detailed information about their methodology, which could enhance the transparency and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar methods have been presented in the literature. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the effectiveness of the proposed two-stage optimization approach needs further justification. It suggests that comparisons with other single-stage attacks and benchmarks with other state-of-the-art (SOTA) algorithms are necessary to demonstrate the effectiveness. This provides clear and concrete actions for the authors to take, such as including these comparisons and benchmarks to strengthen their claims. The comment is specific in detailing what additional information is needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed two-stage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further justifications, comparisons with other single-stage attacks, and benchmarks with SOTA algorithms to justify the effectiveness of the technical contributions. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed two-stage optimization approach needs further justification. It suggests that showing only the performance drop on fusion models is insufficient and that comparisons with other single-stage attacks are necessary to demonstrate effectiveness. The comment also implies that without proper benchmarks and comparisons with other state-of-the-art (SOTA) algorithms, it is difficult to justify the technical contributions. However, the comment does not provide specific examples or references to support these claims, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the critique, as the reasoning is not fully articulated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the need for further justification of the proposed two-stage optimization approach. It suggests that showing only the performance drop on fusion models is insufficient and that comparisons with other single-stage attacks and benchmarks with state-of-the-art algorithms are necessary to demonstrate the effectiveness. This feedback is clear and actionable, as it provides specific guidance on what additional information is needed to strengthen the paper\\'s claims. By addressing these points, the authors can significantly improve the clarity and robustness of their technical contributions. However, the comment could be more helpful if it included examples of specific comparisons or benchmarks that would be beneficial. Overall, the comment is mostly helpful as it effectively directs the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not specify the type of GPUs used for testing or the inference time. This is an explicit observation that the authors can directly address by including this information in their draft. The comment provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be added to improve their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the absence of information about the type of GPUs used for testing and the inference time, allowing the authors to accurately identify the part of the paper being addressed. It specifies what needs to be added, namely the type of GPUs and inference time, providing clear guidance on what needs to be included in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not provide information about the type of GPUs used for testing or the inference time. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting the lack of information about the type of GPUs used for testing and the inference time. This feedback is clear and actionable, as it directs the authors to include this information in their draft. By addressing this point, the authors can enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details to include. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the monotonic increase in performance of RS-D4PG with respect to \u03bb values in Table 1 and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s'\" in the bracket on Line 4 in the paragraph about D4PG. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors can infer that they need to correct the table and the paragraph, but the comment lacks concrete details on how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1\" and \"Page 3, Line 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the monotonic increase in performance of RS-D4PG with respect to \u03bb values and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s'\" in the bracket on Line 4 in the paragraph about D4PG. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the monotonic increase in performance of RS-D4PG with respect to \u03bb values in Table 1 and questions what happens when \u03bb is even smaller. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues in the paper, such as the monotonic increase in performance of RS-D4PG with respect to \u03bb values in Table 1 and the missing symbols \"J o b j \u03c0 ( \u03b8 )\" and \"\u03c4\" in the bracket on Page 3, Line 2, and the missing \"s'\" in the bracket on Line 4 in the paragraph about D4PG. This feedback is clear and actionable, as it points out areas where the authors need to correct errors or clarify their work. However, the comment could be more helpful if it provided suggestions on how to address these issues or explained why they are important. Overall, the comment is mostly helpful as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. While the comment identifies a specific area of concern, it does not provide explicit instructions on how to address this issue or what changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to make a correction but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Perceptual Metric should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Perceptual Metric in Figure 2, noting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback is clear and actionable, as it points out a potential error in the experimental setup that the authors can correct to ensure the accuracy of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining why this distinction is important or offering guidance on how to implement the correction. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that a specific sentence is confusing and suggests that the authors should clarify it. However, it does not provide any explicit guidance on how to improve the sentence or what specific changes should be made to make it clearer. The authors are left to infer that they need to revise the sentence, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific sentence, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the sentence, which is that it is confusing and lacks immediate clarity. However, the comment does not provide specific suggestions on how to improve the clarity or what aspects of the sentence are confusing. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that a specific sentence is confusing and lacks immediate clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why the sentence is confusing or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific sentence that is confusing and lacks clarity. It acknowledges that the reviewer understood the sentence after re-reading it, but notes that it is not immediately obvious what is meant. This feedback is valuable as it highlights a potential issue with the clarity of the paper, which the authors can address to improve the readability and comprehension of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the sentence or offered alternative wordings that might improve its clarity. Overall, the comment is somewhat helpful as it points out a specific area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several instances where citations are missing or needed, specifically in lines 78-79, 129-130, 156-158, and 217-218. While it identifies these areas, it does not provide explicit instructions on how to include the missing citations or what specific references should be used. The actions are implicit and somewhat vague, as the authors need to infer that they should add citations but are not given specific guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for citations in lines 78-79, 129-130, 156-158, and 217-218. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of claims that require specific citations to support the assertions. For example, the claim about diffusion models outperforming generative adversarial networks is not substantiated with a reference. Similarly, the claim about previous work having limited success is also unsupported. The reviewer requests citations for these claims, which would provide the necessary evidence to support the claims. Therefore, the comment is considered unverifiable due to the lack of references or evidence to substantiate the claims.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where citations are missing or needed, which is a clear and actionable piece of feedback. It highlights specific lines in the paper where references are missing, such as lines 78-79, 129-130, 156-158, and 217-218. By pointing out these gaps, the comment provides the authors with a concrete way to improve the paper by including necessary citations. However, the comment could be more helpful if it suggested specific references or examples to include, which would enhance the guidance for the authors. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between Figures 1 and 2, specifically noting that Fig 1 shows a single shared encoder-decoder for multiple tasks, while Fig 2 shows one encoder-decoder per auxiliary task. This feedback implies that the authors should reconcile these figures to ensure consistency. However, the comment does not provide explicit instructions on how to address this issue, such as suggesting specific changes or clarifications. While the action is implied, it lacks concrete guidance on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the figures, noting that Fig 1 shows a single shared encoder-decoder for multiple tasks, while Fig 2 shows one encoder-decoder per auxiliary task. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Fig 1 is inconsistent with Fig 2, specifically noting that Fig 1 shows a single shared encoder-decoder for multiple tasks, while Fig 2 shows one encoder-decoder per auxiliary task. This claim is somewhat verifiable as it highlights a discrepancy between the figures, but it lacks detailed explanation or justification for why this inconsistency is problematic or how it affects the overall understanding of the paper. The authors might need to infer the significance of this inconsistency and how it impacts the paper\\'s conclusions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Figures 1 and 2, noting that Fig 1 shows a single shared encoder-decoder for multiple tasks, while Fig 2 shows one encoder-decoder per auxiliary task. This feedback highlights an inconsistency in the figures, which could impact the clarity and coherence of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the consistency between the figures. While it points out a potential problem, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether each node can attend to its own lower-level representation, based on the description of N_l^(s) from equation 2. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify or modify the description of N_l^(s) to ensure that each node can attend to its own lower-level representation, but it lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether each node can attend to its own lower-level representation, based on the description of N_l^(s) from equation 2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether each node can attend to its own lower-level representation, based on the description of N_l^(s) from equation 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the ability of each node to attend to its own lower-level representation, based on the description of N_l^(s) from equation 2. This is a relevant point that could impact the understanding and interpretation of the model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the description. While it identifies a potential area for improvement, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about how the inequality after line 433 follows from Lemma 7. It suggests that the authors should clarify how Lemma 7 is applied to this inequality. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 433\" and \"Lemma 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the inequality after line 433 follows from Lemma 7, and it suggests that the authors should clarify how Lemma 7 is applied in this context. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on how an inequality follows from a lemma. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the derivation of an inequality after line 433, asking how it follows from Lemma 7. This is a clear and actionable feedback that prompts the authors to clarify their reasoning and provide additional explanation to facilitate understanding. By addressing this question, the authors can improve the clarity and coherence of their paper. However, the comment could be more helpful if it provided suggestions on how to present this explanation or what specific details should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the paper\\'s main contribution is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic large-scale multitasking. It points out that the method\\'s ability and applicability are overstated or not well-supported, and that the automation process is unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to clarify the main contribution. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations and evidence to support their claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the main contribution of the paper, specifically the novel properties of the proposed method and how it copes with dynamic large-scale multitasking. It points out that the method\\'s ability and applicability are overstated or not well-supported, and that the automation process is unclear. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of the main idea and the automation process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic large-scale multitasking. The reviewer suggests that the method\\'s ability and applicability are overstated or not well-supported, and that the automation process is unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of specific evidence or references makes the claim somewhat verifiable, as the authors would need to make a significant effort to address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s main contribution, which is the clarity of the novel properties and the method\\'s ability to cope with dynamic large-scale multitasking. It points out that the method\\'s ability and applicability are overstated or not well-supported, and that the automation process is unclear. This feedback is valuable as it highlights areas where the authors need to provide more detailed explanations and evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to clarify these aspects or provided examples of how similar methods have been effectively communicated. Overall, the comment is mostly helpful as it directs the authors to critical areas needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include the bottom-up method [9] in their tables and evaluate its performance on the standard MS COCO dataset to see if there is a drop in performance in easy (non occluded) settings. While the comment explicitly states what needs to be done, it does not provide detailed guidance on how to implement these changes or what specific aspects of the method should be included in the tables. The action is clear but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the bottom-up method [9] and its results on the crowdpose dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is to include the bottom-up method in the tables and evaluate its performance on the MS COCO dataset. This provides clear guidance on what changes need to be made to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the bottom-up method [9] has reported results on the crowdpose dataset outperforming all methods, including the paper's own method, with a ResNet-50. The comment also recommends evaluating the method on the standard MS COCO dataset to see if there is a drop in performance in easy settings. While the claim is based on a specific external work, it lacks detailed justification or references to support the claim that the bottom-up method outperforms all methods, including the paper's own method. The suggestion to evaluate on the MS COCO dataset is logical, but the claim about the bottom-up method's performance is not fully substantiated. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include the bottom-up method [9] in their tables and evaluate its performance on the standard MS COCO dataset. This suggestion is based on the reported results of the bottom-up method on the crowdpose dataset, which could help the authors compare their method with a well-established baseline. By including this information, the authors can enhance the transparency and robustness of their work. However, the comment could be more helpful if it provided additional context or analysis on why this comparison is important or how it might impact the overall evaluation of the method. Overall, the comment is mostly helpful as it offers clear and actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper's claim of using \"annotation guideline\" may be an overstatement, as it only considered label name, label description, and few-shot examples. It suggests that the annotation guideline in the IE domain is complex and curated by linguists, providing an example from the TACRED slot filling guidelines. The reviewer implies that the prompts proposed by the paper might not fully capture the depth of true guideline understanding. However, the comment does not explicitly instruct the authors to revise their claims or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claims and provide more detailed explanations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim of using \"annotation guideline\" and provides a specific example of the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This allows the authors to identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the overstatement of the paper\\'s use of annotation guidelines and the need to provide a more nuanced understanding of the true complexity of annotation guidelines. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim of using \"annotation guideline\" may be an overstatement, as it only considered label name, label description, and few-shot examples. The reviewer provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This example highlights the nuances and specificity of annotation guidelines, which are curated by linguists. The claim is supported by logical reasoning and specific examples, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential overstatement in the paper\\'s claim of using \"annotation guideline,\" noting that the paper only considered label name, label description, and few-shot examples. It provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain, which are curated by linguists. This feedback is valuable as it highlights a potential misrepresentation in the paper\\'s claims and suggests that the prompts proposed might not fully capture the depth of true guideline understanding. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or improve their claims. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to compare their method to token pruning and token combination baselines, in addition to the BERT-baseline. This provides a clear and concrete action for the authors to take, specifying exactly what additional comparisons are needed to strengthen the experiment comparison. The comment is specific and direct, giving the authors a clear path to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment comparison\" and the need to compare the method to token pruning and token combination baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional baselines for comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment comparison is weak because it only compares the method to the BERT-baseline. It suggests that the authors should compare their method to token pruning and token combination baselines. While the comment identifies a potential issue with the experiment comparison, it does not provide specific reasoning or evidence to support why the current comparison is insufficient. The suggestion to include additional baselines is logical, but the lack of detailed justification or examples makes the claim somewhat verifiable. The authors would need to further explore the rationale behind the need for these additional comparisons to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the experiment comparison, noting that the authors only compare their method to the BERT-baseline. It suggests that the authors should also compare their method to token pruning and token combination baselines. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental evaluation by including additional baselines. By addressing this suggestion, the authors can strengthen their analysis and provide a more comprehensive comparison of their method. Therefore, the comment is mostly helpful, as it offers a clear and constructive path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental section should include a comparison to coordinate-aware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison to coordinate-aware methods in their experimental section. The comment is specific in identifying the missing comparison and offers a concrete direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison to coordinate-aware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This provides clear guidance on what the authors should add to their experimental section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental section should include a comparison to coordinate-aware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This claim is somewhat verifiable as it logically suggests that including such comparisons would provide a more comprehensive understanding of the methods being evaluated. However, the comment lacks specific examples or references to these methods, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section, suggesting that a comparison to coordinate-aware methods, such as TFN or SchNet, would be beneficial. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the experimental analysis by including a comparison to methods that are aware of the point coordinates. By addressing this point, the authors can improve the comprehensiveness and depth of their experimental evaluation. However, the comment could be more helpful if it explained why this comparison is important or how it would enhance the understanding of the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any specific guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending which weaknesses should be explored or how they could be demonstrated. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the authors did not show the possible weaknesses of the proposed model, but it does not specify which part of the paper this issue pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what weaknesses should be explored or how they could be demonstrated. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area for improvement by pointing out that the authors did not show the possible weaknesses of the proposed model. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific weaknesses should be explored. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the lack of related work and experimentation with other extract-then-generate methodologies in the paper. It implies that the authors should include a related work section and experiment with other methods to demonstrate the novelty and effectiveness of their proposed system. While the comment does not explicitly instruct the authors to add a related work section or conduct additional experiments, the action is implied and concrete. The authors can infer that they need to address these gaps in their work, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the idea of long document summarization and questions the novelty of the proposed system compared to previous extract-then-generate methodologies. It specifically mentions the absence of a related work section and the lack of experimentation with other extract-then-generate methodologies. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. While the authors can infer that it relates to the sections discussing the methodology and results, the comment is not fully grounded as it does not explicitly mention these sections. The comment is specific in identifying the need for a related work section and experimentation with other methods, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the novelty and effectiveness of the proposed system compared to previous extract-then-generate methodologies. It questions the absence of a related work section and the lack of experimentation with other methods. However, the comment does not provide specific examples or references to support the claim that the system does not offer any novelty or improvement over existing approaches. Without such evidence or reasoning, the claim remains unverifiable, as it lacks the necessary justification to be considered fully verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of a related work section and the lack of experimentation with other extract-then-generate methodologies. This is a critical observation that could impact the paper\\'s credibility and novelty. The comment highlights the need for the authors to address this issue by including a related work section and experimenting with other approaches. While it does not provide specific suggestions on how to conduct these experiments or what specific related work should be included, it points out a clear area for improvement. This feedback is somewhat helpful as it directs the authors to a crucial aspect of their work that needs attention, but it could be more helpful with additional guidance on how to address the identified gaps. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The authors are left to infer that they should consider these directions but are not given specific guidance on how to integrate them into their work. The lack of actionable details makes the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in suggesting alternative approaches, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints. However, it does not provide any supporting evidence, reasoning, or references to justify why these directions are more appealing or effective. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is not verifiable, and the authors may find it challenging to implement the suggestions without further guidance. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. While these suggestions are interesting and could potentially improve the paper, the comment lacks depth and does not provide specific guidance on how to implement these directions or integrate them into the existing work. The authors are left with a general idea of what could be explored but are not given actionable steps or detailed explanations to follow. Therefore, the comment is somewhat helpful, as it points out potential areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the introduction of related work is not sufficient and recommends providing more information on the advantages or differences of the proposed method, specifically in comparison to B-GLN. While the comment implies that additional work on GLN is needed, it does not explicitly instruct the authors to include this information or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should add more information about GLN and its differences. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction of related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficiency of the introduction of related work and the need for more work on GLN to reflect the advantages or differences of the proposed method, such as the difference from B-GLN. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction of related work is insufficient and suggests that more work on GLN is needed to reflect the advantages or differences of the proposed method, specifically in comparison to B-GLN. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and recommends providing more information on the advantages or differences of the proposed method, particularly in comparison to B-GLN. This feedback is clear and actionable, as it points out a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the methodology. However, the comment could be more helpful if it offered suggestions on how to present this additional information or what specific aspects of the methodology should be highlighted. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of hyperparameters in Moon's approach, specifically questioning why only one dropout rate is used when Variational dropout has input-output and recurrent dropout parameters. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks actionable guidance or recommendations on how the authors might improve their draft in response to this observation. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Moon\\'s approach\" and \"Variational dropout,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of hyperparameters in Moon\\'s approach, particularly the use of only one dropout rate compared to Variational dropout, which has input-output and recurrent dropout parameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of hyperparameters in Moon\\'s approach, specifically noting that Variational dropout has input-output and recurrent dropout parameters, while Moon\\'s approach only uses one dropout rate. This observation raises a logical question about the choice of hyperparameters and their impact on the results. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or how it might affect the results. Without additional context or explanation, the claim remains somewhat verifiable, as it highlights an area for consideration but lacks detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid question about the choice of hyperparameters in Moon\\'s approach, specifically questioning why only one dropout rate is used when Variational dropout has input-output and recurrent dropout parameters. This observation highlights a potential oversight or inconsistency in the paper, prompting the authors to reconsider their choice of hyperparameters. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for improvement, it lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting larger-scale experiments with non-trivial dynamics, specifically mentioning grid-worlds with walls and other non-trivial tiles. It also suggests conducting experiments on simple video-game domains, which would naturally have a low-cardinality discrete state- and action-space. The reviewer provides a clear and specific action for the authors to take, which is to conduct these experiments and compare their results against other approaches. The comment is explicit and provides concrete details on how to implement the suggested changes, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for larger-scale experiments with non-trivial dynamics, specifically mentioning grid-worlds with walls and other non-trivial tiles. It also suggests conducting experiments on simple video-game domains, which would naturally have a low-cardinality discrete state- and action-space. This provides clear guidance on what aspects of the paper need to be addressed. The comment is also specific in detailing what kind of experiments should be conducted and how they could be conducted, such as using publicly available simulators and comparing against other approaches. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the current experiments are insufficiently large-scale and do not include non-trivial dynamics, such as grid-worlds with walls and other non-trivial tiles. The reviewer questions whether this is due to a lack of time or severe scalability issues with the method. The comment proposes conducting experiments on simple video-game domains, which would naturally have a low-cardinality discrete state- and action-space, and suggests using publicly available simulators for these experiments. This provides a logical reasoning for the need to conduct larger-scale experiments and suggests a specific direction for improvement. However, the comment lacks specific examples or references to support the claim that conducting these experiments would be beneficial. Therefore, the comment is somewhat verifiable, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending larger-scale experiments with non-trivial dynamics, specifically mentioning grid-worlds with walls and other non-trivial tiles. It also suggests conducting experiments on simple video-game domains, which would naturally have a low-cardinality discrete state- and action-space. The comment highlights the importance of these experiments to address scalability issues and provide convincing evidence for the method's effectiveness. By suggesting specific domains and methods for conducting these experiments, the comment offers detailed guidance that can help the authors improve their draft. However, it could be more helpful if it provided additional context or examples of how these experiments could be conducted or what specific aspects of the method should be tested. Overall, the comment is mostly helpful as it provides clear and actionable feedback for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not provide any guidance on what specific quantitative measurement should be used or how to implement it. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely, a quantitative measurement to assess occupation bias. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors have not provided a quantitative measurement to assess the extent of occupation bias relative to real distributions in society. This is a relevant point that could impact the validity and generalizability of the study. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific quantitative measurement could be used. While it points out a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete suggestions on how to address this issue. The authors are left to infer that they should explore the potential impact of using adaptive gradient methods, but the comment lacks specific guidance on how to conduct this exploration or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this issue might be relevant. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the potential impact, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. The comment does not present any claims or opinions but rather seeks clarification or additional information. It is a request for further exploration or explanation, not a statement that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. This is a valuable observation that could lead to a deeper understanding of the results and their robustness. However, the comment lacks specific guidance or suggestions on how the authors might explore this aspect or what specific experiments or analyses could be conducted to address it. While it points out an important area for consideration, the feedback could be more actionable with additional details or examples. Therefore, the comment is somewhat helpful, as it provides a direction for further exploration but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these issues, such as suggesting additional teacher architectures or suggesting more recent methods to compare. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experiments and the types of teacher architectures used, as well as the comparison with methods proposed before 2019. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the experiments and the need for more diverse teacher architectures and more recent methods for comparison. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are insufficient and that there are limited types of teacher architectures. It also mentions that most compared methods are proposed before 2019. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. While it highlights these areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The mention of a table suggests that additional information might be available elsewhere in the paper, but without further elaboration, the authors are left without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of information from 2-hop neighbors and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to include information from 2-hop neighbors or how to clarify the effectiveness of the method. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the lack of information from 2-hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of information and the need to clarify the effectiveness of the method. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"no information from 2-hop neighbors is included\" and questions the effectiveness of the method. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting the lack of information from 2-hop neighbors and questioning the effectiveness of the method. However, it does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the clarity of their work. Without specific recommendations or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends using the real DICOM image as experiment data instead of the PNG image and suggests using the FastMRI challenge dataset for this purpose. It also advises comparing inference speeds between different methods. This feedback provides clear and concrete actions for the authors to take, such as changing the image format and including a specific dataset for evaluation. The suggestions are direct and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"real dicom image\" and suggests using the FastMRI challenge dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done, recommending the use of the real DICOM image and suggesting the FastMRI challenge dataset for comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests using the real DICOM image as experiment data instead of the PNG image and recommends using the FastMRI challenge dataset for comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the DICOM image is preferred or how it would impact the results. This lack of justification makes the claim unverifiable, as the authors are left without clear guidance on how to address the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by recommending the use of the real DICOM image as experiment data instead of the PNG image. It also suggests using the FastMRI challenge dataset for comparison, which is a clear and concrete suggestion. Additionally, it advises comparing inference speeds between different methods, offering a practical and valuable direction for the authors to improve their draft. This level of detail and specificity makes the comment highly helpful, as it guides the authors on how to enhance their experimental setup and analysis. Therefore, the comment is rated as 5: Highly Helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the binder design needs further optimization and validation, specifically mentioning that ProtPainter only provides empirical conformation estimation. However, it does not provide any explicit guidance on how to optimize or validate the binder design or what specific aspects need attention. The action is implied but not clearly stated, leaving the authors to infer the necessary steps to take. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ProtPainter\" and \"binder design,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further optimization and validation of the binder design. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ProtPainter only provides empirical conformation estimation for binder design, suggesting that further optimization and validation are required. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the binder design, noting that ProtPainter only provides empirical conformation estimation and that further optimization and validation are required. This feedback is clear and actionable, as it points out a gap in the current work and suggests specific areas for enhancement. However, the comment could be more helpful if it provided examples or guidance on how to optimize or validate the binder design. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify how the model in Figure 7 was trained, specifically inquiring about the stimulus used and the duration of the cycle. It also raises a question about whether the time scale of adaptation would shorten if the duration of the cycle changes, referencing a specific work by Smirnakis et al. in Nature 1997. The comment provides clear and direct actions for the authors to take, such as clarifying the training process and addressing the potential impact of cycle duration changes on adaptation. The explicit nature of the request and the concrete details on how to implement it make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the training process and the potential impact of cycle duration changes on the time scale of adaptation. The comment provides a clear direction for the authors to address the issue by asking for clarification on the training process and its potential implications. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training process of the model in Figure 7, specifically inquiring about the stimulus used and the duration of the cycle. It also references a specific work by Smirnakis et al. in Nature 1997 to support the claim that the time scale of adaptation might change with cycle duration. While the comment does not make a subjective claim or opinion, it does require clarification and evidence to be fully understood. Therefore, it is classified as \"3: Somewhat Verifiable\" as it provides some basis for the question but lacks detailed justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area of the paper that requires clarification regarding the training process of the model in Figure 7. It asks for clarification on the stimulus used and the duration of the cycle, which are crucial details for understanding the methodology. Additionally, it raises a relevant question about the potential impact of cycle duration changes on the time scale of adaptation, referencing a specific work by Smirnakis et al. in Nature 1997. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and completeness of their methodology section. However, the comment could be more helpful if it offered suggestions on how to address the potential impact or provided additional references to support the claim. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and comprehensiveness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about what happens if the original CAD model is already associated with spatially-varying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific steps they should consider. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the implications of having a CAD model associated with spatially-varying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the potential consequences of this association, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the implications of having a CAD model associated with spatially-varying (SV) BRDF maps. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the implications of having a CAD model associated with spatially-varying (SV) BRDF maps. While it highlights an area of interest, it does not provide any guidance or suggestions for the authors to address this question or explore its implications in their work. Without actionable feedback or context, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more evaluation is needed, specifically on CIFAR-10 in the full label and lower label scenarios. While the comment implies that additional evaluation is necessary, it does not provide specific guidance on what aspects of the evaluation should be expanded or how to conduct it. The authors are left to infer that they should conduct more evaluations, but without concrete instructions on what to evaluate or how to do it, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more evaluation is needed, specifically on CIFAR-10 in the full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or experiment. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting what kind of evaluation is needed, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more evaluation is needed, specifically on CIFAR-10 in the full label and lower label scenarios. However, it does not provide any supporting evidence, reasoning, or examples to justify why this additional evaluation is necessary or how it would benefit the paper. Without such information, the claim remains unverifiable, as it lacks the necessary context and justification to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more evaluation is needed, specifically on CIFAR-10 in the full label and lower label scenarios. This feedback is somewhat helpful as it identifies a potential area for improvement in the evaluation section of the paper. However, it lacks specific guidance on what aspects of the evaluation should be expanded or how to conduct it. The authors are left to infer that they should conduct more evaluations, but without detailed instructions or examples, the comment does not fully support the authors in making improvements. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. It suggests that comparisons should be made between using the same amount of data, such as H->N and H->B using less data than H->N+B. Additionally, it points out that H->N->H and H->N->H use less data than H->N+B->H. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their comparisons and ensure they are using the same amount of data. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons made in the table, questioning whether they are comparing apples to apples by using the same amount of data. The comment provides specific examples of comparisons that should be made, such as H->N and H->B using less data than H->N+B. Additionally, it points out that H->N->H and H->N->H use less data than H->N+B->H. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. The reviewer provides specific examples of comparisons that should be made, such as H->N and H->B using less data than H->N+B. Additionally, it points out that H->N->H and H->N->H use less data than H->N+B->H. This provides a logical reasoning and specific examples to support the claim, making the comment mostly verifiable. However, the comment could be strengthened by referencing specific studies or literature that support the importance of using the same amount of data for comparisons. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. It provides specific examples of comparisons that should be made, such as H->N and H->B using less data than H->N+B. Additionally, it points out that H->N->H and H->N->H use less data than H->N+B->H. This feedback is clear and actionable, as it guides the authors on how to improve the comparisons in their table to ensure they are making valid and meaningful assessments. By addressing these points, the authors can enhance the clarity and robustness of their analysis. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to it in the introduction. Additionally, it points out that the authors do not mention the use of iterative algorithms, which typically run until some criterion is fulfilled, with T >> 2. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they should clarify the placement of Alg 1, add a reference to Laplacian eigenmaps, and mention iterative algorithms. The actions are concrete but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to it in the introduction. It also points out that the authors do not mention the use of iterative algorithms, which typically run until some criterion is fulfilled, with T >> 2. While the comment does not explicitly mention specific sections or lines, the authors can infer that it relates to the discussion of Alg 1 and the introduction. The comment is specific in detailing what needs to be addressed, such as the placement of Alg 1 and the need for a reference to Laplacian eigenmaps. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps, and the absence of a reference to iterative algorithms. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to it in the introduction. It also points out that the authors do not mention the use of iterative algorithms, which typically run until some criterion is fulfilled, with T >> 2. These observations are clear and actionable, as they provide specific areas for improvement and guidance on how to address them. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or presentation of these issues. Overall, the comment is mostly helpful as it effectively identifies weaknesses and provides actionable feedback for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and provide more motivation for the CBN approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the section and provide more motivation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of Section 2.1 is problematic or where the ResNet architecture is discussed, making it weakly grounded. The comment is specific in suggesting that the time spent on the ResNet architecture could be better used, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. The reviewer argues that Batch Normalization is a general technique and that the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or references to support the claim that the inclusion of Section 2.1 is unnecessary or that the ResNet architecture could be better utilized. Without detailed reasoning or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting that the authors focus on the ResNet architecture to provide more context and motivation for the proposed methodology. However, the comment could be more helpful if it provided specific suggestions on how to enhance the motivation and intuition sections or how to better integrate the ResNet architecture into the paper. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a confusion regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending clarification or potential solutions to the confusion. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a confusion regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. The comment provides a clear issue to address, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the assumption that multiplying in equation (1) by a dense projection matrix would result in a sparse matrix, given that the projection matrix is assumed to be dense. This is a logical observation that challenges the authors\\' understanding of the process. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors may need to further explore the reasoning behind the assumption to fully address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, questioning the assumption that multiplying in equation (1) by a dense projection matrix would result in a sparse matrix. This is a clear and actionable point that prompts the authors to reconsider their reasoning or provide additional clarification. However, the comment could be more helpful if it suggested ways to address this issue or provided examples of how the authors might clarify their reasoning. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This is a clear and concrete action that the authors can take to address the issue of lacking direct evidence for the motivation. The comment provides a specific suggestion for how to present the evidence, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of direct evidence for the motivation and the need to plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evidence for the motivation is not direct, suggesting that the authors need to plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This claim is somewhat verifiable as it provides a logical reasoning for the need to present such a figure, but it lacks specific examples or references to similar studies or existing literature that could further substantiate the claim. The authors might need to explore this further to fully understand and address the reviewer\\'s concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of direct evidence for the motivation of the study. It provides a clear and actionable suggestion by recommending that the authors plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This feedback is valuable as it guides the authors on how to strengthen their argument and provide more robust evidence for their work. However, the comment could be more helpful if it explained why this figure is necessary or how it would enhance the paper\\'s credibility. Overall, the comment is mostly helpful as it offers a concrete direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the definition and calculation of excessive risk in the paper, particularly in relation to the optimal solution and data from different groups. It suggests that the authors should explain more about the concept of excessive risk and how it is calculated in practice, including the expectation. Additionally, it questions the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. While the comment provides a clear direction for the authors to clarify their explanation of excessive risk, it does not explicitly instruct them to do so. The action is implicit but concrete, as it specifies what needs to be addressed and provides a rationale for the request. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines, \"line 103\" and \"Figure 3 and Figure 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the definition of excessive risk and how it is calculated in practice, particularly in relation to the optimal solution and data from different groups. The comment also raises questions about the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the definition and calculation of excessive risk, particularly in relation to the optimal solution and data from different groups. It suggests that the values of excessive risk in Figure 3 and Figure 7 are positive, despite the fact that the optimal solution is not the optimal solution for the loss function w.r.t. data of group a. The reviewer questions the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. While the comment identifies a potential issue with the definition and calculation of excessive risk, it lacks specific examples or references to support the claim that the values are positive. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or clarification to fully address the reviewer\\'s concerns.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area of confusion regarding the definition and calculation of excessive risk in the paper. It questions the relevance of the concept of excessive risk as a fairness metric and points out that the values in Figure 3 and Figure 7 are positive, despite the fact that the optimal solution is not the optimal solution for the loss function w.r.t. data of group a. The reviewer also raises questions about the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. This feedback is clear and actionable, as it prompts the authors to clarify their explanation of excessive risk and its practical application. By addressing these points, the authors can improve the clarity and coherence of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It also references a specific paper ([1] Kunstner et al., 2019) to provide context and guidance on how to address the issue. While the comment does not explicitly instruct the authors to revise their statement, it clearly identifies a potential area for improvement and provides a reference to support the claim. The action is implicit but concrete, as the authors can infer that they need to rephrase their statement and consider the reference provided. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement about initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more careful statement about initialization. The comment provides a reference to a specific paper ([1] Kunstner et al., 2019) to support the claim, which further clarifies the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that initialization plays a role in natural gradient descent (NGD) and suggests that it should be treated as pre-training. The reviewer supports this claim by referencing a specific paper ([1] Kunstner et al., 2019) that discusses the limitations of empirical Fisher approximation for natural gradient descent. This reference provides a logical basis for the claim, as it highlights the importance of initialization in the context of NGD. However, the comment could be strengthened by providing more detailed explanations or examples of how initialization affects NGD. Overall, the claim is mostly verifiable, as it is supported by a relevant reference but could be further substantiated with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It provides a specific reference to a relevant paper ([1] Kunstner et al., 2019) to support the claim that initialization plays a role in natural gradient descent (NGD). This feedback is valuable as it highlights a specific area for improvement and offers a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it provided additional guidance on how to rephrase the statement or what specific aspects of initialization should be emphasized. Overall, the comment is mostly helpful as it directs the authors to a relevant reference and offers a clear suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues: the lack of clarity regarding how named entities were extracted from datasets and the need for an English-proofreading to improve the readability of the paper. While the first point is explicit in asking for clarification on the extraction process, the second point is more implicit in suggesting an improvement. However, both points are concrete in their request for clarification and actionable in that the authors know exactly what needs to be addressed to improve the draft. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for clarification on how named entities were extracted from datasets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for an English-proofreading to improve the readability of the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding how named entities were extracted from datasets and suggests that an English-proofreading would significantly improve the readability of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement: clarity regarding the extraction of named entities from datasets and the need for an English-proofreading to enhance the readability of the paper. While the comment highlights these issues, it does not provide detailed guidance or suggestions on how to address them. The authors are informed of the need for clarity and improved readability but are left without specific steps to take. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which would improve the condition slightly. This feedback is explicit and provides a clear action for the authors to take, suggesting a specific change to improve the condition. The comment is concrete, as it details the exact change needed and how it could enhance the condition. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines, \"L200\" and \"L303,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a potential issue with the statement \"for every arm a,\" suggesting that it implies a single optimistic parameter. The comment further specifies a potential improvement by proposing an alternative condition, \"B > Sqrt(m) T^(3/4),\" which could enhance the condition. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a critique of the statement \"for every arm a\" and a suggestion for improvement. The first part questions the implication of a single optimistic parameter, which is a logical observation. However, the second part provides a specific suggestion for improvement by proposing an alternative condition. This suggestion is based on a logical reasoning that could potentially improve the condition. While the comment lacks detailed justification or references, it provides a clear and actionable suggestion, making it mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the statement \"for every arm a\" in the paper, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which could improve the condition. This feedback is clear and actionable, as it offers a concrete way for the authors to enhance their work. However, the comment could be more helpful if it explained why this alternative condition is beneficial or how it relates to the overall context of the paper. Despite this, the feedback is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the terms \"L\" and \"E\" should be defined in the immediate vicinity and highlights the inconsistency in whether they are italicized or not. This provides a clear and direct action for the authors to take, ensuring that the terms are consistently defined and styled throughout the paper. The comment is specific and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in the definition and styling of the terms \"L\" and \"E.\" This provides clear guidance on how to improve the consistency and clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the inconsistency in the definition and styling of the terms \"L\" and \"E\" in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the clarity or readability of the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formatting and consistency of the terms \"L\" and \"E\" in the paper. It points out that these terms are sometimes italicized and sometimes not, which can lead to confusion and inconsistency in the document. This feedback is clear and actionable, as it provides the authors with a concrete step to improve the clarity and consistency of their work. By addressing this issue, the authors can enhance the readability and professionalism of their paper. However, the comment could be more helpful if it suggested a standard or convention for consistently formatting these terms throughout the document. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the experimental section is weak and suggests that more experiments are required. However, it does not provide specific guidance on what additional experiments should be conducted or how they should be structured. The authors are left to infer that they need to expand their experimental section, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental section is weak and needs more experiments. However, it does not specify which part of the experimental section is considered weak or what specific experiments are needed. Without explicit references to sections, figures, or experiments, the authors cannot confidently determine which parts of the paper need improvement. The comment lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experimental section is weak and suggests that more experiments are required. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a weakness in the experimental section, suggesting that more experiments are required. However, it lacks specificity and does not provide any guidance on what additional experiments should be conducted or how they could enhance the paper. Without specific suggestions or examples, the authors are left without actionable feedback on how to improve their experimental section. Therefore, the comment is not helpful, as it does not provide the authors with a clear path to address the identified weakness.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the manuscript should include more extensive comparisons with a wider range of models and parameter-efficient fine-tuning techniques beyond LoRA and SPP. While the comment implies that additional comparisons are needed, it does not specify which models or techniques should be included or how to conduct these comparisons. The action is implicit and somewhat vague, as the authors can infer that they need to expand their comparisons but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameter-efficient fine-tuning techniques beyond LoRA and SPP. However, it does not specify which parts of the paper should include these comparisons or which models or techniques should be included. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these comparisons could be added, the comment lacks specificity in detailing what needs to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameter-efficient fine-tuning techniques beyond LoRA and SPP. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these comparisons are necessary or how they would enhance the manuscript. Without such evidence or justification, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameter-efficient fine-tuning techniques beyond LoRA and SPP. This feedback is somewhat helpful as it identifies an area where the manuscript could be strengthened by expanding its comparisons. However, the comment lacks specificity and does not provide guidance on which models or techniques should be included or how to conduct these comparisons. While it points out a potential improvement, the lack of detailed suggestions limits its usefulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies four specific errors in the text, including incorrect grammar and spelling. It provides explicit corrections for each error, such as \"Despite being compact\" and \"We refer to multiway arrays.\" Additionally, it points out that \"HPFN to a even deeper ConAC\" should be corrected to \"HPFN to an even deeper ConAC.\" The reviewer also notes that \"Effect of the modelling mixed temporal-modality features\" is not grammatically correct and is unclear. These corrections are direct and concrete, providing the authors with clear guidance on how to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific corrections to errors in the text, such as incorrect grammar and spelling. It explicitly mentions lines 2, 56, 158, and 265, allowing the authors to accurately identify the parts of the paper being addressed. Each correction is clearly specified, providing full grounding. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of corrections to errors in grammar and spelling, which are factual statements. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific errors in the text, such as incorrect grammar and spelling, and provides clear and actionable corrections. It also points out that the phrasing \"Effect of the modelling mixed temporal-modality features\" is not grammatically correct and is unclear. This feedback is valuable as it helps the authors improve the clarity and accuracy of their writing, which is essential for effective communication of their ideas. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or coherence of the text beyond these specific corrections. Overall, the comment is mostly helpful as it provides actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the inversion of matrix determination or the division of the number of samples is being referred to in the context of the equations. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address it. The action is implicit, as the authors need to infer that they should clarify the context of the equations, but it is vague because it does not specify how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W4\" and \"Eqs.,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the inversion of matrix determination or the division of the number of samples is being referred to in the context of the equations. This provides clear guidance on what needs to be clarified. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the context of the equations. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the context of the equations, specifically whether the inversion of matrix determination or the division of the number of samples is being referred to. This is a clear indication of a potential confusion in the paper that could impact the clarity and understanding of the results. However, the comment does not provide any suggestions or guidance on how the authors might clarify this issue or improve the clarity of the equations. While it identifies a potential problem, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to make the work more innovative or differentiate it from existing work. As a result, the authors are left without any clear direction on how to enhance their draft based on this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this assessment is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the model extension are considered incremental or straightforward. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assessment and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any specific feedback or suggestions on how the authors might address this issue or improve their work. Without actionable guidance or constructive criticism, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While the comment implies that the authors should conduct a comparison between the two designs, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison between sequential and combinational designs, but without explicit references to sections or figures, the authors may struggle to identify where this information should be included. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the method may perform better in combinational logic. The comment lacks specific details or examples to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While it identifies a potential area for improvement, it lacks specificity and actionable guidance. The comment does not provide details on how to conduct the comparison or what specific aspects to focus on, leaving the authors with a general suggestion that requires further exploration. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not offer detailed guidance or suggestions for implementation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a discussion of the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While the comment implies that the authors should include this analysis, it does not explicitly instruct them to do so. The action is concrete, as it specifies the metric to be analyzed and provides a clear direction for improvement, but it is somewhat vague because it does not provide detailed guidance on how to conduct the analysis or what specific aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This provides clear guidance on what aspect of the experiment needs further analysis or discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline combining LDA and LSTM (LDA+LSTM) can capture sequential information and provide topic assignment for each word. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it relates to the experiment section. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that could be improved by discussing the performance of a baseline combining LDA and LSTM (LDA+LSTM) in terms of the topic switch percent metric. This feedback is clear and actionable, as it prompts the authors to include a discussion of the baseline's performance in their experiment section. However, the comment could be more helpful if it provided additional context or suggestions on how to interpret or analyze the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the motivation for the task and questions the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide more information about the motivation and potential applications of their work, but the comment lacks concrete suggestions on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not offer specific steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the clarity of the motivation for the task and questions the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the motivation and potential applications of the work, as well as the handling of uncertainty in predictions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it lacks specific examples, references, or detailed reasoning to support the claim that the motivation is unclear or that the task is difficult to predict. This makes the claim somewhat verifiable, as the authors would need to further develop the reasoning and evidence to fully address the reviewer\\'s concerns.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the motivation for the task, which is the difficulty in predicting the state of an object when it is occluded. It questions the potential downstream applications or benefits of amodal tracking and how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out areas for clarification and potential enhancements, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include experiments with GPT-3.5, which is a more affordable option than GPT-4, to provide a more comprehensive evaluation of their proposed approach. This feedback is explicit and provides a clear action for the authors to take, which is to include experiments with GPT-3.5. The comment is concrete because it specifies the exact change needed to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including experiments with GPT-3.5, which is a more affordable option than GPT-4, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of the proposed approach. The authors can infer that it relates to the experimental setup or evaluation, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a change to include GPT-3.5. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include experiments with GPT-3.5, which is a more affordable option than GPT-4, to provide a more comprehensive evaluation of their proposed approach. However, the comment does not provide any supporting evidence or reasoning to justify why GPT-3.5 is a better option or why it would provide a more comprehensive evaluation. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include experiments with GPT-3.5, which is a more affordable option than GPT-4, to provide a more comprehensive evaluation of their proposed approach. This feedback is clear and actionable, as it directly advises the authors to include a more cost-effective option in their experiments. By doing so, the authors can enhance the scope and depth of their evaluation, which is valuable for improving the draft. However, the comment could be more helpful if it provided additional context or justification for why GPT-3.5 is a better choice than GPT-4. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include bold numbers for the baselines of previous work, specifically for WMT17-WIKT, where the best result in terms of BLEU is in the baselines. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what to add, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of bold numbers for the baselines of previous work, particularly for WMT17-WIKT where the best result in terms of BLEU is in the baselines. This provides clear guidance on what needs to be added to the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 4 should include bold numbers for the baselines of previous work, specifically for WMT17-WIKT, where the best result in terms of BLEU is in the baselines. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific issue with Table 4, suggesting that bold numbers should be included for the baselines of previous work, particularly for WMT17-WIKT where the best result in terms of BLEU is in the baselines. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of the data. However, the comment could be more helpful if it explained why this change is important or how it would enhance the clarity or impact of the table. Overall, the comment is valuable for guiding the authors in making a specific improvement to their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. This request is clear and direct, providing the authors with a specific action to take by asking for examples. The comment is concrete because it specifies the exact part of the paper where the examples should be provided, making it easy for the authors to understand and implement the action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 170 to 171,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for examples of \"unreliable neighbors\" mentioned in those lines. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a normal statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area in the paper where examples of \"unreliable neighbors\" are mentioned. By asking for examples, the reviewer prompts the authors to provide more detailed explanations or examples to support their claims. However, the comment could be more helpful if it offered suggestions on how to present these examples or what specific aspects to focus on. While it provides a clear direction for improvement, it lacks depth and could be more actionable with additional guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of support for the claim about the synergies between DQD and PPO, specifically noting the absence of mention of the TD3GA algorithm in the main paper. It also suggests that the comparison to TD3GA should be central to the paper. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include a discussion of TD3GA and its relevance to the synergies between DQD and PPO. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement the suggested changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the synergies between DQD and PPO, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the TD3GA algorithm and the importance of comparing it to TD3. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the synergies between DQD and PPO are insufficiently supported, specifically mentioning the absence of the TD3GA algorithm in the main paper. The reviewer suggests that the comparison to TD3GA should be central to understanding these synergies. This claim is somewhat verifiable as it highlights a gap in the paper\\'s discussion and provides a specific suggestion for improvement. However, the comment lacks detailed reasoning or references to support the importance of including TD3GA or the centrality of the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the paper. This feedback is clear and actionable, as it points out a gap in the paper\\'s discussion and provides a specific direction for improvement. By addressing these points, the authors can enhance the clarity and robustness of their claims. However, the comment could be more helpful if it offered additional guidance on how to integrate the TD3GA algorithm or the comparison to TD3GA into the paper. Overall, the comment is mostly helpful as it effectively directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to explain why the tree-sliced Wasserstein distance outperforms the original optimal transport distance, as observed in Sections 6.1 and 6.2. This request is clear and provides a specific action for the authors to take, which is to provide an explanation for this observation. The comment is concrete in its request for clarification, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for an explanation of why the tree-sliced Wasserstein distance outperforms the original optimal transport distance, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the observation that the tree-sliced Wasserstein distance outperforms the original optimal transport distance, suggesting that an explanation is needed. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific observation in the paper regarding the tree-sliced Wasserstein distance outperforming the original optimal transport distance. It asks the authors to explain this observation, which is a clear and actionable request for further clarification. By prompting the authors to provide an explanation, the comment helps guide them in understanding and potentially resolving a potential issue or misunderstanding in their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address this observation. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the word \"confident\" in the sentence is unclear and suggests rephrasing it to clarify whether it pertains to model confidence or human interpretability. While the comment implies that the authors should rephrase the sentence to improve clarity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should revise the sentence to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence containing the word \"confident,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, suggesting that the word \"confident\" should be rephrased to clarify whether it pertains to model confidence or human interpretability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the word \"confident\" in the sentence, suggesting that it may refer to model confidence or human interpretability. The reviewer provides a logical reasoning by questioning the word choice, which is a common practice in academic writing. However, the comment lacks specific examples or references to support the claim that the word is unclear or misleading. While the reasoning is sound, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the word \"confident\" in the sentence, suggesting that it may be unclear whether it pertains to model confidence or human interpretability. While the comment highlights a potential source of confusion, it does not provide specific suggestions for rephrasing the sentence to improve clarity. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks actionable guidance on how to address the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the practicality of the proposed method, which relies on known causal relationships between features. It acknowledges that prior knowledge might not always be available or accurate for specific subpopulations, which is why researchers often focus on mining causal relationships from data automatically. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern or improve their draft. It lacks guidance on how to address the practicality issue or suggestions for improving the methodology. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s proposal to use known causal relationships between features, noting that prior knowledge might not always be available or accurate for specific subpopulations. It highlights the practicality concern and suggests that researchers focus on mining causal relationships from data automatically. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the practicality of the proposed method, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method relies on known causal relationships between features, which might not always be available or accurate for specific subpopulations. The reviewer supports this claim by noting that most researchers focus on mining causal relationships from data automatically. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable, as it requires more robust evidence to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s proposal, noting that it relies on known causal relationships between features, which might not always be available or accurate for specific subpopulations. It highlights the practicality concern and suggests that researchers focus on mining causal relationships from data automatically. While the comment points out a relevant issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their methodology. The feedback is somewhat helpful as it provides insight into a potential weakness but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of polishing in figures and empirical results, which affects clarity and confidence in empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on small-scale datasets and a single architecture type. However, the comment does not explicitly instruct the authors on how to address these issues or provide guidance on how to improve the clarity and polish of the figures and results. While the actions are implied, they are not stated directly, making the comment somewhat actionable. The authors can infer that they need to improve the clarity and polish of their figures and results, but the lack of concrete guidance makes it somewhat challenging to implement the suggested improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific issues with the figures and empirical results, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the lack of polishing in figures and empirical results, including missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on small-scale datasets and a single architecture type. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks polishing in figures and empirical results, which affects clarity and confidence in empirical findings. The comment provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on small-scale datasets and a single architecture type. These examples provide a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have addressed these issues. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity and confidence in the empirical findings of the paper. It points out specific problems, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on small-scale datasets and a single architecture type. These observations highlight areas where the paper could be improved in terms of polish and clarity. However, the comment does not provide detailed guidance on how to address these issues or suggest specific improvements. While it highlights the problem, it lacks actionable advice or suggestions for improvement, making it somewhat helpful. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of task-specific fine-tuning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the novelty of their work. There is no guidance on how to enhance the generalizability of the findings or suggestions for further exploration. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the work, specifically noting that the findings are expected due to task-specific fine-tuning. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the novelty, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the work is limited due to the expected outcome of task-specific fine-tuning. However, it does not provide any supporting evidence or reasoning to substantiate this claim. The comment lacks specific examples or references to similar studies or observations that would help the authors understand the basis of the critique. As a result, the claim is not verifiable, making it difficult for the authors to address the feedback effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of task-specific fine-tuning. It suggests that the novelty is expected given the general trend of task-specific fine-tuning increasing confidence for specific tasks while potentially reducing generalizability. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the generalizability of their findings. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper's case. It explicitly states that this would further test the conjecture and provide valuable insights, even if the phenomenon weakens in this setting. The comment is clear and provides a direct action for the authors to take, which is to include these numbers in their report. The action is concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, which would further test the conjecture. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting that reporting these numbers would strengthen the case, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\\'s case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this additional information would be beneficial or how it would impact the paper\\'s conclusions. Without such justification, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\\'s case. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper by including additional data that could further test the conjecture. The comment acknowledges the potential weakening of the phenomenon in this setting but emphasizes the importance of including the numbers to enhance the paper\\'s robustness. This guidance is valuable as it offers a concrete way for the authors to improve their draft, making the comment mostly helpful. However, it could be more helpful if it provided more detailed reasoning or examples of how this additional data could be incorporated into the paper. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. It implies that the authors should provide additional feedback to explain this choice and potentially justify it. However, the comment does not explicitly instruct the authors to provide this feedback or specify what additional information should be included. While the action is implied, it is not concrete, as the authors are left to infer what specific details or justifications are needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this metric is discussed. The authors can infer that it relates to the discussion of metrics or experimental results, but this inference is not direct. The comment is specific in its question about the choice of metrics, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of weight updates is a better metric. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to substantiate the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the choice of metrics used in the paper, specifically questioning the rationale behind using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. This is a relevant point that could lead to a deeper understanding of the paper\\'s methodology and its implications. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential weakness, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the objective should be clarified. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the objective, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification, which is factual in nature. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. This is a relevant point that could help the authors clarify their methodology and provide a more comprehensive understanding of their approach. However, the comment lacks specific guidance or suggestions on how the authors might address this question or what aspects of the objective should be clarified. While it identifies an area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the evaluation section of the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of in-content examples used, and the limited exploration of varying the number of In-Context Examples. It also points out that the evaluation relies solely on one dataset, which may limit the generalizability of the results. The comment provides explicit actions for the authors to take, such as including more details on the experiment setup and exploring different datasets. The suggestions are concrete and provide clear guidance on how to improve the evaluation section. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"experiment setup,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the number of different sets of in-content examples used and the limited exploration of varying the number of In-Context Examples. The comment also points out that the evaluation relies solely on one dataset, which may limit the generalizability of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in the paper is not comprehensive and lacks transparency regarding the experiment setup. It specifically mentions the absence of information on the number of different sets of in-content examples used and the limited exploration of varying the number of In-Context Examples. The comment also highlights the reliance on a single dataset, which may limit the generalizability of the results. The claim is supported by logical reasoning and specific examples, making it mostly verifiable. However, it could be strengthened by providing more detailed evidence or references to similar studies that demonstrate the importance of these aspects. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several critical issues with the evaluation section of the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of in-content examples used, and the limited exploration of varying the number of In-Context Examples. It also points out that the evaluation relies solely on one dataset, which may limit the generalizability of the results. These are all important areas for improvement, and the comment provides clear and actionable suggestions for the authors to address these issues. By highlighting the need for more comprehensive and transparent evaluation, the comment offers valuable guidance for enhancing the paper\\'s rigor and applicability. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the contrastive learning framework used in the paper is the same as SimCLR, which is a direct observation. However, it does not provide any guidance or suggestions on how the authors should address this observation or what changes they should make to their framework. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the contrastive learning framework used in the paper is the same as SimCLR, but it does not specify which part of the paper this observation is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the comparison to SimCLR. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the contrastive learning framework used in the paper is the same as SimCLR, which could be a potential issue or a point of comparison. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this observation or differentiate their work from SimCLR. Without actionable feedback or constructive advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that there is a lack of comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. It suggests that these comparisons could showcase the unique advantages or potential shortcomings of the proposed method in a broader context. This feedback provides a clear and concrete action for the authors to take, as it specifies exactly what comparisons are needed and why they are important. The authors know exactly what to add to their draft to improve it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is somewhat verifiable as it suggests that these comparisons could provide a broader context for the proposed method. However, the comment lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback suggests that such comparisons could provide a broader context for the proposed method and highlight its unique advantages or potential shortcomings. By suggesting these comparisons, the comment offers a clear and actionable suggestion for the authors to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided specific examples or references to similar comparative experiments in the literature. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so or provide guidance on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include these references. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not specify which part of the paper should include this additional attention or how it should be integrated. The authors can infer that it relates to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of the references to include, but it is not grounded in the context of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, the comment does not provide any reasoning or explanation as to why these references are relevant or how they could enhance the paper. Without additional context or justification, the claim lacks verifiability, as it does not provide sufficient evidence or guidance for the authors to understand and address the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While this feedback identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how the authors should integrate these references into their work or what aspects of the related work are most relevant to their study. The comment is somewhat helpful as it points out a potential gap in the literature review, but it does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of a comparison against existing text GANs, specifically mentioning that many of them have open-source implementations. It also notes that SeqGAN is mentioned but not tested with the pretrained version. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they should include comparisons with existing text GANs and test SeqGAN with the pretrained version, but the comment lacks specific guidance on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of comparisons against existing text GANs and the mention of SeqGAN, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that SeqGAN is mentioned but not tested with the pretrained version. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is no comparison against existing text GANs, specifically mentioning that many of them have open-source implementations. It also notes that SeqGAN is mentioned but not tested with the pretrained version. However, the comment lacks specific examples or references to existing text GANs that could be compared to, making it somewhat verifiable. The authors would need to infer the specific GANs to compare against and determine the relevance of testing SeqGAN with a pretrained version. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of comparisons against existing text GANs, many of which have open-source implementations. It also points out that SeqGAN is mentioned but not tested with the pretrained version. This feedback is clear and actionable, as it highlights specific areas where the paper could be strengthened by including comparisons and testing with existing models. However, the comment could be more helpful if it provided examples of specific GANs to compare against or suggested ways to test SeqGAN with pretrained models. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. While the comment implies that the paper lacks depth in this area, it does not provide specific guidance on how to address this issue or what aspects of the algorithmic aspects should be covered. The action is implicit and somewhat vague, as the authors can infer that they need to expand on the algorithmic aspects but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. However, it does not specify which part of the paper this suggestion pertains to, such as the sections discussing the algorithmic aspects or the introduction of the Blackwell winner. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithmic aspects should be addressed or how they should be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This claim is based on the observation that the novelty of the paper seems limited after this introduction. However, the comment lacks specific examples or detailed reasoning to support why the algorithmic aspects are crucial or how they could enhance the paper\\'s contribution. Without concrete evidence or references, the claim is somewhat verifiable, as it provides a logical basis but lacks the necessary depth to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting that the paper could provide more depth on the algorithmic aspects. However, the comment lacks specific guidance on which algorithmic aspects should be addressed or how they could be integrated into the paper. Additionally, it does not provide examples or detailed suggestions on how to enhance the algorithmic sections, which would make the feedback more actionable. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that Table 4 and 5 should be split into two tables each, with one table per measure. This provides a clear and concrete action for the authors to take, as it specifies the exact change needed to improve the readability of the tables. The suggestion is specific and actionable, leaving no ambiguity about what the authors should do to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of the tables by splitting them into two tables each, with one table per measure. This gives the authors a clear idea of what needs to be addressed to improve the clarity of the tables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that splitting tables 4 and 5 into two tables each would improve their readability. This claim is based on a logical reasoning that splitting the tables would make it easier to follow the data presentation. However, the comment does not provide specific examples or references to support this claim, such as how other papers or studies have successfully implemented this structure. While the suggestion is logical, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5 by splitting them into two tables each, with one table per measure. This is a clear and constructive piece of feedback that can help the authors enhance the clarity and organization of their data presentation. By following this suggestion, the authors can make their tables more intuitive and easier to navigate, which is a valuable improvement for the overall readability of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that it would be helpful to specify what \"valid\" and \"orig\" differ in, as presented in Fig. 5. This is a direct and concrete action for the authors to take, as it clearly identifies the specific information that needs to be clarified. The comment provides a clear and specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of \"valid\" and \"orig\" in the context of Fig. 5. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it would be helpful to specify what \"valid\" and \"orig\" differ in, as presented in Fig. 5. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the understanding of the figure. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Fig. 5, noting that it would be helpful to specify what \"valid\" and \"orig\" differ in. This feedback is clear and actionable, as it directly points out a gap in the figure\\'s explanation that the authors can address to improve the clarity. By providing a specific suggestion for improvement, the comment offers valuable guidance for enhancing the draft. However, it could be more helpful if it included additional context or examples to further explain the importance of clarifying these terms. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by making the comparisons with the most closely related work more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and concrete action for the authors to take. The comment is explicit in its suggestion and offers a specific improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"most closely related work of Zemel et al. (2013)\" and the present paper, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely making comparisons more systematic with respect to the tuning of each method. This provides clear guidance on how to enhance the originality and comparative analysis of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper could be improved by making comparisons with the most closely related work more systematic, specifically by comparing the best performance of each method. The comment provides a logical reasoning by suggesting that such comparisons would enhance the originality and depth of the paper. However, it lacks specific examples or references to the Zemel et al. (2013) work, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the comparisons with the most closely related work. It suggests that the paper could be strengthened by making these comparisons more systematic, particularly by comparing the best performance of each method. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the originality and depth of the paper. By addressing this point, the authors can significantly improve the comprehensiveness and rigor of their comparative analysis. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to loss-based sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. While the comment implies that the authors should consider including such a comparison, it does not provide specific guidance on which method to compare or how to adapt it to language tasks. The action is implicit and somewhat vague, as the authors need to infer the specific method and adaptation steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a comparison to one of the methods mentioned in the computer vision setting, rather than loss-based sampling, which is currently being used. However, it does not specify which method from the computer vision setting should be compared, nor does it provide details on how this comparison would be beneficial or what specific aspects of the computer vision methods could be applied to language tasks. This lack of specificity and grounding makes it difficult for the authors to understand exactly what needs to be addressed or improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to loss-based sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors would need to infer the specific methods and adaptations themselves, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to loss-based sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. This feedback is somewhat helpful as it provides a specific suggestion for improving the draft by including a comparison that could enhance the paper\\'s contribution. However, the comment could be more helpful if it included specific examples of methods that could be adapted or how they could be applied to language tasks. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explicitly estimate the time complexity of the learning algorithm to prove its scalability properties. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion for how to enhance the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the need to estimate the time complexity of the learning algorithm to prove its scalability properties, which provides full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be addressed, namely the estimation of time complexity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper\\'s conclusions. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This is a clear and actionable suggestion that can help the authors strengthen their claims about the algorithm\\'s performance. By addressing this point, the authors can provide more robust evidence to support their conclusions. However, the comment could be more helpful if it included examples or guidance on how to estimate the time complexity effectively. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there may be a connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, it does not provide explicit instructions or guidance on how the authors should explore this connection or what specific aspects of the universal kernel properties should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should explore the connection between their work and universal kernels. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a connection to properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann, which discusses the ability of universal kernels to separate an arbitrary finite data set with margin arbitrarily close to one. This provides clear guidance on what aspect of the paper needs attention. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a potential connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, the comment does not provide any detailed reasoning or evidence to support this claim. It lacks specific examples or references to the relevant sections of Steinwart and Christmann, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is not verifiable, as it does not provide sufficient justification or context for the authors to address it effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a potential connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. This is a valuable suggestion that could lead to a deeper understanding of the topic and potentially enhance the paper\\'s contribution. However, the comment lacks specific guidance on how to explore this connection or what aspects of the universal kernel properties should be considered. While it points to a relevant reference, it does not provide detailed instructions or examples on how to integrate this information into the paper. Therefore, the comment is somewhat helpful, as it offers a direction for further exploration but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit suggestions for how the authors should improve the discussion or clarify the explanation. Without guidance on what specific aspects need attention or how to address the issue, the authors are left without actionable steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the discussion around equation (10) is terse and not clearly explained. This provides full grounding and specificity, as the authors can accurately identify the part of the paper being addressed and what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is somewhat helpful as it points out a potential weakness in the paper, but it lacks depth and does not provide suggestions on how to improve the discussion or clarify the explanation. While it highlights an area for improvement, the comment could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
