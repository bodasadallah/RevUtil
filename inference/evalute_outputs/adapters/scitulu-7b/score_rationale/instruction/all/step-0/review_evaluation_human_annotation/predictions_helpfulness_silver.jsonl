{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more analysis around the quality of the collected dataset and the potential noise it might contain. While it implies that the authors should conduct additional analysis, it does not specify what kind of analysis is needed or how to conduct it. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the artificially created dataset and its potential noise, specifically mentioning the \"pristine\" set of tweets and outofcontext images. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that more analysis is needed around the quality of the dataset and the amount of noise it might have. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the dataset might have noise due to the artificial creation process, and it provides a specific example of the \"pristine\" set of tweets that might contain misinformation or outofcontext images. However, the comment lacks detailed evidence or references to support this claim, such as specific examples of misinformation or outofcontext images. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset, suggesting that it might contain noise due to its artificial creation process. It provides a specific example of the \"pristine\" set of tweets that might not be pristine enough and could contain misinformation or outofcontext images. This feedback is valuable as it highlights a potential weakness in the dataset that the authors should address. However, the comment could be more helpful if it suggested specific analyses or methods to evaluate the dataset\"s quality and noise level. Overall, the comment is 4 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific theoretical aspects to explore or methods to demonstrate convergence. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where these aspects should be addressed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the theory profs or convergence properties should be explored or demonstrated. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. This feedback is clear and actionable, as it points out a critical area where the paper could be strengthened by providing more theoretical analysis and experimental evidence. However, the comment could be more helpful if it offered specific suggestions on how to address this gap, such as which theoretical aspects to explore or how to demonstrate convergence. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification or explanation for their choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the selection of 10 answers from all correct answers, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on whether this selection affects the underestimation of performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the selection of 10 answers from all correct answers and its potential impact on performance underestimation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. This is a relevant question that could prompt the authors to reconsider their methodology or provide additional context to explain their choice. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and asks for a supporting explanation. It does not provide explicit instructions or suggestions for the authors to follow, but it implies that the authors should clarify the purpose of the reported duration and potentially include information about the time spent by the user waiting for the model to generate a response. While the action is implied, it is clear and concrete, as it guides the authors to provide a more detailed explanation or clarification in their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in Table 1 and requests a supporting explanation, including whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and requests a supporting explanation. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification and does not present an argument or claim that needs justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the purpose of the average duration reported in Table 1, noting the lack of a supporting explanation. It highlights an area where the authors could provide more clarity and context for their readers. By asking for a clearer explanation, the comment prompts the authors to consider how their readers might interpret the reported duration and whether it includes time spent by the user waiting for the model to generate a response. This feedback is 3 as it identifies a potential gap in the paper that could be addressed to enhance its clarity and comprehensibility. However, it could be more helpful if it offered specific suggestions on how to provide the requested explanation or what additional context might be beneficial. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests clarification on the splits used for obtaining the ATIS numbers in Table 4. This is a direct and concrete action for the authors to take, as it clearly identifies the specific area that needs clarification. The comment also expresses gratitude for the authors\" response, which implies that the authors have already addressed this issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the splits used for obtaining the ATIS numbers. This provides clear guidance on what the authors need to address to improve the clarity of their work. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point requests clarification on the splits used for obtaining the ATIS numbers in Table 4. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of clarity needed in the paper, specifically regarding the splits used for obtaining the ATIS numbers in Table 4. By asking for clarification, the reviewer provides actionable feedback that can help the authors improve the transparency and understandability of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 3 as it directs the authors to a clear area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a formatting issue in Tables 2 and 3, specifically noting the inconsistent spacing between accuracy and standard deviation. This is an explicit observation that the authors can directly address by ensuring consistent spacing in their tables. The comment provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation in these tables, which affects the presentation\"s aesthetics. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that inconsistent spacing between accuracy and standard deviation in Tables 2 and 3 affects the presentation\"s aesthetics. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific formatting issue in Tables 2 and 3, noting inconsistent spacing between accuracy and standard deviation. This is a clear and actionable observation that the authors can address to improve the presentation of their data. By pointing out this inconsistency, the comment provides valuable feedback that can help the authors enhance the aesthetics and readability of their tables. However, the comment could be more helpful if it offered suggestions on how to standardize the spacing or provided examples of how other tables in the field handle this issue. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the novelty or what specific aspects of the paper could be revised to enhance its originality. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a lack of novelty in the paper, specifically mentioning that adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered a lack of novelty, namely the application of similar ideas to videotext models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, specifically mentioning that adversarial attacks on text have been done on many NLP and imagetext models. It further notes that the paper summarizes this work and only adds a new effort by applying similar ideas to videotext models. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to substantiate the claim fully. The authors might need to infer the extent of novelty in their work based on this comment, which could be improved with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and imagetext models. It highlights that the paper summarizes this work and only adds a new effort by applying similar ideas to videotext models. While the comment points out a potential issue with the paper\"s originality, it does not provide specific suggestions or guidance on how the authors might address this lack of novelty or enhance the originality of their work. The feedback is 3 as it alerts the authors to a potential weakness, but it lacks actionable advice or detailed insights to fully support the authors in improving their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It provides a clear and concrete suggestion to improve the organization of the section by recommending separate paragraphs for lexical features and sentencelevel features. This explicit guidance offers a direct action for the authors to take, making the comment 5. Authors know exactly what changes to make to improve the clarity and coherence of their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the intertwined explanations for features and the suggestion to organize the section with separate paragraphs for lexical features and sentencelevel features. This provides clear guidance on how to improve the clarity and coherence of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It suggests that the section would be more coherent with separate paragraphs for lexical features and sentencelevel features. While the comment provides a logical reasoning for the suggested improvement, it lacks specific examples or references to support the claim that the current organization is confusing. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization and clarity of the explanations for features in Section 3.2. It suggests that the section would be more coherent and easier to understand with separate paragraphs dedicated to lexical features and sentencelevel features. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the organization and readability of their draft. By following this advice, the authors can enhance the clarity and comprehensibility of their explanations, which is valuable for improving the overall quality of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a more concise presentation or offering suggestions for prioritizing content. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not specify which section or part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the assumptions or experimental results are problematic or how they could be improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that dedicating a whole section and experimental results for the assumptions is a significant amount of space. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it could be improved. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not provide any specific guidance or suggestions on how the authors might address this issue, such as by streamlining the content or focusing on the most important aspects. The comment lacks actionable feedback, leaving the authors without a clear path forward to improve their draft. Therefore, it is rated as 2, as it identifies a potential issue but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the abstract could be improved by providing an example of the inconsistency between evaluating with gold answers and human evaluation. While the comment implies that the authors should include this example, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include an example to make the abstract more effective. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved: adding an example of the inconsistency between evaluating with gold answers and human evaluation. This specificity helps the authors understand the issue and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the abstract is wellwritten and invokes intrigue, but it also provides a suggestion for improvement. The reviewer suggests that including an example of the inconsistency between evaluating with gold answers and human evaluation could enhance the abstract further. However, the comment lacks specific examples or references to support the claim that including such an example would indeed improve the abstract. While the suggestion is logical, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the abstract is wellwritten and invokes intrigue, which is a positive observation. It also provides a specific suggestion for improvement by recommending the inclusion of an example to illustrate the inconsistency between evaluating with gold answers and human evaluation. This feedback is actionable and constructive, as it guides the authors on how to enhance their abstract to better convey the significance of their work. However, the comment could be more helpful if it provided a specific example of the inconsistency or suggested how to present it effectively. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This provides a clear and direct action for the authors to take, which is to include these discussions in their draft. The comment is specific and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"joint learning process\" for RNN and CopyRNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the convergence of the proposed joint learning process and how stable points in the probabilistic metric space are obtained. This provides clear guidance on what the authors need to clarify or expand upon in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This claim is 3 as it logically suggests that understanding the convergence process is crucial for reproducing results. However, the comment lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully grasp the importance of this discussion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that discussions on the convergence of the proposed joint learning process are required. This feedback is clear and actionable, as it directs the authors to provide more detailed information on how the stable points in the probabilistic metric space are obtained. By addressing this point, the authors can enhance the clarity and reproducibility of their results. However, the comment could be more helpful if it provided examples or references to similar discussions in related literature, which would further guide the authors in developing their analysis. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). Additionally, it mentions that it would be better to use the same terminology for the model in Tables 1 and 2. While the comment provides explicit actions to take, it does not offer concrete guidance on how to implement these suggestions. The authors are given a clear direction but lack detailed instructions on how to execute these tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, \"681\" and \"778,\" allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed, namely the discussion of results for the task of inferring knowledge on objects and the inclusion of results for model (B) in Tables 1 and 2. Additionally, it points out a potential inconsistency in terminology and suggests using the same terminology for the model in Tables 1 and 2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). It also mentions that it would be better to use the same terminology for the model in Tables 1 and 2. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that using the same terminology would be beneficial. The absence of detailed justification or evidence makes the claim 3, as the authors would need to make a concerted effort to understand and implement the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors discuss the results for the task of inferring knowledge on objects and include results for model (B) in Tables 1 and 2. It also points out a potential inconsistency in terminology by suggesting that the same terminology be used for the model in Tables 1 and 2. This feedback is clear and offers a concrete direction for improvement, making it 5 for the authors to enhance the clarity and completeness of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific sentence in line 212 that is not correct and suggests a correction. It provides a clear and explicit action for the authors to make the sentence more accurate by suggesting that they should say they do a bidirectional encoder instead of a GRU. The comment also references Figure 2, which provides a concrete example of what the correct sentence should look like. This level of detail and specificity makes the action explicit and concrete, ensuring that the authors know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the sentence, suggesting a correction by proposing a more accurate description of the process. The comment provides a clear and detailed suggestion for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not correct and suggests a correction. The reviewer provides a specific example from Figure 2, which supports the claim by showing the correct way of encoding a source sentence into a set of vectors. This detailed explanation and reference to an external source provide robust evidence for the claim, making it 5. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the sentence in line 212, noting that it is not strictly correct. It suggests a correction by proposing that the authors should say they do a bidirectional encoder instead of a GRU. Additionally, the comment references Figure 2 to provide a concrete example of what the correct sentence should look like. This feedback is clear and actionable, as it guides the authors on how to improve the accuracy of their description. However, the comment could be more helpful if it explained why the current sentence is incorrect or how the suggested correction would improve the clarity of the paper. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment implies that the authors should consider including these baselines, it does not provide explicit instructions or detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should include additional baselines but may not be entirely sure which ones to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, it does not specify which part of the paper this extension or the baselines should be added to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional baselines, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension is necessary or how character embeddings would enhance the work. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to implement these additional baselines or why they are necessary. The suggestion is 3 as it points out a potential area for enhancement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the yaxis label in Figure 5 should use \"Exact Match ratio\" directly. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is 5 as it clearly instructs the authors on how to make a specific change to their figure, ensuring that they know exactly what needs to be done to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the yaxis label, and suggests changing it to \"Exact Match ratio.\" This provides clear guidance on how to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the yaxis label in Figure 5 should use \"Exact Match ratio\" directly. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of Figure 5 by recommending that the yaxis label be changed to \"Exact Match ratio.\" This feedback is clear and direct, offering a straightforward way for the authors to enhance the accuracy and readability of their figure. By addressing this point, the authors can improve the clarity and comprehensibility of their visual presentation, which is valuable for ensuring that their findings are effectively communicated. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to ensure that the knowledge bases are free from societal biases. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains but does not provide any context or explanation for this preference. Overall, the comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains, but this is not directly related to the issue of societal biases. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. While this is an important consideration, the comment lacks specificity and does not provide any actionable guidance or suggestions on how the authors might address this issue. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains, but this is not directly related to the main concern about societal biases. Overall, the comment identifies a potential area for improvement but does not offer detailed or constructive feedback, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that while it is easier to show that attention in seq2seq MTL is not working, the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks specific guidance on how to identify the reasons for the failure or how to modify the attention mechanism. As a result, the authors are left without a clear path forward, making this comment 1.", "grounding_specificity_rationale": "The comment suggests that it is easier to show that attention in seq2seq MTL is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to focus on identifying the reasons for the failure and modifying the attention mechanism, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is easier to show that attention in seq2seq MTL is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment highlights a common issue in research, where it is easier to show that something is not working but more challenging to identify the underlying reasons and make improvements. It suggests that the true value lies in finding out why the attention mechanism in seq2seq MTL is not working and changing it to make it work. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address the issue or what specific changes to the attention mechanism might be necessary. This limits the comment\"s helpfulness, as it provides insight but not actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Table 3 should include many strong baselines that are not currently compared in the paper. It explicitly asks the authors to justify the reason for not including these baselines. This feedback provides a clear and direct action for the authors to take, which is to include additional baselines and explain the rationale behind their exclusion. The comment is specific and provides concrete guidance on what needs to be done to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3\" and \"MCNC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that Table 3 should include many strong baselines that are not currently compared in the paper, and it asks for a justification of the reason for their exclusion. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 3 should include many strong baselines that are not currently compared in the paper. However, it does not provide any specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate why these baselines should be included or how they would enhance the analysis. As a result, the claim is not verifiable, as it does not provide sufficient justification or evidence to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the inclusion of strong baselines in Table 3. It suggests that the table should include many more baselines, specifically mentioning those from 1. This feedback is clear and actionable, as it provides a specific direction for the authors to consider expanding their analysis and comparison. By including these additional baselines, the authors could enhance the robustness and comprehensiveness of their evaluation. However, the comment could be more helpful if it provided further guidance on how to select and justify the inclusion of these baselines. Overall, the comment is 4 as it points out a specific area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper relies on supplemental space to contain the paper, which makes it not truly independent. It specifically mentions the reference to Supplementary Figure 6 in S3.1 and the model comparison and other details of the span vs. sentence investigation as examples of this reliance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the independence of the paper. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to independence but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as S3.1 and the model comparison, allowing the authors to accurately identify the parts being addressed. It also specifies the issue of reliance on supplemental space and the lack of independence in the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain the paper, which makes it not truly independent. It supports this claim by referencing specific sections, such as S3.1 and the model comparison, where the paper references supplementary figures and details of the span vs. sentence investigation. This provides a clear and specific basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it relies on supplemental space to contain the paper, which makes it not truly independent. It provides specific examples, such as the reference to Supplementary Figure 6 in S3.1 and the model comparison, to illustrate this reliance. This feedback is valuable as it highlights a critical weakness in the paper\"s independence, which the authors can address to improve the credibility and standalone nature of their work. However, the comment could be more helpful if it offered suggestions on how to mitigate this issue or what specific changes could be made to enhance the paper\"s independence. Overall, the comment is 4 as it provides clear and actionable feedback on a critical aspect of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to describe the traits of the experts and justify why annotation must be carried out by them, outside of its commercial value. It also asks specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. These questions provide clear guidance on what the authors need to address to improve their draft. The action is explicit and concrete, as it specifies exactly what needs to be added or clarified. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first point, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of the traits of the experts and the justification for why annotation must be carried out by them, outside of its commercial value. The comment also raises questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. This level of detail provides clear guidance on what the authors need to address to improve their draft, making the comment 5.", "verifiability_rationale": "The review point raises questions about the expertise of the annotators and the justification for why annotation must be carried out by them, outside of its commercial value. It suggests that the authors should provide more information about the traits of the experts and the linguistic challenges introduced by the annotation process. While the comment highlights areas for improvement, it lacks specific examples or references to support the claim that the annotation process introduces linguistic challenges. This makes the claim 3, as it provides a direction for improvement but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by asking the authors to describe the traits of the experts and justify why annotation must be carried out by them, outside of its commercial value. It raises specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. This feedback is valuable as it prompts the authors to clarify and substantiate their claims about the expertise and process involved in annotation. By addressing these points, the authors can enhance the transparency and credibility of their work. Therefore, the comment is 4, as it provides clear and actionable guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. While the action is implied, it is clear and provides a concrete direction for the authors to take. The comment explicitly states what the authors should do, which is to include examples of the system on actual texts. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including examples of the system on actual texts, rather than focusing on other components and models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where examples could be included. Without explicit references, the authors may struggle to identify the exact areas that need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The comment suggests including examples of the system on actual texts, rather than focusing on other components and models. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. This feedback is 3 as it points out a potential area for improvement in the paper, which could enhance the reader\"s understanding of the system\"s capabilities. However, the comment lacks specific guidance on how to implement this suggestion or what specific examples would be most effective. Without additional details or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper\"s claims would benefit from more indepth analysis. However, it does not provide specific examples of which claims need more analysis or what aspects of the claims should be explored further. The comment lacks concrete guidance on how to improve the analysis or what specific aspects to focus on. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that a number of claims from the paper would benefit from more indepth analysis, but it does not specify which claims or parts of the paper are being referred to. Without explicit references to sections, figures, or specific claims, the authors cannot confidently determine which parts of the paper need further analysis. Additionally, the comment lacks specificity regarding what aspects of the claims should be analyzed more deeply. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a number of claims from the paper would benefit from more indepth analysis. However, it does not provide any specific examples or reasoning to support why these claims need further examination. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a number of claims from the paper would benefit from more indepth analysis. However, it does not specify which claims or aspects of the paper need this additional analysis. Without specific guidance or examples, the authors are left without clear direction on how to improve their draft. The comment lacks actionable feedback and does not provide the authors with a concrete path to enhance the depth and rigor of their analysis. Therefore, it is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a discrepancy between the paper\"s claims and its actual content. It points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. The reviewer suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics. While the comment provides a clear direction for improvement, it lacks specific guidance on how to test the hypotheses or what aspects of the topics should be explored. The action is explicit but somewhat vague, as the authors know they need to address the hypotheses but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078086, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. The comment suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. The reviewer suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics. However, the comment lacks specific examples or references to support the claim that the hypotheses are not tested or discussed. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant discrepancy between the paper\"s claims and its actual content. It points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not follow through on testing or discussing them. This is considered misleading, as the authors may have led readers to expect a deeper exploration of these topics. The comment suggests that the hypotheses could be tested as given and that the paper should delve deeper into the respective topics, at least to some extent. While the feedback highlights an important area for improvement, it lacks specific guidance on how to address the issue or what aspects of the hypotheses should be explored. This limits the comment\"s usefulness, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential use of feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to achieve better results. While the comment implies that the authors should explore this possibility, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the same feature set from the cited work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the potential use of feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to achieve better results. However, the comment does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the experimental results or methodology, but this inference is not direct. The comment is specific in suggesting the use of a particular feature set, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using feature engineering could improve the performance of the paper, citing an example from Uto et al. (2020) where a QWK of 0.801 was achieved using a set of handcrafted features. This provides a logical basis for the claim, as it suggests that using similar features could potentially enhance the results of the current work. However, the comment lacks specific details on how the feature engineering could be implemented or which features from Uto et al. (2020) could be adapted. This makes the claim 3, as it provides a reasonable suggestion but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment raises a question about the potential use of feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to achieve better results. While the comment identifies a potential area for improvement, it lacks specific guidance on how to implement this suggestion or what aspects of the feature engineering process should be considered. The authors are given a direction to explore but are not provided with detailed steps or examples on how to effectively integrate this approach into their work. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully guide the authors on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and seeks clarification on its role in the evaluation process. It implies that the authors should provide more information about how the CS is used, whether it is used for augmenting the training material, and the data split used. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the CS. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Challenge Set\" (CS), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the CS is used, whether it is used for augmenting the training material, and the data split used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the use of the Challenge Set (CS) in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set (CS) in the paper, specifically inquiring about its role in evaluation and whether it is used for augmenting the training material. It also asks for clarification on the data split used. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential gap in the paper, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment raises concerns about the paper\"s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words. It also questions the use of constituent parse as knowledge and points out that the term \"knowledge\" may be misleading in this context. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to clarify the terminology. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the use of \"knowledge\" and the generalization of the model, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific concerns about the paper\"s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words and questioning the use of constituent parse as knowledge. It also points out that the term \"knowledge\" may be misleading in this context, as it is typically used to refer to external knowledge sources like a knowledge base of entities. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the use of \"knowledge\" and the generalization of the model, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words and questioning the use of constituent parse as knowledge. The reviewer also points out that the term \"knowledge\" may be misleading, as it is typically used to refer to external knowledge sources like a knowledge base of entities, whereas here it is used to describe syntax or semantics. The comment provides a logical reasoning and specific examples to support the claim that the term \"knowledge\" is misleading in this context. However, it could be strengthened by providing more detailed references or examples from the literature to further substantiate the critique. Overall, the comment is 4, as it provides a clear rationale and examples to support the claim, but it could be more fully substantiated with additional references or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also points out that the term \"knowledge\" may be misleading, as it is typically used to refer to external knowledge sources like a knowledge base of entities, whereas here it is used to describe syntax or semantics. This feedback is clear and actionable, as it provides the authors with a concrete direction for clarifying their terminology and improving the accuracy of their claims. By addressing these concerns, the authors can enhance the clarity and precision of their work, making the comment 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the performance of the TWSI model on nouns and questions the generalizability of the clustering approach to all parts of speech. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment implies that the authors should investigate the gap between the oracle GAP for PPDBClus and the performance of the clustering approach, but it does not specify how to conduct this investigation or what specific aspects to focus on. Additionally, it does not offer suggestions on how to improve the uniformity of the performance across all parts of speech. As a result, the comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the TWSI model on nouns and the contradiction with the claim of generalizability to all parts of speech. It mentions the oracle GAP for PPDBClus and the fact that the performance is not uniform, which directly contradicts the claim. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the concerns about the performance and the contradiction with the claim, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the performance of the TWSI model on nouns and questions the generalizability of the clustering approach to all parts of speech. It mentions the oracle GAP for PPDBClus and the fact that the performance is not uniform, which directly contradicts the claim that the clustering approach is generalizable. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration for the authors to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a concern about the performance of the TWSI model on nouns, which is a significant issue. It also questions the generalizability of the clustering approach to all parts of speech, given the performance gap between the oracle GAP for PPDBClus and the clustering approach. This feedback is valuable as it highlights a potential weakness in the paper that the authors should address. However, the comment could be more helpful if it provided specific suggestions on how to investigate or resolve these issues, such as recommending additional experiments or analyses. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It explicitly asks for examples of spurious structures to help clarify the discussion. This feedback is clear and provides a specific action for the authors to take, which is to provide examples of spurious structures to support their claims. The request for examples is concrete, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is that it is too abstract and does not provide insights into why the new model is better than MH. The comment also requests examples of spurious structures to help clarify the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. However, the comment lacks specific examples or references to support the claim that the discussion is abstract or unclear. Without additional context or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstractness of the discussion in Section 5.2, noting that it does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. While the comment highlights a clear area for improvement, it lacks depth and does not provide detailed guidance on how to address the issue or what specific examples of spurious structures might be relevant. This limits the comment\"s helpfulness, as it points out a problem but does not fully support the authors in resolving it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. The reviewer provides a specific suggestion for how to implement this baseline, which is to directly parameterize $H, I, J, K, L$ as learned matrices. While the comment provides a clear action, it lacks detailed guidance on how to implement this suggestion or what specific parameters should be adjusted. The authors are given a clear direction but may need to infer additional details to fully execute the action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this baseline could be added. The authors can infer that it relates to the PCFG model or the baseline comparison, but this inference is not direct. The comment is specific in detailing what needs to be added, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. The comment provides a logical reasoning for this suggestion, noting that this baseline could help compare perplexity but not parsing F1. However, the comment lacks specific examples or references to support the claim that this baseline would be beneficial or how it would affect the comparison. While the suggestion is logical, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. This suggestion is clear and actionable, as it offers a concrete way to address a potential issue with the comparison of PCFG models. By adding this baseline, the authors can better compare the performance of their model with other PCFGs. However, the comment could be more helpful if it provided additional context or justification for why this baseline is necessary or how it would enhance the paper\"s contribution. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is an explicit action that the authors can directly implement by adding a statement to their paper. The comment is clear and provides a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests adding a statement about the maximum number of tasks done by any annotator. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. Without explicit references, the authors cannot confidently determine the exact location of the suggestion in the paper. The comment is specific in suggesting what needs to be added, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should state the maximum number of tasks done by any annotator. However, it does not provide any supporting evidence, reasoning, or examples to justify why this information is important or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is a specific and actionable piece of feedback that can help the authors improve the transparency and reproducibility of their results. By including this information, the authors can provide a clearer understanding of the variability in task completion across annotators, which could be important for assessing the robustness of their findings. However, the comment could be more helpful if it explained why this information is important or how it might impact the interpretation of the results. Overall, the comment is 4 as it identifies a specific area for improvement but could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and direct action for the authors to take, as it provides a specific request for inclusion in the table. The comment is specific and concrete, giving the authors a clear idea of what to add to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to show the increase in performance of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the inclusion of the hard prompt baseline, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including the hard prompt baseline in Table 1 would provide insight into the increase in performance of each method. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this inclusion is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and actionable suggestion that could help the authors better present their results and provide a more comprehensive analysis. By including the hard prompt baseline, the authors can demonstrate the effectiveness of their methods and highlight the improvements achieved. However, the comment could be more helpful if it provided additional context or justification for why this inclusion is important or how it would enhance the analysis. Overall, the comment is 4 as it offers a specific and actionable suggestion for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. While it implies that the authors should include numerical results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include numerical results to address the reviewer\"s curiosity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the application to popular algorithms should be discussed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for numerical results and application to popular algorithms, but it is 1 as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of numerical results and expressing curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. This feedback is valuable as it highlights an area where the paper could be strengthened by including numerical results, which would provide more concrete evidence and support for the claims made. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these results or provided examples of how similar studies have been conducted. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on execution."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is explicit in its request for additional evidence, providing a clear action for the authors to take. However, it does not specify what kind of evidence would be sufficient or how to present it, leaving some room for interpretation. Therefore, the comment is 4, as it identifies a specific area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests providing empirical evidence to support the claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what kind of evidence would be sufficient. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this claim is made, the comment lacks full grounding. It is specific in its request for empirical evidence but lacks detailed guidance on how to present it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is clear and actionable, as it identifies a specific area where the paper could be strengthened by providing empirical evidence to substantiate the claim. However, the comment could be more helpful if it provided guidance on what kind of evidence would be sufficient or how to present it effectively. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with highdimensional domains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or suggestions for modifications to improve the scalability of the robust training scheme. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the robust training scheme, specifically questioning its scalability to practical datasets, particularly those with highdimensional domains. However, it does not specify which part of the paper this concern is based on, such as a specific section or figure where the robust training scheme is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. The comment is specific in its critique of the scalability issue but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the robust training scheme is unlikely to scale to practical datasets, particularly those with highdimensional domains. The comment provides a logical reasoning by suggesting that the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples or references to support this claim, making it 3. The authors may find it challenging to fully understand and address the concern without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with highdimensional domains. It points out that the accuracy might unfavorably scale unless the size of V scales exponentially with the dimension. This feedback is 3 as it highlights a potential limitation of the robust training scheme, which the authors should consider when designing their experiments or evaluating its applicability. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how it might be overcome. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. While the comment implies that the authors should make this distinction, it does not provide explicit instructions or concrete steps on how to implement this distinction. The authors are left to infer that they should make this distinction, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this distinction is necessary or how it would improve the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. This feedback is 3 as it identifies a potential area for clarification and differentiation in the paper. However, the comment lacks specific guidance on how to implement this distinction or why it is important for the paper. While it points out a potential issue, it does not provide detailed suggestions or examples on how to address it, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly better, given the small difference in performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The authors are left to infer that they might need to reconsider the data usage or provide additional justification for the conclusion. The lack of concrete suggestions or detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the amount of data used to train the text disambiguation model and compares it to the data used for the endtoend system. It questions the conclusion that the direct model is clearly better, given the small difference in performance. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the discrepancy in data usage and the conclusion, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the amount of data used to train the text disambiguation model is significantly lower than the data used for the endtoend system, which raises questions about the conclusion that the direct model is clearly better. However, the comment does not provide specific data or references to support this claim, making it difficult for the authors to verify the validity of the assertion. The lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s conclusion regarding the superiority of the direct model over the endtoend system. It points out that the difference in performance is only a few percentage points, which raises questions about the validity of the conclusion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their conclusion. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues with the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. While the comment highlights specific areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and evidence for GaRare\"s advantages over GaLore, as well as clarify the process of updating parameters. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement these improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the paper, such as the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for GaRare and provides a specific example of the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. The comment suggests that this lack of detail hinders understanding. However, the comment does not provide specific examples or references to support the claim that GaRare\"s advantages over GaLore are unclear or that the algorithmic presentation is insufficient. While the claim is logical, the lack of detailed evidence or examples makes it 3, as the authors would need to make a significant effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve their draft. The suggestion to provide more detailed explanations and evidence for GaRare\"s advantages over GaLore is particularly valuable, as it can help the authors better justify their approach and enhance the paper\"s clarity. However, the comment could be more helpful if it offered specific examples or references to support the need for a more detailed algorithmic presentation. Overall, the feedback is 4 as it guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides explicit actions, it does not offer detailed guidance on how to conduct the ablation study or the specific experiment with ATT(+H). The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to implement the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 4 left\" and \"visDial dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely conducting an ablation study on the visDial dataset and conducting an experiment on the performance of ATT(+H) in figure 4 left. The comment provides detailed guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides a logical request for additional experiments, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact experiments and analyses required to address the suggestion. Therefore, the comment is 3, as it provides a clear direction but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. This feedback is clear and offers a concrete direction for the authors to improve their draft by conducting additional experiments and analyses. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it offers valuable suggestions for enhancing the paper, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. It also questions whether any input serves as white paper and points out that Figure 2 suggests Gaussian noise input does not work as well as WPA. The reviewer notes that the authors spend a lot of time showing WPA improves the test performance of the original model but do not provide insights into how WPA works. This feedback highlights a gap in the paper that needs to be addressed, suggesting that the authors should provide more detailed explanations or analysis to support their findings. The comment is explicit in its request for clarification and actionable, as it clearly identifies areas where the authors can improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"np.ones input,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of why WPA works and the implications of the results shown in Figure 2. The comment provides a clear direction for the authors to improve their draft by explaining the model\"s predictions and the limitations of Gaussian noise input. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the effectiveness of WPA and suggests that the authors should provide more insights into how WPA works. It references Figure 2, which appears to suggest that Gaussian noise input does not work as well as WPA. The reviewer also points out that the paper spends a lot of time showing WPA improves test performance but lacks insights into its mechanism. This claim is 3 as it highlights a gap in the paper\"s explanation and suggests a direction for further exploration. However, the comment could be strengthened by providing more detailed reasoning or examples to support the claim about the effectiveness of WPA. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, highlighting several areas where the authors could improve their work. It suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. The comment also questions whether any input serves as a white paper and points out that Figure 2 suggests Gaussian noise input does not work as well as WPA. This feedback is particularly valuable as it identifies a gap in the paper\"s explanation of WPA\"s mechanism, which is crucial for future research directions. The comment is clear and actionable, providing the authors with specific areas to focus on to enhance their draft. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method part of the paper is similar to a related work mentioned, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification on this similarity. While the comment implies that the authors should provide more information or explanation regarding the similarities, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification, but it is concrete in that it specifies the need for more information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"method part\" of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the similarity to a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and requests clarification on this similarity. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the method part of the paper is similar to a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential similarity between the method part of the paper and a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and requests clarification on this similarity. While the comment highlights an area of concern, it does not provide specific guidance or suggestions on how the authors might address this issue or differentiate their work from the related work. The feedback is 3 as it points out a potential problem but lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison with other methods and consider promoting existing methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed method, such as the use of a proposal generator pretrained on MSCOCO and its potential impact on existing class incremental semantic segmentation methods. It also mentions the authors\" adequate addressing of limitations and potential negative societal impact. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its inquiry about the fairness of comparison and the potential promotion of existing methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about fairness or the potential impact on existing methods. This makes the claim 3, as the authors would need to infer the basis of the critique and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. While it points out areas for consideration, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two important parameters/thresholds (minimum cluster size and conductance threshold) that are not discussed in the experimental section. It explicitly states that the experimental section should mention and discuss how these parameters are set and how sensitive the performance is with respect to these parameters. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"End of Sec.2\" and the \"experimental section (Sec. 3),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of discussion on how the minimum cluster size and conductance threshold are set and how sensitive the performance is to these parameters. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental section does not discuss how the minimum cluster size and conductance threshold are set and how sensitive the performance is to these parameters. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper, specifically the lack of discussion on how the minimum cluster size and conductance threshold are set and how sensitive the performance is to these parameters. This is a crucial aspect that could significantly impact the validity and reproducibility of the experimental results. By pointing out this oversight, the comment provides the authors with a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to address this issue, such as suggesting ways to discuss the parameter settings or providing examples of how other studies have handled this aspect. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific changes could be made to improve the approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the use of reinforcement learning, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to studies that have demonstrated the inefficiency or difficulty of using reinforcement learning for static VQA tasks. Without such support, the claim remains 1, as it is based on a personal opinion without sufficient evidence or reasoning. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. While the comment identifies a potential issue, it lacks specificity and actionable guidance on how the authors might address this concern. It does not provide suggestions on how to mitigate the potential weakness or improve the approach. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the limited novelty of the proposed method and its similarity to other attentional modules in previous works. It specifically mentions that the group attention design is related to ResNeSt but not discussed in the paper. The comment implies that the authors should discuss the similarities and differences between their work and previous attentional modules, particularly in the context of object detection and instance segmentation. While the action is implicit, it is clear that the authors need to address these points to enhance the novelty and originality of their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"group attention design\" and \"ResNeSt,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty and the similarity to other attentional modules, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. The reviewer supports this claim by referencing specific works, such as 1, 2, 3, which have similar structures. However, the comment also notes that the group attention design is related to ResNeSt but not discussed in the paper, which adds a specific critique. While the reference to previous works provides some basis for the claim, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method differs from the existing works. Overall, the claim is 4, as it provides a logical basis for the critique but lacks comprehensive evidence or detailed comparisons. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to other attentional modules in previous works. It specifically mentions the group attention design and its relation to ResNeSt, which is not discussed in the paper. This feedback is clear and actionable, as it points out a critical weakness in the originality of the work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as discussing the differences or improvements over existing methods. Overall, the comment is 4 as it highlights a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the lack of comparison with testtime adaptation (TTA) methods, specifically mentioning AB. It suggests that a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of robustness in video action recognition and the lack of comparison with testtime adaptation (TTA) methods, such as AB. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a comparison with TTA methods to prove the superiority of data processing over model parameter adjustment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with testtime adaptation (TTA) methods, specifically mentioning AB. The reviewer suggests that such a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. However, the comment does not provide specific examples or references to support the claim that TTA methods are relevant or how they could be applied to the paper. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of comparison with testtime adaptation (TTA) methods, such as AB. This is a critical observation as TTA methods aim to adapt to outofdistribution data when the input data is disturbed by noise. The reviewer suggests that a comparison with TTA methods could provide valuable insights into the effectiveness of data processing versus model parameter adjustment. While the comment highlights an important area for improvement, it does not offer specific guidance on how to conduct such a comparison or what specific aspects to focus on. This limits the comment\"s helpfulness, as it points out a significant issue but lacks detailed instructions for addressing it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific error in the first expression for J (\u03b8) and suggests that it should be Q (s t 0, \u03c0\u03b8(s t 0)). This provides a clear and concrete action for the authors to take, as they are directly instructed to correct the mistake. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J (\u03b8), suggesting that it should be Q (s t 0, \u03c0\u03b8(s t 0)). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first expression for J (\u03b8) is incorrect and should be Q (s t 0, \u03c0\u03b8(s t 0)). However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the first expression for J (\u03b8) in Section 3.2.1, noting that it should be Q (s t 0, \u03c0\u03b8(s t 0)). This is a clear and actionable piece of feedback that the authors can easily address to correct the mistake. However, the comment could be more helpful if it provided additional context or explanation about why this error occurred or how it affects the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area needing correction."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with capitalization in the paper, including specific references that need capitalization. It also mentions that various words in the references need capitalization. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to correct these issues. The authors are left to infer that they should review and correct the capitalization in the references and in the text. The action is implicit and somewhat vague, as it lacks detailed guidance on how to implement the corrections. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p. 8\" and \"Various words in many of the references need capitalization,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it details the capitalization issues in the references and the text, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and observations about capitalization issues in the paper and references. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several capitalization errors in the paper and references, which is a clear and actionable piece of feedback. It provides specific guidance on where these errors occur, allowing the authors to easily correct them. Additionally, it points out that many references need capitalization, which is a helpful observation that can improve the overall presentation of the paper. However, the comment could be more helpful if it provided examples of the correct capitalization or offered suggestions on how to address these issues consistently throughout the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the missing parameter values for task 1 and the Boltzmann policy, specifically asking about the model parameters and the method used to choose them. While it highlights the need for clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to provide more information about the parameter choices, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific tasks, such as \"task 1\" and the Boltzmann policy, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by asking about the model parameters and the method used to choose them, as well as how the parameters were chosen (e.g., maximum likelihood estimates). This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification about specific parameter values and the method used to choose them. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the paper lacks clarity, specifically regarding the model parameters and the method used to choose them. It asks about the parameters for task 1 and the Boltzmann policy, as well as how the parameters were chosen. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the parameter choices, which is crucial for understanding the methodology and results. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar details have been addressed in similar works. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors claim to achieve stateoftheart results on challenging scene text recognition tasks, but the reviewer finds this claim unconvincing. The reviewer suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. While the comment implies that the authors should conduct such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct comparisons experiments to validate their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. It also mentions the need for comparisons experiments with existing detection methods. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or claims presented in the paper. The comment is specific in its critique of the authors\" claims and the need for comparisons experiments, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks are unconvincing. The reviewer suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or detailed comparisons to substantiate the claim, making it 3. The authors would need to make a significant effort to understand and address the critique, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks. The reviewer suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. This feedback is 3 as it points out a potential weakness in the authors\" claims and suggests a direction for improvement. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain why they believe applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 deteriorates performance compared to only applying it to layers 3 and 4. It provides a clear and direct action for the authors to take, which is to provide an explanation or rationale for this observation. The comment is specific and actionable, as it guides the authors on how to address the issue by offering a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the deterioration in performance when Conditional Batch Norm (CBN) is applied to layers 2, 3, and 4 compared to only layers 3 and 4. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2 deteriorates performance compared to only applying it to layers 3 and 4. However, the comment lacks specific details or evidence to support this claim, such as data or analysis that demonstrates the performance difference. Without such supporting information, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2, noting that this deteriorates performance compared to only applying it to layers 3 and 4. It prompts the authors to explain why this might be happening and suggests that the authors provide an explanation or rationale for this observation. This feedback is clear and actionable, as it directs the authors to address a specific issue in their draft that could impact the paper\"s conclusions. However, the comment could be more helpful if it included suggestions on how to investigate or resolve the issue. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out the lack of comparison with a highly relevant method, specifically mentioning 1 and its proposed approach of utilizing previous knowledge with intertask ensemble. It also highlights the absence of a comparison with the current task\"s performance using intratask ensemble. The comment clearly identifies the missing element in the paper, which is the inclusion of method comparisons and performance comparisons. This provides a direct and concrete action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, specifically mentioning 1 and its approach of utilizing previous knowledge with intertask ensemble. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of method comparisons and performance comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning 1 and its approach of utilizing previous knowledge with intertask ensemble. The reviewer also notes the absence of a comparison with the current task\"s performance using intratask ensemble. However, the comment does not provide specific details or references to 1 or the method being compared, making it difficult for the authors to fully understand the basis of the claim. While the reviewer highlights a potential gap in the paper, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of comparison with a highly relevant method that proposes to utilize previous knowledge with intertask ensemble. It also points out the absence of a comparison with the current task\"s performance using intratask ensemble. This feedback is clear and actionable, as it directs the authors to include method comparisons and performance comparisons to enhance the comprehensiveness and rigor of their work. By addressing this feedback, the authors can significantly improve the clarity and relevance of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the proposed method\"s inability to handle headpose and questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to a previous work. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The comment implies that the authors should consider incorporating headpose control into their method, but it lacks concrete steps or detailed instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"headpose,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the method cannot handle headpose and why it cannot be conditioned like a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, noting that a previous work has already demonstrated control over both facial expression and headpose. The comment suggests that the authors should consider conditioning the headpose parameters in the NeRF beyond facial expression, similar to the previous work. However, the comment lacks specific references or detailed reasoning to support why this is a significant issue or how it could be addressed. While it highlights a potential gap in the methodology, the lack of detailed justification makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that it cannot handle headpose while deferring this problem to future work. It questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to a previous work. This feedback is 3 as it points out a gap in the methodology and suggests a potential area for improvement. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or incorporate headpose control into their method. While it highlights an important area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear only a few times in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) to illustrate this point. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific actions to take. The authors are left to infer that they should investigate the impact of these spurious features and consider ways to mitigate their influence on the model. Therefore, the comment is 3, as it implies an action but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the similarity between the spurious features and backdoor triggers, and it provides examples from Chen et al. (2017) and Gu et al. (2019) to support its claim. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, which are artificial patterns that only appear a few times in the training set. The reviewer supports this claim by referencing specific examples from Chen et al. (2017) and Gu et al. (2019), where backdoor triggers are used. This provides a logical basis for the claim, as it highlights a known issue in the literature that could impact the model\"s performance. However, the comment could be strengthened by providing more detailed examples or additional references to further substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers. It provides specific examples from Chen et al. (2017) and Gu et al. (2019) to illustrate this point, highlighting the potential impact of such triggers on the trained model. This feedback is valuable as it alerts the authors to a potential problem in their work and suggests a direction for further investigation or mitigation. However, the comment could be more helpful if it offered suggestions on how to address this issue or what specific experiments could be conducted to validate the impact of these spurious features. Overall, the comment is 3 as it provides a clear direction for improvement but lacks detailed guidance on how to implement it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is a main component and that the optimization algorithm seems to be directly from previous works, which can be confusing and reduce the contribution. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific improvements. The comment lacks concrete actions or detailed suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of structural optimization being a main component and the use of an optimization algorithm that seems to be directly from previous works. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the confusion caused by the direct use of an algorithm from previous works and how it affects the contribution of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the structural optimization is a main component and that the optimization algorithm seems to be directly from previous works, which can be confusing and reduce the contribution. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the use of a structural optimization component that seems to be directly from previous works. This observation highlights a potential confusion in the contribution of the paper, as it may not be seen as original or innovative. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their contribution. While it points out a potential weakness, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of poor baseline model introduction or how to improve the pipeline style method. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the pipeline style method, which includes two models, and notes that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses these models or the pipeline style method, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what needs to be addressed regarding the baseline models or the pipeline style method. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the pipeline style method, which includes two models, not yielding better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the pipeline style method. Without actionable advice or detailed feedback, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as 2, as it points out areas for improvement but does not provide sufficient guidance for the authors to make meaningful changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve their methodology. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their methodology but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. However, it does not specify which part of the paper this observation is made in, making it weakly grounded. The comment is specific in detailing the issue with the authors\" methodology, questioning why this observation needs to be made using the \"coarse\" methodology. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have reproduced a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion that this observation is unnecessary. The authors may need to further substantiate the claim by providing evidence or references to similar works that have already addressed this issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. This feedback highlights a potential redundancy in the authors\" approach and suggests that they might need to reconsider their methodology or provide a more novel contribution. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their work. While it identifies a potential weakness, it lacks actionable advice, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. It lacks concrete suggestions on what specific comparisons or contrasts should be included or how to present them. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on SSC and contrasting methods like thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of contrast with other methods in terms of computational efficiency and guarantees. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other methods like thresholded subspace clustering (TSC) and greedy subspace clustering by Park. However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the basis of the claim. Without detailed comparisons or references, the claim is not fully substantiated, making it 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. This feedback is 3 as it points out a gap in the paper that could be addressed by including comparisons with other methods. However, the comment lacks specific suggestions on how to incorporate these comparisons or what specific aspects to focus on. While it highlights an area for improvement, it does not provide detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to remove the statement about semantic segmentation being a lowlevel cue, as it is not accurate given that categories are specified for each pixel. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"semantic\" segmentation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the statement about semantic segmentation being a lowlevel cue. This provides clear guidance on what needs to be revised or removed from the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"semantic\" segmentation is not lowlevel since categories are specified for each pixel. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to remove the statement about semantic segmentation being a lowlevel cue. This feedback is valuable as it helps the authors correct an inaccurate claim in their paper, ensuring that their work is presented accurately and consistently. By addressing this point, the authors can improve the clarity and accuracy of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies the main weakness of the paper as the lack of comprehensive experimental evaluation, specifically the limited consideration of datasets from Federated learning benchmarks. It suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. While the comment provides a clear direction for improvement by recommending specific works to consider, it does not explicitly instruct the authors on how to incorporate these works into their evaluation or how to address the identified weakness. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the main weakness of the paper, which is the limited consideration of datasets from Federated learning benchmarks and the lack of comprehensive experimental evaluation. The comment suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main weakness of the paper is the limited consideration of datasets from Federated learning benchmarks and the lack of comprehensive experimental evaluation. The reviewer suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. While the comment provides a logical reasoning for the need to expand the experimental evaluation, it lacks specific examples or references to these works to fully substantiate the claim. This makes the claim 3, as the authors would need to follow up on the suggestion to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited consideration of datasets from Federated learning benchmarks and the lack of comprehensive experimental evaluation. It suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback is clear and actionable, as it provides specific guidance on how the authors can enhance the comprehensiveness and relevance of their experimental evaluation. By addressing this feedback, the authors can significantly improve the quality and impact of their paper. However, the comment could be more helpful if it provided additional context or examples of how these works could be integrated into the paper. Overall, the comment is 4 as it effectively directs the authors toward a meaningful improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve their draft. The comment implies that the authors should consider using another dataset, but it lacks concrete details on how to implement this suggestion or what specific aspects of the claim need to be revised. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the table and the claim about accuracy and completeness, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the claim and suggests using another dataset for the ablation study. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. This is a constructive suggestion that could help the authors strengthen their argument by providing additional evidence or comparisons. However, the comment lacks specific guidance on which dataset to use or how to conduct the ablation study, which would make it more actionable. Overall, the comment is 3 as it identifies a potential weakness in the claim but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It suggests that additional explanations are needed to address this issue. However, the comment does not provide specific guidance on how to provide these explanations or what aspects of the relationship should be clarified. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but without concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by the theorems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2 is not intuitive enough. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It points out that while the theorems prove conformity to a clearer community structure, the relationship with degree bias is not intuitive. This feedback is valuable as it highlights a potential gap in the paper\"s explanation, which the authors can address to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify this relationship or examples of how it might be explained more effectively. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the construction of clean exemplar manifolds for a nonstochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this question or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the construction of the clean exemplar manifolds and the denominator computation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 182183,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the construction of clean exemplar manifolds for a nonstochastic network and how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for a nonstochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. The comment is 3 as it highlights a potential inconsistency in the paper regarding the construction of clean exemplar manifolds. However, it lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the paper regarding the construction of clean exemplar manifolds for a nonstochastic network. It raises a specific question about how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks, which is a critical aspect of the paper\"s methodology. By pointing out this discrepancy, the comment provides the authors with a clear and actionable step to address the issue. However, the comment could be more helpful if it offered suggestions on how to clarify this point or provided examples of how similar issues have been addressed in similar works. Overall, the comment is 4 as it directs the authors\" attention to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the evaluation of shape model invariance, specifically asking if there are any quantitative results on testing images. While the comment implies that the authors should include such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide quantitative results on testing images. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the evaluation on transformations of training images and asks for quantitative results on testing images. This provides clear guidance on what additional information is needed to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the evaluation on transformations of training images for the shape model invariance study. It suggests that quantitative results on testing images might be needed to fully prove the point. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the evaluation of shape model invariance, specifically questioning the use of transformations of training images to prove the point. It suggests that quantitative results on testing images might be necessary to fully substantiate the claim. This feedback is 3 as it identifies a potential gap in the evaluation process and prompts the authors to consider additional evidence. However, the comment could be more helpful if it provided specific suggestions on how to conduct the testing or what types of quantitative results might be relevant. Overall, the comment offers a constructive direction for improvement, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the omission of a related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the stateoftheart. The comment is clear and provides a direct action for the authors to take, which is to include a discussion of the related work. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the omission of this related work and its potential impact on the understanding of the stateoftheart. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared with the current work. The comment provides a logical reasoning by suggesting that the AAAI15 paper deals with hypergraph data with tensors, which is relevant to the current work. However, the comment lacks specific examples or references to the content of the AAAI15 paper, making it 3. The authors would need to conduct additional research to fully understand the relevance of the AAAI15 paper to their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant oversight in the paper, noting the absence of a related work discussion on the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. It suggests that this paper, which deals with hypergraph data with tensors, should be discussed and compared with the current work to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a relevant discussion that could significantly enhance the paper\"s comprehensiveness and impact. However, the comment could be more helpful if it provided specific guidance on how to integrate this discussion into the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it would be beneficial to test its scalability on normal machines with a few cores. It also questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific tests should be conducted. The action is implicit and somewhat vague, as the authors need to infer that they should test scalability and clarify the computation of optimal transport. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Approach\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the scalability of the method and questions how the authors compute the optimal transport distance, suggesting that they should test it on normal machines with a few cores. Additionally, it questions how the Sinkhorn method relates to the computation of optimal transport. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it is not clear how scalable the method is. The reviewer questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies potential issues, it lacks specific examples or references to support the claim that the method is not scalable or how it could be improved. The lack of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the method and raises questions about how the authors compute the optimal transport distance. It suggests that the authors should test the scalability on normal machines with a few cores and clarify how they compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. This feedback is clear and actionable, as it provides specific areas for improvement and suggests ways to address the concerns raised. However, it could be more helpful if it included examples or references to similar studies that have addressed these issues. Overall, the comment is 4 as it guides the authors toward improving the scalability and clarity of their method."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is extremely hard to follow, indicating that the authors need to improve the clarity and accessibility of their experimental procedures and evaluations. However, it does not provide specific guidance on how to achieve this improvement, such as recommending changes to the structure, language, or presentation of the paper. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the clarity of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper is difficult to follow, specifically mentioning the experimental procedures and evaluations. However, it does not specify which sections or parts of the paper are particularly challenging to understand. Without explicit references to sections or details, the authors cannot confidently determine which parts need improvement. The comment is specific in identifying the issue of clarity but lacks grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is \"extremely hard to follow,\" suggesting that the experimental procedures and evaluations are unclear. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific references or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that it is \"extremely hard to follow.\" This feedback highlights a critical weakness in the clarity and accessibility of the experimental procedures and evaluations, which is crucial for readers to understand and replicate the work. However, the comment lacks specific suggestions or guidance on how the authors might improve the clarity or structure of their paper. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to address it. Therefore, the comment is 3, as it points out a significant issue but does not provide enough detail for the authors to make significant improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. While the comment implies that the authors should explore these applications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their work to include these other areas. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the model and experiments to other research areas, such as NLP or simpler models in the image domain (CNNs). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. However, the comment lacks specific examples or references to support the claim that the model and experiments are limited to image data and ViT. Without such evidence or reasoning, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. This feedback is valuable as it prompts the authors to consider expanding their work beyond the specific focus on transformers in vision, which could enhance the generalizability and impact of their research. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might apply these principles to other areas. Overall, the comment is 4 as it encourages the authors to broaden their work, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should evaluate TTA methods on more conditions of natural distribution shift, like WILDS 9, to strengthen the paper. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Performance of TTA methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating TTA methods on more conditions of natural distribution shift, like WILDS, to strengthen the paper. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using nonstandard benchmarks breaks popular TTA methods and recommends evaluating TTA on more conditions of natural distribution shift, like WILDS. However, the comment does not provide specific examples or references to support this claim, nor does it explain why using nonstandard benchmarks is significant or how it affects the performance of TTA methods. Without additional context or evidence, the claim remains 3, as it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies an interesting observation about the performance of TTA methods under nonstandard benchmarks, suggesting that evaluating these methods on more conditions of natural distribution shift could strengthen the paper. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to implement this evaluation or what specific conditions of natural distribution shift should be considered. The feedback is 3 as it points out a potential enhancement but does not provide detailed instructions or examples for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper discusses tensor networks used to represent PMF of discrete variables but does not clarify how these results are useful to machine learning algorithms or how they can be analyzed. The reviewer suggests that the paper lacks significance due to this lack of clarity. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific ways to integrate the tensor networks into machine learning algorithms or how to present the results more effectively. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or explanation but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of tensor networks to represent PMF of discrete variables and questions the significance of the paper due to a lack of clarity on how these results are useful to machine learning algorithms or how they can be analyzed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the paper\"s significance, as it highlights the need for clarity on the practical applications and analysis of the tensor networks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clarity on how the tensor networks used to represent PMF of discrete variables are useful to machine learning algorithms or how they can be analyzed. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some basis but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that while tensor networks can be used to represent PMF of discrete variables, the paper lacks clarity on how these results are useful to machine learning algorithms or how they can be analyzed. This feedback highlights a critical gap in the paper\"s explanation, which could impact its significance and impact. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the paper\"s clarity. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a critical area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the absence of experiments on a specific setting. It highlights the need for experiments on surveillance in museums with thresholded rewards and privacypreserving data collection. While the comment identifies a specific issue with the experimental section, it does not provide explicit guidance on how to address this concern. The authors are left to infer that they should include experiments on these settings, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the specific setting of the POMDP problem with nonconvex value functions. It also specifies the issue with the experiments section, noting the absence of experiments on surveillance in museums with thresholded rewards and privacypreserving data collection. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the experimental results, specifically the absence of experiments on specific settings. It references the examples of surveillance in museums with thresholded rewards and privacypreserving data collection as motivating cases for the paper. However, the comment lacks specific evidence or detailed reasoning to support why these examples are insufficient or why the experiments are not useful. The claim is 3, as it highlights a potential issue but does not provide sufficient justification or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, specifically questioning the absence of experiments on specific settings that were used to motivate the paper. It highlights the need for experiments on surveillance in museums with thresholded rewards and privacypreserving data collection, which are relevant examples of POMDP problems with nonconvex value functions. This feedback is clear and actionable, as it points out a critical gap in the experimental section that the authors can address to strengthen their work. However, the comment could be more helpful if it provided suggestions on how to conduct these additional experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a clear rationale for why epochwise analysis could be valuable, it does not explicitly instruct the authors on how to implement this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It provides a specific example of how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The suggestion is specific, as it clearly outlines the potential benefits of epochwise analysis and how it could be applied to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a logical reasoning for the potential benefits of epochwise analysis, it lacks specific examples or references to support the claim. The suggestion is 3, as it provides a clear rationale but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It suggests that epochwise analysis, particularly in finite sum settings, could offer insights into the behavior of optimization algorithms. The reviewer highlights the potential benefits of this analysis, such as investigating the effect of batch size or different sampling strategies on the progress of algorithms and aiding in comparative analysis of deterministic and stochastic methods. This feedback is valuable as it suggests a specific direction for the authors to explore, which could enhance the understanding and interpretation of their results. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully employed epochwise analysis. Overall, the comment is 4 as it offers a clear and actionable suggestion for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the immense workload, the incremental contribution, and the lack of citation of key baselines. It also points out that the paper focuses on RAG for EHR and suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific details to include. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the code and details in the article, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issues with the workload being immense and the contribution being incremental, as well as the lack of citation of key baselines and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is incremental and essentially a combination of GraphRAG and GraphCare, referencing the absence of essential RAG algorithms like MedRetriever and KGRAG. The reviewer also mentions that key baselines were not cited, which supports the claim of incremental contribution. However, the comment lacks specific examples or references to substantiate the claim about the lack of essential RAG algorithms or the absence of citation of key baselines. This makes the claim 3, as the authors would need to infer the specific algorithms and references to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the immense workload and the incremental contribution, which are not fully explained. It points out that the paper essentially combines GraphRAG and GraphCare, and that key baselines were not cited. Additionally, the comment suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced, as they are relevant to the focus on RAG for EHR. While the comment provides some insight into areas that need improvement, it lacks specific guidance on how to address these issues or what specific details should be included. The authors are given a general direction but not detailed steps to follow, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be included in the graph and why it is important. The comment also offers a rationale for why this graph is necessary, helping the authors understand the potential sources of performance improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be included in the graph and why it is important to understand the sources of performance improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This claim is 3 as it logically suggests that such a graph would help clarify whether the performance improvement is solely due to the network design or whether it is influenced by the nature of ImageNet. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This is a specific and detailed piece of feedback that can help the authors better understand the performance improvement and its potential sources. By including this graph, the authors can address the reviewer\"s concern about whether the improvement is solely due to the network design or whether it is influenced by the nature of ImageNet. The comment is also helpful as it provides a rationale for why this graph is important, which can guide the authors in making improvements to their draft. Overall, the comment is 5 as it offers a clear and constructive suggestion for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper needs to be mathematically correct and provides a specific example by questioning the notation \"L_l\" instead of just \"L.\" It also suggests introducing the notation beforehand. While the comment identifies areas for improvement, it does not provide explicit instructions on how to make these changes or what specific changes should be made. The authors are left to infer that they need to make these corrections, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" and \"L_l instead of just L,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the notation \"L_l\" and the need for mathematical correctness. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper needs to be mathematically correct and questions the notation \"L_l\" instead of \"L.\" It provides a specific example of the notation issue and suggests introducing the notation beforehand. However, the comment lacks detailed reasoning or references to support why this change is necessary or how it would improve the paper. The suggestion is 3 as it identifies a specific issue but does not provide a comprehensive rationale or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, suggesting that \"L_l\" should be changed to \"L\" to maintain mathematical correctness. It also points out that the notation should be introduced beforehand. This feedback is clear and actionable, as it provides the authors with a concrete suggestion for improving the clarity and correctness of their work. However, the comment could be more helpful if it explained why this change is necessary or how it would impact the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, making it a valuable contribution to the authors\" draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also notes that this limitation prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take to study the effect of noise accumulation. The action is implicit and somewhat vague, as the authors can infer that they need to consider this aspect but are not given clear instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"sequential ensembling\" and \"homomorphic encryption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of noise accumulation in the context of homomorphic encryption, which prevents the use of even single deep neural networks on homomorphically encrypted data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that noise accumulation in the context of homomorphic encryption is a critical issue for sequential ensembling, as it prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion and how it affects the study. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the study of sequential ensembling in the context of homomorphic encryption. It points out that the accumulation of noise in this setting prevents the use of even single deep neural networks on homomorphically encrypted data. This is a significant limitation that the authors should consider and address in their work. However, the comment does not provide specific suggestions or guidance on how to address this issue or what aspects of the study should be prioritized. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case, the authors should use a standard regularization trick. While the comment implies that the authors should apply this standard technique, it does not provide explicit instructions on how to implement it or which specific regularization trick to use. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the use of a standard regularization trick, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this standard technique is necessary or how it would improve the comparison. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance on which standard regularization trick to use or how it would impact the comparison. The feedback is 3 as it points out a potential issue but does not offer detailed instructions or examples to help the authors address it effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This is a clear and concrete action for the authors to take, as it provides a specific enhancement to the figure that would help clarify the impact of mean teacher on learning. The suggestion is direct and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 3\" and \"left graph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is a learning curve for a model without mean teacher or pi regularization. This provides clear guidance on how to enhance the figure and compare the impact of mean teacher on learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This is a request for additional data or analysis, which is a factual observation rather than an opinion or claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This additional information would help clarify the impact of mean teacher on learning, providing valuable insights for the authors. The comment is clear and direct, offering a concrete way to enhance the figure and improve the draft. Therefore, it is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the need to discuss how to handle different types of inputs, such as biomedical signals or speech, and the disorderly citation style. While the first point suggests a specific area for improvement, it does not provide explicit guidance on how to address it, such as recommending a particular approach or method. The second point about the citation style is more of a general observation, and while it highlights an issue, it does not offer specific suggestions for improvement. Therefore, the comment is 3, as it identifies areas for improvement but lacks concrete details on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss how to handle different types of inputs, such as biomedical signals or speech, and suggests that the citation style is disordered. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need to discuss solutions for handling different input types and the disorderly citation style. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims: the need to discuss how to handle different types of inputs and the disorderly citation style. The first claim is 3 as it suggests a potential area for improvement, but it lacks specific examples or detailed reasoning on how to address the issue. The second claim about the citation style is more vague, as it does not specify what constitutes disorderly citation or how it could be improved. Overall, the comment provides some direction but lacks detailed justification or examples, making it 3.", "helpfulness_rationale": "The review comment identifies two areas for improvement: discussing how to handle different types of inputs, such as biomedical signals or speech, and addressing the disorderly citation style. While it highlights these issues, it does not provide specific guidance or examples on how to address them. The comment suggests that the authors should discuss their solutions, but it lacks detailed suggestions on how to structure this discussion or what specific aspects of the citation style need attention. This limits the comment\"s helpfulness, as it points out areas for improvement but does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance on how to address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their question answering method, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the question answering process, particularly the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with the question answering process, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process, which involves template mapping, might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to studies or literature that demonstrate the limitations of this approach or suggest alternative methods. Without such support, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. While the comment highlights a potential problem, it lacks specific guidance or suggestions on how the authors might address this issue or improve their question answering process. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to cite the source of the rockpaperscissors example, which is clearly inspired by previous work. This is a direct and concrete action, as it specifies the exact source that needs to be cited. The authors know exactly what needs to be done to address the comment, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to cite the source of the example. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is inspired by previous work and suggests that the source should be cited appropriately. However, the comment does not provide specific examples or references to the previous work that inspired the example, making it difficult for the authors to verify the claim. Without additional context or evidence, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rockpaperscissors example is inspired by previous work and should be appropriately cited. This is a clear and actionable piece of feedback, as it directs the authors to provide proper attribution to the source of the example. By addressing this point, the authors can ensure that their work is properly credited and that their contribution is transparent. Therefore, the comment is 5, as it provides a clear and specific direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the innovations or how to mitigate the constraints. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, it does not specify which part of the paper discusses these innovations or where the constraint embedding is mentioned. The authors cannot confidently determine which sections or parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the innovations or the constraint embedding are considered limited or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the innovations of network architecture design and constraint embedding, suggesting that the performance is constrained by the performance of the oracle expert. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. The comment lacks actionable feedback or detailed insights into potential improvements, leaving the authors without a clear path forward. As a result, the comment is 2, as it points out a weakness but does not offer constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that comparing the performance of a model pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors instead. It further suggests that the authors should provide the performance of the model pretrained on synthetic data but finetuned on realworld datasets with different losses. While the comment provides a clear action\u2014to demonstrate the importance of the projection errors and finetune the model on realworld datasets\u2014it does not specify how to implement this action or what specific steps to take. The authors are left with a general idea of what needs to be done but without detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of comparing the performance of a model pretrained on synthetic data, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the need to demonstrate the importance of the proposed three projection errors and suggests providing performance results for models pretrained on synthetic data but finetuned on realworld datasets with different losses. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that comparing the performance of a model pretrained on synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors instead. The comment provides a logical reasoning by suggesting that finetuning the model on realworld datasets with different losses is necessary to showcase the model\"s performance. However, the comment lacks specific examples or references to support the claim that the current comparison is unfair. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s comparison of model performance, suggesting that comparing a model pretrained on synthetic data is unfair. It recommends demonstrating the importance of the proposed three projection errors and provides a clear suggestion for improvement by suggesting that the authors should provide performance results for models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is actionable and offers a clear direction for the authors to enhance their analysis and presentation of results. However, it could be more helpful if it provided additional guidance on how to implement this suggestion or what specific metrics to use for the finetuning process. Overall, the comment is 4 as it effectively points out a weakness and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the lack of discussion on crucial conditions for DICE and the need to ensure that these conditions are met. It explicitly mentions that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. However, the comment does not provide specific guidance on how to ensure DICE meets these conditions or what aspects of the discussion should be expanded. While the authors can infer that they need to address these issues, the lack of concrete steps or examples makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on crucial conditions for DICE and how to ensure these conditions are met. The comment provides specific examples of the conditions (ID and OOD range and the need for an identical mean) and suggests that these should be discussed in more detail. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. These claims are supported by logical reasoning, as the reviewer points out that these conditions are crucial for DICE and should be discussed in more detail. However, the comment could be strengthened by providing specific examples or references to similar studies or literature that demonstrate the importance of these conditions. As it stands, the claims are 4, as they are based on logical reasoning and common knowledge. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of discussion on crucial conditions for DICE and the need to ensure these conditions are met. It points out that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. These observations are important for the authors to address, as they highlight areas where the paper could be strengthened. However, the comment could be more helpful if it provided specific suggestions on how to discuss these conditions or what aspects of the discussion should be expanded. While it highlights the issues, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the integration of updates across all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. While the comment implies that the authors should consider these changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these changes to improve the readability and clarity of their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the integration of updates across all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. However, it does not specify which part of the paper these sections are located in, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what changes should be made to the bolded sections or how they should be structured. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the integration of updates across all possible environments and suggests that it might be necessary for space reasons. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment also suggests breaking out the bolded sections in page 6 into paragraphs for better readability, but this suggestion is not substantiated with detailed reasoning or examples. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the integration of updates across all possible environments, suggesting that it might be necessary for space reasons. It also points out that the bolded sections in page 6 are currently a large wall of text and should be broken out into paragraphs for better readability. While the comment raises valid points, it lacks specific guidance on how to address these issues, such as suggesting specific changes to the integration or formatting of the text. The feedback is 3 as it highlights areas for improvement, but it could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add a citation on differential privacy, specifically mentioning a standard work like 2. This is a clear and direct action for the authors to take, as it provides a specific reference to include in the paper. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the addition of a citation on differential privacy, such as a standard work like 2. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like 2. This is a factual suggestion that does not involve an opinion, judgment, or claim that requires verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by suggesting the addition of a citation on differential privacy. By mentioning a standard work like 2, the reviewer provides a clear and actionable suggestion that can enhance the paper\"s credibility and comprehensiveness. However, the comment could be more helpful if it explained why differential privacy is relevant to the paper or how it could be integrated into the existing content. Despite this, the feedback is valuable as it directs the authors to a specific area for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme. The reviewer provides a specific example of an additional assumption (the test set being drawn from the same distribution as the query set) and points out that this assumption is natural in many machine learning settings. The reviewer also notes an issue with the inequality on line 310, suggesting that it has the wrong sign. While the comment identifies specific areas of concern, it does not provide explicit guidance on how to address these issues or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and correct the inequality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of Section 3.2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the claim, suggesting that it is too extreme and provides a specific example of an additional assumption that is natural in many machine learning settings. Additionally, it points out an issue with the inequality on line 310, which is incorrect. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the additional assumption of using the same distribution for the test and query sets is natural in many machine learning settings. The reviewer provides a logical reasoning by pointing out that this assumption is common in practice. However, the comment lacks specific examples or references to support the claim that this assumption is not significant. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme. The reviewer offers a logical reasoning by pointing out that the additional assumption of using the same distribution for the test and query sets is natural in many machine learning settings. This feedback is valuable as it challenges the authors to reconsider their claim and potentially revise it to align with common practices. Additionally, the comment identifies an issue with the inequality on line 310, which is incorrect. However, the comment could be more helpful if it provided suggestions on how to address these issues or improve the draft. Overall, the comment is 4 as it offers actionable feedback on the claim and the inequality, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. Additionally, it recommends including a discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space. While the comment provides explicit actions, it lacks concrete details on how to conduct these comparisons or what specific aspects of the advantages and disadvantages should be discussed. The authors are given a clear direction but need more guidance on how to implement these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of Shapely values over other methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for experimental comparisons with other methods and a discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. It also recommends a discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that Shapely values are superior to other methods. This makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the need for experimental comparisons with other methods, such as CaCE or raw gradients, to support the authors\" argument for using Shapely values over other methods. Additionally, it recommends a significant discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space, which could enhance the paper\"s comprehensiveness and depth. While the comment identifies specific areas for improvement, it could be more helpful if it provided examples of how these comparisons or discussions might be structured or conducted. Overall, the feedback is 4 as it guides the authors toward making meaningful enhancements to their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, additional experiments, or guidance on how to enhance the validation process. As a result, the authors are left without any clear direction on how to address the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not specify which part of the paper these experiments are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the types of experiments conducted, but it lacks grounding as it does not specify where in the paper this information is presented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that these experiments are comprehensive. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and crossdomain imitation. However, it lacks specificity and actionable feedback. It does not provide guidance on how the authors could improve or expand upon these experiments, nor does it offer suggestions for further validation or analysis. As a result, the comment is 3, as it identifies a strength but does not provide detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a direct and concrete action for the authors to take, which is to improve the clarity of the illustration in Appendix A.2. The comment is specific about what needs to be addressed, making it 5. Authors know exactly what needs to be done to enhance the clarity of their illustration.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be improved in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. It points out that the illustration is not clear, which is a critical aspect of the paper\"s presentation. This feedback is actionable as it directs the authors to improve the clarity of the illustration, ensuring that readers can better understand the environment\"s state space. However, the comment could be more helpful if it provided suggestions on how to enhance the clarity or examples of how similar illustrations have been effectively presented. Despite this, the comment is 4 as it highlights a specific area for improvement, which is valuable for the authors to address."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors\" approach is only applicable to small or mediumscale problems, as it cannot handle truly large problems that would overwhelm current LPsolvers. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach to handle larger problems. There is no guidance on potential modifications, alternative methods, or additional experiments that could be conducted to address this issue. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the authors\" approach, noting that it is only applicable to small or mediumscale problems and cannot handle truly large problems that would overwhelm current LPsolvers. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the applicability of the approach to large problems, but without clear grounding, the authors may struggle to pinpoint the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable to small or mediumscale problems and cannot handle truly large problems that would overwhelm current LPsolvers. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without concrete evidence or detailed reasoning, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment identifies a limitation in the authors\" approach, noting that it is only applicable to small or mediumscale problems and cannot handle truly large problems that would overwhelm current LPsolvers. This feedback highlights an important area for improvement, as it points out a potential weakness in the applicability of the authors\" work. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their approach to handle larger problems. While it provides some insight into a potential issue, it does not offer actionable steps for improvement, making it 3. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the motivation for using characteristic function regularization is not clear. However, it does not provide any explicit or implicit suggestions for how the authors might clarify this motivation or what specific aspects of the motivation are unclear. There is no guidance on how to address this issue, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that the motivation for using characteristic function regularization is not clear, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine whether it relates to the introduction, methodology, or results sections. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a lack of clarity in the motivation for using characteristic function regularization, which is a critical aspect of the paper. However, it does not provide specific guidance or suggestions on how the authors might clarify this motivation or what aspects of the methodology are unclear. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the contribution is incremental because these techniques are not novel. However, the comment does not provide any explicit or implicit actions for the authors to take to address this limitation or improve their draft. There is no guidance on how to differentiate their work from existing techniques or how to enhance the contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is problematic: the paper\"s limited contribution due to the combination of existing techniques. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. However, the comment lacks specific examples or references to these existing techniques, making it difficult for the authors to understand the basis of the claim. Additionally, the reasoning is not fully articulated, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. While the comment highlights a potential issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the novelty of their work. The feedback lacks actionable advice or detailed critique, making it 3 but incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referred to. This feedback is clear and concrete, as it specifies exactly what needs to be added or clarified in the paper. The authors know exactly what information is missing and how to address it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"aggregation operation after \"Integration,\"\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the details of the aggregation operation and the acknowledgment of other architectures if they are referred to. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the aggregation operation after \"Integration\" needs further clarification and that if other architectures are referred to, their structure should be acknowledged properly. However, the comment does not provide specific examples or detailed reasoning to support why these clarifications are necessary or how they would improve the paper. Without additional context or examples, the claim is 3, as it requires the authors to infer the importance of the suggested clarifications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further clarification, namely the aggregation operation after \"Integration.\" It suggests that the authors provide more details in the main paper and acknowledge the structure of other architectures if they are referred to. This feedback is clear and actionable, as it directs the authors to enhance the clarity and completeness of their explanation. However, the comment could be more helpful if it provided specific examples or guidance on what additional details should be included. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of a search model comparison. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or address this issue. The comment lacks guidance on what the authors should do to improve their draft, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"5.1: Search models comparison,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on what \"100 steps\" means in the context of the search model comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the meaning of \"100 steps\" in the context of a search model comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of a search model comparison, specifically asking for clarification on whether it refers to 100 sampled strategies. This feedback is 3 as it prompts the authors to clarify a specific aspect of their work that may be confusing to readers. However, it lacks depth and does not provide suggestions on how to address the issue or improve the clarity of the explanation. While it points out a potential area for improvement, the comment could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the results are statistically significant. This feedback provides a clear and explicit action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific in its request for additional analyses, making it 5.", "grounding_specificity_rationale": "The comment addresses the improvement over previous methods, specifically mentioning the results in Table 1 and Fig. 5. It also suggests repeating the experiments and conducting statistical significance analysis on the numbers. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of mean and standard deviation reporting and the difficulty in determining statistical significance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, about 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation. Additionally, it suggests repeating the experiments and conducting statistical significance analysis to determine whether the results are statistically significant. The comment provides some logical reasoning by pointing out the lack of detailed reporting and suggesting a potential solution. However, it lacks specific examples or references to support the claim about the size of the improvement or the statistical significance analysis. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the limited improvement over previous methods and the lack of detailed reporting in the results. It suggests repeating the experiments and conducting statistical significance analysis to determine whether the results are statistically significant. This feedback is clear and actionable, providing the authors with a specific direction to enhance the robustness and credibility of their findings. However, the comment could be more helpful if it offered additional guidance on how to conduct the statistical analysis or provided examples of what specific analyses should be conducted. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a clear path for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly recommends conducting experiments on a different benchmark, such as Atari, to verify the generalizability of the method. This suggestion is clear and provides a specific action for the authors to take. Additionally, it highlights the importance of evaluating the method on a diverse set of domains to ensure its applicability beyond the current domain. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation on a single domain, Meta World, and suggests running experiments on a different benchmark, such as Atari. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for generalizability testing and the importance of evaluating the method on a diverse set of domains. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method is evaluated only on the tasks from Meta World, a robotic manipulation domain, which makes it difficult to judge whether the results will generalize to other domains. The reviewer suggests running experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is based on the need to verify whether the method works with discrete action spaces and highdimensional observations. The claim is 3 as it provides a logical reasoning for the need to test generalizability, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the method, noting that it is evaluated only on the tasks from Meta World, a robotic manipulation domain. This observation highlights the need for generalizability testing to ensure that the results can be applied to other domains. The comment provides a specific recommendation to conduct experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is actionable and offers a clear path for the authors to improve their draft by expanding the evaluation to a more diverse set of domains. However, the comment could be more helpful if it included examples of how the Atari benchmark could be used or why it is particularly relevant for the method under consideration. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The comment implies that the authors should add more depth to the explanation of the model, but it lacks concrete instructions or examples on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not specify which part of the paper this analysis should be included in, nor does it provide details on what aspects of the model should be analyzed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is specific in suggesting the need for an analysis but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that while the method is presented well and the experiments are thorough, there is a lack of analysis on what the model does. This feedback highlights an area for improvement, suggesting that the authors should include an analysis of the model\"s functionality, which could be interesting. However, the comment does not provide specific guidance or examples on how to conduct this analysis or what aspects to focus on. While it points out a potential area for enhancement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of the approach section in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the approach section. The comment implies that the authors should include the approach section in the main paper, but it lacks concrete details on how to integrate it or what specific content should be included. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" and the \"supplementary material,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the approach section in the main paper and the use of supplementary material as additional information rather than an extension to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach section is missing in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the approach section should be included or how the supplementary material should be used. Without additional context or explanation, the claim remains 1, as it lacks the necessary justification to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the approach section is missing in the main paper. It suggests that the supplementary material should be used as additional information rather than an extension to the paper. While the comment highlights an important oversight, it lacks specific guidance on how to address this issue or what content should be included in the approach section. The feedback is 3 as it points out a critical gap in the paper, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the statement regarding the biological plausibility of backpropagation in the introduction may be too weak and points out that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to strengthen the statement. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the statement and provide more robust evidence or reasoning to support it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the introduction regarding the biological plausibility of backpropagation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the weakness of the statement and the need to provide more robust evidence or reasoning to support it. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation in the introduction is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the introduction regarding the biological plausibility of backpropagation. It points out that the statement may be too weak and that it is widely accepted that backpropagation is biologically implausible. This feedback is 3 as it highlights an area where the authors may need to provide more robust evidence or reasoning to support their claims. However, the comment could be more helpful if it suggested specific ways to strengthen the statement or provided examples of alternative perspectives or evidence that could be considered. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the modulator is heuristically designed and questions whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the scalability issue or suggestions for improving the modulator design. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of scalability in the modulator design, specifically questioning whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the scalability issue and the potential need for hyperparameter tuning, but without clear grounding, the authors cannot confidently determine which part of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the modulator is heuristically designed and questions whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the modulator design, suggesting that it might require tedious hyperparameter tuning for diverse training data. This is a relevant concern that could impact the performance and generalizability of the model. However, the comment lacks specific guidance or suggestions on how to address this issue or improve the scalability of the modulator. Without actionable advice or detailed feedback, the authors are left with a general observation but no clear path forward. Therefore, the comment is 3, as it points out a potential weakness but does not provide enough detail for the authors to effectively improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that f_R and f_P can be adapted over time but highlights the incorporation of domain knowledge into their structure. It suggests that a less informed f_R/f_P might require an impractical amount of data to learn. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to consider. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of domain knowledge being incorporated into the structure of the experiments, specifically mentioning f_R and f_P. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the impractical amount of data required for a less informed f_R/f_P. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments performed here incorporate a great deal of domain knowledge into their structure, which could require an impractical amount of data to learn for a less informed f_R/f_P. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that f_R and f_P can be adapted over time but highlights the incorporation of domain knowledge into their structure. It suggests that a less informed f_R/f_P might require an impractical amount of data to learn. While the comment identifies a potential issue with the experiments, it lacks specific suggestions or guidance on how the authors might address this concern. The feedback is 3 as it points out a potential limitation, but it does not provide actionable advice or detailed insights for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the connection between the necessary conditions and generalization bounds, suggesting that the constructions of ReLU networks for robust memorization may not lead to robust generalization. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the connection between necessary conditions and generalization bounds, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of overparameterization and its implications on generalization bounds, suggesting that the necessary conditions may have stronger implications if they are connected to generalization bounds. It mentions that the constructions of ReLU networks for robust memorization may not lead to robust generalization, but does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the sections discussing overparameterization and generalization, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in its concern about the connection between necessary conditions and generalization bounds, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the connection between overparameterization and generalization bounds, suggesting that the necessary conditions may have stronger implications if they are connected to generalization. The reviewer acknowledges that the authors acknowledge this in the conclusion but considers it a serious question. However, the comment lacks specific examples or detailed reasoning to support the claim that the constructions of ReLU networks for robust memorization would not lead to robust generalization. Without such evidence or references, the claim remains 3, as it provides a logical basis but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the connection between overparameterization and generalization bounds. It suggests that the necessary conditions may have stronger implications if they are connected to generalization bounds, and points out that the constructions of ReLU networks for robust memorization may not lead to robust generalization. While the comment acknowledges that the authors acknowledge this in the conclusion, it highlights a serious concern that the authors should address. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it raises an important point, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. However, it does not provide specific guidance on how the authors should address this issue or what additional exploration is needed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the generalizability of their results. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s exploration of the implications of the proposed method for other NLP tasks, suggesting that the paper\"s generalizability is somewhat limited due to this lack of exploration. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which somewhat limits its generalizability. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. This observation highlights a potential weakness in the generalizability of the results, which could impact the paper\"s impact and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional exploration could be conducted. While it points out an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed sample selection mechanism is not clearly explained in terms of how it preserves the label distribution. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific ways to clarify the mechanism or suggesting alternative explanations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed sample selection mechanism, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding how the mechanism preserves the label distribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the proposed sample selection mechanism in preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the proposed sample selection mechanism, noting that it is not clear how it preserves the label distribution. This feedback is 3 as it points out a potential weakness in the paper that the authors should address to improve clarity and understanding. However, the comment lacks depth and does not provide specific suggestions or examples on how to clarify the mechanism or what aspects of the explanation are unclear. While it highlights an area for improvement, it does not fully guide the authors on how to address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any explicit or implicit suggestions for improvement or additional models to consider. The authors are left without guidance on how to enhance the scope or relevance of their evaluation. As a result, the comment lacks actionable advice, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the results and analysis, noting that they are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not specify which part of the paper this critique pertains to, such as the results or analysis sections. Without explicit references to sections or figures, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the evaluation are lacking or how the authors could expand their analysis. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the paper\"s evaluation, noting that it only considers two relatively old and small models. While this observation highlights a potential weakness in the scope and relevance of the analysis, it does not provide specific suggestions or guidance on how the authors might expand their evaluation to include more diverse or contemporary models. The feedback identifies an area for improvement but lacks actionable advice or detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS, particularly when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this suggestion or what specific conditions should be considered. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. However, it does not specify which part of the paper this discussion pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion that KD and LS are equivalent under certain conditions, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that KD can be considered a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. It provides a specific example of when this equivalence occurs, which is when the teacher network is uniformly distributed and the temperature is set at 1. This feedback is 3 as it offers a potential insight into the relationship between KD and LS, which could be useful for the authors to explore further. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate this understanding into the paper. Overall, the comment offers a valuable perspective but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include results on largescale datasets, such as ImageNet, to verify the effectiveness of their proposed method. This feedback is explicit and provides a clear action for the authors to take, which is to include results on larger datasets. The comment also mentions that competing dynamicpruning methods are outdated, implying that the authors should consider more recent works. However, it does not specify which recent works should be included or how to incorporate them into the paper. While the action is clear, the lack of detailed guidance on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.3. 2021\" and \"Competing dynamicpruning methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of results on largescale datasets, such as ImageNet, and the need to consider more recent works on dynamicpruning methods. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"competing dynamicpruning methods are kind of outofdate\" and suggests that more recent works should be included. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the current methods are considered outdated. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include results on largescale datasets, such as ImageNet, to verify the effectiveness of their proposed method. It also points out that competing dynamicpruning methods are outdated, implying that the authors should consider more recent works. This feedback is clear and constructive, as it guides the authors on how to enhance their experimental evaluation and demonstrate the relevance and impact of their method. However, the comment could be more helpful if it provided examples of recent works or specific suggestions on how to incorporate them into the paper. Overall, the comment is 4 as it directs the authors toward improving their experimental evaluation and methodology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to provide an explanation for why the performance degrades when using additional information about missing, wrong, or redundant information. This is a clear and direct request, giving the authors a specific action to take. The comment is specific in its request for an explanation, which provides a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why the performance degrades when using additional information about missing, wrong, or redundant information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance degradation when using additional information about missing, wrong, or redundant information. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance degradation when using additional information about missing, wrong, or redundant information. This is a clear and actionable request for the authors to provide an explanation or analysis of this phenomenon. By addressing this question, the authors can improve the clarity and robustness of their results. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of similar cases where performance degradation was observed. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It raises a valid point about the interest in this particular dimension of difficulty, but it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment lacks actionable details, such as recommending alternative methods or explaining why this choice might be problematic. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of CIFAR images as backgrounds, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind this choice and seeks clarification on why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that this choice is not wellmotivated and raises a valid point about the interest in this particular dimension of difficulty. However, the comment lacks specific examples or references to support the claim that this choice is not wellmotivated. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 3, as it provides a logical argument but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not wellmotivated. It raises a valid point about the interest in this particular dimension of difficulty, which could be an important consideration for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide a more compelling justification for their choice. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy in the paper\"s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds the flat minima, the analysis about flatness is missing. The reviewer suggests that the authors should provide an analysis of the losses of the noiseinjected models after training to substantiate their claim. This feedback is explicit and provides a clear action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the analysis about flatness\" and \"the loss used for training base model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the losses of the noiseinjected models after training to substantiate the claim about the flatness of the minima found by the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis about the flatness of the minima is missing, and it suggests that minimizing the averaged loss across the noiseinjected models does not ensure the flatness of the minima. The reviewer provides a logical reasoning by explaining that the loss used for training the base model is the averaged loss for the noiseinjected models, and that the convergence analysis on this loss does not guarantee the flatness of the minima. However, the comment lacks specific examples or references to support the claim that the analysis on the losses of the noiseinjected models after training is necessary to substantiate the claim about the flatness of the minima. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds the flat minima, the analysis about flatness is missing. The reviewer provides a logical explanation of why minimizing the averaged loss across the noiseinjected models does not ensure the flatness of the minima, and suggests that the authors should provide an analysis of the losses of the noiseinjected models after training to substantiate their claim. This feedback is clear and actionable, guiding the authors to address a crucial aspect of their argument that could significantly impact the paper\"s credibility. Therefore, the comment is 4, as it provides a concrete direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to make the text inside the figure and labels roughly the same size as the manuscript text. This is a clear and direct action that the authors can take to improve the readability of their figures. The comment provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text inside the figure and the labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the size of the text compared to the manuscript text. This provides clear guidance on how to improve the readability of the figures. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and labels is too small to read without zooming, suggesting that it should be roughly the same size as the manuscript text. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of the figures, noting that the text inside the figure and the labels are too small to read without zooming. It provides a clear and actionable suggestion to make the text roughly the same size as the manuscript text. This feedback is valuable as it directly addresses a usability concern that could impact the accessibility and comprehension of the figures. However, the comment could be more helpful if it included examples or additional guidance on how to achieve this improvement. Overall, the comment is 4 as it effectively points out a specific issue and offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This provides a direct and concrete action for the authors to take, which is to revise the introduction to clarify the motivation. The comment also implies that the current introduction may be confusing or difficult to understand, which further guides the authors on what aspects need improvement. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the motivation and the need for a revised introduction to make the paper easier to follow. This provides clear guidance on what aspects of the paper need improvement, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the motivation is not clear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or justification to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of clarity in the motivation. It suggests that the introduction should be revised to make the paper easier to follow, which is a crucial aspect of any scientific paper. However, the comment does not provide specific guidance on how to revise the introduction or what aspects of the motivation are unclear. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but does not offer actionable steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to validate the alignment or what specific steps to take to ensure its validity. As a result, the authors are left without any clear direction on how to improve their draft in this area. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the alignment of relabeled reward data with human annotator judgments, indicating that this alignment is insufficiently validated. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of insufficient validation, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the insufficient validation of the alignment between relabeled reward data and human annotator judgments. This is a critical point that could impact the reliability and robustness of the results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional validation methods or providing examples of how to validate the alignment. Without actionable advice, the authors are left with a clear area for improvement but without a clear path forward. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model is somewhat complicated and recommends improving its presentation in Section 4, possibly by referring to the supplement. It also provides specific suggestions for enhancing the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These actions are explicit and concrete, providing clear guidance on how to improve the presentation of the model. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, such as suggesting the use of notation and breakout diagrams to enhance the presentation of the model. This level of detail provides the authors with a clear understanding of what changes are needed to improve the presentation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model is somewhat complicated and recommends improving its presentation in Section 4. It provides a specific suggestion to replace natural language descriptions with notation and adds breakout diagrams to illustrate the attention mechanisms. This claim is 3 as it offers a logical suggestion for improving the presentation, but it lacks detailed justification or examples to fully substantiate the claim. The authors might need to explore the specific benefits of using notation and diagrams to enhance the presentation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of the model in Section 4, noting that it is somewhat complicated and requires careful reading. It provides specific suggestions for improving the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These suggestions are actionable and can help the authors enhance the clarity and accessibility of their presentation. However, the comment could be more helpful if it explained why these changes are necessary or provided examples of how they might be implemented. Overall, the comment is 4 as it offers clear and constructive guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their work. The authors are left to infer that they need to expand their experiments to more molecules or consider alternative approaches for training. While the comment highlights a potential limitation, it lacks concrete suggestions for improvement, making it 3.", "grounding_specificity_rationale": "The comment addresses the limited scope of the experiments conducted in the paper, specifically mentioning that only a few molecules are tested and that indistribution testing is provided for these samples. However, it does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its critique of the limited scope of the experiments and the potential limitation of the method if it requires training for each molecule individually. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically noting that the experiments are conducted on a limited number of molecules and only provide indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. This feedback is 3 as it points out a potential weakness in the paper\"s scope and suggests a direction for improvement. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their experiments to include more molecules. While it highlights an area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the symbols or how to make them more accessible to the reader. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the complexity of the symbols used in the paper, suggesting that they are difficult to understand. However, it does not specify which symbols or parts of the paper are causing this issue, making it difficult for the authors to pinpoint the exact areas that need attention. The comment lacks specificity regarding which symbols or sections are problematic, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the complexity of the symbols used in the paper, suggesting that they are difficult to understand and take a lot of time to comprehend. While this feedback identifies a potential weakness, it lacks specificity and does not provide actionable guidance on how to simplify the symbols or improve their clarity. Without detailed suggestions or examples, the authors may struggle to address the issue effectively. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the origin of the test data in Figure 3 and whether there is a ground truth. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the source of the test data and the existence of a ground truth, but it lacks specific instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the origin of the test data and the existence of a ground truth, providing clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The comment consists of questions about the origin of the test data and the existence of a ground truth in Figure 3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the origin of the test data in Figure 3 and whether there is a ground truth. This is a relevant point that could help the authors clarify their methodology and ensure the validity of their results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide explicit instructions or concrete steps for the authors to take. It lacks actionable details, such as recommending specific modifications or experiments to address this concern. As a result, the authors are left without a clear path forward, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, such as specific experiments or sections where the results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the role of periodicity in the results, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides a logical basis for the question but lacks sufficient evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve their results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending experiments or modifications to the model. While it provides a thoughtprovoking insight, it could be more helpful with additional actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper is poorly written and possibly rushed, making it difficult to read. It specifically mentions issues with presentation and formatting, particularly in figures and tables. However, the comment does not provide any specific guidance on how to improve the writing or formatting. It lacks concrete suggestions or examples of what changes could be made to enhance the clarity and readability of the paper. As a result, the authors are left without actionable steps to take in order to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of the paper\"s writing quality, specifically mentioning that it is not wellwritten and possibly rushed, making it difficult to read. It also points out issues with presentation and formatting, particularly in figures and tables. However, the comment does not specify which parts of the paper are problematic or how the formatting could be improved. While the authors might have an idea of where these issues are, the lack of specificity makes it challenging for them to address the feedback effectively. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, and it is not specific in detailing what needs to be improved. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that the paper is poorly written and possibly rushed, making it difficult to read. It also mentions issues with presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or references to specific sections or examples, the authors may find it challenging to understand and address the feedback effectively. Therefore, the claim is considered 2, as it provides some indication but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s writing quality, suggesting that it is poorly written and possibly rushed, making it difficult to read. It also points out issues with presentation and formatting, particularly in figures and tables. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are informed of the problem but are not provided with actionable steps to improve the writing or formatting. Therefore, the comment is 3, as it provides insight into potential weaknesses but does not offer detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the introduction to orthogonality in Part 2 could be more detailed. This provides a clear and direct action for the authors to take, which is to expand or clarify the introduction to make it more comprehensive. The comment is specific in identifying the need for more detail, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Part 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction to orthogonality. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific reasoning or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the introduction to orthogonality in Part 2. It suggests that the introduction could be more detailed, providing a clear direction for the authors to enhance their draft. However, the comment lacks specific guidance on what aspects of the introduction need more detail or how to achieve this improvement. While it points out a potential weakness, it does not offer actionable steps or examples to help the authors address it effectively. Therefore, the comment is 3, as it provides a general direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should highlight the novelty of its result in relation to prior work, particularly regarding the removal of double descent in certain anisotropic settings. It acknowledges that the authors may have made a correct observation but points out the need for better communication of this contribution. However, the comment does not provide specific guidance on how to highlight the novelty or what aspects of the paper should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the novelty of their result in relation to prior work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical results of samplewise multiple descent in linear regression, which provides a clear reference point for the authors to identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper should highlight the novelty of its result in relation to prior work, particularly regarding the removal of double descent in certain anisotropic settings. The comment is specific in its critique of the paper\"s contribution and the need for better communication of the novelty. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s main contribution is the result that optimal regularization can remove double descent even in certain anisotropic settings. However, the comment lacks specific references or detailed reasoning to support this claim. It mentions prior work on samplewise multiple descent in linear regression but does not provide specific examples or detailed analysis of how the current work builds upon or differs from these prior results. The lack of detailed evidence or references makes the claim 3, as the authors would need to further explore the literature to fully understand and address the reviewer\"s point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s contribution, noting that the main result about removing double descent in certain anisotropic settings may not be novel if prior work has already shown samplewise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the particular techniques and tools used in the paper, but suggests that the paper should better highlight the novelty of its result in relation to prior results. This feedback is 3 as it points out a potential weakness in the paper\"s contribution and suggests a way to improve the clarity of its novelty. However, the comment could be more helpful if it provided specific guidance on how to better communicate the novelty or if it referenced specific prior works that might be relevant. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed methods, contrastive training objective and contrastive search, are independent and lack a clear connection on both the intuition and the algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to integrate the methods or improve their connection. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the proposed methods, specifically contrastive training objective and contrastive search, and notes that they are independent methods with little inner connection on both the intuition and the algorithm. However, it does not specify which part of the paper these methods are discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of lack of connection between the methods, but it is 1 as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed methods, contrastive training objective and contrastive search, are independent and lack a clear connection on both the intuition and the algorithm. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed methods, contrastive training objective and contrastive search, noting that they are independent and lack a clear connection on both the intuition and the algorithm. This feedback is 3 as it points out a potential weakness in the paper, but it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. While it highlights an area for improvement, the comment could be more helpful if it offered specific suggestions or examples of how to integrate the methods or improve their connection. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern regarding the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the claim is to establish the paper as a foundation model, the authors should clarify this and demonstrate a future useful application. While the comment implies that the authors should provide a comparison and justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the goal of the paper and the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. It also suggests that if the claim is to establish the paper as a foundation model, the authors should clarify this and demonstrate a future useful application. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the claim is to establish the paper as a foundation model, the authors should clarify this and demonstrate a future useful application. While the comment identifies a potential issue with the paper\"s goal and suggests a need for comparison and justification, it lacks specific examples or references to support the claim that existing DAS earthquake detectors exist. This makes the claim 3, as the authors would need to infer the need for comparison and justification based on the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s goal, noting the absence of a comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the lack of justification for the benefits of the proposed method over these existing methods. It suggests that if the paper is to establish a foundation model, the authors should clarify this and demonstrate a future useful application. This feedback is clear and actionable, as it points out a critical area for improvement in the paper\"s justification and comparison with existing work. However, the comment could be more helpful if it provided specific suggestions on how to address these issues, such as which aspects of the comparison or justification are missing. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It asks whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. While the comment implies that the authors should consider this limitation and potentially explore alternatives, it does not provide explicit instructions or concrete suggestions on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider extending the approach to longer subsequences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its inquiry about whether the limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It does not present an opinion, judgment, or suggestion that requires verification. It is a request for clarification and does not contain subjective claims or statements that require evidence or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a valid concern about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It questions whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. This feedback prompts the authors to consider whether their approach is limited by the specific windowing method used and whether it could be extended to accommodate longer sequences. While the comment identifies a potential weakness, it does not provide specific suggestions or guidance on how to address this limitation or explore alternative approaches. Therefore, the comment is 3, as it points out an area for improvement but lacks detailed guidance for the authors to act upon."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps to consider. The authors are left without any direction on how to incorporate this suggestion into their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the inclusion of AccNet in a larger predictor. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation. It suggests that it might make sense to learn AccNet in this context. However, the comment lacks depth and does not provide any specific guidance or suggestions on how the authors might incorporate this idea into their work. While it identifies a potential area for improvement, it does not offer actionable steps or detailed reasoning to support the authors in making changes. Therefore, the comment is 3, as it points out a potential area for enhancement but does not fully guide the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or expand the testing to other datasets. The comment lacks actionable guidance, such as recommending additional datasets to test on or proposing strategies for broadening the evaluation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the proposed metric is only tested on a single dataset, which is a specific issue. However, it does not specify which dataset or which part of the paper discusses this metric, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue with the testing of the metric, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed metric is only tested on a single dataset, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the validity of the metric. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the significance of this observation. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment points out a limitation in the paper, specifically that the proposed metric is only tested on a single dataset. This is a relevant observation that could impact the generalizability and applicability of the metric. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue, such as recommending additional datasets for testing or discussing potential implications of this limitation. While it identifies a weakness, the feedback does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the setting but may not be entirely sure of the exact details to address. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first three paragraphs of section 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting needs to be spelled out more clearly and suggesting that the authors may be trying to present something in greater generality than what is actually presented, which muddles the exposition. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors may find it challenging to understand the exact issue without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It suggests that the authors may be presenting something in greater generality than what is actually shown, which muddles the exposition. This feedback is clear and actionable, as it points out a specific area where the authors need to clarify their work to improve the reader\"s understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the setting or what specific aspects need to be addressed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the convincing nature of the experiments and questions the choice of the old baseline, R3D and C3D. It suggests that the authors should consider using more recent baselines or 3D CNNs, such as X3D, SlowFast, etc., to test the proposed method. The comment implies that the authors should compare their method with these baselines to demonstrate its advantage. While the action is implicit, it is clear that the authors need to address these points to improve the draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of baseline and suggesting that the proposed method should be tested against more recent 3D CNNs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the convincing nature of the experiments and suggests that the authors should consider using more recent baselines or 3D CNNs, such as X3D and SlowFast. The comment provides a logical reasoning by pointing out that many papers have proposed methods for reducing computation complexity in 3D CNNs. However, it lacks specific examples or references to these papers, which would strengthen the claim. The suggestion to compare the proposed method with these baselines is a valid point, but the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experiments, questioning the choice of baseline and suggesting that the proposed method should be tested against more recent 3D CNNs. It also points out that many papers have proposed methods for reducing computation complexity in 3D CNNs, such as X3D and SlowFast. This feedback is 3 as it highlights an area where the authors could improve their work by expanding the experimental comparison. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or what aspects of the proposed method should be compared with these baselines. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the proposed method\"s performance at low bitrates, suggesting that it is close to the baselines in this range. It also asks for clarification on the precise bitrate range used for BDrate comparison and suggests discussing a related work about implementing contentadaptive algorithms in learned video compression. While the comment provides explicit actions\u2014asking for clarification and suggesting a related work for discussion\u2014it does not offer specific guidance on how to implement the contentadaptive algorithm or what aspects of the method need improvement. The authors are given clear directions but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"BDrate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the method\"s performance at low bitrates and suggests discussing a related work about implementing contentadaptive algorithms in learned video compression. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s performance at low bitrates, suggesting that it is close to the baselines in this range. The reviewer asks for clarification on the precise bitrate range used for BDrate comparison and suggests discussing a related work about implementing contentadaptive algorithms in learned video compression. While the comment identifies a potential issue with the method\"s performance, it lacks specific examples or detailed reasoning to support the claim. The suggestion to discuss a related work is helpful but does not fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but requires further elaboration to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it performs stronger at high bitrates but is close to the baselines at low bitrates. This is a valuable observation that prompts the authors to reconsider the method\"s performance range and potentially adjust their claims. Additionally, the comment suggests discussing a related work about implementing contentadaptive algorithms in learned video compression, which could provide a valuable context for the authors to consider. While the comment does not offer specific suggestions on how to address the issue or implement the contentadaptive algorithm, it provides clear and actionable feedback that can guide the authors in improving their draft. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should make this distinction, it does not provide explicit instructions on how to do so or what specific aspects of the paper need to be revised. The action is implicit and somewhat vague, as the authors need to infer that they need to make a distinction but are not given specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide detailed guidance on how to make this distinction. The authors can infer that it relates to the discussion or analysis of the results, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would benefit the paper. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in making the suggested distinction. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While this feedback identifies a potential area for clarification and differentiation, it lacks specific guidance on how to achieve this distinction or what aspects of the paper need to be revised. The comment does not provide detailed suggestions or examples of how to effectively distinguish these concepts, leaving the authors with a general direction but without actionable steps. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what additional analysis should be conducted. The comment lacks concrete details or specific actions for the authors to take, leaving them uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not specify which tasks, previous works, or selfimplemented baselines are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what additional analysis should be conducted or how it could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks specific references or detailed analysis to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide specific examples or details about which tasks or analyses are lacking, nor does it offer suggestions on how the authors might address these issues. The comment lacks actionable feedback or guidance, leaving the authors without a clear understanding of what improvements are needed or how to implement them. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a significant issue with the theoretical result, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates to existing rates in the literature. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this comparison or what specific rates should be compared. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the result only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. Additionally, it suggests that the authors should compare their rates to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper provides utility guarantees only when the features and noise are Gaussian, which is a strong requirement on the data. The reviewer suggests that this assumption is not necessary for previous algorithms and that the authors should compare their rates to existing rates in the literature. The claim is 3 as it provides a logical reasoning for the requirement and suggests a potential area for improvement. However, it lacks specific examples or references to existing works that support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical result of the paper, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates to existing rates in the literature, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific examples of existing works or rates that should be compared, or if it offered guidance on how to conduct this comparison. Overall, the comment is 3 as it highlights a critical area for improvement but lacks detailed guidance on execution. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This implies that the authors should include such a comparison in their paper. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects to focus on. While the action is implied, it is not as concrete as it could be, as the authors are left to infer the details of the comparison themselves. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting the need for a comparison, but without clear guidance on where to place it, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be useful to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison that could enhance the paper\"s contribution. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, such as which specific aspects of the original approach should be compared or how to interpret the results. While it points out a potential improvement, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it implies that the authors should include additional experiments, it does not specify which specific baselines or comparisons should be included. The action is clear but lacks concrete details on which additional experiments to conduct or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it references specific works that focus on similar questions, it does not provide detailed reasoning or evidence to support why these additional comparisons are necessary or how they would enhance the paper. The reference to specific works is a helpful starting point, but the comment lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but requires more detailed explanation to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section, suggesting that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method. It references specific works that focus on similar questions, providing a clear direction for the authors to expand their experimental analysis. However, the comment could be more helpful by offering specific suggestions on which additional baselines or comparisons to include, or how to present the results in a more comprehensive manner. Overall, the feedback is 3 as it points out a gap in the experimental section but lacks detailed guidance on how to address it fully."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This is a clear and explicit action for the authors to take, as it provides a specific direction for improving the presentation of results. The comment is concrete because it specifies the exact changes needed to be made, such as presenting average results on the test set and defining error bars. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the presentation of results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not present convincing results because it only reports the best results on the development set with hyperparameter search and model selection on the development set. The reviewer suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it logically argues that presenting results on the test set would provide a more comprehensive evaluation. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, noting that the authors only report the best results on the development set with hyperparameter search and model selection on the development set. It suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of results, which could enhance the credibility and impact of the paper. However, the comment could be more helpful if it explained why presenting results on the test set is important or how it would impact the conclusions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors provide more values of the parameter \u03b1, specifically suggesting values of 1e2 and 1e3. This guidance is clear and concrete, as it specifies exactly what additional values should be included and why (to bridge the gap between 1e4 and 1e1). The authors know exactly what changes to make to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficient ablation study on \u03b1 and recommends providing more values of \u03b1, such as 1e2 and 1e3. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ablation study on \u03b1 is insufficient, as it only considers values of 1e4, 1e1, and 5e1 with a large gap between 1e4 and 1e1. The reviewer recommends providing more values, specifically 1e2 and 1e3, to bridge this gap. This claim is 3 as it logically suggests that more values would provide a better understanding of the parameter\"s impact. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation study on the parameter \u03b1, noting that it only considers values of 1e4, 1e1, and 5e1 with a large gap between 1e4 and 1e1. The reviewer recommends providing more values, specifically 1e2 and 1e3, to bridge this gap and improve the understanding of the parameter\"s impact. This feedback is clear and actionable, as it directly suggests specific values to include in the ablation study. By addressing this point, the authors can enhance the robustness and comprehensiveness of their analysis. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the questions are explicit, the comment lacks concrete guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the dataset, but the specific actions to take are not clearly stated. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the dataset and methodology sections. The comment is specific in detailing what needs to be addressed, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the questions are relevant and could guide the authors in improving their draft, the comment lacks specific suggestions or actionable advice on how to address these issues. The authors are left with a clear understanding of what needs to be clarified but without detailed guidance on how to implement these improvements. Therefore, the comment is 3, as it identifies areas for improvement but does not provide comprehensive guidance for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, stating that it distracts from the main point of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes, if any, should be made to the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the distraction but lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the zeroshot version and its connection to density estimation are distracting from the main point of the paper, which is about learning effective prototypes for fewshot learning. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks specificity and does not guide the authors on how to address the issue or improve the clarity of their work. As a result, it offers limited value to the authors in terms of enhancing the draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the filtering process used to create the Arabic climate change QA dataset is lacking and that more information on the translation and filtering methodology is needed to assess the dataset quality. This provides a clear and direct action for the authors to take, which is to provide additional details on the filtering process. The comment is specific about what information is missing and how it could be improved, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the creation of the Arabic climate change QA dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking, namely details on the filtering process used to create the dataset and the translation and filtering methodology. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the filtering process used to create the Arabic climate change QA dataset is lacking and that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without additional context or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of details on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the transparency and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment results could be enriched by adding attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that these additions would improve the results, it does not provide specific guidance on how to implement these changes or what specific types of attacks or threshold analyses should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to enhance their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or figures where these additions could be made. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that these additions would improve the results. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered 2, as it provides a general direction but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the experiment results by suggesting the addition of attacks with different strengths and an exploration of how different thresholds influence detection performance. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experimental analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or what specific types of attacks or threshold analyses should be considered. Overall, the comment is 4 as it directs the authors toward meaningful enhancements to their experimental results, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer notes that this is different from Figure 4, as the discriminator is coadapting with the generator, which could lead to getting stuck at a local optimum. While the comment provides a clear action\u2014to evaluate the claim by training a discriminator\u2014it does not offer specific guidance on how to implement this evaluation or what metrics to use. The authors are left to infer the details of execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the claim to reduce exposure bias and the need to train a discriminator on generations from the learned model. The comment provides a clear direction for the authors to follow, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer explains that this is different from Figure 4, as the discriminator is coadapting with the generator, which could lead to getting stuck at a local optimum. This claim is 3 as it provides a logical reasoning for the need to evaluate the claim and explains the difference between Figure 1 and Figure 4. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for evaluating the claim of the paper, which is to train a discriminator on generations from the learned model to confirm if the paper successfully reduces exposure bias. The reviewer explains the difference between Figure 1 and Figure 4, noting that the former involves coadaptation between the discriminator and generator, while the latter is a static representation. This feedback is valuable as it guides the authors on how to test their claim and provides a specific method for evaluation. However, the comment could be more helpful if it offered additional insights or examples on how to implement this evaluation or what metrics to use. Overall, the comment is 4 as it provides a clear direction for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. While the action is implicit, it is clear and concrete, as it specifies what additional information is needed to be included in the paper. The authors know exactly what to do to address the comment, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance difference resulting from using different image sizes and variations of ResNets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically regarding the impact of the experimental setup on performance. However, the comment lacks depth and does not provide specific guidance on how to present this information or what specific aspects of the performance should be highlighted. While it points out a potential gap, it does not offer detailed suggestions or examples to help the authors address it effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to present and describe the Algorithm in detail, which is helpful for understanding the proposed method. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the algorithm is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to present and describe the algorithm in detail, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and comprehensibility of their work. By addressing this suggestion, the authors can improve the reader\"s ability to understand and evaluate the proposed method. However, the comment could be more helpful if it included specific examples or guidance on how to present and describe the algorithm in detail. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper. While it implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a runtime comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the comparison could be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a runtime comparison, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific comparison that could enhance the paper\"s contribution. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. While it points out a potential improvement, it does not fully support the authors in making that enhancement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, it does not provide any explicit guidance or suggestions on how to improve the organization of the prompts. The authors are left to infer that they need to reorganize the prompts, but without specific instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 6, 7,\" providing full grounding as it allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the organization of prompts, noting that all sentences are squeezed together. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, the comment does not provide any specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is 3 as it points out a clear area for improvement in the presentation of the prompts. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the organization. While it highlights a potential problem, it does not offer actionable guidance or examples for the authors to enhance the clarity and readability of their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is unclear. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to improve the clarity of the figures and label the modules, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"CMAF, L_BT, VoLTA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the clarity of the figures, particularly the confusion regarding the relation between subfigures in Figure 2 and the lack of labeling for certain modules. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning Figure 2 and the confusion regarding the relation between subfigures. It also notes that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the need for clarification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. This feedback is clear and actionable, as it provides the authors with specific areas to improve the clarity and labeling of their figures. By addressing these issues, the authors can enhance the readability and comprehension of their paper. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar issues have been addressed in other works. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. While these questions imply that the authors should investigate the effect of image number and provide an explanation for BYOL, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an analysis and provide an explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific questions about the cluster structure and its impact on model performance, as well as the first appearance of BYOL in the abstract. However, it does not explicitly mention which part of the paper these questions pertain to, such as specific sections or figures. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for an explanation of BYOL and the impact of the number of images on performance, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the impact of the number of images on model performance and suggests that more training images might worsen performance. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The comment also requests an explanation of BYOL in the abstract, but it does not explain why this explanation is necessary or how it would impact the paper. Without additional context or evidence, the claims are difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of images on model performance and suggests that more training images might worsen performance. It also requests an explanation of BYOL in the abstract, which is a relevant point for clarity. While the comment identifies potential areas for improvement and provides a clear direction for the authors to explore, it lacks specific guidance or examples on how to conduct the analysis or explain BYOL. This limits the comment\"s helpfulness, as it provides some direction but not enough detail for the authors to fully address the feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information to address the reviewer\"s concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of understanding the effectiveness of the method, particularly regarding the L_pixel component. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors provide stronger arguments or intuitions to explain why the method works, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the understanding of why the method works, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. However, the comment does not provide specific examples or references to support the claim that the current explanation is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the explanation of why the method works, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial to enhance the understanding of the method. While the comment highlights an important area for improvement, it lacks specific guidance on how to address this issue or what kind of arguments or intuitions would be most effective. The feedback is 3 as it points out a potential weakness but does not provide detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and points out that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to improve the dataset. The action is implicit and somewhat vague, as the authors can infer that they need to consider the size and diversity of their training data but are not given specific instructions on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and compares them to the typical training data for LLMs, which is typically on trillions of tokens. The comment suggests that the dataset needs to be massive to cover varied domains. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. The authors can infer that it relates to the dataset used for training, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing the concern about the training data. This aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, comparing them to the typical training data for LLMs, which is typically on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that 44k dialogues are insufficient. This makes the claim 3, as the authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, given that LLMs are typically trained on trillions of tokens. The comment suggests that the dataset needs to be massive to cover varied domains, which is a critical point for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve their dataset. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what alternative metrics or approaches might be more suitable. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of binary classification as a baseline metric and expresses skepticism about its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the binary classification are problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the use of binary classification as a baseline metric, suggesting that it may not be adequate for assessing models\" understanding of finegrained errors like technique errors. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to alternative metrics or methods that could be used instead. As a result, the claim is not 5, making it difficult for the authors to understand and address the concern. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not provide any specific suggestions or alternatives for how the authors might address this issue or improve their baseline metrics. The comment highlights a potential weakness in the paper but lacks actionable guidance, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or details about what is unclear or how the writing could be improved. The comment lacks explicit guidance on how to address the issues, leaving the authors without a clear understanding of what changes to make. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide examples of what needs to be clarified. Without specific references to sections, figures, or other elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing need improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not provide specific examples or detailed reasoning to support why the writing is unclear or how it could be improved. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing should be improved, indicating that some points in the paper are unclear. However, it does not provide specific examples or detailed feedback on what aspects of the writing are unclear or how they could be clarified. Without this information, the authors are left without actionable guidance on how to improve their draft. The comment lacks depth and specificity, making it 2 as it does not assist the authors in making significant improvements to their writing. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should use other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback provides a clear and explicit action for the authors to take, which is to consider using additional metrics for evaluating their results. The suggestion is concrete, as it specifies a specific metric to use, making it easy for the authors to implement the change. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation of results, but the lack of explicit reference makes it weakly grounded. The comment is specific in suggesting the use of BERTScore as an alternative metric, providing some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, the comment does not provide any reasoning or evidence to support why BERTScore is a better choice or why the current metrics are insufficient. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification to be 5.", "helpfulness_rationale": "The review comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback is 3 as it identifies a potential area for improvement by suggesting the use of a different metric. However, the comment lacks depth and does not provide detailed guidance on why BERTScore might be a better choice or how it could be integrated into the evaluation process. Additionally, it does not address other potential metrics or discuss the implications of using a different metric. While the suggestion is a step in the right direction, it could be more helpful with additional context and explanation. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, specifically mentioning metrics like MMLU and Big Bench for language generation. While the comment does not explicitly instruct the authors to conduct this comparison, it provides a clear direction for how to enhance the evaluation of their metric. The action is implicit but concrete, as it specifies the metrics to compare and the conditions under which SynTextBench should be used. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"large amount of work on LLM evaluation\" and references specific metrics like MMLU and Big Bench, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of SynTextBench to other metrics proposed in the literature and how to use SynTextBench under specific conditions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there has been a large amount of work on LLM evaluation and that some of the metrics do not satisfy the proposed desiderata. It also mentions that it would be beneficial to compare SynTextBench to other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. The comment provides a logical reasoning for why this comparison is important, but it lacks specific examples or references to support the claim that some metrics do not satisfy the desiderata. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to compare their SynTextBench metric to other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. This feedback is valuable as it guides the authors in demonstrating the strengths and limitations of their metric in the context of existing evaluations. By addressing this suggestion, the authors can enhance the clarity and robustness of their evaluation, which is essential for the credibility and impact of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific conditions should be considered. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment points out that the writing and annotations are difficult to follow, but it does not provide any specific guidance on how to improve them. It lacks actionable advice or suggestions on how to make the writing and annotations clearer or more accessible. Without concrete steps or examples, the authors are left without a clear understanding of what changes to make to enhance the clarity of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations,\" but it does not specify which parts of the paper are affected by this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the writing and annotations are difficult to follow. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing and annotations are difficult to follow. However, it does not provide any specific examples or detailed reasoning to support this claim. Without such evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a general issue with the writing and annotations being difficult to follow. However, it lacks specificity and does not provide any actionable suggestions or examples on how to improve the clarity or accessibility of the paper. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of their writing need attention or how to enhance the annotations. As a result, the comment is not helpful, as it does not offer any constructive feedback for improvement. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should provide an explanation or analysis to clarify this discrepancy. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. The comment does not present any claims or opinions but rather seeks clarification or explanation. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This is a relevant observation that could prompt the authors to reconsider their results and provide a more comprehensive analysis. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of discussion on the scalability bounds of FedDES, specifically mentioning the need for a clear discussion on memory requirements and computational complexity. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should include a discussion on scalability bounds, but the comment lacks concrete suggestions on what specific aspects to cover or how to present this information. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"upper limits of FedDES\"s scalability\" and \"memory requirements or computational complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the scalability bounds and memory/computational complexity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a thorough exploration of the upper limits of FedDES\"s scalability and does not provide a clear discussion on memory requirements or computational complexity. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of a thorough exploration of the scalability bounds of FedDES. It points out that there is no clear discussion on memory requirements or computational complexity, which are crucial aspects of the system\"s performance. This feedback is valuable as it highlights an area where the authors can enhance their draft by providing a more comprehensive analysis of the system\"s scalability. However, the comment could be more helpful if it offered specific suggestions on how to address these gaps or provided examples of how similar studies have approached this issue. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that needs further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the setting of Unsupervised Online Adaptation is strange, as it requires a training set, including documents, queries, and labels. The reviewer suggests that this is not \"Unsupervised\" because the training set also requires annotations. While the comment identifies a potential issue with the labeling process, it does not provide explicit guidance on how to address this issue or suggest specific changes to improve the clarity or accuracy of the description. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the nature of the training set and its annotation requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The comment provides clear guidance on what needs to be addressed, namely the clarification of the training set and its annotation requirements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The reviewer supports this claim by referencing Section 3.1, where the model\"s training requirements are described. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a logical basis for the critique, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, noting that the model requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. This is a relevant observation that could lead to confusion for readers. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the clarity of the description. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a specific direction for improvement, it does not offer concrete guidance on how to implement these changes or which specific baselines to consider. The authors are left to infer the necessary steps to take, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative approaches to consider, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why these alternative approaches would be beneficial or how they would improve the paper. Without specific examples or detailed explanations, the claim remains 1, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a specific direction for improvement by suggesting alternative approaches to consider. However, the comment could be more helpful if it offered examples of how these alternative approaches have been applied in similar contexts or provided guidance on how to implement them effectively. While the suggestion is actionable, it lacks depth and specificity, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case and questions how the data distribution illustrated in Figure 1 is inseparable from the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or experiments to be conducted, or suggesting ways to clarify the explanation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the synthetic experiment in a nonseparable case, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the data distribution illustrated in Figure 1 is inseparable from the network model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the synthetic experiment in a nonseparable case, specifically questioning how the data distribution illustrated in Figure 1 is inseparable from the network model. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to similar studies that might have addressed this issue, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model. This is a valid point that could lead to a deeper understanding of the model\"s behavior and limitations. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify their explanation. It does not provide actionable steps or examples of how to improve the explanation or analysis. As a result, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. However, it does not provide any guidance on how to address this issue or suggest improvements to the presentation. The comment lacks explicit instructions or concrete details on how to improve the presentation, leaving the authors uncertain about what changes to make. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" and the \"first 1000 episodes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes and questioning the reason for presenting them in this way. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted way, specifically mentioning the disregard of safety violations in the first 1000 episodes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this presentation is problematic or how it affects the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to present the results in a clearer or more comprehensive manner. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more detailed to be fully comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to define the bounds for \tau_i^l, which is important for understanding the timewarp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the bounds for \tau_i^l, which is important for understanding the timewarp function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment requests the definition of the bounds for \tau_i^l, which is important for understanding the timewarp function. However, it does not provide any supporting evidence or reasoning to justify why this definition is necessary or how it would impact the understanding of the function. Without additional context or explanation, the claim is not 5, as it lacks the necessary justification to be considered 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area where the authors need to provide more detail. By pointing out the importance of defining the bounds for \tau_i^l, the reviewer highlights a critical aspect of the paper that could impact its understanding and clarity. This feedback is clear and actionable, as it directs the authors to include this information in their draft. By addressing this point, the authors can enhance the comprehensibility and rigor of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests elaborating on the reasoning behind the statement on line 134, which pertains to the theorem about the standard sigmoid function. It also mentions that elaborating on why this theorem holds would be useful, particularly in the context of the RNN and URNN convergence. While the comment provides a clear direction for the authors to expand on the explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detail, but it is concrete in that it specifies what needs to be elaborated. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the reasoning behind the statement regarding the standard sigmoid function and its relation to the RNN and URNN convergence. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests elaborating on the reasoning behind a statement on line 134 and Theorem 4.1. It provides a logical basis for the suggestion by explaining that the RNN will converge to the nearest FP, unlike the URNN. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the reasoning themselves, which may not be immediately clear. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors elaborate on the reasoning behind a statement on line 134 and Theorem 4.1. It highlights the need to explain why the theorem holds, particularly in the context of the RNN and URNN convergence. This feedback is clear and constructive, as it guides the authors to enhance the clarity and depth of their explanation. By addressing this suggestion, the authors can improve the understanding and comprehensibility of their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the efficiency of pairwise matching, noting that it is very low and difficult to use in practical applications. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their pairwise matching. There is no guidance on potential solutions, alternative methods, or specific actions to take. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the efficiency of pairwise matching, specifically noting that it is very low and difficult to use in practical application systems. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem with the efficiency of pairwise matching, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the efficiency of pairwise matching, noting that it is very low and difficult to use in practical application systems. This is a relevant observation that could impact the practicality and applicability of the work. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the efficiency of their pairwise matching. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance on how to improve the allocation or what aspects of the figure are considered naive. The comment lacks concrete details on how to address the issue, leaving the authors uncertain about how to apply the feedback. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment mentions \"Figure 1,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, it lacks specificity as it does not detail what is considered naive about the allocation of Figure 1 or how it could be improved. The comment suggests that the authors could have edited the space of the main paper more wisely, but it does not provide specific guidance on how to achieve this. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support why the allocation is considered naive or how it could be improved. Without these elements, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance or examples on how the authors could improve the allocation or what aspects of the figure are considered naive. The comment lacks depth and does not offer actionable suggestions for enhancing the figure or the main paper. As a result, the feedback is not particularly helpful, as it does not provide the authors with clear steps to take in order to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the first sentence of the abstract needs to be rewritten. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and provides a concrete action, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first sentence of the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be rewritten, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the first sentence of the abstract needs to be rewritten. However, it does not provide any reasoning, evidence, or examples to support why this change is necessary or how it would improve the paper. Without additional context or explanation, the claim is 1.", "helpfulness_rationale": "The comment identifies a specific issue with the first sentence of the abstract, suggesting that it needs to be rewritten. While this feedback is clear and actionable, it lacks depth and does not provide any further explanation or guidance on what aspects of the sentence need improvement. The authors are given a specific task to address, but without additional context or suggestions, the comment may not fully support the authors in making the necessary changes. Therefore, it is 3, as it points out a specific area for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. While the comment implies that this is a necessary step, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this exercise. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results section. The authors can infer that it relates to the experimental setup, but this inference is not direct. The comment is specific in suggesting the need for multiple train/test splits, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the paper. The suggestion is based on a general understanding of standard practices in the field, but lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some rationale but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental setup by suggesting that the authors should consider using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. This feedback is 3 as it points out a common practice in the field and encourages the authors to enhance their experimental design. However, the comment lacks specific guidance on how to implement this suggestion or what specific benefits it might bring to the paper. While it highlights an area for improvement, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the method or what specific aspects of the method are overly complex. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, such as a particular section, figure, or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in suggesting that the method might be overly complex and that there might be a simpler principle driving the quality gains. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide specific guidance or suggestions on how the authors might simplify the method or explore the underlying principle. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a potential issue but lacks depth and specificity in its critique."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to determine what constitutes a significant contribution or how to improve the transferability of the method. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section, method, or result. Without explicit references to sections or elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the method or transferability need improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. Without additional context or explanation, the claim remains 1, as it lacks the necessary information to support the assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might improve the transferability of their method or what aspects of the contribution are lacking. Without actionable feedback or detailed reasoning, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain the challenges and the differences between this analysis and that of Zhang et al. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context and explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of Adam under the (L0,L1)smoothness condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the challenges and differences between this analysis and that of Zhang et al. This provides clear guidance on what the authors need to clarify or improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of Adam under the (L0,L1)smoothness condition is unclear and suggests that the authors should explain the challenges and differences with Zhang et al. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the analysis of Adam under the (L0,L1)smoothness condition. It points out that the challenges in this analysis are not clearly explained and suggests that the authors should clarify these challenges, especially in comparison to Zhang et al. This feedback is actionable as it directs the authors to provide more detailed explanations and comparisons, which can enhance the clarity and depth of their analysis. However, the comment could be more helpful if it offered specific suggestions on how to address these challenges or what aspects of the analysis should be emphasized. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific reference to an endtoend method. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how this information should be incorporated into the paper or what specific aspects of the methodology should be addressed. As a result, the authors are left without any actionable steps to improve their draft based on this comment. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific reference to an endtoend method. However, it does not specify which part of the paper this information pertains to, making it weakly grounded. The comment is specific in detailing the type of person reID methods and the reference to an endtoend method, but without explicit grounding, the authors cannot confidently determine where this information fits in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific reference to an endtoend method. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific reference to an endtoend method. While this information is relevant, it does not offer any actionable feedback or suggestions for improvement. It does not guide the authors on how to incorporate this information into their paper or how it might impact their research. As a result, the comment is 2, as it provides some context but lacks depth and actionable advice. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper is missing citations to set it in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and provides concrete actions for the authors to take, namely, to include these citations to enhance the context of their work. The explicit nature of the suggestion and the specific references make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for citations to set the paper in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly outlines what needs to be addressed, namely, the inclusion of these citations to enhance the context of the work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing citations to set it in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. The reviewer provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This provides a clear and concrete basis for the claim, as it offers specific references that can help the authors understand the broader context of their work. Therefore, the claim is 5, as it is supported by explicit and relevant references.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper lacks citations to set it in the context of other MARL work, particularly selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and actionable, as it directs the authors to include these citations to enhance the context and relevance of their work. By addressing this point, the authors can significantly improve the comprehensiveness and impact of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. While the suggestion is clear, it lacks specific guidance on which methods to compare with or how to conduct the comparison. The authors are left to infer that they should explore other methods, but without detailed instructions on how to do so, the action remains vague. Therefore, the comment is 3, as it provides a direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this comparison could be made. The authors may infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison with other methods, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any supporting evidence, examples, or references to justify why this comparison is necessary or beneficial. Without such details, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. This is a valuable suggestion as it could help the authors broaden the scope of their work and demonstrate the applicability of their method in a wider context. However, the comment lacks specificity and does not provide guidance on which methods to compare with or how to conduct the comparison. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. While the comment implies that the authors should provide a clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between the two processes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the abstention process differs from a decision threshold used by the models, and it suggests that the authors clarify this distinction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the abstention process and its distinction from a decision threshold used by the models. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the abstention process, asking for clarification on how it differs from a decision threshold used by the models. This is a clear and actionable request for the authors to provide additional explanation or clarification in their draft. By addressing this question, the authors can improve the clarity and understanding of their methodology. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of convincing evidence in the paper\"s conclusions, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer suggests that the results might be due to limited exploration of combination methods and points to recent works that have shown the potential of featurereplay methods in continual learning. While the comment provides a specific area for improvement by suggesting the exploration of combination methods, it does not offer concrete guidance on how to implement this suggestion or what specific combination methods should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific conclusion about continuous learning with unlabeled data and the claim that it accumulates noise, which is detrimental to representation quality. It also references specific works, such as R1, R2, and R3, to support the claim that featurereplay methods have shown great potential in continual learning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some conclusions in the paper are not convincing, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer supports this claim by referencing recent works that have shown the potential of featurereplay methods in continual learning, such as R1, R2, and R3. These references provide a logical basis for the claim, as they demonstrate the effectiveness of featurereplay methods in continual learning scenarios. However, the comment could be strengthened by providing more detailed analysis or specific examples from these works to further substantiate the claim. Overall, the claim is 4, as it is supported by relevant references, but it could be more fully substantiated with additional details.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s conclusions, noting that some are not convincing. It provides a detailed example by referencing recent works that have shown the potential of featurereplay methods in continual learning, such as R1, R2, and R3. This feedback is clear and actionable, as it suggests that the authors should explore the use of combination methods, which could strengthen their conclusions. By pointing to relevant literature, the comment offers a concrete direction for improvement that can enhance the paper\"s credibility and impact. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also inquires about the generalizability of this approach when labels are not available. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the pretraining of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the generalizability of the approach when labels are not available. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the pretraining of the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the pretraining of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalizability of this approach when labels are not available. This feedback is 3 as it prompts the authors to clarify an important aspect of their methodology, which could impact the robustness and applicability of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to improve the generalizability of the model. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. While the comment implies that the authors should address these issues, it does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to investigate the accuracy of the ground truth and the noticeability/measurability of the difference, but the comment lacks specific guidance on how to conduct this investigation or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. However, it does not specify which part of the paper these questions pertain to, such as a particular section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its inquiry about the accuracy and noticeability of the differences, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the accuracy and reliability of the results presented in the paper. It questions whether the small differences observed are actually noticeable or due to noise or randomness in the training process. Additionally, it points out a lack of difference between the results reported in the ablation study table. While the comment identifies potential issues, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve the accuracy of their results. The feedback is 3 as it prompts the authors to consider the reliability of their findings, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of new evaluation metrics and the limited exploration of existing metrics in the experimental analysis section. It explicitly states that there needs to be an indepth exploration of the reasons for the experimental results. This provides a clear and concrete action for the authors to take, as they are directed to conduct a more thorough analysis of the experimental results. The comment is specific in detailing what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental analysis section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of new evaluation metrics and the limited exploration of existing metrics. The comment suggests an indepth exploration of the reasons for the experimental results, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that existing metrics are combined linearly. It suggests that the experimental analysis section needs an indepth exploration of the reasons for the experimental results. However, the comment does not provide specific examples or references to support the claim that existing metrics are combined linearly or that there is a lack of new metrics. This makes the claim 3, as the authors would need to infer the basis of the critique and potentially conduct additional analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of new evaluation metrics and the limited exploration of existing metrics. It suggests that the experimental analysis section needs an indepth exploration of the reasons for the experimental results. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and understanding of the experimental findings. However, the comment could be more helpful if it offered suggestions on how to conduct this exploration or what specific aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It specifically mentions the use of separate embeddings and positional encoding, but it does not provide explicit guidance on how the embeddings are combined or how they are fed into the CSCM. The comment implies that the authors should provide more detailed information on this process, but it does not specify exactly what needs to be clarified or how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text\" and \"CSCM,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, how historical observations are combined with inputs known over all time given differences in sequence lengths. The comment provides a clear direction for the authors to address the issue by asking for clarifications on how the embeddings are combined and fed into the CSCM. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It mentions the use of separate embeddings and positional encoding, but it does not provide any supporting evidence, reasoning, or references to justify the claim that clarification is needed. The comment lacks specific examples or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the combination of historical observations and inputs known over all time, given differences in sequence lengths. It points out that the text mentions separate embeddings and positional encoding but lacks clarity on how these are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed information on the process of combining embeddings and positional encoding. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects should be clarified. Overall, the comment is 4 as it effectively highlights a critical area for improvement in the paper."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the first two bullets about contributions at the end of the introduction should be combined together. This is an explicit action that the authors can directly implement by merging the two bullets. The comment provides a clear and concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests combining the first two bullets about contributions at the end of the introduction. However, it does not specify which part of the introduction this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a potential improvement by combining the two bullets. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests combining the first two bullets about contributions at the end of the introduction. However, it does not provide any supporting evidence, reasoning, or examples to justify why this combination would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the first two bullets about contributions at the end of the introduction could be combined together. This is a specific and actionable suggestion that could streamline the introduction and make it more concise. However, the comment does not provide further explanation or guidance on why this combination would be beneficial or how it might impact the overall structure or content of the paper. While it identifies a potential improvement, the lack of detailed justification or examples limits its helpfulness. Therefore, the comment is 3, as it provides a clear suggestion but lacks depth and context for the authors to fully understand and act upon it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clearly defined. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify these concepts or what specific changes should be made to improve the clarity. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clearly defined. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of unclear definitions, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations and social norms, such as physical and psychological safety, are not clearly defined in the main paper. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the paper, noting that the types of situations and social norms, such as physical and psychological safety, are not clearly defined. This feedback is 3 as it points out a potential area for improvement, but it lacks depth and does not provide specific suggestions on how to clarify these concepts or what aspects of the paper need further explanation. While it highlights an important issue, the comment could be more helpful with additional guidance or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem. However, it points out the need to demonstrate the algorithm\"s improvement over existing solutions by addressing robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment implies that the authors should provide more evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional evidence to substantiate their claims. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the paper\"s focus on a specific problem and its potential benefits to the neuroscience community. It highlights the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The comment suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where the authors present their algorithm and its performance. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem. It highlights the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment identifies a critical area for improvement, it lacks specific examples or references to support the claim about the algorithm\"s improvement over existing solutions. This makes the claim 3, as it provides a direction for improvement but lacks detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem in the neuroscience community. It identifies a critical area for improvement, namely the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment provides a clear direction for improvement, it lacks specific suggestions or examples on how to address this issue. The authors are given a general idea of what needs to be improved but are not provided with actionable steps or detailed guidance. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more baselines should be compared and more domains should be tested. It also mentions that the choices of weighting and learning density functions are not strongly motivated, and that stronger empirical results are needed. However, the comment does not provide specific guidance on which baselines to compare or how to test the additional domains. The authors are left to infer that they need to expand their experimental setup, but without concrete suggestions on which baselines or domains to include, the action remains vague. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that more baselines should be compared and more domains should be tested, and it mentions the choices of weighting and learning density functions as areas for improvement. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or experiments where these improvements could be made. Additionally, the comment lacks specific guidance on which baselines or domains should be included, making it weakly grounded. The suggestion to provide stronger empirical results is somewhat specific, as it highlights the need for additional comparisons and domains, but it does not detail how to achieve this. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that more baselines should be compared and more domains should be tested, and it critiques the choices of weighting and learning density functions as not being strongly motivated. However, the comment lacks specific examples or references to support the claim that these choices are not justified or that the current results are insufficient. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that more baselines should be compared and more domains should be tested. It also critiques the choices of weighting and learning density functions as not being strongly motivated, implying that the empirical results could be stronger. However, the comment lacks specific guidance on which baselines or domains to include, and it does not provide detailed suggestions on how to address the identified weaknesses. While it points out areas for improvement, the feedback is 3 as it highlights potential areas for enhancement but does not offer actionable steps for the authors to take. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the comparability of the results or what specific aspects need to be improved. As a result, the authors are left without any clear direction on how to enhance the significance of their work. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the results are not comparable or how they could be improved. Without clear guidance on where to focus the revision, the authors may struggle to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, which suggests that the significance of the proposed methods is questionable. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods may be questionable. However, it does not provide any specific examples or guidance on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that it is a straightforward application of existing literature, such as DeCorr, in a specific application domain. It highlights the main contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment implies that the authors should provide more insights into these challenges, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of unique insights. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DeCorr 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems, despite being a straightforward application of existing literature. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr. The reviewer supports this claim by mentioning that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also acknowledges that modifications like different penalty coefficients for users and items are proposed. While the claim is 4 due to the mention of DeCorr and the transposition of insights, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it lacks novelty and is a straightforward application of existing literature, specifically DeCorr. It highlights the main contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. This feedback is 3 as it identifies a critical area for improvement, namely the need to provide more insights into the unique challenges of overcorrelation. However, the comment could be more helpful if it offered specific suggestions on how to address this gap or what kind of insights would be valuable. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance or suggestions on how to address this issue. It lacks concrete steps or recommendations for the authors to follow, leaving them uncertain about how to proceed. Therefore, the comment is 3, as it identifies a potential issue but does not offer specific actions for the authors to take.", "grounding_specificity_rationale": "The comment raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. While the authors might have an idea of where this discussion might occur, the comment lacks full grounding. It is specific in its critique of the methodology but does not provide detailed guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment lacks specific examples or references to support the claim that this is a drawback or how it affects the accuracy of the model. Without detailed reasoning or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification to be 5.", "helpfulness_rationale": "The review comment raises a critical question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker\"s identity. This feedback is 3 as it identifies a potential issue with the methodology that the authors may not have considered. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what alternative approaches might be considered. Overall, the comment offers a valuable insight but lacks detailed guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states that the writing is difficult to follow in many places and suggests simplifying it. However, it does not provide specific examples or guidance on how to achieve this simplification. The authors are left to infer that they need to make their writing more accessible, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and suggests simplifying it. However, it does not specify which parts of the paper are particularly challenging or where the simplification is needed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests simplifying it. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or examples, the authors may find it challenging to understand where the writing is difficult to follow and how to simplify it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper\"s writing, noting that it is difficult to follow in many places and suggests simplifying it. While this feedback highlights a potential problem, it lacks specificity and does not provide actionable guidance on how to improve the writing or which sections are particularly challenging. Without detailed suggestions or examples, the authors may struggle to address the issue effectively. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to 31. However, it does not provide any guidance on how the authors could address this issue or improve the paper. There is no explicit suggestion for improvement or actionable advice on how to enhance the technical substance or innovation of the work. As a result, the comment is 1, as it does not offer any direction for the authors to follow.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to 31. However, it does not specify which part of the paper this assessment is based on, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or lacking in technical substance. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to 31. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it only adds a new loss to 31. However, it does not provide any specific feedback or suggestions on how the authors could improve the paper or address this issue. Without actionable guidance or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it would be beneficial to provide some intuition regarding the proof of Theorem 1. It also raises a question about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. Additionally, it asks how to determine which $P^*$ to fix in practice. While the comment implies that the authors should provide more detailed explanations or examples, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"the invertible function $f^*$,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the proof of Theorem 1 and the dependence of $f^*$ on the fixed $P^*$. The comment suggests providing intuition and guidance on how to determine which $P^*$ to fix in practice. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification regarding the proof of Theorem 1 and the dependence of the invertible function $f^*$ on the fixed $P^*$. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the proof of Theorem 1 and the dependence of the invertible function $f^*$ on the fixed $P^*$. It suggests that providing intuition for the proof and guidance on determining which $P^*$ to fix would be beneficial. This feedback is clear and actionable, as it prompts the authors to consider how to enhance the clarity and depth of their explanation. However, the comment could be more helpful if it offered specific suggestions or examples on how to present this information. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of notation in equations (7) and (10), noting that they should be analogous but are not. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending a specific notation change or explaining why the current notation is problematic. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of notation, suggesting that the equations should be analogous but are not. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the choice of notation in equations (7) and (10), suggesting that they should be analogous but are not. However, the comment does not provide any reasoning or explanation for why this choice is unexpected or problematic. Without additional context or justification, the claim lacks verifiability, as it does not provide sufficient evidence or explanation to support the assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of notation in equations (7) and (10), suggesting that they should be analogous but are not. This feedback identifies a potential issue with the clarity and consistency of the notation used in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their notation. While it points out a potential area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to demonstrate the applicability of their model to realworld diffusion processes. While the comment implies that the authors should conduct experiments or provide examples to support their claims, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors know they need to provide empirical evidence but may not be entirely sure of the specifics of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the applicability of the model to realworld diffusion processes, suggesting that the authors should provide empirical evidence to demonstrate its effectiveness. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for empirical evidence, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the applicability of the model to realworld diffusion processes is a concern, and it provides a logical reasoning by stating that the authors should provide empirical evidence to demonstrate its effectiveness. However, the comment lacks specific examples or references to support the claim that the model captures diffusion phenomena in realworld scenarios. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the applicability of the model to realworld diffusion processes. It acknowledges the elegance of the proposed solutions but suggests that empirical evidence is needed to demonstrate the model\"s effectiveness in realworld scenarios. This feedback is clear and actionable, as it provides a specific direction for the authors to address the applicability issue by providing empirical evidence. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or what specific aspects of the diffusion process should be examined. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, and that alternatives already exist, as noted in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or improve the novelty of the contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the main contribution, which is the combination of attention with other linear mechanisms. However, it does not specify which part of the paper discusses this contribution, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the contribution are not novel or how the alternatives are addressed. Without clear guidance on where to focus improvements, the authors may struggle to effectively address the critique. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, the comment does not provide specific examples or references to these alternatives, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or reasoning, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. This is a valid observation that could prompt the authors to reconsider the originality of their contribution. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without detailed feedback or constructive advice, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the novelty of the paper is limited, specifically pointing out that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to enhance the novelty or what specific aspects of the decomposition part could be improved. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the incremental contribution of the decomposition part. However, it does not specify which section of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing the limitations of the novelty and the incremental contribution, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the paper, specifically noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare the performance of their proposed CLN (region proposal generation algorithm) with that of another work. While the comment implies that the authors should conduct a performance comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the details of the comparison themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not specify which part of the paper discusses the CLN or where the performance comparison should be included. The authors cannot confidently determine which section or part of the paper is being addressed, making this comment 1. Additionally, the comment lacks specificity regarding what aspects of the performance comparison should be considered or how it should be conducted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work, which could provide valuable insights into the effectiveness of the proposed method. However, the comment lacks specificity and does not offer guidance on how to conduct this comparison or what aspects to focus on. Without detailed instructions or examples, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is 3 as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the presentation is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It also recommends the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment provides a clear action\u2014adding an illustrative figure\u2014it does not specify which concepts should be illustrated or how the figure should be designed. The authors are given a general direction but lack detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the presentation, specifically mentioning that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It also suggests the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the presentation and notation in chapter 3. The suggestion for an illustrative figure provides some specificity, making the comment weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. While the comment identifies specific issues with the presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for an illustrative figure is a logical point, but without further explanation or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation by adding visual aids. However, the comment could be more helpful if it offered specific examples of what types of figures or illustrations would be beneficial. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out that the visual presentation, specifically the subscripts, could be improved for better readability and aesthetic appeal. While the comment identifies an area for enhancement, it does not provide explicit guidance on how to achieve this improvement. The authors are left to infer that they should make changes to the subscripts, but without specific suggestions or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the visual presentation of the subscripts, for better readability and aesthetic appeal. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the comprehensive nature of the data presented in Figure 3 but suggests that the visual presentation, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, the comment does not provide specific examples or detailed reasoning to support why the subscripts are problematic or how they could be improved. Without such examples or references, the claim is not 5, as it lacks the necessary evidence or justification to substantiate the suggestion. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out a specific area for improvement. It suggests that the visual presentation, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. While the comment identifies a clear area for improvement, it lacks detailed guidance or suggestions on how to achieve this enhancement. The authors are left to infer that they should make changes to the subscripts, but without specific instructions or examples, the feedback is 3. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical details or formulations, nor are there suggestions for how to better highlight the novelty of the scheme or procedure. As a result, the authors are left without any clear direction on how to improve their draft based on this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the technical details or formulations are lacking or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide any specific examples or suggestions for how the authors might improve the technical details or formulations to better highlight the novelty. Without actionable feedback or guidance, the authors are left without a clear understanding of what changes to make or how to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how the archetype positions are updated after initialisation in Algorithm 2. It explicitly asks the authors to clarify this aspect, providing a clear action for the authors to take. The comment is explicit in its request for clarification, making it 5. The authors know exactly what needs to be addressed and how to implement the action, as they are instructed to provide a comment on the update process. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"the query Q consists of the archetypes z_1, \u00e2\u0080\u00a6, z_k,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the update process of the archetype positions after initialisation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the update process for the archetype positions in Algorithm 2. It does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is a factual statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the update process of the archetype positions in Algorithm 2. It asks the authors to clarify this aspect, which is important for understanding the methodology. This feedback is clear and actionable, as it directs the authors to provide a comment on the update process. However, the comment could be more helpful if it offered suggestions on how to clarify this aspect or provided examples of how the update process might be explained. Overall, the comment is 4 as it points out a critical area for clarification, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These are all clear and concrete actions that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the \"empirical study\" and \"supplement,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details what information is missing, such as recording parameters, preprocessing steps, and the condition under which the restingstate was recorded. Additionally, it suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point makes several claims about the missing information in the empirical study, such as recording parameters, preprocessing steps, and the condition under which the restingstate was recorded. It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These claims are 3 as they are based on logical reasoning and common knowledge about empirical studies. However, the comment could be strengthened by providing specific references or examples to support the claims or by offering more detailed explanations of the missing information. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the transparency and completeness of their empirical study. By addressing these points, the authors can significantly improve the clarity and robustness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should reconsider their statement about overparameterization, which is currently perceived as a negative aspect. The reviewer provides a rationale by pointing out that overparameterization can be beneficial for supervised learning of deep neural networks in practice, and references a theoretical work that supports this claim. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their stance on overparameterization. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 47  48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the authors\" claim about overparameterization, providing a rationale based on practical and theoretical benefits. The reviewer references a specific theoretical work, which adds clarity and specificity to the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the authors\" claim about overparameterization, suggesting that it is beneficial for supervised learning of deep neural networks in practice. The reviewer provides a rationale by referencing a theoretical work, which supports the benefits of overparameterization. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or specific references to the theoretical work, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment challenges the authors\" claim about overparameterization, suggesting that it is beneficial for supervised learning of deep neural networks in practice. The reviewer provides a rationale by referencing a theoretical work that supports the benefits of overparameterization. This feedback is 3 as it prompts the authors to reconsider their stance on overparameterization and potentially explore its benefits in their work. However, the comment could be more helpful if it provided specific examples or references to the theoretical work, which would guide the authors in further exploring this topic. Overall, the comment offers a valuable perspective but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific aspects of the training and testing process should be described. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed description and comparison with existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the shape model and the parsing model, including the timeconsuming nature of training and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. However, the comment does not explicitly mention which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the timeconsuming nature of training and the complexity of the parsing model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the shape model is timeconsuming due to its training in pixel level and the model being trained independently on all font images and characters. It also mentions the complexity of the parsing model, which is described as a highorder factor graph with four types of factors. The reviewer suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment provides some logical reasoning by pointing out the timeconsuming nature of the training process, it lacks specific examples or references to existing work that could substantiate the claim. This makes the claim 3, as it provides a general rationale but requires more detailed evidence or references to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment highlights important areas for improvement, it lacks specific guidance on how to address these issues or what aspects of the training and testing process should be described. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with additional details or suggestions on how to improve the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and guidance on what to discuss. The comment is specific and leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. This makes the comment weakly grounded, as the authors cannot confidently determine the exact location of the discussion. The comment is specific in suggesting what needs to be addressed, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. This feedback is 3 as it identifies a specific area that could enhance the paper by providing more context and detail about the dataset creation process. However, the comment lacks depth and does not offer suggestions on how to structure or present this discussion, nor does it provide examples of what could be included. While it points out a potential improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it would be beneficial to see how it affects the performance of the method in a scenario where the game has repetitive background sounds. The reviewer provides a clear rationale for why this ablation is important, noting that the weighting might have helped remedy the underperformance in such scenarios. However, the comment does not explicitly instruct the authors to conduct this ablation or provide detailed guidance on how to implement it. While the action is implied, the lack of concrete steps makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning the scenario where the game has repetitive background sounds. This provides a clear reference to the section where the authors discuss the performance of their method in Atlantis. However, the comment does not specify which part of the paper should include this ablation, making it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, namely the weighting method of the crossentropy loss in the context of repetitive background sounds. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation on the weighting method of the crossentropy loss, specifically mentioning that it might help remedy the underperformance of the method in a scenario with repetitive background sounds. This claim is 3 as it is based on a logical reasoning that the weighting might improve performance in such a scenario. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it might help remedy the underperformance of the method in a scenario with repetitive background sounds. This is a clear and actionable suggestion that could improve the paper by providing additional insights into the performance of the method in different contexts. However, the comment could be more helpful if it included specific guidance on how to conduct the ablation or what specific aspects of the weighting method should be explored. Overall, the comment is 4 as it identifies a potential area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to demonstrate novelty and incremental improvements, but the comment lacks concrete suggestions on how to achieve this. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of the lack of novelty and incremental nature of the work, as well as the problem of column operations in designing semantic parsers for TexttoSQL. It also mentions the design of a new dataset, which is a different train/test split of an existing dataset, SQUALL. Additionally, it points out a synthetic benchmark paper based on a single question template. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be improved, such as demonstrating novelty and incremental improvements, and providing suggestions for addressing the issue of column operations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, specifically addressing a problem of column operations in designing semantic parsers for TexttoSQL. The reviewer provides some justification by mentioning that the proposed dataset is a different train/test split of an existing dataset, SQUALL, and that the synthetic benchmark paper is based on a single question template. However, the comment could be strengthened by providing more detailed examples or references to support the claim of lack of novelty. As it stands, the comment is 3, as it provides some evidence but lacks comprehensive justification. Therefore, the score is 3.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template, which further highlights the lack of novelty. This feedback is clear and actionable, as it directs the authors to address the issue of novelty and incremental nature in their work. However, the comment could be more helpful if it provided suggestions on how to demonstrate novelty or incremental improvements, such as by suggesting alternative approaches or datasets. Overall, the comment is 4 as it effectively identifies a critical weakness and offers direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This is a clear and direct action for the authors to take, as it specifies the need for a detailed explanation with examples. The comment provides a concrete direction for improvement, ensuring that the authors know exactly what needs to be done to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a detailed explanation with examples. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are important or how removing them would contribute to the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This feedback is clear and actionable, as it directs the authors to provide a detailed explanation with examples to strengthen their argument. By addressing this point, the authors can enhance the clarity and impact of their paper. However, the comment could be more helpful if it provided specific examples or guidance on how to present these explanations. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer any explicit guidance or actionable steps for the authors to take. The comment lacks specific instructions or suggestions on how to incorporate this idea into the paper. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that labeled data might provide effective information for consistency training and provides examples of relevant works, such as \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation.\" Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. The reviewer supports this suggestion by referencing two external works, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which demonstrate the effectiveness of using labeled data for this purpose. However, the comment lacks detailed reasoning or specific examples from the works to fully substantiate the claim. While the references provide some support, the comment could be strengthened by further elaboration on why labeled data might be beneficial and how it could be integrated into the paper. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer specific guidance or actionable steps for the authors to explore this idea further. The comment references two external works, which could be useful for the authors to consider, but the lack of detailed suggestions or examples limits its helpfulness. Overall, the comment provides some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental part needs to be reorganized and improved, and it provides specific suggestions for how to do so. It suggests that the experimental content listed in the main text should highlight the superiority of the method, and it provides a list of experimental suggestions that should be included in the main text. These suggestions are concrete and provide clear guidance on what changes the authors should make to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental part\" and the \"experimental section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the reorganization and highlighting of the experimental content to showcase the superiority of the method. The suggestions for improvement are detailed and provide a clear direction for the authors to follow. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental part needs to be reorganized and improved, suggesting that the experimental content listed in the main text does not effectively highlight the superiority of the method. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to specific sections of the paper where the issue is apparent, making it difficult for the authors to understand and address the critique. As a result, the claim is 3, as it provides a general direction for improvement but lacks the necessary detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental part of the paper, noting that the experimental content does not effectively highlight the superiority of the method. It provides a clear and actionable suggestion to reorganize the experimental section and includes specific experimental suggestions that should be included in the main text. These suggestions are detailed and provide a clear direction for the authors to improve the clarity and effectiveness of their experimental results. However, the comment could be more helpful if it explained why the current experimental content is insufficient or how the suggested improvements would enhance the paper\"s impact. Overall, the comment is 4 as it offers valuable guidance for improving the experimental section, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what specific changes could be made to improve the argument or simulations. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific argument related to the practicality of the recognition process, particularly in the context of old vs. new judgments. It questions the feasibility of implementing and testing concrete predictions with simulations, given the exhaustive nature of the list of items available in memory. However, the comment does not specify which part of the paper this argument is discussed in, making it weakly grounded. The comment is specific in its critique of the argument and the implications for simulations, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. The reviewer points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. This claim is 3 as it provides a logical reasoning for the difficulty in implementing the argument, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the argument presented in the paper regarding the practicality of the recognition process. It questions the feasibility of implementing and testing concrete predictions with simulations, given the exhaustive nature of the list of items available in memory. This feedback is valuable as it prompts the authors to reconsider the practicality of their argument and potentially revise it to align with more realistic scenarios. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what alternative approaches might be considered. Overall, the comment is 3 as it highlights a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset, specifically referring to Table 3 on page 7. It also provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016.\" The comment is explicit in its suggestion to use better metadata embeddings and provides a specific reference to a related work. However, it does not provide detailed guidance on how to implement this suggestion or what specific steps to take. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of better metadata embeddings for the zeroshot learning results on the CUB dataset. The comment provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the authors should consider this approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset, specifically referring to Table 3 on page 7. The reviewer provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016.\" This reference provides a clear rationale for the suggestion, as it demonstrates that better metadata embeddings can lead to improved performance. However, the comment could be strengthened by providing more detailed analysis or specific examples of how the proposed method could benefit from these embeddings. Overall, the claim is 4, as it is supported by a specific example and logical reasoning, but it could be further substantiated with additional evidence or detailed analysis.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by recommending the use of better metadata embeddings for the zeroshot learning results on the CUB dataset. It references a specific example from a related work, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which demonstrates the potential for better metadata embeddings to improve performance. This feedback is actionable and provides a clear direction for the authors to enhance their results. However, it could be more helpful if it included additional details on how to implement this suggestion or what specific steps the authors should take to explore this approach. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, and suggests that the code should be published to demonstrate the computation time advantage. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or publish the code to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"German and Law school dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reasonableness of the shorter training time for Gerrymandering compared to Independent, and suggests that the code should be published to demonstrate the computation time advantage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might not be reasonable. It also mentions that the code should be published to demonstrate the computation time advantage. However, the comment lacks specific evidence or references to support the claim about the training time or the need for code publication. The reasoning is based on logical reasoning and common sense, but it does not provide detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might not be reasonable. It also suggests that the code should be published to demonstrate the computation time advantage, which could be beneficial for the authors. While the comment identifies a potential issue and provides a suggestion for improvement, it lacks depth and does not offer specific guidance or examples on how to address the issue or improve the code. The feedback is 3 as it points out a potential weakness but does not provide detailed guidance for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the assumption for termination states of instructions is quite strong, particularly when it comes to labeling a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, particularly the issue of labeling a large number of data manually. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the problem of manual labeling and the associated expense, but it lacks detailed guidance on how to address this issue or what specific changes could be made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is \"quite strong,\" particularly when it comes to labeling a large number of data manually. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the assumption for termination states of instructions, particularly when it comes to labeling a large number of data manually. This is a relevant point that could impact the feasibility and costeffectiveness of the proposed method. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue or mitigate its impact. Without detailed feedback or constructive advice, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in the paper regarding the nature of the contribution with respect to ECE_sweep. It explicitly states that the contribution is not clearly described and suggests that the authors should be upfront about it. The reviewer provides a concrete example of what is missing, which is the autotuning of a hyperparameter in the estimate, and notes that this is not fundamentally different from the contribution. The comment is explicit in its request for clarification and provides a specific example of what needs to be addressed. Therefore, the action is clear and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ECE_sweep\" and the issue with the contribution being unclearly described. It specifies the problem by pointing out that the contribution is not clearly described, particularly regarding the autotuning of a hyperparameter in the estimate. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the contribution with respect to ECE_sweep is not clearly described in the text. It provides a specific example of the issue, which is the autotuning of a hyperparameter in the estimate, and notes that this is not fundamentally different from the contribution. The reviewer acknowledges being confused about the paper\"s point until they realized this. This provides a logical reasoning and a clear example of the issue, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim that this is not fundamentally different. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the contribution regarding ECE_sweep. It points out that the contribution is not clearly described in the text, particularly regarding the autotuning of a hyperparameter in the estimate. The reviewer acknowledges being confused about the paper\"s contribution until they realized this. This feedback is clear and actionable, as it provides a concrete example of what needs to be clarified in the paper. By addressing this issue, the authors can improve the clarity and understanding of their contribution. However, the comment could be more helpful if it suggested how to improve the clarity or provided additional context or examples. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the authors\" use of the term \"efficient proxy\" or \"efficient proxies\" in their work. It suggests that the term \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests a broader reference to a family of efficient proxies. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should clarify this ambiguity or what specific changes should be made to address it. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the use of \"efficient proxy\" or \"efficient proxies\" in their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"efficient proxy\" or \"efficient proxies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ambiguity in the use of these terms, suggesting that \"is\" might imply a particular proxy but that the lack of a specific \"Efficient Proxy\" suggests a broader reference to a family of efficient proxies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the ambiguity in the use of the term \"efficient proxy\" or \"efficient proxies\" in the paper. It suggests that the term \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests a broader reference to a family of efficient proxies. This reasoning is based on logical deduction from the text and the use of the term \"is,\" but it does not provide explicit references or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or references to fully support it.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the authors\" use of the term \"efficient proxy\" or \"efficient proxies\" in their work. It suggests that the term \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests a broader reference to a family of efficient proxies. This feedback is 3 as it points out a potential source of confusion in the paper, which the authors can address to clarify their terminology. However, the comment could be more helpful if it provided suggestions on how to clarify this ambiguity or offered examples of how the authors might rephrase their terminology for clarity. Overall, the comment is 3 as it highlights an area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors stack multiple methods, including those from Mirzasoleiman et al., 2020 and a grouplearning setting, and then use a classical method, DBSCAN, for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what changes should be made to improve the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the use of multiple methods, including those from Mirzasoleiman et al., 2020 and a grouplearning setting, and then using a classical method, DBSCAN, for clustering. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the stacking of methods and the use of DBSCAN, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors stack multiple methods, including those from Mirzasoleiman et al., 2020 and a grouplearning setting, and then use a classical method, DBSCAN, for clustering. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this stacking is problematic or how it affects the paper\"s outcomes. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to substantiate the critique. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment points out a specific issue with the paper, noting that the authors stack multiple methods, including those from Mirzasoleiman et al., 2020 and a grouplearning setting, and then use a classical method, DBSCAN, for clustering. This observation highlights a potential problem in the paper\"s methodology, as it suggests that the authors may be overloading the analysis with too many methods. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to enhance the model\"s complexity or complexity analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as the model description, results, or analysis. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the model\"s simplicity are problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the model seems overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the model\"s complexity. Without actionable feedback or detailed analysis, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as 2, as it identifies a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the action is explicit, it is somewhat vague as it does not specify which part of the main paper should include the mention or how to present the runtime examples. However, the authors can infer that they need to add a brief mention and provide examples, making the comment 4.", "grounding_specificity_rationale": "The comment suggests mentioning the negligible computational cost of CHR in the main paper and providing a rough example of runtimes in the experiments. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the computational cost is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the inclusion of a brief mention and examples, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests mentioning the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or references to support the claim about the computational cost. The mention of \"negligible\" implies that the cost is minimal, but without further context or evidence, the claim is 3. The suggestion to include runtime examples is a helpful addition, but the lack of detailed justification or examples makes the claim 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It recommends mentioning the negligible computational cost of CHR in the main paper, which could help motivate the method. Additionally, it suggests providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. This feedback is specific and offers concrete steps for the authors to enhance the clarity and applicability of their work. By addressing these points, the authors can improve the comprehensiveness and accessibility of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors leverage the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes could be made to improve the directness of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" approach to addressing the problem, specifically mentioning the use of the Witness oracle and its complexity. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspect of the complexity issue is problematic or how it could be addressed. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not address the problem directly by leveraging the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" approach, specifically the use of the Witness oracle and its complexity. It suggests that the authors may not be addressing the problem directly, as the oracle is described as \"polynomial time\" in the tabular case. While the comment identifies a potential weakness, it lacks specific guidance or suggestions on how the authors might address this issue or improve their approach. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should compare their work with existing code completion commercial applications, such as Copilot, as a baseline. It provides a specific suggestion for testing on a smaller subset of RepoEval and highlights the importance of comparing with stateoftheart code completion systems. This feedback is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. It specifies that this comparison should be tested on a smaller subset of RepoEval and is essential for comparing with stateoftheart code completion systems. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the evaluation or comparison sections, the lack of explicit grounding makes it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. This claim is 3 as it provides a logical reasoning for the suggestion, which is to test the performance of the proposed system against stateoftheart code completion systems. However, the comment lacks specific examples or references to these existing applications, making it somewhat challenging for the authors to fully understand and implement the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending the inclusion of baselines, specifically comparing the proposed work with existing code completion commercial applications, such as Copilot. This feedback is clear and constructive, as it highlights a gap in the evaluation that could enhance the understanding and validation of the proposed system. By suggesting a specific test setup and referencing a wellknown commercial application, the comment offers a concrete direction for the authors to improve their draft. However, it could be more helpful if it provided additional context or examples on how to implement this comparison effectively. Overall, the comment is 4 as it offers a clear and actionable suggestion for enhancing the evaluation section."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the second paragraph in the introduction discusses modelling curves but does not clearly state what is being modelled, presumably tumour growth. While the comment identifies a potential issue with the clarity of the introduction, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to clarify the modelled curves, but the comment lacks specific suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph in the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of not being immediately obvious what is being modelled, which is a clear and actionable concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph in the introduction discussing modelling curves is not immediately obvious what is being modelled, presumably tumour growth. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue in the introduction, specifically the lack of clarity regarding what is being modelled in the second paragraph. It points out that the mention of modelling curves is not immediately obvious, and it suggests that the authors should clarify what is being modelled, presumably tumour growth. While the comment highlights an area for improvement, it does not provide specific guidance or suggestions on how to address this issue. The authors are left with a general understanding of the problem but without actionable steps to improve the draft. Therefore, the comment is 3, as it identifies a weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of the model and baselines on test samples from the observational (in) distribution. It suggests that showing this performance would be useful. However, the comment does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and vague, as the authors are left to infer that they should include this information in their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shiftedMNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions why shift=0 is better than shift~N (0, \u03c32) and suggests showing the performance on test samples from the observational (in) distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the superiority of shift=0 over shift~N (0, \u03c32) in the context of \"shiftedMNIST,\" suggesting that both cases incorporate a domain shift. The comment also suggests that it would be useful to show the performance of the model and baselines on test samples from the observational (in) distribution. While the comment raises valid points, it lacks specific examples or references to support the claim that shift=0 is indeed better than shift~N (0, \u03c32). This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid point about the superiority of shift=0 over shift~N (0, \u03c32) in the context of \"shiftedMNIST,\" suggesting that both cases incorporate a domain shift. It also suggests that it would be useful to show the performance of the model and baselines on test samples from the observational (in) distribution. This feedback is 3 as it identifies a potential area for improvement and provides a suggestion for enhancing the paper. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct the performance analysis. Overall, the comment provides some insight but lacks depth and actionable details, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more explanation to clarify the main contributions of the paper, specifically regarding the optimization strategies and their corresponding results. It suggests discussing different scenarios, such as minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is clear and concrete, as it specifies exactly what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more explanation regarding the optimization strategies and their corresponding results. The comment provides a clear direction for the authors to improve their draft by discussing different scenarios and their implications. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks clarity regarding the optimization strategies and their corresponding results, specifically mentioning the contribution of the CBR. The reviewer provides a specific example of what could be discussed, such as the consequences of minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This suggestion is based on logical reasoning and a clear understanding of the paper\"s content, making it 4. However, the comment could be strengthened by providing more detailed examples or references to similar studies, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, specifically regarding the optimization strategies and their corresponding results. It suggests that the authors should provide more explanation to make the main contributions of the paper clearer. The comment provides a concrete example by asking what would happen by minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is actionable and constructive, as it guides the authors on how to enhance the clarity and comprehensibility of their work. However, it could be more helpful if it offered additional suggestions or examples of how to present this information effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is an explicit action, as it clearly instructs the authors to include a definition of treewidth. The comment also provides a specific suggestion for how to improve the paper by including a definition, making it concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, methodology, or results sections. The authors can infer that it relates to the proofs, but this inference is not direct. The comment is specific in suggesting the inclusion of a definition, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their work. By including a definition, the authors can provide a foundation for understanding the concept and its importance in the context of their research. However, the comment could be more helpful if it explained why a formal definition is necessary or how it would enhance the paper. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, and references a specific sentence regarding the performance of the secret model with or without fusion. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the algorithms should be clarified or how the authors might address the issue of information redundancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode algorithms\" and the specific sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it asks for clarification on how information redundancy is built into the algorithms and how it affects the performance of the secret model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how information redundancy is built into the Fill, Propagate, Decode algorithms. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms, specifically asking for clarification on how this redundancy is built into the algorithms. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the algorithms need clarification. The feedback is 3 as it points out a potential weakness, but it could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of using multiple INs at different speeds in the dynamics predictor, suggesting that this design choice is not ablated. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider ablating this feature to determine its impact, but it lacks concrete instructions on how to do so or what specific aspects to focus on. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the model, namely the use of multiple INs at different speeds in the dynamics predictor. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the importance of the added complexity and suggesting that one IN might suffice. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of using multiple INs at different speeds in the dynamics predictor, suggesting that this design choice is not ablated. However, it does not provide any supporting evidence, reasoning, or references to justify why this design choice is important or not. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the importance of using multiple INs at different speeds in the dynamics predictor, suggesting that this design choice might not be necessary. It prompts the authors to consider whether one IN would suffice, which is a valuable point for the authors to consider. However, the comment lacks depth and does not provide specific suggestions or examples on how to address this issue or what alternative approaches might be considered. While it identifies a potential area for improvement, it could be more helpful with additional guidance or reasoning. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the opponent in the experiments does not aim to maximize the multiagent payoff proposed by the authors, which is a surprise. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their experimental design. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the opponent does not aim to maximize the multiagent payoff proposed by the authors, which is a clear and specific critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the opponent in the experiments does not aim to maximize the multiagent payoff proposed by the authors, which is a surprise. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the experimental setup, specifically noting that the opponent does not aim to maximize the multiagent payoff proposed by the authors. This observation highlights a potential weakness in the experimental design, as it suggests that the opponent\"s behavior may not accurately reflect the proposed method. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve their experimental design. Without specific advice or constructive feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, specifically regarding the potential disadvantage of MMD DRO compared to the variance regularized problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this confusion or what specific steps to take to clarify the statement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the statement in the theorem, which could indicate a disadvantage of MMD DRO compared to the variance regularized problem. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO compared to the variance regularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding a statement in Theorem 5.1, which could be interpreted as a disadvantage of MMD DRO compared to the variance regularized problem. This feedback is 3 as it points out a specific area that may need clarification or further explanation. However, the comment lacks depth and does not provide suggestions on how to address the confusion or improve the clarity of the statement. While it highlights an area for potential improvement, it does not offer actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique used in LUMP. This is a clear and direct action, as it specifies exactly what needs to be done to improve the draft. The authors know exactly what additional experiments are needed and how to implement them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of experimental results demonstrating the pure contribution of the proposed method without the mixup technique used in LUMP. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mixup technique used in LUMP should be excluded from the proposed method to demonstrate its pure contribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the mixup technique used in LUMP is also adopted for the proposed method in the experiments on SplitCIFAR100 and SplitTinyImageNet. It suggests that the authors should include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their draft by including additional experiments. However, the comment could be more helpful if it explained why the mixup technique is important or how its exclusion might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the object detectionbased attention being performed on the image or on some convolutional feature map. It suggests clarifying this point and potentially rescaling based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the object detectionbased attention, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on whether the attention is performed on the image or on some convolutional feature map, and whether rescaling is done based on the receptive field. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the object detectionbased attention and its implementation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the object detectionbased attention, specifically asking whether it is performed on the image or on some convolutional feature map. It also suggests clarifying whether rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. This feedback is 3 as it identifies a potential area of confusion in the paper and suggests a way to clarify it. However, the comment could be more helpful if it provided specific suggestions on how to clarify the attention mechanism or offered examples of how rescaling might be implemented. Overall, the comment is 3 as it points out a potential area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide explicit guidance on how to address this issue or what specific analysis should be conducted. The action is implicit and somewhat vague, as the authors can infer that they need to provide theoretical support but are not given specific steps to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for theoretical support and analysis, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. This feedback is valuable as it prompts the authors to consider a potential gap in their analysis and provides a clear direction for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to address this gap or what kind of theoretical analysis might be needed. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider an error in the initial calibration steps (steps 1 and 2) as a possible explanation for the speed disparities observed between the RSPs and FDs. However, it does not provide explicit instructions or concrete steps for the authors to follow in investigating this possibility. The comment implies that the authors should look into the original algorithm used in Section III of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper, but it does not specify how to integrate this into their work or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section of the paper, \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential explanation for the speed disparities observed between the RSPs and FDs, based on an error in the initial calibration steps. The comment provides a clear direction for the authors to consider investigating this possibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a potential explanation for the speed disparities observed between the RSPs and FDs, based on an error in the initial calibration steps. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks detailed justification or examples to support the suggestion, making it difficult for the authors to understand or address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the initial calibration steps, suggesting that an error might explain the speed disparities observed between the RSPs and FDs. It provides a specific reference to the original algorithm used in Section III of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper, which the authors should consider for further investigation. While the comment highlights a potential area for improvement, it lacks detailed guidance or suggestions on how to investigate or address the issue. The authors are given a direction to explore but are not provided with specific steps or actions to take. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that the artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the resemblance between artificial and biological networks. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the issue of artificial networks trained using ASAP (and similar methods) not necessarily resembling biological networks, except for the weight transport problem. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the resemblance of artificial and biological networks, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment acknowledges that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any constructive feedback or suggestions for improvement. The comment does not offer guidance on how the authors might address this issue or improve the resemblance between artificial and biological networks. Without actionable advice or specific recommendations, the comment does not assist the authors in enhancing their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the paper\"s focus on learning HMMs with nonparametric emission distributions but questions how these distributions affect inference. It specifically asks about the inference tasks that can be computed with an NPSPECHMM, such as filtering, smoothing, and marginal observation likelihood. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the inference tasks should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the impact of emission distributions on inference tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on learning HMMs with nonparametric emission distributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how these emission distributions affect inference and asks about the inference tasks that can be computed with an NPSPECHMM. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It asks which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. This is a request for clarification and does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It specifically questions which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. This feedback is valuable as it prompts the authors to clarify and expand on the implications of their work regarding inference tasks. However, the comment could be more helpful if it provided suggestions on how to address this gap or examples of how the authors might explore this aspect further. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. While the comment implies that the authors should consider expanding their dataset analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analyses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section where the authors discuss the datasets considered, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions why only 10 out of 120 datasets are considered and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This feedback is 3 as it identifies a potential area for improvement in the dataset analysis, which could enhance the paper\"s comprehensiveness and rigor. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, making it 3 but not fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation in the introduction, specifically the lowrank factorization, is unnecessary given that the main result is about polytopes. It also implies that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications of the results for lowrank matrix factorization. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"lowrank factorization\" in the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary nature of the lowrank factorization and the potential implications for lowrank matrix factorization. This provides clear guidance on what the authors should consider and discuss in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation in the introduction, specifically the lowrank factorization, is unnecessary given that the main result is about polytopes. The reviewer suggests that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the need for discussing lowrank matrix factorization based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation in the introduction, specifically the use of lowrank factorization. It suggests that the main result is about polytopes and that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. This feedback is 3 as it points out a potential weakness in the paper\"s motivation and suggests a direction for improvement. However, the comment could be more helpful if it provided specific guidance on how to address this issue or what aspects of the lowrank factorization should be discussed. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper is incremental with respect to a specific reference 31 and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their work or what specific aspects of the paper are lacking. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental with respect to a specific reference 31 and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, it does not specify which part of the paper this assessment is based on, such as the methodology or results sections. This makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the authors could improve their work. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental with respect to a specific reference 31 and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any specific details or references to support this claim, such as how the paper is incremental or how the adaptation affects the results. Without additional context or evidence, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental with respect to a specific reference 31 and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve their work or address the issue of incrementality. Without actionable feedback or detailed analysis, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. However, it does not provide any guidance or suggestions on how the authors should address this issue or what specific information should be included to clarify the method. The comment lacks explicit instructions or concrete details, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of an alternating direction method to solve the minmin problem, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what needs to be addressed or improved regarding this method, making it underspecific. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking for clarification about the method used to solve the minmin problem. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or what specific information should be included to clarify the method. The comment lacks actionable feedback or constructive advice, making it 2 for the authors in improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in other environments. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these concerns or improve the draft. The authors are left without any clear direction on how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure2\" and \"MsPacman,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the effectiveness of lower bound double qlearning, noting that the algorithm shows a slight performance decrease in MsPacman and that it may overestimate the true maximum value. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of lower bound double qlearning is doubtful, based on observations from MsPacman and other environments. The reviewer provides specific examples of performance decreases and convergence issues, as well as an overestimation of the true maximum value. These claims are supported by logical reasoning and specific observations, making the comment 4. However, the comment could be strengthened by providing more detailed evidence or references to support the claims, such as specific experiments or data that demonstrate the performance issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the effectiveness of lower bound double qlearning, specifically noting that the algorithm shows a slight performance decrease in MsPacman and may converge to the same solutions in other environments. Additionally, it points out that the algorithm could overestimate the true maximum value. While the comment highlights these concerns, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is 3 as it points out areas of concern, but it lacks actionable advice or detailed analysis to fully support the authors in improving their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the observed behavior, but it lacks concrete steps or suggestions for improvement. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small, and suggests that it should approach vanilla methods from above but from below. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the observed performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. This feedback identifies a potential discrepancy in the results that the authors may need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this issue or improve their analysis. While it points out a potential area for further exploration, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a gap in the paper, noting that it does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not doing so in the author response, the comment suggests that they should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback provides a clear and explicit action for the authors to take, which is to include comparisons with these systems. The comment is specific and provides concrete guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors have explained their reasons for not comparing their results with some earlier research work from 2020. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the comparison with earlier systems with worse performances, such as Taghipour and Ng (2016). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not compare its results with some earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer suggests that the authors should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). However, the comment lacks specific examples or references to the earlier works that the authors have overlooked, making it 3. The authors would need to infer which systems are being referred to and might find it challenging to fully understand the basis of the critique without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that it does not compare its results with some earlier research work from 2020, despite the authors explaining their reasons for not doing so. The comment suggests that the authors should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by including comparisons with relevant earlier works. However, the comment could be more helpful if it included examples of which systems should be compared or how these comparisons could be structured. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors elaborate on the Hoeffding\"s bound and its implications for stochastic algorithms. It provides a clear and specific action for the authors to take, which is to elaborate on the topic. The comment is explicit and provides concrete guidance on what needs to be added to the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 124125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the Hoeffding\"s bound and its implications for stochastic algorithms. This provides clear guidance on what the authors need to address in this section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Hoeffding\"s bound holds true for any w as long as samples are drawn independently, and that stochastic algorithms impose conditioning on the previous iterate to guarantee the inequality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (Line 124125) and suggests that the authors elaborate on the Hoeffding\"s bound and its implications for stochastic algorithms. This feedback is clear and actionable, as it directs the authors to provide additional explanation or context that could enhance the understanding of the paper\"s content. By addressing this suggestion, the authors can improve the clarity and depth of their discussion, making the comment 4. However, it could be more helpful if it provided specific examples or references to support the claim about the Hoeffding\"s bound. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. While the comment implies that the authors should consider adding this information, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is clear but lacks concrete details on how to integrate the metalearning approach into the table. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, it does not specify which part of the table this addition should be made, making it weakly grounded. The comment is specific in suggesting the addition of these approaches, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it would enhance their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. This is a specific and actionable suggestion that could potentially enhance the paper by providing additional context and depth to the table. However, the comment lacks detailed guidance on how to integrate these approaches or why they are relevant to the table. While it points out a potential area for improvement, the feedback could be more comprehensive and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to be careful with the terms \"causal mechanisms\" and \"temporal relationship,\" as they are not interchangeable. This feedback is clear and provides a specific action for the authors to take, ensuring that they use the terms correctly. The comment is concrete, as it specifies the exact issue and offers a direct way to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of terms like \"causal mechanisms\" and \"temporal relationship,\" providing guidance on how to avoid confusion and ensure clarity in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the use of terms \"causal mechanisms\" and \"temporal relationship,\" suggesting that they are not interchangeable. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it points out a specific issue with the use of terms like \"causal mechanisms\" and \"temporal relationship\" in the paper. It provides a clear and actionable suggestion to avoid confusion by using these terms carefully. However, the comment could be more helpful if it offered additional guidance on how to effectively use these terms or provided examples of how they might be misused. While the feedback is valuable, it could be more comprehensive to fully assist the authors in improving their draft. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a desire for a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" While it implies that the authors should include this discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the results need to be addressed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, it is not specific, as it lacks detailed guidance on what aspects of the results need to be discussed or how they relate to the lower bounds. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered 5. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" This feedback is 3 as it identifies a potential area for further exploration and discussion. However, it lacks specific guidance on how to integrate this discussion into the paper or what aspects of the results need to be addressed. While it points out a relevant reference, it does not provide detailed suggestions on how to effectively incorporate this discussion into the paper. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to clarify the assumptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the assumptions and the significance of their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are discussed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the novelty and significance of the results, but without clear grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. The reviewer provides a reference to a related work by Dombrowski et al. (2022) to support their claim about the use of PCA. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the use of PCA is not novel or significant. While the reference provides some context, the comment could be strengthened by offering more detailed analysis or examples to support the critique. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment questions the novelty and significance of the paper, suggesting that the use of PCA to reduce interaction count is intuitive and that the assumptions made are unclear. It references a related work by Dombrowski et al. (2022) to support its claim. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their assumptions. The reference to the external work is helpful, but the comment could be more beneficial if it provided more detailed feedback or suggestions for improvement. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fewshot RC models considered in the paper, noting that they are not stateoftheart models. It asks a question about how the performance of these models compares to relation extraction/generation models in fewshot settings. While the comment implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the fewshot RC models considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of these models compared to relation extraction/generation models in fewshot settings. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart models, referencing external sources. However, it does not provide specific details or comparisons to support this claim, such as which models are considered stateoftheart or how the performance of the models in question compares to those mentioned. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the claim and potentially conduct their own analysis to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the fewshot RC models considered are not stateoftheart models. It raises a relevant question about how the performance of these models compares to relation extraction/generation models in fewshot settings. This feedback is 3 as it prompts the authors to consider the relevance and impact of their model selection, which could influence the paper\"s contribution and significance. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or improve their model selection. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to provide results or observations regarding the use of sequential MCB versus a single MCT layer for the decision head. This is a clear and direct request, as it specifies exactly what the authors need to include in their discussion. The action is concrete, as it specifies the exact information that should be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB versus a single MCT layer for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation or results regarding the observed differences between the two approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the discussion of using sequential MCB versus a single MCT layer for the decision head, noting that no results were shown. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is important or how it could be improved. The comment lacks specificity and does not offer a clear direction for the authors to follow, making it difficult for them to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of interest in the paper, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It points out that while the discussion is interesting, no results or observations are presented, prompting the authors to provide more details. This feedback is 3 as it highlights a gap in the paper that could be addressed with additional information or analysis. However, it lacks specific guidance on what kind of results or observations would be beneficial, leaving the authors with a general direction but not a clear path forward. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights specific language issues in the paper, such as \"we typically considers\" and \"two permutation,\" and requests that the authors proofread the paper to fix all language problems. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should proofread the paper to fix language issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"the above of (7)\" and \"the above of Theorem 1,\" allowing the authors to accurately identify the parts being addressed. It also specifies the language issues, such as \"we typically considers\" and \"two permutation,\" providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of comments on language usage and requests for proofreading. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific language issues in the paper, such as \"we typically considers\" and \"two permutation,\" and requests that the authors proofread the paper to fix all language problems. While this feedback is clear and actionable, it does not provide detailed guidance on how to improve the language usage or suggest specific improvements. The authors are given a clear direction to address the language issues, but the comment could be more helpful if it included examples or suggestions for improvement. Therefore, the comment is 3, as it provides a starting point for the authors to improve their draft but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks about the implications of selecting only a few distribution sets. While the comment implies that the authors should clarify these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the distribution sets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of 20 distribution sets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the number of distribution sets for each class can be controlled and what the implications would be if only a few distribution sets are selected. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks about the implications of selecting only a few distribution sets. While the comment highlights areas of uncertainty, it does not provide specific reasoning or evidence to support why these questions are relevant or how they impact the paper. The lack of detailed justification or examples makes the claim 3, as the authors may find it challenging to fully understand and address the concerns without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the choice of 20 distribution sets and the potential implications of selecting only a few distribution sets. It prompts the authors to clarify whether the number of distribution sets for each class can be controlled and what the consequences might be if only a few distribution sets are selected. This feedback is clear and actionable, as it guides the authors to provide more detailed information about their methodology and potential limitations. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how other studies have handled similar issues. Overall, the comment is 4 as it directs the authors to clarify important aspects of their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models, which raises concerns about its broader applicability. The reviewer suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicunna or Alpaca. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this limitation or expand the scope of their framework. The action is implicit and somewhat vague, as the authors need to infer that they should consider broadening the scope of their framework. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluative framework, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited scope of the framework, which is restricted to only three QuestionAnswering tasks and two language models, and raises concerns about its broader applicability. The comment suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicunna or Alpaca. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope, restricted to only three QuestionAnswering tasks and two language models, which raises concerns about its broader applicability. The comment suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicunna or Alpaca. However, the comment lacks specific examples or references to substantiate these concerns, making it 3. The authors would need to infer the potential applicability issues and address them themselves, rather than having clear guidance on how to improve the framework. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. This observation raises concerns about the method\"s broader applicability, as it may not generalize to other reasoning or generation tasks or more advanced models like Vicunna or Alpaca. While the comment highlights a potential issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or expand the scope of their framework. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice or detailed guidance for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This is a clear and concrete action for the authors to take, as it provides a specific direction for improvement. The comment also highlights the issue with using obsolete language models, which adds context and guidance for the authors. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the specific language models used, such as ngram HMM and RNN, which are considered obsolete. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the perplexity experiments are carried out on obsolete language models, specifically ngram HMM and RNN, which are not commonly used nowadays. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models to align the paper with current NLP trends. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to current NLP trends or the relevance of transformerbased models. The authors would need to make an effort to understand and address the suggestion, which justifies a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the perplexity experiments, noting that they are carried out on obsolete language models (ngram HMM, RNN) that are no longer commonly used in NLP. It suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that could enhance the relevance and impact of the paper. By addressing this issue, the authors can better align their work with current research trends and demonstrate the applicability of their approach. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, which makes it unclear how it can be estimated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might clarify this issue or what specific steps they could take to address it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the discussion on the misestimation of mu, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper this discussion is located in, making it weakly grounded. The comment is specific in pointing out the issue with the estimation of mu, as it is the proportion of missing observations, which is not clear how it can be estimated. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the discussion on the misestimation of mu, noting that it is the proportion of missing observations, which makes it unclear how it can be estimated. This claim is 3 as it highlights a potential issue with the clarity of the discussion. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the discussion on the misestimation of mu, noting that it is the proportion of missing observations, which makes it unclear how it can be estimated. This feedback highlights a specific area where the authors need to provide more clarity in their explanation. However, the comment does not offer suggestions or guidance on how to improve the clarity or what specific aspects of the discussion need attention. While it points out a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This feedback is explicit and provides concrete guidance on how to implement the suggested approach. The authors know exactly what steps to take to address the issue of sensitivity to initialization. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of sensitivity to initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, with a detailed explanation of how to implement this approach. This level of detail provides the authors with clear guidance on how to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This claim is 4 as it logically follows the suggestion to present the performance in this way, and it provides a clear rationale for the expected behavior of the performance with varying initialization quality. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have demonstrated this effect. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for addressing the issue of sensitivity to initialization. It suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, which is a clear and concrete approach. The comment also provides a detailed explanation of how to implement this approach, specifying a range of distances to consider and suggesting a method for randomly sampling initialization. This level of detail and guidance is highly beneficial for the authors, as it offers a clear path for improving their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider providing highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the use of ensemble methods and robustness measures, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to ensemble methods or robustness measures that have been successfully used in similar contexts. This makes the claim 3, as the authors would need to infer the specifics of how to implement these suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, as it provides a concrete direction for enhancing the paper\"s rigor and robustness. By suggesting specific methods to improve the analysis, the comment empowers the authors to make meaningful enhancements to their draft. However, it could be more helpful if it included examples or references to similar studies that have successfully implemented these methods. Overall, the comment is 4 as it offers clear and actionable guidance for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation for the work is good but that the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so or provide specific guidance on how to implement these evaluations. The action is implicit and somewhat vague, as the authors need to infer the need for these additional evaluations and determine how to incorporate them into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation for the work is good but the results are less impressive, and it recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specific areas for improvement, it lacks full grounding as it does not explicitly mention where these issues are discussed or addressed in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the motivation for the work is good but the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, the comment lacks specific examples or detailed reasoning to support why the results are less impressive or how these additional aspects should be evaluated. Without specific examples or references, the claim is 3, as it provides a general direction for improvement but lacks detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, suggesting that they are less impressive despite a good motivation. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment provides some insight into areas for improvement, it lacks specific guidance or examples on how to implement these evaluations or what specific metrics to use. The feedback is 3 as it points out a potential weakness but does not offer detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might incorporate diversity into their model or what specific steps they should take to ensure that their model enforces diversity. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the paper\"s motivation for diversity, specifically mentioning that the model does not enforce diversity explicitly. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the model\"s lack of diversity enforcement, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model. The reviewer expresses disappointment at the lack of diversity in the model. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. This is a critical point as it undermines the paper\"s claims about promoting diversity. However, the comment lacks specificity and actionable suggestions on how the authors might address this issue or improve their model to enforce diversity. Without detailed guidance or examples, the authors may struggle to understand the exact areas needing improvement or how to implement changes. Therefore, the comment is 3, as it points out a critical weakness but does not provide enough direction for the authors to effectively address it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on how the authors should address this issue or what specific experiments should be included. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated into the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence affects the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue by pointing out the absence of certain experiments, such as contrastive learning and adversarial learning. This feedback is 3 as it highlights a potential gap in the experimental setup, which the authors should address to provide a more comprehensive evaluation of their work. However, the comment lacks depth and does not offer suggestions on how to incorporate these experiments or what specific aspects of the paper would benefit from their inclusion. While it points out a potential area for improvement, it does not provide detailed guidance on how to address it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The suggestion to use DinoV2 Frechet Distances is specific and actionable, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simplistic Inception network\" and \"FIDs,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of DinoV2 Frechet Distances for comparisons in addition to the widely used FID metric. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are \"clear flaws associated with FIDs and the simplistic Inception network,\" but it does not provide specific examples or references to support this claim. The suggestion to use DinoV2 Frechet Distances is made, but without further explanation or justification, it remains unclear why this alternative metric is preferred over FIDs. The lack of detailed reasoning or evidence makes the claim 2, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of FIDs for evaluation, noting that there are \"clear flaws associated with them and the simplistic Inception network.\" It provides a constructive suggestion by recommending the use of DinoV2 Frechet Distances in addition to FIDs for comparisons. This feedback is actionable and offers a clear path for improvement, as it directs the authors to consider an alternative metric that could provide a more comprehensive evaluation. However, the comment could be more helpful if it explained why FIDs are flawed or why DinoV2 Frechet Distances are preferred. Overall, the comment is 4 as it provides a specific and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the novelty of the paper and asks for clarification on how it differs from a specific reference. While it implies that the authors should provide a comparison with the reference, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed comparison to justify the novelty of their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the novelty of the paper and seeks clarification on how it differs from a specific reference. However, it does not specify which part of the paper should be addressed or where the comparison with the reference is made. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where the comparison is made, the comment lacks specificity in terms of what needs to be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the novelty of the paper and seeks clarification on how it differs from a specific reference. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the novelty is incremental. Without such details, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the novelty of the paper and seeks clarification on how it differs from a specific reference. While it identifies a potential issue with the paper\"s novelty, it does not provide specific guidance or suggestions on how the authors might address this concern. The comment lacks depth and does not offer actionable feedback or constructive advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their analysis. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them without a clear path forward. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"CUB and SOP datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the reported ablation studies, where the complete loss function performed worse than those with missing terms. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. This observation raises a valid concern about the validity of the results and prompts the authors to question why this might be the case. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a potential problem, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should test inverse triples in other embedding models besides CP, which could provide additional insights into the effectiveness of their approach. While the comment implies that the authors should conduct these tests, it does not explicitly instruct them to do so. The action is concrete, as it specifies a specific test that could be conducted, but it is somewhat vague because it does not provide detailed guidance on how to implement these tests or what specific models should be tested. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should test inverse triples in other embedding models besides CP, which could provide additional insights into the effectiveness of their approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental setup, but this inference is not direct. The comment is specific in suggesting a potential test, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that introducing inverse triples might be useful in other embedding models besides CP, but it does not provide any evidence or reasoning to support this claim. The comment lacks specific examples or references to other models where inverse triples could be applied, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors test inverse triples in other embedding models besides CP. This is a relevant point as it could provide additional insights into the effectiveness of their approach. However, the comment lacks specific guidance on which models should be tested or how to implement these tests. While it highlights a potential area for improvement, it does not offer detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly points out that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. It also implies that technical details are not necessary for the abstract. While the comment provides a clear action\u2014to clarify the statement and simplify the abstract\u2014it does not offer specific guidance on how to achieve this clarity or what aspects of the statement are unclear. The authors are left to infer the necessary changes, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement regarding the lowrank feature subspace, a small number of attacked samples, and other mild assumptions. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and that technical details are not necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. The reviewer provides a specific example of the unclear statement, \"with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions,\" which is helpful in clarifying the issue. However, the comment lacks detailed reasoning or references to support why this statement is unclear or how it could be clarified. While the example is provided, the lack of further explanation or justification makes the claim 3, as the authors may need to infer the basis of the claim and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and suggests that it should be revised to be more highlevel. It provides a clear example of the problematic statement, \"with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions,\" which helps the authors understand the exact part of the abstract that needs improvement. The comment also suggests that technical details are not necessary for the abstract, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it offered suggestions on how to simplify the statement or provided examples of how to achieve a more highlevel abstract. Overall, the comment is 3 as it identifies a specific issue and offers a direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific guidance or suggestions on how to achieve this improvement. The authors are left to infer that they need to make changes to the algorithm, but without concrete steps or examples, they may struggle to determine what exactly is required. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of the paper discusses Algorithm 2 or where it is located. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of Algorithm 2 need improvement or how to achieve this improvement. Without clear guidance or examples, the authors may struggle to understand and address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that there is room to improve the complexity of Algorithm 2, which is a relevant observation. However, it lacks specificity and does not provide any guidance or suggestions on how to achieve this improvement. Without actionable advice or examples, the authors are left without a clear path to follow, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not provide explicit guidance on how the authors should address this critique or improve their approach. It lacks actionable details, such as recommending specific ways to enhance the novelty or suggesting alternative approaches. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not specify which part of the paper discusses the use of GP, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where GP is discussed, the comment lacks full grounding. It is specific in pointing out the issue of novelty, but without detailed guidance on how to address it, the authors may struggle to make the necessary changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of Gaussian Processes (GP) is straightforward and naive, suggesting that the approach is not novel. The reviewer supports this claim by referencing the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. This reference provides a basis for the claim, as it highlights a wellestablished area of research within the GP community. However, the comment could be strengthened by providing more detailed examples or comparisons to other approaches that have been explored in the literature. As it stands, the claim is 4 due to the reference to a specific work, but it could be further substantiated with additional evidence or examples.", "helpfulness_rationale": "The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. While the comment identifies a potential weakness in the paper\"s contribution, it lacks specific guidance on how the authors might address this critique or improve their approach. It does not provide actionable suggestions or examples of alternative approaches that could enhance the novelty or impact of the work. As a result, the comment is 3, as it points out a potential issue but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the statement in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. It points out that this claim is not supported by the authors\" experience, as evidenced by the training of 1500dimensional LSTMs on PTB. The reviewer also asks about the application of dropout to both embeddings and hidden states. While the comment identifies a specific issue with the statement, it does not provide explicit guidance on how to address it or what changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and provide evidence or clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the supplemental section D.4, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that smaller architectures are necessary for LM compared to GAN models, suggesting that the baseline models are not properly regularized. The reviewer also asks about the application of dropout to both embeddings and hidden states. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. The reviewer provides a counterexample by citing the training of 1500dimensional LSTMs on PTB, which suggests that the baseline models are not properly regularized. This provides a logical and 3 argument against the claim, as it challenges the basis of the statement. However, the comment could be strengthened by providing more detailed evidence or references to support the counterexample. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific claim in the supplemental section D.4 that is questionable, suggesting that the statement about smaller architectures being necessary for LM compared to GAN models is not supported by the authors\" experience. The reviewer provides a counterexample by citing the training of 1500dimensional LSTMs on PTB, which challenges the basis of the claim. Additionally, the comment asks about the application of dropout to both embeddings and hidden states, which could be a relevant area for clarification or discussion. While the comment highlights a potential issue and raises a relevant question, it could be more helpful if it provided more detailed guidance on how to address the claim or the dropout application. Overall, the comment is 3 as it points out a potential weakness and offers a direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly challenging to locate. The action is implicit and vague, as the authors are left to infer that they need to improve the clarity of the writing, but without concrete steps on how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"previous sections\" and \"the following contents,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the ablations being difficult to locate in the writing, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without specific examples or references, the claim lacks verifiability, making it challenging for the authors to understand and act upon the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the writing, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. This feedback is valuable as it highlights an area where the authors can improve the readability and accessibility of their work. However, the comment could be more helpful if it provided specific examples of where the ablations are difficult to locate or suggested ways to improve the clarity of the writing. Despite this, the comment still offers actionable guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is currently \"halfbaked\" and encourages the authors to think through it more clearly. It also highlights the novelty of the online algorithm and robustness, which should be integrated into the main paper. However, the comment does not provide specific guidance on how to improve the differential privacy application or what aspects need more clarity. The feedback lacks concrete steps or detailed suggestions, leaving the authors uncertain about how to address the issues. As a result, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also mentions the online algorithm and robustness as being interesting and novel, and suggests that the experimental results in the appendix would be better in the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application, making it weakly grounded. The comment is specific in its critique of the differential privacy application and the suggestion to integrate the online algorithm and robustness into the main paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. However, the comment does not provide specific reasoning or examples to support this claim. It mentions the online algorithm and robustness as being interesting and novel, but this does not address the issue of the differential privacy application being \"halfbaked.\" The lack of detailed justification or examples makes the claim 3, as the authors may find it challenging to understand and address the issue without further explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the differential privacy application, suggesting that it is currently \"halfbaked.\" It encourages the authors to think through it more clearly and integrate the online algorithm and robustness into the main paper. This feedback is 3 as it points out an area that could be improved, but it lacks specific guidance on how to address the issue or what aspects need more clarity. The comment could be more helpful if it provided suggestions on how to improve the differential privacy application or examples of how to integrate the online algorithm and robustness into the main paper. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the contribution of multilingual chainofthought is incremental compared to the villa chainofthough. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their work. There is no explicit or implicit action for the authors to take, such as suggesting ways to enhance the contribution or providing examples of how to differentiate the two approaches. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthough, but it does not specify which part of the paper this comparison is made in. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered incremental or how the authors might address this issue. Without explicit references or detailed guidance, the authors cannot effectively understand or address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthough. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthough, suggesting that the former is incremental. However, it does not provide any specific insights or suggestions on how the authors might address this issue or improve their work. Without actionable feedback or detailed guidance, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to include the METEOR results, which are reported in recent works. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment provides a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the inclusion of METEOR results, which is a specific aspect of the paper. However, it does not specify which part of the paper should include these results, such as a specific section or table. This makes the comment weakly grounded, as the authors cannot confidently determine the exact location of the METEOR results in the paper. The comment is specific in its request for the inclusion of METEOR results, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include the METEOR results, which are reported in recent works. However, the comment does not provide any supporting evidence, references, or reasoning to justify why this inclusion is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include the METEOR results, which are reported in recent works. This is a clear and actionable suggestion that can help improve the paper by providing additional evidence or comparison. However, the comment lacks depth and does not explain why the inclusion of these results is important or how they might impact the paper\"s conclusions. While it identifies a specific area for improvement, it could be more helpful if it provided more context or justification for the suggestion. Therefore, the comment is 3, as it points out a potential improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern regarding the comparability of Geffect values across various unlearning objectives and approaches. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting ways to improve the comparability of Geffect values or recommending specific analyses to be conducted. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across various unlearning objectives and approaches. It does not present any claims or opinions but rather highlights a potential issue in the study. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential concern regarding the comparability of Geffect values across various unlearning objectives and approaches. It points out that studying these effects in isolation may lead to inaccurate conclusions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparability of their results. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider the reason why information value is a stronger predictor for dialogue and whether there are existing linguistic theories that could explain this phenomenon. It also implies that adding this information would strengthen the paper. While the comment provides a clear direction for the authors to explore and potentially include additional information, it does not specify how to integrate this into the paper or what specific linguistic theories should be considered. The action is explicit but somewhat vague in terms of execution, as the authors need to determine the exact approach to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the reason why information value is a stronger predictor for dialogue and whether there are existing linguistic theories that could explain this phenomenon. The comment suggests that adding this information would strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors consider the reason why information value is a stronger predictor for dialogue and whether there are existing linguistic theories that could explain this phenomenon. The comment implies that adding this information would strengthen the paper. However, it does not provide specific examples or references to existing linguistic theories or studies that could support this claim. Without such evidence or detailed reasoning, the claim is 3, as it requires the authors to make a significant effort to explore and substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a potential area for improvement by suggesting that the authors consider the reason why information value is a stronger predictor for dialogue and whether there are existing linguistic theories that could explain this phenomenon. This feedback is clear and actionable, as it prompts the authors to explore a specific aspect of their work that could enhance its theoretical foundation and rigor. However, the comment could be more helpful if it provided specific suggestions on how to integrate this information or what linguistic theories might be relevant. Overall, the comment offers valuable guidance for improving the paper, but it could be more comprehensive with additional details. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a perceived lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performance, specifically mentioning the extraction of hints for future network architecture design. It implies that the authors should provide more detailed commentary on these aspects. However, the comment does not explicitly instruct the authors to include this discussion or specify what specific takeaways should be highlighted. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AutoML approaches and the potential benefits beyond raw performance, such as extracting hints for future network architecture design. It also specifies the lack of discussion on these aspects, providing clear guidance on what the authors should address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main reason for using AutoML approaches is not just improving raw performance but also extracting hints for future network architecture design. The reviewer suggests that the authors should have spent more time discussing these aspects, specifically what might be the biggest takeaways from the found architecture. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the importance of these aspects and might find it challenging to understand the basis of the claim without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of discussion on the potential benefits of using AutoML approaches beyond raw performance. It highlights the importance of extracting hints for future network architecture design and suggests that the authors should have spent more time discussing these aspects. While the comment provides a clear direction for improvement, it lacks specific suggestions or examples on what might be the biggest takeaways from the found architecture. This limits the comment\"s helpfulness, as it points out an area for improvement but does not fully guide the authors on how to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the paper where T_a(t) is used in Section 3.1 but only defined in Section 4. This is an explicit observation that the authors can directly address by providing the definition in the appropriate section. The comment is clear and concrete, as it specifies the exact issue and suggests a straightforward action to resolve it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the use of T_a(t) in Section 3.1 but only being defined in Section 4. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that T_a(t) is used in Section 3.1 but only defined in Section 4. This is a factual observation that does not require any subjective judgment or opinion. It is a statement of fact that can be verified by the authors themselves, as it is directly observable from the paper. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper regarding the use of T_a(t) in Section 3.1 but only being defined in Section 4. This is a clear and actionable observation that the authors can address to improve the consistency and clarity of their work. By pointing out this issue, the comment provides the authors with a specific area to focus on for revision, ensuring that the definition is in the appropriate section. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or completeness of the definition in Section 4. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While the action is implicit, it is clear that the authors need to condense the introduction and include empirical results to enhance the paper. The comment provides a specific direction for improvement, but it lacks detailed guidance on how to achieve this concision or which empirical results should be included. Therefore, the action is 3, as the authors know they need to make changes but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, it does not specify which part of the introduction is too long or where empirical results should be included. The authors can infer that the introduction and empirical results sections are being addressed, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, the comment does not provide any specific examples or reasoning to support why the current introduction is too long or how empirical results could enhance it. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While it identifies a potential area for improvement, it lacks specific guidance on how to achieve this concision or which empirical results would be most relevant. The comment provides a general direction for improvement but does not offer detailed suggestions or examples to help the authors effectively enhance their draft. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not provide specific guidance on what kind of evidence or arguments would be sufficient or how the authors should present them. The action is implicit and somewhat vague, as the authors can infer that they need to provide more substantial evidence or arguments but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not specify which part of the paper discusses this advancement or where the authors should provide additional evidence or arguments. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment is specific in suggesting that more substantial evidence or arguments are needed, but without clear guidance on where to apply this, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s contribution, suggesting that the primary contribution appears to be an incremental advancement in efficiency over the TACTiS approach. It acknowledges that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, the comment does not provide specific guidance on what kind of evidence or arguments would be sufficient or how the authors might present them. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities is incremental and does not provide a clear direction for improvement. However, the comment does not offer specific guidance on how to address these concerns or what additional aspects could be explored to enhance the novelty of the paper. The lack of explicit suggestions or concrete actions makes it difficult for the authors to know how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, it does not specify which datasets or parts of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the novelty could be enhanced. Without clear guidance on what needs to be addressed, the authors cannot effectively improve their draft. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities seems incremental and does not provide a clear direction for improvement. However, the comment lacks specific suggestions or examples of how the authors could enhance the novelty or impact of their work. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the critique or improve their draft. Therefore, the comment is rated as 2, as it identifies a potential issue but does not provide sufficient guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the method only provides marginal improvements over baselines, with most improvements within the error bar range. It also notes that the authors claim the method performs better than the baselines, but the high error range suggests that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance of their method. The action is implicit and vague, as the authors are left to infer that they need to improve the performance of their method, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method compared to baselines, suggesting that the improvements are marginal and within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the high error range suggests otherwise. However, the comment does not specify which part of the paper discusses these claims or where the performance comparisons are made, making it weakly grounded. The comment is specific in its critique of the performance improvements and the high error range, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method provides only marginal improvements over baselines, with most improvements within the error bar range. It also suggests that the authors\" claim of better performance is not supported by the high error range, implying that the performance differences are not significant. The comment provides some logical reasoning by pointing out the high error range, but it lacks specific examples or references to support the claim that the performance differences are not significant. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the method provides only marginal improvements over baselines, with most improvements within the error bar range. It also points out that the authors claim the method performs better than the baselines, but the high error range suggests otherwise. This feedback is valuable as it highlights a potential weakness in the paper\"s claims and provides a clear direction for the authors to address. However, the comment could be more helpful if it offered specific suggestions on how to improve the performance or how to present the results more effectively. Overall, the comment is 4 as it directs the authors\" attention to a critical area needing improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how to make the proposed evaluation set more diverse and representative than the previous method and how to select representative images. However, it does not provide any explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should provide more details or examples, but it does not specify what those details or examples should be. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of diversity and representation in the proposed evaluation set, specifically mentioning the need for clarity on how to make the set more diverse and representative than the previous method and how to select representative images. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the evaluation set is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what needs to be clarified regarding diversity and representation, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed evaluation set is unclear in terms of diversity and representation, and how to select representative images. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed evaluation set, specifically the lack of clarity on how to make it more diverse and representative than the previous method and how to select representative images. This is an important point that could significantly impact the validity and applicability of the evaluation results. However, the comment does not provide specific suggestions or examples on how to address these issues, nor does it offer guidance on how to improve the diversity and representation of the evaluation set. While it highlights a significant area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. It also suggests providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. These actions are clear and concrete, as they specify exactly what needs to be added to the paper to improve clarity and understanding. The authors know exactly what steps to take to address the feedback, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the background section and provides guidance on the overview of the original DPO algorithm. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the context. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. While the comment identifies specific areas that need clarification, it lacks detailed reasoning or examples to fully substantiate the claim. The authors might find it challenging to understand the exact nature of the issues without additional context or examples. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting the inclusion of a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. This is crucial for clarifying the context and setting the stage for the subsequent sections. Additionally, it recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This feedback is 5 as it directly addresses areas where the paper could be improved in terms of clarity and comprehensibility. By following this advice, the authors can significantly enhance the accessibility and understanding of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the method to accommodate continuous language addition. The comment lacks actionable guidance or specific steps for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a potential limitation of the proposed method, specifically the issue of handling continuous addition of new languages due to the limited model capacity. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the method, but without explicit references to sections or details, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method may encounter a limitation due to the limited model capacity when users continuously add new languages. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. This is a relevant point that could impact the scalability and applicability of the method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or improve the method to accommodate continuous language addition. Without actionable advice or detailed feedback, the comment offers some insight but does not fully support the authors in improving their draft. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The comment implies that the authors should provide more information about the parameters and their impact on efficiency, but it lacks concrete steps or examples to follow. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the number of parameters does not change when the kernel height/width remains the same, and it suggests that more details are expected regarding the efficiency improvements. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. The reviewer provides a logical reasoning by explaining that if the kernel height/width remains the same, the depth will increase, resulting in more parameters. However, the comment lacks specific examples or references to support the claim about the number of parameters or the efficiency improvements. While the reasoning is somewhat clear, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the S2D structure regarding the number of parameters and suggests that more details are expected regarding the efficiency improvements. It provides a logical explanation of how the depth of the structure could increase with the same kernel height/width, resulting in more parameters. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional details should be included. While it points out a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in 10, suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or differentiate their method from 10. The comment lacks actionable details, such as recommending specific modifications or discussions to be included in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"approach in 10,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the approach in 10 cannot use the additional information of scoring causal predictions and interventional data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the similarity between the proposed method and an existing approach in 10, suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comparison or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in 10, suggesting that the latter could also incorporate scoring causal predictions and interventional data. It questions why 10 cannot use these side information. While the comment identifies a potential issue with the originality of the proposed method, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from 10. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results presented in Section 7.2 are limited to a single game and a single baseline, making it difficult to interpret the findings. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the interpretability of their results. There is no guidance on whether they should expand the scope of their experiments, include additional baselines, or provide more detailed analysis. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results are limited to a single game and a single baseline, making it difficult to interpret the findings. This provides clear guidance on what needs to be addressed to improve the interpretability of the results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Section 7.2 are limited to a single game and a single baseline, making it difficult to interpret the findings. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the results presented in Section 7.2, specifically noting that the Atari game result is limited to a single game and a single baseline. This observation highlights a potential issue with the interpretability of the findings, as it may be difficult for readers to understand the significance of the results without additional context or comparisons. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the interpretability of their results. While it points out a relevant issue, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that the GPC\"s superior performance is due to the bandit feedback and not the form of the cost function. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be addressed in the paper. The comment is 5 as it offers a specific guidance on how to improve the draft by clarifying the rationale behind the simulation results.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comment, which is that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). The comment provides a clear suggestion for improvement by recommending that the authors reiterate the reason for the GPC\"s superior performance, which is due to the bandit feedback and not the form of the cost function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study does not provide a clear explanation for why the GPC (benchmark) is performing better than BPC (the authors\" method). The reviewer suggests that the authors should reiterate that the GPC\"s superior performance is due to the bandit feedback and not the form of the cost function. While the comment identifies a specific issue with the presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion is 3 as it points out a potential gap in the explanation but requires more detailed justification to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that the GPC\"s superior performance is due to the bandit feedback and not the form of the cost function. This feedback is clear and actionable, as it provides a concrete suggestion for improvement by directing the authors to clarify the rationale behind the simulation results. By addressing this point, the authors can enhance the clarity and comprehensibility of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. It implies that the authors should provide more information about the calculation method or clarify the discrepancy between the reported perplexities and the better BLEU scores. While the comment does not explicitly instruct the authors to provide this information, it clearly points out a potential issue that needs to be addressed. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks explicit instructions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reported perplexities, which are over 30, and asks for clarification on how they were calculated. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the reported perplexities in Figure 1, which are over 30, and suggests that this high perplexity contradicts better BLEU scores. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the overall quality of the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be fully understood and addressed by the authors. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. This is a relevant observation that could impact the interpretation and validity of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their methodology. While it points out a potential problem, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the evaluation should include experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, specifying exactly what additional experiments are needed to improve the draft. The comment is specific and concrete, giving the authors a clear path to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for additional experiments, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or examples to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is 3 as it identifies a potential area for improvement in the evaluation section. However, it lacks specific guidance on how to conduct these experiments or what aspects of the evaluation would be enhanced by including them. The comment could be more helpful if it provided suggestions on how to design and implement these experiments, or how they would impact the evaluation results. As it stands, the comment offers a general direction for improvement but does not fully support the authors in making those changes. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors need to elaborate on the importance of rooted patterns and how they choose the roots. It suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback provides clear and concrete actions for the authors to take, such as elaborating on the importance of rooted patterns or discussing nonrooted patterns in the supplementary material. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concept of \"rooted patterns\" and how they are defined, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of elaboration on why rooted patterns are important and how they are chosen. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not elaborate on the importance of rooted patterns or how they choose the roots. It suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, that the discussion should be moved to the supplementary material. The comment provides a logical reasoning for the need to clarify these aspects, but it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more detail or clarification. It points out that the concept of rooted patterns is defined in a similar way to orbit counting in GSN, but it does not elaborate on why rooted patterns are important or how they are chosen. The comment suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and completeness of their explanation. However, it could be more helpful if it provided specific suggestions on how to elaborate on the importance or the choice of roots. Overall, the comment is 4 as it directs the authors to a critical area needing further explanation, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include failure cases and related discussions. While it implies that the authors should include these elements, it does not provide specific guidance on how to implement this suggestion or what aspects of the failure cases should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should include failure cases and related discussions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including failure cases and related discussions, but it does not specify which part of the paper should include these elements. The authors cannot confidently determine which sections or parts of the paper are being addressed, making the comment weakly grounded. However, the suggestion is specific in terms of what needs to be added, providing clear guidance on what the authors should consider. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including failure cases and related discussions would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be valuable or how it would enhance the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that including failure cases and related discussions would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what types of failure cases should be included or how they should be discussed. The comment is 3 as it points out a potential enhancement, but it does not offer actionable advice or detailed suggestions for implementation. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that an ablation study on the necessity of the base layer GNN encoding would be helpful. This provides a clear and direct action for the authors to take, which is to conduct an ablation study to understand the role of the base layer GNN encoding in the proposed method. The comment is specific in its request, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"base layer GNN encoding\" in the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the necessity of the base layer GNN encoding and the need for an ablation study. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to understand its role. However, the comment does not provide specific reasoning or evidence to support why the base layer GNN encoding is unnecessary or how an ablation study would benefit the paper. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the suggestion without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the necessity of the base layer GNN encoding in the proposed method. It suggests conducting an ablation study to understand the role of this layer and its impact on the overall performance. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to explore and potentially improve their method. By addressing this point, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it included specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to explicitly add the upper bounds of counting homomorphisms and potentially elaborate on empirical runtimes. This is a clear and concrete action for the authors to take, as it provides a specific direction for improvement. The comment also suggests that the authors should elaborate on empirical runtimes, which adds another actionable point. Therefore, the comment is 5, as it provides clear guidance on how to enhance the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the computational complexity of counting homomorphisms, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, providing a specific example of a brief statement made in the paper. The reviewer suggests that the paper should explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. While the comment identifies a specific issue with the paper, it lacks detailed reasoning or references to support the claim that the current discussion is insufficient. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their paper, namely the discussion of computational complexity in counting homomorphisms. It points out that the current discussion is brief and lacks depth, suggesting that the authors should explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their analysis and presentation. By addressing these points, the authors can significantly improve the clarity and depth of their discussion on computational complexity. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. The reviewer implies that a comparison with previous topdown and bottomup pose estimation methods could be valuable. While the comment implies that the authors should conduct this study, it does not provide explicit instructions or concrete steps on how to conduct the comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests studying the inference time of the pose estimation method, which is a direct method that does not require detection or keypoint grouping. It implies that a comparison with previous topdown and bottomup pose estimation methods could be valuable. However, the comment does not specify which part of the paper should include this study or how it should be conducted. While the authors might have an idea of where this information could be included, the lack of explicit guidance makes it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. The reviewer claims that a comparison with previous topdown and bottomup pose estimation methods could be valuable. However, the comment lacks specific examples or references to support the claim that a comparison is necessary or beneficial. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. This is a valuable suggestion as it could provide insight into the performance of the method compared to other pose estimation methods. However, the comment lacks specific guidance on how to conduct this study or what aspects of the inference time should be analyzed. While it identifies a potential area for improvement, the lack of detailed instructions or examples limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed guidance for the authors to fully address the suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment critiques the claim about evolutional dropout and its limitations in addressing internal covariate shift. It suggests that the authors should explicitly discuss these limitations, particularly regarding the role of batch normalization in standardizing variance and centering activation. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to discuss these limitations or what aspects should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the limitations but may not be entirely sure of the exact details to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about evolutional dropout and its limitations in addressing internal covariate shift. It also specifies the issue with batch normalization, which standardizes variance and centers activation. This provides clear guidance on what needs to be addressed in the paper. However, the comment could be more specific by suggesting how the authors should discuss these limitations or what aspects of batch normalization should be emphasized. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer supports this claim by comparing it to batch normalization, which standardizes variance and centers activation. However, the comment lacks specific examples or references to substantiate the claim, making it 3. The authors would need to infer the limitations and make a logical connection themselves, which may not be immediately clear. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the claim about evolutional dropout addressing internal covariate shift. It suggests that the claim is limited because it can only increase the variance of some lowvariance units, while batch normalization standardizes the variance and centers the activation. This feedback is clear and actionable, as it directs the authors to explicitly discuss these limitations in their paper. However, the comment could be more helpful if it provided specific suggestions on how to discuss these limitations or what aspects of batch normalization should be emphasized. Overall, the comment is 4 as it guides the authors toward improving the clarity and depth of their discussion on this topic."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the author to add more description about the contribution of the paper. This is a clear and direct action, as it specifies what the authors need to do to improve their draft. The comment provides a specific suggestion for enhancing the paper\"s clarity by adding more details about the contribution. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper this additional description should be added to, nor does it provide any guidance on what specific aspects of the contribution should be elaborated on. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need additional description. Therefore, this comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without specific guidance or evidence, the claim is not verifiable, as it lacks the necessary support to help the authors understand and address the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that the authors should add more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what aspects of the contribution should be elaborated on or how this additional description would enhance the paper. Without detailed suggestions or examples, the authors may find it challenging to understand and implement the feedback effectively. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides several explicit suggestions for improving the paper. It recommends separating the introduction of two types of attention for deep VAEs into a separate section, which would help clarify the main contributions. Additionally, it suggests describing the generative and inference models after introducing the attention mechanisms. The comment also recommends organizing tricks like normalization or feature scaling into a separate section. Each of these suggestions is clear and concrete, providing the authors with specific actions to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"2.3\" and \"2.4,\" where the description of the layerwise attention mechanism is scattered. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear suggestions for improvement, such as separating the introduction of the two types of attention for deep VAEs and organizing tricks like normalization or feature scaling into a separate section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests several improvements to the paper, including separating the introduction of two types of attention for deep VAEs into a separate section, describing the generative and inference models after introducing the attention mechanisms, and organizing tricks like normalization or feature scaling into a separate section. These suggestions are based on logical reasoning and common practices in the field, but they do not provide specific examples or references to support the claim. The authors might find it challenging to fully understand and implement the suggestions without additional context or evidence. Therefore, the comment is 3, as it provides a basis for the claims but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It recommends separating the introduction of two types of attention for deep VAEs into a separate section, which would help clarify the main contributions of the paper. This suggestion is clear and specific, as it directs the authors to organize their material in a way that enhances the reader\"s understanding. Additionally, the comment suggests describing the generative and inference models after introducing the attention mechanisms, which would further clarify the paper\"s contributions. The comment also recommends organizing tricks like normalization or feature scaling into a separate section, which could improve the paper\"s organization and readability. Overall, the comment is 5 as it offers detailed and actionable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. It also notes that the benchmarks used are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of minimal performance differences or how to update the benchmarks. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance differences between methods, noting that they are minimal across evaluations and often less than 1 percentage point. It also mentions that the benchmarks used are outdated and likely saturated, referencing specific works. However, the comment does not specify which part of the paper discusses these performance differences or the benchmarks, making it weakly grounded. The comment is specific in detailing the issue of minimal performance differences and the need to update the benchmarks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point, which may be due to random variation. The reviewer supports this claim by referencing the outdated and likely saturated benchmarks used. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some evidence, it could be strengthened with more detailed analysis or references to specific experiments or studies that support the claim. Therefore, the comment is 3, as it provides some evidence but could be more fully substantiated with additional details or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. This observation suggests that the methods may be overfitting or that the benchmarks are saturated. The comment also points out that the benchmarks used are outdated, which could impact the relevance and applicability of the results. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. Providing more detailed advice or examples on how to update the benchmarks or improve the performance evaluation would make the comment more helpful. Therefore, the comment is 3, as it identifies a significant weakness but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the method and its applicability, suggesting that it may not be beneficial in certain domains due to deterministic dynamics. It also questions the absence of BEAR from baselines and suggests evaluating the method on nondeterministic domains. While the comment implies that the authors should address these questions and consider evaluating the method on different domains, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the concerns raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the method\"s effectiveness on deterministic domains like Hopper, suggesting that it may not have much benefit. It also questions the absence of BEAR from baselines and suggests evaluating the method on nondeterministic domains. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in its inquiry about the method\"s applicability and the need for evaluation on different domains. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises questions about the method\"s effectiveness on deterministic domains like Hopper, suggesting that it may not have much benefit. It also questions the absence of BEAR from baselines and suggests evaluating the method on nondeterministic domains. While the comment identifies potential issues and questions, it lacks specific examples or references to support the claims. The absence of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is 3, as it provides a basis for the authors to explore these questions but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises several questions about the method\"s effectiveness and applicability, particularly on deterministic domains like Hopper. It suggests that the method may not have much benefit in these domains and questions the absence of BEAR from baselines. Additionally, it recommends evaluating the method on nondeterministic domains to assess its empirical efficacy. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given a direction to explore, but the feedback could be more actionable with detailed advice on how to conduct the evaluation or what specific aspects to focus on. Therefore, the comment is 3, as it provides insight but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. While the action is explicit, it lacks concrete guidance on how to present this justification or what specific aspects should be addressed. The authors are left to infer that they need to provide theoretical reasoning, but without detailed instructions on how to do so, the comment remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. However, it does not specify which part of the paper this justification should be provided in, nor does it provide guidance on what aspects of the results should be justified. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its request for theoretical justification, it lacks grounding as it does not specify where in the paper this should be provided. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. However, it does not provide any specific reasoning or evidence to support this claim. Without detailed explanation or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. This is a valid point as these techniques are important for performance, and theoretical justification can help the authors better understand and articulate their contributions. However, the comment lacks specific guidance on how to present this justification or what aspects should be addressed. While it identifies a potential area for improvement, it does not provide detailed instructions or examples on how to achieve it. Therefore, the comment is 3, as it points out a need for theoretical justification but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or offer specific guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details but may not be entirely sure of the exact content or structure of these details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper these details should be added to, nor does it provide specific guidance on what aspects of the method should be elaborated on. While the authors might have an idea of where these details could be added, the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these details are necessary or how they would enhance the understanding of the method. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment identifies areas for improvement, it lacks specific guidance or examples on what kind of details should be included or how they should be presented. The authors are given a general direction but are not provided with actionable steps to enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer suggests that the method might struggle to detect inconsistencies in responses due to the variety of individuals being discussed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the method\"s detection capabilities. The action is implicit and somewhat vague, as the authors can infer that they need to consider this issue but are not given detailed instructions on how to address it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the specific example of a prompt like \"introduce a sports celebrity to me,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed method, namely that it might struggle to detect hallucinations in openended responses due to the variety of individuals being discussed. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The comment provides a logical reasoning by suggesting that the variety of individuals discussed in the responses could make it challenging to identify shared information for consistency checking. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be improved with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" This feedback highlights a specific challenge that the method might face in detecting inconsistencies in responses due to the variety of individuals being discussed. While the comment points out a potential weakness, it does not provide actionable suggestions or guidance on how the authors might address this issue or improve the method\"s detection capabilities. The feedback is 3 as it directs the authors\" attention to a specific area for improvement, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. While the comment does not explicitly instruct the authors to perform these experiments, it provides a clear direction for action. The authors can infer that they need to conduct these experiments to verify the conclusion, making the action implicit but still clear. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests verifying the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for verification on MNIST and CNN, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical findings are unclear in their relation to realworld deep learning models. It provides a specific suggestion to verify the conclusion about label noise and model size on MNIST and CNN. This claim is 3 as it logically suggests that verification is necessary to clarify the theoretical findings. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical findings and their relation to realworld deep learning models. It suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which is a clear and actionable suggestion. This feedback is valuable as it points out a potential gap in the paper and provides a concrete direction for the authors to address it. However, the comment could be more helpful if it explained why verification on these datasets is important or how it would impact the overall conclusion. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the probability distribution p(y|Hf(t)) should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. This is a clear and direct action for the authors to take, as it specifies the exact requirement for the probability distribution. The comment also mentions that this assumption is already made in the ELBOs, providing a concrete reference point for the authors to verify and apply the change. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the probability distribution \"p(y|Hf(t))\" and the need for it to be Gaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with assuming Kalman Filtering and Smoothing, as well as CVI, cannot be performed without this choice. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the probability distribution \"p(y|Hf(t))\" should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. The comment provides a logical reasoning by stating that this assumption is already made in the ELBOs, which supports the claim. However, the comment lacks specific references or examples to fully substantiate the claim, such as explaining why this assumption is necessary or how it affects the analysis. Therefore, the comment is 3, as it provides a logical basis but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the probability distribution \"p(y|Hf(t))\" and its choice as Gaussian, which is crucial for the applicability of Kalman Filtering, Smoothing, and CVI. It points out that this assumption is already made in the ELBOs, providing a clear and actionable suggestion for the authors to ensure consistency in their analysis. This feedback is valuable as it directs the authors to a specific area that needs attention and clarification, which can significantly impact the clarity and validity of their work. However, the comment could be more helpful if it included additional context or examples to further explain the importance of this choice. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a lack of qualitative experiments to demonstrate the validity of the conditional independence model and suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. It also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics. The comment provides specific actions for the authors to take, such as providing experimental results, visualization, and schematic diagrams. These are explicit and concrete suggestions, giving the authors clear guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of qualitative experiments to demonstrate the validity of the conditional independence model, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD, as well as the need for a correctness test and comparative experiments with other metrics. The suggestion to use a toy dataset to demonstrate the separability of inlier and outlier features is also clear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. The reviewer also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. The comment is 4 as it provides logical reasoning and suggests specific actions for the authors to take. However, it could be strengthened by providing more detailed examples or references to similar studies that have successfully demonstrated the benefits of such approaches. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides actionable suggestions for improvement, such as providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. The comment also recommends using a toy dataset to demonstrate the separability of inlier and outlier features, which is a valuable suggestion for clarity. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics, suggesting that visualization results or schematic diagrams could be beneficial. Overall, the comment is 5 as it provides clear and actionable feedback that can significantly enhance the paper\"s clarity and validity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the computational complexity of the proposed method compared to other methods. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a computational complexity comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"online version of the algorithm\" and the issue of training multiple iterations/epochs with large models and datasets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for a comparison of the computational complexity with other methods, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the proposed method requires more computational complexity than other methods. It suggests comparing the computational complexity with other methods. However, the comment does not provide any evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to address the claim effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the computational complexity of the proposed method compared to other methods. It suggests that the authors should provide a comparison to substantiate their claim about the impracticality of training multiple iterations/epochs with large models and datasets. This feedback is 3 as it prompts the authors to address a critical aspect of their methodology, which could impact the feasibility and practicality of their approach. However, the comment could be more helpful if it provided specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides a clear direction for further analysis, it does not explicitly instruct the authors to conduct this study. The action is implicit but concrete, as it specifies what aspects of the analysis should be explored. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. However, it does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The comment is specific in detailing what aspects of the analysis should be explored, such as the roles between \"winners\" and \"cooperators\" and the potential impact of cost on collective return. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides logical reasoning and examples, it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct a systematic analysis of the impact of the cost of incentivization on performance. It offers a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The comment also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. This feedback is highly valuable as it guides the authors to a specific area for further exploration and analysis, which could significantly enhance the paper. However, the comment could be more helpful if it provided additional details or examples on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 5 as it offers a clear and actionable direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the approach description in Section 3 is difficult to follow and suggests revising it. It also suggests using the additional page of the cameraready version to extend the approach description rather than adding more experiments. This provides clear and concrete guidance on what needs to be done to improve the draft. The authors know exactly what changes to make and how to implement them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the approach description being difficult to follow and suggests revising it. The comment also suggests using the additional page of the cameraready version to extend the approach description rather than adding more experiments. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach description in Section 3 is difficult to follow and suggests revising it. However, the comment does not provide specific examples or detailed reasoning to support why the approach description is challenging or how it could be improved. Without additional context or evidence, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the approach description in Section 3, noting that it is difficult to follow. It suggests revising the description and provides a clear suggestion to extend the approach description using the additional page of the cameraready version rather than adding more experiments. This feedback is actionable and offers a concrete direction for improvement, making it 4. However, it could be more helpful if it included specific suggestions on how to revise the approach description or what aspects are particularly challenging for readers to understand. Overall, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two main issues with the experimental section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparison with other stateoftheart methods that do not rely on gyrostructures. While the comment highlights these gaps, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to include more interpretive insights and comparisons with other methods. The action is implicit and somewhat vague, as it lacks concrete details on how to implement these improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It also specifies the issues with the related discussion, noting the lack of interpretive insights and the need for comparison with other stateoftheart methods. The comment further highlights the absence of comparison with methods that do not rely on gyrostructures, which makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights and that the paper lacks comparison with other stateoftheart methods that do not rely on gyrostructures. The comment suggests that this omission makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques. However, the comment does not provide specific examples or references to support these claims, making it 3. The authors would need to infer the importance of these comparisons and the potential impact on the conclusions of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two significant issues with the experimental section of the paper. First, it points out the lack of interpretive insights into why the proposed gyrostructures outperform existing methods. This feedback highlights an important area for improvement, as it would help the authors better understand and communicate the strengths of their approach. Second, the comment notes the absence of comparison with other stateoftheart methods that do not rely on gyrostructures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques. This omission is crucial for the paper\"s conclusions and impact, and the comment provides a clear and actionable suggestion for improvement. By addressing these issues, the authors can enhance the rigor and comprehensiveness of their experimental evaluation. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 5 is difficult to comprehend and recommends providing more details about the two baselines presented. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages in the future. While the comment provides a clear action for the authors to take, it does not specify which details should be added or how to extend CATER to other languages. The action is explicit but lacks concrete guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as its difficulty in comprehension and the need for more details about the baselines presented. The comment suggests extending CATER to other languages, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is difficult to comprehend and suggests that more details about the baselines presented are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation. The reviewer suggests extending CATER to other languages, which is a logical suggestion based on the widespread use of translation APIs. However, the comment lacks specific examples or references to support the claim about the difficulty of comprehension or the need for more details about the baselines. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and suggesting that more details about the baselines presented should be included. It also points out a limitation in the study, noting that the authors only focus on CATER for Englishcentric datasets, despite the widespread use of translation APIs for multiple languages. The comment provides a clear and actionable suggestion for improvement by recommending that the authors extend CATER to other languages in the future. This feedback is valuable as it directs the authors to enhance the comprehensibility and scope of their work, making it 4. However, it could be more helpful if it included specific guidance on how to extend CATER to other languages or what additional details should be included in the figure. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity in the literature review, specifically regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment implies that the authors should make these improvements, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added (an explicit and comparative analysis of related work), but it is somewhat vague in terms of how to execute this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" and \"GFlowNet for sequence generation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the clarity of the main contribution and the distinction from existing work. The comment provides guidance on how to enhance the literature review by suggesting a more explicit and comparative analysis of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear, particularly regarding the main contribution of the proposed method and its distinction from existing work. The reviewer suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment identifies a potential issue, it lacks specific examples or references to existing work that could clarify the distinction. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the literature review, specifically the lack of clarity regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work, which is crucial for effectively communicating the novelty and significance of the proposed method. This feedback is clear and actionable, as it directs the authors to enhance the literature review section to better support their claims. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct a more comprehensive analysis of related work. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any explicit guidance on how to implement this suggestion or what specific content should be removed from section 3.2. The action is implicit and vague, as the authors are left to infer that they should remove the section but without clear instructions on what to replace it with or how to integrate the information elsewhere. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not specify which part of section 3.2 is problematic or what needs to be addressed. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The suggestion to eliminate section 3.2 is specific, as it clearly identifies what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or how it affects the paper\"s content or clarity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any reasoning or explanation for why this section is unnecessary or how it might detract from the paper\"s overall clarity or contribution. Without additional context or suggestions for improvement, the comment offers limited value to the authors in terms of actionable feedback or guidance. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two specific actions for the authors to take: (i) to include performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility of the framework, and (ii) to include morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These are explicit actions that the authors can directly implement to improve their draft. The second point is a minor suggestion, but it is still clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of performance on word similarity and sentence translation tasks and the inclusion of morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. This provides clear guidance on how to enhance the robustness and effectiveness of the framework. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility of the framework. It also recommends including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These suggestions are based on common practices in the field and are logical, but the comment lacks specific examples or references to support the claim fully. The authors would need to infer the importance of these additions themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the experiments section of the paper. First, it recommends adding performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility and effectiveness of the framework. This is a clear and concrete suggestion that can help the authors demonstrate the robustness and effectiveness of their work. Second, it suggests including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments, which could further strengthen the validation of the framework. These suggestions are actionable and can significantly improve the paper. However, the comment could be more helpful if it provided additional context or examples of how these tasks are relevant to the framework. Overall, the comment is 4 as it offers clear and actionable guidance for improving the experiments section."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the link between IP and the terms/equations should be explained more explicitly and prominently. It also requests that labels be included for subfigures in Figures 3 and 4, rather than just being mentioned in the captions. While the comment provides a clear action for the authors to take, it does not specify how to implement this improvement or what specific changes are needed to make the link more explicit. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for labels on subfigures and the clarification of the link between IP and the terms/equations. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the link between IP and the terms/equations could be explained more explicitly and prominently. However, it does not provide any specific examples or reasoning to support this claim. The suggestion to include labels for subfigures in Figures 3 and 4 is also mentioned, but without further explanation or justification, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the link between IP and the terms/equations could be explained more explicitly and prominently. It also provides a clear and actionable suggestion to include labels for subfigures in Figures 3 and 4, rather than just mentioning them in the captions. This feedback is valuable as it directs the authors to enhance the clarity and accessibility of their figures, which can significantly improve the readability and comprehension of their work. However, the comment could be more helpful if it included additional guidance on how to effectively explain the link or how to label the subfigures. Overall, the comment is 4 as it provides clear and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the observations and conclusions should be highlighted in the paper, particularly in the experimental section. This feedback implies that the authors should make the observations and conclusions more prominent or accessible to the reader, which is a clear and explicit action. However, the comment does not provide specific guidance on how to achieve this, such as recommending a particular section or method for highlighting the observations. While the action is clear, the lack of concrete details on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section, which implies that the authors should highlight these elements to improve the paper\"s clarity. However, it does not specify which observations or conclusions are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment is weakly grounded because it does not specify the exact sections or elements being addressed, but it is specific in suggesting that the observations and conclusions should be highlighted. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section, implying that they are not clearly highlighted or accessible to the reader. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these elements would be beneficial for understanding the tradeoffs of annotation effort and corresponding training performance. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper\"s clarity and accessibility. However, the comment could be more helpful if it offered specific guidance on how to highlight these observations and conclusions, such as recommending a particular section or method for doing so. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This feedback is explicit and provides a clear action for the authors to take, which is to conduct ablation experiments. However, it does not specify which modifications should be tested or how to conduct the experiments, leaving some details to be inferred. While the action is clear, the lack of concrete guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests conducting ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. However, it does not provide any specific examples or references to support the claim that these modifications are necessary or beneficial for model performance. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests conducting ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This feedback is 3 as it identifies a potential area for improvement by suggesting an additional validation method. However, the comment lacks specific guidance on which modifications to test or how to conduct the ablation experiments. While it points out a potential area for improvement, it does not provide detailed instructions or examples, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the KDE requiring more data when the classifier space is beyond binary, and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1\" and \"Zhang et. al.\" (presumably references in the paper), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the KDE requiring more data when the classifier space is beyond binary and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the KDE requiring more data when the classifier space is beyond binary, and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the KDE requiring more data when the classifier space is beyond binary, which is relevant to the methodology and results sections. It raises a question about the comparison of performance on datasets with a decision space beyond binary, suggesting that this could be an important aspect to consider. However, the comment lacks specific guidance or suggestions on how to address this issue or what specific datasets should be considered. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an area for further exploration but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions imply that the authors should investigate these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to explore the impact of capacity on FID and consider potential artifacts in the pipeline, but the comment lacks specific details or suggestions on how to conduct these investigations. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, such as a particular section or experiment. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for information about the impact of capacity and artifacts, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions themselves are not claims but rather requests for clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could be valuable for the authors to explore: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. These questions highlight potential areas for further investigation or discussion in the paper. However, the comment lacks specific guidance or suggestions on how to address these questions or what specific aspects of the capacity or artifacts should be examined. While it points out potential areas for improvement, it does not provide detailed or actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the purpose of Proposition B.1 might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the purpose of Proposition B.1 and provide a proof, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues: the blank Appendix A and the unclear purpose of Proposition B.1, suggesting that it might be illustrating a wellknown concept in machine learning. The comment also points out the missing \"proof\" for this proposition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the purpose might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that the purpose is unclear or that the \"proof\" is missing. This makes the claim 3, as the authors would need to further investigate and clarify the purpose and proof themselves.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the purpose of Proposition B.1 might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. This feedback is clear and actionable, as it directs the authors to clarify the purpose and provide evidence for their claims. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar concepts have been presented in other works. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments. The comment is specific about the types of experiments that are missing, giving the authors a concrete understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing the types of experiments that are missing, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide specific examples or detailed reasoning to support why these experiments are necessary or how they would enhance the paper. Without such evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of additional necessary experiments such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly points out areas where the paper could be strengthened by including these experiments. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct a more careful analysis of the model\"s performance, especially on \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis, it does not specify exactly how to do so or what additional details should be included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures, which could be helpful. However, the comment does not specify which part of the paper discusses the model\"s performance or the evaluation procedures, making it weakly grounded. The suggestion to provide more details is specific, but without clear grounding, the authors may struggle to identify where to address these issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. However, the comment lacks specific examples or references to support the claim that the model\"s performance is due to indirect exposure through data curation. Without such evidence or detailed reasoning, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2, as it provides a logical suggestion but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s performance on \"old\" benchmarks that might have been indirectly seen by the model through the \"data curation\" process. It suggests that more careful analysis is needed, particularly for these benchmarks, and recommends providing more details about the evaluation procedures. While the comment highlights an area for improvement, it lacks specific guidance on how to conduct the analysis or what additional details should be included. The authors are given a general direction but may find it challenging to fully understand and address the issue without more detailed instructions. Therefore, the comment is 3, as it points out a potential weakness but does not provide actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include collaborative games in their experiments to explore how the evaluated methods behave in both collaborative and competitive settings. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to implement this suggestion or what specific collaborative games should be included. The authors are left to infer the details of how to incorporate collaborative games into their experiments, which could be improved with more concrete instructions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, it does not specify which part of the paper this issue pertains to, such as the sections where the experiments are described or discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of collaborative games, but without grounding, it is difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or necessary. Without specific examples or detailed explanations, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the absence of collaborative games in the experiments. It suggests that including such games would be beneficial to explore the behavior of the evaluated methods in both collaborative and competitive settings. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in their experiments. However, the comment could be more helpful if it offered examples of collaborative games or provided guidance on how to incorporate them into the existing experimental setup. Overall, the comment is 4 as it points out a meaningful area for improvement and provides a clear suggestion for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific settings to include or suggesting ways to improve the figures. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of experimental settings for these figures, making them difficult to be convincing. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the absence of experimental settings for figures 1 to 9. This is a critical observation that could impact the credibility and persuasiveness of the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the figures. While it points out a problem, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the rationale behind the work, specifically regarding the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment identifies a specific area for clarification, it does not provide explicit instructions on how to address this issue or what specific details should be included in the clarification. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the rationale behind the work, specifically the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the proposed method and its potential impact on task knowledge acquisition. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the rationale behind the work is based on the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the basis of the claim and potentially conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the rationale behind the work, specifically regarding the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are specifically tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment highlights an important area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of the rationale need clarification. The feedback is 3 as it points out a potential weakness but lacks depth and actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to conduct comparisons with existing fairness algorithms in the experimental section. It clearly states the action needed, which is to integrate benchmark comparisons against stateoftheart fairness algorithms. This provides a concrete and specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of comparisons with existing fairness algorithms. The comment provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would significantly enhance the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that integrating benchmark comparisons with stateoftheart fairness algorithms would enhance the paper by providing tangible evidence of the proposed method\"s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This claim is 3 as it logically suggests that comparisons with existing algorithms would strengthen the paper, but it lacks specific examples or references to existing fairness algorithms that could be used for comparison. The authors would need to infer the specific algorithms to include, which adds a degree of uncertainty. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section, noting the absence of comparisons with existing fairness algorithms. It suggests that integrating benchmark comparisons against stateoftheart fairness algorithms would enhance the paper by providing tangible evidence of the proposed method\"s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This feedback is clear and actionable, offering a concrete suggestion for improvement that could significantly impact the paper\"s impact and credibility. However, it could be more helpful if it provided specific examples of existing fairness algorithms that could be used for comparison. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the iteration cost (computational budget) of their proposed method and to include the iteration cost of all related methods, including baseline methods. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and direct, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the iteration cost should be discussed, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the iteration cost of the proposed method and the iteration cost of related methods, including baseline methods. This provides clear guidance on what the authors need to include in their discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the iteration cost is a critical aspect to discuss. The authors are left to infer the importance of this discussion themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including a detailed discussion on computational efficiency. By addressing this point, the authors can improve the comprehensiveness and clarity of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed this issue. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the authors\" statement on lines 8082 regarding the center correlation not being insightful for discriminating model defenses, but then using it in figure 4 A&B. The reviewer questions why the metric was considered useful in one place but not another, or what the authors meant by their statement. This feedback implies that the authors should clarify their reasoning or explanation for using the metric in both contexts. However, it does not provide explicit instructions on how to address this issue, leaving the authors to infer the necessary actions. The comment is 3 as it identifies a potential inconsistency but lacks concrete guidance on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (8082) and figures (A&B), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\" reasoning for using the center correlation metric in figure 4 A&B, despite claiming it is not insightful for discriminating model defenses. This provides clear guidance on what needs to be addressed, namely the inconsistency in the authors\" reasoning or the clarification of their statement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" statement about the center correlation not being insightful for discriminating model defenses, as it is used in figure 4 A&B. The reviewer is seeking clarification on why the metric is considered useful in one context but not another, or what the authors meant by their statement. This is a request for clarification rather than a subjective claim or opinion, making it a factual observation. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" reasoning regarding the center correlation metric. It points out that the authors claim it is not insightful for discriminating model defenses but then use it in figure 4 A&B. This feedback is valuable as it prompts the authors to clarify their reasoning or explanation for using the metric in both contexts. By addressing this inconsistency, the authors can improve the coherence and credibility of their work. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency or explained why it might be relevant in figure 4 A&B. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the term \"distributional generalization\" may be too strong to accurately represent the empirical phenomenon presented. It points out that the total variation between the test and train distributions of the network\"s outputs might not be zero, and that this conclusion is difficult to draw from a few test functions where the outputs match. However, the comment does not provide explicit guidance on what term or phrasing would be more appropriate or how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative terms or phrasing to better represent the phenomenon. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it may be too strong to accurately represent the empirical phenomenon presented. The comment provides a clear rationale for why the term might not be appropriate and suggests an alternative approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the appropriateness of the term \"distributional generalization\" to describe the phenomenon presented, suggesting that it may be too strong. The reviewer provides a logical reasoning by explaining that the term implies a total variation between the test and train distributions of the network\"s outputs, which might not be the case. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the issue to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the term \"distributional generalization\" used to describe the phenomenon presented in the paper. It points out that the term might be too strong and might not accurately represent the empirical phenomenon, as the total variation between the test and train distributions of the network\"s outputs might not be zero. The comment provides a logical reasoning for why the term might be misleading and suggests that the authors consider alternative terms or phrasing to better represent the phenomenon. While the comment highlights an important consideration, it could be more helpful if it provided specific suggestions for alternative terms or phrasing. Overall, the comment is 3 as it directs the authors to reconsider the terminology used in their paper, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use \"above/below diagonal\" instead of \"above/below 45 degree\" to make the plot easier to interpret. While the comment provides a specific suggestion for clarity, it does not offer detailed guidance on how to implement this change or why it is necessary. The action is implicit and somewhat vague, as the authors need to infer that they should make this change to improve clarity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plot\" and suggests a specific change to \"above/below diagonal\" instead of \"above/below 45 degree.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the clarity of the plot labels. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is described as a local property. The reviewer provides a logical reasoning that \"above/below diagonal\" is clearer because it refers to a visual aspect, while \"above/below 45 degree\" is more ambiguous. However, the comment lacks specific examples or references to support the claim that \"above/below diagonal\" is inherently clearer. This makes the claim 3, as the authors would need to make a logical inference to understand the reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to improve the clarity of the plot by using \"above/below diagonal\" instead of \"above/below 45 degree.\" This feedback is actionable and offers a clear and concise way for the authors to enhance the interpretability of their plot, which is a valuable contribution. However, the comment could be more helpful if it explained why \"above/below diagonal\" is more intuitive or provided examples of how this change would improve the plot. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear suggestion for enhancing the clarity of the plot."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism over prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior. The reviewer does not provide explicit guidance on how the authors should address this issue, but the implication is that they should provide a clearer explanation of the relationship between their work and prior taskoptimized approaches. The comment is 3 as it identifies a gap in understanding but lacks concrete steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scientific insight provided by the model and formalism over prior taskoptimized approaches. The comment highlights a lack of clarity regarding the relationship between the model and nonlinear RNN models that exhibit emergent behavior. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the scientific insight provided by the model and formalism over prior taskoptimized approaches. It specifically mentions that the model is not shown to be a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which is a critical point for understanding the contribution of the work. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to provide additional evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the scientific insight provided by the model and formalism over prior taskoptimized approaches. It questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which is a crucial aspect of understanding the contribution of the work. The comment highlights a lack of clarity regarding the relationship between the model and prior approaches, suggesting that the authors need to provide a clearer explanation of their work. While the comment identifies an important area for improvement, it does not offer specific suggestions or guidance on how to address this issue. Therefore, the comment is 3, as it points out a critical weakness but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the use of adaptive convolutions in the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It points out that Table3 shows ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). The reviewer suggests that the placement of adaptive convolutions is important, but no analysis or comments are provided on this aspect of the technique. While the comment identifies a potential issue, it does not offer specific guidance on how the authors should address this issue or what kind of analysis or comments would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should include analysis or comments on the placement of adaptive convolutions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the use of adaptive convolutions does not always lead to better performance, as evidenced by the comparison between ACNNv2 and ACNNv3. The comment suggests that the placement of adaptive convolutions is important and highlights the need for analysis or comments on this aspect of the technique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that replacing normal convolutions with adaptive convolutions does not always lead to better performance, based on the experimental results in Table3. The reviewer provides a specific example by comparing ACNNv2 (adaptive convolutions only in the last layer) with ACNNv3 (all adaptive convolutions), which supports the claim. This provides a clear and concrete basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that support this observation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of adaptive convolutions in the experimental results, noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It provides a specific example by comparing ACNNv2 (adaptive convolutions only in the last layer) with ACNNv3 (all adaptive convolutions), which performed worse. This observation highlights the importance of the placement of adaptive convolutions, suggesting that the authors should analyze or comment on this aspect of the technique. However, the comment could be more helpful if it offered suggestions on how to analyze or comment on this aspect, such as potential factors to consider or methods to evaluate the placement. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including a brief discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, namely the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is explicit and provides concrete guidance on what the authors should add to their discussion. The action is clear and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion\" and \"Section 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the empirical motivation for a timevarying Q ^ t and S t , and provides an example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. The reviewer provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This suggestion is based on logical reasoning and provides a clear direction for the authors to consider. However, the comment could be strengthened by referencing specific studies or examples to support the claim. Overall, the claim is 4, as it provides a logical basis for the suggestion but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the draft. It highlights the need for a discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one, which is a relevant and important aspect of the paper. The comment offers a specific example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is valuable as it guides the authors to enhance their discussion section with a more detailed and empirically grounded analysis. However, the comment could be more helpful if it included references to similar studies or examples that have explored this topic, which would further strengthen the authors\" understanding of the importance and relevance of this discussion. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. It also mentions that the experiments have little to hang on to. However, it does not provide any specific guidance or suggestions on how the authors could improve the clarity or coherence of the paper. The comment implies that the authors should make the paper more accessible and easier to understand, but it does not offer concrete steps or examples of what changes could be made. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment suggests that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not specify which parts of the paper are particularly challenging or where the lack of clarity is most prominent. Without explicit references to sections, figures, or experiments, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment does not provide specific guidance on how to enhance the clarity or coherence of the paper. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not particularly easy to follow and lacks a clear intuition for how the pieces fit together. It also points out that the experiments have little to hang on to, which could impact the paper\"s impact and clarity. However, the comment does not provide specific suggestions or guidance on how the authors could improve the clarity or coherence of the paper. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the refined region vector, specifically questioning whether the attention weight is scaled before being used in the calculation. The reviewer suggests that having a scaling variable before the attention weight might help. While the comment implies that the authors should consider this suggestion, it does not provide explicit instructions or concrete guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding a scaling variable before the attention weight. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the refined region vector and suggests that having a scaling variable before the attention weight might help. The comment provides a clear direction for improvement by asking whether the refined vector scales only the most important regions before global pooling. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the refined region vector and its scaling. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the refined region vector, specifically questioning whether the attention weight is scaled before being used in the calculation. It suggests that having a scaling variable before the attention weight might help. This feedback is 3 as it prompts the authors to consider a potential improvement in their methodology. However, the comment lacks depth and does not provide specific guidance or examples on how to implement this suggestion. To be more helpful, the comment could offer suggestions on how to incorporate a scaling variable or provide a rationale for why it might be beneficial. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the LLM\"s ability to accurately recover the formal goal predicate or how to handle ambiguities in human language. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to goal misspecification in the LLM, particularly when faced with ambiguities in human language. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem of goal misspecification and its consequences, such as failures on the ALFRED benchmark. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue and how to address it. Without detailed evidence or reasoning, the claim is not 5, leaving the authors without a clear understanding of the problem or how to improve their draft. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the LLM, noting that failures on the ALFRED benchmark often occurred due to goal misspecification. It highlights that the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This feedback is valuable as it points out a potential weakness in the model\"s performance, which the authors can address to improve their draft. However, the comment could be more helpful if it provided suggestions on how to mitigate this issue or examples of how other models have successfully handled similar challenges. Despite this, the feedback is 4 as it directs the authors\" attention to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. It also raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While the comment provides a clear direction for the authors to take, it lacks specific guidance on how to conduct the analysis or what specific aspects of the analysis should be focused on. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"IGEV\" and \"SOTA methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. Additionally, it raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the improvement of the method over SOTA methods like IGEV is small, and questions whether there is no multipeak distribution problem in iterative optimization schemes similar to IGEV. The reviewer provides a suggestion to analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. This claim is 3 as it logically questions the improvement over IGEV and suggests a potential analysis to address the issue. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. This feedback is valuable as it guides the authors to conduct a specific analysis that could help clarify the limitations of their method compared to SOTA methods. Additionally, the comment raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV, prompting the authors to consider potential limitations or areas for improvement. Overall, the comment is 4 as it offers clear and actionable guidance for the authors to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include results using the GCPG model without pretrained initializations to clarify the contribution of the task formulation and pretrained language models. This is a clear and direct action for the authors to take, as it provides a specific step to address the issue of attribution. The comment is specific in detailing what additional results are needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for results using the GCPG model without pretrained initializations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the contribution of the task formulation and pretrained language models. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks ablations, specifically the results without pretrained language models. The reviewer claims that it is unclear how much performance gain is due to the task formulation and how much is because of pretrained language models. The suggestion to include results using the GCPG model without pretrained initializations is a logical request to clarify the contribution of the task formulation. However, the comment does not provide specific examples or references to support the claim that the current results are unclear. This makes the claim 3, as the authors would need to make a logical inference to understand the basis of the suggestion.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of ablations to clarify the contribution of the task formulation and pretrained language models. It suggests using the GCPG model without pretrained initializations to provide a clearer understanding of the performance gains. This feedback is clear and actionable, as it directs the authors to include additional results that can help clarify their findings. However, the comment could be more helpful if it provided more detailed guidance on how to implement these ablations or why the GCPG model is particularly relevant. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that it is difficult to understand what the axes are for Figure 1. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the axes should be labeled more clearly or if additional explanations are needed. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve the clarity of the figure. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes in Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand what the axes are for Figure 1. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of Figure 1, noting that it is difficult to understand what the axes represent. This feedback is 3 as it points out a clear area for improvement in the paper, which is the labeling and explanation of the axes. However, the comment lacks depth and does not provide suggestions on how to improve the clarity or offer alternative ways to present the data. While it highlights an important issue, it could be more helpful with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider presenting results on ImageNet to enhance the convincingness of their proposed method. While the comment implies that the authors should include these results, it does not provide specific guidance on how to conduct the experiments or what aspects of the results should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should include results on ImageNet to improve the paper\"s credibility. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. However, it does not specify which part of the paper should include these results or how they should be presented. The authors cannot confidently determine which section or part of the paper is being addressed, making this comment weakly grounded. The suggestion is specific in terms of what could be added to enhance the paper\"s credibility, but without clear grounding, it is difficult for the authors to effectively address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that results on ImageNet could be more convincing for the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to justify why this would be beneficial or how it would enhance the credibility of the work. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. While it provides a general direction for improvement, it lacks specific guidance or examples on how to achieve this or what aspects of the results on ImageNet would be most impactful. The feedback is 3 as it points out a potential area for enhancement, but it does not offer detailed advice or actionable steps for the authors to follow. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which requires additional computational costs. This implies that the authors should include direct runtime comparisons to demonstrate the efficiency of their proposed approach. The comment is clear and provides a specific action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for direct runtime comparisons with existing methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of implicit differentiation and its potential impact on runtime efficiency, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which requires additional computational costs. The comment suggests that these comparisons are necessary to demonstrate the efficiency of the proposed approach. While the reasoning is logical and the claim is based on a common understanding of implicit differentiation and its computational implications, it lacks specific examples or references to support the claim fully. This makes the comment 3, as it provides a clear rationale but requires more detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper, noting the absence of direct runtime comparisons with existing methods. It highlights the importance of these comparisons to demonstrate the efficiency of the proposed approach, which is based on implicit differentiation. This feedback is clear and actionable, as it directs the authors to include these comparisons to strengthen their claims about the efficiency of their method. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or suggested potential methods for doing so. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the proposed framework is a simple combination of metalearning and federated learning and does not see any technical contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of the framework need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed framework for being a simple combination of metalearning and federated learning, indicating a lack of technical contribution. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where the framework is discussed. Without explicit references, the authors cannot confidently determine which parts of the paper need attention or improvement. The comment is specific in its critique of the framework but lacks grounding, making it difficult for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning, lacking any technical contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment critiques the proposed framework for being a simple combination of metalearning and federated learning, indicating a lack of technical contribution. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or what aspects of the framework could be improved. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the insufficiency of the contribution and suggests that the authors should further explore how to leverage the connection between complementary and model robustness to improve model robustness. While the comment implies that more insightful findings or solutions should be included, it does not provide specific guidance on what these findings or solutions should be. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their analysis to be more comprehensive. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, specifically the connection between complementary and model robustness. It suggests that the authors should explore how to leverage this connection to improve model robustness. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely, more insightful findings or solutions related to the connection between complementary and robustness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution is insufficient and suggests that the authors should explore how to leverage the connection between complementary and model robustness to improve model robustness. The reviewer provides a logical reasoning by pointing out that the conclusion about the relationship between complementary and robustness is intuitive and could be easily obtained. However, the comment lacks specific examples or references to support the claim that the contribution is insufficient or to suggest how the authors might expand their analysis. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern about the contribution of the paper, noting that the connection between complementary and model robustness is studied but not further explored to leverage these characteristics for improving model robustness. The reviewer suggests that the authors should provide more insightful findings or solutions to address this gap. While the comment highlights an important area for improvement, it lacks specific suggestions or examples of how the authors might expand their analysis to be more comprehensive. This limits the comment\"s helpfulness, as it points out a critical issue but does not fully guide the authors on how to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should focus on what the differences in representation are between clusters rather than on which clusters are \"best.\" However, it does not provide explicit guidance on how to implement this change or what specific aspects of the representation differences should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should prioritize the differences in representation over the selection of \"best\" clusters. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the focus on which clusters are \"best\" is an odd choice given the motivation of the paper. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this focus is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the representation differences should be prioritized over the selection of \"best\" clusters. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that focusing on which clusters are \"best\" rather than the differences in representation between them is an odd choice given the motivation of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unaligned with the paper\"s goals. Without specific examples or detailed explanations, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential inconsistency in the paper\"s focus, suggesting that the authors should prioritize the differences in representation between clusters rather than which clusters are considered \"best.\" This feedback is 3 as it identifies an area where the paper may not align with its stated motivation. However, the comment lacks specific guidance on how to address this issue or what aspects of the representation differences should be emphasized. While it highlights a potential weakness, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. While the comment provides explicit actions for the authors to take, such as increasing font size and ensuring proper placement, it does not offer detailed guidance on how to address these issues. The authors are left to infer the specific steps needed to improve the organization and layout of their paper. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Figure 1,\" \"Figure 2,\" \"Table 2,\" and \"page 6,\" allowing the authors to accurately identify the areas being addressed. It also specifies the issues with the layout, such as the font size and placement of figures and tables, and the formatting of the top two lines on page 6. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is not wellorganized and that the layout is rushed, providing specific examples such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. These examples are detailed and provide clear justification for the claim, making the comment 4. However, the comment could be strengthened by providing additional context or references to similar issues in other papers, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the organization and layout of the paper. It identifies issues such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. By pointing out these specific problems, the comment empowers the authors to make improvements that enhance the clarity and professionalism of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as providing examples of better formatting or offering alternative layout options. Overall, the comment is 4 as it provides clear guidance on areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions about the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" that is not explicitly defined. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or definitions, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"upper faces\" of the convex hull, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for better explanation of the dual subdivision and projection process, as well as the issue with the variable \"p\" not being explicitly defined. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the meaning of \"upper faces\" of the convex hull and the dual subdivision and projection process. It also points out the lack of explicit definition for the variable \"p,\" which has been used extensively throughout the paper. These are factual observations that do not contain subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several areas of confusion or lack of clarity in the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" that is not explicitly defined. These are important issues that could impact the understanding and interpretation of the paper. The comment suggests that these areas need to be explained better, which is a clear and actionable piece of feedback. However, it could be more helpful if it provided specific suggestions on how to clarify these concepts or offered examples of how they have been addressed in similar works. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific changes they could make to support the integration of images and their augmentations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the idea are questionable or how it could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s skepticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately, suggesting that they can be interchangeable. However, it does not provide any specific reasoning or evidence to support this claim or offer suggestions for how the authors might address this concern. Without actionable feedback or detailed guidance, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, as it identifies a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"equation (12)\" and \"the presentation of these methods,\" which provides some grounding by referencing specific elements of the paper. However, it does not specify which part of the paper these elements are discussed in, making it weakly grounded. The comment is specific in pointing out the issue of vagueness in the presentation of existing methods, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some pieces rely on existing methods, such as equation (12), and that the presentation of these methods is vague. This feedback is 3 as it points out a potential weakness in the paper\"s originality and clarity. However, the comment lacks specific suggestions or guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific guidance or suggestions on how to improve it. There is no explicit or implicit action for the authors to take, such as suggesting ways to clarify or organize the content. Without any actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not specify which parts of the paper are affected. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the writing or presentation are jumbled, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing or presentation is \"jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific examples or guidance on how to improve the clarity or organization of the paper. Without actionable feedback or suggestions, the authors are left without a clear understanding of what aspects of their writing need attention or how to address the issue. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. While the comment does not explicitly instruct the authors to perform a computational complexity analysis or provide guidance on how to address the power demand concern, it implies that the authors should consider these aspects. The action is implicit but concrete, as it points to specific areas that need attention. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where computational complexity is discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific in its inquiry about computational complexity and power demand, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. However, the comment lacks specific examples or references to support the claim about computational complexity or power demand. Without detailed evidence or comparisons, the claim is not 5, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. While the comment identifies a relevant concern about computational complexity and power demand, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it prompts the authors to consider these aspects, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It explicitly states that these heads are active at the S2 token but do not primarily attend to it, referencing Section 3 of Wang et al., 2023. This provides a clear and concrete action for the authors to correct the statement in their draft. The comment is explicit and provides specific guidance on how to revise the text, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section of the paper, \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the incorrect claim about the attention of these heads and references Section 3 of Wang et al., 2023 to support its assertion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\" is incorrect, citing Section 3 of Wang et al., 2023. This claim is supported by a specific reference to the external work, which provides a clear and verifiable basis for the assertion. The authors can easily verify the claim by consulting the referenced section, making the comment 4. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It points out that these heads are active at the S2 token but do not primarily attend to it, which is a critical correction for the authors to make. The comment is clear and actionable, providing the authors with specific guidance on how to correct their draft. By addressing this issue, the authors can improve the accuracy and clarity of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method is not scalable and suggests that a distributed version is needed to accommodate realworld datasets. However, it does not provide explicit guidance on how to develop a distributed version or what specific aspects need to be considered. The action is implied and somewhat vague, as the authors can infer that they need to develop a distributed version but are not given concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the scalability of the method, suggesting that it is not scalable without a distributed version. However, it does not specify which part of the paper discusses the method or where the scalability issue is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the scalability issue but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is not scalable and suggests that a distributed version is needed to accommodate realworld datasets. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the scalability of the method, suggesting that a distributed version is needed to accommodate realworld datasets. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks specific guidance or suggestions on how to develop a distributed version or what aspects of the method need to be adapted for scalability. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide more detailed analysis or justification for the proposed algorithm, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of difference in performance between the proposed sensitivelayer selection and randomized selection, as well as the absence of mathematical or theoretical justification for the proposed Algorithm.1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. The comment provides some logical reasoning by pointing out the lack of difference in performance and the absence of theoretical justification, but it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to further explore the data or provide additional justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion. Additionally, it points out the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues or improve their analysis. The feedback is 3 as it directs the authors to focus on these aspects, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets to better illustrate their tuplelike structure. This is a clear and direct action for the authors to take, as it provides a specific guidance on how to improve the presentation of their data. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presentation of triples as tuples instead of sets. This provides clear guidance on how to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets to better illustrate their tuplelike structure. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the clarity of the paper by recommending that the triples denoted as $(e_1, r, e_2)$ be presented as tuples instead of sets. This feedback is clear and directly addresses a potential issue with the presentation of the data, which could enhance the readability and understanding of the paper. By following this suggestion, the authors can improve the clarity and precision of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). The reviewer notes that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this scalability problem or suggest specific actions to improve the scalability of the quantization. The authors are left to infer that they need to address this issue, but without concrete steps, the comment remains 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of scalability in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the problem of quantization being a bottleneck for the method, which is a clear and specific concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It also notes that even with clustering before, the cost of quantization is high in terms of both N (number of data) and M (dimension). The reviewer further explains that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. While the comment provides logical reasoning and references the paper, it could be strengthened by providing specific examples or references to quantization methods that are known to be scalable. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of the optimal quantization method, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). This is a significant concern, as it affects the speed of VI and the method\"s applicability to big data/big model settings. The reviewer highlights that the paper aims to speed up VI by achieving fast convergence, which is crucial for these settings. However, the comment notes that the quantization is a bottleneck for this, making the method lose its purpose. This feedback is valuable as it highlights a critical weakness in the paper that the authors need to address to improve its impact and applicability. The comment provides clear guidance on a key area for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their methodology against existing methods, such as contrastive decoding, and to address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more applicationoriented venue. The comment provides clear and concrete actions for the authors to take, specifying what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning\" and \"core methodology,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is comparing the effectiveness of the method against existing methods like contrastive decoding and addressing issues mentioned above. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to existing methods or issues that need to be addressed. This makes the claim 3, as the authors would need to infer the specific methods and issues to be addressed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more applicationoriented venue. This feedback is specific and constructive, guiding the authors on how to enhance the rigor and relevance of their work. However, the comment could be more helpful if it provided examples of specific issues or methods to address. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. It also points out that the validation experiments are not comprehensive and that the time complexity and efficiency of the computation are not clearly analyzed. Additionally, it suggests that the authors should further elucidate the technical contribution rather than the form of the attack. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what changes are needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment also lacks specificity in terms of what needs to be addressed regarding the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questioning how it would operate effectively when the dataset is not fully perceptible. It also critiques the validation experiments as not comprehensive and points out the lack of analysis on the time complexity and efficiency of the computation. The reviewer expects the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claims. This makes the claim 3, as the authors would need to make a concerted effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. It points out that the algorithm requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. Additionally, it critiques the validation experiments as not comprehensive and suggests that the authors should further elucidate the technical contribution rather than focusing solely on the form of the attack. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how similar problems have been addressed in similar works. Overall, the comment is 4 as it guides the authors toward improving their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a statement in the paper that claims every kernel can be described by a feature space parameterized by a neural network, which is not true. The reviewer suggests that the limitation of representing infinitedimensional RKHSs with neural networks should be made more clear. While the comment identifies a specific issue with the claim, it does not provide explicit guidance on how to address it or what specific changes should be made to clarify the limitation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the limitation, but it lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.\" This allows the authors to accurately identify the part of the paper being addressed, which is the discussion of feature spaces and neural networks. The comment is also specific because it clearly specifies what needs to be addressed, namely the limitation of representing infinitedimensional RKHSs with neural networks. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that every kernel can be described by a feature space parameterized by a neural network, pointing out a limitation with RBF kernels and their infinitedimensional representation. The reviewer supports this claim by referencing the fact that RKHS is famously infinitedimensional, making it impossible to represent with a neural network of finite width. This logical reasoning provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing specific references or examples to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It points out a limitation with RBF kernels, which are famously infinitedimensional, making it impossible to represent them with a neural network of finite width. The reviewer suggests that the limitation should be made more clear, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights a critical aspect of the paper that needs clarification, guiding the authors to enhance the accuracy and completeness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or improve the handling of autoregressive decoding, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It mentions the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the handling of autoregressive decoding and the potential impact on inference benefits. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It suggests that the use of long token dimensions during training might limit the benefits of inference. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. This feedback is valuable as it prompts the authors to consider the limitations of their approach and how it might impact the inference phase. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how other approaches handle autoregressive decoding. Overall, the comment is 3 as it directs the authors to consider an important aspect of their work but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment implies that the authors should provide additional analysis or discussion, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the reproducibility of GPI with noise added and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. The comment also mentions the suitability of the approach for pattern separation tasks and suggests discussing this aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to infer the need for additional analysis or discussion based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given a direction to explore but are not provided with actionable steps to take. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. The reviewer suggests that directly comparing the results is unfair and recommends reproducing the results using the same setting as the other methods, which have their code released. This feedback provides a clear and explicit action for the authors to take, which is to reproduce the results using the same setting as the other methods. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AdamW with cosine lr for training and the comparison of methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that directly comparing results is unfair due to the different training settings. This provides clear guidance on what needs to be addressed to ensure fair comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that directly comparing results is unfair due to the different training settings, specifically mentioning the use of AdamW with cosine lr for training in the proposed method. The comment suggests that reproducing the results using the same setting as the other methods, which have their code released, would be more fair. This claim is 3 as it logically points out a potential issue with the comparison, but it lacks specific examples or references to support the claim fully. The authors would need to infer the specifics of the issue and determine how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. This observation highlights a potential bias in the comparison, as the different training settings could affect the results. The comment suggests that reproducing the results using the same setting as the other methods, which have their code released, would be more fair. This feedback is clear and actionable, providing the authors with a specific direction to address the issue and ensure a more accurate comparison. However, the comment could be more helpful if it included suggestions on how to reproduce the results or what specific aspects of the comparison should be considered. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear path for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a series of questions about the impact of the information about incorrect and corrected phrases and the type of mistake on the feedback network. It also asks about the performance without and with each of these two types of information and the performance with just natural language feedback. While the questions imply that the authors should analyze and present this information, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this analysis and present the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"information about incorrect phrase / corrected phrase and the information about the type of the mistake,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the impact of this information on the feedback network and the performance without and with each of these two types of information. Additionally, it asks about the performance with just natural language feedback. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point poses a question about the impact of certain types of information on the feedback network, specifically asking about the performance without and with each of two types of information. However, it does not provide any supporting evidence, reasoning, or references to justify why these types of information are relevant or how they might affect the feedback network. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment poses a series of questions about the impact of certain types of information on the feedback network, specifically asking about the performance without and with each of two types of information and the performance with just natural language feedback. This is a thoughtful and insightful question that could prompt the authors to analyze and present data on the effectiveness of different types of feedback. However, the comment does not provide specific guidance or suggestions on how to conduct this analysis or what specific types of information should be included. While it points out an area for potential improvement, it lacks actionable advice or detailed instructions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with Table 1, noting that it does not show standard deviations. It suggests that this omission would make the submission stronger if the experiments were more extensive. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to include standard deviations. The action is implicit and somewhat vague, as the authors need to infer that they should include standard deviations in Table 1 and potentially expand the experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of standard deviations in Table 1 and the need for more extensive experiments. This provides clear guidance on what changes need to be made to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations, which would make the submission stronger if the experiments were more extensive. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this omission is significant or how it affects the overall strength of the submission. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not show standard deviations. This is a clear and actionable point that could significantly improve the paper by including this information. Additionally, the comment suggests that the experiments could be more extensive, which is a valuable suggestion for enhancing the paper\"s comprehensiveness and rigor. However, the comment could be more helpful if it provided additional guidance on how to expand the experiments or what specific aspects should be included. Overall, the feedback is 4 as it highlights a critical oversight and offers a direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit suggestions for improving the structure of the paper and highlights specific sections that require multiple readings. It suggests reorganizing the structure from introduction to method to experiments, which is a clear and concrete action for the authors to take. Additionally, it points out the importance of the IEM in Fig. 3 and recommends focusing on it, providing a specific area for improvement. The comment also suggests improving the visualization of Fig. 7 and Fig., which are specific tasks that the authors can address. Overall, the comment is 5 as it provides clear and detailed guidance on how to improve the paper\"s structure and presentation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as the \"introduction,\" \"method,\" and \"experiments,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear suggestions for improvement, such as reorganizing the structure and focusing on the IEM in Fig. 3. The comment also suggests improving the visualization of Fig. 7 and Fig., providing detailed guidance on how to enhance the clarity and effectiveness of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests improvements to the structure, specifically recommending a change from introduction to method to experiments. The reviewer also highlights the importance of the IEM in Fig. 3 and suggests focusing on it, as well as improving the visualization of Fig. 7 and Fig. The comment provides logical reasoning by suggesting a structural change to enhance the clarity of the paper. However, it lacks specific examples or references to support the claim about the IEM or the visualization issues. Therefore, the comment is 3, as it provides a logical basis but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the structure and organization of the paper, suggesting improvements such as reorganizing the sections from introduction to method to experiments. This is a clear and concrete suggestion that can help the authors enhance the clarity and readability of their draft. Additionally, the comment highlights the importance of the IEM in Fig. 3, which is the main figure in the paper, and recommends focusing on it. It also suggests improving the visualization of Fig. 7 and Fig., which are specific areas for enhancement. Overall, the comment is 5 as it offers detailed guidance on how to improve the structure and presentation of the paper, making it more accessible and engaging for the readers."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. It highlights the concern that the authors only tested four different learning rates and suggests that if the optimal learning rate for the baseline was outside the tested interval, it could affect the results. While the comment explicitly states what information is missing and why it is important, it does not provide specific guidance on how to address this issue or what additional testing might be needed. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"deep models\" and \"CIFAR10 and CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what information is missing\u2014the final used learning rates for the deep models\u2014and why it is important, as it could affect the results if the optimal learning rate for the baseline is outside the tested interval. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the need for information on the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. The reviewer suggests that if the optimal learning rate for the baseline is outside the tested interval, it could affect the results. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the importance of this information and the potential impact on the results, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by requesting information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. This is important as it could affect the results if the optimal learning rate for the baseline is outside the tested interval. The comment is clear and actionable, providing the authors with a direct and specific request for additional data or analysis. However, it could be more helpful if it offered suggestions on how to address this issue or what additional testing might be needed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\"s utility, it could deter their adoption. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to mitigate the potential impact. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the potential impact of their mitigation strategies on performance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the mitigation strategies aimed at reducing memorization and questions their impact on the overall performance of the model. It suggests that there might be a tradeoff between reducing a particular behavior and maintaining high performance, and points out that significant impairment of the model\"s utility could deter adoption. However, the comment does not specify which part of the paper discusses these mitigation strategies, making it weakly grounded. The comment is specific in its concern about the potential impact on performance, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. The comment highlights a potential issue with the adoption of these strategies if they significantly impair the model\"s utility. However, the comment lacks specific examples or references to support the claim that such a tradeoff exists or that the mitigation strategies might significantly impair the model. Without detailed evidence or examples, the claim is 3, as it provides a logical basis but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies aimed at reducing memorization, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It raises a concern about the impact of these strategies on the overall performance of the model, noting that if they significantly impair the model\"s utility, it could deter their adoption. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or mitigate the potential impact on performance. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the reason for using 6fold crossvalidation in the experiments. It points out that other papers in the field did not use crossvalidation, which raises questions about its necessity. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the rationale behind the crossvalidation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clear explanation for the use of crossvalidation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of 6fold crossvalidation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the reason for using crossvalidation is unclear due to the absence of this practice in other papers compared. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the reason for using 6fold crossvalidation is unclear because other papers in the field did not use it. However, the comment does not provide specific examples of these papers or explain why the absence of crossvalidation in those papers is relevant to the current work. This lack of detailed justification or references makes the claim 3, as the authors would need to infer the significance of the comparison to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the reason for using 6fold crossvalidation. It points out that other papers in the field did not use this validation method, which raises questions about its necessity. This feedback is valuable as it highlights an area where the authors need to provide more detailed justification or explanation for their methodology. However, the comment could be more helpful if it suggested ways to address this issue, such as by explaining the rationale behind the choice of crossvalidation or providing examples of how other papers in the field have handled this challenge. Overall, the comment is 3 as it directs the authors to a critical area for improvement, but it lacks detailed guidance on how to address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. While the comment implies that the authors should conduct more experiments or analysis, it does not provide explicit instructions on how to do so. The action is clear but lacks concrete details on what specific experiments or analysis should be conducted. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in the table, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three and there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This claim is 3 as it provides a logical reasoning for the need for additional experiments, but it lacks specific examples or references to support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This feedback is clear and actionable, as it points out a critical weakness in the paper\"s results and provides a concrete direction for improvement. However, the comment could be more helpful if it offered specific suggestions on what additional experiments or analysis might be needed to address this issue. Overall, the comment is 4 as it guides the authors toward improving the robustness and clarity of their results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the paper presents an effective engineering method for ReC but notes that the proposed framework incorporates combinatorial and heuristic aspects. It specifically points out the NonAmbiguous Query Generation procedure, which relies on a sophisticated filtering template. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information about the heuristic components, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the heuristic components. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NonAmbiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the impact of the heuristic components, such as the sophisticated filtering template. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents an effective engineering method for ReC but notes that the framework incorporates combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential area for clarification, it lacks specific examples or references to support the claim that these heuristic components are problematic or unclear. The reasoning is 3, as it points out a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the proposed framework incorporates combinatorial and heuristic aspects, such as the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components, which is a valuable point for improving the paper. However, the comment could be more helpful if it provided specific suggestions on how to clarify these aspects or examples of how they might impact the framework. While it highlights an important area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a doubt about the proposed method\"s ability to be trained without using camera information, specifically questioning the \"knowledge of CAD model correspondences\" mentioned in Line 223. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific steps they could take to clarify or improve their method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the method\"s ability to be trained without camera information and the \"knowledge of CAD model correspondences.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the proposed method\"s ability to be trained without camera information, specifically mentioning the \"knowledge of CAD model correspondences\" (Line 223). However, the comment lacks any supporting evidence, reasoning, or references to substantiate the claim that this knowledge is necessary for training. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the proposed method\"s ability to be trained without camera information, specifically questioning the \"knowledge of CAD model correspondences\" mentioned in Line 223. It highlights the importance of camera information for performing ray marching and determining the ray\"s origin. While the comment identifies a potential weakness in the methodology, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. The feedback is 3 as it points out a potential problem but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically mentioning the need for a detailed comparison of time complexity and competitiveness with prior art. While the comment implies that the authors should include such a comparison, it does not provide explicit instructions on how to conduct it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact details of what is expected. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what aspects of the comparison should be addressed. The authors can infer that it relates to the discussion or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a particular comparison to be made. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, the comment does not provide specific examples or references to prior work that should be compared, nor does it explain why this comparison is necessary or how it would enhance the paper. Without detailed guidance or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. This feedback is 3 as it identifies an area where the paper could be improved by providing a more comprehensive comparison with existing work. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but without detailed steps to follow. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. While the comment explicitly states the need for additional experiments, it does not provide specific guidance on which datasets to use or how to conduct these experiments. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results, but this inference is not direct. The comment is specific in suggesting additional experiments and encouraging experiments on the full dataset, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to justify why additional experiments are necessary or how they would improve the evaluation. The claim is based on a general suggestion, but without specific examples or detailed justification, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. This feedback is clear and actionable, as it directly instructs the authors to expand their experimental scope and improve the comprehensiveness of their evaluation. However, the comment could be more helpful if it provided specific suggestions on which datasets to include or how to conduct these experiments. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity in the paper regarding the generic argument task and the random argument task, specifically questioning how they prove the authors\" claims. It also mentions that the dataset transformation and experimental setup feel cumbersome and unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve clarity. The action is implicit and vague, as the authors are left to infer that they need to clarify the tasks and experimental setup. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the generic argument task and the random argument task, as well as the cumbersomeness of the dataset transformation and experimental setup. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the proof of the authors\" claims and the clarity of the experimental setup. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generic argument task and the random argument task are unclear and that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without specific references or detailed explanations, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper regarding the generic argument task and the random argument task, as well as the cumbersomeness of the dataset transformation and experimental setup. It highlights that the authors\" claims are not clearly supported by the tasks and experimental setup, which could lead to confusion for readers. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their work. While it points out areas for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential for information leaking in AutoAugment\"s policy, which is obtained through supervised training on ImageNet. It also questions the authors\" conclusion in L114 about the pretraining dataset matching the target dataset in terms of object or scene centricity. The reviewer suggests that this might be a setback for SSL algorithms that strive to learn generic representations. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the potential impact of information leaking and the implications for SSL algorithms. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about information leaking in AutoAugment\"s policy, questions the authors\" conclusion about pretraining datasets, and suggests that this might be a setback for SSL algorithms. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the potential for information leaking in AutoAugment\"s policy, which is obtained through supervised training on ImageNet. It questions the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity and suggests that this might be a setback for SSL algorithms. The comment is 3 as it provides a logical reasoning for the concern about information leaking and its potential impact on SSL algorithms. However, it lacks specific examples or references to support the claim about information leaking or the implications for SSL algorithms. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the potential for information leaking in AutoAugment\"s policy, which is obtained through supervised training on ImageNet. It questions the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity and suggests that this might be a setback for SSL algorithms that strive to learn generic representations. The comment provides a thoughtprovoking perspective on the implications of the authors\" findings and encourages them to consider the potential impact on their work. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it identifies an important area for consideration, it does not offer actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include more analysis on the multilingual alignment of entity representations, specifically recommending visualizations or case studies for different types of languages. It also expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific visualizations or case studies should be included. The action is concrete but somewhat vague in terms of execution, as the authors need to determine the specific aspects of multilingual alignment to focus on and how to present the results. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the languageagnostic characters of entity representations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more analysis on the multilingual alignment of entity representations and the suggestion for visualizations or case studies for different types of languages. The comment also raises an interest in the alignment of entities from lowresourced languages with highresourced ones. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis on the alignment of entity representations, specifically for multilingual alignment. It suggests that adding more analysis and visualizations or case studies for different languages would be beneficial. While the comment identifies a potential gap in the analysis, it does not provide specific examples or references to support the claim that the current analysis is insufficient. The suggestion for visualizations or case studies is a logical one, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of analysis on the alignment of entity representations, particularly for multilingual alignment. It suggests that adding more analysis and visualizations or case studies for different languages would be beneficial. Additionally, it raises an interest in the alignment of entities from lowresourced languages with highresourced ones. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their analysis and presentation. However, it could be more helpful if it included specific examples or suggestions on how to implement these improvements. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. While it identifies specific issues, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to check for duplicates and ensure the correct publication venues and years are included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions the references list, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of duplicates and missing publication venues/years, providing clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. However, it does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact nature of the issues. Without specific examples or references, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the references list, noting that it contains duplicates and that the publication venues and/or publication years of many of the papers are missing. This feedback is clear and actionable, as it directs the authors to review and correct their references list to ensure accuracy and completeness. However, the comment could be more helpful if it provided suggestions on how to identify and correct duplicates or how to locate missing publication details. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. It suggests that the authors should analyze and compare their theoretical results to those of other comparable methods. This feedback provides a clear and concrete action for the authors to take, which is to clarify the error bound and compare their results with others in the field. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound in Theorem 1 and the need for analysis and comparison with other comparable methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. The comment suggests that the authors should analyze and compare their theoretical results with those of other comparable methods. While the comment identifies a potential issue with the clarity of the theoretical analysis, it does not provide specific examples or references to support the claim that the error bound is unclear. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and that the authors need to analyze and compare their results with other comparable methods. This feedback is clear and actionable, as it provides a direct suggestion for the authors to improve the clarity and robustness of their theoretical analysis. By addressing this issue, the authors can enhance the rigor and credibility of their work. However, the comment could be more helpful if it offered specific guidance on how to analyze and compare the results, or provided examples of comparable methods to consider. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and points out that the pseudocode of the proposed method is missing. It also references external works that may be relevant to understanding the performance difference. However, the comment does not provide explicit instructions or suggestions on how the authors should address this issue or what specific aspects of the pseudocode should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include the missing pseudocode and possibly explore the performance difference between explicit and implicit methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"locomotion tasks\" and the \"proposed method,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the performance difference between explicit and implicit methods and points out the missing pseudocode of the proposed method. Additionally, it references external works that could be relevant to understanding the performance difference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and mentions the missing pseudocode of the proposed method. It references external works by S\u00f8ren Asmussen and Peter W Glynn and P. Florence et al., which could provide some basis for the claim. However, the comment lacks detailed reasoning or specific examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment is 3 as it requires more detailed explanation or examples to fully justify the claim.", "helpfulness_rationale": "The review comment raises a critical question about the performance of explicit methods compared to implicit methods on locomotion tasks, which is an important aspect of the paper. It also points out the missing pseudocode of the proposed method, which is a significant oversight. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the pseudocode should be included. While it identifies a significant gap in the paper, it does not provide actionable feedback or detailed advice on how to improve the draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the use of lowresource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. It also mentions the method R3F and suggests that the authors should use it to maintain the generalization ability of the model. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the method R3F should be applied to. The action is implicit and somewhat vague, as the authors need to infer that they should explore the use of R3F and how it might impact their results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of lowresource language pairs to finetune the multilingual model and mentions the method R3F. It suggests that the improvement of 0.8 in some lowresource language translations is insignificant in practical terms. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The suggestion to use R3F is specific, as it provides a potential solution to maintain the generalization ability of the model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of lowresource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. The reviewer supports this claim by referencing the method R3F, which is used to maintain the generalization ability of the model. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a reference to a relevant work, the explanation is not comprehensive enough to fully support the claim. Therefore, the comment is 3, as it provides some evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of lowresource language pairs to finetune the multilingual model, suggesting that the improvement of 0.8 is insignificant in practical terms. It also mentions the method R3F as a potential solution to maintain the generalization ability of the model. However, the comment lacks specific guidance on how to implement R3F or what aspects of the model should be adjusted to achieve this goal. While it points out a potential weakness, the feedback could be more helpful by providing actionable steps for improvement. Therefore, the comment is 3, as it highlights an area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should visualize the effect of increasing dimensionality on the performance of existing PU learning methods. This is a clear and direct action for the authors to take, as it provides a specific request for visualization that is crucial to the research motivation of the paper. The comment is specific and actionable, as it clearly identifies what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the performance of existing PU learning methods as the dimensionality of the data increases. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, which is the visualization of this effect. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s claim about the performance of existing PU learning methods as the dimensionality of the data increases. It suggests that visualizing this effect is crucial to understanding the research motivation of the paper. This feedback is clear and actionable, as it directs the authors to provide a visualization that can help substantiate their claim. By addressing this suggestion, the authors can enhance the clarity and credibility of their work. However, the comment could be more helpful if it provided specific guidance on how to create the visualization or what aspects to focus on. Overall, the comment is 4 as it highlights an important area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from 1 and references 2 to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. While the comment provides some guidance on what needs to be improved, it lacks explicit instructions on how to simplify the result descriptions or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from 1 and references 2 to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. However, the comment does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The suggestions are specific, but without clear grounding, the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the result descriptions are needlessly convoluted and suggests that the authors consider a related idea from 1 and check for useful communication in light of 2. The reviewer provides references to external works, which supports the claim by offering a logical connection to related literature. However, the comment could be strengthened by providing more detailed reasoning or examples of specific convoluted descriptions that need simplification. Overall, the claim is 4 due to the references, but it could be further substantiated with additional justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the complexity and clarity of the result descriptions, noting that some are needlessly convoluted. It provides a constructive suggestion by referencing a related idea from 1 and referencing 2 to check for useful communication. This feedback is actionable as it offers a clear direction for the authors to simplify their descriptions and potentially enhance the clarity of their work. However, the comment could be more helpful if it provided specific examples of convoluted descriptions or detailed guidance on how to simplify them. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for how to address the human labor issue or how to improve scalability. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of human labor in building text descriptions and the scalability of the framework with longtext inputs. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for human labor and the scalability issue, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two claims: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. The first claim is based on the observation that text descriptions still require human labor, which is a factual observation. However, the second claim about scalability is less verifiable, as it lacks specific examples or references to support the assertion that longtext inputs restrict scalability. The comment could be strengthened by providing more detailed reasoning or evidence to substantiate the claim about scalability. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. It acknowledges the complexity of determining the optimal textual format for policy learning, which varies across tasks and models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the scalability of their framework. While it highlights important areas for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance improvement of the proposed methods is not significant, as evidenced by the figure 3, and recommends using tables to show the key improvements more intuitively and in detail. While the comment provides a clear action\u2014using tables to present the key improvements\u2014it does not specify which tables should be used or how to present them. The authors are left to infer the details of implementing this suggestion, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods seems not so significant, with the biggest improvement in the bank dataset being around 0.02. Additionally, it suggests using tables to show the key improvements more intuitively and in detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, based on the figure 3, and suggests using tables to show the key improvements more intuitively and in detail. The comment provides a logical reasoning by pointing out the lack of significant performance improvement and the potential for more detailed presentation using tables. However, it does not provide specific data or references to support the claim about the performance improvement or the suggestion for using tables. This makes the claim 3, as the authors would need to make a concerted effort to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the performance improvement of the proposed methods seems not to be significant, as evidenced by figure 3. It suggests using tables to present the key improvements more intuitively and in detail. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of results. By recommending the use of tables, the reviewer offers a method for making the improvements more understandable and detailed, which is valuable for the authors. However, the comment could be more helpful if it provided specific guidance on which tables to use or how to present the data in a more intuitive manner. Overall, the comment is 4, as it effectively points out a potential weakness and offers a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the experimental validation, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to provide more detailed information about the optimization strategy and consider related works, but the comment lacks specific instructions on how to implement these improvements. Therefore, the comment is 3, as it identifies areas for improvement but does not offer concrete steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental validation\" and \"shallow networks\" being considered, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental validation, such as the lack of description of the optimization strategy and the consideration of layer redundancy in the context of network pruning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing, specifically mentioning the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, such as the consideration of layer redundancy in the context of network pruning. The reviewer provides a reference to a specific paper that discusses this issue, which adds some level of verification to the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation section, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how to address them. The reference to a specific paper on network pruning could be more helpful if it included suggestions on how to incorporate this work into the experimental validation. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not provide any guidance on how the authors might prove these results or what specific theoretical aspects should be addressed. The action is implicit and vague, as the authors are left to infer that they need to provide theoretical evidence or results to support their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the lack of theoretical results, but it is 1 as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or what theoretical results could be explored. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors can provide more evidence to either prove or disprove it. While the comment implies that the authors should provide evidence to support or refute the hypothesis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence to substantiate the hypothesis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. However, it does not specify which part of the paper this hypothesis pertains to, making it weakly grounded. The comment is specific in suggesting that the human test results might support the hypothesis but questions whether the authors can provide more evidence to prove or disprove it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. While the comment provides a logical reasoning for the hypothesis, it lacks specific examples or references to support the claim. The suggestion for additional evidence is a clear indication of what the authors could do to improve the draft, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a hypothesis about the two parts of the paper, suggesting that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. This feedback is 3 as it identifies a potential area for further exploration and evidence gathering, which could lead to a more robust understanding of the paper\"s findings. However, the comment could be more helpful if it provided specific suggestions on how to gather or present this evidence, such as recommending specific experiments or analyses. Overall, the comment is 3 as it points out a potential area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the authors should improve Section 3.2 by providing more illustrations and examples. This feedback is clear and direct, giving the authors a specific action to take to enhance the clarity and comprehensiveness of their draft. The comment provides a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more illustrations and examples to improve the clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Section 3.2 is hard to follow and recommends providing more illustrations and examples to improve clarity. However, the comment does not provide specific examples or detailed reasoning to support why the section is difficult to follow or how additional illustrations and examples would enhance comprehension. Without these details, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides a general suggestion but lacks the necessary justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 3.2, noting that it is hard to follow. It suggests that the authors might improve the section by providing more illustrations and examples, which could enhance its clarity and comprehensiveness. While the comment highlights a potential area for improvement, it lacks detailed guidance on what specific illustrations or examples would be beneficial or how to effectively integrate them into the section. This limits the comment\"s helpfulness, as it provides a general direction but does not offer detailed steps for implementation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. While the comment implies that the authors should add these baselines, it does not provide explicit instructions on how to implement this suggestion or what specific baselines to include. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the addition of fullysupervised baselines but lacks grounding as it does not explicitly mention the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or how it would contribute to the understanding of the gap. Without such justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. This is a clear and actionable suggestion that could provide valuable insights into the performance of the models. However, the comment could be more helpful if it explained why this addition is necessary or how it would impact the understanding of the gap. Despite this, the suggestion is still valuable and provides a clear direction for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically asking about the time required to calculate the hypervolume of different regions in each step of LaMOO. It also mentions that the computation of hypervolume could be timeconsuming, especially for problems with many objectives. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete suggestions on how to improve the time complexity or optimize the algorithm. The action is implicit and somewhat vague, as the authors need to infer that they should address the time complexity issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Time Complexity\" and the \"proposed algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the time complexity of the algorithm, particularly the repeated calculation of hypervolume for promising region selection. The comment further raises a concern about the practicality of LaMOO for problems with many objectives, suggesting that the time complexity could be a significant issue. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in LaMOO could be timeconsuming, especially for problems with many objectives. While the comment identifies a potential issue, it lacks specific examples or references to substantiate the claim that the time complexity is a significant problem. The authors are left to infer the potential impact on the practicality of the algorithm, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in LaMOO could be timeconsuming, especially for problems with many objectives. This is an important consideration for the practicality of the algorithm, as it could impact the feasibility of using LaMOO for certain types of problems. The comment prompts the authors to consider this aspect of their algorithm and potentially explore ways to optimize the time complexity. However, the comment could be more helpful if it provided specific suggestions or examples of how to address this issue. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to implement it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, as well as the generic and vague title. It suggests being honest and direct in the critique and provides a specific example of what \"brittle convergence properties\" means. Additionally, it mentions that DeepRL methods are widely adopted and suggests considering the landscape 10 years ago. While the comment provides some guidance on what aspects to address, it lacks concrete details on how to implement these suggestions. The authors are given a general direction but may need to infer specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues, including the limitations of evolutionary methods, the generic and vague title, and the need for more detailed discussion on leveraging state, reactiveness, and learning during an episode. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting that the title is too generic and vague and that the authors should be more precise in their critique. It also asks for clarification on the term \"brittle convergence properties\" and provides an example of DeepRL methods being widely adopted. Overall, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point makes several claims, including that the paper discusses limitations of evolutionary methods, the title is too generic and vague, and that DeepRL methods are widely adopted. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The mention of \"brittle convergence properties\" is not explained, and the suggestion to be more precise in critiques is not accompanied by examples or detailed guidance. As a result, the claims are not fully substantiated, making the comment 1. Therefore, the feedback is rated as 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, which could enhance the paper\"s contribution. It also points out that the title is too generic and vague, suggesting that the authors be more precise in their critique. Additionally, the reviewer questions the term \"brittle convergence properties\" and provides an example of DeepRL methods being widely adopted. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending specific topics for discussion or providing examples of how to improve the title. While the feedback highlights important areas for improvement, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image, and how the edges are handled in areas where depth discontinuities occur. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The authors know they need to provide more information about the synthesis process, but the comment lacks specific suggestions on how to improve the explanation or what details should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks about how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas with depth discontinuities. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing what needs to be addressed, providing clear guidance on what aspects of the synthesis process are unclear. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. While the questions are valid, they do not provide specific examples or references to support the claim that these aspects are unclear or lacking in the paper. The comment lacks detailed reasoning or evidence to substantiate the need for clarification, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. These questions highlight areas where the paper could be improved by providing more detailed explanations of the methodology. However, the comment does not offer specific suggestions or guidance on how the authors might address these issues, such as recommending additional experiments or clarifications. While it identifies important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, it highlights that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. While the comment identifies issues with novelty and similarity, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should improve the novelty and differentiate their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"specific components of the approach,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with novelty and similarity, such as the use of MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before, and the similarity in sampling strategy to epsilongreedy and BRPNAS. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. The reviewer also notes that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, the reviewer states that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. The claim is supported by references to external works, which provide a basis for the assertion that the components are not novel. However, the comment could be strengthened by providing specific examples or detailed comparisons to further substantiate the claim. Therefore, the comment is 4, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty and originality of the approach, noting that the specific components are not novel as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also points out that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, it highlights that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. This feedback is 3 as it provides clear and actionable information about areas where the authors need to improve the novelty and differentiation of their approach. However, it could be more helpful if it offered suggestions on how to address these issues or improve the originality of the components. Overall, the comment provides valuable insights but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a gap in the paper regarding the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix, asking why these methods are not included in the experiments and how they compare to ConBO. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include experiments with continuous tasks and consider including entropy methods in the experiments. The action is concrete but somewhat vague, as it lacks detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on how KG handles the continuous task setting, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of experiments with continuous tasks and questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix. The comment further asks how these methods compare to ConBO, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix and asks how these methods compare to ConBO. While the comment identifies a potential gap in the experimental setup, it lacks specific examples or references to support the claim that these methods should be included in the experiments. The reasoning is 3, as it highlights a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix and asks how these methods compare to ConBO. This feedback is clear and actionable, as it prompts the authors to address the missing experiments and provide a comparison with other methods. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the authors\" explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. While it acknowledges the novelty of the approach, it explicitly requests a more detailed explanation to better understand the difference. This feedback is clear and provides a specific action for the authors to take, which is to provide a more detailed explanation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of unsupervised feature selection from a diffusion perspective, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a more detailed explanation of the difference between similarity and exit times in nature. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. The reviewer acknowledges the novelty of the approach but expresses difficulty in understanding the distinction. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the explanation is unclear. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses a need for a more detailed explanation to better understand the distinction. This feedback is 3 as it points out a potential gap in the paper\"s explanation, prompting the authors to provide a more detailed explanation. However, the comment could be more helpful if it offered suggestions on how to clarify this distinction or provided examples to illustrate the point. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the calculation of precision/recall/F1score for a 4class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should include these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these metrics and AUC results. However, the comment provides a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the calculation of precision/recall/F1score for a 4class classification of breast density and the reporting of AUC results for breast cancer detection. It also specifies the need for sensitivity and specificity at different operating points for model performance comparisons. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual questions about the calculation of precision/recall/F1score and the reporting of AUC results for breast cancer detection. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the calculation and reporting of metrics for a 4class classification of breast density and breast cancer detection. It suggests that providing AUC results with sensitivity and specificity at different operating points could be more informative for comparisons. This feedback is clear and actionable, as it directs the authors to include specific metrics that could enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it provided examples of how these metrics are typically reported or suggested specific operating points to consider. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the use of Transformer in the paper, noting that it is no longer novel in the field and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer also questions the significance of the selfcross attention improvement in the ablation study, suggesting that it is limited (<1%). However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific modifications should be made to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the novelty and impact of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Transformer\" and \"crosslayer,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the modification does not bring much insight and that the selfcross attention improvement is limited. Additionally, it provides specific examples from the ablation study (table 4 and 5) to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of Transformer in the paper is not novel and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer supports this claim by referencing the widespread adoption of Transformer in NLP and vision tasks, which suggests that the modification is not innovative. Additionally, the reviewer points out that the selfcross attention improvement is limited (<1%) and questions whether this should be considered significant. The comment is 4 as it provides logical reasoning and references to common practices in the field, but it could be strengthened with specific examples or references to studies that demonstrate the limited impact of the proposed modification. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment provides a critical analysis of the paper\"s contribution, specifically regarding the use of Transformer and the authors\" modification (crosslayer). It points out that the Transformer is no longer novel in the field and that the modification does not bring significant insight. The reviewer also questions the significance of the selfcross attention improvement, suggesting that it is limited (<1%). This feedback is 3 as it identifies a potential weakness in the paper\"s contribution and highlights areas that need further consideration. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these concerns or improve their work. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and concrete action for the authors to take, specifying exactly what additional tasks they should include in their experiments. The comment is specific and actionable, giving the authors a direct path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, specifically mentioning \"sentence similarity tasks and open domain QA tasks.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited and suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. The comment provides a logical reasoning by pointing out that these tasks are common in the NLP field and could enhance the scope of the experiments. However, the comment lacks specific examples or references to support the claim that these tasks are necessary or how they would improve the experiments. While the suggestion is logical, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically that they are limited to sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing a specific direction for the authors to expand their experiments and enhance the scope of their work. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their experiments. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include the prompt in the appendix or supplement, providing a clear action for the authors to take. Additionally, it suggests that the abstract may be difficult to understand and recommends rephrasing it. The comment about Figure 2 is more vague, as it lacks specific guidance on how to clarify the figure or what changes are needed. However, it does point out a potential issue that the authors can address. Overall, the comments are 4, as they provide clear and concrete suggestions for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the appendix or supplement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the appendix or supplement and provides a suggestion for clarifying the abstract and Figure 2. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, providing a clear and actionable suggestion for improvement. However, the comment does not provide any supporting evidence or reasoning to justify why this is necessary or how it would enhance the paper. Additionally, the comment about the abstract and Figure 2 is factual and descriptive, not requiring verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two main pieces of feedback: first, it suggests that the prompt should be included in the appendix or supplement, which is a clear and actionable suggestion for improving the paper. Second, it points out that the abstract and Figure 2 are difficult to understand, suggesting that the authors consider rephrasing the abstract and clarifying the figure. While the comment identifies specific areas for improvement, it could be more helpful if it provided more detailed guidance on how to address these issues. Overall, the feedback is 4 as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It highlights a specific assumption (Assumption 4.1) that indicates $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be trivially adapted with straightforward modifications following Modification 1 in Appendix C. This provides a clear and concrete action for the authors to take, which is to reconsider the theoretical proof and potentially revise it to enhance its rigor and novelty. The comment is explicit and provides detailed guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical proof for convergence, noting that it lacks novelty and rigor due to the trivial adaptation following Modification 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial and lacks novelty and rigor. It supports this claim by pointing out that Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer also suggests that the convergence proof can be trivially adapted with straightforward modifications following Modification 1 in Appendix C. This reasoning is 3 as it provides a logical explanation for the claim, but it lacks specific examples or references to support the claim fully. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It points out that Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be trivially adapted with straightforward modifications following Modification 1 in Appendix C. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By addressing this issue, the authors can enhance the rigor and novelty of their theoretical proof, which is crucial for the credibility of their work. However, the comment could be more helpful if it offered suggestions on how to improve the rigor and novelty of the proof. Overall, the comment is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental setup borrowed from 2 is only semireal because it involves artificially created multinode seed cascades by merging singlenode seed cascades. This provides a clear and direct action for the authors to take, which is to mention this fact clearly in their paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental setup borrowed from 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, namely that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental setup borrowed from 2 is only semireal because it involves artificially created multinode seed cascades by merging singlenode seed cascades. This claim is 3 as it provides a logical reasoning for the classification, based on the description of the experimental setup. However, it lacks specific examples or references to 2 to fully substantiate the claim. The authors would need to infer the details of the setup from the reference, which could be challenging without direct access to the original work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This is a clear and actionable point that the authors should address to ensure the validity and reliability of their results. By mentioning this issue clearly, the authors can improve the transparency and credibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify this point in the paper or offered guidance on how to address the issue. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential contradiction in the paper, noting that the multienv model is stated to have an inevitable performance loss but also outperforms the singleenv model due to knowledge sharing. The reviewer requests clarification on this contradiction, implying that the authors should address this issue to ensure consistency in their claims. While the action is implicit, it is clear that the authors need to clarify the contradiction, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement about the multienv model having an inevitable performance loss and the statement about knowledge sharing leading to outperformance. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue of contradiction between these two statements and requests clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the contradiction between the claims that the multienv model has an inevitable performance loss and that it outperforms the singleenv model due to knowledge sharing. The reviewer does not provide specific reasoning or evidence to support the claim of contradiction, making it difficult for the authors to understand the basis of the issue. Without additional context or examples, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the performance of the multienv model. It points out that the model is stated to have an inevitable performance loss but also outperforms the singleenv model due to knowledge sharing. This feedback is valuable as it prompts the authors to clarify this contradiction, which could be a source of confusion or misinterpretation in their work. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to reconcile these conflicting statements. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more actionable with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or a citation to the metrics. This feedback is explicit, as it clearly states what the authors need to do to improve their draft: either provide an explanation or a citation to the metrics. The action is concrete, as it specifies exactly what the authors need to do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"description of the metrics,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an explanation or a citation to the metrics used in the paper. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the metrics is limited and suggests that an explanation or citation to the metrics would be beneficial. However, the comment does not provide specific examples or detailed reasoning to support why the current description is insufficient or how an explanation or citation would improve the paper. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically the lack of an explanation or citation for the metrics used. This is a critical feedback as it highlights an area where the authors could enhance the clarity and transparency of their work. By suggesting that an explanation or citation would be beneficial, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific examples of how the metrics are used or why they are important, which would guide the authors in addressing the issue more effectively. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"learned MASK embedding\" is unclear in the SSL pretraining stage of the proposed method. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this term or what specific actions they should take to address this issue. The comment lacks concrete details or suggestions for improvement, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SSL pretraining stage\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"learned MASK embedding,\" which is unclear in the context of SSL pretraining. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"learned MASK embedding\" is unclear in the SSL pretraining stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to explain why this term is unclear or how it could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary justification to support the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the term \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. This is a clear and actionable point that the authors can address to improve the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or examples to help the authors better understand the issue and how to resolve it. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks depth and detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the reported results are partially derivative, as they extend to hypernetworks results that have already been presented for standard networks in the literature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the originality of the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the reported results are partially derivative, as they extend to hypernetworks results that have already been presented for standard networks in the literature. However, it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in identifying the issue of derivative results, but without clear grounding, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the reported results are partially derivative, as they extend to hypernetworks results that have already been presented for standard networks in the literature. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the originality of the reported results, suggesting that they are partially derivative as they extend to hypernetworks results that have already been presented for standard networks in the literature. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the originality of their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it appears to focus on injecting a CoTbased approach to smallscale language models. The reviewer suggests that if this is not the case, additional relevant CoT baselines for incontext learning of large language models should be included in Tables 2 and 3. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to add these baselines or specify how to do so. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3\" and \"Question A,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional relevant CoT baselines for incontext learning of large language models. This provides clear guidance on what the authors need to address to improve their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach to smallscale language models. The reviewer provides a specific observation that additional relevant CoT baselines for incontext learning of large language models (such as text003 and ChatGPT) are missing in Tables 2 and 3. This claim is 3 as it provides a logical reasoning for the need to include these baselines, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it appears to focus on injecting a CoTbased approach to smallscale language models. The reviewer suggests that if this is not the case, additional relevant CoT baselines for incontext learning of large language models (such as text003 and ChatGPT) should be included in Tables 2 and 3. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance the scope and comprehensiveness of their study. By addressing this point, the authors can ensure that their work is more comprehensive and relevant to the field. However, the comment could be more helpful if it included specific examples or references to relevant CoT baselines. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their study."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that Figure 3 is difficult to read, providing a clear action for the authors to take. However, it does not specify what aspects of the figure are challenging to read or how the authors might improve the figure to make it more readable. While the action is explicit, the lack of concrete details on how to address the issue makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, stating that it is difficult to read anything on the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment claims that \"Figure 3 is very hard to read anything on the figure.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with Figure 3, stating that it is difficult to read anything on the figure. This feedback is clear and actionable, as it directs the authors to address a specific visual aspect of their work that may impact the readability and comprehension of their findings. However, the comment could be more helpful if it provided suggestions on how to improve the figure, such as recommending adjustments to the figure size, font, or color scheme. Overall, the comment is 3 as it points out a clear issue but lacks detailed guidance on how to resolve it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific aspects of the connection should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential area for further exploration or discussion, it does not provide any actionable feedback or suggestions for the authors to address this question or improve their draft. The comment lacks depth and specificity, leaving the authors without clear guidance on how to proceed. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and questions the justification behind using an SGD learning rate of ~0.1. While the comment provides a specific action to take regarding the parameter `lambda`, it does not offer guidance on how to address the issue with the SGD learning rate or what the justification should be. The action is explicit but lacks concrete details on how to implement the suggested change or provide a justification for the learning rate choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes two claims: (1) replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and (2) questioning the justification behind using an SGD learning rate of ~0.1. The first claim is 3 as it suggests a change in the mathematical expression but lacks detailed explanation or justification for the proposed change. The second claim is also 3, as it questions the justification behind the learning rate choice without providing specific reasoning or examples. Overall, the claims are not fully substantiated, making the comment 3.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. It points out that the justification for these choices is unclear, which is a valuable observation that can help the authors improve their draft. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered alternative justifications for the changes. While it highlights areas for improvement, the feedback is somewhat limited in its guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to discuss a previous work on joint error for UDA, specifically mentioning \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. It also suggests that the authors should illustrate the relationship between this work and their proposed method, and explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of joint error for UDA, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the relationship between the proposed method and previous work on joint error, and why the proposed method is better. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about the lack of research on joint error for UDA is incorrect, as it has already been studied in previous works like \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. The reviewer suggests that the authors should discuss this work and illustrate the relationship between it and the proposed method. This claim is 3 as it references a specific work, providing some evidence for the existence of prior research on joint error. However, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method differs from the existing work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the lack of research on joint error for UDA. It points out that this issue has already been studied in previous works, specifically mentioning \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. The comment suggests that the authors should discuss this work and illustrate the relationship between it and their proposed method, as well as explain why their method is better. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by addressing the existing literature and justifying their method\"s novelty. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It also notes the absence of a discussion on the research gap, such as why existing methods cannot be applied. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the research gap should be discussed. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification for the need of a new curriculum learning method and address the research gap, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that while several curriculum learning methods have been discussed in Section 1, the need for designing a new curriculum learning method for text graphs is not justified. It also points out the absence of a discussion on the research gap, such as why existing methods cannot be applied. This feedback is 3 as it highlights a potential gap in the paper\"s justification for the need of a new curriculum learning method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the research gap should be discussed. While it provides some insight, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion for the authors to use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of using the simplest ngram features. This is an explicit and concrete action that the authors can take to improve their draft. The comment clearly specifies what needs to be done and how it can be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the domain adaptation in the NLP field and suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods. It also provides specific guidance on how to compare the efficacy of the transfer parts instead of using the simplest ngram features. This level of detail allows the authors to accurately identify the part of the paper being addressed, making the comment 5. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods in domain adaptation in the NLP field. This claim is 3 as it provides a logical reasoning based on the known capabilities of these models in overcoming domainshift problems. However, the comment lacks specific examples or references to support the claim fully, such as studies or experiments that demonstrate the effectiveness of these models in domain adaptation. This makes the claim 3, as it provides a reasonable basis but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to use powerful pretrained language models like BERT and XLNet as the base encoder for all methods in domain adaptation in the NLP field. It suggests comparing the efficacy of the transfer parts instead of using the simplest ngram features. This feedback is clear and offers a concrete way for the authors to improve their draft by leveraging more advanced language models. However, the comment could be more helpful if it provided additional context or examples of how these models have been used successfully in similar applications. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. While the comment identifies an area for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a more detailed analysis or provide additional experiments to clarify the contribution of each module. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, which comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for more detailed analysis or additional experiments to clarify the contribution of each module. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the main performance gain is due to a specific module or the increased number of parameters. It suggests that the current ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the need for more detailed analysis or additional experiments to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters, and points out that the current ablation study does not provide definitive answers to these questions. This feedback is 3 as it highlights an area where the authors could improve their analysis and provide more detailed explanations of the method\"s performance. However, the comment could be more helpful if it suggested specific experiments or analyses that could address these questions. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of explanation in the paper regarding the two quantities mentioned in lines 196197. It explicitly asks for more clarification on why the two quantities are different and how they capture the difference in learning settings. This feedback provides a clear and direct action for the authors to take, which is to provide additional explanation in these lines. The comment is specific and concrete, giving the authors a clear idea of what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l 1967,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation regarding the two quantities and their relationship to learning settings. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the explanation provided in lines 196197, asking for more clarification on why the two quantities are different and how they capture the difference in learning settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this explanation is necessary or how it would impact the paper\"s understanding. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires more explanation, specifically the two quantities mentioned in lines 196197. It asks for clarification on why the two quantities are different and how they capture the difference in learning settings. While the comment highlights a potential gap in the paper\"s explanation, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a specific area for improvement, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a clear and direct request, providing the authors with a specific action to take. The comment is specific in detailing what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss the sensitivity of fixed tuning parameters in the model, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the strengths and weaknesses of these parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 3 as it prompts the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a relevant and important aspect to consider, as it could impact the robustness and generalizability of the model. However, the comment lacks specific guidance or examples on how to approach this discussion or what aspects to focus on. While it points out a potential area for improvement, it does not provide detailed instructions or suggestions for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed framework should be tested with different policy gradient approaches and provides a specific question about the number of random seeds used for learning the policies (DDPO and IPPG). While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment results. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in its request for information about the random seeds used, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they would impact the framework\"s performance. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the suggestion or the importance of addressing these points. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). This feedback is 3 as it identifies a potential area for further exploration and experimentation, which could enhance the robustness and generalizability of the framework. However, the comment lacks depth and does not provide specific guidance on how to implement these changes or what specific policy gradient approaches should be considered. While it points out a potential area for improvement, it could be more helpful with additional details or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. While it implies that the authors should expand their analysis, it does not provide specific guidance on which datasets or tasks to include or how to conduct the additional evaluations. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should evaluate on more datasets and tasks to strengthen the results and conclusions. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting that the analysis should be expanded, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would be stronger if it evaluated on more datasets and tasks. This is a logical suggestion based on the idea that broader applicability and generalizability can strengthen the results and conclusions. However, the comment lacks specific examples or references to support why this is necessary or how it would improve the paper. Without detailed reasoning or evidence, the claim is 3, as it provides a logical basis but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. This is a valid point as it could provide a broader perspective on the applicability and generalizability of the findings. However, the comment lacks specific guidance on which datasets or tasks to consider, or how to effectively integrate these additional evaluations into the paper. While it identifies a potential area for improvement, it does not offer detailed suggestions or examples to help the authors achieve this enhancement. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific areas where the writing could be improved, providing examples of unclear or difficulttointerpret definitions. It explicitly asks for clarification on the \"relevant\" auxiliary model weights in definition 2.1. This feedback is clear and provides concrete guidance on what needs to be addressed to improve the clarity of the writing. The authors know exactly what needs to be done to enhance the clarity of their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the \"relevant\" auxiliary model weights in definition 2.1. This provides clear guidance on what needs to be improved in the writing. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the clarity of the writing in specific sections, such as definition 2.1. It provides examples of unclear or difficulttointerpret definitions, which is a logical observation. However, the comment does not offer specific examples or references to support the claim that the writing is unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is considered 2, as it provides some support but lacks detailed justification.", "helpfulness_rationale": "The review comment identifies specific areas where the writing could be improved, providing examples of unclear or difficulttointerpret definitions. This feedback is actionable and constructive, as it points out specific parts of the paper that need clarification. By addressing these issues, the authors can enhance the clarity and accessibility of their work, which is valuable for improving the overall quality of the draft. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the definitions or provided examples of clearer explanations. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the robustness of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It suggests that the use of ULiRA 1 is recommended. However, the comment does not provide explicit instructions on how to address this concern or implement the suggested use of ULiRA. While the authors can infer that they should consider using ULiRA, the comment lacks concrete guidance on how to integrate it into their work. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and raises concerns about the robustness of MIA testing for privacy guarantees. It suggests using ULiRA 1 as an alternative. However, the comment does not specify which part of the paper discusses the use of MIA testing or where the recommendation for ULiRA should be integrated. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue with MIA testing and the recommendation for ULiRA, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness is not robust enough for privacy guarantees. It suggests that the use of ULiRA 1 is recommended. However, the comment does not provide specific examples or references to support this claim, such as data or studies that demonstrate the limitations of MIA testing or the benefits of ULiRA. Without such evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the issue without additional context or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It raises a valid concern about the robustness of MIA testing for privacy guarantees, which is an important consideration for the paper\"s contributions. The comment suggests using ULiRA 1 as an alternative, providing a specific recommendation that could help improve the robustness and credibility of the paper\"s claims. However, the comment could be more helpful if it provided additional context or examples on how ULiRA could be integrated into the paper or why it is considered a better option. Overall, the comment is 3 as it points out a potential weakness and offers a specific suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that it could be presented in the \"language of kernel interpolation/smoothing.\" However, it does not provide explicit instructions or concrete steps for the authors to take. The comment implies that the authors should consider presenting this information, but it lacks specific guidance on how to do so or what aspects of kernel regression should be addressed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting this information in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its suggestion to present the information in the language of kernel interpolation/smoothing, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression. It suggests that the information could be presented in the \"language of kernel interpolation/smoothing.\" However, the comment lacks any supporting evidence, reasoning, or references to justify why this is relevant or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it does not provide sufficient justification for the authors to address the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression, suggesting that it could be presented in the \"language of kernel interpolation/smoothing.\" While it identifies a potential area for improvement, the comment lacks specific guidance or suggestions on how to present this information or what aspects of kernel regression should be addressed. The feedback is 3 as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that adding more details to the paper and/or supplementary information would be beneficial. Additionally, it recommends including error bars and/or pvalues when statistical inferences are made. While the comment provides explicit actions (adding details, including error bars), it does not specify which parts of the paper need more detail or which figures are confusing. The authors are given a clear direction to improve their draft, but the lack of detailed guidance on specific areas or figures makes the action somewhat vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"simulation or experimentbased evidence\" and \"fig. 2,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details the issues with the explanations, the lack of detailed procedures, and the confusion regarding figures, such as \"sample count\" in fig. 2. Additionally, it provides specific suggestions for improvement, such as adding more details to the paper and including error bars or pvalues when statistical inferences are made. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations in the paper are qualitative and that the procedures are described minimally or not at all, with some figures being confusing. The reviewer suggests that adding more details and supplementary information would be beneficial. The comment also mentions the need for error bars and/or pvalues when statistical inferences are made. While the comment identifies specific issues, it lacks detailed examples or references to support the claim about the qualitative nature of the explanations or the confusion in the figures. This makes the claim 3, as the authors would need to make a concerted effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that adding more details to the paper and/or supplementary information would be beneficial. Additionally, it recommends including error bars and/or pvalues when statistical inferences are made. While the comment provides clear and actionable feedback on areas for improvement, it could be more helpful if it offered specific suggestions on how to enhance the explanations or which figures need clarification. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add supportive references for claims that may be inspired by existing studies. It provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment is clear and concrete, as it specifies which parts of the paper need references and provides a specific example of where these references should be added. This gives the authors a direct action to take to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to add supportive references for claims inspired by existing studies. The comment provides a detailed example of the factors that need references, such as order sensitivity, complexity, diversity, and style sensitivity. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some claims may be inspired by existing studies and suggests that it is critical to add supportive references. The reviewer provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. This reference supports the claim by pointing out that many of these factors have been discussed in existing studies. However, the comment could be strengthened by providing specific references to these studies or explaining how the current claims differ from existing work. Despite this, the claim is 4 due to the specific example provided.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that some claims may be inspired by existing studies and suggesting that supportive references are necessary. It provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. This feedback is clear and actionable, as it directs the authors to include references to support their claims. However, the comment could be more helpful if it suggested specific studies or references to include, which would provide the authors with a more comprehensive understanding of how to address the issue. Overall, the comment is 4 as it highlights a critical area for improvement and offers a concrete suggestion for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback implies that the authors should include this information in their paper to enhance its clarity and usefulness to the community. However, the comment does not provide specific guidance on how to present these settings or what aspects should be included. While the action is implied, it is not as concrete as it could be, as the authors are left to infer the exact details of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting that providing these settings would help the community by providing a single review of advances in this area. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This claim is 3 as it provides a logical reasoning for improvement, suggesting that such a comparison would enhance the paper\"s clarity and usefulness to the community. However, the comment lacks specific examples or references to prior work or studies that have successfully implemented this approach, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and usefulness of their work. By including this information, the authors can contribute to the community by offering a single review of advances in the area. However, the comment could be more helpful if it provided examples of how these settings were presented in prior work or suggested specific ways to present them in the paper. Overall, the comment is 4 as it identifies a clear area for improvement and offers actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that adding a few more datasets would be beneficial, particularly in terms of crosstask transferability. While the comment implies that the authors should consider adding more datasets, it does not provide specific guidance on which datasets to include or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors need to infer that they should add more datasets but are not given concrete details on which datasets to include or how to integrate them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on crosstask transferability. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need to be revised. The comment is specific in its suggestion to include more datasets, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or how it would impact the analysis. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets to include or how they would enhance the analysis. The feedback is 3 as it points out a potential area for improvement, but it does not offer actionable steps for the authors to take. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the tasks are somewhat standard and implies that the authors could have included more unique tasks to showcase the diversity of images/plots. It provides a specific example of interleaved imagetext tasks, such as question answering from images, as a potential area for improvement. While the comment does not explicitly instruct the authors to implement these tasks, it clearly outlines a direction for enhancing the paper by suggesting a specific area for innovation. The action is implicit but concrete, as the authors can infer the need to explore unique tasks and understand the potential benefits of doing so. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the tasks are somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It also mentions the potential for unique tasks that could showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the tasks or experiments described. The comment is specific in suggesting a potential area for improvement, which is to include more unique tasks that highlight the diversity of images/plots. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the tasks are somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It also implies that the authors could have included more unique tasks to showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. The comment provides a logical reasoning for why the tasks could be more diverse and suggests a specific area for improvement. However, it lacks specific examples or references to support the claim that these tasks would be beneficial or how they would enhance the paper. Therefore, the comment is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the tasks being somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It suggests that the authors could have included more unique tasks to showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. This feedback is 3 as it points out an area for improvement and provides a specific example of a potential unique task. However, the comment could be more helpful if it offered more detailed guidance on how to implement these unique tasks or why they are important for the paper. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not provide explicit actions for the authors to take, they imply that the authors should address these issues in their paper. The comment is 3 as it prompts the authors to clarify the relevance of their framework and its applicability to specific scenarios. However, it lacks concrete guidance on how to address these questions or what specific aspects to focus on, making it somewhat vague in terms of execution.", "grounding_specificity_rationale": "The comment raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it specifically references the section on binary classification. However, it does not explicitly mention which part of the paper discusses these topics, making it weakly grounded. The comment is specific in its inquiry about the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints, as well as the potential use of statistics like covariance to design better defenses. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints. The comment also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not present claims, they imply a need for clarification or explanation. However, the comment lacks specific examples, references, or detailed reasoning to support the questions, making it 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment raises important questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not provide actionable feedback, they prompt the authors to consider the broader implications of their work and to address potential limitations or areas for improvement. The comment is 3 as it encourages the authors to think critically about the applicability and robustness of their framework. However, it could be more helpful if it offered specific suggestions or examples on how to address these questions or improve the paper. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it would impact the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This is a clear and actionable suggestion that could help the authors improve their draft by exploring a new approach to evaluating their model. However, the comment could be more helpful if it provided additional context or justification for why this approach might be beneficial or how it could impact the results. Overall, the comment is 4 as it offers a specific direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to reorganize the Appendix H section, which is difficult to follow. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve the draft. The comment is specific about the issue of difficulty in following the section, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the Appendix H section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, which is that it is difficult to follow. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Appendix H section is difficult to follow. However, it does not provide any specific examples or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow. This feedback is clear and actionable, as it directs the authors to reorganize the section to improve its clarity and accessibility. However, the comment could be more helpful if it provided suggestions on how to reorganize the section or what specific changes might improve its readability. Overall, the comment is 3 as it points out a clear area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the reproducibility of the paper, noting that while the pseudocode is provided in the supplementary material, it does not provide enough detail for actual reproduction. The reviewer suggests that more technical details, such as the number of units in the RNN implementation, are missing. This feedback implies that the authors should include more detailed descriptions of the technical aspects of their work to improve reproducibility. However, the comment does not explicitly instruct the authors to add these details, leaving it somewhat vague. While the action is implied, the authors can infer that they need to provide more technical information, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the supplementary material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with reproducibility, such as the lack of technical details like the number of units in the RNN implementation. This provides clear guidance on what needs to be addressed to improve reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not written to be reproduced, as it lacks technical details necessary for reproduction. The reviewer provides a specific example of the lack of details about the RNN implementation, such as the number of units. This claim is 3 as it highlights a gap in the paper\"s reproducibility, but it could be strengthened by providing more detailed examples or references to similar works that require such technical details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the reproducibility of the paper, noting that while the pseudocode is provided in the supplementary material, it does not provide enough detail for actual reproduction. The reviewer highlights specific areas that are missing, such as technical details about the RNN implementation, which are necessary for reproducing the work. This feedback is clear and actionable, as it points out specific gaps in the paper that need to be addressed to improve its reproducibility. However, the comment could be more helpful if it suggested ways to address these gaps or provided examples of how similar details have been presented in other works. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they should consider to improve the clarity of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its concern about the model\"s ability to generate novel knowledge or testable hypotheses, but without clear grounding, it lacks actionable guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of their work. Without actionable feedback or detailed insights, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the calculation of the keypoint mask averaged feature vector, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the calculation of the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the calculation of the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While this question may be relevant to the authors, it does not provide any actionable feedback or suggestions for improvement. It lacks depth and does not guide the authors on how to address the issue or improve the clarity of the explanation. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or provide a convincing analytical or empirical argument. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspects of the analytical or empirical evidence are lacking, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the central contribution of the paper, which is based on modeling weight evolution using ODEs, is not convincing due to the issue of neural ODEs exhibiting inaccuracy while recomputing activations. The reviewer questions whether this problem has been previously reported and suggests that the current paper lacks a convincing analytical or empirical argument to support the claim. However, the comment does not provide specific references or examples to substantiate the claim, making it difficult for the authors to understand the basis of the reviewer\"s skepticism. As a result, the claim is 3, as it provides some reasoning but lacks detailed evidence or references to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s central contribution, which is based on modeling weight evolution using ODEs. It questions the accuracy of neural ODEs while recomputing activations, suggesting that this issue has been previously reported. The comment highlights a gap in the paper\"s analytical or empirical evidence to support the claim, indicating that the authors need to provide a more convincing argument or evidence to address this concern. However, the comment does not offer specific suggestions or guidance on how the authors might improve their analysis or evidence to address this issue. While it points out a potential weakness, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it notes that this paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment implies that the authors should not focus on proving lower bounds for round complexity, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer that they should focus on other aspects of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it also notes that this paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the results and methodology sections where the lower bound results are discussed. The comment is specific in detailing what is considered an easy corollary and why the paper does not need to focus on proving lower bounds for round complexity. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it suggests that this paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. The comment provides a logical reasoning for why the lower bound results are not as significant as initially thought, but it lacks specific examples or references to support the claim about the ease of the reduction. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it also points out that this paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. This feedback is 3 as it highlights a potential oversight in the paper\"s approach and suggests that the authors should reconsider their focus on proving lower bounds. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what alternative approaches might be considered. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. While the comment implies that the authors should consider using more advanced prompting techniques, it does not provide specific guidance on how to implement this suggestion or what specific prompts might be effective. The action is implicit and somewhat vague, as the authors need to infer the need for more advanced prompting techniques and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, suggesting that it is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. The suggestion to use carefully curated prompts is specific, but without clear grounding, the authors may struggle to identify the exact section that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It suggests that using carefully curated prompts can lead to better results in generating systematic reviews. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as the authors would need to infer the need for more advanced prompting techniques and how to implement them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the study, namely the basic nature of the prompting technique used and its failure to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment highlights an important area for improvement, it lacks specific guidance on how to implement this suggestion or what prompts might be effective. The feedback is 3 as it points out a potential area for enhancement but does not provide detailed instructions on how to achieve it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the performance of the model on REC and RES is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance or suggestions for potential improvements. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the performance of the model on REC and RES being behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. This claim is supported by references to external works, which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or specific metrics to support the claim further. As it stands, the claim is 4 due to the inclusion of references, but it could be more robust with additional evidence or explanation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a significant issue with the performance of the model on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This feedback is valuable as it identifies a clear area for improvement, allowing the authors to address the issue and potentially improve their results. However, the comment could be more helpful if it provided suggestions on how to improve the performance or offered guidance on potential strategies for catching up with more recent models. Despite this, the feedback is 4 as it directs the authors\" attention to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the term \"evidence\" might be too strong and recommends a more appropriate wording, such as \"Fig.\" This implies that the authors should revise the language in the paper to be more precise and accurate. However, the comment does not provide specific guidance on how to rephrase the term or what alternative wording would be more appropriate. The action is implicit and somewhat vague, as the authors need to infer the exact changes needed to make the comment more actionable. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific figure (Fig. 5) and suggests that the term \"evidence\" might be too strong. However, it does not specify which part of the figure or the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting a more appropriate term, such as \"Fig.\" This provides some guidance on what needs to be addressed, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the term \"evidence\" might be too strong in describing the figure (Fig. 5) and recommends using a more appropriate term, such as \"Fig.\" This is a suggestion for clarification rather than a claim or opinion that requires verification. It does not present an argument or evidence to support the claim that \"evidence\" is inappropriate. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential issue with the language used in describing a figure, suggesting that the term \"evidence\" might be too strong. It provides a specific recommendation to use a more appropriate term, such as \"Fig.\" This feedback is 3 as it points out a potential inaccuracy in the language used, which could be clarified to improve the clarity and precision of the paper. However, the comment could be more helpful if it explained why \"evidence\" might be inappropriate or suggested alternative terms that would be more accurate. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed video storyboarding approach lacks novelty, as it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation instead of crossattention. While the comment identifies a specific area of concern, it does not provide explicit guidance on how the authors should address this issue or improve the novelty of their approach. The action is implicit and somewhat vague, as the authors can infer that they need to explore ways to enhance the innovation of their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed video storyboarding approach\" and \"framewise SDSA,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty in the approach, noting that it relies heavily on framewise SDSA and that the only notable difference is the mask source. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed video storyboarding approach lacks novelty, as it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation rather than crossattention. This claim is 3 as it provides a specific comparison to ConsiStory, which is a wellknown approach, and highlights the difference in the mask source. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer highlights the only notable difference as the mask source, which uses CLIPseg and OTSU segmentation rather than crossattention. This feedback is 3 as it points out a specific area where the paper could be improved by exploring more innovative approaches or techniques. However, the comment lacks detailed suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. To be more helpful, the comment could provide specific suggestions or examples of alternative methods that could be considered. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison, but it is not as concrete as it could be. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, and it proposes a comparison with previous approaches on fewshot classification in such datasets. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison with previous approaches, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The suggestion to compare the method with previous approaches on fewshot classification in such datasets is a logical one, but without additional context or justification, the claim remains 3. The authors may find it challenging to understand the basis of the suggestion without further explanation or evidence. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, which is a valuable observation. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets. This feedback provides a clear direction for the authors to consider, which could enhance the relevance and impact of their work. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it identifies a potential area for improvement and provides a clear direction for the authors to explore further."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not provide specific guidance on how the authors should address this concern or what steps they should take to improve the results on larger backbones like SwinB or SwinL. The action is implicit and somewhat vague, as the authors can infer that they need to test the method on larger backbones but are not given concrete steps to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. It also suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the relative gains and the potential impact of the global pooling structure on the results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment lacks specific examples or references to support the claim about the relative gains or the potential impact of the global pooling structure. Without detailed evidence or comparisons, the claim is 3, as it provides a logical reasoning but lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that the relative gains are not very strong, even on smaller backbone models like ResNet50. It suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the results on larger backbones like SwinB or SwinL. While it points out a potential weakness, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the analysis or what specific aspects of the neural network analysis need attention. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. It references specific sections, \"Section 3.2, 3.3,\" which allows the authors to accurately identify the parts of the paper being addressed. However, the comment lacks specificity in detailing what aspects of the analysis are problematic or how it could be improved. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the analysis of neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks by only considering wide fullyconnected neural networks. The comment supports this claim by referencing specific sections, \"Section 3.2, 3.3,\" which provides some basis for the assertion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why the analysis is trivial or how it bypasses the core problem. This makes the claim 3, as it provides some support but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. It points out that the analysis only considers easy wide fullyconnected neural networks, which is a valid observation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable feedback or detailed advice, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as 2, as it identifies a weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential confusion in the paper regarding the use of terms like \"relatively inexpensive\" and \"expensive to evaluate.\" However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to clarify the terms. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the multifidelity framework and sequential design for learning quantities, specifically mentioning a reference to Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017). This provides full grounding as it clearly identifies the part of the paper being addressed. The comment also specifies the issue of confusion regarding the terms \"relatively inexpensive\" and \"expensive to evaluate\" in the abstract and first line of the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the terms \"relatively inexpensive\" and \"expensive to evaluate\" are confusing, as they appear in different parts of the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these terms are confusing or how they could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary information to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the terms \"relatively inexpensive\" and \"expensive to evaluate,\" which are used in different parts of the document. This feedback is 3 as it points out a specific issue that could be clarified to improve the clarity and consistency of the paper. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a rephrasing or offering examples of how to clarify the terms. Overall, the comment is 3 as it highlights an area for improvement but lacks detailed guidance for the authors to fully address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"curated AH36M dataset\" and the need for clarification on whether it is used for training. It also raises questions about whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the fairness of the comparison. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the use of the curated AH36M dataset for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This is a clear and actionable point that could help the authors ensure the fairness and transparency of their experimental setup. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending the authors clarify their methodology or provide more detailed information on data access. Overall, the comment is 4 as it identifies a critical area for improvement but lacks depth in its guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to compare their captioning experiment results to the official COOC leader board on the blind test set, which is a clear and direct action. It also suggests that the paper should compare to other approaches that have been evaluated on the blind challenge set, such as 5,17 and other recent approaches. The comment provides specific references to the leaderboard and the need for comparison, making it 5. The authors know exactly what needs to be done to improve their draft, which is to include these comparisons in their results section.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the captioning experiment and the comparison to related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to compare the results to the official COOC leader board on the blind test set and to include comparisons to other approaches that have been evaluated on the blind challenge set. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the captioning experiment should be compared to the official COOC leader board on the blind test set, which is a specific suggestion for improvement. The reviewer provides a reference to the COOC leaderboard and specific examples of approaches that have been evaluated on the blind challenge set, such as 5,17. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on how the authors can improve their captioning experiment. It points out that the paper currently compares to related work only on some not official test set or dev set, which is not ideal for demonstrating the final results. The reviewer suggests that the paper should compare to the official COOC leader board on the blind test set, which is a widely recognized benchmark in the field. Additionally, the comment suggests that the authors should compare their results to other approaches that have been evaluated on the blind challenge set, such as 5,17, which is a clear and constructive suggestion. This feedback is valuable as it guides the authors to include more comprehensive and meaningful comparisons in their paper, which can significantly enhance the credibility and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the reliability of the results or what specific steps to take to validate them. As a result, the authors are left without clear direction on how to improve the draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, particularly the MSE being significantly smaller than the MAE, which raises concerns about their validity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results and highlights a potential weakness in the paper. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the reliability of their experimental results. Without specific recommendations or examples, the feedback lacks depth and does not fully support the authors in improving their draft. Therefore, the comment is rated as 2, as it points out a problem but does not offer a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their work. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to differentiate the methodology from existing work. As a result, the authors are left without a clear understanding of what steps to take to enhance the novelty of their methodology. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique is based on, such as specific sections or methods where the extension is evident. Without explicit references to sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or references to existing methods to substantiate this claim. Without detailed comparisons or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might differentiate their work or enhance its novelty. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the critique or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific line (L248) where the term \"wrong\" is used and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using those concepts. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is 5 as it offers a direct and specific suggestion for clarification, making it easy for the authors to implement the suggested changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of \"wrong\" and the use of terms like \"good\" and \"bad\" explanations. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of the term \"wrong\" in a specific context and suggests that the authors clarify what is meant by \"good\" and \"bad\" explanations before using those concepts. This is a request for clarification rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the term \"wrong\" in the paper and suggests that the authors clarify what is meant by \"good\" and \"bad\" explanations before using those concepts. This feedback is clear and actionable, as it points out a potential confusion in the paper that could be resolved by providing additional context or explanation. By addressing this issue, the authors can improve the clarity and coherence of their argument. However, the comment could be more helpful if it provided suggestions on how to clarify these concepts or offered examples of how they might be clarified. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the concept of \"state\" and questions the equivalence of \"elements\" to \"states\" or \"actions.\" It suggests that more elaboration is needed. While the comment identifies an area for improvement, it does not provide explicit guidance on how to clarify the concept or what specific aspects need elaboration. The authors are left to infer that they need to provide more detail, but the comment lacks concrete steps or examples on how to achieve this. Therefore, the comment is 3, as it points out an area for improvement but does not offer detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the equivalence of \"elements\" to \"states\" or \"actions\" and suggests that more elaboration is needed. This provides clear guidance on what needs to be clarified or expanded in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of \"state\" and seeks further elaboration on the equivalence of \"elements\" to \"states\" or \"actions.\" While the comment raises a valid concern about the clarity of the concept, it does not provide specific examples or references to support the claim that the concept is unclear. The lack of detailed reasoning or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it highlights a potential area for improvement but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the concept of \"state\" and questions the equivalence of \"elements\" to \"states\" or \"actions.\" It suggests that more elaboration is needed to clarify this concept. While the comment highlights an area for improvement, it does not provide specific suggestions or examples on how to clarify the concept or what aspects need further explanation. The feedback is 3 as it points out a potential weakness but lacks detailed guidance, making it challenging for the authors to fully address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific observation regarding the behavior of a generator equipped with a standard RGCN as a discriminator, noting that it tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address this issue. While it implies that the authors should investigate and explain the reason behind the difference, it lacks detailed guidance on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not offer specific steps for implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the tendency of a generator equipped with a standard RGCN as a discriminator to collapse after several iterations, while the proposed module does not. The comment suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, it does not provide specific suggestions on how to address this issue or what aspects of the proposed module should be explored. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a generator equipped with a standard RGCN as a discriminator tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to further explore the issue to fully understand and address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific observation regarding the behavior of a generator equipped with a standard RGCN as a discriminator, noting that it tends to collapse after several iterations, while the proposed module does not. This observation is important as it highlights a potential difference between the proposed method and previous ones, which could be crucial to understanding the mechanism of the proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out an area for improvement, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any explicit or implicit suggestions on how the authors should clarify these comparisons or what specific aspects need to be addressed. There is no guidance on whether additional explanations or examples are needed, nor is there a recommendation for how to present the comparisons more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical comparisons to adaptive learning of GPRGNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the theoretical comparisons to adaptive learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical comparisons to adaptive learning of GPRGNN. It points out that the comparisons are not clear, which is a critical issue for understanding the paper\"s contributions and implications. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify these comparisons or what aspects need to be addressed. While it highlights an important area for improvement, the feedback is incomplete and does not fully support the authors in making the necessary changes. Therefore, the comment is 3, as it provides a direction for improvement but lacks actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the sufficiency of using only yes/no responses to measure object hallucination. It points out that a simple yes response does not necessarily indicate comprehension of the object in the image, as the model may still produce incorrect objects when performing other tasks. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative methods could be used. The action is implicit and somewhat vague, as the authors can infer that they need to consider alternative methods for measuring object hallucination, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this measurement is used. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the methodology but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of using only yes/no responses to measure object hallucination, suggesting that a simple yes response does not necessarily indicate comprehension of the object in the image. The reviewer provides a logical reasoning by explaining that the model may still produce incorrect objects when undertaking other tasks. However, the comment lacks specific examples or references to support the claim that a simple yes/no response is insufficient. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. It points out that the model may still produce incorrect objects when undertaking other tasks. This feedback is 3 as it identifies a potential limitation in the methodology and encourages the authors to consider alternative methods for measuring object hallucination. However, the comment could be more helpful if it provided specific suggestions or examples of alternative methods that could be used. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. It suggests that this is a key difference between the work and VideoChatGPT and other works. The reviewer implies that the authors should include experiments and explanation to address this gap. While the comment does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to conduct them, it clearly identifies an area for improvement and suggests a direction for the authors to take. Therefore, the comment is 3, as it provides a clear but implicit action for the authors to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experiments  Ablation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. The reviewer suggests that this is a key difference between the work and VideoChatGPT and other works. However, the comment lacks specific examples or references to support the claim that these queries are crucial or how they impact the results. Without detailed justification or evidence, the claim remains 3, as it provides a logical suggestion but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of experiments and explanation regarding the different queries used in spatiotemporal representation. It highlights the importance of these queries, as they are a key difference between the work and VideoChatGPT and other works. The comment suggests that the authors should include experiments and explanation to address this gap, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it points out a critical area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a specific reorganization of the sections, proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This provides a clear and concrete action for the authors to take, as it offers a specific way to restructure the sections to improve clarity and coherence. The comment is explicit in its suggestion and provides a concrete implementation, making it 5.", "grounding_specificity_rationale": "The comment suggests reorganizing sections 3 and 4 to improve clarity and coherence. It explicitly mentions \"Section 3 and Section 4,\" providing full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is specific because it suggests a specific reorganization, such as moving the first paragraph of Section 4 to Section 3 and placing the remainder before Section 3. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that sections 3 and 4 are redundant and proposes a specific reorganization to improve clarity and coherence. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the sections are redundant or how the proposed reorganization would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making changes. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential redundancy in sections 3 and 4, suggesting that reorganizing these sections could improve clarity and coherence. It provides a specific and actionable suggestion by proposing to move the first paragraph of section 4 to section 3 and placing the remainder before section 3. This feedback is clear and offers a concrete way for the authors to enhance the organization and flow of their paper, which could improve the overall readability and comprehensibility. However, the comment could be more helpful if it explained why the current organization is redundant or how the suggested reorganization would benefit the paper. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It suggests that the authors should provide more details to establish a connection between these concepts. However, the comment does not specify what kind of details are needed or how to present them, leaving the authors to infer the necessary actions. While the comment identifies an area for improvement, it lacks concrete guidance on how to address the issue, making it 3.", "grounding_specificity_rationale": "The comment addresses a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the connection between these concepts and the zeroshot learning effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It points out that this lack of clarity is due to poor clarity in the paper. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or establish a connection between these concepts. While it highlights an area for improvement, the feedback lacks depth and actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for a citation regarding the kmax problem, which is a clear and direct action for the authors to take. The comment provides a specific request for additional information, making it 5. The authors know exactly what needs to be done, which is to provide a citation or additional information on the kmax problem. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for a citation regarding the kmax problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the citation for the kmax problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for additional information, specifically a citation regarding the kmax problem. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual request for clarification and does not fit the criteria for a claim.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where additional information or clarification is needed. By asking for a citation regarding the kmax problem, the reviewer prompts the authors to provide more context or references to support their claims. This feedback is clear and actionable, as it directs the authors to include relevant information that could enhance the paper\"s comprehensiveness and credibility. However, the comment could be more helpful if it provided specific examples or guidance on how to address the kmax problem or why it is important. Overall, the comment is 3 as it points out a potential gap in the paper but lacks depth in its suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback implies that the authors should provide more detailed information about the estimation process and the model\"s reliability. However, the comment does not explicitly instruct the authors to include this information, nor does it provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to add more details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information on how the function for the optimal sequence length was estimated and how reliable the model is expected to be. This provides clear guidance on what the authors need to include in their paper to improve it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is no information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback is clear and actionable, as it points out a gap in the paper that the authors need to address to provide a more comprehensive understanding of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a discrepancy in the language used in Figure L006, specifically noting that \"thousands\" is not accurate. It suggests a possible correction by adding \"on the subword level.\" This feedback is clear and provides a direct action for the authors to take, which is to revise the language in the figure to be more accurate. The suggestion is concrete, as it specifies the exact change needed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the language used in the figure and suggests a possible correction by adding \"on the subword level.\" This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the phrase \"thousands\" is not accurate in Figure L006, as later written in the main text. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why \"thousands\" is inaccurate or how it could be improved. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific discrepancy in the language used in Figure L006, noting that the phrase \"thousands\" is not accurate. It suggests a possible correction by adding \"on the subword level.\" This feedback is clear and actionable, as it provides a direct suggestion for improving the accuracy of the figure. However, the comment could be more helpful if it explained why \"thousands\" is inaccurate or how the suggested correction would improve the figure. Despite this, the feedback is 4 as it guides the authors toward a specific improvement that could enhance the clarity and accuracy of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It notes that several hyperparameters, such as regularization, are not explicitly mentioned and asks for clarification on why the yvalue in the latent path figures is always 0 at x=0. The reviewer also expresses interest in further analysis of the model, specifically mentioning interpolations as a potential area for exploration. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestions are somewhat vague and lack detailed guidance, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig 3\" and \"regularization,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues by questioning the yvalue at x=0 in the latent path figures and expressing interest in further analysis of the model. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the absence of certain hyperparameters, such as regularization, and the yvalue at x=0 in the latent path figures. It also expresses interest in further analysis of the model. While the comment identifies areas for clarification and potential improvements, it lacks specific examples or references to support the claim that these issues are problematic or require attention. The lack of detailed justification or evidence makes it difficult for the authors to fully understand the basis of the critique or how to address it. Therefore, the comment is categorized as 2, as it provides some indication of an issue but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the absence of certain hyperparameters, such as regularization, and the yvalue at x=0 in the latent path figures. It also expresses interest in further analysis of the model, specifically mentioning interpolations as a potential area for exploration. While the comment highlights important issues, it lacks specific guidance or suggestions on how to address these concerns or improve the paper. The authors are given direction but not detailed steps on how to implement the suggested improvements, making the feedback 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It specifically points out that the exact contributions need to be written more clearly in the Introduction and that the material supporting the main contributions is in the appendix rather than the main sections. While the comment provides a clear indication of what needs to be addressed, it does not offer specific guidance on how to improve the clarity of the contributions or suggest ways to integrate the material into the main sections. The action is explicit but somewhat vague in terms of execution, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"deeprag algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of forward referencing, where material is introduced without proper explanation and is later explained in later sections. The comment further details the need for clearer contributions in the Introduction and the placement of supporting material in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. The reviewer provides specific examples, such as Figure 1 and the deeprag algorithm, which are mentioned as being in the appendix rather than the main sections. This provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to similar issues in other papers, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It provides specific examples, such as Figure 1 and the deeprag algorithm, which are mentioned as being in the appendix rather than the main sections. This feedback is clear and actionable, as it directs the authors to clarify the contributions in the Introduction and ensure that supporting material is integrated into the main sections. By addressing these points, the authors can significantly improve the clarity and coherence of their paper. However, the comment could be more helpful if it provided suggestions on how to effectively integrate the material into the main sections or offered additional guidance on how to improve the clarity of the contributions. Overall, the comment is 4 as it provides clear and actionable feedback, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. While the comment implies that the authors should add results on the generative setting, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"visual dialog,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on the generative setting in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. The reviewer suggests that the authors should include results on the generative setting as well. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. This feedback is clear and actionable, as it directs the authors to address a gap in their experimental evaluation. However, the comment could be more helpful if it provided additional context or examples on how to conduct the analysis on the generative setting. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to explore the effectiveness of the approach for other language families. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the effectiveness of the proposed approach for other language families, which is a clear and specific concern. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of exploration for other language families, but without explicit references to sections or details, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the effectiveness of the proposed approach for other language families. It highlights a gap in the paper that needs to be addressed, which is the lack of exploration or evaluation of the approach for other language families. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of the approach should be tested or explored. While it points out a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. While it implies that the authors should expand on these differences, it does not explicitly instruct them to do so or provide specific guidance on how to approach this enhancement. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed descriptions of the differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not specify which parts of the related work section are lacking in detail or which works are not described adequately. Without explicit references to specific sections or works, the authors cannot confidently determine which parts need attention. The comment is 1 as it does not specify where in the paper the related work section is located, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not provide specific examples or references to the works that are lacking in detail or clarity. Without these details, the claim is not fully substantiated, making it difficult for the authors to understand the exact areas that need improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the related work section, specifically noting that some related works are named but not described in sufficient detail. This feedback is 3 as it points out a specific area where the authors could enhance their work, providing a clear direction for improvement. However, the comment lacks specific examples or guidance on how to improve the descriptions of the differences between the works. To be more helpful, the comment could provide suggestions on what aspects of the related works should be emphasized or how the differences could be better explained. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain what type of understanding is gained by looking at the PPP maps. This is a clear and direct request for clarification, providing the authors with a specific action to take. The comment is concrete because it specifies the exact information that needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors state the importance of reliable PPP metrics for understanding PPP effects in different tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for an explanation of what type of understanding is gained by looking at the PPP maps, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the authors\" explanation regarding the understanding gained from looking at PPP maps. It suggests that while the importance of reliable PPP metrics is mentioned, the article lacks explicit explanation or understanding of this concept. The comment is 3 as it logically points out a gap in the explanation but does not provide specific examples or references to support the claim. The authors may need to clarify the understanding gained from the PPP maps, but the comment lacks detailed guidance on how to do so. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the understanding gained from looking at PPP maps. It points out that while the authors mention the importance of reliable PPP metrics, they do not explicitly explain what type of understanding is gained from these maps. This feedback is valuable as it prompts the authors to clarify their explanation, which could enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to address this gap or what aspects of the PPP maps should be emphasized. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This implies that the authors should include such comparisons to enhance the credibility of their work. The action is clear and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with other stateoftheart methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT, which affects the credibility of their work. However, the comment does not provide specific examples or references to these stateoftheart methods or explain how the absence of such comparisons impacts the credibility of the work. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of the comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided sufficient evidence for the credibility of their work. It points out the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT, which is a relevant benchmark for evaluating the effectiveness of the proposed methods. This feedback is clear and actionable, as it directs the authors to include such comparisons to enhance the credibility of their work. However, the comment could be more helpful if it provided examples of how these comparisons could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), which lacks a schematic representation. It suggests that the figure should be redrawn to better connect the text and equations with the visual representation. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b)\" and \"the forwardprediction model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a schematic representation in Figure 2(b) and the difficulty in connecting the text with the figure and equations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), which lacks a schematic representation. The reviewer suggests that the figure should be redrawn to better connect the text and equations with the visual representation. This claim is 3 as it provides a specific example of the issue (Figure 2(b)) and suggests a potential solution (redrawing the figure). However, the comment lacks detailed reasoning or references to support why the current representation is insufficient or how it could be improved. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of a clear and detailed explanation of the forwardprediction model, particularly in Figure 2(b). It points out that the figure does not provide a schematic representation of the model, making it difficult for readers to connect the text and equations with the visual representation. The comment suggests that the figure should be redrawn to address this issue. While the feedback is clear and actionable, it could be more helpful if it provided additional guidance on how to improve the explanation or suggested specific improvements to the figure. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The reviewer also questions the authors\" choice of baseline and suggests they should provide a stronger baseline to prove the usefulness of FP. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger baseline and consider the impact of rewardless actions on RBI. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the training process for RBI, specifically noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The comment also questions the authors\" choice of baseline and suggests they should provide a stronger baseline to prove the usefulness of FP. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where RBI and FP + RBI are discussed. The comment is specific in its critique of the training process and the need for a stronger baseline, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The comment suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the significance of the issue and the potential impact on the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. This is a significant observation that could impact the performance and effectiveness of the method. The comment suggests that this could be a factor contributing to the superiority of FP + RBI over RBI alone. Additionally, it questions the authors\" choice of baseline and recommends providing a stronger baseline to prove the usefulness of FP. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is 3, as it provides valuable insights but could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestion to discuss the similarity and difference with reinforcement learning is a vague direction, and the comment lacks specific guidance on how to address these issues. The authors are left with a general idea of what needs to be improved but without clear steps on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses several issues, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment does provide specific suggestions, such as discussing the similarity and difference with reinforcement learning and the generalizability of results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not stateoftheart, and that there is no discussion of limitations. It suggests that the paper could benefit from a discussion of the similarity and difference with reinforcement learning, implying that the results may not be generalizable to RL settings. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The suggestion for improvement is 3, as it provides a direction for the authors to consider, but the lack of detailed evidence or reasoning makes it challenging for the authors to fully address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. It suggests that the paper could benefit from a discussion of the similarity and difference with reinforcement learning, implying that the results may not be generalizable to RL settings. While the comment provides some insight into potential areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general idea of what needs to be improved but without detailed instructions or examples on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the distinction between the expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. While the comment implies that the authors should make this distinction clearer upfront, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction, but it is concrete in that it provides a clear direction for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. The comment provides a clear direction for improvement by suggesting that the distinction should be made clearer upfront. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the expected performance under observation noise is typically used for evaluation because the decisionmaker is interested in the true objective function and the noise is assumed to be noise (misleading, not representative). The reviewer suggests that in the current paper, the decisionmaker does care about the noise, and the objective function of interest is the stochastic noisy function. The comment provides a logical reasoning for the distinction between the two scenarios, but it lacks specific examples or references to support the claim that the current paper\"s approach is misleading. Therefore, the claim is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s approach to evaluation, noting that the expected performance under observation noise is typically used because the decisionmaker is interested in the true objective function and the noise is assumed to be noise. However, in the current paper, the decisionmaker is interested in the stochastic noisy function, which is a different objective. The comment suggests that the distinction between these two should be clarified upfront to avoid misleading assumptions. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to clarify this distinction or provided examples of how other papers have addressed similar issues. Overall, the comment is 4 as it directs the authors to a critical area for clarification, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the good performance of the method, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to enhance the novelty or contribution of their work. The action is implicit and vague, as the authors are left to infer that they need to improve the novelty or contribution of their work, but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method, specifically mentioning Table 2, and acknowledges the novelty and contribution of the work. However, it does not specify which part of the paper discusses the novelty or contribution, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also suggests that the main contribution is a new network design inspired by prior work, but it does not provide specific details on how this contribution is incremental or what aspects need improvement. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be improved. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that the method\"s performance is good, especially in Table 2, but questions the novelty and contribution of the method. The comment suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment lacks specific examples or references to support the claim that the method is incremental or lacks novelty. Without detailed evidence or comparisons to similar methods, the claim is difficult for the authors to verify. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the good performance of the method, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. While the comment identifies a potential issue with the novelty and contribution of the work, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their contribution. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether there is a demonstration or result related to the model collapsing less than other methods. It also asks about the specific observation of gradients becoming 0 and collapsing, mentioning line 159. While the comment implies that the authors should provide evidence or examples to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or examples to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a demonstration or result related to the model collapsing less than other methods, and it raises questions about the common occurrence of gradients becoming 0 and collapsing. This provides clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the demonstration or results related to the model collapsing less than other methods. It specifically mentions line 159, where the authors mention gradients becoming 0 and collapsing. This feedback is 3 as it prompts the authors to provide evidence or examples to support their claim, which could strengthen the paper. However, the comment lacks specific guidance on how to present this evidence or what aspects of the model\"s performance should be highlighted. While it identifies an area for improvement, it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify the formulation or what aspects are unclear. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper these issues are related to. Without explicit references to sections or examples, the authors cannot confidently determine where to focus their revisions. The comment is specific in identifying the issue of unclear problem formulation, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim. Without specific references or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide guidance on how to improve the clarity or what aspects of the formulation are unclear. Without actionable suggestions or examples, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests conducting experiments with different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This provides a clear and concrete action for the authors to take, as it specifies the exact models to include in the experiments and the purpose of doing so. The comment is specific and directs the authors on how to enhance their draft by including these additional experiments. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, specifically mentioning OPT, BLOOM, or other alternatives. This provides a clear direction for the authors to expand their experimental scope. However, the comment does not specify which part of the paper should include these experiments, such as the results or methodology sections. While the authors can infer that it relates to the experimental section, the comment lacks full grounding as it does not explicitly mention the section. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is 3 as it provides a logical reasoning for expanding the experimental scope to include a broader range of LLM families. However, the comment lacks specific examples or references to support the claim that these additional experiments would provide valuable insights into the method\"s applicability and generalizability. While the suggestion is reasonable, the lack of detailed justification or evidence makes it 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directs the authors to expand their experimental scope and includes specific models to consider. By addressing this suggestion, the authors can enhance the comprehensiveness and robustness of their study. However, the comment could be more helpful if it provided additional guidance on how to interpret or analyze the results of these experiments. Overall, the comment is 4 as it effectively points out a critical area for improvement and offers concrete suggestions for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the method seems to only work for generative models that can be finetuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes, if any, are needed to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the method are limited to finetuning or how this limitation could be addressed. Without clear guidance on where to focus improvements, the authors may struggle to effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method only works for generative models that can be finetuned as an in/outpainting model. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the method, suggesting that it only works for generative models that can be finetuned as an in/outpainting model. This feedback is 3 as it identifies a specific area where the method may be limited, which could impact its applicability or generalizability. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or expand the method\"s applicability. While it highlights an important issue, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a perceived weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not align with the title or the author\"s imagined process. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the connections. The comment lacks actionable details, such as recommending specific modifications or suggesting alternative approaches. As a result, the authors are left without clear direction on how to improve their draft in this area. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first part and the second part of the paper, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the perceived weakness in the connections between the curve finding and FGE, and it provides a rationale for this observation. However, the comment lacks specificity regarding what needs to be addressed or improved in these connections. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the connections between the curve finding and FGE are weak, suggesting a discrepancy between the title and the actual process described in the first part. The reviewer provides a rationale by explaining their understanding of the process, which is based on their interpretation of the title and the first part. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the comment does not provide clear guidance on how to improve the draft. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not align with the title or the author\"s imagined process. It highlights a discrepancy between the title and the actual content, which could be a significant issue for the authors to address. However, the comment lacks specific suggestions or guidance on how to improve the connections or what changes could be made to better align the content with the title. While it points out a potential problem, it does not provide actionable feedback that would help the authors address it effectively. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and specificity."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include results for linear scalarization + Concorde, which is a heuristicbased solver, in their experimental analysis. This is an explicit action that the authors can directly implement to improve their draft. The comment provides a clear rationale for why this inclusion is necessary, as it highlights the competitive nature of learningbased solvers compared to heuristicbased solvers and the fact that the SOTA heuristicsolver usually has the best performance for single objective TSP. However, the comment could be more concrete by specifying which section of the paper should include these results, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and \"Pareto front\" from Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of results for linear scalarization + Concorde, a heuristicbased solver, for a better comparison. This provides clear guidance on how to improve the paper by including additional results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers, but it also acknowledges that for single objective TSP, the SOTA heuristicsolver (e.g., Concorde) usually has the best performance. The comment suggests that the authors should include results for linear scalarization + Concorde to provide a better comparison. This claim is 3 as it is based on the experimental results, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to include additional results is logical, but the comment could be strengthened with more detailed evidence or references to support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It highlights the competitive nature of learningbased solvers compared to heuristicbased solvers, particularly for single objective TSP, where the SOTA heuristicsolver (e.g., Concorde) usually has the best performance. The comment suggests that the authors should include results for linear scalarization + Concorde to provide a better comparison. This feedback is valuable as it directs the authors to include additional results that could enhance the comprehensiveness and relevance of their analysis. However, the comment could be more helpful if it explained why linear scalarization + Concorde is particularly relevant or how it might impact the overall conclusion. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving some experimental details and tasks back into the main text and moving background information from Section 2 to the appendix. While the comment provides a clear action\u2014moving specific details and information\u2014it does not specify which details or information should be moved or how to structure them in the main text. The authors are left to infer which details are relevant and how to integrate them effectively. The action is explicit but lacks concrete guidance on execution, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, tasks, and other details being moved to the appendix, making it difficult to interpret the paper. It suggests moving some of these details back into the main text and moving background information from Section 2 to the appendix. However, the comment does not specify which details or information should be moved or where in the main text they should be placed. This lack of specificity makes it difficult for the authors to effectively address the feedback. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the experimental setup, tasks, and other details are moved to the appendix, making it difficult to interpret the paper. The reviewer proposes moving some of these details back into the main text and suggests moving background information from Section 2 to the appendix. However, the comment lacks specific examples or detailed reasoning to support why these changes would improve the clarity or interpretability of the paper. Without specific examples or references, the claim is 3, as it provides a general suggestion but lacks the necessary detail to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization and presentation of the experimental setup, tasks, and other details, which are currently relegated to the appendix. This makes it difficult for readers to interpret the paper effectively. The comment suggests a solution by proposing moving some of these details back into the main text and moving background information from Section 2 to the appendix. This feedback is clear and actionable, providing the authors with a concrete way to improve the clarity and accessibility of their paper. However, it could be more helpful if it included specific examples of which details should be moved or how to structure them in the main text. Overall, the comment is 4 as it effectively guides the authors on how to enhance the clarity and readability of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that providing glosses in Figure 2 would be helpful. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the figure. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests providing glosses in Figure 2, which implies that it is referring to a specific figure in the paper. However, it does not explicitly mention the figure, making it weakly grounded. The comment is specific in suggesting what needs to be added, which is the provision of glosses. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests providing glosses in Figure 2, which is a request for clarification or additional information. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"", "helpfulness_rationale": "The comment suggests providing glosses in Figure 2, which is a specific and actionable piece of feedback. By suggesting this addition, the reviewer helps the authors improve the clarity and accessibility of their figures, making it easier for readers to understand the content. However, the comment could be more helpful if it provided additional context or examples of what kind of glosses would be beneficial. Overall, the comment is 4 as it directs the authors to a specific improvement that can enhance the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"Memb\" is mentioned as the previous stateoftheart but no reference is provided. This implies that the authors should include a reference to the work or clarify the context in which \"Memb\" is mentioned. However, the comment does not explicitly instruct the authors to add a reference or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a reference, but it is not explicitly stated. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Memb,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of a reference to the stateoftheart \"Memb,\" which is a clear issue that needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Memb\" is mentioned as the previous stateoftheart but no reference is provided. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the term \"Memb\" is mentioned as the previous stateoftheart but no reference is provided. This is a clear and actionable point, as it highlights a potential gap in the paper that could affect its credibility and comprehensiveness. By pointing out this oversight, the comment provides the authors with a specific area to address in their draft, ensuring that they include relevant references to support their claims. However, the comment could be more helpful if it suggested specific references or provided guidance on how to incorporate them effectively. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. However, it does not provide any explicit or implicit suggestions for how the authors might address this question or what specific changes they should consider. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of grouping for quantization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of pertensor and perchannel grouping and suggests considering finer grouping instead. This provides clear guidance on what aspect of the quantization method is being questioned and what alternative might be considered. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. However, it does not provide any supporting evidence, reasoning, or references to justify why finer grouping might be preferable. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. This is a valid point that could lead to a more efficient or accurate quantization process. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific advantages finer grouping might offer. While it identifies a potential area for improvement, the feedback is incomplete and does not fully support the authors in making changes to their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It explicitly recommends conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback provides a clear and concrete action for the authors to take, as it specifies the exact aspect to investigate and offers a specific direction for further analysis. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this analysis could be conducted. The authors can infer that it relates to the model evaluation or results section, but this inference is not direct. The comment is specific in suggesting a particular aspect to investigate, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the study. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests studying the impact of the ratio of unseen classes on the performance of the model. It provides a specific direction for further analysis by recommending conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback is actionable and constructive, as it offers a clear and concrete suggestion for the authors to enhance their study. However, the comment could be more helpful if it provided additional context or examples of how this analysis could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. While the comment implies that the authors should provide an explanation or rationale for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address this question but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these architectures are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the choice of architectures and their impact on the results, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of using GRU for the Pyramid and LSTM for the sequential part, questioning whether the combination of these architectures is a reason for the improvements. This is a valuable point as it prompts the authors to consider the rationale behind their choice of models and whether it is a significant factor in their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered insights into potential alternatives or improvements. While it identifies a critical area for consideration, it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in a specific line of the paper. While it identifies a potential issue with the clarity of the definition, it does not provide any guidance on how the authors should address this concern. The comment lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \"active vertices\" and seeks clarification on how this term is used in the context of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the definition of \"active vertices\" in a specific line of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"active vertices\" in a specific line of the paper, which is a clear and specific point of confusion. By asking for clarification on the term\"s definition, the reviewer prompts the authors to provide more detailed explanations or definitions to improve the clarity of their work. This feedback is actionable and can help the authors enhance the readability and comprehensibility of their draft. However, the comment could be more helpful if it suggested alternative terms or explanations that might be clearer to readers. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to address it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy between the paper\"s claims and the limitations it discusses. It points out that the theory is not mentioned as a limitation in the main text, despite being applicable to the model. The reviewer suggests that the authors should address this issue by explicitly mentioning the theoretical limitation in the main text. Additionally, the reviewer suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general, which could be a valuable addition to the paper. While the comment provides clear and explicit actions for the authors to take, it does not specify how to elaborate on the potential negative impact. Therefore, the comment is 4, as it provides concrete guidance on what needs to be addressed but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"vagueness of unspecified \"structural assumptions\"\" in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the theoretical limitation is not mentioned in the main text and suggesting that the authors should address it. Additionally, it provides a specific suggestion to elaborate on the potential negative societal impact of graph neural networks in general. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not mention the theoretical limitation of its theory being applicable to the used model, despite the vagueness of unspecified \"structural assumptions\" in the appendix. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and should elaborate on the potential negative societal impact of these networks. The comment provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion about the current use of graph neural networks in industry. Additionally, the suggestion to elaborate on the potential negative impact is somewhat vague, as it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks sufficient evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the theoretical limitation of the theory being applicable to the used model is not mentioned in the main text. It points out that the vagueness of unspecified \"structural assumptions\" in the appendix makes it difficult for readers to find this limitation. The reviewer suggests that the authors should address this issue by explicitly mentioning the theoretical limitation in the main text. Additionally, the comment provides a valuable suggestion to elaborate on the potential negative societal impact of graph neural networks in general, which could be a valuable addition to the paper. While the comment identifies important areas for improvement, it could be more helpful if it provided specific examples or guidance on how to elaborate on the societal impact. Overall, the comment is 4 as it highlights critical gaps in the paper and offers actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"epsilongreedy\" in the context of training, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the meaning of \"epsilongreedy\" in the context of training. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. This question highlights a potential area of confusion or misunderstanding in the paper, which could be clarified to improve the reader\"s comprehension. However, the comment does not provide specific guidance or suggestions on how to address this issue, leaving the authors with a clear need for clarification but without detailed direction on how to implement it. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the method or what specific aspects need attention. The authors are left without any direction on how to address the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the method is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in detailing the combination of GCN and normalizing flow, but without grounding, it lacks actionable guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian mixture distribution replacing the Gaussian distribution in conventional normalizing flows. However, it does not provide any specific insights or suggestions for improvement. The comment lacks actionable feedback or detailed analysis, leaving the authors without a clear understanding of how to address the critique or enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to ensure that both heads are affected. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the affected layers, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). This is a clear observation that could be relevant for the authors to address, as it highlights a potential imbalance in the paper\"s focus. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific changes could be made to ensure a more balanced presentation. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the weakness of the analogy between HOI analysis and Harmonic analysis, noting that there is only a limited basis for forming an HOI. It also questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. While the comment identifies areas of concern, it does not provide explicit guidance on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the basis for HOI and the connection to Fourier analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the analogy between HOI analysis and Harmonic analysis, noting that the link is weak. It also questions the connection between the decomposition/integration steps and Fourier analysis. However, it does not specify which part of the paper discusses these analyses, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its critique of the analogy and the connection to Fourier analysis, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, and questions the connection between the decomposition/integration steps and Fourier analysis. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or detailed explanations to substantiate the critique, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is considered 2, as it requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a weakness in the analogy between HOI analysis and Harmonic analysis, noting that the link is limited. It also questions the connection between the decomposition/integration steps and Fourier analysis, which is a significant concern. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their analysis. While it points out areas for improvement, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. However, it also acknowledges that most existing ML accelerators use bitparallel fixedpoint numbers, which could restrict the implications of the proposed methodology. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or explore its implications further. The action is implicit and somewhat vague, as the authors can infer that they might need to consider the impact of this limitation on the applicability of their methodology. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the potential limitation of the proposed methodology, specifically regarding the performance gains of dynamic precision control during training on bitserial accelerators. It also mentions the use of bitparallel fixedpoint numbers by most existing ML accelerators, which could restrict the implications of the proposed methodology. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the applicability of the methodology to existing accelerators. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which is a specific observation about the applicability of the proposed methodology. However, the comment lacks supporting evidence or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered 2, as it provides a logical reasoning but lacks sufficient evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. This is a relevant observation that could impact the applicability of the methodology to most existing ML accelerators, which typically use bitparallel fixedpoint numbers. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore its implications further. While it highlights an important consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the focus distance shown in Figure 8, noting that it only includes 1m and 5m, which are both present in the training data. The reviewer asks whether the focus distance extends beyond these examples and whether it generalizes well. While the comment implies that the authors should consider including additional focus distances, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the focus distance range. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the focus distance shown in the figure, suggesting that it should include other distances beyond those present in the training data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the focus distance shown in Figure 8, noting that it only includes 1m and 5m, both of which are present in the training data. The reviewer asks whether the focus distance extends beyond these examples and whether it generalizes well. This claim is 3 as it raises a valid question about the scope and applicability of the results. However, it lacks specific examples or references to support the claim that other focus distances should be considered. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 8, noting that it only shows focus distances of 1m and 5m, both of which are present in the training data. It raises a valid question about whether the focus distance extends beyond these examples and whether it generalizes well. This feedback is 3 as it prompts the authors to consider the broader applicability of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional focus distances or discussing the implications of this limitation. Overall, the comment is 3 as it points out a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a main weakness of the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed Xtransformation seems similar to STN, and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to include comparisons to STN and provide more detailed explanations of the novelty of their approach. However, the comment lacks concrete suggestions on how to conduct these comparisons or what specific aspects to focus on. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses a specific issue with the paper, namely the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It mentions the proposed Xtransformation and its similarity to STN, as well as the use of STN in PointNet. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these topics are discussed. The comment is specific in detailing what needs to be addressed, such as the need for comparisons to STN and the need for more detailed explanations of the novelty of the proposed approach. Therefore, this comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the technical novelty of the work is limited due to its similarity to spatial transformer networks (STN) and the absence of comparisons to STN. The reviewer supports this claim by pointing out that the proposed Xtransformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, the reviewer notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment provides some logical reasoning and references to existing works, it lacks specific examples or detailed comparisons to fully substantiate the claim. This makes the comment 3, as it provides a basis for the claim but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed Xtransformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper, which is important for demonstrating the novelty of the work. The comment provides clear and actionable feedback by highlighting areas where the authors need to improve their work, such as including comparisons to STN and providing more detailed explanations of the novelty of their approach. This feedback is valuable for the authors to enhance the originality and impact of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It explicitly instructs them to correct the labeling of \"Fig.7\" to \"Fig.12\" in Supp. Page 31 and to attach each theorem and corollary to its corresponding proof link. Additionally, it highlights the primary concerns of motivation, methodology soundness, and experiment persuasion, which the authors should address to improve the paper. The comment is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected (the labeling of \"Fig.7\" to \"Fig.12\") and suggests attaching each theorem and corollary to its corresponding proof link. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes several claims about the paper, including the need to correct the labeling of \"Fig.7\" to \"Fig.12\" and the importance of attaching each theorem and corollary to its corresponding proof link. These claims are 3 as they are based on logical reasoning and common practices in academic writing. However, the comment lacks specific examples or references to support the need for these corrections or the importance of the suggested improvements. While the claims are not entirely 1, they could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It points out a specific error in the labeling of a figure and suggests attaching each theorem and corollary to its corresponding proof link. This feedback is clear and concrete, offering the authors a direct path to enhance the clarity and accessibility of their work. Additionally, the comment acknowledges the paper\"s strengths, such as its novelty, clear theoretical guarantees, and convincing empirical results. This recognition is helpful as it validates the paper\"s contributions and provides a positive context for the authors to consider. Overall, the comment is 4 as it offers actionable guidance and recognition, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the definition and implementation of certain concepts in the paper. It specifically asks about the determiner missing in Section 3, the action verbs used, and the \"action frames\" mentioned later in the paper. While the questions are clear and specific, they do not provide explicit guidance on how the authors should address these issues. The authors can infer that they need to clarify the missing determiner, explain the action verbs, and provide more information on the \"action frames,\" but the comment lacks concrete details on how to implement these changes. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to execute them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"306ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by asking about the determiner missing in Section 3, the action verbs used, and the \"action frames\" mentioned later in the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the definition and implementation of certain concepts in the paper, specifically the missing determiner in Section 3, the action verbs used, and the \"action frames\" mentioned later in the paper. These questions are clear and specific, prompting the authors to clarify and provide more detailed explanations in their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what the authors might consider in their explanations. Overall, the comment is 4 as it identifies areas for improvement and prompts the authors to provide more detailed explanations, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the design of rewards as an example. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific steps to clarify the reward design or suggesting ways to improve the explanation. As a result, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the design of rewards, which is a clear and specific point. However, it does not explicitly mention which part of the paper discusses the rewards, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of understanding of how the rewards are designed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically mentioning the design of rewards as an example. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some details are missing, particularly regarding the design of rewards. This is a clear and actionable point that the authors can address to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to design the rewards or examples of how this might be done. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the generalizability of a model to different numbers of entities, referencing Figure 3 of INs as an example. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider generalizing their model to different entity counts, but it lacks concrete steps or detailed advice on how to achieve this. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a concern about the generalizability of a model to different numbers of entities, referencing Figure 3 of INs as an example. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the model\"s generalizability, as it highlights the issue of fixed entity numbers and references a specific figure. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the number of entities is fixed and that it is unclear how to generalize a model to different numbers of entities, referencing Figure 3 of INs as an example. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the generalizability of the model to different numbers of entities. It references Figure 3 of INs as an example of how this issue is addressed in another work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the generalizability of their model. While it points out a relevant example, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required. It also mentions that the experimental design is good. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest improvements, nor does it offer guidance on how to address the weakness of the execution effort being more significant than the novelty. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"double edge point,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, but with little novelty. The comment further highlights the importance of the experimental design and the potential lack of code release after the revision process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. However, it also points out that the execution effort is more significant than the novelty, which is a subjective observation. The comment suggests that the lack of code release after the revision process could be a weakness, but it does not provide specific examples or detailed reasoning to support this claim. While the comment highlights a potential issue, it lacks the necessary evidence or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. It also points out that the execution effort is more significant than the novelty, which is a subjective observation. However, the comment suggests that the lack of code release after the revision process could be a weakness, which is a valid point. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this weakness or improve the paper. The feedback is 3 as it highlights a potential area for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count and computational cheapness. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and guidance on how to address it. The comment is concrete, as it specifies the need for runtime discussion and highlights a potential limitation for the application of Prithvi WxC. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Prithvi WxC\" emulator, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the runtime of Prithvi WxC and its potential limitations for applications due to its large parameter count. This provides clear guidance on what aspect of the emulator needs attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed due to its large parameter count and computational cheapness. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this runtime discussion is necessary or how it would impact the application of Prithvi WxC. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the runtime of Prithvi WxC should be discussed, given its large parameter count and computational cheapness. This is a clear and actionable suggestion that could help the authors address a potential limitation of their emulator in the context of climate model parametrizations. However, the comment could be more helpful if it provided additional context or examples of how this runtime discussion might impact the application of Prithvi WxC. Despite this, the feedback is 4 as it directs the authors to a critical aspect of their work that could be improved."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions for the authors to follow, leaving them without a clear understanding of what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue is related to, such as specific sections, figures, or claims. Without explicit references to these elements, the authors cannot confidently determine where to address the issue. Additionally, the comment lacks specificity regarding what aspects of the framing contribute to the overselling and how it affects the clarity of the contribution. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specific references or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the framing of the paper, suggesting that it oversells the method and makes the contribution less clear. However, it does not provide specific examples or guidance on how the authors might address this issue or what aspects of the framing are problematic. Without actionable feedback or detailed suggestions, the authors are left without a clear understanding of how to improve the clarity of their contribution. Therefore, the comment is 2, as it identifies a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. While the comment provides a clear direction for improvement, it does not specify which steps should be taken or how to implement the changes. The authors are given a general idea of what needs to be improved but are left to determine the exact details of execution. Therefore, the comment is 3, as it provides a clear direction but lacks concrete guidance on how to implement the suggested improvements.", "grounding_specificity_rationale": "The comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the model description is discussed. The authors can infer that it relates to the model description section, but this inference is not as direct as it could be. The comment is specific in suggesting improvements, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the understanding of the model. The suggestion is based on general logic but lacks the necessary evidence or examples to fully substantiate the claim. Therefore, the comment is considered 2, as it provides a logical basis but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be presented in separate steps for better understanding. It also recommends reducing the number of symbols and using a notation table, which could enhance the clarity of the model description. While the comment provides actionable suggestions, it lacks depth and does not explain why these changes would be beneficial or how they would impact the overall understanding of the model. The authors are given a clear direction for improvement but could benefit from more detailed guidance on how to implement these changes effectively. Therefore, the comment is 3, as it provides a starting point for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not provide any specific guidance on how to improve the writing or what aspects need attention. The comment lacks concrete suggestions or examples of what changes could be made to enhance the clarity or coherence of the paper. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not specify which parts of the paper are particularly challenging to understand or where the writing could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing could be improved, suggesting that it took effort to understand the main idea and theoretical analysis of the paper. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it lacks specificity and does not provide any actionable feedback or suggestions on how to improve the writing. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the writing need attention or how to enhance clarity and coherence. Therefore, the comment is not helpful, as it does not provide the authors with meaningful insights or direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the sentence in lines 1217 is cumbersome and could be made clearer. However, it does not provide any guidance on how to achieve this clarity or what specific changes should be made to the sentence. The action is implicit and vague, as the authors are left to infer that they need to revise the sentence but without detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence in lines 1217, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the sentence is cumbersome and could be made clearer. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 is cumbersome and could be made clearer. However, it does not provide any specific reasoning or examples to support this claim. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the abstract, specifically the sentence in lines 1217. It points out that the sentence is cumbersome and could be made clearer, providing a clear direction for improvement. However, the comment lacks depth and does not offer specific suggestions or examples on how to improve the clarity of the sentence. While it highlights an area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides a starting point for the authors but could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative comparisons that might be more fair. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their comparisons, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the domainspecific model being trained on Pix3D and the experiments being conducted on Pix3D, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the comparisons to zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparisons between the domainspecific model and zeroshot singleimage 3D reconstruction models are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these comparisons are unfair. Without additional context or explanation, the claim remains 1, as it lacks the necessary information to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This feedback highlights a potential bias in the experimental setup that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the bias in their comparisons. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a limitation in the evaluation, specifically the reliance on only four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for additional datasets, but it is somewhat vague in terms of how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" and \"4 OCR QA datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the limited evaluation and the need for more scenarios like the LLaVA benchmark in ablation studies. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited and relies on only four OCR QA datasets, which may be unreliable. The reviewer supports this claim by referencing Fig 4(5), where the authors admit this limitation. However, the comment could be strengthened by providing specific examples of how the LLaVA benchmark could be incorporated into the evaluation or explaining why it is considered more reliable. While the reference to Fig 4(5) provides some support, the comment could be more 5 with additional details or examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section, specifically the reliance on only four OCR QA datasets. It suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their evaluation to include additional datasets. By addressing this suggestion, the authors can enhance the robustness and comprehensiveness of their evaluation. However, the comment could be more helpful if it explained why the LLaVA benchmark is considered important or how it might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the tasks. It lacks actionable details, such as recommending specific changes or methods to simplify the tasks. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its critique of the tasks and the need for proof that more complex tasks are necessary. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. The reviewer expresses difficulty in solving these tasks and questions the interpretation of the models\" learning. However, the comment lacks specific examples or references to support the claim that these tasks are overly complex or confusing. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification to be 5.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the interpretation of the models\" learning and whether simpler tasks would suffice. The comment also asks for proof that more complex tasks are necessary. While the feedback identifies potential issues with the tasks, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the tasks. The comment highlights areas for consideration but does not provide actionable steps for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the evaluation of weak supervision could be improved by addressing the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors\" generation, suggesting that the authors\" embeddings are initialized by averaging artificial tweets. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should improve the realism of the evaluation and generation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"weak supervision\" and the \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the generation process, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the realism of the evaluated tweets and the generation process, suggesting that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. The reviewer also points out that the authors\" embeddings are initialized by averaging artificial tweets, which further undermines the realism. These claims are based on logical reasoning and observations about the nature of the prompt and the generation process. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the unrealistic nature of the evaluation or generation. As it stands, the claims are 3, as they provide a logical basis but lack detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation process. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors\" generation, suggesting that the authors\" embeddings are initialized by averaging artificial tweets. This feedback is 3 as it highlights areas where the evaluation could be improved, but it lacks specific suggestions or guidance on how to address these issues. The authors are given a direction to consider, but the comment could be more actionable with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action, providing the authors with a specific task to accomplish. The comment is specific in detailing where the results should be included, making it 5. Authors know exactly what needs to be done to address the feedback, ensuring they can effectively implement the suggested changes. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included, namely \"keypoint detection results.\" This provides clear guidance on what the authors need to address in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by suggesting that keypoint detection results should be included in the experiments section. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s content and clarity. However, the comment could be more helpful if it explained why this inclusion is important or how it would enhance the understanding of the results. Overall, the comment offers a clear direction for improvement but lacks depth and explanation, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. It also mentions minor problems, but does not provide further details or suggestions for improvement. The comment implies that the authors should clarify this aspect of their methodology, but it lacks explicit guidance on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the grid search process but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grid search of learning rate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking whether the grid search is performed on the validation set, providing clear guidance on what needs to be clarified. However, the comment lacks specificity regarding the minor problems mentioned, such as what these problems are or how they impact the paper. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking about the grid search for learning rate, specifically whether it is performed on the validation set. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. This is a relevant point that could impact the robustness and generalizability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for clarification, it does not offer actionable advice or detailed feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or that the term \"discourse\" is being used inappropriately. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify or adjust their terminology. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" This is a relevant point that could prompt the authors to reconsider their terminology and potentially clarify their findings. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. While it points out a potential area for clarification, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they need to consider diversity but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the diversity of the sample in terms of racial and economic backgrounds, and it asks how well the results might generalize to other groups, including marginalized ones. This is a relevant and insightful point that could prompt the authors to consider the broader implications of their findings and ensure that their work is inclusive and applicable to diverse populations. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional analyses or discussions. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality. However, the comment does not provide specific guidance on how to achieve this improvement or what aspects of the output need to be addressed. The authors are left to infer that they need to improve the quality, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, comparing it to recent GAN works and suggesting that there is still room for improvement. However, it does not specify which part of the paper discusses the output quality, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the output quality and the need for improvement, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. The reviewer suggests that there is still room for improvement in result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment lacks specific examples or references to recent GAN works that demonstrate the improvement in quality, making it 3. The authors would need to infer the specific examples or references themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the output quality of the paper, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment does not provide specific suggestions or guidance on how the authors might improve the output quality or what aspects of the paper need attention. While it highlights an area for improvement, the lack of actionable feedback limits its usefulness for the authors. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their work. It lacks concrete details on what specific changes or improvements are needed, leaving the authors uncertain about how to proceed. Therefore, the comment is 3, as it identifies areas of concern but does not offer detailed instructions on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"soft labels is essentially on top of CRM and Cross entropy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the use of subpar hyperparameters and the results being impressive but potentially misleading. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is 3 as it points out areas of concern, but it could be more beneficial if it provided actionable advice or examples of how to improve the analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the simple/traditional experiment for unseen characters is a good idea but is presented as an afterthought. It implies that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for nonChinese speakers. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to add translations or specify how to present the evaluation results. The action is concrete but somewhat vague in terms of execution, as the authors need to determine the specific translations and how to present the evaluation results. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of more evaluation on classifying unseen words and the addition of translations to Figure 6 for nonChinese speakers. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the simple/traditional experiment for unseen characters is presented as an afterthought and that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for nonChinese speakers. While the comment identifies a potential issue with the presentation of the experiment, it lacks specific examples or references to support the claim that the experiment is presented as an afterthought. The suggestion to add translations is somewhat vague, as it does not specify which translations should be included or how they would enhance the figure. Therefore, the claim is 3, as it provides a logical basis but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of the simple/traditional experiment for unseen characters, suggesting that it is presented as an afterthought. It also suggests that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. Additionally, the reviewer suggests adding translations to Figure 6 for nonChinese speakers. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these suggestions or what specific translations should be included. This limits the comment\"s helpfulness, as it points out areas for improvement but does not fully support the authors in making those improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the number of images provided in the VioT dataset is small, which may impact the validity of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should increase the number of images, provide additional data, or justify the current number of images. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the VioT dataset, specifically mentioning the number of images provided in each of the four categories. This provides full grounding as it allows the authors to accurately identify the part of the paper being discussed. However, the comment lacks specificity as it does not detail what aspect of the dataset\"s size is problematic or how it affects the validity of the approach. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the number of images in the VioT dataset is small, which may impact the validity of the approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of images is insufficient. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to substantiate the claim. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the VioT dataset, noting that the number of images provided is small, which may impact the validity of the approach. However, it does not provide any specific suggestions or guidance on how the authors might address this issue, such as recommending an increase in the number of images or suggesting alternative datasets. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed and provides examples of what could be improved, such as explaining the colors in Fig. 2. Additionally, the reviewer mentions that Fig. 1 and 2 did not contribute much to their understanding, and they had to read the text multiple times. While the comment provides some guidance on what needs to be improved, it lacks concrete details on how to implement these changes. The authors are given a general direction but may need to infer specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig. 1 and 2\" and \"Figure captions,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the paper, such as the difficulty in following the mathematical derivations and the lack of explanations in figure captions. The comment suggests that more intuitive explanations are needed and provides examples of what could be improved, such as explaining the colors in Fig. 2. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also mentions that figure captions are lacking and require additional explanations and legends. The reviewer provides specific examples, such as the need to explain the colors in Fig. 2, which adds a level of detail and specificity to the claim. This makes the comment 4, as it provides a clear rationale for the claim and examples of what needs to be improved. However, it could be further strengthened by referencing specific mathematical derivations or figure captions to illustrate the issues more clearly. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed and provides examples of what could be improved, such as explaining the colors in Fig. 2. The comment also points out that Fig. 1 and 2 did not contribute much to the reviewer\"s understanding, and they had to read the text multiple times. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and accessibility of their paper. However, it could be more helpful if it offered suggestions on how to improve the mathematical derivations or figure captions, or if it provided more detailed examples of what constitutes intuitive explanations. Overall, the comment is 4 as it directs the authors toward significant improvements in the clarity and comprehensibility of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the text in Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. Additionally, it provides references for the missing gradient symbol and suggests that the authors should include them. These points are explicit and provide concrete actions for the authors to take, such as increasing the font size of the text in Table 1 and adding the missing gradient symbol in Algorithm 1. The references also offer guidance on where to find the necessary information. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the text size in Table 1 and the missing gradient symbol in Algorithm 1. Additionally, it provides references for the missing gradient symbol, which is helpful for the authors to understand and address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and observations about the paper, such as the font size of Table 1 and the missing gradient symbol in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the font size of Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. It also provides references for the missing gradient symbol, which is helpful for the authors to address the issue. However, the comment could be more helpful if it offered suggestions on how to improve the font size or provided guidance on how to include the missing symbol. Overall, the comment is 3 as it points out specific areas for improvement but lacks detailed guidance or suggestions for resolution."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between the residual blocks. It suggests that if not, a deeper ResNet with parameter sharing could be a potential baseline for comparison. While the comment implies that the authors should consider this baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the ResNet in the experiments shares parameters between the residual blocks. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between the residual blocks. It suggests that if not, a deeper ResNet with parameter sharing could be a potential baseline for comparison. However, the comment lacks any supporting evidence, reasoning, or references to justify why this comparison would be meaningful or beneficial. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the ResNet in the experiments, specifically whether it shares parameters between the residual blocks. It suggests that if not, a deeper ResNet with parameter sharing could be a potential baseline for comparison. This feedback is 3 as it identifies a potential area for improvement or further exploration in the experiments. However, the comment lacks depth and does not provide specific guidance on how to implement this suggestion or what specific aspects of the comparison should be considered. While it points out a potential area for enhancement, it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a major issue with the paper\"s motivation, specifically regarding the crossencoder architecture. It notes that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the motivation or what specific changes should be made to the architecture. As a result, the authors are left without a clear understanding of how to improve their draft in this area. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the motivation of the crossencoder architecture, noting that it is not ignoring crossentity comparison but instead attends to all candidates at once. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the motivation, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation for the crossencoder architecture is poorly explained, specifically stating that it is not ignoring crossentity comparison but instead attends to all candidates at once. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a major issue with the paper\"s motivation, specifically regarding the crossencoder architecture. It points out that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the motivation for their architecture. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the work uses an outdated GNN model and method, which affects the performance of the framework. It also mentions that the baseline algorithms/methods are also outdated. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue, such as suggesting modern alternatives or updating the methods. Without actionable guidance, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of an outdated GNN model and method, which affects the performance of the framework. However, it does not specify which part of the paper discusses the GNN model or the baseline algorithms/methods, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the GNN model or baseline algorithms/methods are outdated or how they could be updated to improve performance. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an outdated GNN model and method, which impacts the performance of the framework. However, the comment does not provide specific examples or references to support this claim, nor does it explain how the use of outdated methods affects the performance. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the work, noting that it uses an outdated GNN model and method, which impacts the performance of the framework. Additionally, it points out that the baseline algorithms/methods are also outdated. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or update the methods. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how the proposed method produces the type of explanation mentioned in Figure 1. It suggests that additional adhoc postanalysis might be required to extract shared motifs to explain a set of instances. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it or what specific steps the authors should take to improve the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations or examples to clarify the process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding how the proposed method produces the type of explanation mentioned in the figure. The comment suggests that additional adhoc postanalysis might be required to extract shared motifs, and it implies that this analysis might be easier with the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the explanation in Figure 1 is unclear and suggests that additional adhoc postanalysis might be required to extract shared motifs. The reviewer provides a quote from Line 48 to support this claim, which suggests that the analysis might be easier with the proposed method but still requires additional effort. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the quote provides some context, it does not fully address the issue of clarity or the necessity of additional analysis. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that the explanation provided is unclear and suggests that additional adhoc postanalysis might be required to extract shared motifs. It references Line 48 to provide context and implies that the proposed method might make this analysis easier but still requires additional effort. While the comment highlights a potential weakness in the explanation, it does not offer specific suggestions or guidance on how to address this issue or improve the clarity of the figure. The feedback is 3 as it points out a specific area for improvement, but it lacks actionable advice or detailed guidance for the authors to enhance their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the lack of model comparison, confusing sections, missing citations, and unreferenced notation. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to compare models, clarify confusing sections, and correct the missing citations and unreferenced notation. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"several sections\" and \"Line 99, section 3.1,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the lack of model comparison, confusing sections, missing citations, and unreferenced notation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors did not compare any models other than GPT2, which is a factual observation. It also mentions that several sections are confusing and points out specific missing citations and unreferenced notation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these claims or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of model comparison, confusing sections, missing citations, and unreferenced notation. It highlights specific areas that need attention, such as the need to compare models and clarify confusing sections. However, the comment does not provide detailed guidance or suggestions on how to address these issues, such as which models should be compared or how to clarify the confusing sections. While it points out areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides some direction but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on how to conduct this analysis or what aspects should be included. The comment implies that the authors should expand their analysis, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not specify which part of the paper this analysis should be applied to, nor does it provide details on what aspects should be included or how the analysis should be conducted. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would enhance the paper. The comment lacks specificity and does not offer a clear path for the authors to follow, making it difficult for them to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on what aspects of the analysis should be expanded or how to conduct it. The comment acknowledges the limitations of the paper\"s length, but it does not offer actionable steps for the authors to take. Without detailed suggestions or examples, the feedback lacks depth and specificity, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cite works related to metalearning and distinguish their approaches from those already cited. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a clear direction for the authors to expand their literature review and improve the connection between their work and existing research, it does not specify which works should be cited or how to distinguish them. The action is explicit but somewhat vague, as the authors need to infer the specific details of how to implement the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also mentions the work on RL for architecture search and optimizers, which should be linked to continual learning. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the need for citation and distinction, but without explicit references to sections or elements of the paper, the authors may struggle to identify the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a logical reasoning for the need to cite and distinguish related works, it lacks specific examples or references to support the claim about the deeper tie to metalearning. The suggestion to link the RL work is more concrete, but the overall claim is 3 due to the lack of detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to expand their literature review and distinguish their work from related approaches in the field of metalearning. It highlights the importance of citing and discussing related works, particularly those that focus on RL for architecture search and optimizers, and their potential application to continual learning. This feedback is valuable as it guides the authors to strengthen their connection to existing research and enhance the clarity and originality of their work. However, the comment could be more helpful if it provided specific examples or references to the works that should be cited or distinguished. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better reflect reallife situations. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these alternatives. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better reflect reallife situations. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results sections. While the authors might have an idea of where this feedback is relevant, it is not explicitly grounded. The comment is specific in suggesting alternative approaches to improve the diversity of teacher feedback, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better reflect reallife situations. However, the comment does not provide any supporting evidence, examples, or references to justify why this diversity is important or how it would improve the paper. Without additional context or explanation, the claim remains 3, as the authors may find it challenging to understand the significance of this suggestion without further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the diversity of teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better reflect reallife situations. This feedback is 3 as it points out a specific area for improvement and provides a direction for the authors to explore. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how other studies have addressed this issue. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". While the comment implies that these comparisons could provide valuable insights, it does not explicitly instruct the authors to conduct these comparisons or explain why they are necessary. The action is implicit and somewhat vague, as the authors need to infer the importance of these comparisons and determine how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, it does not specify which part of the paper these comparisons should be included in, making it weakly grounded. The comment is specific in suggesting the need for these comparisons, as it clearly identifies the potential benefits of including them. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, the comment does not provide any justification or reasoning for why these comparisons are necessary or how they would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the relevance of these comparisons. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the performance of the paper with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This feedback is 3 as it provides a clear direction for the authors to consider in terms of benchmarking their work against existing approaches. However, the comment lacks depth and does not explain why these comparisons are important or how they could enhance the paper. Additionally, it does not offer specific guidance on how to conduct these comparisons or what aspects to focus on. While it provides a starting point, the feedback could be more comprehensive and actionable with additional details. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the absence of standard deviations in the paper, which raises concerns about the validity of the results. It suggests that the authors should include standard deviations to provide more transparency and confidence in their findings. While the comment explicitly states the action needed (displaying standard deviations), it does not provide specific guidance on how to present these deviations or what aspects to focus on. The action is clear but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the paper, which raises concerns about the validity of the results. However, it does not specify which part of the paper this issue pertains to, such as specific sections or tables where standard deviations should be displayed. This makes it difficult for the authors to pinpoint the exact location of the issue. While the comment is specific in identifying the absence of standard deviations, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations in the paper raises concerns about the validity of the results. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to similar studies that have included standard deviations, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the absence of standard deviations. This is a critical observation that could impact the validity and reliability of the results presented. By pointing out this oversight, the reviewer highlights an area where the authors need to improve the transparency and robustness of their work. However, the comment does not provide specific guidance on how to address this issue or what aspects of the results might be affected by the absence of standard deviations. While it identifies a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide explicit guidance or suggestions on how to achieve this extension. The comment implies that the authors should consider broadening the scope of their work, but it lacks concrete steps or detailed advice on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the specificity of the setting, suggesting that the approach could be extended to more general settings. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the setting and its suggestion for broadening the scope, but without clear references to specific sections or elements, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide any supporting evidence, reasoning, or references to justify why the current setting is specific or how it could be broadened. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in improving their work. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid point about the specificity of the setting, suggesting that the approach could be extended to more general settings. It questions the need for a generative model and episodic tasks, which are specific to the current setting. The comment prompts the authors to consider broadening the scope of their work, which could lead to more general applicability. However, the comment lacks specific suggestions or examples on how to achieve this extension, making it 3. The authors are given a direction but not detailed guidance on how to implement this suggestion, which limits its utility. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While it implies that the authors should include these details, it does not explicitly instruct them to do so or provide specific guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should include these details but may not be entirely sure how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not specify which part of the paper these details should be included in, nor does it provide any context or examples of what kind of details are needed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need to be addressed. The comment is 1 and lacks specificity, making it difficult for the authors to understand and act upon the suggestion. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would enhance the paper. Without specific examples or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what details should be included or how they could be presented. Without further explanation or examples, the authors may find it challenging to understand and implement the suggested changes. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the choice of p < 0.4 in Algorithm 1, indicating that the reviewer is seeking clarification or explanation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific information they should include in their response. The action is implicit and vague, as the authors are left to infer that they need to provide a detailed explanation or justification for their choice. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the choice of p < 0.4 in Algorithm 1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the choice of p < 0.4 in Algorithm 1, indicating a potential area for clarification or explanation. While it highlights a specific aspect of the paper that may need further elaboration, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. It specifically mentions the need to clarify why there are negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This feedback provides clear and concrete actions for the authors to take, such as adding explanations or analysis to these figures. The comment is 5 as it directly instructs the authors on what needs to be done to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanations or analysis for Figures 1, 2, and 3. The comment provides detailed guidance on what needs to be clarified, such as the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. The reviewer suggests that the authors need to clarify why there are negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This claim is 3 as it logically points out the need for additional analysis or explanation, but it lacks specific examples or references to support the claim. The authors would need to infer the need for clarification themselves, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. It highlights the need for clarification regarding the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This feedback is clear and actionable, as it directs the authors to address these gaps in their analysis and explanation. By providing specific guidance on what needs to be clarified, the comment offers valuable insight into how the authors can improve their draft. However, it could be more helpful if it provided examples or suggestions on how to address these issues. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. While the comment implies that the authors should provide more analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more analysis and comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not specify which sections or parts of the paper should include this analysis or comparison, making it somewhat specific. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. The comment provides a logical reasoning by suggesting that such comparisons would clarify the unique advantages of the method. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the claim, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of analysis regarding the effectiveness of data augmentation methods. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and comparison sections. However, the comment could be more helpful if it offered examples or guidance on how to conduct these comparisons. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a clear path for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is concrete, as it specifies what the authors should test, but it is somewhat vague in its execution, as the authors need to determine the exact methodology and implementation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative approaches and providing examples, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. The comment provides a logical reasoning by suggesting alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, it lacks specific examples or references to support the claim that these alternative approaches would provide a clearer understanding of the net effect. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is actionable and offers a clear direction for the authors to improve their draft by conducting an ablation study to better understand the impact of each component. However, the comment could be more helpful if it provided additional guidance on how to conduct the ablation study or suggested specific metrics to use. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it does not explicitly instruct the authors to perform a specific action, it implies that the authors should consider this scenario and its implications for their model. The comment is 3 as it provides a direction for further exploration, but it lacks concrete guidance on how to implement this exploration or what specific aspects to focus on. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspect of the model\"s performance is being questioned or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an area of interest, it does not provide any guidance or suggestions for improvement. It lacks depth and does not offer actionable feedback or insights that could help the authors enhance their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It suggests that RLCD (or RLCDRescore) may not be able to scale to larger language models that are better at differentiating responses near the decision boundary. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific steps they should consider to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the shrinking advantage of RLCD over RLAIF as the model size increases, and it raises a question about whether RLCD can scale to larger language models. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases, and it questions whether RLCD can scale to larger language models. However, the comment lacks specific evidence or references to support this claim, such as data or comparisons with other models. Without such details, the authors may find it challenging to verify the claim or address it in their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It raises a question about whether RLCD (or RLCDRescore) can scale to larger language models that are better at differentiating responses near the decision boundary. While the comment highlights an important aspect of the comparison, it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to conduct a quantitative analysis to substantiate the computational gains claimed in the paper. It specifies the types of measurements that would be helpful, such as GPU hours, memory usage, or training time. This provides clear and concrete guidance on what the authors need to do to improve their draft. The action is explicit and concrete, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for quantitative analysis to substantiate the computational gains claimed in the paper. This includes suggestions like GPU hours, memory usage, or training time. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the computational gains from replacing the MAE model with a CNNbased data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This claim is 3 as it logically suggests that quantitative analysis would strengthen the paper\"s claims, but it lacks specific examples or references to similar studies that have used such analyses. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of quantitative analysis to substantiate the computational gains claimed in the paper. It suggests that including measurements such as GPU hours, memory usage, or training time would provide stronger evidence of the efficiency improvements in DQ V2. This feedback is clear and actionable, as it directs the authors to conduct a quantitative analysis that would enhance the credibility and robustness of their claims. However, the comment could be more helpful if it provided examples of how such analyses have been conducted in similar studies or offered guidance on how to conduct them effectively. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not provide explicit guidance on how the authors should incorporate this consideration into their analysis or what specific changes should be made to account for this time. The action is implied and somewhat vague, as the authors can infer that they need to consider the time aspect but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to consider the time aspect, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this time consideration is important or how it affects the efficiency of the method. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the efficiency of the method, specifically the time required for COLMAP and scenebyscene finetuning. This is a relevant point that could impact the practicality and applicability of the method in certain scenarios. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what specific aspects of the method could be improved to mitigate the time constraints. While it points out a potential weakness, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or what specific steps to take to improve the results. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of reporting results after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. It raises a concern about early training, where the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the training process and the potential impact on the agent\"s behavior, but without clear grounding, the authors cannot confidently determine where to address these concerns. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a logical observation but lacks specific evidence or references to support the claim. The comment is 3 as it provides a reasonable basis for the concern but could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. It speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a thoughtprovoking observation that could prompt the authors to consider how their results might be impacted by the agent\"s behavior during learning. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or explore the behavior of the agent during learning. While it identifies an important area for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the approach taken for handling documents in DocRED, specifically asking whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. While the comment identifies a potential gap in the manuscript, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information about their approach but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DocRED\" and \"the documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the handling of documents as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. This provides clear guidance on what needs to be addressed in the manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification about the approach taken in handling documents in DocRED, specifically regarding the consideration of documents as an entire sentence and the handling of concepts involving multiple entity mentions. These questions are factual in nature and do not express an opinion, judgment, or suggestion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the approach taken in handling documents in DocRED, particularly regarding the consideration of documents as an entire sentence and the handling of concepts involving multiple entity mentions referring to the same entity. This feedback identifies a gap in the manuscript that could be addressed to provide a more comprehensive understanding of the methodology. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or what specific information should be included in the manuscript. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an important area for clarification but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation of tail classes. While the comment identifies a potential issue with the clarity of the main contribution, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the motivations for PBSD and its contribution to the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation study\" and the \"DSCL part,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the clarity of the main contribution, particularly regarding the motivations for PBSD beyond improving the discriminative representation of tail classes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation of tail classes. This claim is 3 as it highlights a potential inconsistency in the paper\"s focus, but it lacks specific examples or references to support the argument. The authors would need to further explore and clarify the motivations for PBSD to address this concern effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation of tail classes. This feedback is 3 as it points out a potential inconsistency in the paper\"s focus, which could be clarified to enhance the coherence and impact of the contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as by providing additional context or examples. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the distribution should be clarified, how it should be clarified, or what specific aspects of the distribution are unclear. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not specify which part of the paper discusses the dataset or where the distribution should be clarified. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in identifying the issue of unclear distribution, but it lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, namely the lack of clarity regarding the detailed distribution of the proposed dataset. This is a relevant point that could impact the reproducibility and comparability of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending additional details or clarifications. Without actionable feedback, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method is limited in its application to supervised training due to the need for annotated labels for learning semantic tokens. It proposes an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. While the comment implies that the authors should consider this alternative approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the proposed method in its application to supervised training due to the need for annotated labels for learning semantic tokens. It suggests an alternative approach using a selfsupervised pretraining approach without annotations. However, the comment does not specify which part of the paper discusses the method or where the limitation is discussed, making it weakly grounded. The suggestion to consider a selfsupervised approach is specific, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is limited in its application to supervised training due to the need for annotated labels for learning semantic tokens. It suggests an alternative approach using a selfsupervised pretraining approach without annotations. While the comment provides a logical reasoning for the limitation and suggests an alternative, it lacks specific examples or references to support the claim that a selfsupervised approach would be more appealing. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a limitation in the proposed method, specifically the requirement for annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in terms of expanding the applicability of their method. However, the comment could be more helpful if it included examples or references to support the argument for the selfsupervised approach. Overall, the comment is 4 as it guides the authors toward a potential improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct additional experiments, but the comment lacks concrete details on how to implement this suggestion.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to demonstrate scalability on more challenging tasks, but without explicit references to sections or figures, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car, and that it is important to demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. The claim is 3 as it logically argues that demonstrating scalability on more complex tasks is important. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of demonstrating scalability on more complex tasks, and the comment could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the current experimental setup, noting that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of the LFF method, it is important to show its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental setup and demonstrate the broader applicability of their method. However, the comment could be more helpful if it offered suggestions on how to conduct these additional experiments or what specific aspects of the LFF method should be emphasized in these more complex tasks. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the abstract should include a specific measurement, such as \"attain greater expressivity, as measured by the change in linear regions in output space after citation, instead of just \"attain greater expressivity.\" Additionally, it recommends including learning curves for all experiments in an appendix. While the comment provides explicit actions, it does not specify which experiments should have learning curves or how to present them. The authors are given clear guidance on what to add to the abstract and an appendix, but the execution of these actions is somewhat vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be changed in the abstract, suggesting a specific measurement to include and recommending the inclusion of learning curves in an appendix. This level of detail provides clear direction for the authors to make improvements. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests changes to the abstract, specifically recommending a specific measurement to include and the inclusion of learning curves in an appendix. While the comment provides a logical reasoning for these suggestions, it lacks specific examples or references to support the claim that these changes would improve the paper. The authors are left to infer the benefits of these changes without detailed justification or evidence. Therefore, the comment is 3, as it provides a logical basis but lacks the necessary evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the abstract section of the paper. It suggests a more precise measurement for expressivity, which is a clear and concrete suggestion that can help the authors improve the clarity and rigor of their abstract. Additionally, it recommends including learning curves for all experiments in an appendix, which is a valuable suggestion for providing additional insights and visual aids. However, the comment could be more helpful if it explained why these changes would enhance the paper\"s clarity or impact. Overall, the feedback is 4 as it guides the authors on how to improve the clarity and comprehensiveness of their abstract and appendix sections."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should consider other baselines or update their references to more recent works. As a result, the authors are left without a clear direction on how to address this issue. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works, \"MISA,\" \"M2FNet,\" and \"MMDFN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This claim is 3 as it provides a specific reference to MULT and its publication year, which supports the assertion that it is outdated. However, the comment lacks detailed reasoning or examples to fully substantiate why MULT is considered out of fashion or how it impacts the current work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but points out that MULT was proposed in 2019 and is therefore out of fashion. This feedback is 3 as it highlights an area where the paper may be outdated and suggests that the authors consider more recent works. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as suggesting alternative baselines or explaining why MULT is still relevant. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a major issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks for all models and the omission of tensor completion results for fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be done to improve the clarity and fairness of the comparisons. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. It also provides specific guidance on how to address this issue by suggesting that the authors compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear and that the value of the used ranks is omitted, making it difficult to conduct a fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This claim is 3 as it provides a logical reasoning for the need for a fair comparison and suggests a method to achieve it. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. It provides a clear and actionable suggestion by recommending that the authors compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback is 5 as it guides the authors on how to improve the clarity and fairness of their experimental comparison, ensuring that the results are more robust and informative. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully conducted such comparisons. Overall, the comment is 5 as it offers a clear and actionable path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the normalization module, noting that it appears different in two versions but is described as the same in the text. It suggests that a standardization of the pictograms is needed, particularly in the context of Fig. 4, where the chosen symbols overlap. Additionally, the reviewer points out minor issues with the text, such as overlapping symbols in Fig. 4 and a lack of clarity after equation (4). While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to standardize the pictograms or address the overlapping symbols issue. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"normalization module\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the normalization module, noting that it appears different in two versions but is described as the same in the text. Additionally, it provides specific feedback on the figures, particularly Fig. 4, where the chosen symbols overlap. The comment also mentions minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4). This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the normalization module appears different in two versions but is described as the same in the text. It suggests that a standardization of the pictograms is needed, particularly in Fig. 4, where the chosen symbols overlap. The reviewer also points out minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4). However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to infer the specific issues and how to address them, which could be challenging without additional context or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the normalization module, noting that it appears different in two versions but is described as the same in the text. This is a clear and actionable point that the authors can address to improve the consistency and clarity of their work. Additionally, the comment highlights the importance of standardizing the pictograms, particularly in Fig. 4, where the chosen symbols overlap. This feedback is valuable as it helps the authors ensure that their figures are clear and easy to understand. The comment also points out minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4), which can be addressed to improve the overall readability. Overall, the comment is 4 as it provides clear and actionable suggestions for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the authors\" claims and the theoretical part of the paper. It highlights that the authors claim that only parts of subdivision splines are useful for decision boundaries, but the theoretical part lacks details on how the proposed algorithm removes these splines. The reviewer questions whether the algorithm requires extra computation cost for space partitioning. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this discrepancy or what additional details should be included in the theoretical part. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations of the algorithm and its computational requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the observation and the goal of pruning, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detail in the theoretical part regarding the proposed algorithm for removing subdivision splines and the potential extra computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the observation that only parts of subdivision splines are useful for decision boundaries. It points out that the theoretical part lacks details on how the proposed algorithm removes these splines, and it raises a concern about the potential extra computation cost for space partitioning. The comment is 3 as it highlights a gap in the paper\"s explanation and seeks clarification on the algorithm\"s computational requirements. However, it does not provide specific examples or references to support the claim or the need for additional details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claims and the theoretical part of the paper. It points out that the authors claim that only parts of subdivision splines are useful for decision boundaries, but the theoretical part lacks details on how the proposed algorithm removes these splines. The reviewer also questions whether the algorithm requires extra computation cost for space partitioning. This feedback is 3 as it highlights a gap in the paper that the authors need to address to provide a more complete understanding of their work. However, the comment could be more helpful if it offered specific suggestions on how to address this discrepancy or what additional details should be included in the theoretical part. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that W1 and W2 are not defined, and it speculates that they might denote the Encoder and Decoder networks. It also mentions that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and directs the authors to define these terms, which is a concrete action for the authors to take. The comment is 5 as it provides specific guidance on what needs to be clarified or defined in the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W1 and W2\" and \"W and V,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that these terms are not defined, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"W1 and W2 are not defined\" and speculates that they might denote the Encoder and Decoder networks. It also mentions that \"W and V are not defined\" and provides specific references to page 3, line A4, and equation 3. This claim is 3 as it points out specific sections where the terms are not defined, providing some basis for the assertion. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that W1 and W2 are not defined and speculating that they might denote the Encoder and Decoder networks. It also points out that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and actionable, as it directs the authors to clarify these terms to avoid confusion and improve the clarity of their work. However, the comment could be more helpful if it offered suggestions on how to define these terms or provided examples of how they might be used in the context of the paper. Overall, the comment is 4 as it effectively guides the authors on how to enhance the clarity of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification or analysis regarding the behavior of negative chips and the potential impact of the alternating process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the behavior of negative chips and the potential impact of the alternating process. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also inquires whether this alternating process could help improve performance. This feedback is 3 as it prompts the authors to clarify their methodology and potentially explore avenues for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or improve their work. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should evaluate their proposed approach on both new and old patients. While the comment implies that the authors should conduct this evaluation, it does not provide specific guidance on how to do so or what aspects of the evaluation should be prioritized. The action is implicit and somewhat vague, as the authors need to infer the details of the evaluation themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or experiment. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for an evaluation on new and old patients, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should evaluate their proposed approach on both new and old patients. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a relevant and actionable suggestion. It highlights the importance of considering both types of patients to ensure the robustness and generalizability of the approach. However, the comment could be more helpful if it provided specific guidance on how to conduct this evaluation or what aspects to focus on. Despite this, the feedback is clear and offers a constructive direction for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the paper lacks indepth analysis and suggests that the authors should provide an explanation for the training dynamics observed. This feedback is clear and provides a direct action for the authors to take, which is to include an analysis of the training dynamics. The comment is specific in its request for an explanation, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis and specifically mentions that the authors found inverse scaling over compute, but does not provide further details on what this means or how it affects the paper. It implies that the authors should provide an explanation for this observation, but without explicit references to specific sections or elements of the paper, the authors may struggle to identify where this analysis should be included. Therefore, the comment is weakly grounded because it does not specify which part of the paper should be analyzed, but it is specific in its request for an explanation. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks indepth analysis and implies that the authors should provide an explanation for the observed training dynamics. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides a general suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that there is no indepth analysis of the training dynamics observed. It suggests that the authors should provide an explanation for the inverse scaling over compute, which would enhance the paper\"s solidity. While the comment highlights an important area for improvement, it lacks specific guidance on how to conduct this analysis or what aspects should be addressed. This limits the comment\"s helpfulness, as it points out a critical issue but does not provide detailed instructions on how to resolve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of mathematical definition for certain architectural details, specifically mentioning multihead attention. It also questions the purpose of a split arrow in Figure 2 and suggests that a formal definition would be beneficial for readers to understand. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues or what specific definitions should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide a formal definition for the architectural details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"multihead attention,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definition for architectural details, such as multihead attention, and questions the purpose of a split arrow in Figure 2. The comment further specifies that a formal definition would be beneficial for readers to understand these details. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of mathematical definition for certain architectural details, specifically mentioning multihead attention. It questions the purpose of a split arrow in Figure 2 and suggests that a formal definition would be beneficial for readers to understand the model. While the comment identifies a potential issue, it does not provide specific examples or references to support the claim that the lack of mathematical definition is problematic. The suggestion for a formal definition is logical, but the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of mathematical definition for certain architectural details, such as multihead attention. It questions the purpose of a split arrow in Figure 2 and suggests that a formal definition would be beneficial for readers to understand the model. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by providing more detailed explanations. However, the comment could be more helpful if it offered suggestions on how to formalize these definitions or provided examples of how similar concepts have been defined in other works. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. While the comment implies that the authors should modify their approach to include more complex tasks, it does not provide explicit instructions on how to implement this change or what specific aspects of the tasks should be altered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a potential improvement by comparing with a reinforcement learning algorithm baseline, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the setting with a fixed policy is a subset of reinforcement learning and proposes that tasks could be made more complex to compare with a reinforcement learning algorithm baseline. However, the comment lacks specific examples or references to support this claim or to justify why the current setting is a subset of reinforcement learning. Without detailed reasoning or evidence, the claim remains 1, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. This feedback is 3 as it identifies a potential area for improvement by suggesting a way to enhance the complexity of the tasks. However, the comment lacks specific guidance on how to implement this change or what specific aspects of the tasks should be altered. Additionally, it does not provide examples or detailed suggestions on how to conduct the comparison with a reinforcement learning algorithm baseline. While the feedback points out a potential area for improvement, it could be more actionable and comprehensive with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to broaden the scope of the paper or what specific aspects of multitask models should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not specify which part of the paper this issue is related to, such as specific sections or examples where the focus on multitask models is discussed. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the multitask models are problematic or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any specific guidance or suggestions on how the authors might broaden the scope of their work or address this limitation. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it identifies a potential issue but lacks depth and specificity in its feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the literature review ignores several relevant papers, specifically mentioning 1 and 2. It suggests that VRMARINA and DASHAMVR, mentioned in these papers, could be relevant to the current work. The reviewer provides a specific question about the Assumption 2 and the rate of QSGD in the stochastic regime, implying that the authors should consider these papers for further analysis. While the comment does not explicitly instruct the authors to include these papers, the action is implicit and concrete, as it clearly identifies the need for additional analysis and provides a specific direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the next section\" and \"Literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of relevant papers, 1 and 2, and suggests that VRMARINA and DASHAMVR could be relevant to the current work. The comment provides a clear direction for the authors to consider these papers and address the Assumption 2 and QSGD rate in the stochastic regime. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning 1 and 2. The reviewer provides a specific example of VRMARINA and DASHAMVR, which are mentioned in these papers, and suggests that they could be relevant to the current work. The comment also includes a question about the Assumption 2 and the rate of QSGD in the stochastic regime. This provides a logical basis for the claim, as it highlights a potential gap in the literature review that could impact the paper\"s conclusions. However, the comment lacks specific references to these papers or detailed analysis of their relevance, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable basis for the claim but could be further substantiated with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the literature review, noting that it ignores several relevant papers. It specifically mentions 1 and 2, which are believed to be relevant to the current work. The reviewer suggests that VRMARINA and DASHAMVR, mentioned in these papers, could be relevant to the Assumption 2 and the rate of QSGD in the stochastic regime. This feedback is clear and actionable, as it provides the authors with specific papers to consider for further analysis and potential inclusion in the literature review. By addressing this issue, the authors can enhance the comprehensiveness and relevance of their literature review, which is valuable for improving the overall quality of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: whether the authors have any additional insights into modest performance gains on Clothing1M and how the algorithm performs on other realworld datasets like WebVision, evaluated by DivideMix. While these questions imply that the authors should provide additional information or analysis, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more insights or data. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises two questions about the performance of the algorithm on Clothing1M and WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for additional insights or performance evaluations on specific datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking for additional insights and performance evaluations on specific datasets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could help the authors gain additional insights into the performance of their algorithm on realworld datasets. By asking about modest performance gains on Clothing1M and the algorithm\"s performance on WebVision, evaluated by DivideMix, the reviewer encourages the authors to provide more detailed evaluations and comparisons. However, the comment lacks specific guidance or suggestions on how to address these questions or what additional insights would be beneficial. While it points out areas for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies potential areas for enhancement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct additional experiments on different LLMs like LLaMA and Falcon as benchmark baselines. While the comment implies that more experiments are needed, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on different LLMs like LLaMA and Falcon as benchmark baselines. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results discussion. The authors can infer that it relates to the experimental results or methodology, but this inference is not direct. The comment is specific in suggesting the need for additional experiments but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more experiments on different LLMs like LLaMA and Falcon are needed as benchmark baselines. However, it does not provide any supporting evidence, reasoning, or references to justify why these specific LLMs are necessary or how they would impact the results. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the experimental setup by suggesting that more experiments on different LLMs like LLaMA and Falcon are needed as benchmark baselines. This feedback is 3 as it points out an area where the authors could enhance their study by including additional comparisons. However, the comment lacks specific guidance on how to conduct these experiments or what specific aspects to focus on, such as the impact of different LLMs on the results. While it provides a direction for improvement, it could be more actionable with additional details. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant gap in the paper, noting that it does not describe the hyperparameters used by each defense nor how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. While the comment identifies a clear area for improvement, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they need to include this information, but the lack of concrete guidance on how to do so makes the action implicit. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of description regarding the hyperparameters used by each defense and how those hyperparameters are derived. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. It is also specific because it clearly specifies what needs to be addressed, namely the description of hyperparameters and their derivation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. The reviewer suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of including this information and might find it challenging to understand the exact implications without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific guidance on how to implement this optimization or how to present the results. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. While it implies that the authors should consider alternative approaches, it does not explicitly instruct them to do so or provide specific guidance on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative pooling strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. It does not present an opinion, judgment, or suggestion that requires verification. It is a request for clarification and does not contain subjective claims or claims that require evidence or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This is a thoughtprovoking observation that could lead to a deeper understanding of the methodology and its implications. However, the comment lacks specific guidance or suggestions on how to explore alternative pooling strategies or what specific aspects of mean pooling should be questioned. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison of the real search cost in terms of GPU days. The comment is specific and actionable, giving the authors a direct and concrete step to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a comparison of the real search cost in terms of GPU days. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback is 3 as it identifies a potential area for improvement in the presentation of data, which could provide a more comprehensive understanding of the system\"s performance. However, the comment lacks depth and does not explain why this comparison is important or how it would enhance the paper. To be more helpful, the comment could provide additional context or examples of how such a comparison could be implemented. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. While the comment implies that the authors should provide more information about the training process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the training details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VQGAN\" and \"Computer Vision Figures dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the training details of the VQGAN, specifically whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, particularly inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. This question highlights a potential gap in the paper that could impact the reader\"s understanding of the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed methods, DualIS and DualDIS, in terms of their generic applicability on crossmodel retrieval tasks, specifically mentioning the minor improvements in MSVD (Table 3). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the methods or what specific aspects of the methods need to be addressed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS,\" allowing the authors to accurately identify the specific methods being discussed. It also specifies the issue by pointing out that the methods are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. However, the comment does not provide specific details or examples of these tasks or the performance improvements, making it difficult for the authors to understand the basis of the claim. Without additional context or references, the claim lacks sufficient evidence or justification to be 5. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the proposed methods, DualIS and DualDIS, by pointing out that they are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3), which shows minor improvements. This feedback is 3 as it highlights an area where the methods may not be as effective as expected, providing the authors with a specific issue to address. However, the comment could be more helpful if it offered suggestions on how to improve the methods or addressed the issue of generic applicability. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to establish this relationship or what specific steps to take to improve the study. As a result, the authors are left without any clear direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the study, namely the lack of establishment of the relationship between the top selected patches and the disease. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this relationship should be discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in identifying the issue of incomplete study, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the study, noting that the relationship between the top selected patches and the disease is not yet established. This is a critical point that could impact the validity and reliability of the study. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or what steps they could take to establish this relationship. Without actionable advice or detailed feedback, the authors are left with a clear area for improvement but without a clear path forward. Therefore, the comment is 3, as it points out a critical weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the performance of FedSP is not the best in Tables 1 and 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the performance or what specific aspects of FedSP need attention. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance of FedSP is not the best in these tables on some datasets. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of FedSP is not the best in Tables 1 and 2 on some datasets. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of FedSP in Tables 1 and 2 on some datasets. It highlights that the theme of the paper is mainly about FedSP, but the performance is not the best. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might improve the performance or address this issue. Without specific recommendations or examples, the feedback does not offer much value to the authors in terms of improving their draft. Therefore, the comment is 3, as it points out a potential weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises questions about the clarity of certain aspects in the paper, specifically asking for more explicit explanations. It suggests that the authors should clarify what Omega is mentioned in L178 and provide more explicit information about the OMD family of algorithms. Additionally, it asks for clarification on the link function and the theorem in reference 32 used for the regret guarantee. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should provide more detailed explanations, but the guidance is somewhat vague. Therefore, the comment is 3, as it identifies areas for improvement but lacks concrete details on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the clarity of certain aspects, such as the definition of Omega and the link function, as well as the reference to a theorem in 32. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and additional information, such as the definition of Omega, the link function, and the reference to a theorem in 32. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved by requesting clarification on certain terms and concepts. It asks for more explicit explanations of Omega and the OMD family of algorithms, as well as the link function and the reference to a theorem in 32 for the regret guarantee. This feedback is clear and actionable, as it provides the authors with specific questions to address in order to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information in a more accessible manner. Overall, the comment is 4 as it directs the authors to important areas for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific aspect of the models being learned directly from pixels without a Markovian state. However, it does not provide any guidance or suggestions on how the authors should address this issue or improve their work. There is no explicit or implicit action for the authors to take, nor is there any indication of what the implications of this observation might be. As a result, the comment lacks actionability and does not provide any direction for the authors to follow. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment mentions \"the models are learned directly from pixels without a Markovian state,\" which suggests that the models are not Markovian. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the models being learned directly from pixels without a Markovian state, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this observation or how it affects the paper\"s conclusions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific aspect of the models being learned directly from pixels without a Markovian state, which could be a potential issue or limitation. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or context, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically using the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and explicit action. The comment is specific in identifying the need for references and provides a concrete direction for the authors to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"sequence example\" and \"Example 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the use of the Hamming distance over entire parts of the sequence as a scoring loss, which is a specific practice in the context of CRF. The comment suggests providing references for this approach, which is a clear and specific request for additional information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer expresses surprise and suggests that they are not familiar with this approach, which is a claim that requires further explanation or evidence to be 5. However, the comment does provide a specific example of a \"nodewise\" approach, which could be used to clarify the issue. Therefore, the comment is 3, as it highlights a potential gap in understanding but lacks detailed justification or references to support the claim fully.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and actionable suggestion. By addressing this point, the authors can enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided specific references or examples of works that use this approach. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear path for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment provides a clear action to take, it lacks specific guidance on how to implement these changes or what specific metrics should be included. The authors are given a general direction but may need to infer the details of execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the evaluation or metrics sections. The suggestion to change the name and mention metrics is specific, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also recommends mentioning the metrics along with the datasets or in the captions of the tables. This suggestion is based on the claim that \"evaluation\" can have a more general meaning and that most, if not all, of the metrics are wellknown and used as standard practice. However, the comment lacks specific examples or references to support the claim that the metrics are wellknown and standard practice. This makes the claim 3, as the authors would need to infer the reasoning behind the suggestion themselves.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to change the name of the \"Evaluation\" element to \"Metrics,\" which is a clear and concise improvement. It also recommends removing the corresponding sections and mentioning the metrics along with the datasets or in the captions of the tables. This suggestion is based on the rationale that \"evaluation\" can have a more general meaning and that most, if not all, of the metrics are wellknown and used as standard practice. By making these changes, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided examples of specific metrics to include or explained why these changes would enhance the paper\"s clarity. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states a fact about the limitations of pruning techniques on GPUs, which is not an actionable statement. It does not provide any guidance or suggestions for the authors to improve their draft. As a result, the authors are left without any actionable steps to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses. It is a general statement about the limitations of pruning techniques on GPUs, which does not provide any context or reference to a specific section, table, or figure in the paper. As a result, the authors cannot determine which part of the paper needs attention or improvement. The comment is also not specific, as it does not provide details on what aspects of the pruning techniques are not efficient on GPUs or how the authors might address this issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"it is not yet possible to realize efficiency gains on GPU\" regarding pruning techniques. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment provides a general observation about the limitations of pruning techniques on GPUs, which is relevant but not actionable. It does not offer any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with 5 being unfair because 5 is designed for a more complex problem. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the evaluation. The comment lacks actionable details, such as suggesting alternative evaluation methods or suggesting how to better align the evaluation with the complexity of the problem. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the numerical evaluation and the comparison with 5, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation, noting that the method is only evaluated on synthetic data and that the comparison with 5 is not fair due to the complexity of the problem. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with 5 being unfair. The reviewer supports this claim by explaining that 5 is designed for a more complex problem, specifically mentioning the absence of knowledge of camera pose parameters. This provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the complexity of 5 or explaining how the comparison should be conducted fairly. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with 5 is not fair due to the complexity of the problem. This feedback is valuable as it highlights a potential weakness in the paper\"s evaluation, which could impact the credibility of the results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending alternative evaluation methods or suggesting ways to better align the evaluation with the complexity of the problem. As it stands, the comment points out a critical area for improvement but lacks actionable guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the study of numbers of bits in logits helps against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps for how to address it. The authors are left to infer that they should consider this experiment, but the comment lacks specific guidance on how to implement it or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the study of numbers of bits in logits and its potential impact on robustness against a larger epsilon in the PGD attack. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely whether the study of 32bit logits helps against a more powerful adversary. This provides clear guidance on what the authors should consider in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the study of numbers of bits in logits and its potential impact on robustness against a larger epsilon in the PGD attack. The reviewer suggests that intuition suggests that having a 32bit logit should improve robustness against a more powerful adversary. However, the comment lacks specific evidence or references to support this claim, making it 3. The authors would need to make a logical deduction or conduct additional research to verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the study of numbers of bits in logits and its potential impact on robustness against a larger epsilon in the PGD attack. It suggests that intuition suggests that having a 32bit logit should improve robustness against a more powerful adversary. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might explore this idea or what specific experiments could be conducted. The feedback is 3 as it points out a potential area for enhancement, but it lacks depth and actionable steps for the authors to follow. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, specifically mentioning a reference to Foester et al. (NIPS 2016) as an example. This provides a clear and concrete action for the authors to take, as they are given a specific area to address and a reference to guide their understanding. The comment is 5 because it directly tells the authors what to do and provides a concrete example to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"meta solvers\" and the \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the difference between the meta solvers and centralized RL, and provides a reference to Foester et al. (NIPS 2016) to guide the authors in understanding this difference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers are centralized controllers, and suggests that the authors should clarify the difference between them and centralized RL. The reviewer provides a reference to Foester et al. (NIPS 2016) to support this claim. However, the comment lacks detailed explanation or analysis of why the meta solvers are considered centralized controllers, making it 3. The reference to Foester et al. provides some support, but the authors would need to further explore the context and implications of the reference to fully understand and address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the classification of the meta solvers as centralized controllers. It suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al. (NIPS 2016) as an example of centralized RL, which is a clear and actionable suggestion for the authors to consider. This feedback is 4 as it guides the authors to clarify a key aspect of their work, which could enhance the understanding and clarity of their paper. However, it could be more helpful if it included additional details or examples on how the authors might address this issue. Overall, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the authors should consider providing examples to explain the concept of M_T, which is defined over the probabilities of atomic events. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific in its request for examples, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of M_T and the notation used, and suggests providing examples to clarify the concept. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of M_T is over the probabilities of atomic events and that the notation is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of M_T, noting that it is defined over the probabilities of atomic events and that the notation is not clear. It suggests that the authors consider providing examples to clarify this concept. While the comment highlights a potential area for improvement, it does not provide detailed guidance on how to present these examples or what specific aspects of the notation should be clarified. This limits the comment\"s helpfulness, as it points out an issue but does not fully support the authors in addressing it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment implies that the authors should provide a clearer explanation or rationale for this distinction, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of detecting both entities in the example and asking for clarification on the difference between detecting both entities and just detecting the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment identifies a potential area of confusion or misunderstanding in the paper, it does not provide specific suggestions or guidance on how to address this issue. The authors are left with a vague understanding of what needs to be clarified, which limits the comment\"s helpfulness. Therefore, the comment is 3, as it points out a potential area for improvement but lacks actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the upper bound in Theorem 1, which seems correct but contains an exception. The reviewer asks how to explain this exception, implying that the authors should provide an explanation or clarification. However, the comment does not explicitly instruct the authors to do so, nor does it offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the upper bound in Theorem 1 and asks for an explanation of an exception. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question about the correctness of Theorem 1 and an observation about an exception. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the correctness of Theorem 1 and points out an exception regarding a separate node with 0 neighbors. This question highlights a potential issue in the paper that the authors may need to address. However, the comment does not provide specific guidance or suggestions on how to address this issue or explain the exception. While it identifies a potential weakness, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it points out a potential problem but does not fully support the authors in resolving it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific analyses or solutions could be proposed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the handling of rumors generated by GPT, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the need for further analysis or solutions regarding the challenges of detecting rumors generated by GPT, and it questions the rationale behind why GPTgenerated rumors are similar to natural rumors. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. It suggests that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor, but the experimental result shows the opposite. The comment provides a logical reasoning by questioning the experimental result and suggesting that the rationale might be flawed. However, it lacks specific examples or references to support the claim that GPTgenerated rumors are easier to detect than natural rumors. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. It points out that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor, but the experimental result shows the opposite. This feedback is 3 as it highlights an area where the authors could provide further analysis or solutions to address the challenge of detecting rumors generated by GPT. However, the comment could be more helpful if it suggested specific analyses or experiments that could be conducted to explore this issue further. Overall, the comment provides some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical contribution or what specific changes should be made to Section 4. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, stating that it is limited and not about a formal and principled solution but rather about heuristics. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution of the paper, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. This feedback highlights an area where the paper could be improved by providing a more comprehensive and rigorous approach to the technical contribution. However, the comment lacks specific suggestions or guidance on how to address this issue or what aspects of the heuristics should be improved. While it points out a potential weakness, it does not offer actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the probability mass function (PMF) is not being effectively utilized in the experimental setting and recommends considering various PMFs for each learner class. It also mentions that the quasiuniform distribution used in MixBoost is dependent on a single parameter and suggests that individual consideration of each learner class would add depth to the experimental setting. However, the comment does not provide specific guidance on how to implement this suggestion or which PMFs to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"probability mass function\" and \"MixBoost,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the probability mass function is not being effectively utilized and recommends considering various probability mass functions for each learner class. This provides clear guidance on what needs to be addressed in the experimental setting. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the probability mass function is not being effectively utilized in the experimental setting and suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. The reviewer provides a logical reasoning by pointing out that the quasiuniform distribution used in MixBoost is dependent on a single parameter and that individual consideration of each learner class would be beneficial. However, the comment lacks specific examples or references to support the claim that the quasiuniform distribution is not wellsuited for the experimental setting. This makes the claim 3, as the authors would need to make a logical inference to understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setting, noting that the probability mass function is not being effectively utilized in the MixBoost method. It suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. While the comment highlights a potential area for improvement, it lacks specific guidance on how to implement this suggestion or which probability mass functions to consider. The feedback is 3 as it points out a potential weakness but does not provide detailed instructions on how to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this issue, provide additional context, or clarify their methodology. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how the authors should address this concern. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to understand and act upon the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is unfair. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment raises a valid question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. This is an important point that could impact the interpretation and comparison of results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to discuss connections with a specific reference, a, which uses supervised learning in QBF solving. It also mentions that QBF generalizes SMT. While the comment provides a clear action to take, it does not offer specific guidance on how to integrate this discussion into the paper or what aspects of the reference are particularly relevant to the paper. The authors are given a direct action to take but may need to infer the exact steps to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need to discuss connections with a, which uses supervised learning in QBF solving, and mentions that QBF generalizes SMT. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper is missing relevant references, specifically mentioning a, which uses supervised learning in QBF solving. The reviewer claims that QBF generalizes SMT, but does not provide further explanation or evidence to support this claim. While the suggestion to discuss connections with a is clear, the lack of detailed justification or examples makes the claim 3. The authors would need to make a significant effort to understand and address the suggestion, which aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue by pointing out the absence of relevant references, particularly a, which uses supervised learning in QBF solving. It suggests that the authors discuss connections with this reference, which could enhance the paper\"s contribution. However, the comment lacks depth and does not provide specific guidance on how to integrate the reference or what aspects of the reference are particularly relevant to the paper. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider whether the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It also suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide specific guidance on how to do so or what specific alternative relationships to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the training process and the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests exploring alternative relationships and provides a reference to a related work for further consideration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss is replaced by other relationships. The reviewer supports this claim by referencing a related work, Navon et al. (2020), which explores learning the Pareto Front with Hypernetworks. This reference provides a basis for the claim, suggesting that the authors should consider alternative relationships. However, the comment could be strengthened by providing more detailed reasoning or examples of how these alternative relationships might be explored. Overall, the claim is 4, as it is supported by a reference but could be further developed with additional justification or examples.", "helpfulness_rationale": "The review comment identifies a specific aspect of the training process that could be improved by exploring alternative relationships between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this could lead to a continuous parameterization of the Pareto Front. The comment also references a related work, Navon et al. (2020), which could provide a starting point for the authors to consider alternative relationships. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions or examples of alternative relationships to explore. Overall, the comment is 4 as it guides the authors toward a potentially valuable area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in traffic signal control, suggesting that it might be a poor example of federated learning. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address these concerns or improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in traffic signal control, suggesting that it might be a poor example of federated learning. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or discussion on privacy preservation. Without explicit references or clear indications, the authors cannot confidently determine which parts of the paper need attention. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in traffic signal control, suggesting that it might be a poor example of federated learning. However, the comment lacks any supporting evidence, reasoning, or references to substantiate these claims. Without detailed justification or examples, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in traffic signal control, suggesting that it might be a poor example of federated learning. While the comment identifies a potential weakness in the paper\"s discussion of privacy preservation, it lacks specific suggestions or guidance on how the authors might address this issue or improve their argument. The feedback is 3 as it prompts the authors to consider the implications of their approach in the context of privacy preservation, but it could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This provides a clear and direct action for the authors to take, which is to verify and potentially fix the links. The comment is specific and concrete, as it clearly identifies the problem and offers a straightforward solution. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnotes 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the hyperlinks not working, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hyperlinks for footnotes 3 and 4 do not work. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable piece of feedback that the authors can address to improve the quality of their paper. By addressing this issue, the authors can ensure that their references are properly linked and accessible to readers. However, the comment could be more helpful if it provided additional guidance on how to verify the links or suggested alternative solutions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is explicit and provides concrete details on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, which is not clear enough. It provides specific feedback on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out that the figure may be misleading, suggesting that the Label Embeddings are the output of the encoder. This provides full grounding as it clearly identifies the sections that need revision, and it is specific in detailing what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific feedback on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure is misleading, suggesting that the Label Embeddings are the output of the encoder. This feedback is supported by logical reasoning and specific examples, making the claim 4. However, it could be further strengthened by providing additional references or detailed explanations to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the clarity of the discussion in the modeling section. It suggests revising the architecture section to better formalize the architecture and clarify the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is clear and constructive, offering the authors a concrete path to improve the clarity and accuracy of their discussion. By addressing these points, the authors can enhance the comprehensibility and effectiveness of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the neural network is difficult to understand and recommends starting the section with the final paragraph that clarifies it. While the comment provides a specific suggestion to improve the clarity of the section, it does not offer detailed guidance on how to achieve this clarity or what specific changes should be made to the description. The action is implicit and somewhat vague, as the authors need to infer that they should start the section with the clarifying paragraph. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"528,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the neural network, suggesting that it is hard to understand and recommending starting the section with the final paragraph that clarifies it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand and suggests starting the section with the final paragraph that clarifies it. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the description is difficult to understand or how the suggested clarification would improve comprehension. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network, noting that it is hard to understand. It suggests starting the section with the final paragraph that clarifies the description, which could improve the reader\"s comprehension. While the comment provides a clear and actionable suggestion, it could be more helpful if it offered additional guidance on how to improve the clarity of the description or provided examples of what aspects are difficult to understand. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the model and suggests exploring the possibility of training it towards attentionbased encoderdecoder training. While the comment implies that the authors should consider this alternative approach, it does not provide explicit instructions or concrete steps on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative training method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the model and suggests exploring the possibility of training it towards attentionbased encoderdecoder training. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the model is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an alternative approach, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the limitations of the model and suggests exploring the possibility of training it towards attentionbased encoderdecoder training. However, it does not provide any supporting evidence, reasoning, or references to justify why this alternative approach might be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the model and suggests exploring the possibility of training it towards attentionbased encoderdecoder training. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples on how to implement this change. The comment is 3 as it points out a potential direction for improvement, but it could be more beneficial with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. It provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment does not explicitly instruct the authors to use these methods or provide guidance on how to integrate them into their work. While the suggestion is clear, the lack of explicit instructions or detailed guidance on implementation makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attack methods\" and \"toy setting with classification tasks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper does not consider other classical attack methods in NLP and suggests using examples from other papers. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment lacks detailed reasoning or references to support why these methods are considered more effective or why the current methods are inadequate. This makes the claim 3, as the authors would need to further explore the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the attack methods used are naive and that the paper does not consider other classical attack methods in NLP. It provides specific examples of alternative methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. This feedback is clear and actionable, as it guides the authors to consider a broader range of attack methods that could enhance the robustness and generalizability of their work. However, the comment could be more helpful if it offered additional insights or suggestions on how to integrate these methods into the paper. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the impact of mitigation methods or suggestions for improving image quality. As a result, the authors are left without any clear direction on how to improve their draft in response to this comment. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation methods on the image generation capabilities of diffusion models, suggesting that this could lead to lower image quality. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the mitigation methods affecting image quality. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, which could lead to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their mitigation methods. The comment highlights a potential problem but lacks actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise about the dominance of function words over content words in a Japanese sentence. However, the comment lacks specificity regarding what aspect of the dominance is surprising or how it might impact the paper. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it lacks any actionable feedback or suggestions for improvement. Without further explanation or context, the authors are left without a clear understanding of what aspect of the observation is surprising or how it might impact their work. As a result, the comment does not provide any meaningful guidance for the authors to enhance their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. The reviewer provides a rationale by referencing two external sources, 1 and 2, which discuss the properties of kmeans clustering and its applicability to different datasets. This explicit suggestion and the inclusion of references provide clear guidance on what the authors should consider as a more reasonable baseline for their analysis. The action is explicit and concrete, as the authors know exactly what to change to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of the average of multiple kmeans objectives with different seeds as a baseline, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suggestion to use the minimum kmeans objective over multiple seeds instead. This provides clear guidance on what the authors should consider as a more reasonable baseline for their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. The reviewer supports this claim by referencing two external sources, 1 and 2, which discuss the properties of kmeans clustering and its applicability to different datasets. This provides a logical basis for the claim, as it aligns with the literature on kmeans clustering. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced sources to fully substantiate the claim. Therefore, the comment is 4, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to improve the paper by recommending the use of the minimum kmeans objective over multiple seeds as a baseline instead of the average of multiple kmeans objectives. This feedback is based on a logical reasoning that aligns with the literature on kmeans clustering, as referenced in the comment. By referencing specific sources, the reviewer offers a solid foundation for the suggestion, making it easy for the authors to understand and implement the change. However, the comment could be more helpful if it provided additional context or examples on why the minimum kmeans objective is more appropriate. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. It points out that the training regularization term (H) requires temperature calibration, but temperature calibration is applied after training. The reviewer asks the authors to clarify this point, which is a clear and explicit action. Additionally, the comment suggests that reducing entropy may make predictions more confident, which is counter to the paper\"s motivation to calibrate the networks. The action is explicit and concrete, as it directly instructs the authors to clarify the confusion regarding H and its relationship to temperature calibration and uncertainty calibration. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 155160,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the relationship between temperature calibration and uncertainty calibration, particularly in the context of the regularization term H. The comment further clarifies the issue by questioning the authors\" clarification of this point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. The reviewer questions whether temperature calibration is required for both uncertainty calibration and the training regularization term (H), as stated in lines 155160. The comment suggests that this is confusing because the training regularization term (H) requires temperature calibration, yet temperature calibration is applied after training. The reviewer also points out that reducing entropy may make predictions more confident, which is counter to the paper\"s motivation to calibrate the networks. The comment provides a logical reasoning and a specific example to support the claim of confusion, making it 4. However, it could be strengthened by providing more detailed references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential source of confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. It points out that the training regularization term (H) requires temperature calibration, yet temperature calibration is applied after training. This is a clear and actionable observation that could help the authors clarify their explanation or correct any inconsistencies in their work. Additionally, the comment highlights an issue with the motivation of the paper, noting that reducing entropy may make predictions more confident, which is counter to the paper\"s goal of calibrating the networks. This feedback is valuable as it prompts the authors to reconsider their approach and potentially adjust their motivation or methodology. Overall, the comment is 4 as it provides clear and actionable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out the absence of an important reference, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. It also highlights the importance of discussing similarities and differences with Lista and placing the paper in appropriate context. This feedback provides a clear and concrete action for the authors to take, which is to include the missing reference and discuss the similarities and differences with Lista. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing reference, \"Lista,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the importance of discussing similarities and differences with the paper \"Lista\" and placing the paper in appropriate context. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. The reviewer provides a link to the paper and highlights the similarities and differences between the proposed work and \"Lista.\" This provides a clear and specific rationale for the claim, making it 5. The authors can easily follow the reference and understand the importance of including it. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a critical omission in the paper, specifically the absence of an important reference, \"Lista,\" which is relevant to the idea of unrolling. It highlights the importance of discussing similarities and differences with \"Lista\" and placing the paper in appropriate context. This feedback is clear and actionable, as it directs the authors to include the missing reference and address the relationship with \"Lista\" in the paper. By providing this guidance, the comment helps the authors improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the linear program in Theorem 3 needs to be explained more intuitively. It acknowledges that this is a main theorem but suggests that providing an explanation of the objective and constraints in (3) would be beneficial for the reader. This feedback is clear and provides a concrete action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of the linear program in Theorem 3 and the objective and constraints in (3). This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the linear program in Theorem 3 needs to be explained more intuitively. While it acknowledges that this is a main theorem, it does not provide specific reasoning or examples to support why this explanation is necessary or how it would benefit the reader. The comment lacks detailed justification or references to common practices or standards, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need to provide a more intuitive explanation of the linear program in Theorem 3. It acknowledges that this is a main theorem but emphasizes the importance of explaining the objective and constraints in (3) to enhance the reader\"s understanding. This feedback is clear and actionable, as it directs the authors to clarify the key components of the theorem for better comprehension. However, the comment could be more helpful if it offered suggestions on how to present this explanation or provided examples of how similar concepts have been explained in other works. Despite this, the feedback is 4 as it guides the authors toward improving the clarity and accessibility of their theorem."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions and points of confusion regarding the algorithm, specifically regarding the use of \"avg\" and the meaning of \"j\"\" and \"i\"\". While it identifies areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take to address these issues. The authors are left to infer that they need to clarify these points, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the use of \"avg\" and the meaning of \"j\"\" and \"i\"\". This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of Algorithm 2, specifically regarding the use of \"avg\" and the meaning of \"j\"\" and \"i\"\". It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification and does not make a claim that needs justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several areas of confusion and potential improvement in the paper, specifically regarding the clarity of Algorithm 2 and the use of \"avg.\" It points out that \"j\"\" and \"i\"\" are not defined, which is a critical oversight. The comment acknowledges the authors\" response and suggests that the initial scores should be kept, indicating that the authors have addressed some concerns. However, it does not provide specific guidance on how to clarify the algorithm or define \"j\"\" and \"i\".\" While it highlights important areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what aspects are missing or how to address these issues. The authors are left to infer that they need to improve the clarity, quality, novelty, and reproducibility of their work, but without concrete suggestions or examples, they may struggle to know where to focus their efforts. The lack of explicit instructions or detailed feedback makes this comment 3, as the authors can infer the need for improvement but are not given specific guidance on how to achieve it.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are missing these details, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment references \"Clarity, Quality, Novelty And Reproducibility,\" but does not provide specific examples or details from these sections. This lack of specificity and grounding makes it challenging for the authors to understand and address the issues effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or examples, the authors may struggle to understand the exact issues and how to address them. Therefore, the claim is considered 2, as it provides some indication of a problem but lacks sufficient detail for the authors to fully understand and act upon it.", "helpfulness_rationale": "The review comment identifies several areas where the paper is lacking, including clarity, quality, novelty, and reproducibility. However, it does not provide specific examples or detailed feedback on what aspects of these categories are missing or how they could be improved. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or guidance, the authors may struggle to understand and address the issues effectively. The comment lacks actionable suggestions or detailed feedback, making it 3 as it points out areas for improvement but does not provide the authors with concrete steps to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 45. It does not provide any explicit or implicit actions for the authors to take, such as suggesting further analysis or experiments to address the issue. The comment lacks guidance on how the authors might investigate or resolve the drop in accuracy. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the drop in accuracy after a certain order around 45 and asks if it is due to overfitting. This provides clear guidance on what needs to be addressed in the paper, namely the explanation of the drop in accuracy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification regarding the drop in accuracy in Figure 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 45. It does not provide any analysis or suggestions for the authors to address this issue, leaving them without actionable feedback or guidance on how to improve their draft. The comment is vague and lacks depth, making it 2 for the authors in understanding and addressing the issue. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of natural ablation studies, specifically mentioning the impact of pretraining on scratchGAN. It suggests that this is a crucial baseline to include, especially given the central argument against pretraining. The comment also includes minor comments and questions, such as the need for more discussion on the results. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to implement these changes or what specific aspects of the ablation studies should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of natural ablation studies, specifically mentioning scratchGAN and the need for a baseline with pretraining. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a baseline with pretraining and the need for more discussion on the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some natural ablation studies are missing, specifically mentioning the impact of pretraining on scratchGAN. The reviewer claims that this is a crucial baseline to include, as it relates to the central argument against pretraining. However, the comment lacks specific examples or detailed reasoning to support why this baseline is crucial or how it would impact the central argument. The suggestion is 3, as it provides a direction for improvement but requires more detailed justification to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of natural ablation studies, particularly the impact of pretraining on scratchGAN. This is a crucial baseline that the authors should consider, as it relates to the central argument against pretraining. Additionally, the comment includes minor comments and questions, such as the need for more discussion on the results. While the comment highlights important areas for improvement, it could be more helpful by providing specific suggestions on how to conduct these studies or what aspects of the results should be discussed. Overall, the comment is 4 as it directs the authors to a critical area for improvement and offers some guidance on enhancing their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention that the preprocessing in SI 6.5 is identical to that in Mnih et al. 7, but the evaluation is slightly different due to the absence of human starts. This feedback provides a clear and direct action for the authors to take, ensuring they are aware of the need to clarify this point in their paper. The comment is specific and concrete, giving the authors a clear idea of what to include in their draft to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to mention that the preprocessing is identical to that in Mnih et al. 7, despite the evaluation being slightly different due to the absence of human starts. This provides clear guidance on what the authors need to include in their paper to clarify this point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in SI 6.5 is slightly different from that in Mnih et al. 7 due to the absence of human starts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the evaluation in SI 6.5 is slightly different from that in Mnih et al. 7 due to the absence of human starts. This feedback is clear and actionable, as it directs the authors to clarify this point in their paper. By mentioning the source of the preprocessing, the authors can ensure that they are transparent about the evaluation process and its differences from the original work. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining the implications of the difference or suggesting ways to improve the clarity of the evaluation. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper claims advantages over previous work in terms of efficiency but does not provide any metrics to substantiate these claims. This implies that the authors should include metrics to demonstrate the efficiency of their proposed method. However, the comment does not specify which metrics should be used or how they should be presented, leaving the authors with a general direction but without concrete guidance on execution. The action is explicit but somewhat vague, as it highlights the need for metrics but does not provide detailed instructions on how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss advantages over previous work in terms of efficiency. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of metrics to demonstrate the efficiency of the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method. However, it does not provide any supporting evidence or examples to substantiate this claim. Without specific metrics or references to previous work that demonstrate the efficiency of the proposed method, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that while the authors claim advantages over previous work in terms of efficiency, they do not provide any metrics to substantiate these claims. This is a critical point that could impact the credibility of the paper, as it lacks empirical evidence to support the efficiency claims. The comment highlights a clear area for improvement, prompting the authors to include metrics to demonstrate the efficiency of their proposed method. However, it does not provide specific suggestions on which metrics to use or how to present them, leaving some room for the authors to determine the exact approach. Overall, the comment is 3 as it points out a critical issue but could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the statespace, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment provides clear and direct actions, it does not specify how to implement these changes or what specific details should be included. The authors are left to infer the exact steps to take, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as providing more details about the statespace, whether it is finite or continuous, and the actions involved. The comment also questions the space in which theta lies and suggests that the authors should be precise in their explanations. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for more details about the statespace, whether it is finite or continuous, and the actions involved. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a lack of detail in the paper, specifically asking for more information about the statespace, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment highlights areas where the paper could be improved, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out potential gaps in the paper, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the method\"s effectiveness on general reasoning tasks or suggestions for potential improvements. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper discusses the method or where the comparison is made. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential weakness in the method, noting that it is less effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the method\"s effectiveness on general reasoning tasks. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it identifies a weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection. The reviewer provides a rationale for this suggestion, stating that LiDARbased segmentation is the best choice due to its ability to learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment does not provide explicit instructions or concrete steps on how to implement this change or what specific aspects of the current approach need to be adjusted. While the suggestion is clear, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this change could be implemented. The comment also lacks specificity regarding why LiDARbased segmentation is considered the best choice or how it would improve the paper. Without explicit references or detailed reasoning, the authors cannot confidently determine which parts of the paper need attention or how to address the suggestion. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that LiDARbased segmentation is a better choice for the downstream task than object detection, citing the ability of LiDAR to learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment lacks specific examples or detailed reasoning to support why LiDARbased segmentation is considered superior to object detection. The claim is 3, as it provides a logical argument but lacks the depth and evidence needed for full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a subjective opinion on the choice of downstream task, suggesting that LiDARbased segmentation is a better option than object detection. The reviewer provides a rationale for this suggestion, stating that LiDARbased segmentation can learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment lacks specific guidance or suggestions on how the authors might implement this change or what aspects of their current approach might need adjustment. While the feedback provides a direction for improvement, it does not offer actionable steps or detailed reasoning, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential contradiction between the objective of Equation (12) and the Inverse Proportional Odds (IPO) principle. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this contradiction or suggestions for clarifying the objective of Equation (12) in relation to IPO. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes, if any, are needed to resolve this issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the objective of Equation (12) and its relation to the Inverse Proportional Odds (IPO) principle. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the contradiction between the objective and IPO, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the objective of Equation (12) is in contradiction with the Inverse Proportional Odds (IPO) principle. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction between the objective of Equation (12) and the Inverse Proportional Odds (IPO) principle. This is a critical observation that could impact the validity and applicability of the work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their objective. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to resolving it. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the adaptation capacity. The comment lacks actionable details, such as recommending specific experiments or modifications to the model architecture. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, the comment does not specify which part of the paper this concern is related to, such as a specific section or experiment. Without explicit references, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the adaptation capacity might be an issue. Without such evidence or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. While the comment identifies a potential concern, it lacks specific guidance or suggestions on how the authors might address this issue or improve the adaptation capacity. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. While the comment identifies an issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should clarify or rename the variable to avoid confusion. The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1\" and \"Phase 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2, suggesting that this might be confusing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using \"$p$\" to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2 might be confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it points out a specific issue that could be clarified or addressed to improve the clarity of the paper. However, the comment could be more helpful if it provided suggestions on how to clarify or rename the variable to avoid confusion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper could benefit from a more detailed mathematical formulation, particularly in the appendix, to enhance the understanding of the approach. It also points out that the figure is confusing and recommends adding text labels to clarify its purpose and align it with the main contribution of the paper, which is improvements on the WiC task. The comment provides specific suggestions for reworking the figure to better align with the WiC task, offering actionable steps for the authors to improve their draft. The explicit nature of these suggestions and the concrete guidance on how to implement them make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"highlevel description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for a more detailed mathematical formulation in the appendix and the confusion caused by the figure, including the need for text labels and better alignment with the main contribution of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the highlevel description and figure are confusing and could benefit from a more detailed (e.g., mathematical) formulation and clearer alignment with the main contribution of the paper. The reviewer provides specific examples of what could be improved, such as adding text labels to the figure and aligning it with the WiC task. This feedback is supported by logical reasoning and specific suggestions, making the claim 4. However, the comment could be strengthened by providing more detailed examples or references to similar works that have successfully addressed similar issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the paper\"s presentation, suggesting that the highlevel description could benefit from a more detailed mathematical formulation, particularly in the appendix, to enhance understanding. It also points out that the figure is confusing and recommends adding text labels to clarify its purpose and better align it with the main contribution of the paper, which is improvements on the WiC task. The comment offers a clear and constructive suggestion for reworking the figure to better align with the WiC task, providing the authors with a concrete step to improve their draft. This level of detail and specificity makes the comment 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide specific guidance on which tasks should be included or how they should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they should consider additional benchmarking tasks but without detailed instructions on what those tasks should be or how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not specify which parts of the paper should include these tasks or which specific benchmarking tasks should be considered. Without explicit references to sections or specific tasks, the authors cannot confidently determine which parts of the paper need revision. The comment is 1 and lacks specificity, making it difficult for the authors to understand and address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide specific tasks or examples of what these tasks could be, nor does it explain why these tasks are necessary or how they would enhance the paper. While the suggestion is 3 in identifying an area for improvement, it lacks depth and actionable guidance, making it 3 but not comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. While it identifies the issue, it does not provide explicit guidance on how the authors should address this discrepancy. The comment lacks concrete suggestions or actions for the authors to take, such as suggesting a correction or clarification in the abstract or text. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and the text, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract statement about requiring the proposal distribution to upper bound the target everywhere is not true, as the authors themselves clarify in the text. However, the comment does not provide specific references or examples from the text to support this claim, making it difficult for the authors to verify the accuracy of the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This is a critical issue that could impact the validity of the paper\"s claims. However, the comment does not provide specific guidance or suggestions on how the authors might address this discrepancy or clarify the text. While it points out a potential problem, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an important issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the policy gradient and the phrases in question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. However, the comment does not specify which part of the paper these issues are located in, making it weakly grounded. The comment is specific in identifying the need for clarification and the potential issues with the lines mentioned. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions and observations about the policy gradient in Equation 6 and its relation to the optimal problem. It also points out an unnecessary phrase in Line 78 and a potential issue with Line 132. These are factual observations and questions that do not contain subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect, which could be a critical point in the paper. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification and potential improvements, it does not provide specific guidance or suggestions on how to address these issues. The feedback is 3 as it highlights areas that need attention, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the limitations of freezing the partitioning in the first iteration, which seems like a risky choice. This feedback is clear and provides a specific action for the authors to take, which is to address the limitations of this choice. The comment is concrete because it specifies the need for a discussion on the limitations, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the risky choice of freezing the partitioning in the first iteration and the need to discuss its limitations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. However, the comment does not provide specific reasoning or examples to support this claim. It lacks detailed justification or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of freezing the partitioning in the first iteration, noting that it may be a risky choice that assumes strong coverage of the initial data. It suggests that the authors should discuss the limitations of this choice, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided additional context or examples of how the authors might address these limitations. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. It acknowledges that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not provide specific guidance on what aspects need clarification or how to clarify them. It lacks concrete suggestions or examples of what the authors should focus on to improve the clarity of their approach. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. It mentions that the paper gets into highly technical details too quickly without explaining the overall approach and its benefits. However, the comment does not specify which parts of the paper need clarification or provide detailed comments on what is unclear. This makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. The reviewer mentions that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the concern. The lack of specific examples or references makes the claim 3, as it requires more detailed justification to be fully understood and addressed by the authors.", "helpfulness_rationale": "The review comment identifies several areas where the paper needs clarification, particularly regarding the interaction between the approach and knowledge about verbs to overcome reporting bias. It highlights that the paper dives into technical details too quickly without explaining the overall approach and its benefits, which can lead to confusion and lack of understanding. While the comment points out a critical issue, it does not provide specific suggestions or examples of what aspects need clarification or how to improve the clarity of the approach. This limits the authors\" ability to address the feedback effectively. Therefore, the comment is 3, as it identifies a significant area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests an explanation for the decision to use early stopping only based on link prediction accuracy. It does not provide suggestions for alternative explanations or methods to consider. The action is clear and concrete, as the authors know exactly what needs to be addressed: providing an explanation for the decision. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely an explanation for the decision to use early stopping only based on link prediction accuracy. The comment provides a clear direction for improvement by asking for an explanation of why not to average with type accuracy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use early stopping only based on link prediction accuracy, suggesting that an explanation is needed. However, it does not provide any reasoning or evidence to support why this decision might be problematic or inadequate. Without additional context or examples, the claim lacks verifiability, as it does not provide a clear basis for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further explanation, namely the decision to use early stopping only based on link prediction accuracy. It suggests that an explanation is needed, such as why not to average with type accuracy. This feedback is clear and actionable, as it directs the authors to provide a rationale for their choice, which could enhance the clarity and transparency of their methodology. However, the comment could be more helpful if it provided additional context or examples of alternative methods that could be considered. Overall, the comment is 4 as it guides the authors toward improving the clarity and justification of their methodology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the paper\"s statement about classimbalanced tasks in the fewshot learning setting. It explicitly asks the authors to provide concrete details on how to set a reasonable classimbalanced task, given the few examples available for each class. This feedback is clear and direct, providing a specific action for the authors to take to improve their draft. The request for concrete details is explicit, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"sampling classimbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the issue of setting a reasonable classimbalanced task in the fewshot learning setting. The comment provides a clear direction for the authors to provide concrete details on how to set a reasonable classimbalanced task, given the few examples available for each class. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim made in the paper regarding classimbalanced tasks in the fewshot learning setting. It suggests that the fewshot learning setting has only a few examples for each class, which raises the question of how to set a reasonable classimbalanced task. The reviewer requests concrete details to be provided to address this issue. However, the comment does not provide specific examples or references to support the claim that the current approach is unreasonable or inappropriate. This lack of detailed justification makes the claim 3, as the authors would need to provide additional information to fully address the reviewer\"s concern.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s statement about classimbalanced tasks in the fewshot learning setting. It points out that the fewshot learning setting has only a few examples for each class, which raises the question of how to set a reasonable classimbalanced task. The comment requests concrete details to be provided to address this issue. This feedback is 3 as it highlights a specific area that needs clarification, but it could be more beneficial if it offered suggestions on how to provide these details or what kind of information would be helpful. Overall, the comment provides a clear direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the chatgpt baseline is rudimentary and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. While the comment provides a clear action to test a fewshot approach and includes a suggestion for enhancing the baseline, it lacks specific guidance on how to implement these changes or what specific aspects of the fewshot approach should be tested. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment addresses the chatgpt baseline, suggesting that it is rudimentary and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. However, the comment does not specify which part of the paper discusses the chatgpt baseline or the fewshot approach, making it weakly grounded. The suggestion to include discourse relation information is specific, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the chatgpt baseline is \"very rudimentary\" and suggests testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. While the comment provides a logical reasoning for the need to test a fewshot approach and includes a suggestion for enhancing the baseline, it lacks specific examples or references to support the claim that the chatgpt baseline is \"very rudimentary.\" This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves.", "helpfulness_rationale": "The review comment identifies a weakness in the chatgpt baseline, suggesting that it is \"very rudimentary\" and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. This feedback is 3 as it provides a clear direction for improvement by suggesting a more comprehensive evaluation of the chatgpt baseline. However, the comment could be more helpful if it offered specific guidance on how to implement the fewshot approach or provided examples of how discourse relation information could be incorporated. Overall, the comment provides actionable suggestions but lacks depth and specificity, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. It points out that the authors only state that they estimate a layer\"s sensitivity by pruning, but do not provide details on how the actual pruning was done. The comment implies that the authors should provide more information on the pruning process to clarify the methodology. While the action is implicit, it is clear and concrete, as it specifies the need for more detailed information on the pruning process. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail on how the ground truth of sensitivity is achieved and the need for more information on the pruning process. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. The reviewer suggests that the authors should provide more information on the pruning process to clarify the methodology. However, the comment lacks specific examples or references to support the claim that the current explanation is insufficient. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is 3, as it provides a general direction for improvement but lacks the necessary evidence or justification to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved. It points out that the current explanation, which mentions pruning, lacks details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to provide more information on a crucial aspect of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs (at least 10) and ideally with errorbars. It also points out that the plotted curves are from single runs and might be subject to significant fluctuations. Additionally, it suggests that the models are small, so there is no excuse for not providing statistics. The comment provides clear and concrete actions for the authors to take, specifying the exact changes needed to improve the presentation of their results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results comparing standard vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting the results as a mean over many runs (at least 10) with errorbars, and it points out that the plotted curves are from single runs and might be subject to significant fluctuations. Additionally, it suggests that the models are small, so there is no excuse for not providing statistics. This provides clear guidance on how to improve the presentation of the results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with errorbars. The reviewer supports this claim by pointing out that the plotted curves are from single runs, which could be subject to significant fluctuations. Additionally, the reviewer suggests that the models are small, so there is no excuse for not providing statistics. This reasoning is logical and based on common knowledge about statistical analysis and model size. However, the comment could be strengthened by providing specific examples or references to similar studies that have used similar methods. Despite this, the claim is 4, as it provides a clear rationale for the suggested improvements.", "helpfulness_rationale": "The review comment provides clear and actionable feedback on the presentation of results comparing standard vs. evolutional dropout on shallow models. It suggests that the results should be presented as a mean over many runs (at least 10) with errorbars, which is a standard practice in statistical analysis. This suggestion is based on the observation that the plotted curves are from single runs, which could be subject to significant fluctuations. Additionally, the comment points out that the models are small, so there is no excuse for not providing statistics. This feedback is 5 as it guides the authors on how to improve the presentation and robustness of their results. By addressing these points, the authors can enhance the credibility and reliability of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific paragraph (L156166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and suggests that the authors clarify the concept of bandit algorithms and the figure. The comment provides explicit guidance on what needs to be clarified and improved, offering concrete suggestions for the authors to enhance the clarity of their draft. Therefore, the comment is 5, as it provides clear and specific instructions on how to enhance the understanding of the content.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paragraph number (L156166), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the paragraph, including the difficulty in understanding the content and the vagueness of the figure description. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paragraph is difficult to understand, particularly regarding the Gittins strategy and the figure. The reviewer suggests that the description is vague and provides examples of unclear phrases, such as \"Dashed lines indicate that the agent can plan ahead...\". However, the comment lacks specific references or detailed explanations to support the claim that the description is unclear or vague. While the reviewer provides some examples, the lack of detailed justification or examples from the text itself makes the claim 3. The authors would need to make a significant effort to understand and address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific paragraph (L156166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and suggests that the authors clarify the concept of bandit algorithms and the figure. The comment provides actionable feedback by highlighting specific areas that need improvement, which can help the authors enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to clarify the content or provided examples of clearer explanations. Overall, the comment is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and actionable, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (078079 and 08) and the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the evaluation metric to clarify the scale of the improvement and for comparability with other works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It references a previous work, Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020), where a similar expression was used. This claim is 3 as it provides a logical reasoning for why the evaluation metric should be included and references a specific example to support the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how this inclusion would enhance the clarity and comparability of the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work, which is relevant to the current paper. This feedback is specific and offers a concrete suggestion for improving the clarity and comprehensiveness of the paper. By addressing these points, the authors can enhance the transparency and reproducibility of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects of DVP performance should be examined. As a result, the authors are left without any clear direction on how to address this interest. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not specify which part of the paper this interest pertains to, such as a specific section or experiment. Without explicit references to sections or experiments, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of DVP performance should be examined or how the results should be interpreted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses interest in seeing how DVP performs on videos with different lengths. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual statement about the authors\" interest in the topic. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it lacks any specific guidance or suggestions on how the authors might explore this topic or what aspects of DVP performance should be examined. Without actionable feedback or detailed instructions, the comment does not provide much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to evaluate the approximation error in the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. It provides a clear and concrete action for the authors to take, specifying the exact calculation that needs to be performed. This level of detail makes the comment 5, as the authors know exactly what steps to take to address the issue. Therefore, the comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely evaluating the approximation error in the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the results. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective, noting that it has ignored the KLdivergence term in equation (3). It provides a clear and actionable suggestion by asking the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This feedback is valuable as it directs the authors to a specific area that needs attention and provides a concrete step for improvement. However, the comment could be more helpful if it explained why this evaluation is important or how it might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should further discuss the situations in which the losses help, particularly in specular areas. While the comment implies that the authors should provide more information about the effectiveness of the losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the effectiveness of the losses in specific situations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the situations in which the losses help, particularly in specular areas. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a particular area for further discussion, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the losses discussed in the paper might be particularly helpful in specular areas. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should further discuss the situations in which the losses help, particularly in specular areas. This feedback is 3 as it identifies a potential area for improvement by encouraging the authors to provide more detailed information about the effectiveness of their losses. However, the comment lacks specific guidance on how to implement this discussion or what aspects of the losses should be highlighted. While it points out a potential gap in the paper, it does not offer actionable steps for the authors to address this issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks clarity regarding its major contributions, specifically questioning whether analyzing previous work constitutes a contribution. However, it does not provide any explicit guidance or suggestions on how the authors might clarify or enhance their contributions. The comment is vague and lacks concrete steps for the authors to take, leaving them without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"major contributions\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the paper\"s contributions and the critique of analyzing previous work as a contribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding its major contributions and questions whether analyzing previous work constitutes a contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the major contributions are unclear and questioning whether analyzing previous work constitutes a contribution. This feedback is 3 as it points out a critical area for improvement, but it lacks depth and specificity. The comment does not provide guidance on how the authors might clarify their contributions or what specific aspects of the analysis or contributions are unclear. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also mentions that the answer is difficult to find in reference 30. This provides a clear and concrete action for the authors to take, which is to clarify the definition and usage of n_t in the algorithm. The comment is specific and provides a direct path for the authors to follow in order to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the \"appropriate number\" in line 225 and notes that the answer is difficult to find in reference 30. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of \"appropriate number\" in Algorithm 2, specifically in line 225, and notes that it is difficult to find the answer in reference 30. This claim is 3 as it highlights a potential issue with the clarity of the algorithm, but it lacks specific examples or references to the exact phrases or sections that need clarification. The reviewer could provide more detailed guidance on how to clarify the \"appropriate number\" or suggest alternative phrasing, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also points out that the answer is difficult to find in reference 30. This feedback is clear and actionable, as it directs the authors to clarify the definition and usage of n_t in the algorithm. By addressing this issue, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the explanation or offered additional context on the importance of n_t. Overall, the comment is 4 as it effectively guides the authors on a specific area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the claims about the mixing time being better in practice are not adequately supported by the experiments and suggests that the evidence provided is limited. However, it does not provide specific guidance on how the authors should address this issue or what additional evidence or experiments would be needed to support their claims. The comment lacks concrete suggestions or detailed instructions on how to improve the draft, leaving the authors uncertain about what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claims about the mixing time being better in practice, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficient support for these claims in the experiments and the limited evidence provided to practitioners. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims about the mixing time being better in practice are not sufficiently supported by the experiments. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specific evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims about the mixing time being better in practice, noting that the evidence provided is limited. It highlights the need for more robust support from the experiments to substantiate these claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional evidence could be included to strengthen their claims. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider this extension and determine how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to extend the protected feature to a vector form, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. This is a 3 suggestion as it points out a potential area for improvement in the paper. However, the comment lacks depth and does not provide specific guidance on how to implement this extension or what benefits it might bring. Without further explanation or examples, the authors may find it challenging to fully understand and act upon the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the reviewer should denote the vector representations of the words in the equation and whether they are L2normalized. Additionally, it asks for clarification on whether the nearest neighbor examples are computed using cosine or dotproduct. These questions are direct and specific, providing clear guidance on how the authors can improve their draft. The action is explicit and the authors know exactly what needs to be done to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223\" and \"following ones,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including denoting the vector representations of the words, whether the vectors are L2normalized, and the method used for computing nearest neighbor examples. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific aspects of the paper, such as the notation used for vector representations and the method for computing nearest neighbor examples. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas for clarification and improvement in the paper. It points out that the notation for vector representations of words is not clearly defined and suggests that the authors denote these somehow. Additionally, it asks whether the vectors are L2normalized and whether the nearest neighbor examples are computed using cosine or dotproduct. These questions provide the authors with actionable steps to improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to denote the vector representations or provided examples of how this could be done. Overall, the feedback is valuable but could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the proposed transductive method is not novel and appears related to a common approach in semisupervised learning, specifically selftraining methods. However, it does not provide any explicit guidance or suggestions on how the authors might address this concern or differentiate their method from existing approaches. The comment lacks actionable details, such as recommending specific ways to improve the novelty or clarifying what aspects of the method are similar to existing approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed transductive method is not novel and appears related to a common approach in semisupervised learning, specifically selftraining methods. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspects of the method are similar to existing approaches or how the authors might differentiate their work. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed transductive method is not novel and is related to a common approach in semisupervised learning, specifically selftraining methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the proposed transductive method is not novel and appears related to a common approach in semisupervised learning, specifically selftraining methods. However, it does not provide any specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might differentiate their method or improve its novelty. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the critique or enhance the novelty of their work. Therefore, the comment is rated as 2, as it identifies a potential weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide specific guidance on which papers should be included or how to improve the depth of the feature comparison. The authors are left to infer that they need to include these papers, but without concrete instructions or examples, the action remains vague. Therefore, this comment is 3, as it identifies an issue but lacks detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment explicitly mentions the feature comparison with prior work, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the shallow comparison and the absence of two relevant papers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is \"shallow\" and mentions the absence of two relevant papers. However, it does not provide specific details about which papers are missing or how they would enhance the comparison. Without these details, the claim lacks sufficient evidence or justification to be 5. The authors would need to infer the relevance of the missing papers and determine how they could improve the comparison. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the shallow feature comparison with prior work and the absence of two relevant papers. This feedback is clear and actionable, as it points out a gap in the literature review that the authors can address to enhance the depth and relevance of their analysis. However, the comment could be more helpful if it provided the names or titles of the missing papers, which would guide the authors in their literature search. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims of equivalence without verification. While the comment provides a specific suggestion for improvement, it does not offer concrete guidance on how to apply this suggestion or what specific changes should be made to the wording or claims. The authors are left to infer that they should be more cautious in their usage of the word \"equivalent,\" but without detailed instructions on how to implement this change, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it suggests a more cautious usage of the word \"equivalent\" and advises caution when making claims without verification. This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims without verification. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the usage of the word \"equivalent\" in the paper, suggesting that the authors should be more cautious in their claims and provide verification when making such claims. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accuracy of the paper. However, the comment could be more helpful if it offered examples of how the authors might verify the equivalence or provided guidance on how to present such verification. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a lack of understanding regarding the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests that there is a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects should be explored. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its critique of the lack of detailed analysis and the need for more comprehensive exploration of the different views. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the effectiveness of the multiview clustering approach and highlights the dominance of the paraphrase similarity view over other views. It suggests that there is a need for a more detailed analysis of the differences and similarities between the views, except for the task directly. The comment provides a logical reasoning for the need of such an analysis, but it lacks specific examples or references to support the claim that the other views are not useful. This makes the claim 3, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the effectiveness of the multiview clustering approach, specifically the dominance of the paraphrase similarity view over other views and their combination. It questions the usefulness of the other views and suggests that a more detailed analysis of the differences and similarities between them is needed. The comment highlights the lack of such analysis in the paper and provides a specific example of how the different views help in clustering paraphrases of the word \"slip.\" However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects should be explored. Overall, the comment provides valuable insights and actionable feedback, but it could be more comprehensive with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This implies that the authors should provide a more detailed explanation of the architecture in their paper. However, the comment does not specify how to improve the explanation or what aspects of the architecture should be covered. While the action is implicit, it is somewhat vague because it lacks concrete guidance on how to enhance the explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear explanation of the architecture and the reliance on external work for details. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This suggests that the paper lacks selfcontainment. However, the comment does not provide specific examples or references to the architecture or the external work, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the specifics themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained and that the authors rely on external work for details. This lack of selfcontainment makes the paper less accessible to readers who may not be familiar with the referenced work. The comment provides a clear and actionable suggestion for improvement, encouraging the authors to include more detailed explanations of the architecture in their paper. However, it could be more helpful if it offered specific guidance on how to improve the explanation or what aspects of the architecture should be emphasized. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out an inconsistency in the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback provides a clear and direct action for the authors to take, which is to ensure consistency in the typesetting of these terms. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore\" and \"BLEURT,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in typesetting these terms throughout the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"BertScore\" and \"BLEURT\" are inconsistently typeset throughout the paper, suggesting that maintaining consistency would be beneficial. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the clarity or readability of the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback is clear and actionable, as it provides a concrete suggestion for improving the draft by ensuring consistency in the typesetting of these terms. By addressing this issue, the authors can enhance the clarity and professionalism of their paper. However, the comment could be more helpful if it included examples of instances where the inconsistency occurs or suggested alternative ways to maintain consistency. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the presentation quality of the paper, such as the lack of informative content in certain tables and figures, the management of Fig. 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. While the comment highlights these areas for improvement, it does not provide explicit instructions or concrete guidance on how to address these issues. The authors are left to infer that they need to improve the presentation quality, but without specific suggestions on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures and tables, such as Figs 1&2, the \"Dataset\" columns in the tables, and Table 1 with a \"*\" appearing without indication of meaning. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issues with the presentation quality, such as the lack of informative content in certain tables and figures, the management of Fig. 3 and Table 2, and the use of a \"*\" in Table 1 without explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific issues with the presentation quality of the paper, such as the lack of informative content in certain tables and figures, the management of Fig. 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. These claims are supported by specific examples, which provide a clear rationale for the reviewer\"s concerns. However, the comment could be strengthened by providing more detailed explanations or references to similar issues in highquality publications, which would further substantiate the claim. Overall, the comment is 4, as it offers a thorough basis for the critique but could be more fully supported with additional evidence or references.", "helpfulness_rationale": "The review comment identifies specific issues with the presentation quality of the paper, such as the lack of informative content in certain tables and figures, the management of Fig. 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. This feedback is clear and actionable, as it points out specific areas where the paper could be improved in terms of clarity and professional standards. By addressing these issues, the authors can enhance the quality of their draft and increase its chances of being accepted for publication. However, the comment could be more helpful if it provided suggestions on how to improve the presentation quality or offered examples of best practices in academic publishing. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include related experiments to demonstrate the utility of the information axis tool. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct additional experiments, but the lack of explicit instruction means the action is not as direct as it could be.", "grounding_specificity_rationale": "The comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the conclusion or discussion, but this inference is not direct. The comment is specific in suggesting the need for related experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not provide any specific examples or references to support this claim. The comment is based on a logical assumption that additional experiments would be beneficial, but it lacks the necessary evidence or reasoning to fully substantiate the claim. As a result, the comment is considered 2, as it provides a suggestion but lacks the necessary support to be fully convincing.", "helpfulness_rationale": "The review comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. This feedback is 3 as it identifies a potential area for improvement by suggesting that the authors include additional experiments to validate their claims. However, the comment lacks specific guidance on what kind of experiments would be beneficial or how they should be conducted. While it points out a potential gap in the paper, it does not provide detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the text in lines 293295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" The reviewer implies that the authors should clarify this point to improve clarity. However, the comment does not provide specific guidance on how to clarify this point or what aspects need to be addressed. While the action is implicit, it is clear that the authors need to make changes to improve the clarity of the text. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 293295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement \"we manually observed the generated examples and find the results acceptable.\" This provides clear guidance on what aspect of the text is unclear and needs improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text in lines 293295, noting that it makes a particular point unclear. It points out that the statement \"we manually observed the generated examples and find the results acceptable\" is difficult for readers to understand and evaluate. While the comment highlights an area for improvement, it does not provide detailed guidance or suggestions on how to clarify the text or what specific aspects need clarification. This limits the comment\"s helpfulness, as it offers some direction but lacks depth and actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3. The authors can infer that they need to conduct experiments on realworld datasets, but the lack of explicit instruction makes it somewhat vague.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, it does not specify which part of the paper discusses the synthetic versus realworld datasets or the outofdistribution setting. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this suggestion fits, the comment lacks full grounding. It is specific in suggesting a change but does not provide detailed guidance on how to implement it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This feedback is 3 as it identifies a potential area for improvement in the paper\"s experimental setup. However, the comment lacks specific guidance on how to conduct these experiments or what specific aspects of the synthetic datasets might be problematic. While it points out a potential issue, it does not provide detailed instructions or examples on how to address it. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and actionable steps."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the proposed approach to pretraining lacks novelty because it follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or make their approach more novel. There is no guidance on potential modifications, alternative approaches, or additional research directions that could be explored. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed approach to pretraining, specifically mentioning that it follows the strategies used in ELECTRA. However, it does not specify which part of the paper discusses this approach, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the lack of novelty, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it follows the strategies used in ELECTRA. However, the comment does not provide any specific examples or references to the strategies used in ELECTRA, nor does it explain how the proposed approach is similar or different from those used in ELECTRA. Without detailed comparisons or references, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the novelty of the proposed approach to pretraining, noting that it follows the strategies used in ELECTRA. While this observation highlights a potential issue, it does not provide specific guidance or suggestions on how the authors might address this limitation or differentiate their approach from existing work. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward to enhance the novelty or impact of their work. Therefore, the comment is rated as 2, as it identifies a weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of motivation or need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function and that even a basic bisecting line search will converge linearly. The reviewer questions the impact of quadratic convergence on runtime and recommends conducting experiments to motivate the need for the analysis/algorithm. While the comment provides a clear suggestion for additional experiments, it does not explicitly instruct the authors on how to conduct these experiments or what specific aspects to focus on. The action is concrete but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of motivation or need for the Newton algorithm and the suggestion to conduct experiments to motivate the need for the analysis/algorithm. The comment provides a clear direction for improvement by recommending specific experiments to conduct. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation for the Newton algorithm in section 4 is lacking, as it is essentially a 1dimensional line search on a convex function. The reviewer questions the impact of quadratic convergence on runtime, suggesting that experiments along these lines would help motivate the need for the analysis/algorithm. While the comment provides a logical reasoning for the need of experiments, it lacks specific examples or references to support the claim that quadratic convergence is not beneficial. This makes the claim 3, as the authors would need to conduct the suggested experiments themselves to fully understand the impact. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the motivation or need for the Newton algorithm in section 4, noting that it is essentially a 1dimensional line search on a convex function. The reviewer questions the impact of quadratic convergence on runtime and suggests that experiments along these lines would help motivate the need for the analysis/algorithm. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to conduct experiments that could strengthen their analysis and motivation. However, the comment could be more helpful if it offered specific guidance on which experiments to conduct or how to interpret the results. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiomspecific and that the results merely indicate that better NMT systems are better at idiomatic translations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. It lacks concrete steps or detailed advice on how to make the methods more idiomspecific or how to improve the results. As a result, the authors are left without clear direction on how to address the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed upweighing and KNN methods\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the methods are not idiomspecific and that the results indicate that better NMT systems are better at idiomatic translations. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods are not idiomspecific and that the results indicate that better NMT systems are better at idiomatic translations. The comment supports this claim by referencing \"Figure 3,\" which presumably shows the impact of these methods on idiomatic vs. random data. However, the comment does not provide detailed analysis or specific examples from the figure to substantiate the claim fully. While the reference to Figure 3 suggests that the claim is based on empirical evidence, the lack of detailed explanation or additional context makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiomspecific and that the results merely indicate that better NMT systems are better at idiomatic translations. While the comment identifies a potential weakness in the methods, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methods to be more idiomspecific. The feedback is 3 as it points out a potential limitation, but it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the volume calculation and the number of biases, suggesting that the authors should clarify this issue. It also mentions that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. The reviewer finds the presence of C biases confusing. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the volume calculation and the number of biases, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the volume calculation and the number of biases, as well as the confusion regarding the presence of C biases. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the volume calculation and the number of biases are incorrect, suggesting that the resulting volume should be WxHx1 and that the bias is a scalar. The reviewer also points out that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion about the number of biases and the confusion regarding C biases. The authors would need to further investigate and clarify these points to fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the volume calculation and the number of biases, suggesting that the resulting volume should be WxHx1 and that the bias is a scalar. It also points out that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. The reviewer finds the presence of C biases confusing. This feedback is 3 as it highlights a potential issue with the paper\"s mathematical modeling, which could be clarified or corrected. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending a specific approach or clarifying the confusion regarding the biases. While it provides some insight, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the smoothed GT shapes should be shown in Figures 3 and 5 to enhance the understanding of the reconstruction quality. This is a clear and direct action for the authors to take, as it provides a specific request for visual clarity. The comment also mentions a minor concern, which may be a suggestion for further improvement, but it is not the primary focus of the action. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure. 3\" and \"Figure. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of smoothed GT shapes to enhance the understanding of the reconstruction quality. This provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the understanding of the reconstruction. The comment lacks specific examples or detailed explanations, making it difficult for the authors to fully understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to enhance the clarity of the paper by showing the smoothed GT shapes in Figures 3 and 5. This feedback is clear and direct, offering a concrete way for the authors to improve the visual representation of their results. Additionally, the comment acknowledges a minor concern, which could be further elaborated upon to provide even more detailed guidance. Overall, the comment is 5 as it offers a clear path for the authors to improve their draft, making it easy for them to understand and act upon the feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the generalizability of the method to other domains and questions the selection of 21 event types from Freebase. It explicitly asks for clarification on how these event types are selected and what the coverage is on the 33 event types in the ACE data. This provides clear and direct actions for the authors to take, such as explaining the selection process and providing more details on the coverage. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2 line 262,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the selection of 21 event types from Freebase and asking about their coverage on the 33 event types in the ACE data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of 21 event types from Freebase. It asks for clarification on how these event types are selected and what the coverage is on the 33 event types in the ACE data. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the selection process is problematic. The authors would need to make a significant effort to understand and address the concern, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the method to other domains, specifically questioning the selection of 21 event types from Freebase and their coverage on the 33 event types in the ACE data. This is an important point that could impact the applicability and robustness of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the generalizability of their work. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to cite and discuss important references for domain adaptation in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for references and discussions on domain adaptation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, namely references and discussions on domain adaptation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact references that are missing. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of important references for domain adaptation. It explicitly instructs the authors to cite and discuss these references in the revised manuscript. This feedback is clear and actionable, as it provides a direct and specific direction for improvement. By addressing this issue, the authors can enhance the comprehensiveness and relevance of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps to take. It lacks concrete details on how to verify the suspicion or improve the model. As a result, the authors are left without clear instructions on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the hyperparameters and the potential issue with the model\"s performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the suspicion. As a result, the claim is 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. This is a relevant observation that could impact the validity of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or verify the suspicion. It does not provide actionable steps or detailed feedback on how to improve the presentation or analysis of the results. As a result, the comment is 3, as it points out a potential issue but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that certain aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide any specific details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. The comment lacks explicit guidance or concrete steps for the authors to take, leaving them without a clear understanding of what needs to be addressed or how to address it. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"w.r.t. to corpora and datasets,\" indicating that it pertains to the experimental setup. However, it does not specify which part of the paper this pertains to, such as a particular section or table where these aspects are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what is unclear or poorly motivated about the corpora and datasets, making it difficult for the authors to understand and address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some aspects of the experimental setup were unclear or poorly motivated,\" specifically regarding corpora and datasets. However, the comment does not provide any specific examples or details about what is unclear or poorly motivated, making it difficult for the authors to understand the exact issues and address them. Without concrete examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that certain aspects, such as corpora and datasets, are unclear or poorly motivated. However, it does not provide any details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. Without specific guidance or actionable feedback, the authors are left without a clear understanding of what needs to be addressed or how to address it. Therefore, the comment is 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the model size. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"size of the model\" and the \"hourglass modules,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of the model size to competing approaches and the details on the size of each hourglass module. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the paper\"s analysis or conclusions. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters, noting that the authors do not provide details on the size of each hourglass module. This feedback is clear and actionable, as it prompts the authors to include this information in their paper. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details to include. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs clarification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the claim about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, it does not provide explicit guidance on how the authors should address this issue or clarify their claim. The comment lacks concrete suggestions on how to improve the clarity or accuracy of the claim, leaving the authors uncertain about what specific actions to take. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about treating climate emulation as a diagnostictype prediction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is misleading about the claim, namely that prior work (e.g., ClimateBench or ClimateSet) already does this. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, the comment does not provide specific examples or references to these works, nor does it explain how the proposed PACE method differs from these existing approaches. Without detailed evidence or comparisons, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a misleading claim in the paper regarding the novelty of treating climate emulation as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, already does this. This feedback is valuable as it highlights an inaccuracy in the paper\"s claims, which the authors can address to improve the clarity and credibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify or correct the claim, such as referencing the prior work or explaining the differences between the proposed method and existing approaches. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it lacks detailed guidance on how to address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should move some visual results from the supplementary to the main paper. It also points out that there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The reviewer suggests condensing the illustration of the proposed network architecture from three figures to two, and using the extra space for visual results. This feedback provides clear and concrete actions for the authors to take, such as selecting specific visual results to include and condensing the figures. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the main paper and the supplementary material, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that some visual results should be moved from the supplementary to the main paper, and it provides a specific suggestion to condense the illustration of the proposed network architecture from three figures to two. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that visual results should be moved from the supplementary to the main paper, as there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The comment provides a logical reasoning by pointing out the lack of visual results in the main paper and suggesting that condensing the illustration of the proposed network architecture could make room for visual results. However, the comment lacks specific examples or references to support the claim that visual results are necessary or how they would enhance the paper. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should move some visual results from the supplementary to the main paper. It highlights the lack of visual results on crowd density estimation, which is the main experiment of the paper, and recommends condensing the illustration of the proposed network architecture from three figures to two. This suggestion is clear and constructive, as it offers a concrete way for the authors to improve the presentation and clarity of their work. By addressing these points, the authors can enhance the reader\"s understanding and engagement with their research. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether a test example is crucially different, such as a patient being \"British\" versus \"American,\" and whether this can be detected using the corpus residual value. While the comment implies that the authors should consider this issue, it does not provide explicit guidance on how to address it or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors can infer that it relates to the analysis or results section, but this inference is not direct. The comment is specific in its question about detecting crucial differences, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a relevant concern or how it could be addressed. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a thoughtprovoking question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. This question highlights a potential issue with the analysis and prompts the authors to consider whether their method can detect such differences. While the comment does not provide specific suggestions or guidance on how to address this issue, it does encourage the authors to think critically about their analysis and consider potential limitations. Therefore, the comment is 3 as it prompts the authors to consider a relevant aspect of their work. However, it could be more helpful if it offered actionable steps or examples to improve the analysis. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using the most popular WebQuestions benchmark set instead of WebQuestionsSP as the testbed. It provides a rationale for this suggestion, noting that using WebQuestions would be more intuitive, straightforward, and could facilitate direct comparison with mainstream QA research. While the comment explicitly states the action to take, it lacks concrete details on how to implement this change or what specific aspects of the WebQuestions benchmark set would be most beneficial. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"WebQuestionsSP\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of dataset and suggesting that using the more popular WebQuestions benchmark set would be more intuitive and straightforward. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP as the testbed. The reviewer provides a logical reasoning by explaining that using WebQuestions would be more intuitive, straightforward, and could facilitate direct comparison with mainstream QA research. However, the comment lacks specific examples or references to support the claim that WebQuestions would be more suitable for the task. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider using a more popular dataset, such as WebQuestions, as the testbed for their work. It offers a logical reasoning that using WebQuestions would be more intuitive, straightforward, and could facilitate direct comparison with mainstream QA research. This feedback is valuable as it guides the authors to make a more appropriate choice for their dataset, which could enhance the clarity and impact of their work. However, the comment could be more helpful if it provided specific examples or references to support the argument for using WebQuestions. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include analysis or results on other datasets, specifically mentioning ImageNet derivatives. It highlights the importance of verifying the effectiveness of the framework on these datasets and recommends presenting these results in the main paper. This feedback provides clear and concrete guidance on what the authors need to do to improve their draft, making it 5. The authors know exactly what additional analysis or results are needed and how to incorporate them into the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for analysis or results on other datasets, specifically ImageNet derivatives. This allows the authors to accurately identify the part of the paper being addressed, which is the analysis or results section. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on ImageNet1k or ImageNet100. This provides clear guidance on what additional analysis is needed to strengthen the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks analysis or results on other datasets, specifically ImageNet derivatives. It highlights the importance of verifying the effectiveness of the framework on these datasets and recommends presenting these results in the main paper. However, the comment does not provide specific examples or references to support why these datasets are important or how the results would impact the paper\"s conclusions. While the suggestion is logical, the lack of detailed justification or evidence makes it 3. The authors would need to make a significant effort to understand and address the suggestion, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should include analysis or results on other datasets, such as ImageNet derivatives. It highlights the importance of verifying the effectiveness of the framework on these datasets and recommends presenting these results in the main paper. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s comprehensiveness and rigor. By addressing this point, the authors can significantly improve the draft\"s impact and credibility. However, the comment could be more helpful if it included specific examples or guidance on how to present these results. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be better to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is explicit and provides a clear action for the authors to take, which is to update the paper to reflect the correct usage of these models. The suggestion is concrete, as it specifies the exact change needed in the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Abstract\" and \"Introduction sections,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy between how BigFive and MBTI are described in the abstract and introduction sections as models to be extended, versus their usage as datasets in the experiments. The comment provides a clear suggestion to correct this discrepancy by stating the models as datasets throughout the paper, unless there is a specific reason to extend the explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are stated as models to be extended in the abstract and introduction sections, while they are used as datasets in the experiments. The reviewer suggests that it would be better to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. The comment is 3 as it logically points out a discrepancy in the paper\"s description of these models. However, it lacks specific examples or references to support the claim that the models should be considered datasets rather than models. This makes the claim 3, as the authors would need to make a logical inference to address the issue.", "helpfulness_rationale": "The review comment identifies a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be more appropriate to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is clear and actionable, as it directs the authors to correct the discrepancy in their description of these models. By following this suggestion, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided additional guidance on how to present the extended explanation or why the models are being extended. Overall, the comment is 4 as it offers a concrete suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should clarify the generalization gaps in their work, specifically regarding the finetuning step in DIMES, and provide a comparison of DIMES with other methods on TSP100. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the generalization gaps and conduct a comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of generalization to the TSP instances, particularly the finetuning step in DIMES. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the generalization gaps and the comparison with other methods on TSP100. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the generalization gaps in their work, particularly regarding the finetuning step in DIMES, and provide a comparison with other methods on TSP100. While the comment identifies a potential issue with the generalization of DIMES, it lacks specific examples or detailed reasoning to support the claim that these gaps need clarification. The suggestion to compare DIMES with other methods is somewhat vague, as it does not specify which methods should be compared or how the comparison should be conducted. Therefore, the claim is 3, as it provides a direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the generalization of the finetuning step in DIMES and suggests that the authors should clarify the generalization gaps in their work. It also proposes a comparison with other methods on TSP100, which could provide valuable insights into the performance of DIMES. While the comment highlights an important area for improvement, it lacks specific guidance on how to clarify the generalization gaps or conduct the comparison. The authors are given a clear direction but may need more detailed instructions to fully address the feedback. Therefore, the comment is 3, as it provides a starting point for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This provides clear and direct actions for the authors to take, ensuring they know exactly what information is needed to improve their draft. The request for the hyperparameters is specific, and the mention of reproducibility highlights the importance of sharing these details. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what information is needed to improve the reproducibility of the results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for information, specifically asking for the final thresholds used for the results and the full set of hyperparameters. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual request for clarification and does not fit the criteria for a claim.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by requesting the final thresholds used for the results and the full set of hyperparameters. This information is crucial for reproducibility and understanding the methodology. However, the comment could be more helpful if it provided guidance on how to present this information or why it is important for reproducibility. Despite this, the feedback is clear and actionable, which makes it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. However, it does not provide any explicit or implicit actions for the authors to take. The comment implies that the authors should clarify their methodology or consider alternative methods for answer detection, but it does not specify how to do so or what specific changes should be made. Without concrete guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the potential inconsistency in the authors\" claim and suggests that it depends on the method/features used for answer detection, such as POS/dependency parse features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. It suggests that the authors\" claim is dependent on the method/features used for answer detection, such as POS/dependency parse features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. It points out that the authors\" claim is dependent on the method/features used for answer detection, such as POS/dependency parse features. This feedback is 3 as it highlights a potential weakness in the authors\" argument and suggests a direction for clarification or further exploration. However, the comment could be more helpful if it provided specific suggestions on how to address this inconsistency or how to better substantiate the claim. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper needs improvement, specifically noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should focus on improving the writing quality and expanding the related work section, but the comment lacks concrete details on how to achieve these improvements. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in identifying areas for improvement, such as the uneven distribution of space and the missing related work sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment lacks specific examples or references to support the claim that the writing is uneven or incomplete. Without detailed evidence or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2, as it provides some indication but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing quality of the paper, noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. This feedback is 3 as it highlights areas where the paper could be improved in terms of balance and comprehensiveness. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending which sections to prioritize or which additional related work to include. While it provides some direction, the lack of detailed advice limits its utility for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific line (Line 140) and raises a concern about the first column of Qo being replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to resolve it. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their assumptions, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the replacement of the first column of Qo by vo to form P\"o, which results in the first state not being reachable anymore. The comment further assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first column of Qo is replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment lacks specific reasoning or evidence to support these claims, such as examples or references to similar studies. This makes the claim 3, as the authors would need to infer the basis of the claim and potentially conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the first column of Qo is replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. While the comment highlights a potential problem, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what alternative assumptions might be considered. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings was tested. While it implies that the authors should address this assumption, it does not explicitly instruct them to do so. The comment is 3 because it provides a clear direction for the authors to consider testing the assumption, but it lacks concrete guidance on how to conduct the test or what specific aspects to focus on. Therefore, the authors can infer that they need to test the assumption but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment raises a question about the assumption that d_e are good replacements for entity embeddings, indicating that this assumption has not been tested. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its request for clarification on whether the assumption has been tested, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the assumption that d_e are good replacements for entity embeddings, suggesting that this assumption has not been tested. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or how it might impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a critical question about the assumption that d_e are good replacements for entity embeddings, suggesting that this assumption has not been tested. This is an important point that could impact the validity and reliability of the paper\"s conclusions. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what kind of testing would be appropriate. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the table or what specific changes could be made to enhance the information presented. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the factors in a table do not effectively convey more messages than pure text, and there is no additional information. However, it does not specify which table or part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity regarding what information is missing or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the use of factors in a table, suggesting that they do not effectively convey more messages than pure text. It points out the lack of additional information and implies that the table is not contributing to the overall understanding of the paper. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the table\"s effectiveness. Without specific advice or examples, the feedback is limited in its usefulness to the authors. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the simulation should be considered. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what kind of physical interactions are being considered or how they might impact the simulation. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, which could be a relevant consideration for the authors to address in their work. However, it lacks depth and does not provide any context or guidance on how this information might impact the simulation or the paper\"s overall contribution. Without further explanation or suggestions, the authors may find it challenging to understand the relevance of this question or how to address it. Therefore, the comment is 3, as it identifies a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the authors\" approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"pruning\" and \"distributed settings,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential need to find global top Q values of the metric over the average of gradients, which could impact acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients. This is a logical claim based on the observation that pruning is often used with large networks and that distributed settings are common for training. However, the comment lacks specific examples or references to support the claim that finding global top Q values is necessary to avoid breaking acceleration techniques like quantization and sparsification. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. This feedback is valuable as it highlights a potential gap in the authors\" discussion of pruning techniques and their impact on distributed settings. However, the comment could be more helpful if it provided specific examples or references to support the claim about the necessity of global top Q values. Overall, the comment is 4 as it directs the authors\" attention to an important aspect of their work that requires further consideration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether some subfigures in Figures 1 and 2 have been swapped by mistake. While it implies that the authors should check the figures and potentially correct any errors, it does not provide explicit instructions on how to do so or what specific subfigures might be affected. The action is implicit and somewhat vague, as the authors need to infer that they should verify the figures themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about whether some subfigures have been swapped by mistake, providing clear guidance on what needs to be checked. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking whether some subfigures in Figures 1 and 2 have been swapped by mistake. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the possibility of subfigures in Figures 1 and 2 being swapped by mistake. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or verify the accuracy of the figures. The comment lacks actionable feedback or detailed analysis, making it 3 as it points out a potential problem but does not assist the authors in resolving it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss the potential increase in false positives due to the dropout probe improving sensitivity. While it implies that this should be a substantial part of the discussion, it does not explicitly instruct the authors to include this in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue in their discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"dropout probe\" and its impact on sensitivity, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should discuss the potential increase in false positives due to the dropout probe. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the dropout probe improves sensitivity and finds a causal role for syntactic representations that previous approaches might have missed. However, it also suggests that this improvement could lead to an increase in false positives, which is a valid concern. The comment provides a logical reasoning for the potential increase in false positives but lacks specific examples or references to substantiate the claim. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific improvement in the sensitivity of the dropout probe and its ability to find causal roles for syntactic representations. It acknowledges the positive aspect of this improvement but also highlights a potential concern about the increased risk of false positives. The comment suggests that this should be a substantial part of the discussion, which is a valuable point for the authors to consider. However, the comment could be more helpful by providing specific suggestions on how to address this concern or discussing potential ways to mitigate the risk of false positives. Overall, the comment is 4 as it directs the authors to consider an important aspect of their work that could impact its validity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND and ICM). However, it does not provide any explicit guidance on how the authors should address this issue. The comment implies that the authors should include a discussion or comparison of these methods, but it lacks concrete instructions on how to structure this discussion or what specific aspects to cover. The action is implicit and somewhat vague, as the authors can infer that they need to include a discussion but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"exploration methods in RL literature, such as countbased methods and intrinsic motivations (RND, ICM),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion and comparison of these methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact nature of the omission. Without detailed explanations or references, the claim is not fully substantiated, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that it does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND, ICM). This is a critical oversight, as these methods are widely used and relevant to the field. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting which methods to discuss or how to structure the comparison. While it highlights a significant gap in the paper, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it implies that the authors should make the annotations larger, it does not provide specific guidance on how to achieve this or what size would be appropriate. The action is implicit and somewhat vague, as the authors need to infer that they should make the annotations larger but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the enlargement of annotations for better visibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 could be enlarged for better visibility. However, it does not provide any supporting evidence, reasoning, or examples to justify why the annotations are currently too small or how enlarging them would improve visibility. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it provides a specific suggestion for improvement, it lacks depth and does not explain why the current annotations are too small or how enlarging them would impact the figure\"s readability. The comment could be more helpful if it included additional context or examples to guide the authors on how to implement this suggestion effectively. As it stands, the feedback is 3, as it points out a potential issue but does not fully support the authors in addressing it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific changes should be made to the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the claim regarding the existence of multiple entities in both sentences and documents, including relation classification. The comment provides a clear critique of the claim and suggests that the authors should clarify or reconsider their statement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. This is a relevant observation that could impact the validity of the paper\"s claims. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue or improve their analysis. Without detailed feedback or constructive advice, the authors are left with only a general direction to consider, which does not fully support their efforts to improve the draft. Therefore, the comment is 3, as it identifies a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, but it does not provide explicit or implicit actions for the authors to take. It asks for clarification on the inference process and the coefficient of the p(L, E | X) term in line 307, but it does not instruct the authors on how to address these questions or provide guidance on how to improve the clarity of the writing. The comment also mentions missing hyperparameter details and suggests that ablation studies may not be welltuned, but it does not provide specific suggestions for improvement. Overall, the comment lacks actionable guidance, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the paper, but it does not specify which part of the paper these issues pertain to. It mentions \"line 307\" but does not provide context or details about what is being referred to. The comment also lacks specificity in terms of what is unclear or missing in the paper, such as the coefficient of the p(L, E | X) term or the hyperparameter details. Without clear references or specific guidance, the authors cannot effectively address the issues raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the clarity of the writing. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions are presented as observations without detailed explanation or justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the clarity of the writing. It questions the inference process and the coefficient of the term, asking for clarification on the basis of these elements. Additionally, it points out the lack of hyperparameter details and suggests that ablation studies may not be welltuned, which could impact the confidence of the results. The comment also notes that the writing is not careful and often impedes understanding. While it identifies several areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given direction on what to focus on but are not provided with actionable steps to improve their draft. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model mentioned in Line 152 is no longer stateoftheart and recommends replacing it with a phrase like \"very high performing model\" or similar. This feedback provides a clear and explicit action for the authors to take, specifying the exact change needed to update the text. The suggestion is concrete, as it directly instructs the authors on what to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the outdated nature of the model mentioned and the suggestion to replace it with a more current description. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model mentioned in Line 152 is no longer stateoftheart and recommends replacing it with a phrase like \"very high performing model\" or similar. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model mentioned in Line 152 is no longer stateoftheart. It provides a clear and actionable suggestion to replace the outdated reference with a more appropriate description, such as \"very high performing model\" or similar. This feedback is valuable as it directs the authors to update their text to ensure accuracy and relevance. However, the comment could be more helpful if it explained why the original reference is no longer relevant or provided examples of alternative phrases to use. Overall, the comment is 4 as it guides the authors to make a necessary correction, but it could be more comprehensive with additional context or suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper, including inappropriate subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment explicitly instructs the authors to provide a detailed explanation to verify these statements. While the action is clear, it is somewhat vague in terms of how to present the explanation, as it does not specify the exact format or content of the explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including inappropriate subjective statements, the need for proofs and references, and the laborintensive nature of designing effective architectures. It also mentions the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. However, the comment does not specify which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for proofs and references, and the need for a detailed explanation of the statements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims and suggestions, including the need for proofs and references to support subjective statements, the laborintensive nature of designing effective architectures, and the uncertainty regarding when to fuse multiscale features. The reviewer also suggests that models with skip connections could be considered implicit multiscale methods. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate these claims. The authors would need to provide more specific evidence or examples to fully address the reviewer\"s concerns. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed justification or references.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including inappropriate subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment provides clear and actionable feedback by suggesting that the authors should provide detailed explanations to verify these statements and address the issues raised. This guidance is valuable for the authors to improve their draft, making the comment 4. However, it could be more helpful if it offered specific examples or suggestions on how to present the explanations. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about how the proposed method compares with prior art. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so or offer guidance on how to conduct this comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison section. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section number \"3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking how the proposed method compares with prior art. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about how the proposed method compares with prior art. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification and does not make a claim that needs justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about how the proposed method compares with prior art. While it highlights an important area for comparison, it does not provide any guidance or suggestions on how the authors might address this comparison or what specific aspects of prior art should be considered. The comment lacks actionable feedback or detailed advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as 2, as it identifies an area for improvement but does not offer sufficient guidance for the authors to act upon."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the analysis could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that the authors should explore potential biases in the data and compare them across different languages/nationalities. While the comment does not explicitly instruct the authors to conduct this analysis, it provides a clear direction for improvement by highlighting a specific area that could be expanded upon. The action is implicit but concrete, as it points to a specific aspect of the analysis that could be enhanced. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the analysis could be more detailed by exploring potential biases in the data and comparing them across different languages/nationalities. This provides clear guidance on what the authors could address to improve their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that there might be interesting observations to be made about biases towards different languages/nationalities. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that such observations would be interesting or valuable. Without additional context or evidence, the claim remains somewhat vague, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the analysis, suggesting that the \"language/nationality\" section could be more detailed by exploring potential biases across different languages/nationalities. It implies that there might be interesting observations to be made about these biases, which could enhance the analysis and contribute to the paper\"s overall quality. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this analysis or what specific observations might be interesting. This limits the comment\"s helpfulness, as it points out an area for improvement but does not provide detailed guidance on how to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. While the question implies that the authors should consider exploring other properties, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore other feature properties. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this discussion might be relevant. The authors can infer that it relates to the methodology or approach sections, but this inference is not direct. The comment is specific in its suggestion to explore other properties of features, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the approach. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a pertinent question about the use of other properties of features in addition to norm, suggesting that this could be necessary and helpful for the approach design. This is a valuable point as it prompts the authors to consider alternative ways to enhance their methodology. However, the comment lacks specific guidance or examples on which properties might be beneficial or how to incorporate them into the approach. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential area for enhancement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. However, it does not provide explicit guidance on how to address these weaknesses or suggest specific changes. The authors are left to infer that they should make changes to the method, but without detailed instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. The comment also questions why the d is a simpler network. However, it does not provide specific suggestions or examples on how to address these issues, making the comment somewhat specific. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the method is mostly constructed on top of previous methods, lacks network changes or losses, and questions the use of two SIRENs for f and d. The reviewer also questions why the d should be a simpler network. While the comment identifies specific weaknesses, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the basis of the critique and determine how to address it. Therefore, the comment is 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. It questions why the d should be a simpler network and suggests that the method is mostly constructed on top of previous methods. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how to address these weaknesses. The authors are left with a general understanding of the issues but without actionable steps to improve their draft. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the RQ1 mentioned in the paper is redundant and does not provide additional information. It also proposes an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reviewer provides a specific reference to a related work that could guide the authors in conducting this analysis. While the comment implies that the authors should reconsider their RQ1 and explore the proposed analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1\" and \"RQ2\" and \"RQ3 tsne plots,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, suggesting that the RQ1 mentioned in the paper is redundant and does not provide additional information. The comment provides a specific suggestion to analyze the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the RQ1 mentioned in the paper is redundant and does not provide additional information. It suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reviewer provides a reference to a related work, which supports the claim by suggesting a specific direction for further analysis. This provides a clear and robust basis for the claim, making it 4. However, the comment could be strengthened by including more detailed reasoning or examples from the reference to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the RQ1 mentioned in the paper and suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in their analysis and interpretation of results. By suggesting a new angle for exploring the relationship between explicit and implicit hate information, the comment offers a valuable opportunity for the authors to enhance their work. However, it could be more helpful if it included additional details or examples on how to conduct the proposed analysis. Overall, the comment is 4 as it guides the authors toward a more meaningful and insightful exploration of their data."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the difference between the authors\" work and other works focusing on semantic face editing. While it implies that the authors should provide a comparison or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this point. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the difference between the authors\" work and other works focusing on semantic face editing. However, it does not specify which part of the paper this comparison should be made, nor does it provide details on what aspects of the work need to be compared. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for clarification on the difference between the authors\" work and other works focusing on semantic face editing. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the difference between the authors\" work and other works focusing on semantic face editing. While it identifies a potential area for comparison, it does not provide any specific guidance or suggestions on how the authors might address this difference or what aspects of their work need to be compared. The comment lacks depth and actionable feedback, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as 2, as it points out an area for improvement but does not offer detailed guidance or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to reduce the use of footnotes and move important content into the main body of the paper. It provides a specific example by suggesting moving details around parameter settings to the appendix. This feedback is clear and concrete, giving the authors a direct action to take to improve the draft. The suggestion to move content to the appendix is also detailed, providing specific guidance on how to structure the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of footnotes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of excessive use of footnotes and suggests moving important content into the main body of the paper. The comment provides a specific example by suggesting moving details around parameter settings to the appendix. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that footnotes are used excessively in the paper, which is distracting. It suggests that much of the content is important and should be moved into the main body of the paper. The reviewer provides a specific example by suggesting moving details around parameter settings to the appendix. This suggestion is based on logical reasoning and common knowledge about the importance of main content versus supplementary information. However, the comment could be strengthened by providing more detailed examples or references to support the claim about the excessive use of footnotes. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that footnotes are used excessively and distract from the main content. It suggests that much of the important content should be moved into the main body of the paper. The comment provides a clear and actionable suggestion by providing an example of where to move content, such as parameter settings, to the appendix. This feedback is valuable as it directs the authors to prioritize the main content of their paper over supplementary information. However, the comment could be more helpful if it explained why the use of footnotes is distracting or provided additional guidance on how to balance the use of footnotes and main content. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference 2. However, it does not provide explicit instructions or suggestions on how the authors should address this question or investigate the impact of the GS module on the effective receptive field. The comment lacks concrete guidance on what specific analyses or experiments the authors should conduct to answer this question. As a result, the authors are left without clear direction on how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module\" and suggests that the effective receptive field can be computed from a reference 2. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks a question about the effectiveness of the GS module and suggests that the authors investigate how the effective receptive field changed after applying it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the effectiveness of the GS module in propagating context information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference 2. This is an interesting point that could lead to further exploration and analysis of the GS module. However, the comment lacks specific guidance or suggestions on how the authors might investigate or analyze the impact of the GS module on the effective receptive field. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network computing the value functions for the states during the finetuning stage. While the comment provides a clear action\u2014adding another head to the network\u2014it does not specify how to implement this addition or what specific changes are needed in the code or methodology. The authors are left with a general idea of what to do but without detailed guidance on execution. Therefore, the comment is 3, as it provides a clear action but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network during the finetuning stage. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the LSTM is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting an additional step for the finetuning stage, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network during the finetuning stage. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network during the finetuning stage. This feedback is 3 as it identifies a potential area for improvement in the methodology, specifically regarding the use of LSTMs. However, the comment lacks depth and does not provide specific guidance on how to implement this suggestion or what potential benefits or challenges this change might entail. While it points out a potential area for enhancement, it does not offer detailed advice or examples that would help the authors fully understand and address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind combining G4RL with HRAC and asks whether G4RL requires HRAC\"s regularization in the latent space. While the comment implies that the authors should provide an explanation or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the question but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HRACG4RL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC\"s regularization in the latent space. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC\"s regularization in the latent space. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind combining G4RL with HRAC and asks whether G4RL requires HRAC\"s regularization in the latent space. This is a relevant question that could help the authors understand the basis of their method and its potential limitations. However, the comment does not provide any suggestions or guidance on how to address this question or improve the draft. While it points out an area for clarification, it lacks actionable feedback that would help the authors improve their work. Therefore, the comment is 3, as it identifies a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge some of the older works related to supervised, multilingual systems. While the comment implies that the authors should include this acknowledgment, it does not provide specific guidance on which works to mention or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works related to supervised, multilingual systems, providing clear guidance on what needs to be addressed in this section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works related to supervised, multilingual systems. However, it does not provide specific examples or references to these older works, nor does it explain why acknowledging them is important. Without additional context or reasoning, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works related to supervised, multilingual systems. While it identifies a potential gap in the literature review, it does not provide specific examples of older works to consider or explain why acknowledging them would be beneficial. The comment is 3 as it points out an area for improvement, but it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer points out that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their results. The suggestion is implied and lacks concrete details, making it 3. The authors can infer that they need to reconsider their sampling strategy, but the comment does not offer specific steps or examples on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the results in Table 2, particularly the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The comment further explains the potential reason for this underperformance, based on the authors\" argument about the predictor\"s accuracy in the good subregion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer provides a logical reasoning by pointing out that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is close. This reasoning is based on a logical assumption and provides a plausible explanation for the potential underperformance. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer provides a logical reasoning by pointing out that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is close. This feedback is 3 as it highlights a potential issue with the results and suggests a possible explanation for the observed underperformance. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or improve their results. Overall, the comment identifies a potential weakness but lacks detailed guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the time complexity of the proposed method, including the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the time complexity. The comment lacks concrete details on how to implement these improvements, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the time complexity, such as the potential for many users associated with a typical item and the larger number of hidden units compared to matrix factorizationbased methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high due to the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. While the comment provides some reasoning by mentioning these factors, it lacks specific examples or detailed explanations to fully substantiate the claim. The authors would need to infer the exact impact of these factors on the time complexity, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. It highlights that these factors could contribute to a high time complexity. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the time complexity. While it points out a potential weakness, it lacks actionable advice or detailed feedback that would help the authors make meaningful improvements. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the figures would be clearer if they explicitly mention \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a specific action for the authors to take, which is to add this information to the figures to enhance clarity. The comment is explicit and provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment suggests that many of the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, it does not specify which figures or sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting what needs to be clarified, namely the types of autoencoders used in the figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the figures. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that many of the figures would be more clear if they explicitly mention \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is 3 as it identifies a specific area where the figures could be improved for clarity. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why it is important. Additionally, it does not offer suggestions on how to address the issue of multiple types of autoencoders. While the comment points out a potential improvement, it could be more helpful with additional context and actionable advice. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This is a clear and direct request for additional details that the authors can easily address by providing the requested information. The action is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what information is needed, providing clear guidance on what needs to be added to the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for additional information about the computational requirements and runtime of the experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it prompts the authors to provide additional information about the computational requirements and runtime of the experiments. This is important as it can help the authors understand the feasibility and scalability of their work. However, the comment could be more helpful if it provided specific suggestions on how to present this information or what aspects to focus on. Despite this, the feedback is clear and actionable, guiding the authors to enhance the transparency and reproducibility of their work. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors only apply the meta sampler in a decoupled way, specifically when the features are fixed. It also requests more discussion on this aspect and asks for clarification on when the authors start applying the meta sampler. While the comment implies that the authors should provide more information on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more discussion and clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"meta sampler\" and the \"linear classifier,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on whether the meta sampler is applied in a decoupled way and requests more discussion on this topic. Additionally, it asks for clarification on when the meta sampler is applied, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It highlights a potential area for clarification and improvement in the paper, which is important for ensuring the accuracy and completeness of the methodology. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific aspects of the discussion should be expanded upon. Overall, the comment is 3 as it identifies a potential area for improvement but lacks detailed guidance on how to implement it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and encourages them to follow a cited AAAI paper on fairnessaware metrics like Equality Odds (EO). While the comment provides a specific recommendation to conduct more experiments and mentions a relevant paper, it does not explicitly instruct the authors on how to implement these suggestions or what specific aspects of the paper should be revised. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a vanilla metric and suggests conducting more experiments on datasets like COMPAS and Drug Consumption. It also references a specific paper, \"Exacerbating Algorithmic Bias through Fairness Attacks,\" which provides a clear context for the feedback. However, the comment lacks specificity regarding what aspects of the paper need improvement or how the authors should conduct these experiments. While it provides a clear direction, the lack of detailed guidance on execution makes it fully grounded but underspecific. Therefore, this comment is categorized as 4, aligning with category 4.", "verifiability_rationale": "The review point suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and mentions a specific paper for reference. However, the comment does not provide any specific reasoning or evidence to support why these additional experiments are necessary or how they would improve the paper. The mention of the cited paper suggests that the reviewer believes it could be relevant, but without further explanation or justification, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors use their own vanilla metric and lack related fairnessaware metrics like Equality Odds (EO). It suggests conducting more experiments on datasets like COMPAS and Drug Consumption, and references a specific paper for guidance. While the comment provides a clear direction for improvement, it lacks detailed guidance on how to implement these suggestions or what specific aspects of the paper should be revised. The feedback is 3 as it points out a gap in the paper but could be more comprehensive with additional details. Therefore, it is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is concrete, as it specifies the baselines to consider, but it is somewhat vague because it does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the evaluation or experimental sections, but this inference is not direct. The comment is specific in suggesting the inclusion of these baselines, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these baselines are relevant or how they would impact the evaluation. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why these specific baselines are relevant. While it points out a potential enhancement, it could be more helpful if it included more detailed reasoning or examples of how these baselines could be integrated into the evaluation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies two missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It suggests that providing insights into the value of h and its robustness is essential, and that the authors should consider using a constant set of parameters to evaluate performance. The comment is clear and provides specific actions for the authors to take, such as conducting an analysis of h and using a constant set of parameters for evaluation. The feedback is concrete and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model\"s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the importance of providing insights into the value of h and its robustness, as well as the use of different hyperparameter sets per dataset. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the value of the neighborhood size h and its influence on the model\"s performance are missing elements in the paper. It suggests that this is a key parameter and that providing insights into its value and robustness is essential. The comment also mentions the use of different hyperparameter sets per dataset, which is not ideal. However, the comment does not provide specific examples or references to support the claim that the value of h is crucial or that the use of different hyperparameter sets is problematic. While the claim is logical, it lacks detailed evidence or references to fully substantiate the argument. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies two important missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It highlights the importance of providing insights into the value of h and its robustness, as well as the ideal use of a constant set of parameters for performance evaluation. This feedback is clear and actionable, as it directs the authors to address specific gaps in their work that could enhance the clarity and robustness of their methodology. By providing detailed guidance on these aspects, the comment offers valuable assistance in improving the paper. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment implies that the authors should consider these questions and potentially address them in their paper, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these aspects of the model. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the model\"s performance or analysis. The comment is specific in its inquiry about the impact of missing modalities and the potential for leveraging additional modalities. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point poses a question about the impact of imperfect multimodal data on the model, specifically asking whether missing modalities affect the model\"s ability to construct higherorder interactions and polynomial tensors. The comment does not make a claim or express an opinion but rather seeks clarification or additional information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. This feedback is valuable as it prompts the authors to consider a critical aspect of their model\"s robustness and generalizability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or explore the impact of missing modalities. Overall, the comment is 3 as it directs the authors to consider an important aspect of their model but lacks detailed guidance on how to implement the suggested exploration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It provides a specific example of how this could be done by showing the frequency of these words in the dataset. The comment is explicit in its request for additional data analysis, providing concrete guidance on what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. The comment provides a specific example of how this could be done, making it clear and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. The reviewer provides a specific example of how this could be done, which is to show the frequency of these words in the dataset. This suggestion is based on logical reasoning and common knowledge about the nature of datasets and data analysis. However, the comment lacks references or detailed justification for why this analysis is necessary or how it would enhance the paper. Therefore, the claim is 3, as it provides a clear direction but could benefit from more detailed explanation or references.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by requesting the inclusion of statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It offers a clear example of how this could be done, which is to show the frequency of these words in the dataset. This feedback is actionable and can help the authors enhance the clarity and depth of their analysis. However, the comment could be more helpful if it explained why this analysis is important or how it would contribute to the paper\"s overall contribution. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors have not verified the stability of the OGEAug on outofdistribution (OOD) benchmarks, specifically mentioning DrugOOD. It suggests that the authors should verify the stability of their model on this benchmark, which is a clear and explicit action. However, the comment does not provide specific guidance on how to conduct this verification or what metrics to use. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"OGEAug\" and \"DrugOOD\" datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of stability verification on OOD benchmarks, such as DrugOOD, where SPE is validated. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not verified the stability of the OGEAug on outofdistribution (OOD) benchmarks, specifically mentioning DrugOOD. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors have not verified the stability of the OGEAug on outofdistribution (OOD) benchmarks, such as DrugOOD. It points out that the SPE model is validated on this dataset, highlighting a potential gap in the paper\"s evaluation. This feedback is clear and actionable, as it directs the authors to verify the stability of their model on OOD benchmarks, which could strengthen the paper\"s claims. However, the comment could be more helpful if it provided additional guidance on how to conduct this verification or what specific metrics to use. Overall, the comment is 4 as it effectively identifies a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to expand the related work section and compare their work to strong baselines that use coordinates. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and concrete, giving the authors a clear path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"related work section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need to expand this section and compare it to strong baselines that use coordinates. This level of detail provides full grounding and specificity, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests expanding the related work section and comparing it to strong baselines that use coordinates. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for expanding the related work section and comparing it to strong baselines that use coordinates. This feedback is specific and offers a concrete direction for the authors to enhance their draft, which could significantly improve the paper\"s comprehensiveness and rigor. By addressing this suggestion, the authors can better situate their work within the existing literature and provide a more robust foundation for their analysis. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the experiments should be expanded to include multiple seed experiments, which would provide a more robust evaluation. This suggestion is clear and concrete, as it specifies the exact action the authors need to take to improve their draft. The comment provides a specific direction for enhancing the evaluation, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Single Seed Experiments\" and the \"experiments in the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for multiple seed experiments to provide a more robust evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experiments are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. This claim is 3 as it logically argues that multiple seed experiments would offer a more comprehensive assessment. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s experiments, specifically the use of a single seed for training. It suggests that multiple seed experiments would provide a more robust evaluation, which is a valuable point for the authors to consider. However, the comment could be more helpful by providing specific guidance on how to implement multiple seed experiments or explaining why this is crucial for assessing the paper\"s claims. While it highlights an important area for improvement, it lacks detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, making it less accessible for many potential users. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more accessible or suggestions for alternative approaches. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, which makes it less accessible for many potential users. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how this requirement affects the accessibility of the method. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, making it less accessible for many potential users. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the accessibility of the method. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the accessibility of the proposed method, noting that an entire multiGPU setup is required for optimizations. This is a relevant point that could impact the practicality and adoption of the method by users who may not have access to such a setup. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or suggesting ways to make the method more accessible. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the current system with another system that also captures semantics, potentially using Ref2 as a baseline. It provides a clear and concrete action for the authors to take, which is to compare their system with another that captures semantics. However, it does not specify which aspects of the current system should be compared or how to implement the comparison. While the suggestion is explicit, the lack of detailed guidance on execution makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the current system with another system that captures semantics, potentially using Ref2 as a baseline. However, it does not specify which part of the paper this comparison should be made, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison with Ref2 as a baseline, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the current system with another system that captures semantics, potentially using Ref2 as a baseline. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref2 as a baseline. This is a clear and actionable suggestion that could help the authors improve their draft by providing a more comprehensive comparison. However, the comment could be more helpful if it specified which aspects of the current system should be compared or how to implement the comparison. Despite this, the feedback is 4 as it provides a concrete direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. While the comment identifies an area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should clarify this aspect of their work, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"user decoder\" and \"agent decoder,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the user decoder only uses information up to time step t and does not consider information from all time steps. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind the user decoder\"s use of information from only time step t and not from all time steps. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the paper\"s overall contribution. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the user decoder\"s use of information from the agent decoder, specifically questioning why it only uses information up to time step t and does not consider information from all time steps. This feedback identifies a potential area of confusion or limitation in the paper, prompting the authors to clarify their methodology or rationale. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider a controlled baseline that ablates heads at different locations in the model to address the confounding factor of head location in the induction and FV heads. This feedback provides a clear and explicit action for the authors to take, which is to implement a controlled baseline that can help isolate the effect of head location on ICL performance. The suggestion is concrete and provides a specific direction for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the issue of induction heads and FV heads being located at different layers within the model, which contributes to the difference in ICL performance when ablating induction heads versus FV heads. It suggests that a controlled baseline should be considered to address this confounding factor. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to include a controlled baseline is specific, as it provides a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be due to the confounding factor of head location within the model. The reviewer proposes a controlled baseline that ablates heads at different locations in the model to address this issue. However, the comment lacks specific examples or references to support the claim that head location is a significant contributing factor to the difference in ICL performance. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the difference in ICL performance when ablating induction heads versus FV heads. It suggests that the location of these heads within the model could be a contributing factor. The comment provides a clear and actionable suggestion to address this issue by proposing a controlled baseline that ablates heads at different locations in the model. This feedback is valuable as it guides the authors in designing a more robust experiment to isolate the effect of head location on ICL performance. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed this issue. Overall, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of a section on synonym identification under similarity measurement, which is a clear and direct action for the authors to take. It specifies the missing section and provides a specific suggestion for what should be included, namely a description of how the multiplechoice task is approached. This level of detail makes the action explicit and concrete, leaving no ambiguity for the authors on what needs to be added to their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on similarity measurement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a section on synonym identification, and provides a clear direction for improvement by suggesting a description of how the multiplechoice task is approached. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the absence of a section on synonym identification under similarity measurement. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their draft. By adding this section, the authors can provide a more comprehensive explanation of their approach to the multiplechoice task, which could enhance the understanding and applicability of their work. However, the comment could be more helpful if it offered suggestions on how to structure or present this section, such as highlighting key aspects or examples to include. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the action is implicit, it is concrete because it specifies what needs to be added (an overview of the workflow and the model). This provides the authors with a clear direction on how to enhance their draft, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, nor does it provide details on what aspects of the workflow and model should be covered. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in suggesting the need for an overview but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning or examples to support why this overview is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. This feedback is 3 as it identifies a potential area for improvement in presenting the key components of the paper. However, the comment lacks specific guidance on what aspects of the workflow and model should be covered or how this overview should be structured. While it points out a need for clarity, it does not provide detailed suggestions or examples to help the authors effectively implement this feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It also mentions that this information cannot be computed accurately without the same runtime as required for ridge regression. The reviewer suggests that this issue is not discussed in the paper and raises a similar concern regarding the surrogate sketch. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to discuss this issue but are not given clear instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to know the statistical dimension d_lambda of the design matrix A and the issue with computing it accurately without the same runtime as ridge regression. It also mentions a similar issue with the surrogate sketch. This allows the authors to accurately identify the parts of the paper being addressed, such as the sections discussing debiasing and surrogate sketch computation. The comment is specific because it clearly outlines the problem with the approach and suggests that it may not achieve its intended purpose due to the computational requirements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the debiasing approach requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without the same runtime as ridge regression. The reviewer suggests that this issue may defeat the purpose of the approach and points out that it is not discussed in the paper. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to substantiate the claim fully. The authors would need to further explore the issue and provide evidence to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It points out that this information cannot be computed accurately without the same runtime as required for ridge regression, which could lead to bias and defeat the purpose of the approach. The comment also notes that this issue is not discussed in the paper. While the comment highlights a significant concern, it lacks specific suggestions or guidance on how the authors might address this issue or discuss it in the paper. The feedback is 3 as it alerts the authors to a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to redefine Figure 3 as the expected quantities are scalars but shown as a vector. This is a clear and direct action that the authors can take to address the issue. The comment provides a specific guidance on how to modify the figure, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the redefinition of the figure to reflect the expected quantities as scalars rather than a vector. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figure should be redefined as the expected quantities are scalars but shown as a vector. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 5 as it provides a specific and actionable suggestion for improving the clarity of Figure 3. It points out that the expected quantities, which are scalars, are shown as a vector, and suggests redefining the figure to accurately reflect the data. This feedback is clear and direct, giving the authors a clear path to enhance the clarity and accuracy of their presentation. By addressing this issue, the authors can improve the readability and comprehensibility of their work, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. While the comment implies that the authors should conduct additional experiments, it does not specify which experiments to conduct or how to conduct them. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed models\" and the \"hypothesis\" related to learning representations for lowfrequency words. It also specifies the issue of lacking empirical evidence to test the hypothesis, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed models are particularly useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. It suggests that the authors should explore this aspect further by providing empirical evidence. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to make a significant effort to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. This feedback is clear and actionable, as it directs the authors to a specific area where they can enhance their work. However, the comment could be more helpful if it provided suggestions on which experiments or data sets to use for this empirical evaluation. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the importance of the global feature by comparing it with different resolutions of voxel features. It specifically mentions that the resolution of the 3D voxel should be considered and that the study should be included in Sec4.2. The comment provides a clear and explicit action for the authors to take, which is to conduct a study comparing the global feature with different voxel resolutions. The suggestion is concrete and provides a specific direction for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the study of the global feature and its resolution, and suggests comparing it with different resolutions of voxel features. This provides clear guidance on what the authors should consider in their analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the study of global features should include a comparison with different resolutions of voxel features. The reviewer provides a logical reasoning by explaining that methods like PiFu avoid using voxellike features due to their high computational and memory cost. The comment also suggests that studying the importance of the global feature in Sec4.2 would be more convincing by comparing it with different resolutions of voxel features. However, the comment lacks specific examples or references to support the claim about the computational and memory cost of voxel features. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct a study comparing the importance of the global feature with different resolutions of voxel features. It highlights the potential issue of high computational and memory cost associated with voxellike features and suggests that studying the global feature at different resolutions could be more convincing. This feedback is valuable as it guides the authors to a specific area for improvement and provides a clear direction for enhancing the paper\"s analysis. However, the comment could be more helpful if it included examples or references to similar studies that have successfully addressed this issue. Overall, the comment is 4 as it offers a concrete suggestion for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer suggests that it would be interesting to see development set trends with respect to these hyperparameters. While the comment implies that the authors should explore this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the trends in Table 3 and the impact of hyperparameters. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in seeing trends in the table, particularly regarding the behavior of PM+CL compared to PM or CL alone. The comment suggests exploring development set trends with respect to these hyperparameters, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer suggests that it would be interesting to see development set trends with respect to these hyperparameters. However, the comment lacks specific examples or detailed reasoning to support why this observation is significant or how it could be addressed. Without additional context or evidence, the claim is 3, as it requires the authors to infer the importance of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to see trends in the data, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer suggests that exploring development set trends with respect to these hyperparameters could be interesting and potentially insightful. This feedback is 3 as it points out a specific area for improvement and provides a direction for further analysis. However, it lacks detailed guidance or suggestions on how to conduct this analysis or what specific trends to focus on. To be more helpful, the comment could provide examples or additional context to guide the authors in their exploration. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of Figure 5, noting that there are many lines on top of each other, making it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added or clarified, but it is somewhat vague in terms of how to implement these changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the difficulty in understanding the figure due to the overlapping lines and suggests reporting additional metrics like flops or model size to provide a more concrete understanding of the results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the overlapping lines and suggests that the authors could report additional metrics like flops or model size to provide a more concrete understanding of the results. However, the comment does not provide specific examples or detailed reasoning to support why the current presentation is unclear or how the suggested metrics would improve clarity. The lack of detailed justification or examples makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some support but lacks the necessary detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 5, noting that the overlapping lines make it difficult to understand. It suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. This feedback is clear and actionable, as it directs the authors to make specific improvements to enhance the clarity and comprehensibility of their figures. However, the comment could be more helpful if it provided examples of how these additional metrics could be presented or explained. Overall, the comment is 4 as it offers concrete suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide specific guidance on what details are missing or how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment mentions the \"questions section below,\" which implies that it is referring to a specific part of the paper. However, without explicit mention of a section or table, the authors cannot confidently determine the exact part being addressed. The comment also lacks specificity regarding what details are missing or how they should be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not provide specific examples or reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to identify which details are missing or how they could address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide any further explanation or guidance on what details are missing or how the authors might address this issue. Without specific examples or suggestions, the comment lacks actionable feedback that could help the authors improve their draft. Therefore, it is 2, as it points out a potential weakness but does not offer a clear path for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation on oversmoothing should include a comparison with the EIGNN model under standard settings on realworld datasets, specifically in relation to variants that focus on dealing with oversmoothing, such as GCNII. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is concrete, as it specifies the type of comparison to be made, but it is somewhat vague in terms of how to implement it. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests a specific comparison to be made regarding the evaluation of oversmoothing, particularly with respect to the EIGNN model and variants that focus on dealing with oversmoothing, such as GCNII. However, it does not specify which part of the paper this evaluation is currently included in, making it weakly grounded. The comment is specific in suggesting a particular comparison to be made, but without explicit references to sections or figures, the authors may struggle to identify the exact location of the evaluation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation on oversmoothing should include a comparison with the EIGNN model under standard settings on realworld datasets, specifically in relation to variants that focus on dealing with oversmoothing, such as GCNII. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this comparison is necessary or how it would benefit the evaluation. Without additional context or examples, the claim remains 3, as it lacks the necessary support to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a specific comparison that could be made in the evaluation of oversmoothing, specifically by comparing the EIGNN model with variants that focus on dealing with oversmoothing, such as GCNII. This feedback is actionable as it provides a clear direction for the authors to enhance their evaluation by including a comparison that could offer insights into the performance of the EIGNN model under standard settings on realworld datasets. However, the comment could be more helpful if it provided additional context or examples of how this comparison might be conducted or what specific aspects to focus on. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that Figure 4 is confusing and notes that the columns are not explained in the text or caption. This provides a clear and direct action for the authors to take, which is to clarify the meaning of the columns in the figure and its caption. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion regarding the meaning of the columns in the figure and the lack of explanation in the text or caption. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The comment claims that Figure 4 is confusing and points out that the columns are not explained in the text or caption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it is confusing and that the columns are not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns and provide explanations in the text or caption. By addressing this issue, the authors can improve the clarity and accessibility of their figure, making it more understandable for readers. However, the comment could be more helpful if it provided suggestions on how to clarify the columns or offered examples of how similar figures have been effectively explained. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. However, it does not provide explicit guidance on how to include ablation analysis or what specific components should be analyzed. The action is implicit and somewhat vague, as the authors are left to infer that they need to include ablation analysis but without clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of ablation analysis in the main paper, which makes it difficult to pinpoint the source of the small performance gain. However, it does not specify which part of the paper lacks this analysis, such as the specific sections or experiments where it should be included. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in identifying the issue of lacking ablation analysis, but without explicit references to sections or experiments, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of ablation analysis, which makes it difficult to pinpoint the source of the small performance gain. This is a critical observation that could significantly impact the authors\" understanding of their work and its implications. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which components should be analyzed or how to conduct the ablation analysis. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any guidance or suggestions on how the authors should address this observation or what implications it might have for their work. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" which likely refers to a specific figure or table in the paper. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity because it does not detail what aspect of the noise rate of similarity labels compared to class labels is problematic or how it affects the paper\"s conclusions. Without additional context or suggestions for improvement, the authors may find it challenging to address the issue effectively. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand or verify the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any actionable feedback or suggestions for the authors to address this observation or how it might impact their work. Without additional context or guidance, the authors are left without a clear understanding of how to proceed or what improvements could be made. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a concern about the verification of the hypothesis, specifically noting that the experiment is not welldesigned. It suggests that the base model should be trained on the original dataset along with the adversarial set to better highlight the impact of the augmented adversarial examples. This feedback provides a clear and explicit action for the authors to take, which is to modify the experimental design to include the comparison between the original dataset and the mixture. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the verification of the hypothesis through an experiment that compares the base model trained on the original dataset with that trained on the mixture of original and adversarial examples. This provides clear guidance on how to improve the experimental design to better highlight the impact of the augmented adversarial examples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is not wellverified by the designed experiment, specifically mentioning that the base model is trained on the adversarial set only, while conventional methods train on the original dataset and the adversarial examples. The reviewer suggests that comparing the model trained on the original dataset with that trained on the mixture would be more convincing. This claim is 3 as it provides a logical reasoning for the need to compare the models, but it lacks specific examples or references to support the claim fully. The authors would need to make a significant effort to understand and address the issue, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental design, specifically the lack of verification for the hypothesis. It points out that the base model is trained on the adversarial set only, while conventional methods train on the original dataset and the adversarial examples. The reviewer suggests that comparing the model trained on the original dataset with that trained on the mixture would be more convincing. This feedback is clear and actionable, as it provides a specific suggestion for improving the experimental design to better verify the hypothesis. By addressing this issue, the authors can significantly enhance the credibility and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. There is no guidance on what aspects of the experiments are lacking or how they could be improved. Without explicit or implicit suggestions for improvement, the authors are left without a clear understanding of what changes are needed to enhance the credibility of their work. As a result, the comment lacks actionability, making it 1.", "grounding_specificity_rationale": "The comment mentions the CNN experiments, but it does not specify which part of the paper discusses these experiments. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the experiments are not convincing or how they could be improved. This makes the comment 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without additional context or reasoning, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This makes the claim 1, as it lacks the necessary evidence or justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment mentions that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without further explanation or guidance, the authors are left without actionable feedback on how to improve the experiments or address the perceived lack of convincing evidence. This lack of specificity and depth makes the comment 2, as it provides some insight but not enough to fully support the authors in enhancing their draft. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This explicit suggestion provides a clear and concrete action for the authors to take, as it directly instructs them to include a comparison with existing methods. The comment is specific in identifying the type of comparison needed, making it 5.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. The comment is specific in suggesting a particular comparison, but it lacks full grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison that could strengthen the paper\"s contribution. However, the comment lacks depth and does not provide specific guidance on how to conduct the comparison or what aspects of the SoTA approaches should be considered. While it points out a potential enhancement, it does not fully address the authors\" needs for improving their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify the rationale behind using freezing in MLS selection, but it is vague because it lacks concrete steps on how to implement this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MLS selection,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of freezing in MLS selection and suggesting that adaptive methods could be used instead. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the use of freezing in MLS selection and suggests that adaptive methods could be used instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why adaptive methods are preferable or how they would improve the selection process. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the use of freezing in MLS selection and suggests that adaptive methods could be a better approach. This feedback prompts the authors to reconsider their methodology and potentially improve their selection process. However, the comment lacks specific guidance or suggestions on how to implement the adaptive method or what aspects of the current methodology might be problematic. While it identifies an area for improvement, it could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should perform a similar analysis on the proposed knowledgeCLIP model as done in existing work that combines text and KGs. This feedback implies that the authors should conduct a closelyrelated analysis to test the robustness of their model, specifically by adding negation or changing entities in the text. While the comment does not explicitly instruct the authors to perform this analysis, it provides a clear direction for further exploration and experimentation. The action is explicit and concrete, as it specifies the type of analysis to be conducted, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed knowledgeCLIP model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting a closelyrelated analysis to test the robustness of the model, such as adding negation or changing entities in the text. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed knowledgeCLIP model should be tested for robustness by conducting a closelyrelated analysis, similar to existing work that combines text and KGs. The comment references an external work, providing a specific example of a related analysis. This reference supports the claim that such an analysis would be valuable for understanding the model\"s robustness. However, the comment does not provide detailed reasoning or evidence to fully substantiate why this analysis is necessary or how it would benefit the paper. While the reference provides some support, the comment could be strengthened by further explanation or justification. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct a closelyrelated analysis on the proposed knowledgeCLIP model. It references existing work that combines text and KGs, suggesting that the authors should perform a similar analysis to test the robustness of their model. This feedback is valuable as it encourages the authors to explore and validate their model\"s capabilities, which could enhance the paper\"s contribution. However, the comment could be more helpful if it provided specific guidance on how to conduct the analysis or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the use of p m in the numerator and p c in the denominator in Eq. 3, and questions the reason for this choice. It also suggests adding the variance for further improvement and recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides explicit actions for the authors to consider, such as using the variance for improvement and changing the notation to be consistent. These actions are concrete and provide clear guidance on how to address the issues raised. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Alg. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of p m in the numerator and p c in the denominator, suggesting that the authors consider adding the variance for further improvement. Additionally, it recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the use of p m in the numerator and p c in the denominator in Eq. 3, questioning the reason for this choice. It suggests adding the variance for further improvement and recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides logical reasoning by pointing out the inconsistency in notation and suggesting a potential improvement. However, it lacks specific examples or references to support the claim that using variance would improve the results. Therefore, the comment is 3, as it provides a logical basis for the suggestion but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation in Eq. 3, where p m is used in the numerator and p c in the denominator. It questions the reason for this choice and suggests that the authors consider adding the variance for further improvement. Additionally, it recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. This feedback is clear and actionable, as it provides specific guidance on how to address the notation issue and improve the paper. By suggesting alternative approaches and offering a rationale for the recommendation, the comment empowers the authors to make meaningful changes to their draft. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should provide a more comprehensive discussion about the computational complexity of the proposal and raises a question about whether the approach becomes prohibitive in certain settings. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed discussion and address the computational cost issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"additional cost\" and the \"computational complexity of the proposal,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the comprehensive discussion of the computational complexity and the potential prohibitive nature of the approach in certain settings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the computational cost of the proposed approach and questions whether it becomes prohibitive in certain settings. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the computational cost of the proposed approach. It suggests that the paper should provide a more comprehensive discussion about the computational complexity and raises a question about whether the approach becomes prohibitive in certain settings. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are given a direction to consider but are not provided with actionable steps or detailed advice on how to improve their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to clarify how novel values in the test set are handled for clarity. This is a direct and concrete action, as it specifies a specific area that needs more explanation. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how novel values in the test set are handled. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that the authors clarify how novel values in the test set are handled for clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where clarity is needed, specifically regarding how novel values in the test set are handled. By pointing out this gap, the comment provides the authors with a clear direction for improving the draft. However, the comment could be more helpful if it offered suggestions on how to clarify this aspect or provided examples of how other studies handle similar issues. While it highlights an important area for improvement, the feedback could be more comprehensive to be fully beneficial. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of indepth analysis on experimental results, specifically questioning why improvements are limited on one dataset and significant on another. This provides a clear and direct action for the authors to take, which is to conduct a more detailed analysis of the experimental results. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for an indepth analysis of the experimental results, particularly regarding the improvements of models on the offense detection dataset and the coarse stereotype set. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited improvements of models on the offense detection dataset and the significant improvements on the coarse stereotype set. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of indepth analysis on experimental results. It points out that the improvements of models are limited on one dataset and significant on another, which is a critical observation that could lead to a deeper understanding of the results. By highlighting this issue, the comment provides the authors with a clear direction for enhancing the paper\"s analysis and interpretation of the experimental findings. However, the comment could be more helpful if it offered suggestions on how to conduct the indepth analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests several actions for the authors to take, including training on labeled data, incorporating input mask explanation annotations for a few examples, and using modern backbone baselines like ResNet50 or DenseNet121 for the feature extraction layer. The reviewer also mentions that the current method may not work due to the small number of conv layers. However, the comment does not provide specific guidance on how to implement these suggestions or what specific changes should be made to the method. The action is implicit and somewhat vague, as the authors need to infer the details of how to apply these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the method of training on labeled data and incorporating input mask explanation annotations, as well as the use of modern backbone baselines like ResNet50 or DenseNet121 for the feature extraction layer. It suggests that the current method may not work due to the small number of conv layers. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the use of modern baselines and the potential limitations of the current method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed method may not work due to the small number of conv layers and the use of modern backbone baselines like ResNet50 or DenseNet121. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to similar interventions that have failed, making it difficult for the authors to understand the basis of the skepticism. As a result, the claim is 3, as it provides a logical argument but lacks sufficient evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several suggestions for improving the methodology, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like ResNet50 or DenseNet121 for the feature extraction layer. The reviewer also points out that the current method may not work due to the small number of conv layers, which is a valid concern. However, the comment lacks specific guidance on how to implement these suggestions or what specific changes should be made to the method. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it provides some direction but could be more comprehensive to be 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method. This implies that the authors should make a comparison between the baseline and the proposed method using the same hyperparameters and resources. However, the comment does not provide specific guidance on how to achieve this or which hyperparameters should be tuned. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of multiple hyperparameters and the extensive hyperparameter search, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the importance of ensuring that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment highlights the extensive hyperparameter search, it lacks specific examples or references to support the claim that this is necessary for a fair comparison. The reasoning is based on a general assumption, and without detailed evidence or examples, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the extensive hyperparameter search and the need to ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This is a relevant point that could impact the validity and fairness of the results. However, the comment lacks specific guidance on how to achieve this or which hyperparameters should be tuned. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the definition of perplexity provided in the paper is incorrect and suggests that it should be replaced with the correct definition. Additionally, it notes that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. While the comment provides explicit guidance on what needs to be corrected, it does not offer specific suggestions on how to revise the text or equations to ensure accuracy. The action is clear but lacks concrete details on how to implement the correction, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is incorrect about the definition of perplexity and the equation mentioned, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity provided in the paper is incorrect and suggests that it should be replaced with the correct definition. The reviewer also notes that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the paper regarding the definition of perplexity and the equation mentioned. It points out that the definition provided is incorrect and suggests that it should be replaced with the correct definition. Additionally, it notes that the equation does not resemble perplexity but instead appears to be crossentropy. This feedback is clear and actionable, as it directs the authors to correct a critical aspect of their work that could impact the understanding and interpretation of their results. However, the comment could be more helpful if it provided additional context or examples of the correct definition or equation. Overall, the comment is 4 as it effectively guides the authors in improving the accuracy and clarity of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add more baselines of graph contrastive learning and test them on common datasets. This is a clear and direct action for the authors to take, as it specifies the exact improvement needed and provides a concrete direction for testing. The comment is specific and provides a concrete action for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task\" and the \"compared baseline,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the missing baselines, such as MVGRL4 and gptgnn5, and suggests adding more baselines of graph contrastive learning. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline for the graph classification task is insufficient, specifically mentioning the absence of MVGRL4 and gptgnn5. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. It suggests adding more baselines of graph contrastive learning and testing them on common datasets, but without further explanation or examples, the claim remains 1. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the insufficiency of the baseline for the graph classification task. It points out the absence of certain baselines, such as MVGRL4 and gptgnn5, and suggests that the authors should add more baselines of graph contrastive learning and test them on common datasets. This feedback is clear and actionable, as it provides a concrete direction for improvement by suggesting specific additions and tests that could enhance the robustness and comprehensiveness of the paper. However, the comment could be more helpful if it explained why these additional baselines are important or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern with the evaluation of the proposed strategies, specifically mentioning the need to test the defense against an adversarial attack. It suggests that the defense should be evaluated against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. However, the comment does not provide specific guidance on how to implement this evaluation or what specific aspects of the defense should be tested. The action is implicit and somewhat vague, as the authors need to infer the details of how to conduct the evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation of the proposed strategies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern about the defense against an adversarial attack, including the need to evaluate the defense against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of the proposed strategies is insufficient, specifically mentioning the need to test the defense against an adversarial attack. The comment provides a logical reasoning by highlighting the potential vulnerability of the defense against an adaptive attack against their edge mapbased defense strategies. However, the comment lacks specific examples or references to support the claim that an adversary could optimize the perturbation to successfully attack the model. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the evaluation of the proposed strategies, specifically highlighting the need to test the defense against an adversarial attack. It points out that the current defense strategy considers purifying the input image before passing it to the model, but it does not address the potential vulnerability of the defense against an adaptive attack against their edge mapbased defense strategies. The comment suggests that the defense should be evaluated against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. This feedback is clear and actionable, providing the authors with a specific direction for improving the evaluation section of their paper. However, it could be more helpful if it included examples or references to similar studies that have successfully addressed this issue. Overall, the comment is 4 as it guides the authors toward a critical area for improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental results lack standard deviations, making it difficult to assess the significance of the results. This is a clear and direct action for the authors to take, as it instructs them to include standard deviations in their results. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014the inclusion of standard deviations\u2014and why this is important for assessing the significance of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results lack standard deviations, making it difficult to assess the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why standard deviations are necessary or how their absence affects the interpretation of the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting the absence of standard deviations. This is a clear and actionable point that can help the authors improve the clarity and significance of their findings. By including standard deviations, the authors can provide more robust and interpretable data, which is crucial for assessing the significance of their results. However, the comment could be more helpful if it offered suggestions on how to present these standard deviations or provided examples of how they might be incorporated into the results section. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the realism of the generated images or suggestions for potential improvements. As a result, the authors are left without any clear direction on how to enhance the quality of their generated images. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of limited realism in the generated images, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the quality of generated images by the proposed method, specifically noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it highlights an area for improvement, but it lacks specific suggestions or guidance on how to address the issue. The authors are informed of a potential weakness but are not provided with actionable steps to enhance the realism of their generated images. Therefore, the comment is 3, as it points out a problem but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest how the authors should address this discrepancy or clarify their statement. Without any guidance on how to improve the draft, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding Cycle Consistency loss is not entirely true, as it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific discrepancy in the paper regarding the Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This is a clear and actionable point that the authors can address to improve the accuracy and completeness of their description. However, the comment could be more helpful if it provided additional context or suggestions on how to clarify or correct the discrepancy. Overall, the comment is 4 as it points out a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"hyperspectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer suggests that the authors should clarify or replace the term with a more appropriate one. While the comment provides a clear suggestion for improvement, it does not offer specific guidance on how to address the issue, such as recommending alternative terms or explaining the context in which the term is used. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it is confusing and not standard in the field of hyperspectral imaging. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer provides a definition of hyperspectral imaging, which is a clear and accurate explanation. However, the comment could be strengthened by providing a specific example or context in which the term \"hyperspectral\" is used, which would further substantiate the claim. Despite this, the comment is 4 due to the clear definition of hyperspectral imaging and the logical reasoning behind the claim.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper by pointing out that the term \"hyperspectral\" is not a standard term in the field of hyperspectral imaging. It provides a clear and concise explanation of what hyperspectral imaging is, which helps the authors understand the issue and make a correction. The comment is actionable as it suggests that the authors should clarify or replace the term with a more appropriate one, which is a straightforward suggestion that can improve the clarity and accuracy of the paper. However, the comment could be more helpful if it offered suggestions on how to address the issue, such as recommending alternative terms or explaining the context in which the term is used. Overall, the comment is 4 as it provides clear guidance on how to improve the draft, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. It specifically mentions that ablation studies in Sections 3 and 4 demonstrate the effectiveness of each component, but the comment implies that a more detailed explanation is needed. While the action is implicit, it is concrete because it specifies what additional information is needed (e.g., how the performance of combining the Linformer and window attention in Big Bird is improved). Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"1), 2) and 3) mentioned above,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the contribution of each component to the final performance improvements. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. While it mentions that ablation studies are conducted, it does not provide specific examples or detailed reasoning to support why this additional information is necessary. The comment lacks specific examples or references to substantiate the claim, making it 3. The authors would need to infer the importance of the suggested information and determine how to incorporate it into their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about how each component contributes to the final performance improvements. It highlights that ablation studies in Sections 3 and 4 demonstrate the effectiveness of each component, but additional explanation is needed. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by explaining the contributions of each component. However, the comment could be more helpful if it offered specific examples or guidance on how to present this information. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the role of visual information, verify the effectiveness of the ablation study, and ensure that the experiment results are significant. The lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10\" and \"w/o perception module and w perception,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the ablation study, the lack of verification, and the questionable significance of the experiment results due to the sample size. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown, questioning the effectiveness of the ablation study and the significance of the experiment results due to the sample size. The comment provides some support by mentioning that the implementation detail of \"w/o perception\" is unknown and that the improvements are unlikely to be significant. However, the comment lacks specific examples or references to substantiate the claim about the effectiveness of the ablation study or the significance of the experiment results. This makes the claim 3, as the authors would need to further explore and substantiate the claims themselves.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. It highlights specific areas that need attention, such as the implementation detail of \"w/o perception\" and the potential for insignificant improvements with a sample size of 1000 users. While the comment provides some guidance on what needs to be addressed, it could be more helpful if it offered suggestions on how to improve the clarity or significance of the results. Overall, the comment is 3 as it points out important areas for improvement, but it lacks detailed guidance on how to address these issues."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This feedback implies that the authors should clarify the meaning of \"%p\" in their results notation. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a possible explanation or alternative notation. While the action is implicit, it is clear that the authors need to clarify the notation, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"notation for results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This provides clear guidance on what needs to be addressed to improve the clarity of the results notation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This claim is 3 as it highlights a potential issue with the clarity of the results notation, but it lacks specific examples or references to support the claim that \"%p\" is unclear. The authors would need to infer the meaning of \"%p\" based on the context, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the results notation, noting that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This feedback is clear and actionable, as it directs the authors to provide a clear explanation or definition of \"%p\" to improve the readability and comprehensibility of their results. By addressing this issue, the authors can enhance the transparency and accessibility of their findings, making the comment 4. However, it could be more helpful if it suggested alternative notations or provided examples of how \"%p\" might be interpreted. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific claim made by the authors on line 238, which is incorrect according to the Central Limit Theorem (CLT). It highlights that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment explicitly identifies the issue with the claim and provides a clear explanation of why it is incorrect. However, it does not offer any guidance on how the authors should address this issue or suggest alternative statements to correct the claim. The action is explicit but lacks concrete details on how to implement the correction, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made by the authors regarding the Central Limit Theorem (CLT) and why it is incorrect. The comment provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement regarding the Central Limit Theorem (CLT) is incorrect. The reviewer provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This logical reasoning and specific examples make the claim verifiable, as it provides a clear understanding of the issue and the basis for the critique. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the Central Limit Theorem (CLT) and points out multiple incorrect assertions. It provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it guides the authors to correct their claim and ensure the accuracy of their statements. However, the comment could be more helpful if it suggested alternative formulations or references to support the correct understanding of the CLT. Overall, the comment is 4 as it effectively highlights a critical issue and offers a constructive path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors need to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific area to focus on, making it 5. The authors know exactly what needs to be done to address the reviewer\"s concern, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the time complexity of the proposed policies mentioned in Section 4. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the proposed policies should be analyzed. However, it does not provide any supporting evidence, reasoning, or examples to justify why this analysis is necessary or how it would benefit the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is clear and actionable, as it explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This feedback is specific and directs the authors to a particular area of the paper that needs further attention and analysis. By addressing this suggestion, the authors can enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the analysis or what specific aspects of time complexity should be considered. Overall, the comment is 4 as it identifies a clear area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make. The comment lacks concrete suggestions or detailed instructions on how to improve the evaluation, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the human evaluation is discussed, the comment lacks full grounding. It is specific in its critique of the use of an automatic metric, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) in the human evaluation, suggesting that it weakens the convincingness of human evaluation. However, the comment does not provide any supporting evidence, reasoning, or references to justify why an automatic metric is less convincing than a human metric. Without such justification, the claim remains 1, as it lacks the necessary information to support the claim. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. This feedback highlights a potential weakness in the evaluation methodology, which could impact the credibility of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what alternative human metrics could be used. While it identifies a potential problem, it lacks depth and actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would be strengthened by including experiments across more diverse domains, specifically mentioning those in TDMPC 2. While the comment implies that the authors should expand their experiments to include more diverse domains, it does not provide explicit instructions on how to do so or which specific domains to consider. The action is implicit and somewhat vague, as the authors need to infer the need for more diverse experiments and determine which domains to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments prove the point made by the authors and recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of more diverse domains, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments prove the authors\" point effectively but recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. This claim is 3 as it provides a logical reasoning for expanding the experiments to enhance the paper\"s impact. However, it lacks specific examples or detailed justification for why these additional domains are necessary or how they would contribute to the paper. The suggestion is somewhat supported by the mention of TDMPC 2, but further elaboration would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the experiments effectively prove the point made by the authors but recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional experiments to enhance the paper\"s impact. However, the comment lacks specific guidance on how to implement this suggestion or which specific domains should be considered. While it provides a direction for improvement, it could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main contribution of the paper is not in proposing novel techniques but rather in demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There are no suggestions for how to enhance the novelty or innovation of the proposed techniques, nor are there any guidance on how to present the results or discuss the findings. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment discusses the simplicity of the LUQ design and the standard nature of the approaches presented in Section 5, suggesting that the main contribution is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not specify which part of the paper this discussion pertains to, such as sections or figures where these aspects are discussed. The authors can infer that it relates to the design and evaluation of the LUQ and the approaches presented, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the LUQ design is straightforward and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution is in demonstrating the effectiveness of a simple combination of existing techniques rather than proposing novel ones. However, the comment lacks specific examples or references to support this claim, making it 3. The authors may find it challenging to fully understand and address the critique without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the straightforward nature of the LUQ design and the standard approaches presented in Section 5, suggesting that the main contribution of the paper is in demonstrating the effectiveness of a simple combination of existing techniques. This feedback highlights a potential limitation in the novelty of the paper, as it does not propose novel techniques but rather demonstrates the potential of existing ones. However, the comment does not provide specific suggestions or guidance on how the authors might enhance the novelty or innovation of their work. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. The reviewer suggests that this could result in unfair comparisons. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their training approach or provide additional context to justify the running speed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup\" and \"training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed and unfair comparisons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. The reviewer supports this claim by referencing the authors\" claim of a 1.5x slower running speed. However, the comment does not provide specific examples or references to other methods or studies that could substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. This is a relevant observation that could impact the fairness of comparisons with other methods. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the running speed. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about relaxing the need to visit all ballaction pairs with each iteration and suggests exploring partial coverage. However, it does not provide explicit guidance or suggestions on how to address this issue or what specific actions the authors should take. The comment is vague and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"in continuation to the above remark,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about relaxing the need to visit all ballaction pairs with each iteration and exploring partial coverage. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification or suggestions regarding relaxing the need to visit all ballaction pairs with each iteration and exploring partial coverage. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about relaxing the need to visit all ballaction pairs with each iteration and exploring partial coverage. It suggests that the authors consider this approach and provides a clear direction for further exploration. However, the comment lacks specific guidance or suggestions on how to implement this relaxation or what specific assumptions or methods should be considered. While it points to a potential area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it provides a starting point for the authors but requires further elaboration to be fully actionable."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This is an explicit action, as it clearly specifies the need for additional datasets to be included in the paper. The comment is concrete because it provides specific examples of datasets that the authors should consider, which gives them a clear direction on what to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional datasets, but without explicit grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed technique should be evaluated on more datasets, specifically mentioning XNLI and XTREME, to demonstrate its generalizability to tasks with different levels of reasoning requirements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these datasets are particularly relevant or how they would impact the evaluation of the technique. Without additional context or explanation, the claim remains 3, as it lacks detailed justification or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This feedback is 3 as it identifies a specific area for improvement by recommending additional datasets to test the technique. However, the comment lacks depth and does not provide detailed guidance on how to select or analyze these datasets, nor does it explain why these specific tasks are important for demonstrating generalizability. While the suggestion is actionable, the comment could be more helpful with additional context or suggestions on how to effectively incorporate the new datasets. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the choice of baseline methods could be improved, specifically recommending RefNeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. While the comment provides specific examples of potential baselines, it does not explicitly instruct the authors to use these methods or explain how to incorporate them into their evaluation. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the choice of baseline methods could be improved, specifically recommending RefNeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. However, it does not specify which part of the paper these suggestions pertain to, such as the methodology or results sections. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting potential baselines. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved by comparing with other existing methods, such as RefNeRF and MipNerf. While the comment provides specific examples of potential baselines, it lacks detailed reasoning or evidence to support why these particular methods would be beneficial or how they would enhance the evaluation. The suggestion is based on general knowledge of existing methods, but without further explanation or justification, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the choice of baseline methods could be improved by comparing with other existing methods, such as RefNeRF and MipNerf. This suggestion is based on the authors\" need to evaluate the appearance decomposition part and larger outdoor scenes, respectively. By providing these examples, the reviewer helps the authors identify potential baselines that could enhance their evaluation and improve the robustness of their results. However, the comment could be more helpful if it explained why these specific methods were chosen or how they would contribute to the evaluation. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional context."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. This provides a clear and direct action for the authors to take, specifying where the details should be added and what needs to be included. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of implementation details of the proposed methods. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of implementation details of the proposed methods, which is a critical aspect of the paper. It suggests that these details should be included in Section 4.1, providing a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to a specific area where their draft could be strengthened, ensuring that the implementation details are transparent and accessible to readers. However, the comment could be more helpful if it offered additional guidance on how to present these details or what specific aspects should be included. Overall, the comment is 4 as it effectively points out a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the lack of empirical evaluation and comparison with other methods, indicating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. It suggests that the authors should provide empirical evaluation and comparisons with other methods to clarify the practical value of their contributions. The comment is explicit in its request for empirical evaluation and comparison, providing concrete guidance on what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that there is no practical value demonstrated and that the theoretical contributions may be significant but not adequately presented. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, which is a subjective claim. The reviewer supports this claim by stating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. However, the comment does not provide specific examples or references to support the claim that the theoretical contributions are significant or that the lack of empirical evaluation is a significant issue. This makes the claim 3, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of empirical evaluation and comparison with other methods. It highlights that the theoretical contributions may be significant but are not adequately demonstrated in the paper, making it unclear what the practical value of the contribution could be. The comment suggests that even a theoretical paper should attempt to argue for its significance, and it concludes that the current submission is not suitable for publication at NeurIPS. This feedback is clear and actionable, providing the authors with a specific direction to enhance the empirical evaluation and comparison sections of their paper. However, it could be more helpful if it offered suggestions on how to conduct the empirical evaluation or what specific comparisons should be made. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRMRL. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or explore more general tasks. The authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRMRL. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the paper\"s applicability to more general tasks, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is limited in its application to navigation problems and suggests that combining RL and planning has already been discussed in PRMRL. However, the comment does not provide specific references or examples from PRMRL to substantiate this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s applicability to navigation problems and suggests that the method discussed is already discussed in PRMRL. It points out that combining RL and planning has been discussed in the literature, which could be relevant to more general tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore more general tasks. While it highlights an area for improvement, the feedback lacks actionable advice or detailed suggestions, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider whether all feature spaces are wellsuited for 1NN and warns that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also recommends standardizing feature dimensions to avoid this issue. While the comment provides a clear action\u2014to evaluate the suitability of feature spaces and standardize dimensions\u2014it does not offer specific guidance on how to implement this suggestion or what metrics to use for evaluation. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suitability of feature spaces for 1NN and the potential issue with nonspherical Gaussian feature spaces. The comment provides a clear suggestion to standardize feature dimensions to avoid this issue, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes a claim about the suitability of feature spaces for 1NN and suggests that nonspherical Gaussian feature spaces may perform poorly. The comment provides a logical reasoning by explaining that standardizing feature dimensions can avoid this issue. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the reasoning is not as robust as it could be. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, specifically the suitability of feature spaces for 1NN. It points out that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment suggests a potential solution by recommending standardizing feature dimensions to avoid this issue. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft. However, it could be more helpful if it included examples or additional details on how to standardize feature dimensions or what metrics to use for evaluation. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the language used in section 3.1, lines 143 and 154, regarding the reward system in a Markov decision process (MDP). It suggests that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. While the comment identifies specific lines and issues, it does not provide explicit instructions on how to address them. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the reward system and the nature of each action. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1, line 143\" and \"line 154,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inaccuracy of the statement regarding rewards in standard MDP formulations and suggests clarifying the nature of each action. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. While the comment identifies specific lines and issues, it lacks detailed reasoning or references to standard MDP formulations or examples to fully substantiate the claim. This makes the comment 3, as it provides a basis for the critique but requires further elaboration to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in section 3.1, lines 143 and 154, regarding the reward system in a Markov decision process (MDP). It points out that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. This feedback is 3 as it highlights a potential misconception in the paper and provides a direction for clarification. However, the comment could be more helpful if it offered specific suggestions on how to clarify the reward system or the nature of each action. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include other baselines, such as those mentioned in related work 29, 5, 6. It also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered. The reviewer provides a specific suggestion to include the explanation of why the chosen baseline makes the most sense. However, the comment does not explicitly instruct the authors to add this explanation or provide guidance on how to integrate it into the paper. While the action is implied, it is not as concrete as it could be, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including other baselines, such as those mentioned in related work 29, 5, 6. It also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional baselines and providing a rationale for why they are relevant. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other baselines should be included, such as those mentioned in related work 29, 5, 6. However, it does not provide any specific reasoning or evidence to support why these baselines are necessary or how they would enhance the study. The comment also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered, but it does not elaborate on these responses. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of including these baselines and the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include other baselines, such as those mentioned in related work 29, 5, 6. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks specific guidance on how to integrate these baselines into the paper or why they are particularly relevant. While it points out a potential enhancement, it does not provide detailed instructions or examples on how to implement this suggestion. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280. While the comment identifies a specific problem, it does not provide any guidance on how the authors should address this issue. It lacks explicit instructions or suggestions for improvement, such as recommending alternative phrasing or explaining the context better. As a result, the authors are left without clear direction on how to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the pervasive use of the phrase \"to meet\" and how it is difficult to understand. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the pervasive use of the phrase \"to meet\" in the paper is difficult to understand. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280. This is a clear and actionable observation that can help the authors improve the clarity and readability of their draft. By pointing out this issue, the comment provides the authors with a concrete step to enhance the quality of their writing. However, the comment could be more helpful if it offered suggestions on how to rephrase or clarify the use of this phrase to make it more understandable. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of the method should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the network depth is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the method\"s limitations should be addressed or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking about the limitations of the method, specifically regarding the depth of the network in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. This is a relevant question that could prompt the authors to consider potential limitations of their method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of the method should be considered. Without actionable feedback or detailed analysis, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work should be evaluated in machine translation, which is seen as a more convincing approach due to its lower uncertainty per word. While the comment implies that the authors should consider this evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider machine translation as an additional evaluation method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the work should be evaluated in machine translation, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work only uses answer generation and summarization, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the proposed method in machine translation would be more convincing due to its lower uncertainty per word. However, the comment lacks specific examples or references to support the claim that machine translation is a more convincing evaluation method. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation, which exhibits lower uncertainties per word, would be more convincing. This feedback is 3 as it points out a potential weakness in the evaluation approach and suggests an alternative method for demonstrating the effectiveness of the proposed method. However, the comment could be more helpful if it provided specific examples or references to support the claim about the benefits of machine translation for evaluating the proposed method. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the dropout method used in the paper, specifically asking about the dropping rate and the number of masks generated. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the dropout\" and \"multiple stochastic masks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dropout method used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the dropout method used in the paper, specifically asking about the dropping rate and the number of masks generated. This feedback is valuable as it prompts the authors to clarify and provide more detailed information about their methodology, which could enhance the transparency and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar methods have been presented in the literature. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to demonstrate the effectiveness. This provides clear and concrete actions for the authors to take, such as including these comparisons and benchmarks to strengthen their claims. The comment is specific in detailing what additional information is needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed twostage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further justifications, comparisons with other singlestage attacks, and benchmarks with SOTA algorithms to justify the effectiveness of the technical contributions. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justification, suggesting that showing performance drop on fusion models alone is insufficient. The reviewer suggests that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to justify the technical contributions. This claim is 3 as it provides a logical reasoning for the need of additional comparisons and benchmarks to substantiate the effectiveness of the approach. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the need for further justification of the effectiveness of the proposed twostage optimization approach. It suggests that showing performance drop on fusion models alone is insufficient and that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to justify the technical contributions. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their paper by including these comparisons and benchmarks. By addressing this feedback, the authors can significantly improve the robustness and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that a specific sentence is confusing and suggests that the authors should clarify it. However, it does not provide any explicit guidance on how to improve the sentence or what specific changes should be made to make it clearer. The authors are left to infer that they need to revise the sentence, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the sentence, which is that it is confusing and lacks immediate clarity. However, the comment does not provide specific suggestions on how to improve the clarity or what aspects of the sentence are confusing. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that a specific sentence is confusing and lacks immediate clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why the sentence is confusing or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific sentence that is confusing and lacks clarity. It acknowledges that the reviewer understood the sentence after rereading it, but notes that it is not immediately obvious what is meant. This feedback is valuable as it highlights a potential issue with the clarity of the paper, which the authors can address to improve the readability and comprehension of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the sentence or offered alternative wordings that might improve its clarity. Overall, the comment is 3 as it points out a specific area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between Figures 1 and 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback implies that the authors should reconcile these figures to ensure consistency. However, the comment does not provide explicit instructions on how to address this issue, such as suggesting specific changes or clarifications. While the action is implied, it lacks concrete guidance on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the figures, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Fig 1 is inconsistent with Fig 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This claim is 3 as it highlights a discrepancy between the figures, but it lacks detailed explanation or justification for why this inconsistency is problematic or how it affects the paper\"s overall message. The authors might need to further investigate the implications of this inconsistency and determine if it affects the validity or interpretation of the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between Figures 1 and 2, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback highlights an inconsistency in the figures, which could impact the clarity and coherence of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending changes to the figures or explaining the rationale behind the discrepancy. While it points out a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify or modify the description of N_l^(s) to ensure that each node can attend to its own lowerlevel representation, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the ability of each node to attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This is a relevant point that could impact the understanding and interpretation of the model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the description. While it identifies a potential area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how the inequality after line 433 follows from Lemma 7. It suggests that the authors should clarify how Lemma 7 is applied to this inequality. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 433\" and \"Lemma 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the inequality after line 433 follows from Lemma 7, and it suggests that the authors should clarify how Lemma 7 is applied. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how an inequality follows from a lemma. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the derivation of an inequality after line 433, asking how it follows from Lemma 7. This is a clear and actionable point, as it prompts the authors to clarify the connection between the two. By addressing this question, the authors can improve the clarity and coherence of their paper, making it easier for readers to understand the derivation and application of the inequality. However, the comment could be more helpful if it provided suggestions on how to present this information or offered additional context to facilitate the explanation. Overall, the comment is 4 as it identifies a specific area for clarification and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several areas where the paper\"s main contribution is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to clarify the main contribution. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations and evidence to support their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically the novel properties of the proposed method and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of the main idea and the automation process. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. The reviewer suggests that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of specific evidence or references makes the claim 3, as the authors would need to make a significant effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s main contribution, which is the clarity of the novel properties and the method\"s ability to cope with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. This feedback is valuable as it highlights areas where the authors need to provide more detailed explanations and evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to clarify these aspects or provided examples of how similar methods have been effectively communicated. Overall, the comment is 4 as it directs the authors to address critical areas of their paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment questions the claim of using \"annotation guideline\" and points out that the paper only considered label name, label description, and fewshot examples, which may not fully capture the complexity of annotation guidelines in the IE domain. It provides an example from the TACRED slot filling guidelines to illustrate the depth of understanding required. However, the comment does not explicitly instruct the authors to revise their claim or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claim and provide more detailed information about their understanding of annotation guidelines. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim of using \"annotation guideline\" and provides a specific example of the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This allows the authors to identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the overstatement of using annotation guidelines and the need to provide more detailed information about the understanding of annotation guidelines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim of using \"annotation guideline\" and provides an example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This example is used to support the claim that the paper\"s prompts may not fully capture the depth of true guideline understanding. The reasoning is based on a specific example and provides a logical argument for the claim. However, the comment could be strengthened by referencing additional examples or sources to further substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper regarding the use of \"annotation guideline\" and provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This feedback is valuable as it highlights a potential weakness in the paper\"s claims and offers a concrete example to help the authors better understand the nuances of annotation guidelines. By addressing this point, the authors can improve the accuracy and clarity of their claims, which is highly beneficial for the paper\"s credibility and comprehensiveness. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their method to token pruning and token combination baselines, in addition to the BERTbaseline. This provides a clear and concrete action for the authors to take, specifying exactly what additional comparisons are needed to strengthen the experiment comparison. The comment is specific and direct, giving the authors a clear path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment comparison\" and the need to compare the method to token pruning and token combination baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional baselines for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because it only compares the method to the BERTbaseline. It suggests that the authors should compare their method to token pruning and token combination baselines. While the comment identifies a potential issue with the experiment comparison, it does not provide specific reasoning or evidence to support why the current comparison is insufficient. The suggestion to include additional baselines is logical, but the lack of detailed justification or examples makes the claim 3. The authors would need to further explore the rationale behind the need for these additional comparisons to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experiment comparison, noting that the authors only compare their method to the BERTbaseline. It suggests that the authors should also compare their method to token pruning and token combination baselines. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental evaluation by including additional baselines. By addressing this suggestion, the authors can strengthen their analysis and provide a more comprehensive comparison, which could improve the overall quality of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any specific guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending which weaknesses should be explored or how they could be demonstrated. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the authors did not show the possible weaknesses of the proposed model, but it does not specify which part of the paper this issue pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what weaknesses should be explored or how they could be demonstrated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by pointing out that the authors did not show the possible weaknesses of the proposed model. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific weaknesses should be explored. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of related work and experimentation with other extractthengenerate methodologies in the paper. It implies that the authors should include a related work section and experiment with other methods to demonstrate the novelty and effectiveness of their proposed system. While the comment does not explicitly instruct the authors to add a related work section or conduct additional experiments, the action is implied and concrete. The authors can infer that they need to address these gaps in their work, making the comment 4.", "grounding_specificity_rationale": "The comment addresses the idea of long document summarization and questions the novelty of the proposed system compared to previous extractthengenerate methodologies. It specifically mentions the absence of a related work section and the lack of experimentation with other extractthengenerate methodologies. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. While the authors can infer that it relates to the sections discussing the methodology and results, the comment is not fully grounded as it does not explicitly mention these sections. The comment is specific in identifying the need for a related work section and experimentation with other methods, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the novelty and effectiveness of the proposed system compared to previous extractthengenerate methodologies. It questions the absence of a related work section and the lack of experimentation with other methods. However, the comment does not provide specific examples or references to support the claim that the system does not offer any novelty or improvement over existing approaches. Without such evidence or reasoning, the claim remains 1, as it lacks the necessary justification to be considered 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of a related work section and the lack of experimentation with other extractthengenerate methodologies. This is a critical observation that could impact the paper\"s credibility and novelty. The comment highlights the need for the authors to address this issue by including a related work section and experimenting with other approaches. While it does not provide specific suggestions on how to conduct these experiments or what specific related work should be included, it points out a clear area for improvement. This feedback is 3 as it directs the authors to a crucial aspect of their work that needs attention, but it could be more helpful with additional guidance on how to address the identified gaps. Therefore, it is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The authors are left to infer that they should consider these directions but are not given specific guidance on how to integrate them into their work. The lack of actionable details makes the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in suggesting alternative approaches but lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints. However, it does not provide any supporting evidence, reasoning, or references to justify why these directions are more appealing or effective. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is not verifiable, and the authors may find it challenging to implement the suggestions without further guidance. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. While these suggestions are interesting and could potentially improve the paper, the comment lacks depth and does not provide specific guidance on how to implement these directions or integrate them into the existing work. The authors are left with a general idea of what could be explored but are not given actionable steps or detailed explanations to follow. Therefore, the comment is 3, as it points out potential areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is not sufficient and recommends providing more information on the advantages or differences of the proposed method, specifically in comparison to BGLN. While the comment implies that additional work on GLN is needed, it does not explicitly instruct the authors to include this information or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should add more information about GLN and its differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficiency of the introduction of related work and the need for more work on GLN to reflect the advantages or differences of the proposed method, such as the difference from BGLN. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN is needed to reflect the advantages or differences of the proposed method, specifically in comparison to BGLN. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2, as it lacks sufficient justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and recommends providing more information on the advantages or differences of the proposed method, particularly in comparison to BGLN. This feedback is clear and actionable, as it points out a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the methodology. However, the comment could be more helpful if it offered suggestions on how to present this additional information or what specific aspects of the methodology should be highlighted. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used when Variational dropout has inputoutput and recurrent dropout parameters. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks guidance on how the authors might improve their draft in response to this observation. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Moon\"s approach\" and \"Variational dropout,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of hyperparameters, particularly the use of only one dropout rate for Moon\"s approach compared to Variational dropout, which has inputoutput and recurrent dropout parameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of hyperparameters in Moon\"s approach, specifically noting that Variational dropout has inputoutput and recurrent dropout parameters, while Moon\"s approach only uses one dropout rate. This observation highlights a potential inconsistency in the paper\"s approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this inconsistency is problematic or how it affects the paper\"s conclusions. Without additional context or explanation, the claim remains 3, as it lacks the necessary detail to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid question about the choice of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used when Variational dropout has inputoutput and recurrent dropout parameters. This observation highlights a potential inconsistency in the paper\"s approach and could prompt the authors to reconsider their choice of hyperparameters. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests conducting largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. The reviewer provides a clear and specific action for the authors to take, which is to conduct these experiments and compare their results against other approaches. The comment is explicit and provides concrete details on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. This provides clear guidance on what aspects of the paper need to be addressed. The comment is also specific in detailing what kind of experiments should be conducted and how they could be conducted, such as using publicly available simulators and comparing against other approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the current experiments are insufficiently largescale and do not include nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. The reviewer questions whether this is due to a lack of time or severe scalability issues with the method. The comment proposes conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace, and suggests using publicly available simulators for these experiments. This provides a logical reasoning for the need to conduct largerscale experiments and suggests specific domains to consider. However, the comment lacks specific examples or references to support the claim that conducting these experiments would be beneficial. Therefore, the comment is 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. The reviewer provides a logical rationale for why these experiments are necessary, as they would help determine whether the method has severe scalability issues or if it is simply a matter of time. The comment is specific and provides detailed guidance on how to enhance the experimental section, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not provide any guidance on what specific quantitative measurement should be used or how to implement it. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely, a quantitative measurement to assess occupation bias. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided a quantitative measurement to assess the extent of occupation bias relative to real distributions in society. This is a relevant point that could impact the validity and generalizability of the study. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific quantitative measurement could be used. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to include information from 2hop neighbors or how to clarify the effectiveness of the method. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the inclusion of information from 2hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of information from 2hop neighbors and the unclear effectiveness of the method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"no information from 2hop neighbors is included\" and questions the effectiveness of the method. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting the lack of information from 2hop neighbors and questioning the effectiveness of the method. However, it does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the clarity of their work. Without specific recommendations or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly recommends using the real DICOM image as experiment data instead of the PNG image and suggests using the FastMRI challenge dataset for this purpose. It also advises comparing inference speeds between different methods. This feedback provides clear and concrete actions for the authors to take, such as changing the image format and including a specific dataset for evaluation. The suggestions are direct and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"real dicom image\" and suggests using the FastMRI challenge dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done, recommending the use of the real DICOM image and suggesting the FastMRI challenge dataset for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using the real DICOM image as experiment data instead of the PNG image and recommends using the FastMRI challenge dataset for comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the DICOM image is preferred or how it would impact the results. This lack of justification makes the claim 1, as the authors are left without clear guidance on how to address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending the use of the real DICOM image as experiment data instead of the PNG image. It also suggests using the FastMRI challenge dataset for comparison, which is a clear and concrete suggestion that can help improve the quality and relevance of the paper\"s experiments. Additionally, the comment advises comparing inference speeds between different methods, which is a valuable suggestion for enhancing the paper\"s methodological rigor. Overall, this feedback is 5 as it guides the authors on how to enhance their experimental setup and methodology."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about what happens if the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what potential implications it might have for their work. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the potential consequences of this association, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment raises a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. While it identifies a potential area of interest, it does not provide any guidance or suggestions for how the authors might address this question or what insights they might gain from exploring it. Without actionable feedback or a clear direction for improvement, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. While the comment implies that additional evaluation is needed, it does not provide specific guidance on what aspects of the evaluation should be conducted or how to conduct it. The authors are left to infer that they should conduct more evaluations, but without concrete instructions on what to evaluate or how to do it, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or experiment. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting what kind of evaluation is needed, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. However, it does not provide any supporting evidence, reasoning, or references to justify why this additional evaluation is necessary or how it would improve the paper. Without specific examples or detailed explanations, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. This feedback is 3 as it identifies a potential area for improvement in the evaluation section of the paper. However, the comment lacks specific guidance on what aspects of the evaluation should be conducted or how it could be integrated into the existing work. While it points out a potential gap in the evaluation, it does not provide detailed suggestions or examples on how to address it. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. It suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their comparisons and ensure they are using the same amount of data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparisons made in the table, suggesting that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. The comment also points out that H>N>H and H>N>H use less data than H>N+B>H. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. The reviewer suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, the comment points out that H>N>H and H>N>H use less data than H>N+B>H. While the comment identifies a potential issue with the comparisons, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for these comparisons and the specific data amounts involved, making the comment 3. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. It suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This feedback is clear and actionable, as it provides specific guidance on how to improve the comparisons in the table. By addressing these points, the authors can ensure that their comparisons are more meaningful and accurate. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue. Overall, the comment is 4 as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should add references or reconsider the placement of Alg 1, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it highlights areas for improvement but does not offer detailed instructions on how to achieve them.", "grounding_specificity_rationale": "The comment addresses several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. However, it does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides specific concerns, it lacks grounding as it does not specify where these issues are addressed in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. These are specific and actionable points that the authors can address to improve the clarity and completeness of their work. Additionally, the comment highlights a potential oversight in the lack of references to Laplacian eigenmaps, which could be important for the context of the paper. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered additional context or examples to guide the authors. Overall, the comment is 4 as it identifies specific areas for improvement but lacks depth in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and provide more motivation for the CBN approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the section and provide more motivation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of Section 2.1 is problematic or where the ResNet architecture is discussed, making it weakly grounded. The comment is specific in suggesting that the time spent on the ResNet architecture could be better used, but it lacks grounding in the original text. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. The reviewer argues that Batch Normalization is a general technique and that the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or references to support the claim that the inclusion of Section 2.1 is unnecessary or that the ResNet architecture could be better utilized. Without detailed reasoning or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is 3 as it identifies a potential area for improvement by suggesting that the authors focus on the ResNet architecture to provide more context and motivation for the proposed methodology. However, the comment could be more helpful if it provided specific suggestions on how to enhance the motivation and intuition sections or how to better integrate the ResNet architecture into the paper. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a confusion regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to clarify the explanation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the assumption of multiplying in equation (1) by a dense projection matrix and points out the potential contradiction of expecting a sparse matrix as a result. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the assumption of multiplying in equation (1) by a dense projection matrix, suggesting that the resulting matrix would be expected to be sparse. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. This is a relevant point that could impact the clarity and accuracy of the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify their explanation. While it points out a potential weakness, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It also references a specific paper, 1 Kunstner et al. (2019), which discusses the limitations of the empirical Fisher approximation for natural gradient descent. While the comment implies that the authors should reconsider their statement about initialization, it does not provide explicit guidance on how to revise the statement or what specific changes should be made. The reference to the external work is helpful but does not fully address the actionability of the comment. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement about initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more careful statement about initialization. The reference to the external work, 1 Kunstner et al. (2019), provides additional context and support for the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that initialization plays a role in natural gradient descent (NGD) and suggests that it should be considered as pretraining. The reviewer supports this claim by referencing 1 Kunstner et al. (2019), which discusses the limitations of the empirical Fisher approximation for natural gradient descent. This reference provides a logical basis for the claim, as it suggests that initialization could be an important factor in the discretization of natural gradient functions. However, the comment could be strengthened by providing more detailed explanations or examples of how initialization affects NGD. Overall, the claim is 4, as it is supported by a relevant reference but could benefit from additional justification or explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It references a specific paper, 1 Kunstner et al. (2019), which discusses the limitations of the empirical Fisher approximation for natural gradient descent. This reference provides a logical basis for the claim and offers a potential solution by suggesting that initialization could be considered as pretraining. However, the comment could be more helpful by providing additional guidance on how to revise the statement about initialization or suggesting specific ways to incorporate the reference into the paper. Overall, the comment is 3 as it points out a potential weakness and offers a reference for further exploration, but it lacks detailed guidance on how to address the issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the lack of clarity regarding how named entities were extracted from datasets and the need for an Englishproofreading to improve the readability of the paper. While the first point is explicit in asking for clarification on the extraction process, the second point is more implicit in suggesting an improvement. However, both points are concrete in their request for clarification and actionable in that the authors know they need to provide more information or improve the readability of the paper. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for clarification on how named entities were extracted from datasets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for an Englishproofreading to improve the readability of the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding how named entities were extracted from datasets and suggests that an Englishproofreading would significantly improve the readability of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement: clarity regarding the extraction of named entities from datasets and the need for an Englishproofreading to enhance the readability of the paper. While it highlights these issues, it does not provide detailed guidance or suggestions on how to address them. The comment is 3 as it points out areas that could be improved, but it lacks depth and actionable advice that would help the authors make significant improvements to their draft. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which would improve the condition slightly. This feedback is explicit and provides a clear action for the authors to take, suggesting a specific change to improve the condition. The comment is concrete, as it details the exact change needed and how it could enhance the condition. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"L200\" and \"L303,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a potential issue with the statement \"for every arm a,\" suggesting that it implies a single optimistic parameter. The comment further specifies a potential improvement by proposing an alternative condition, \"B > Sqrt(m) T^(3/4),\" which could enhance the condition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a logical reasoning by pointing out that this statement could be misleading and offers a specific suggestion to improve it by considering T_0 = m Sqrt(T) in line 303. This suggestion is based on a logical analysis of the statement and its potential implications, making the claim 4. However, the comment could be strengthened by providing a more detailed explanation or reference to similar cases where this issue has been addressed. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which could improve the condition. This feedback is clear and actionable, as it offers a concrete way for the authors to enhance their draft by addressing a potential misinterpretation. However, the comment could be more helpful if it explained why this change would improve the condition or provided additional context or references to support the suggestion. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the terms \"L\" and \"E\" should be defined in the immediate vicinity and highlights the inconsistency in whether they are italicized or not. This provides a clear and direct action for the authors to take, ensuring that the terms are consistently defined and styled throughout the paper. The comment is specific and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in the definition and styling of the terms \"L\" and \"E.\" This provides clear guidance on how to improve the consistency and clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the inconsistency in the definition and styling of the terms \"L\" and \"E\" in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the clarity or readability of the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting and consistency of the terms \"L\" and \"E\" in the paper. It points out that these terms are sometimes italicized and sometimes not, which can lead to confusion and inconsistency in the document. This feedback is clear and actionable, as it provides the authors with a concrete step to improve the clarity and consistency of their work. By addressing this issue, the authors can enhance the readability and professionalism of their paper. However, the comment could be more helpful if it suggested a standardized approach for defining and styling these terms throughout the document. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the experimental section is weak and suggests that more experiments are required. However, it does not provide specific guidance on what additional experiments should be conducted or how they should be structured. The authors are left to infer that they need to expand their experimental section, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and needs more experiments. However, it does not specify which part of the experimental section is considered weak or what specific experiments are needed. Without explicit references to sections or experiments, the authors cannot confidently determine which parts of the paper need improvement. The comment lacks both grounding and specificity, making it 1 at all.", "verifiability_rationale": "The review point claims that the experimental section is weak and suggests that more experiments are required. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a weakness in the experimental section, suggesting that more experiments are required. However, it lacks specificity and does not provide guidance on what additional experiments should be conducted or how they could enhance the paper. Without specific suggestions or examples, the authors are left with a general direction but without actionable steps to improve their draft. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the manuscript should include more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that additional comparisons are needed, it does not specify which models or techniques should be included or how to conduct these comparisons. The action is implicit and somewhat vague, as the authors can infer that they need to expand their comparisons but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which parts of the paper should include these comparisons or which models or techniques should be included. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these comparisons could be added, the comment lacks specificity in detailing what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these comparisons are necessary or how they would enhance the manuscript. Without such support, the claim is difficult for the authors to verify or address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it identifies an area where the manuscript could be strengthened by expanding its comparisons to include a broader range of models and techniques. However, the comment lacks specific suggestions on which models or techniques to include or how to conduct these comparisons. While it points out a potential area for improvement, it does not provide detailed guidance on how to implement this suggestion, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point identifies four specific errors in the text, including incorrect grammar and spelling. It provides explicit corrections for each error, such as \"Despite being compact\" to \"Despite being compact\" and \"We refer to multiway arrays\" to \"We refer to multiway arrays.\" Additionally, it corrects \"HPFN to a even deeper ConAC\" to \"HPFN to an even deeper ConAC\" and clarifies \"Effect of the modelling mixed temporalmodality features\" to \"Effect of modeling mixed temporalmodality features.\" These corrections are direct and concrete, providing clear guidance for the authors to make the necessary changes to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific corrections to errors in the text, such as incorrect grammar and spelling. It explicitly mentions lines 2, 56, 158, and 265, allowing the authors to accurately identify the parts of the paper being addressed. Each correction is clearly specified, providing full grounding. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of corrections to errors in grammar and spelling, which are factual statements. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific errors in the text, including incorrect grammar and spelling, which are important to correct for clarity and professionalism. It provides clear and actionable feedback by pointing out the errors and offering corrections, such as \"Despite being compact\" to \"Despite being compact\" and \"We refer to multiway arrays\" to \"We refer to multiway arrays.\" Additionally, it corrects \"HPFN to a even deeper ConAC\" to \"HPFN to an even deeper ConAC\" and clarifies \"Effect of the modelling mixed temporalmodality features\" to \"Effect of modeling mixed temporalmodality features.\" This feedback is clear and precise, helping the authors improve the clarity and accuracy of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the inversion of matrix determination or the division of the number of samples is being referred to in the context of the equations. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address it. The action is implicit, as the authors need to infer that they should clarify the context of the equations, but it is vague because it does not specify how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W4\" and \"Eqs.,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the inversion of matrix determination or the division of the number of samples is being referred to in the context of the equations. This provides clear guidance on what needs to be clarified or corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the context of the equations. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the context of the equations, specifically whether the inversion of matrix determination or the division of the number of samples is being referred to. This is a clear and actionable point that can help the authors clarify the meaning of their equations and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to address the confusion or offered additional context to aid in the clarification process. Overall, the comment is 4 as it identifies a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to make the paper more innovative or differentiate it from previous work. As a result, the authors are left without any clear direction on how to enhance their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this assessment is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the model extension are considered incremental or straightforward. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assessment and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any specific feedback or suggestions on how the authors might address this issue or improve their work. Without actionable guidance or constructive criticism, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a discussion of the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While the comment implies that the authors should include this analysis, it does not explicitly instruct them to do so. The action is concrete, as it specifies the metric to be analyzed and provides a clear direction for improvement, but it is somewhat vague because it does not provide detailed guidance on how to conduct the analysis or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This provides clear guidance on what aspect of the experiment needs further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline combining LDA and LSTM (LDA+LSTM) can capture sequential information and provide topic assignment for each word. However, the comment lacks specific evidence or references to support this claim. It does not provide details on how the baseline performs or why it is considered a valid approach. Without additional context or examples, the claim remains 1, making it difficult for the authors to understand and address the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by discussing the performance of a baseline combining LDA and LSTM (LDA+LSTM) in terms of the topic switch percent metric. This feedback is clear and actionable, as it prompts the authors to include a discussion of the baseline\"s performance in their results section. However, the comment could be more helpful if it provided additional context or suggestions on how to interpret or analyze the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the clarity of the motivation for the task and questions the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide more information about the motivation and potential applications of their work, but the comment lacks specific suggestions on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not offer concrete steps for implementation.", "grounding_specificity_rationale": "The comment raises questions about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the motivation and potential applications of the work, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it lacks specific examples, references, or detailed reasoning to support the claim that the motivation is unclear or that the potential benefits are unclear. This makes the claim 3, as it provides some insight but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It highlights the difficulty in predicting the state of an object when it is occluded and questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. This feedback is valuable as it prompts the authors to consider the broader implications and potential impact of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or clarify their motivation. Overall, the comment is 4 as it identifies areas for improvement and encourages the authors to consider the broader implications of their work, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of support for the claim about the synergies between DQD and PPO, specifically mentioning the absence of reference to the TD3GA algorithm in the main paper. It also suggests that the comparison to TD3GA should be central to the paper. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include references to the TD3GA algorithm and emphasize the comparison to TD3GA, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the synergies between DQD and PPO, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of reference to the TD3GA algorithm and the need for a central comparison to TD3GA. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the synergies between DQD and PPO are insufficiently supported, specifically mentioning the absence of reference to the TD3GA algorithm in the main paper. The reviewer suggests that the comparison to TD3GA should be central to understanding these synergies. This claim is 3 as it highlights a gap in the paper\"s discussion of the TD3GA algorithm, which is crucial for understanding the synergies. However, the comment lacks specific examples or references to the TD3GA algorithm to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the paper. This feedback is clear and actionable, as it points out a specific gap in the paper\"s discussion and provides a direction for improvement. By addressing these points, the authors can enhance the clarity and robustness of their claims. However, the comment could be more helpful if it offered suggestions on how to incorporate the TD3GA algorithm or provided examples of how it could be integrated into the discussion. Overall, the comment is 4 as it effectively guides the authors on how to strengthen their paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain why the treesliced Wasserstein distance outperforms the original optimal transport distance, as observed in Sections 6.1 and 6.2. This request is clear and provides a specific action for the authors to take, which is to provide an explanation for this observation. The comment is concrete in its request for clarification, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for an explanation of why the treesliced Wasserstein distance outperforms the original optimal transport distance, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the observation that the treesliced Wasserstein distance outperforms the original optimal transport distance, suggesting that an explanation is needed. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation in the paper regarding the performance of the treesliced Wasserstein distance compared to the original optimal transport distance. It asks the authors to explain why this occurs, which is a relevant and actionable request for clarification. By addressing this point, the authors can provide a more comprehensive understanding of their results and potentially improve the clarity and robustness of their work. However, the comment could be more helpful if it offered suggestions on how to present this explanation or what aspects of the methodology might be contributing to the observed performance. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the word \"confident\" in the sentence is unclear and suggests rephrasing it to clarify whether it refers to model confidence or human interpretability. While the comment implies that the authors should rephrase the sentence to improve clarity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should revise the sentence to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence containing the word \"confident,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, suggesting that the word \"confident\" should be rephrased to clarify whether it refers to model confidence or human interpretability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the word \"confident\" in the sentence, suggesting that it may refer to model confidence or human interpretability. The reviewer provides a logical reasoning by questioning the word choice, which is a common practice in scientific writing. However, the comment lacks specific examples or references to support the claim that the word is unclear or misleading. While the reasoning is sound, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the word \"confident\" in the sentence, suggesting that it may be unclear whether it refers to model confidence or human interpretability. While the comment highlights a specific area for improvement, it does not provide detailed guidance on how to rephrase the sentence or clarify the intended meaning. The feedback is 3 as it points out a potential source of confusion, but it lacks actionable suggestions or examples to fully support the authors in making the necessary changes. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of polishing in figures and empirical results, which affects clarity and confidence in empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. However, the comment does not explicitly instruct the authors on how to address these issues or provide guidance on how to improve the clarity and polish of the figures and results. While the actions are implied, they are not stated directly, making the comment 3. The authors can infer that they need to improve the clarity and polish of their figures and results, but the lack of concrete guidance makes it somewhat challenging to implement the suggested improvements.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the figures and empirical results, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the lack of polishing in figures and empirical results, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. This provides clear guidance on what needs to be addressed to improve the clarity and confidence in empirical findings. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks polishing in figures and empirical results, which affects clarity and confidence in empirical findings. The comment provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These examples provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have addressed these issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity and confidence in the empirical findings of the paper. It points out specific problems, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These observations highlight areas where the paper could be improved to enhance its clarity and credibility. However, the comment does not provide detailed guidance on how to address these issues or suggest specific improvements. While it highlights the problem, it lacks actionable advice or suggestions for improvement, making it 3 but incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. It explicitly states that this would further test the conjecture and provide valuable insights, even if the phenomenon weakens in this setting. The comment is clear and provides a direct action for the authors to take, which is to include these numbers in their report. The action is concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, specifically mentioning the nontail classes. This provides a clear direction for the authors to consider, as it specifies the part of the paper where the additional information should be included. However, the comment does not explicitly mention which section or part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific, as it details what additional information would strengthen the case of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this additional information is necessary or how it would impact the paper\"s conclusions. Without such justification, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. This feedback is actionable as it provides a clear and specific direction for the authors to enhance their work by including additional data that could further substantiate their findings. The comment also acknowledges the potential weakening of the phenomenon in this setting but emphasizes the importance of including the numbers for completeness and transparency. However, the comment could be more helpful if it provided additional context or explanation on why this additional data is crucial or how it might impact the paper\"s conclusions. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of using the number of weight updates as a metric over the number of network updates, given that the brain operates in parallel. It suggests providing additional feedback to improve the paper. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to improve the paper. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional feedback to address the question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of metrics used in the paper, specifically questioning why the number of weight updates is preferred over the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this metric is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its question about the choice of metrics, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using the number of weight updates as a metric over the number of network updates, given that the brain operates in parallel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of weight updates is a better metric. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to substantiate the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of metrics used in the paper, specifically questioning why the number of weight updates is preferred over the number of network updates, given that the brain operates in parallel. This is an important point that could impact the interpretation and understanding of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential weakness, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the objective should be clarified. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the objective, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification, which is factual in nature and does not involve claims or opinions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. This is a relevant point that could help the authors clarify the purpose and significance of their proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or improve their explanation. While it identifies an area for clarification, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It also suggests that the paper should explore the effects of varying the number of InContext Examples. While the comment provides explicit actions for the authors to take, such as including more details on the experiment setup and exploring different datasets, it does not specify how to implement these actions or provide concrete guidance on how to address the issues. Therefore, the comment is 3, as it clearly identifies areas for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"experiments\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. The comment suggests exploring the effects of varying the number of InContext Examples and provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not comprehensive and lacks transparency regarding the experiment setup. It specifically mentions the absence of information on the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. The comment also highlights the reliance on a single dataset, which could limit the generalizability of the results. While the comment provides some logical reasoning by pointing out the limitations of the evaluation, it lacks specific examples or references to support the claim about the effects of varying the number of InContext Examples. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies several critical issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It suggests that the paper should explore the effects of varying the number of InContext Examples and provides a clear direction for improvement. This feedback is actionable and offers specific suggestions for enhancing the comprehensiveness and generalizability of the evaluation. However, it could be more helpful if it provided examples of how the authors might address these issues or offered additional guidance on how to conduct the experiments. Overall, the comment is 4 as it highlights important areas for improvement and provides a clear direction for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the contrastive learning framework used in the paper is the same as SimCLR, which is a direct observation. However, it does not provide any guidance or suggestions on how the authors should address this observation or what changes they should make to their framework. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the contrastive learning framework used in the paper is the same as SimCLR, but it does not specify which part of the paper this observation is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the comparison to SimCLR. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the contrastive learning framework used in the paper is the same as SimCLR, which could be a potential issue or a point of comparison. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this observation or what implications it might have for their work. Without actionable feedback or constructive advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so or provide guidance on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include these references. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. However, it does not specify which part of the paper should include this additional attention or how it should be integrated. The authors can infer that it relates to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of the references to include, but it is 1 in the context of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. However, the comment does not provide any reasoning or explanation as to why these references are relevant or how they could enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. While this feedback identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to integrate these references into the paper or why they are relevant. The comment does not offer suggestions on how to effectively incorporate related work or how it could enhance the paper\"s contribution. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of a comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with the pretrained version. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they should include comparisons with existing text GANs and test SeqGAN with the pretrained version, but the comment lacks specific guidance on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of a comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with the pretrained version. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or results. The comment is specific in detailing what is missing, namely the comparison with existing GANs and the testing of SeqGAN with pretrained data. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with the pretrained version. However, the comment lacks specific examples or references to existing GANs or SeqGAN implementations to support the claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of a comparison against existing text GANs, many of which have opensource implementations. It also points out that SeqGAN is mentioned but not tested with the pretrained version. This feedback is clear and actionable, as it highlights specific areas where the paper could be strengthened by including comparisons with existing GANs and testing SeqGAN with pretrained data. However, the comment could be more helpful if it provided examples of existing GANs or suggested specific ways to conduct the comparisons. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. While the comment implies that the paper lacks depth in this area, it does not provide specific guidance on how to address this issue or what aspects of the algorithmic aspects should be covered. The action is implicit and somewhat vague, as the authors can infer that they need to expand on the algorithmic aspects but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. However, it does not specify which part of the paper this suggestion pertains to, such as the sections discussing the algorithmic aspects or the introduction of the Blackwell winner. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithmic aspects should be addressed or how they should be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This claim is based on the observation that the novelty of the paper seems limited after introducing the Blackwell winner. However, the comment lacks specific examples or detailed reasoning to support why the algorithmic aspects are crucial or how they could enhance the paper\"s contribution. The lack of specific evidence or detailed justification makes the claim 3, as it provides a logical basis but requires more detailed support to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This feedback is 3 as it identifies a potential area for improvement by suggesting that the paper could provide more depth on the algorithmic aspects. However, the comment lacks specific guidance on what aspects of the algorithmic aspects should be covered or how they could be integrated into the paper. While it points out a potential weakness, it does not offer detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. While the comment implies that the authors should consider including such a comparison, it does not provide specific guidance on which method to compare or how to adapt it to language tasks. The action is implicit and somewhat vague, as the authors need to infer the specific method and adaptation steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a comparison to one of the methods mentioned in the computer vision setting, specifically mentioning lossbased sampling as an example. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison could be included. While the authors might infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in suggesting a potential improvement by including a comparison to computer vision methods, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some could be adapted to language tasks relatively easily. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that these methods could be adapted. The authors would need to infer the applicability and adaptability themselves, making the comment 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by including a comparison to one of the methods mentioned in the computer vision setting, specifically lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some could be adapted to language tasks relatively easily. This feedback is actionable as it provides a clear direction for the authors to enhance their draft by including a comparison that could strengthen their analysis. However, the comment could be more helpful if it included specific examples of methods that could be adapted or how to adapt them to language tasks. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explicitly estimate the time complexity of the learning algorithm to prove its scalability properties. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion for how to enhance the paper, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need to estimate the time complexity of the learning algorithm to prove its scalability properties, providing full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be addressed, namely the estimation of time complexity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This is a clear and actionable suggestion that can help the authors strengthen their claims about the algorithm\"s performance. By addressing this point, the authors can provide more robust evidence to support their conclusions. However, the comment could be more helpful if it included examples or guidance on how to estimate the time complexity effectively. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that there may be a connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, it does not provide explicit instructions or guidance on how the authors should explore or incorporate this connection. The comment implies that the authors should investigate the relationship but lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential connection to properties of universal kernels, referencing chapter 4 of Steinwart and Christmann, which discusses the ability of universal kernels to separate an arbitrary finite data set with margin arbitrarily close to one. This provides clear guidance on what aspect of the paper needs attention and how it might be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a potential connection between the third point of definition one and properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. However, the comment does not provide specific examples or detailed reasoning from the referenced work to support the claim. While it points to a relevant source, the lack of detailed explanation or examples makes the claim 3, as the authors would need to follow up on the reference to fully understand the connection. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment suggests a potential connection between the third point of definition one and properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. This is a valuable suggestion that could lead to a deeper understanding and exploration of the topic. However, the comment lacks specific guidance or examples on how the authors might incorporate this connection into their work or what specific aspects of the universal kernel properties might be relevant. While it points to a potentially valuable direction, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit suggestions for how the authors should improve the discussion or clarify the explanation. Without guidance on what specific aspects need attention or how to address the issue, the authors are left without actionable steps to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the terse and unclear discussion around equation (10). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is \"very terse\" and \"not very clearly explained.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. While it highlights a potential weakness in the paper, it does not provide any suggestions or guidance on how the authors might improve the discussion or clarify the explanation. Without actionable feedback or specific advice, the comment offers limited value to the authors in terms of enhancing the draft. Therefore, it is rated as 2, aligning with a score of 2."}
