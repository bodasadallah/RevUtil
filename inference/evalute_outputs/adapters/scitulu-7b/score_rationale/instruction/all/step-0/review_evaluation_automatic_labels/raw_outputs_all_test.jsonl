{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a revision due to the lack of clarity regarding the precise steps involved in the methodology. However, it does not provide specific guidance on what aspects of the methodology need clarification or how to improve the presentation. The comment implies that the authors should clarify the steps, but it lacks concrete instructions or examples of what these steps might be. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a revision due to the lack of clarity regarding the precise steps involved in the methodology. However, it does not specify which part of the paper this issue pertains to, such as the methodology section or the results section. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting that the presentation and clarity of the steps need improvement, but it lacks full grounding as it does not explicitly mention which sections or parts of the paper are being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the methodology presented in the paper is challenging to train and implement, particularly for PDEs with advective terms. It acknowledges that the authors have achieved better results than baselines, but notes the lack of clarity in the presentation and the precise steps involved. The comment provides a logical reasoning for the need for clarity and improvement, but it lacks specific examples or references to support the claim about the difficulty of training and implementation. This makes the claim somewhat verifiable, as it provides a general rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity and presentation of the methodology, noting that the authors are doing a min-max optimization, which is challenging to train and implement, particularly for PDEs with advective terms. While the comment acknowledges that the methodology seems to perform better than baselines, it points out the lack of clarity in the precise steps involved. This feedback is somewhat helpful as it highlights an area where the authors could improve the clarity and presentation of their work, but it lacks specific suggestions or guidance on how to address the issue. The authors are given a direction to improve the clarity of their methodology, but the comment could be more actionable with additional details or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the practical relevance of the modified TD learning algorithm compared to the original proposal (Algorithm 1). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of the practical relevance should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking why the original proposal (Algorithm 1) should be preferred over the modified learning algorithm in practice. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the practical relevance of the modified TD learning algorithm compared to the original proposal (Algorithm 1). It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification and does not make a claim that needs justification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a valid question about the practical relevance of the modified TD learning algorithm compared to the original proposal (Algorithm 1). It prompts the authors to consider the practical implications of their theoretical analysis and encourages them to provide a justification for why the original proposal is preferred in practice. This feedback is somewhat helpful as it prompts the authors to consider a critical aspect of their work that could impact its applicability. However, it lacks specific suggestions or guidance on how to address this issue, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant concern regarding the practical utility of the data quality metric, specifically the diversity coefficient, which is suggested as a potential metric. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to validate the claim or what specific experiments could be conducted to demonstrate the utility of the metric. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"diversity coefficient\" and \"Task2Vec and model diversity,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of empirical validation for the suggested data quality metric. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks empirical validation for the suggested data quality metric, the diversity coefficient, which is a significant concern given the emphasis on Task2Vec and model diversity. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the practical utility of the data quality metric, specifically the diversity coefficient, which is suggested as a potential metric. It highlights the lack of empirical validation for this claim, which is a critical issue given the emphasis on Task2Vec and model diversity in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or validate the metric empirically. While it points out a significant weakness, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that using canary clients is less efficient than using canary examples and that more resource allocation might be needed. However, it does not provide specific guidance on how to implement this suggestion or what changes to make to improve efficiency. The comment lacks concrete details on how to execute the action, such as recommending specific techniques or suggesting ways to allocate resources more effectively. As a result, the authors are left without clear direction on how to address the issue of inefficiency. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that using canary clients is less efficient than using canary examples and that more resource allocation might be needed. However, it does not specify which part of the paper discusses the use of canary clients or examples, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what changes or improvements are needed to address the inefficiency issue. Without clear guidance on where to focus the revision or how to improve the efficiency, the authors are left without a clear path for action. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that using canary clients is less efficient than using canary examples and that more resource allocation might be needed. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential inefficiency in the use of canary clients compared to canary examples, suggesting that more resource allocation might be needed. However, it lacks specificity and does not provide actionable guidance on how to address this issue or what changes to make to improve efficiency. Without detailed suggestions or examples, the authors are left without a clear path for improvement. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer enough detail for the authors to effectively address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the relevance of Carefl to the paper and points out that it is mentioned only around Equation (6), which appears to be a standard definition of a nonlinear SEM. The reviewer suggests that the authors might have missed something, but does not provide explicit guidance on how to address this issue or what specific changes should be made to clarify the relevance of Carefl. The comment lacks actionable details, such as suggesting how to integrate Carefl into the paper or explaining its significance in the context of the work. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (6)\" and \"Carefl,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the relevance of Carefl to the paper and suggests that it might be a standard definition of a nonlinear SEM, referencing Equation (4) from \"On Causal Discovery with Cyclic Additive Noise Models.\" This provides clear guidance on what needs to be addressed, namely, the clarification of Carefl\\'s relevance to the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of Carefl to the paper and suggests that it might be a standard definition of a nonlinear SEM. The reviewer provides a reference to Equation (4) in \"On Causal Discovery with Cyclic Additive Noise Models\" to support their claim. This reference provides a logical basis for the claim, as it suggests that Carefl might be a standard definition that is not unique to the paper. However, the comment could be strengthened by providing more detailed reasoning or examples from the literature to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the relevance of Carefl to the paper and suggests that it might be a standard definition of a nonlinear SEM. It provides a reference to Equation (4) in \"On Causal Discovery with Cyclic Additive Noise Models\" to support this claim. While the comment identifies a potential issue with the paper\\'s relevance, it lacks specific guidance on how the authors might address this concern or clarify the relevance of Carefl. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed approach, noting that it is compute-intensive due to the pretraining of the GAA model on the same dataset as the QA model needs to be trained on. It also raises a concern about the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, suggesting that this could lead to longer annotation times and question the speedup claim. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to mitigate it. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider the assumptions and potential limitations of their approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the computational requirements of the proposed approach, specifically the pretraining of the GAA model on the same dataset as the QA model needs to be trained on. It also raises a concern about the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times and question the speedup claim. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the computational requirements and the assumption about the GAA model\\'s performance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed approach is compute-intensive due to the pretraining of the GAA model on the same dataset as the QA model needs to be trained on. It also raises a concern about the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times and question the speedup claim. The comment provides a logical reasoning by highlighting the potential computational burden and the assumption that could be questioned. However, it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed approach, noting that it is compute-intensive due to the pretraining of the GAA model on the same dataset as the QA model needs to be trained on. It also raises a concern about the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times and question the speedup claim. This feedback is somewhat helpful as it highlights a potential weakness in the approach that the authors should consider addressing. However, the comment could be more helpful if it provided specific suggestions on how to mitigate the computational burden or how to validate the assumption about the GAA model\\'s performance. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation of the proposed method, which is its high dependence on the server dataset. This suggests that the method may not be as versatile or applicable in different contexts. However, the comment does not provide specific guidance on how the authors might address this limitation or suggest ways to improve the generality of the method. The action is implicit and somewhat vague, as the authors can infer that they need to consider ways to broaden the applicability of their method, but the comment does not offer concrete steps or examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed method, namely its high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the limitation of the method and its impact on its applicability. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and reduces its generality. This claim is somewhat verifiable as it logically follows that a method's applicability is constrained by its dependence on a specific dataset. However, the comment lacks specific examples or references to support the claim, such as data or studies that demonstrate the limitations of the method in different contexts. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, which is its high dependence on the server dataset. This limitation is critical as it significantly reduces the generality of the method, limiting its potential use cases. The comment highlights an important area for improvement, suggesting that the authors should consider broadening the applicability of their method by exploring other datasets or contexts. However, the comment does not provide specific suggestions or guidance on how to address this limitation, such as recommending alternative datasets or methods. While it points out a critical issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include additional downstream search methods, such as BO and LS, in addition to the single method currently provided (EA). While the comment implies that the authors should consider adding these methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be beneficial to include additional downstream search methods, such as BO and LS, in addition to the single method currently provided (EA). However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting additional methods to consider, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include additional downstream search methods, such as BO and LS, in addition to the single method currently provided (EA). However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these additional methods would be beneficial or how they would enhance the study. Without such justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include additional downstream search methods, such as BO and LS, in addition to the single method currently provided (EA). This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of additional methods that could enhance the study. However, the comment lacks specific guidance on how these additional methods might be integrated or why they are particularly relevant to the study. While it points out a potential area for improvement, it does not provide detailed suggestions or examples to help the authors fully understand and address the issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the paper does not sufficiently highlight the comparison between FLOPs and FPS in sparse network research, despite the critical importance of these metrics. It suggests that a direct comparison with other sparse models is missing. This feedback provides a clear and concrete action for the authors to take, as it explicitly instructs them to include a direct comparison with other sparse models. The comment is specific and actionable, giving the authors a clear direction to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not sufficiently highlight the comparison between FLOPs and FPS in sparse network research, despite the critical importance of these metrics. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not sufficiently highlight the comparison between FLOPs and FPS in sparse network research, despite the critical importance of these metrics. The comment suggests that FLOPs for pDETR are listed in Table 7 but that a direct comparison with other sparse models is missing. However, the comment does not provide specific examples or references to support the claim that other sparse models are not compared. This lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the missing comparisons themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically the lack of a direct comparison between FLOPs and FPS in sparse network research. It points out that FLOPs for pDETR are listed in Table 7 but that a comparison with other sparse models is missing. This feedback is clear and actionable, as it directs the authors to include a direct comparison with other sparse models to enhance the paper\\'s comprehensiveness and relevance. By addressing this issue, the authors can significantly improve the clarity and depth of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the metrics described in Appendix A.1, noting that they are difficult to understand and that the results in the tables are unclear. The reviewer provides a specific example of a discrepancy in the accuracy for binary boolean questions, suggesting that reversing the prediction would yield an inaccurate result of 97%. This feedback is explicit and provides a concrete example of what needs to be addressed, making it highly actionable. The authors know exactly what needs to be clarified and how to correct the issue. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the metrics, explaining that they are difficult to understand and providing an example of a discrepancy in the accuracy for binary boolean questions. This specificity helps the authors understand what needs to be addressed in the metrics section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metrics described in Appendix A.1 are difficult to understand and provides an example of a discrepancy in the accuracy for binary boolean questions. The reviewer suggests that reversing the prediction would yield an inaccurate result of 97%, which is clearly wrong. This claim is somewhat verifiable as it provides a specific example to illustrate the issue, but it lacks detailed reasoning or references to support the claim that the metrics are difficult to understand. The example is logical but could be strengthened with additional explanation or references to similar studies. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the metrics described in Appendix A.1, noting that they are difficult to understand and that the results in the tables are unclear. The reviewer provides a concrete example of a discrepancy in the accuracy for binary boolean questions, suggesting that reversing the prediction of Dolly-V2-7B would yield an inaccurate result of 97%. This feedback is valuable as it highlights a critical area for clarification and improvement in the paper, allowing the authors to better communicate their findings. However, the comment could be more helpful if it provided suggestions on how to clarify the metrics or improve their presentation. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and offers a clear example of a potential issue.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the Gaussian assumption and its applicability in practice. It asks whether this assumption is typical and whether it is always possible to compute the effective variance for non-Gaussian outputs. Additionally, it inquires about a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues or what specific actions to take. The authors are left to infer that they need to provide more information or analysis regarding the Gaussian assumption and its applicability. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the Gaussian assumption and its applicability in practice, specifically asking whether it is typical and whether it is always possible to compute the effective variance for non-Gaussian outputs. It also inquires about a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the analysis or results sections where the Gaussian assumption is discussed. The comment is specific in its questions about the Gaussian assumption and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the Gaussian assumption and its applicability in practice. It asks whether this assumption is typical and whether it is always possible to compute the effective variance for non-Gaussian outputs. The reviewer also inquires about a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While the questions are valid and relevant, they do not provide specific examples, references, or detailed reasoning to support the claim that the Gaussian assumption is crucial or that it is always possible to compute the effective variance. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to provide additional information to fully address the questions raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several questions about the Gaussian assumption and its applicability in practice. It inquires whether this assumption is typical and whether it is always possible to compute the effective variance for non-Gaussian outputs. Additionally, it asks about a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. These questions are relevant and could prompt the authors to provide more detailed explanations or justifications for their analysis. However, the comment does not offer specific suggestions or guidance on how to address these questions or improve the paper. While it identifies areas for further exploration, it lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the approach to the math and science categories, suggesting an open vocabulary problem that is not clearly addressed. It also mentions that other categories are tackled via Wikipedia and a popularity metric. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their approach. It lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is vague and lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the approach to the math and science categories, suggesting an open vocabulary problem that is not clearly tackled. It also mentions that other categories are tackled via Wikipedia and a popularity metric. However, the comment does not specify which part of the paper discusses the approach to the math and science categories, making it weakly grounded. The comment is specific in identifying the issue with the open vocabulary problem and the use of Wikipedia and popularity metrics for other categories. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach to the math and science categories suggests an open vocabulary problem that is not clearly tackled. It also mentions that other categories are addressed via Wikipedia and a popularity metric. However, the comment lacks specific examples or detailed reasoning to support the claim that the open vocabulary problem is not clearly addressed. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some indication but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the approach to the math and science categories, suggesting an open vocabulary problem that is not clearly tackled. It also mentions that other categories are addressed via Wikipedia and a popularity metric. While the comment highlights a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the comparison against stochastic routing should be discussed more thoroughly, implying that the similarity at a more fundamental level to this work warrants a more detailed exploration. However, it does not provide specific guidance on what aspects of the comparison should be discussed or how to conduct this analysis. The action is implicit and somewhat vague, as the authors can infer that they need to expand the discussion but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing against stochastic routing and implies that the similarity at a more fundamental level to this work warrants a more thorough discussion. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in suggesting that the comparison should be more thorough, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the comparison against stochastic routing should be discussed more thoroughly, implying that the similarity at a more fundamental level to this work warrants a more detailed exploration. However, the comment does not provide specific reasoning or examples to support why this comparison is significant or how it could be improved. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the comparison against stochastic routing should be discussed more thoroughly, implying that the similarity at a more fundamental level to this work warrants a more detailed exploration. However, the comment lacks specific guidance or suggestions on how to conduct this discussion or what aspects of the comparison should be emphasized. While it identifies an area for improvement, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that convergence in direction should be considered as convergence, given that the CE loss cannot be minimized due to the exponential. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the paper. The action is implicit and vague, as the authors are left to infer that they should consider convergence in direction as convergence, but without concrete instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that convergence in direction should be considered as convergence due to the CE loss being unable to be minimized due to the exponential. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where this issue is discussed. The authors can infer that it relates to the convergence analysis or results, but this inference is not direct. The comment is specific in its suggestion to consider convergence in direction as convergence, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that convergence in direction should be considered as convergence due to the CE loss being unable to be minimized due to the exponential. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case or how it affects the paper\\'s analysis. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered fully verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that convergence in direction should be considered as convergence, given that the CE loss cannot be minimized due to the exponential. This is a somewhat helpful suggestion as it points out a potential issue with the paper\\'s analysis, which could lead to a more accurate representation of the results. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the analysis should be revised. While it identifies a potential area for improvement, it does not provide detailed instructions or examples to help the authors fully understand and address the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim components can be replaced by other models for flexibility but did not attempt any changes or alternatives to prove the robustness of the proposed framework. This implies that the authors should conduct experiments to demonstrate the robustness of their framework with alternative models. However, the comment does not provide specific guidance on which models to use or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that components can be replaced by other models for flexibility but notes that the authors did not attempt any changes or alternatives to prove the robustness of the proposed framework. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of alternative models or changes to demonstrate robustness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not attempt any changes or alternatives to prove the robustness of their framework, despite claiming flexibility through component replacement. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. Without concrete evidence or detailed reasoning, the claim is not fully verifiable, as it relies on general assertions without specific examples or references. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the lack of attempts to prove the robustness of the proposed framework. It points out that while the authors claim components can be replaced by other models for flexibility, they did not attempt any changes or alternatives to demonstrate the robustness of their framework. This feedback is somewhat helpful as it highlights an area where the authors could improve their work by providing more experimental evidence to support their claims. However, the comment could be more helpful if it suggested specific models or experiments to conduct, which would provide more actionable guidance. Overall, the comment is somewhat helpful as it directs the authors to a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of 30 disentangled factors for the Atari game experiments, suggesting that it might be difficult to specify for an arbitrary domain. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes they should make to improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Atari game experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of 30 disentangled factors and suggesting that it might be difficult to specify for an arbitrary domain. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of 30 disentangled factors for the Atari game experiments, suggesting that it might be difficult to specify for an arbitrary domain. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or how it might impact the results. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the choice of 30 disentangled factors for the Atari game experiments, suggesting that it might be difficult to specify for an arbitrary domain. This feedback is somewhat helpful as it prompts the authors to consider the generalizability and applicability of their choice. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what alternative approaches might be considered. While it points out a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the use of colloquial expressions, specifically mentioning the example of \"By the way, our training stage ... ...\". However, it does not provide any guidance on how the authors should address this issue or suggest alternative phrasing. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to revise their draft to improve professionalism. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions the use of colloquial expressions, specifically referencing the example of \"By the way, our training stage ... ...\". This provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the use of colloquial expressions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of colloquial expressions is unprofessional, specifically referencing the example of \"By the way, our training stage ... ...\". However, the comment does not provide any reasoning or evidence to support why this specific expression is considered unprofessional. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the use of colloquial expressions in the paper, specifically mentioning the example of \"By the way, our training stage ... ...\". This feedback is somewhat helpful as it points out a potential area for improvement in terms of professionalism and clarity. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the professional tone of the paper. While it highlights a specific concern, it does not offer actionable guidance or examples for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific abbreviations that have not been defined in the paper, such as \"LLH,\" \"OOD,\" and \"ECE.\" It also points out that these abbreviations are pivotal metrics in the line of work but have not been explained. The comment implies that the authors should define these abbreviations and provide explanations for their use. While the action is implicit, it is clear and concrete, as it specifies what needs to be done to improve the clarity of the paper. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"LLH,\" \"OOD,\" and \"ECE,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of definitions for these abbreviations and the importance of these metrics in the line of work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that certain abbreviations, such as \"LLH,\" \"OOD,\" and \"ECE,\" have not been defined and that these abbreviations are pivotal metrics in the line of work. However, the comment does not provide any supporting evidence or references to justify why these abbreviations are crucial or how they are used in the context of the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of these abbreviations and how they impact the paper. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific abbreviations that have not been defined in the paper, such as \"LLH,\" \"OOD,\" and \"ECE,\" which are considered pivotal metrics in the line of work. It points out that these abbreviations are important but have not been explained, leaving the authors with a clear action to take. By highlighting these omissions, the comment provides valuable feedback that can help the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it suggested how to define or explain these abbreviations, which would provide more detailed guidance. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, suggesting that the probability of failure cases increases due to stochastic/random projection at each layer. The reviewer explicitly asks the authors to justify the stability of their method and what happens when stacking more layers. This feedback provides a clear and direct action for the authors to take, which is to address the stability concerns and provide a justification for the method. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"stochastic/random projection\" and the \"WLS units,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the concern about the stability of the method when stacking multiple layers and asks for a justification of the method's stability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, suggesting that the probability of failure cases increases due to stochastic/random projection at each layer. The reviewer provides a logical reasoning by explaining that the probability of failure increases as more layers are added. However, the comment lacks specific examples or references to substantiate this claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves, which requires additional effort. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the stability of the proposed method when stacking multiple layers of WLS units, suggesting that the probability of failure cases increases due to stochastic/random projection at each layer. It raises a valid concern about the method's robustness and asks the authors to justify its stability and what happens when more layers are added. This feedback is clear and actionable, as it prompts the authors to address the stability of their method and provide a rationale for its robustness. However, the comment could be more helpful if it offered specific suggestions on how to justify the method's stability or what aspects to focus on in the analysis. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that certain sections, such as the computation of the Bottleneck Distance in Definition 4.1, lack clarity. This provides a clear and direct action for the authors to take, which is to clarify the computation in those sections. The comment is specific about what needs to be addressed, making it highly actionable. The authors know exactly what part of the paper needs clarification and how to implement the action. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking clarity in the computation of the Bottleneck Distance, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"some sections of the paper lack clarity, such as the computation of the Bottleneck Distance in Definition 4.1.\" This is a factual observation about the clarity of the paper, but it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly in the computation of the Bottleneck Distance in Definition 4.1. This feedback is clear and actionable, as it directs the authors to a specific section where clarification is needed. By addressing this issue, the authors can improve the readability and comprehensibility of their paper, which is valuable guidance for improving the draft. However, the comment could be more helpful if it provided additional context or suggestions on how to improve the clarity of the computation. Overall, the comment is mostly helpful as it effectively points out a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should provide a longer exemplar and make color assignment consistent with the topics listed in Figure 4 to enhance the visualization. This feedback is clear and provides specific actions for the authors to take, such as expanding the exemplar and aligning the color assignment with the topics. The comment is concrete, as it details what needs to be done to improve the visualization, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the visualization, suggesting that it is weaker compared to Balikas COLING16's work and that it raises doubts about the actual segmenting and assigning results of documents. The comment further suggests that a longer exemplar and consistent color assignment with the topics listed in Figure 4 could be more convincing. This provides clear guidance on what needs to be addressed to improve the visualization. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s visualization is weaker compared to Balikas COLING16\\'s work, which raises doubts about the actual segmenting and assigning results of documents. The comment suggests that a longer exemplar and consistent color assignment with the topics listed in Figure 4 could be more convincing. While the comment provides a logical reasoning for the need to improve the visualization, it lacks specific examples or references to Balikas COLING16\\'s work to fully substantiate the claim. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper\\'s visualization, noting that it is weaker compared to Balikas COLING16\\'s work. It suggests that the paper could be more convincing by providing a longer exemplar and aligning color assignment with the topics listed in Figure 4. This feedback is clear and actionable, as it points out a specific area for improvement and offers a concrete suggestion for enhancing the visualization. However, the comment could be more helpful if it provided additional context or examples of how Balikas COLING16\\'s work is superior in this regard. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of P5-small as the backbone model, suggesting that the authors do not understand the purpose of using a parameter-efficient training method. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or what specific changes they should make. The comment lacks actionable details, such as recommending alternative models or methods to improve the efficiency of the training process. As a result, the authors are left without a clear understanding of what steps to take to address the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of P5-small as the backbone model and questions the purpose of using a parameter-efficient training method. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the use of a small model and the purpose of using a parameter-efficient training method, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of P5-small as the backbone model and suggests that the purpose of using a parameter-efficient training method is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or how it might impact the paper\\'s results. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the use of P5-small as the backbone model and suggests that the purpose of using a parameter-efficient training method is unclear. While it identifies a potential issue with the choice of model, it lacks specific guidance or suggestions on how the authors might address this concern or improve their work. The comment does not provide actionable feedback or detailed reasoning, leaving the authors without a clear path forward. Therefore, the comment is rated as barely helpful, as it points out a potential weakness but does not offer constructive advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors propose a method for creating a challenging set but that what is described seems specific and not scalable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more scalable or how to improve its scalability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors propose a method for creating a challenging set but that what is described is specific and not scalable. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment lacks specificity regarding what aspects of the method are considered specific or how they could be made more scalable. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method for creating a challenging set is specific and not scalable. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method for creating a challenging set, noting that it seems specific and not scalable. However, it does not provide any specific examples or suggestions for how the authors might address this issue or make the method more scalable. Without actionable feedback or detailed guidance, the authors are left without a clear path forward to improve their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the proposed method, specifically its reliance on the optimal value function corresponding to the reward function. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out a potential issue with the proposed method, specifically its reliance on the optimal value function corresponding to the reward function. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspect of the reliance on the optimal value function is problematic or how it could be addressed. Without clear guidance on where to focus the revision or what changes are needed, the authors are left without a clear path for improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method relies heavily on the optimal value function corresponding to the reward function. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the proposed method, specifically its reliance on the optimal value function corresponding to the reward function. This is a relevant observation that could impact the robustness and generalizability of the method. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or suggest alternative approaches. Without detailed feedback or suggestions for improvement, the authors are left without a clear path for enhancing their draft. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not fully support the authors in improving their work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment acknowledges that the approach is derivative, meaning it combines two existing approaches. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the derivative nature of the approach or suggestions for enhancing its originality. Without actionable advice or constructive feedback, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the approach is derivative, meaning it combines two existing approaches. However, it does not specify which part of the paper discusses this approach, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the approach are derivative or how it could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively revise their work. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the approach is derivative, meaning it combines two existing approaches. However, it does not provide any reasoning or evidence to support why this is a problem or how it affects the paper\\'s contribution. The comment lacks specificity and does not offer suggestions for improvement, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges that the approach is derivative, meaning it combines two existing approaches. However, it does not provide any specific feedback or suggestions on how to improve the derivative nature of the approach or why it might be problematic. Without actionable guidance or constructive criticism, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include comparisons against other potential baseline approaches, specifically mentioning a simple photographic style transfer method. This provides a clear and concrete action for the authors to take, as it specifies the exact type of comparison that should be included. The comment is specific and actionable, giving the authors a direct path to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that there are no comparisons against potential baseline approaches in the evaluation, specifically mentioning a simple photographic style transfer method. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting a potential baseline approach for comparison, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no comparisons against potential baseline approaches in the evaluation, specifically mentioning a simple photographic style transfer method. The reviewer provides a specific example of what could be compared, which adds some support to the claim. However, the comment lacks detailed reasoning or references to justify why this comparison is necessary or how it would improve the paper. While the suggestion is logical, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of comparisons against potential baseline approaches in the evaluation. It suggests that a simple photographic style transfer method could achieve similar or better results, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights a specific area where the paper could be strengthened by including comparisons against alternative methods. However, the comment could be more helpful if it provided additional context or examples of how such comparisons could be conducted. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the mapping of symbols in Figure 2 to those in the equations, noting that the authors did not explain the meaning of certain symbols in the context of the proposed method. It also points out that S_i in Figure 2 is different from the calligraphic S_j in line 431, but the computation of S_i is not explained. The comment provides explicit actions for the authors to take, such as explaining the meaning of the symbols and their computation. However, it does not specify which symbols need to be explained or how to compute S_i, leaving some ambiguity. Overall, the comment is mostly actionable as it provides clear guidance on what needs to be addressed, but the lack of detailed instructions on how to implement the changes makes it somewhat vague.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"line 431,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the mapping of symbols and the lack of explanation for certain symbols, such as C_i, Q_i, R_i, and A_i, and the difference between S_i and the calligraphic S_j. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the difficulty in mapping symbols in Figure 2 to those in the equations makes it difficult to understand the proposed method. It provides specific examples of symbols that are not explained, such as C_i, Q_i, R_i, and A_i, and notes the difference between S_i in Figure 2 and the calligraphic S_j in line 431. The comment also suggests that the authors should explain these symbols and their computation. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that these symbols are not explained or that the computation is unclear. This makes the claim somewhat verifiable, as the authors would need to further investigate and clarify the issues themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mapping of symbols in Figure 2 to those in the equations, noting that the authors did not explain the meaning of certain symbols in the context of the proposed method. It provides examples of symbols that are not explained, such as C_i, Q_i, R_i, and A_i, and points out the difference between S_i in Figure 2 and the calligraphic S_j in line 431. The comment also suggests that the authors should explain these symbols and their computation, which is a clear and actionable suggestion for improving the draft. However, the comment could be more helpful if it provided additional guidance on how to address these issues, such as suggesting specific ways to clarify the symbols or explaining why the current explanation is insufficient. Overall, the comment is mostly helpful as it identifies a critical area for improvement and offers a clear direction for the authors to enhance the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should study the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. While the comment implies that these additional studies could provide insight into the tuning required for obtaining the good results, it does not explicitly instruct the authors to conduct these studies or specify how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these additional studies. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests studying the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. However, it does not specify which part of the paper these additional studies should be integrated into, making it weakly grounded. The comment is specific in suggesting the need for these studies and what they could reveal about the tuning required for obtaining the good results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests studying the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. However, it does not provide any supporting evidence, reasoning, or examples to justify why these additional studies would be beneficial or how they would impact the results. The comment lacks specificity and does not offer a clear rationale for the suggestion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests studying the number of backtracking steps and the acceptance rate in addition to the hyper-parameter $I$. This feedback identifies a potential area for further exploration and analysis, which could provide insights into the tuning required to achieve the reported results. However, the comment lacks specific guidance on how to conduct these studies or what specific aspects to focus on. While it points out a potential area for improvement, it does not offer detailed instructions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the objective function for GSdyn and FABOLAS, specifically asking about the accuracy metric used in the DNN model. It highlights a potential inconsistency in the paper regarding the objective function, noting that the DNN accuracy is mentioned as the objective function but without clarification on which dataset it is based on. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the objective function and the accuracy metric used. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the objective function for GSdyn and FABOLAS, asking for clarification on the accuracy metric used in the DNN model. The comment clearly specifies what needs to be addressed, namely the objective function and the accuracy metric used. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the objective function and accuracy metric used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the objective function and accuracy metric used in the paper, specifically regarding GSdyn and FABOLAS. It points out a potential inconsistency in the paper regarding the DNN accuracy being mentioned as the objective function but without clarification on which dataset it is based on. This feedback is valuable as it prompts the authors to clarify these aspects, which could enhance the clarity and transparency of their work. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered guidance on how to present the objective function and accuracy metric more clearly. Overall, the comment is mostly helpful as it identifies a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that section 3.1 should be moved to the related work section and that the new section 3 should be split more properly. This provides a clear and explicit action for the authors to take, which is to reorganize the sections of their paper. The comment also suggests a specific way to split the sections, making it concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests moving section 3.1 to the related work section and proposing a new section 3 with the proposal. However, it does not specify which part of the paper section 3.1 is currently located in or where it should be moved to. This lack of explicit grounding makes it difficult for the authors to identify the exact sections being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in the new section 3. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that section 3.1 should be moved to the related work section and proposes a new section 3 with the proposal. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this reorganization is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific suggestion to reorganize the sections of the paper, particularly recommending that section 3.1 be moved to the related work section and proposing a new section 3 with the proposal. This feedback is actionable and offers a clear and concrete way for the authors to improve the organization and structure of their paper. By following this suggestion, the authors can enhance the clarity and coherence of their work. However, the comment could be more helpful if it provided additional context or justification for why this reorganization is beneficial. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about how the authors obtain the priors, specifically mentioning the need for examples. It also points out that the authors may not have a practical way to obtain the required prior. While the comment implies that the authors should provide examples or clarify their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples or clarify their method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"priors\" and the \"numerical experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for examples of how to obtain the priors and points out a potential issue with the authors not having a practical way to obtain them. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about how the authors obtain the priors, specifically mentioning the need for examples. It also suggests that the authors may not have a practical way to obtain the required prior. However, the comment lacks specific examples or references to support the claim that the authors do not have a practical way to obtain the priors. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed support to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the practicality of obtaining the priors mentioned in the paper. It specifically asks for examples and points out a potential issue with the authors not having a practical way to obtain the required prior. This feedback is valuable as it highlights a potential weakness in the methodology and prompts the authors to clarify their approach. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how others have obtained similar priors. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should perform additional evaluation on the VOT dataset to compare their method with others using different metrics such as Accuracy, Robustness, and EAO. While the comment explicitly states the action to take, it does not provide detailed guidance on how to implement this additional evaluation or what specific metrics should be used. The authors are left to infer the details of how to conduct the evaluation, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the datasets used for evaluation, including OTB-50, OTB-100, OTB-2015, and LASOT datasets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests additional evaluation on the VOT dataset to compare methods using different metrics such as Accuracy, Robustness, and EAO. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should perform additional evaluation on the VOT dataset to compare their method with others using different metrics such as Accuracy, Robustness, and EAO. While the comment provides a logical reasoning for why this additional evaluation is necessary, it lacks specific examples or references to support the claim that these metrics are necessary or how they would benefit the evaluation. This makes the claim somewhat verifiable, as the authors would need to infer the importance of these metrics and how they would enhance the evaluation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to perform additional evaluation on the VOT dataset to compare their method with others using different metrics such as Accuracy, Robustness, and EAO. This feedback is valuable as it suggests a specific area for improvement and provides a rationale for why these metrics are important. By addressing this suggestion, the authors can enhance the comprehensiveness and depth of their evaluation, which could lead to a stronger paper. However, the comment could be more helpful if it explained why these metrics are particularly relevant or how they might impact the overall evaluation. Overall, the comment is mostly helpful as it offers a clear and constructive direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant concern regarding the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques. It points out that the paper claims comparable performance to supervised semantic segmentation but does not report any state-of-the-art unsupervised segmentation method performance. While the comment identifies an important area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include comparisons to unsupervised methods, but the comment lacks concrete details on how to conduct these comparisons or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"method\" and the \"performance of the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques. The comment provides a clear direction for improvement by suggesting that the paper should include comparisons to unsupervised methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is not compared to any state-of-the-art unsupervised semantic segmentation technique, despite the paper claiming comparable performance to supervised semantic segmentation. The reviewer supports this claim by pointing out that the paper does not report any state-of-the-art unsupervised segmentation method performance. This provides a logical reasoning and specific examples to substantiate the claim, making it mostly verifiable. However, the comment could be strengthened by providing references to specific state-of-the-art unsupervised methods or discussing why these comparisons are important. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that the method is not compared to any state-of-the-art unsupervised semantic segmentation technique. It highlights a critical omission in the paper, as the authors claim comparable performance to supervised semantic segmentation but do not report any state-of-the-art unsupervised segmentation method performance. This feedback is clear and actionable, as it directs the authors to include comparisons to unsupervised methods to substantiate their claims. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is mostly helpful as it points out a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the clarity of the first curve-finding part regarding the FGE work, specifically mentioning the cyclical learning rate scheduling and its potential impact on the weight. However, it does not provide explicit guidance or suggestions on how the authors might improve the explanation or address this concern. The comment lacks concrete steps or specific actions for the authors to take, leaving them uncertain about how to improve the draft. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the first curve-finding part of the paper, specifically questioning the explanation of the FGE work and the impact of cyclical learning rate scheduling on the weight. However, it does not specify which part of the paper this discussion is located in, making it weakly grounded. The comment is specific in detailing the issue with the explanation and the potential impact of the cyclical learning rate scheduling on the weight. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the first curve-finding part regarding the FGE work, specifically mentioning the cyclical learning rate scheduling and its potential impact on the weight. However, the comment lacks specific examples or references to support the claim that the explanation is unclear or inadequate. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the first curve-finding part of the paper, specifically questioning the explanation of the FGE work and its relationship to cyclical learning rate scheduling. While the comment highlights a potential weakness in the explanation, it does not provide specific suggestions or guidance on how the authors might improve the clarity or address the issue. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should present a case study, preferably with synthetic datasets, to demonstrate why and when a distillation strategy is better. It also questions the authors about the performance of LFADS-Hard compared to LFADS-Soft in Table 3 and asks for more reasoning or hypotheses based on the performance. While the comment provides explicit actions, such as presenting a case study and offering more reasoning, it does not specify how to implement these suggestions or provide detailed guidance on what specific aspects to focus on. The authors are left with a clear direction but may need to infer the exact steps to take. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting a case study with synthetic datasets to demonstrate the effectiveness of a distillation strategy. The comment also questions the authors about the performance of LFADS-Hard compared to LFADS-Soft and suggests providing more reasoning or hypotheses based on the performance. This level of detail provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should present a case study, preferably with synthetic datasets, to demonstrate why and when a distillation strategy is better. It questions the performance of LFADS-Hard compared to LFADS-Soft in Table 3 and asks for more reasoning or hypotheses based on the performance. While the comment provides a logical request for additional analysis, it lacks specific examples or references to support the claim that a case study is necessary or how it would improve the paper. The suggestion is somewhat verifiable, as it provides a clear direction but requires more detailed justification to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to present a case study, preferably with synthetic datasets, to demonstrate the effectiveness of a distillation strategy. It also questions the performance of LFADS-Hard compared to LFADS-Soft in Table 3 and asks for more reasoning or hypotheses based on the performance. This feedback is valuable as it encourages the authors to provide a more comprehensive analysis of their results, which could enhance the paper\\'s clarity and impact. However, the comment could be more helpful if it offered specific examples or guidance on how to structure the case study or what aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more detailed to be fully comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should create cloze-style or question answering evaluation sets to focus on the generation of factual knowledge. While the comment provides a clear action\u2014creating these evaluation sets\u2014it does not specify how to implement them or what specific aspects of factual knowledge should be evaluated. The authors are left to infer the details of execution, such as which questions or cloze-style tasks to use. Therefore, the comment is somewhat actionable, as it provides a direction but lacks concrete guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on evaluation of LM loss throughout the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests creating cloze-style or question answering evaluation sets to focus on the generation of factual knowledge, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation of LM loss throughout the paper is not clean enough because only a few tokens in a sentence are related to facts. The reviewer proposes creating cloze-style or question answering evaluation sets to focus on the generation of factual knowledge. While the comment provides a logical reasoning for the need to focus on factual knowledge, it lacks specific examples or references to support the claim that the current evaluation is insufficient. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and implement the suggested evaluation method. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of LM loss throughout the paper, noting that it is not clean enough because only a few tokens in a sentence are related to facts. The reviewer suggests creating cloze-style or question answering evaluation sets to focus on the generation of factual knowledge. This feedback is somewhat helpful as it provides a clear direction for improvement by suggesting a specific method to evaluate the generation of factual knowledge. However, the comment could be more helpful if it included examples or detailed guidance on how to create these evaluation sets. Overall, the comment offers a constructive suggestion that can help the authors improve their draft, but it lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the theoretical or topological aspects of the RTD score being sensitive to clusters, which is a valid point. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they might need to provide theoretical or topological explanations, but the comment lacks concrete steps or examples on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the key contribution of the paper, specifically the claim that the RTD score is sensitive to clusters and the verification of this in experiments. It raises a question about the theoretical or topological aspects of the RTD score and suggests that the authors should explain why it is specific to network representations. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for theoretical or topological explanations, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the theoretical or topological aspects of the RTD score being sensitive to clusters, suggesting that the authors should explain why it is specific to network representations. The comment is based on logical reasoning, as it points out that the RTD score could potentially be applied to other vector sizes. However, it lacks specific examples or references to support the claim that the RTD score is unique to network representations. This makes the claim somewhat verifiable, as it requires further elaboration or evidence to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s key contribution, specifically the claim that the RTD score is sensitive to clusters and the verification of this in experiments. It raises a valid question about the theoretical or topological aspects of the RTD score, questioning why it is specific to network representations. This feedback is somewhat helpful as it prompts the authors to consider the theoretical underpinnings of their method, which could enhance the paper\\'s clarity and rigor. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is somewhat helpful as it directs the authors\\' attention to an important area for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide inference timings to support their claim that ROCK has similar complexity to the original model. It also suggests conducting an ablation study to demonstrate the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. While the comment provides clear actions, it does not specify how to conduct the ablation study or what specific tasks should be included. The authors are left to infer the details of the ablation study, which could be improved with more explicit guidance. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 88-89, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely providing inference timings to support the claim that ROCK has similar complexity to the original model. Additionally, it suggests conducting an ablation study to demonstrate the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that ROCK has similar complexity to the original model, suggesting that the addition of 8 conv layers, 3 pooling layers, and 1 fusion layer would make this unlikely. The reviewer provides a logical reasoning by pointing out the number of layers and layers types, which could be considered a verifiable claim. However, the comment lacks specific examples or references to support the claim further, such as inference timings or detailed comparisons with the original model. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific claim made in the paper regarding the complexity of ROCK compared to the original model. It questions the validity of this claim by pointing out the addition of layers and layers types, suggesting that inference timings should be provided to support the claim. The comment also provides a constructive suggestion by recommending an ablation study to demonstrate the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. This feedback is clear and actionable, offering the authors a concrete way to address the claim and improve the paper. However, it could be more helpful if it provided more detailed guidance on how to conduct the ablation study or what specific tasks should be included. Overall, the comment is mostly helpful as it effectively guides the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about how to calculate the joint probability P(y_1, y_2, ..| y_{<i}, X) if this part is not autoregressive. It suggests adding the equation to the paper for clarity. While the comment implies that the authors should include the equation, it does not explicitly instruct them to do so. The action is concrete, as it specifies the addition of an equation, but it is somewhat vague because it does not provide detailed guidance on how to present the equation or where to integrate it into the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 197-198,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning how to calculate the joint probability P(y_1, y_2, ..| y_{<i}, X) if this part is not autoregressive. The comment suggests adding the equation to the paper for clarity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on how to calculate a joint probability in a non-autoregressive context. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific question regarding the calculation of a joint probability in a non-autoregressive context. It suggests adding the equation to the paper for clarity. While the comment highlights a potential area of confusion, it does not provide detailed guidance on how to address this issue or suggest alternative approaches for clarifying the calculation. The feedback is somewhat helpful as it points out a specific area that needs clarification, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations, and how the model might behave on noisy or imbalanced real-world medical datasets. While it identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The comment implies that the authors should discuss these aspects in more detail, but it lacks concrete suggestions or examples on how to do so. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations, and how the model might behave on noisy or imbalanced real-world medical datasets. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what aspects of the dataset and model behavior are missing from the discussion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations, and how the model might behave on noisy or imbalanced real-world medical datasets. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations, and how the model might behave on noisy or imbalanced real-world medical datasets. It highlights a critical area for improvement in the paper, which is the evaluation of the model's robustness in real-world scenarios. However, the comment lacks specific suggestions or guidance on how the authors might address these issues, such as recommending additional datasets or discussing potential challenges in model performance. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the reproducibility of the results due to the lack of code (training or testing) being provided. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure reproducibility. The comment implies that the authors should provide the missing code, but it lacks concrete details on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the overall model, which is comprised of multiple components, and the training process, which requires multiple separate stages. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the lack of code (training or testing) and the implications for reproducibility. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model is comprised of multiple components and requires multiple separate stages for training, which affects reproducibility due to the lack of code (training or testing). The comment provides a logical reasoning by highlighting the importance of code availability for reproducibility. However, it lacks specific examples or references to support the claim, such as detailed descriptions of the components or the training process. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the reproducibility of the results due to the lack of code (training or testing) being provided. It highlights the importance of code availability for ensuring that the results can be reliably replicated. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of code or offering advice on how to improve the reproducibility of the results. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that critical setup information is missing, specifically the total number of agents available in Flow\\'s default configuration. This feedback implies that the authors should include this information in their paper to provide a clearer understanding of the setup. However, the comment does not explicitly instruct the authors to add this information or specify how it should be presented. While the action is implied, it is not as concrete as it could be, as the authors may not be entirely sure of the exact details that need to be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"critical setup information\" and specifies the missing information, such as the total number of agents available in Flow\\'s default configuration. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added to the paper, providing clear guidance on what information is missing. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that critical setup information is missing, specifically the total number of agents available in Flow\\'s default configuration. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this omission or how it affects the paper\\'s clarity or validity. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically the lack of information about the total number of agents available in Flow\\'s default configuration. This is a significant oversight that could impact the clarity and reproducibility of the study. By pointing out this missing information, the comment provides a clear and actionable suggestion for the authors to include this detail in their paper. However, the comment could be more helpful if it offered guidance on how to present this information or why it is important for readers to know this detail. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the claim of being the \"first deep generative model for unsupervised scene-graph discovery,\" pointing out that there are many works that infer structures in an unsupervised way. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific changes should be made to the claim. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim of being the \"first deep generative model for unsupervised scene-graph discovery,\" which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out that there are many works that infer structures in an unsupervised way, and it questions the narrow definition of \"scene graph\" and the claim of being the first. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim of being the \"first deep generative model for unsupervised scene-graph discovery,\" pointing out that there are many works that infer structures in an unsupervised way. However, the comment does not provide specific examples or references to support this claim, nor does it offer a detailed explanation of why the claim is invalid or unsupported. Without concrete evidence or reasoning, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the claim of being the \"first deep generative model for unsupervised scene-graph discovery,\" pointing out that there are many works that infer structures in an unsupervised way. This feedback highlights a potential overstatement in the paper\\'s contribution, which could be misleading to readers. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify their contribution. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the ablation study, noting that it does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. However, it does not offer any guidance on how the authors should address this issue or what specific changes should be made to the study. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of information on the effect of different numbers of projectors on distillation when the feature dimensions are different. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ablation study, noting that it does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. This is a relevant point that could impact the validity and generalizability of the results. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might address this issue or what specific analyses could be conducted to provide a more comprehensive understanding of the results. While it points out a potential weakness, it does not provide actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more experiments on diverse datasets are needed to demonstrate the generalization capabilities of the model beyond the three categories mentioned (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. While the comment provides a clear direction for additional experiments, it does not specify which datasets or topologies should be used. The action is explicit but somewhat vague in terms of execution, as the authors know they need to conduct more experiments but may not be entirely sure of the exact details. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on diverse datasets to demonstrate the generalization capabilities of the model beyond the three categories mentioned (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. However, the comment does not specify which parts of the paper these suggestions pertain to, such as specific sections or experiments. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting additional experiments and the need for more complex shapes, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments on diverse datasets are needed to demonstrate the generalization capabilities of the model beyond the three categories mentioned (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. While the comment provides a logical reasoning for the need to expand the dataset and shape complexity, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to infer the specific datasets or topologies to consider. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending more experiments on diverse datasets to demonstrate the generalization capabilities of the model beyond the three categories mentioned (chair, airplane, car). It also suggests evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. This feedback is specific and offers a concrete direction for the authors to enhance the robustness and generalizability of their work. However, the comment could be more helpful if it provided examples of specific datasets or topologies to consider, which would guide the authors in implementing these suggestions. Overall, the comment is mostly helpful as it offers clear and actionable advice for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a comparison against methods that require more training time is necessary. It highlights the low computational requirements of the neural networks proposed by Park & Van Hentenryck (2023) and others, which may render low compute restrictions during test time unnecessary. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects to focus on. While it implies that the authors should consider this comparison, the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison against methods that require more training time, specifically mentioning the neural networks proposed by Park & Van Hentenryck (2023) and others. It also highlights the low computational requirements of these networks and the potential implications of this for training restrictions. However, the comment does not specify which part of the paper this comparison should be included in, nor does it provide detailed guidance on how to conduct the comparison. While the authors can infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting a comparison against methods with more training time, but without detailed guidance on execution, it remains under-specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison against methods that require more training time is necessary, as the neural networks proposed by Park & Van Hentenryck (2023) and others do not necessitate extensive training time. The reviewer provides a logical reasoning by explaining that low computational requirements during test time are typically essential for inference on new examples. However, the comment lacks specific examples or references to support the claim that low compute restrictions during test time are unnecessary. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to conduct a comparison against methods that require more training time, specifically mentioning the neural networks proposed by Park & Van Hentenryck (2023) and others. It highlights the low computational requirements of these networks and the potential implications of this for training restrictions. The comment is valuable as it directs the authors to consider a critical aspect of their work that could impact its practical applicability. However, it could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide more comparisons between DetNAS and other networks constructed with efficient blocks, such as ShuffleNetv2. It also provides a specific example by suggesting the inclusion of a 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is clear and concrete, giving the authors a direct action to take to improve their draft. The explicit nature of the suggestion and the specific example provided make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison between DetNAS and ResNet, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison between DetNAS and other networks constructed with efficient blocks, and provides a specific example of a 3.8G FLOPs ShuffleNetv2 in Table 2. This level of detail provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between DetNAS and ResNet is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. The reviewer suggests that the authors should provide more comparisons with other networks constructed with efficient blocks, such as ShuffleNetv2. The comment provides a specific example of a 3.8G FLOPs ShuffleNetv2 in Table 2, which supports the claim by providing a concrete example of what could be included. This level of detail and specificity makes the claim mostly verifiable, as it provides a clear rationale for the suggestion. However, the comment could be further strengthened by referencing studies or literature that demonstrate the efficiency of ShuffleNetv2 compared to ResNet. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison between DetNAS and ResNet, noting that the ShuffleNetv2 block is more efficient than the Residual block in ResNet. It provides a clear and actionable suggestion by recommending that the authors include more comparisons with other networks constructed with efficient blocks, such as ShuffleNetv2. The comment also offers a specific example of a 3.8G FLOPs ShuffleNetv2 in Table 2, which would help the authors improve their draft. This feedback is valuable as it guides the authors to address a critical aspect of their comparison, ensuring a more comprehensive and fair evaluation of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in the input and output spaces/representations, suggesting that they are restricted to either the group itself or a homogeneous space. It implies that the current approach is not as general as other papers mentioned in point (3), which can work with any finite-dimensional representation. However, the comment does not provide explicit guidance on how to address this limitation or suggest specific improvements. The authors are left to infer that they need to broaden the input and output spaces, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the input and output spaces/representations, suggesting that they are restricted to either the group itself or a homogeneous space. It mentions two papers that can work with any finite-dimensional representation, providing a basis for comparison. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the limitation of the input and output spaces, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the input and output spaces/representations are restricted to either the group itself or a homogeneous space, which is a limitation compared to other papers mentioned in point (3). However, the comment does not provide specific examples or references to these papers, making it difficult for the authors to understand the full context or assess the validity of the claim. The lack of detailed evidence or references results in the comment being somewhat verifiable, as it requires further exploration to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the input and output spaces/representations, suggesting that they are restricted to either the group itself or a homogeneous space. It compares this approach to two papers mentioned in point (3), which can work with any finite-dimensional representation. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s generality, but it lacks specific suggestions or guidance on how to address this issue. The authors are left to infer that they need to broaden the input and output spaces, but without detailed advice or examples, the comment does not fully support the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential complexity in the practical applications of the system, specifically in real-world image editing tasks involving multiple objects and flexible prompts. It suggests that the need to specify a source prompt, blend word, and various conditions can complicate the process and restrict its practical usability for typical users seeking simpler image adjustments. However, the comment does not provide explicit guidance or suggestions on how the authors might address this complexity or simplify the process. The action is implicit and somewhat vague, as the authors can infer that they need to consider the practical implications of their system but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the complexity in practical applications of the system, specifically in real-world image editing tasks involving multiple objects and flexible prompts. It highlights the need to specify a source prompt, blend word, and various conditions, which can complicate the process and restrict its practical usability. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the complexity and its potential impact on practical usability. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the practical applications of the system are complicated due to the need to specify multiple prompts, blend words, and conditions. This claim is somewhat verifiable as it logically follows from the description of real-world image editing tasks involving multiple objects and flexible prompts. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors might need to infer the complexity and its impact on practical usability, which could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential complexity in the practical applications of the system, specifically in real-world image editing tasks involving multiple objects and flexible prompts. It highlights the need to specify a source prompt, blend word, and various conditions, which can complicate the process and restrict its practical usability for typical users seeking simpler image adjustments. While the comment points out a relevant issue, it lacks specific suggestions or guidance on how the authors might address this complexity or simplify the process. The feedback is somewhat helpful as it provides insight into a potential problem but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s contributions are not significant, despite the novelty of the technique. It also points out the lack of comparison with traditional classification or manifold learning literature. However, it does not provide explicit guidance on how the authors should address these issues or what specific comparisons should be made. The feedback is vague and lacks concrete steps for improvement, leaving the authors uncertain about how to enhance their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper\\'s contributions are not significant, despite the novelty of the technique. It also mentions the lack of comparison with traditional classification or manifold learning literature. However, it does not specify which part of the paper this critique is based on, such as specific sections or results where these comparisons could be made. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in identifying the need for comparison but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s contributions are not significant, despite the novelty of the technique. It also suggests that there is a lack of comparison with traditional classification or manifold learning literature. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper\\'s contributions are not significant, despite the novelty of the technique. It also points out the lack of comparison with traditional classification or manifold learning literature. While the comment identifies areas for improvement, it does not provide specific guidance on how the authors might address these issues or what comparisons could be made to enhance the paper\\'s impact. The feedback is somewhat helpful as it highlights potential weaknesses, but it lacks actionable suggestions or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a discussion on the impact of few-shot datasets for the sparsity ratio is necessary. It acknowledges that larger datasets could provide more accurate estimates but would require more time to compute. The reviewer provides references to external works that discuss this topic, which could serve as a starting point for the authors to explore. However, the comment does not explicitly instruct the authors to conduct this discussion or specify how to integrate the references into their work. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a discussion on the impact of few-shot datasets for the sparsity ratio is necessary. It mentions that larger datasets could provide more accurate estimates but would require more time to compute. The references to external works, [1] and [2], provide some grounding as they are specific references to studies that discuss this topic. However, the comment does not explicitly mention which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting a discussion on the impact of few-shot datasets, but it lacks detailed guidance on how to integrate this into the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the impact of few-shot datasets for the sparsity ratio is necessary. It provides a logical reasoning by acknowledging that larger datasets could provide more accurate estimates but would require more time to compute. The reviewer supports this claim by referencing two external works, [1] and [2], which discuss the effectiveness of language model fine-tuning and the trade-off between accuracy and computational time. However, the comment could be strengthened by providing more detailed analysis or examples from these references to further substantiate the claim. As it stands, the claim is mostly verifiable due to the inclusion of references, but it could be more robust with additional justification or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the impact of few-shot datasets on the sparsity ratio. It suggests that a discussion on this topic is necessary, acknowledging that larger datasets could provide more accurate estimates but would require more time to compute. The comment provides a logical reasoning for the need to discuss this issue and references two external works that could serve as a starting point for the authors to explore this topic further. However, the comment could be more helpful by offering specific suggestions on how to integrate this discussion into the paper or what aspects of the few-shot dataset impact should be discussed. Overall, the comment provides a clear direction for improvement but could be more actionable with additional guidance. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors do not provide a justification for why it is beneficial to keep representations in the same hidden space and that this has not been experimentally verified. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to provide a rationale or experimental evidence. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification or evidence but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of justification for why it is beneficial to keep representations in the same hidden space and the absence of experimental verification that they are in the same hidden space. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for a justification and experimental evidence. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not provide a justification for why it is beneficial to keep representations in the same hidden space and that this has not been experimentally verified. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that the authors do not provide a justification for why it is beneficial to keep representations in the same hidden space and that this has not been experimentally verified. This is a critical point that could impact the validity and applicability of the paper\\'s findings. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or provide evidence to support their claims. While it points out a significant weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of novelty in the methodology, specifically noting that the paper extends Karwande et al. (2022) by using Faster R-CNN (Ren et al., 2015). It suggests that this approach does not offer a significant advancement beyond existing methods, which could limit its contribution to the NLP community. However, the comment does not provide explicit guidance on how the authors might address this issue or suggest ways to enhance the novelty of their methodology. The action is implicit and somewhat vague, as the authors can infer that they need to explore ways to differentiate their approach from existing methods, but the comment does not offer specific steps or examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Longitudinal Representation Learning\" methodology and its extension from Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of lack of novelty in the methodology and how it might limit the paper\\'s contribution to the NLP community. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient novelty due to its extension of Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015). The reviewer suggests that this approach does not offer a significant advancement beyond existing methods, which could limit its contribution to the NLP community. However, the comment does not provide specific examples or references to existing methods that are being extended, nor does it explain how the current approach compares to these methods. This lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique and potentially conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the methodology lacks sufficient novelty as it is an extension of existing work by Karwande et al. (2022) and uses Faster R-CNN (Ren et al., 2015). This observation suggests that the paper may not offer a significant advancement in the field and could limit its contribution to the NLP community. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their approach from existing methods. While it points out a critical weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overlooks various SSM-based approaches that get around keeping $\\\\Delta t$ fixed, specifically mentioning S5 as an example. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or incorporate these approaches into their work. The comment lacks actionable details, such as recommending specific sections to update or suggesting how to integrate these approaches into the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"S5,\" which provides full grounding as it allows the authors to identify the specific approach being referred to. However, it does not specify what needs to be addressed or improved in the paper regarding this approach. The comment is specific in identifying the issue of overlooking SSM-based approaches that get around keeping $\\\\Delta t$ fixed, but it lacks detailed guidance on how to address this issue. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper overlooks various SSM-based approaches that get around keeping $\\\\Delta t$ fixed, specifically mentioning S5 as an example. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it overlooks various SSM-based approaches that get around keeping $\\\\Delta t$ fixed, such as S5. This feedback is valuable as it highlights a gap in the paper that could be addressed to enhance its comprehensiveness and relevance. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might incorporate these approaches into their work or address the issue of overlooking them. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the claim that data generation mechanism 3 is presented when it isn\\'t, the suggestion to discuss causal graphs instead of the label inference process, and the difficulty in understanding definition 4 due to unclear graph considerations. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to clarify the data generation mechanism and the causal graphs, but the comment lacks specific instructions on how to do so. Additionally, it does not offer suggestions on how to improve the readability of definition 4 or provide examples of what graphs should be considered for determining independencies. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the data generating mechanism, the label inference process, and the definition of 4, providing clear guidance on what needs to be addressed. The comment is specific in detailing the problems with the data generation mechanism, the label inference process, and the definition of 4, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that data generation mechanism 3 is presented when it isn\\'t, and suggests that it would be more standard to discuss causal graphs instead of the label inference process. Additionally, it criticizes the difficulty in understanding definition 4 due to unclear graph considerations. The comment provides some logical reasoning by suggesting that causal graphs would be a more standard approach, but it lacks specific examples or references to support the claim about the data generation mechanism. The suggestion to discuss causal graphs is somewhat vague, as it does not provide detailed guidance on how to implement this change. Overall, the claim is somewhat verifiable, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the claim that data generation mechanism 3 is presented when it isn\\'t, the suggestion to discuss causal graphs instead of the label inference process, and the difficulty in understanding definition 4 due to unclear graph considerations. The comment provides clear and actionable feedback by suggesting that the authors clarify the data generation mechanism and the causal graphs, which could improve the clarity and accuracy of the paper. Additionally, it points out the need to improve the readability of definition 4 by providing more detailed information on the graph considerations. However, the comment could be more helpful if it offered specific suggestions on how to present the causal graphs or provided examples of what graphs should be considered for determining independencies. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the feasibility of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate a dual-free approach. While the comment implies that the authors should provide more examples or clarify the feasibility issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples or clarify the feasibility issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the feasibility of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate a dual-free approach. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this issue is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion to include more examples, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the feasibility of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate a dual-free approach. However, the comment lacks any supporting evidence, reasoning, or references to substantiate the claim that evaluating the gradient is expensive or infeasible. Without such justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the feasibility of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate a dual-free approach. While the comment identifies a potential issue with the feasibility of the proposed method, it lacks specificity and does not provide actionable guidance on how to address this issue or what examples to include. The feedback is somewhat helpful as it points out a potential weakness but does not offer detailed suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to explain the reason for selecting a probability range for the appearance of an unobservable data point. This is a clear and direct request, providing the authors with a specific action to take. The comment is concrete because it specifies the exact part of the algorithm where the explanation is needed and provides a specific range to consider. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"step 3 of Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of the reason for selecting a probability range for the appearance of an unobservable data point, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of explanation regarding the selection of a probability range for the appearance of an unobservable data point. It does not make a subjective claim or express an opinion but rather seeks clarification on a specific aspect of the methodology. Therefore, it is classified as a normal statement.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors need to provide more explanation, specifically regarding the selection of a probability range for the appearance of an unobservable data point. This feedback is clear and actionable, as it directs the authors to clarify the rationale behind their choice. By addressing this point, the authors can improve the clarity and transparency of their methodology. However, the comment could be more helpful if it provided suggestions on how to explain this selection or what aspects should be emphasized. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide a precise definition or informal description of the concept of \"spectrum of distributions and their characteristic functions.\" This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, \"line 128\" and \"line 168,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the precise definition or informal description of the concept of \"spectrum of distributions and their characteristic functions.\" This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks a precise definition or informal description of the concept of \"spectrum of distributions and their characteristic functions.\" While it identifies a potential gap in the paper, it does not provide specific examples or references to support the claim that this is necessary or how it would improve the paper. The comment is somewhat verifiable as it points out a potential area for clarification, but it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of a precise definition or informal description of the concept of \"spectrum of distributions and their characteristic functions.\" This is a clear and actionable suggestion that can help the authors clarify their work and improve its comprehensibility. By addressing this feedback, the authors can enhance the clarity and accessibility of their paper, which is valuable for both the reviewer and the broader audience. However, the comment could be more helpful if it provided additional context or examples of how this definition or description might be presented. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity regarding the challenges of the AIG-generation task and suggests that more background should be provided for readers unfamiliar with the area of logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance its convincingness. While the comment provides a clear direction for improvement, it does not specify which aspects of the background or benchmarking should be addressed. The action is explicit but somewhat vague in terms of execution, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the AIG-generation task and suggests that more background should be provided for readers unfamiliar with the area of logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or results sections where the AIG-generation task is discussed. The comment is specific in suggesting that more background and benchmarking are needed to enhance the paper\\'s convincingness. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the AIG-generation task is not convincing and suggests that more background should be provided for readers unfamiliar with the area of logic synthesis. The reviewer also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance its convincingness. While the comment identifies a potential issue with the paper\\'s presentation, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to benchmark on existing datasets is a logical step, but the comment could be strengthened by providing more context or examples of how this would improve the paper. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the challenges of the AIG-generation task and suggests that more background should be provided for readers unfamiliar with the area of logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the paper\\'s convincingness. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific examples of what additional background or benchmarking information would be beneficial. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and robustness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that some statements in the paper lack detail and analysis. However, it does not specify which statements are lacking or provide any concrete guidance on what additional detail or analysis is needed. The authors are left to infer that they need to improve the depth and clarity of their statements, but without specific examples or suggestions, they may struggle to determine which parts need the most attention. As a result, the comment is vague and lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that some statements in the paper lack detail and analysis, but it does not specify which statements are being referred to. Without explicit references to sections, figures, or specific statements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what kind of detail or analysis is missing, making it difficult for the authors to address the issue effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some statements in the paper lack detail and analysis. However, it does not provide specific examples or reasoning to support this claim, making it difficult for the authors to understand which statements are lacking and how they could improve them. Without specific references or detailed explanations, the claim is not verifiable, as it lacks the necessary evidence or justification to support the claim. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a general issue with the paper, stating that some statements lack detail and analysis. However, it does not provide specific examples or guidance on which statements are lacking or how they could be improved. Without this level of detail, the authors are left with a general suggestion to enhance their writing but without actionable steps to achieve it. This makes the comment barely helpful, as it points out an area for improvement but lacks the depth and specificity needed for the authors to effectively address the issue. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a comparison with other generative models, specifically VAE, could be more informative. It highlights the unique features of diffusion models, such as diffusion timesteps, and suggests that an analysis of how these differences affect feature learning would add significant value. While the comment implies that the authors should conduct a comparison and analyze the differences, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison with other generative models, specifically mentioning VAE, and highlights the unique features of diffusion models, such as diffusion timesteps. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting an analysis of how these differences affect feature learning, which adds value to the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with other generative models, specifically VAE, could be more informative. It highlights the unique features of diffusion models, such as the diffusion timesteps, and proposes an analysis of how these differences affect feature learning. While the comment provides a logical reasoning for the need for such a comparison, it lacks specific examples or references to support the claim that these differences significantly affect feature learning. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of comparing the diffusion model with other generative models, specifically mentioning VAE, and suggests an analysis of how the unique features of diffusion models, such as diffusion timesteps, affect feature learning. This feedback is valuable as it directs the authors to a specific area for improvement, which could enhance the comprehensiveness and originality of their work. However, the comment could be more helpful if it provided examples or references to similar analyses or studies that have been conducted in the field. Overall, the comment is mostly helpful as it offers a clear direction for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the effectiveness of the DaPI task, which is not significant despite doubling GPU memory usage, and questions the absence of corresponding experiments to show the influence of the number of negatives in the ICoL method. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they should conduct experiments to demonstrate the influence of the number of negatives and potentially explore alternative methods to mitigate memory constraints. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the combination of self-supervised tasks ICT and DaPI, noting that the effectiveness of DaPI is not significant despite doubling GPU memory usage. Additionally, it raises concerns about the absence of corresponding experiments to show the influence of the number of negatives in the ICoL method. The comment is specific in detailing what needs to be addressed, providing clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the effectiveness of the DaPI task, noting that its impact on GPU memory usage is not significant despite doubling GPU memory. It also questions the absence of experiments to demonstrate the influence of the number of negatives in the ICoL method. While the comment provides some logical reasoning by referencing the TAS-B, it lacks specific examples or references to support the claim about the effectiveness of the DaPI task or the importance of negatives. The authors would need to make a significant effort to verify the claim themselves, as the comment does not provide sufficient evidence or detailed reasoning. Therefore, the comment is somewhat verifiable, as it requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the table 4, noting that the combination of self-supervised tasks ICT and DaPI does not seem to be complementary, despite doubling GPU memory usage. It also highlights the lack of corresponding experiments to demonstrate the influence of the number of negatives in the ICoL method, which is crucial for performance. The comment suggests that the quality of negatives is more important than the quantity, referencing the TAS-B. While the comment provides valuable insights into potential weaknesses and areas for improvement, it could be more helpful if it offered specific suggestions or guidance on how to address these issues. Overall, the comment is somewhat helpful as it directs the authors\\' attention to important aspects of their work that need further exploration and clarification.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the figure is unclear due to the similarity of three plots on the same row. It suggests that a caption should be added to emphasize the differences between the plots. This feedback provides a clear and concrete action for the authors to take, which is to add a caption to clarify the distinction between the plots. The suggestion is specific and actionable, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the differences between the three plots on the same row. The comment provides a clear suggestion for improvement by recommending the addition of a caption to emphasize the differences. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is unclear due to the similarity of three plots on the same row. However, it does not provide any specific reasoning or examples to support this claim. The comment suggests adding a caption to emphasize the differences, but without further explanation or evidence, it remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that the similarity of three plots on the same row makes it unclear what the differences are. It suggests that a caption should be added to emphasize the differences between the plots. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity of the figure. However, it could be more helpful if it offered additional guidance on how to write the caption or what specific aspects of the plots should be emphasized. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide a deeper dive into the computational complexity of GPSE, particularly when compared to hand-crafted PSEs and other encoding strategies. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on computational complexity. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"hand-crafted PSEs\" and \"GPSE,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a deeper dive into the computational complexity of GPSE compared to hand-crafted PSEs and other encoding strategies. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a deeper dive into the computational complexity of GPSE is necessary, particularly when compared to hand-crafted PSEs and other encoding strategies. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of clarity on the computational complexity of GPSE compared to hand-crafted PSEs and other encoding strategies. It suggests that a deeper dive into this topic would benefit the paper. While the comment highlights an important aspect that could enhance the paper, it does not provide specific guidance or examples on how to address this issue. The authors are left with a general direction but may struggle to fully understand the exact steps to take. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the results on the VQA dataset are reported on the test-dev split, which is not ideal according to the guidelines from the dataset authors. It provides a clear and concrete action for the authors to take, suggesting that they report the results on the test-standard split instead. This guidance is direct and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1\" and \"VQA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with reporting results on the test-dev split and provides guidance on how to address it by suggesting reporting on the test-standard split. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results on the VQA dataset are reported on the test-dev split, which is not ideal according to the guidelines from the dataset authors. The reviewer supports this claim by referencing the guidelines from the VQA dataset website, which provides a clear and specific justification for the suggestion. This reference to external sources makes the claim verifiable, as it offers a logical and widely accepted basis for the critique. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reporting of results on the VQA dataset, noting that the test-dev split is used instead of the test-standard split as recommended by the dataset authors. This feedback is clear and actionable, as it provides the authors with a concrete suggestion to improve their reporting by using the test-standard split. By addressing this issue, the authors can ensure their results are more accurate and aligned with best practices. However, the comment could be more helpful if it explained why this change is important or how it might impact the interpretation of the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to choose values for $\\\\beta$, $\\\\alpha$, and $\\\\eta$ to ensure a certain decision-making loss level while optimizing the Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss could improve the impact of the theoretical result. However, the comment does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they need to consider the trade-off and manage it, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about how to choose values for $\\\\beta$, $\\\\alpha$, and $\\\\eta$ to ensure a certain decision-making loss level while optimizing the Brier scores. It suggests managing the trade-off between prediction accuracy and decision-loss to improve the impact of the theoretical result. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for guidance on how to manage the trade-off, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how to choose values for $\\\\beta$, $\\\\alpha$, and $\\\\eta$ to ensure a certain decision-making loss level while optimizing the Brier scores. It suggests managing the trade-off between prediction accuracy and decision-loss to improve the impact of the theoretical result. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that managing this trade-off would improve the impact of the theoretical result. Without such evidence or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about how to choose values for $\\\\beta$, $\\\\alpha$, and $\\\\eta$ to ensure a certain decision-making loss level while optimizing the Brier scores. It suggests managing the trade-off between prediction accuracy and decision-loss to improve the impact of the theoretical result. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to manage this trade-off or what specific steps the authors should take to address it. The feedback is somewhat helpful as it points out a potential issue, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of LBEN to more structured layers like convolutions, noting that its performance trails that of MON. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the applicability of their method to more structured layers. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the applicability of LBEN to more structured layers like convolutions, noting that its performance trails that of MON. However, it does not specify which part of the paper this applicability is discussed in, making it weakly grounded. The comment is specific in its critique of the performance comparison with MON, but it lacks detailed guidance on how to address this issue or improve the applicability to more structured layers. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the applicability of LBEN to more structured layers like convolutions is limited, as its performance trails that of MON. However, the comment does not provide specific evidence or references to support this claim, such as data or comparisons with MON. Without detailed justification or examples, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the applicability of LBEN to more structured layers like convolutions, noting that its performance trails that of MON. This is a relevant observation that could prompt the authors to consider the limitations of their method and explore ways to improve its performance. However, the comment does not provide specific suggestions or guidance on how to address this limitation or extend the method to more structured layers. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the reviewer's lack of understanding regarding the evaluation of the refactoring process but provides a list of potential metrics for the authors to consider. This explicit suggestion offers a clear action for the authors to take, which is to explore these metrics for their next benchmark. The comment is specific in identifying the need for alternative metrics and provides concrete guidance on what to consider. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment acknowledges the reviewer\\'s lack of understanding regarding the evaluation of the refactoring process and suggests potential metrics for the authors to consider. However, it does not specify which part of the paper discusses the refactoring process, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment provides some guidance on what metrics to consider, it lacks specificity regarding the current evaluation or the context in which these metrics should be applied. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges the reviewer\\'s lack of understanding regarding the evaluation of the refactoring process and suggests potential metrics for the authors to consider. However, it does not provide any supporting evidence, reasoning, or references to justify why using a pass rate for unit tests is insufficient. The comment lacks detailed explanation or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the reviewer\\'s lack of understanding regarding the evaluation of the refactoring process and suggests potential metrics for the authors to consider. While it provides a list of metrics, it lacks depth and does not explain why the current approach using a pass rate for unit tests is insufficient. The comment could be more helpful by providing a rationale or examples of why these metrics are better suited for evaluating refactoring. As it stands, the feedback offers a starting point but does not fully address the authors\\' needs for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the Wiener deconvolution has been proposed before, which implies that the main contribution of the paper is not significant. However, it does not provide any guidance on how the authors could address this issue or what specific improvements could be made to enhance the contribution. The comment lacks explicit instructions or concrete suggestions for the authors to follow, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the main contribution of the paper is not significant because the Wiener deconvolution has been proposed before. However, it does not specify which part of the paper discusses the Wiener deconvolution or how it relates to the main contribution. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is not significant because the Wiener deconvolution has been proposed before. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the main contribution of the paper is not significant because the Wiener deconvolution has been proposed before. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or enhance the contribution of their work. Without actionable feedback or detailed analysis, the comment lacks depth and does not help the authors improve their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the connection to spin glasses is weak and lacks explanation. It explicitly states that the regularization term and its effect on the Parisi order parameter, as well as the role of temperature, are not adequately explained. The comment provides a clear and specific action for the authors to take, which is to explain these connections more thoroughly. The feedback is concrete and actionable, as it guides the authors on what aspects need to be addressed to strengthen the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the connection to spin glasses, the role of the regularization term, the effect on Parisi's order parameter, and the role of temperature. This provides clear guidance on what aspects of the paper need further explanation or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the connection to spin glasses is weak and lacks explanation, specifically regarding the role of the regularization term, Parisi's order parameter, and temperature. The reviewer provides logical reasoning by pointing out that these aspects are crucial to understanding the connection to spin glasses and should be addressed in the paper. However, the comment lacks specific examples or references to support the claim, such as detailed explanations or comparisons with related literature. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper\\'s connection to spin glasses, noting that the explanation of the role of the regularization term, Parisi\\'s order parameter, and temperature is insufficient. It provides a clear and actionable critique by pointing out specific areas that need further explanation and elaboration. By highlighting these gaps, the comment offers the authors a concrete direction for improving their draft, ensuring that the connection to spin glasses is more robust and comprehensible. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the self-training scheme is more of a direct application and that the contribution is relatively limited. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the contribution or what specific aspects of the self-training scheme could be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the self-training scheme is more of a direct application and that the contribution is relatively limited. However, it does not specify which part of the paper this pertains to, such as a particular section or figure where the self-training scheme is discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the self-training scheme are considered direct applications or how the contribution could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the self-training scheme is more of a direct application and that the contribution is relatively limited. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the self-training scheme is more of a direct application and that the contribution is relatively limited. However, it does not provide specific feedback or suggestions on how the authors could enhance the contribution or improve the self-training scheme. Without actionable guidance or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality of the results. This feedback is explicit and provides a clear action for the authors to take, which is to include these zoomed-in regions in their paper. The suggestion is concrete, as it specifies exactly what needs to be added to the paper to improve the clarity of the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results shown in the paper are low-resolution and recommends providing zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. However, it does not specify which part of the paper this suggestion pertains to, such as specific figures or sections where the low-resolution issue is observed. While the authors might have an idea of where these images are presented, the comment lacks full grounding. It is specific in suggesting a way to improve the resolution, but without explicit references, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results shown in the paper are low-resolution and recommends providing zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. However, the comment does not provide any supporting evidence or reasoning to justify why the current resolution is insufficient or how providing zoomed-in regions would improve the results. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s results, noting that they are low-resolution. It suggests a potential solution by recommending the inclusion of zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and detail of the results. By addressing this issue, the authors can enhance the quality of their paper and make their findings more accessible to readers. However, the comment could be more helpful if it explained why the current resolution is insufficient or how the suggested changes would improve the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the comparative inference method: the increase in inference cost due to multiple forward passes and the need for post-hoc calibration validation data, which may not be readily available for open-ended generation tasks. While the comment identifies these concerns, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to consider the computational cost and the availability of validation data, but the comment lacks concrete suggestions on how to mitigate these issues or improve the method. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the comparative inference method, including the increase in inference cost due to multiple forward passes and the need for post-hoc calibration validation data. It provides a clear rationale for these concerns, which are relevant to the applicability of the method in real-world applications. However, the comment does not explicitly mention which part of the paper discusses the comparative inference method, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issues with the inference method and its applicability, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparative inference method increases the inference cost significantly due to multiple forward passes, which may be a concern for real-world applications with limited computational resources. It also notes that the post-hoc calibration requires validation data, which may not be readily available for open-ended generation tasks. These claims are supported by logical reasoning and common knowledge about the limitations of computational resources in real-world applications. However, the comment could be strengthened by providing specific examples or references to studies that have encountered similar issues. Despite this, the claims are mostly verifiable, as they are based on reasonable assumptions and observations.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two significant issues with the comparative inference method: the increase in inference cost due to multiple forward passes and the need for post-hoc calibration validation data, which may not be readily available for open-ended generation tasks. These are important concerns that could impact the applicability of the method in real-world applications. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or mitigate their impact. While it highlights potential weaknesses, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the authors\\' approach to handling exploding gradients, suggesting that they perform gradient clipping with a high value for the gradient norm to avoid NaNs. The reviewer also criticizes the authors\\' method of simply reinitializing the model as hacky. While the comment implies that the authors should consider alternative methods, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative methods to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L265,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\\' approach to handling exploding gradients and suggests an alternative method of gradient clipping with a high value for the gradient norm to avoid NaNs. The comment provides a clear direction for improvement by critiquing the hacky nature of simply reinitializing the model. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' approach to handling exploding gradients, suggesting that they perform gradient clipping with a high value for the gradient norm to avoid NaNs. The reviewer criticizes the authors\\' method of simply reinitializing the model as hacky. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that gradient clipping is a better approach. This makes the claim somewhat verifiable, as the authors would need to further explore the issue and consider the merits of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' approach to handling exploding gradients, suggesting that they perform gradient clipping with a high value for the gradient norm to avoid NaNs. The reviewer also critiques the authors\\' method of simply reinitializing the model as hacky. While the comment provides a clear direction for improvement, it lacks depth and does not offer specific guidance on how to implement the suggested solution or why it is more effective. The feedback is somewhat helpful as it points out a potential weakness but could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for a more detailed explanation of the term \"common pattern,\" indicating that the authors need to clarify this concept. This is a direct and concrete action for the authors to take, as it clearly specifies what needs to be addressed. The comment provides a clear direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the exact meaning of \"common pattern\" and the need for a more detailed explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the term \"common pattern.\" It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the term \"common pattern,\" which is not clearly defined in the paper. By asking for a more detailed explanation, the reviewer highlights a potential gap in the clarity and comprehensibility of the paper. This feedback is actionable as it directs the authors to provide a clearer explanation of the term, which could improve the overall understanding and accessibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this explanation or provided examples of what a detailed explanation might entail. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks depth in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that all five downstream datasets are related to Reddit, which raises a concern about whether the pre-trained model could generalize to datasets from other sources, such as Twitter or Facebook. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting experiments or analyses to test generalizability. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of generalizability to datasets outside of Reddit, specifically mentioning Twitter and Facebook. However, it does not specify which part of the paper this concern is discussed in, making it weakly grounded. The comment is specific in identifying the concern about generalizability, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets outside of Reddit, specifically mentioning Twitter and Facebook. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or analysis, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the generalizability of the pre-trained model to datasets outside of Reddit, specifically mentioning Twitter and Facebook. This is a relevant concern that could impact the applicability and robustness of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses to test generalizability. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors ensure the quality of the generated dataset, specifically mentioning that LLM often hallucinates. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific steps the authors should take to address this issue or how to ensure the quality of the generated dataset. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the quality check of the generated dataset, specifically mentioning that LLM often hallucinates. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where the dataset is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the dataset quality check are questionable or how the authors might address these concerns. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the quality check of the generated dataset, specifically mentioning that LLM often hallucinates. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that LLM often hallucinates. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the quality check of the generated dataset, specifically mentioning that LLM often hallucinates. This is a relevant point that could prompt the authors to consider the robustness and reliability of their dataset. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the quality check. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the comparison across four models, suggesting that the fine-tuned wav2vec model might perform better than the others. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting ways to improve the comparison or provide additional analysis. As a result, the authors are left without any clear direction on how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the comparison across four models, specifically mentioning the fine-tuned wav2vec model and the other three models that are trained from scratch. This provides some grounding by allowing the authors to identify the part of the paper being discussed, which is the comparison across models. However, the comment lacks specificity as it does not detail what is problematic about the comparison or how it could be improved. Without specific guidance or examples, the authors may struggle to understand the exact issue and how to address it. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the comparison across four models might not be meaningful because the wav2vec model is fine-tuned, while the others are trained from scratch. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide details on why the fine-tuning of the wav2vec model would necessarily lead to better performance or how this affects the comparison across models. Without additional context or examples, the claim remains unverifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the comparison across four models, suggesting that the fine-tuned wav2vec model might perform better than the others due to its fine-tuning. This is a relevant point that could impact the interpretation and conclusions of the study. However, the comment lacks specificity and actionable suggestions on how to address this issue or improve the comparison across models. It does not provide guidance on how to conduct a more meaningful comparison or what aspects of the models should be considered in the analysis. As a result, the comment is somewhat helpful, as it identifies a potential weakness but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is dense and provides a specific example by mentioning Figure 2, which could be used to illustrate the point. However, it does not explicitly instruct the authors to include more examples or provide guidance on how to make the paper less dense. The action is implied and somewhat vague, as the authors need to infer that they should include more examples to improve the readability. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is dense and provides an example by mentioning Figure 2, which could be used to illustrate the point. However, it does not specify which part of the paper is considered dense or how it compares to other papers. The authors can infer that the issue is related to the density of the paper, but they cannot confidently determine which sections or aspects are being addressed. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the inclusion of more examples. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is dense, comparing it to other pure-math ML papers. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of Figure 2 is a suggestion for improvement but does not fully substantiate the claim of density. The comment lacks the necessary evidence or detailed reasoning to make the claim fully verifiable, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the paper is dense, comparing it unfavorably to other pure-math ML papers. It provides a specific example by mentioning Figure 2, which could be used to illustrate the point. This feedback is somewhat helpful as it identifies a potential issue with the paper's readability and suggests a specific area for improvement. However, the comment lacks depth and does not provide detailed guidance on how to address the issue of density or suggestions for improving the clarity of the paper. While it points out a potential problem, it does not offer comprehensive advice, making it somewhat helpful but not fully actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the introduction of high-level intuition in section 4.2 and the lack of it in section 4.1. While it identifies an issue, it does not provide explicit guidance on how to address this discrepancy. The authors are left to infer that they should ensure a consistent introduction of high-level intuition across sections. The action is implicit and somewhat vague, as it lacks concrete steps on how to implement the suggested improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4.2\" and \"4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the inconsistency in the introduction of high-level intuition between sections 4.2 and 4.1. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the inconsistency in the introduction of high-level intuition between sections 4.2 and 4.1. However, it does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the paper\\'s clarity or coherence. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that section 4.2 provides high-level intuition while section 4.1 does not. This feedback highlights a potential inconsistency in the paper\\'s structure and content, which could impact the reader\\'s understanding and comprehension. However, the comment does not provide detailed guidance or suggestions on how to address this issue, such as recommending a consistent approach to introducing high-level intuition across sections. While it points out a problem, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more discussions on the obtained permutation matrices, specifically mentioning Figure (e)(j)(o) in Figure 3. While the comment implies that the authors should include additional discussions, it does not explicitly instruct them to do so or provide guidance on what specific aspects of the permutation matrices should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should add more discussions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure (e)(j)(o) in Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of more discussions on the obtained permutation matrices. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Figure (e)(j)(o) in Figure 3 represents obtained permutation matrices and recommends including more discussions on these matrices. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these discussions are necessary or how they would improve the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that Figure (e)(j)(o) in Figure 3 represents obtained permutation matrices and recommends including more discussions on these matrices. While the comment identifies a specific area for improvement, it lacks depth and does not provide detailed guidance on what aspects of the permutation matrices should be discussed or how this could enhance the paper. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not offer actionable steps or examples to help the authors effectively address the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the crowd workers, asking for information on how they were recruited and trained. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include this information but may not be entirely sure of the exact details or format. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the crowd workers, specifically asking for information on how they were recruited and trained. However, it does not specify which part of the paper this information should be included in, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact location of the relevant information. The comment is specific in its request for details about the crowd workers, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for information about the crowd workers, such as how they were recruited and trained. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the crowd workers, specifically asking for information on how they were recruited and trained. This is a relevant inquiry that could help the authors ensure the validity and reliability of their results. However, the comment lacks depth and does not provide specific guidance on how to address these questions or what kind of information should be included. While it identifies a potential area for improvement, it does not offer actionable steps or detailed suggestions for the authors to enhance their draft. Therefore, the comment is somewhat helpful, as it points out a gap in the paper but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It also emphasizes the importance of human evaluations. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or improve their evaluation methods. The action is implicit and somewhat vague, as the authors need to infer that they should focus on human evaluations and consider the validity and robustness of their conclusions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"weakly correlated human evaluation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications and questioning the validity and robustness of the conclusions. The comment also emphasizes the importance of human evaluations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the correlation between automatic metrics and human evaluations is weak, suggesting that the automatic metrics may not fully capture the quality of the simplifications. This claim is somewhat verifiable as it logically follows from the observation of weak correlation, but it lacks specific examples or references to support the claim. The authors might need to infer the implications of this claim and consider the potential impact on the validity and robustness of their conclusions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It highlights the importance of human evaluations in assessing the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the evaluation process. While it points out a relevant concern, it does not provide actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to be more specific about the \"Chain of Reasoning\" section, particularly line 276. This provides a clear and direct action for the authors to take, as it specifies the exact part of the paper that needs more detail. The comment is specific and concrete, giving the authors a clear understanding of what needs to be addressed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 276,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the \"Chain of Reasoning\" section and line 276. This provides clear guidance on what the authors need to focus on to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests more specificity in the \"Chain of Reasoning\" section, particularly line 276. However, it does not provide any supporting evidence, reasoning, or examples to justify why this specificity is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area of the paper that needs more detail, particularly the \"Chain of Reasoning\" section and line 276. This feedback is clear and actionable, as it directs the authors to provide more specific information in a particular part of the paper. However, the comment could be more helpful if it offered suggestions on what kind of details or examples would be beneficial for clarity. Overall, the comment provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a sample quality metric on the CARLA data, specifically mentioning the common metric minADE or minMSD. This feedback is explicit and provides a clear action for the authors to take, as it specifies the exact metric to include and its purpose in evaluating the quality of the samples. The comment is concrete, as it directly instructs the authors on what to add to their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ability to perform hypothetical inference/planning\" and refers to the demonstration using a graphical model and likelihood function. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests including a sample quality metric, such as minADE or minMSD, and provides a clear example of what this metric entails. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there should be a sample quality metric on the CARLA data, specifically mentioning the common metric minADE or minMSD. The reviewer provides a brief explanation of what these metrics are, noting that they are computed by fixing a budget of samples. However, the comment lacks detailed justification or examples of how these metrics would be applied or how they would improve the paper. While the suggestion is logical, the lack of specific examples or detailed reasoning makes it somewhat verifiable. The authors would need to further explore the metric and its relevance to their work to fully understand and address the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the inclusion of a sample quality metric on the CARLA data, specifically mentioning the common metric minADE or minMSD. This feedback is actionable and constructive, as it offers a clear and concrete way for the authors to enhance their work by incorporating a metric that could improve the evaluation of their results. By addressing this suggestion, the authors can strengthen the robustness and generalizability of their findings. However, the comment could be more helpful if it provided additional context or examples on how to apply these metrics in the context of the paper. Overall, the comment is mostly helpful as it offers a clear and actionable path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the assumption that every constraint and corresponding discriminator can be naturally assumed. However, it does not provide any guidance or suggestions on how the authors should address this assumption or what changes they should make to their draft. The comment lacks explicit or implicit actions, leaving the authors uncertain about how to proceed. Since there is no actionable advice or direction, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the assumption that every constraint and corresponding discriminator can be naturally assumed. However, it does not specify which part of the paper this assumption is discussed in, nor does it provide any context or guidance on how the authors should address this question. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. The comment is not specific because it does not provide details on what needs to be clarified or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about an assumption made in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the assumption that every constraint and corresponding discriminator can be naturally assumed. While it highlights a potential issue with the paper\\'s assumptions, it does not provide any guidance or suggestions on how the authors might address this concern or improve their draft. The comment lacks actionable feedback or specific suggestions for improvement, making it barely helpful. The authors are left with a vague understanding of the issue but without clear direction on how to address it. Therefore, the comment aligns with a score of 2, indicating that it is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss Wasserstein GAN (WGAN) or even include it as a baseline method. While the comment implies that the authors should add a discussion on WGAN or include it as a baseline, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment somewhat actionable. The authors can infer that they need to add a discussion or include WGAN as a baseline, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Optimal Transport (OT)\" and \"Wasserstein Distance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors discuss Wasserstein GAN (WGAN) or include it as a baseline method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using Optimal Transport (OT) or Wasserstein Distance in GANs was first introduced in the Wasserstein GAN (WGAN) paper by Arjovsky et al. (ICML 2017). However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the paper that could be improved by discussing Wasserstein GAN (WGAN) or including it as a baseline method. This suggestion is clear and actionable, as it provides a concrete direction for the authors to enhance their work by either including a discussion on WGAN or adding it as a baseline. By addressing this feedback, the authors can improve the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided additional context or examples on why WGAN is relevant or how it could be integrated into the paper. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of important related work on MCMC in discrete spaces and suggests that the paper should discuss methods that have applied Langevin MCMC to discrete sequences. It also points out that the paper may not meet the standards expected for a conference publication due to issues with clarity and organization. While the comment provides specific references to relevant works, it does not offer detailed guidance on how to incorporate these references or improve the clarity and organization of the paper. The action is explicit but somewhat vague, as the authors know they need to discuss related work but may not be entirely sure how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of important related work on MCMC in discrete spaces and suggests that the paper should discuss methods that have applied Langevin MCMC to discrete sequences. It also provides specific references to two relevant works, which helps the authors identify the exact parts of the paper that need attention. However, the comment does not specify what needs to be addressed or improved in these sections, such as how the related work could be integrated or what aspects of clarity and organization need attention. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper is more suitable for a workshop due to its preliminary results and issues with clarity and organization. It supports this claim by referencing two specific works that have applied Langevin MCMC to discrete sequences, which should be discussed in the paper. These references provide a logical basis for the claim, as they demonstrate the relevance of related work to the paper\\'s topic. However, the comment could be strengthened by further explaining why these references are important or how they relate to the paper\\'s contributions. Overall, the claim is mostly verifiable, as it is supported by specific references but could be improved with additional justification or explanation.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of important related work on MCMC in discrete spaces. It suggests that the paper should discuss methods that have applied Langevin MCMC to discrete sequences, which is a relevant and potentially impactful area for the paper. Additionally, the comment acknowledges the preliminary nature of the results and the issues with clarity and organization, suggesting that the paper may not yet meet the standards expected for a conference publication. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific guidance on how to incorporate the suggested related work or improve the clarity and organization of the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the different methods used by DS-FedDRO and FedDRO to estimate $g$. While it does not explicitly instruct the authors to address this question, it implies that the authors should clarify or explain the reasoning behind the different methods used. The action is implicit but concrete, as it points to a specific area that needs clarification. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DS-FedDRO\" and \"FedDRO,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks a question about the different methods used by these two approaches to estimate $g$. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the different methods used by DS-FedDRO and FedDRO to estimate $g$. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the different methods used by DS-FedDRO and FedDRO to estimate $g$. While it highlights an area of potential confusion, it does not provide any guidance or suggestions for improvement. The comment lacks actionable feedback or context that would help the authors understand how to address this issue or improve their draft. As a result, it offers limited value to the authors in terms of enhancing the clarity or comprehensiveness of their work. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there should be a discussion about the differences between Nicekl Kiela and l. However, it does not provide any guidance on what specific aspects of these differences should be discussed or how the authors should approach this discussion. The comment lacks explicit instructions or concrete details on how to implement this suggestion, leaving the authors uncertain about how to proceed. As a result, the action is vague and not actionable, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests a discussion about the differences between Nicekl Kiela and l, but it does not specify which part of the paper this discussion should be included in. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what aspects of these differences should be discussed or how they should be addressed. Without clear guidance, the authors cannot effectively identify the areas that need revision. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there should be a discussion about the differences between Nicekl Kiela and l. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary information to support the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there should be a discussion about the differences between Nicekl Kiela and l. However, it does not provide any context or explanation about why this discussion is important or how it could benefit the paper. Without additional information or guidance, the authors are left without a clear understanding of what aspects of these differences should be discussed or how they could enhance the paper. As a result, the comment lacks actionable feedback and does not assist the authors in improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, it does not provide explicit guidance on how the authors should address these issues. The comment lacks specific suggestions or actions for the authors to take, such as recommending additional experiments or suggesting how to conduct variance analysis. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of multiple experiment runs and variance analysis for the results. However, it does not specify which part of the paper this issue pertains to, such as the experimental section or the results section. Without explicit references to sections or figures, the authors cannot confidently determine where to address these concerns. Additionally, the comment lacks specificity regarding what aspects of the experiments or variance analysis are lacking. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental design, noting that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. This is a critical observation that could impact the validity and reliability of the findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or discussing potential implications of the lack of variance analysis. While it points out a significant weakness, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a gap in the paper regarding the lack of consideration of real-world dataset qualities and temporal drifts in data distributions. It explicitly points out that these factors are not accounted for in the experiments, which is a clear and direct action for the authors to take. The comment provides a specific area for improvement, indicating that the authors should consider these factors in their experiments. However, it does not offer detailed guidance on how to address these gaps or suggest specific methods to incorporate real-world dataset qualities. While the action is explicit, it lacks concrete details on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"gaps with real-world datasets\" and the \"experiments conducted in the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of consideration for factors such as dataset qualities and temporal drifts in data distributions, which are important aspects for achieving label efficiency with a human in the loop. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are gaps in the paper regarding the consideration of real-world dataset qualities and temporal drifts in data distributions. The reviewer acknowledges that these factors are not accounted for in the experiments, which is a valid observation. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of these factors and how they might impact the results, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the consideration of real-world dataset qualities and temporal drifts in data distributions. It points out that these factors are not accounted for in the experiments, which is a critical issue for achieving label efficiency with a human in the loop. By highlighting this gap, the comment provides the authors with a clear and actionable suggestion for improving their work. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these factors into the experiments or provided examples of how they might impact the results. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the communication cost provided in the paper (O(SAH^2) or O(MSAH^2)) is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated that O(H) communication rounds are sufficient. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left to infer that they should consider whether their communication cost is justified or if it needs to be revised, but no guidance is given on how to achieve this. The comment lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the communication cost provided in the paper, specifically mentioning the values O(SAH^2) or O(MSAH^2). However, it does not specify which part of the paper this communication cost is discussed in, making it weakly grounded. The comment is specific in pointing out that the communication cost is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated that O(H) communication rounds are sufficient. This provides clear guidance on what needs to be addressed, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the communication cost provided in the paper is not particularly low or noteworthy, as other federated Q-learning algorithms have demonstrated that O(H) communication rounds are sufficient. However, the comment lacks specific references to these algorithms or detailed reasoning to support the claim that O(H) is sufficient. Without such references or detailed explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the communication cost provided in the paper, noting that it is not particularly low or noteworthy given that other federated Q-learning algorithms have demonstrated that O(H) communication rounds are sufficient. This feedback is somewhat helpful as it points out a specific area where the paper may need improvement, but it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. The comment highlights a potential weakness but does not offer detailed advice on how to improve the communication cost or what specific aspects of the paper should be revised. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the main idea of using an ensemble of neural networks is common in machine learning literature and that the paper does not provide any specific adaptation to the homomorphic encryption domain. However, it does not provide any guidance on what specific adaptation should be added or how the authors might address this issue. The comment lacks actionable details, such as suggesting specific approaches or methods that could be used to enhance the paper in the context of homomorphic encryption. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper for not providing specific adaptations to the homomorphic encryption domain, despite the use of an ensemble of neural networks being a common practice in machine learning. However, it does not specify which part of the paper discusses this idea or where specific adaptations should be added. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in identifying the issue of lacking adaptation, but it is not grounded as it does not point to a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main idea of using an ensemble of neural networks is trivial and common in machine learning literature, and that the paper does not provide any specific adaptation to the homomorphic encryption domain. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the main idea of using an ensemble of neural networks is common in machine learning literature and that the paper lacks specific adaptations to the homomorphic encryption domain. This feedback highlights a critical gap in the paper, as it does not provide any novel contributions or insights specific to the homomorphic encryption context. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or what specific adaptations could be considered. Without actionable advice or examples, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding why and how the new model for detecting overlapping entities in text works better than the previous state-of-the-art, MH. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should provide more detailed explanations or examples to demonstrate the improvements, but it does not specify what aspects need to be clarified or how to do so. As a result, the action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be improved but without concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper presents a new model for detecting overlapping entities in text and that the new model improves the previous state-of-the-art, MH, in experiments on a few benchmark datasets. However, it notes that the paper does not explain why and how the new model works better. This provides clear guidance on what needs to be addressed in the General Discussion section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents a new model for detecting overlapping entities in text and that it improves the previous state-of-the-art, MH, in experiments on a few benchmark datasets. However, the comment lacks specific examples or detailed reasoning to support why the new model works better or how it improves over the previous state-of-the-art. Without these details, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that while the authors present a new model for detecting overlapping entities in text, they do not provide a clear explanation of why and how the new model works better than the previous state-of-the-art, MH. This feedback is valuable as it highlights a critical area for improvement in the paper, namely the lack of detailed explanation and justification for the model's performance. However, the comment could be more helpful if it suggested specific ways to address this issue, such as providing additional experimental results or detailed theoretical explanations. Overall, the comment is somewhat helpful as it points out a significant gap in the paper but lacks actionable guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the formula used in the Adjective Projection part is not reasonable and provides a specific alternative approach. It suggests that the authors should first calculate the similarity between \"large\" and the object, then \"small\" and the object, respectively, before calculating the difference between the two similarities. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Adjective Projection part,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the formula used in this part, suggesting that the authors should calculate the similarity between \"large\" and the object, then \"small\" and the object, respectively, before calculating the difference between the two similarities. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the formula used in the Adjective Projection part is not reasonable, suggesting that the authors should calculate the similarity between \"large\" and the object, then \"small\" and the object, respectively, before calculating the difference between the two similarities. The reviewer provides a logical reasoning for this claim by explaining that the current approach uses the similarity between the object embedding and the difference between \"large\" and \"small\" embeddings. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors may find it challenging to fully understand and address the issue without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formula used in the Adjective Projection part, suggesting that the approach is not reasonable for estimating whether an object is large or small. It provides a clear and actionable suggestion by proposing an alternative method for calculating the similarity between \"large\" and the object, then \"small\" and the object, respectively, before calculating the difference between the two similarities. This feedback is valuable as it offers a concrete and logical alternative that could improve the paper\\'s methodology. However, the comment could be more helpful if it included additional context or examples to further explain the rationale behind the suggested approach. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaning of \\sigma_k = sigmoid(\\\\sigma_k) in line 121 and suggests that the authors elaborate on the issues mentioned. While the comment implies that the authors should clarify the meaning of this equation, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the equation and address the issues mentioned. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 121,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \\sigma_k = sigmoid(\\\\sigma_k) and suggests that the authors elaborate on the issues mentioned. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the meaning of a specific equation in the paper, specifically \\sigma_k = sigmoid(\\\\sigma_k) in line 121. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, questioning the meaning of an equation in line 121. It suggests that the authors elaborate on the issues mentioned, which could provide valuable insights into the methodology and its implications. While the comment highlights a potential area for clarification, it does not offer specific suggestions or guidance on how to address the issue. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss and compare their work on any-resolution generation to more recent works that specifically focus on any-resolution image generation. It provides specific references to two recent works, [1] and [2], which are relevant to the topic. While the comment does not explicitly instruct the authors to conduct a comparison or discuss these works, it clearly implies that such an analysis would be beneficial. The action is implicit but concrete, as the authors can infer the need to include a comparison and understand the specific references to follow. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests discussing and comparing the advantage of any-resolution generation to more recent works that specifically focus on any-resolution image generation. It provides specific references to two recent works, [1] and [2], which are relevant to the topic. However, the comment does not specify which part of the paper should include this discussion or comparison, making it weakly grounded. The comment is specific in suggesting the need for a comparison with recent works, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the claim about the advantage of any-resolution generation should be discussed and compared with more recent works that specifically focus on any-resolution image generation. The reviewer provides specific references to two recent works, [1] and [2], which are relevant to the topic. This provides a clear and concrete basis for the claim, making it mostly verifiable. However, the comment could be strengthened by explaining why these references are particularly relevant or how they support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss and compare their work on any-resolution generation to more recent works that specifically focus on any-resolution image generation. It provides specific references to two recent works, [1] and [2], which are relevant to the topic. This feedback is actionable as it directs the authors to include a comparison with these works, which could enhance the paper\\'s contribution and relevance. However, the comment could be more helpful if it explained why these specific references are important or how the comparison would benefit the paper. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the paper, including the limited number of subjects in the test set, the lack of discussion on limitations, and the need for a more detailed explanation of the theoretical assumptions and implementation considerations. It also suggests discussing the relative improvement of ODER over RED (Unfold) or RED (Denoising) and how the training time compares with online learning alternatives. While the comment provides explicit actions for the authors to take, such as discussing limitations and theoretical assumptions, it does not specify how to implement these suggestions or what specific details should be included in the discussion. The authors are left with a clear understanding of what needs to be addressed but may need to infer the exact steps to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the CT experiment, such as the limited number of subjects and the need for a more comprehensive discussion of limitations. The comment also suggests discussing theoretical assumptions, implementation considerations, and the relative improvement of ODER over RED (Unfold) or RED (Denoising). This provides clear guidance on what needs to be addressed in Section 6. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the limited number of subjects in the test set and the lack of discussion on limitations in Section 6. It suggests that the authors should discuss theoretical assumptions, implementation considerations, and the relative improvement of ODER over RED (Unfold) or RED (Denoising). The comment also questions the training time comparison with online learning alternatives. While the comment identifies potential issues, it lacks specific examples or references to support the claims about overfitting or the need for a more comprehensive discussion of limitations. The suggestion to discuss theoretical assumptions and implementation considerations is logical, but the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the limited number of subjects in the test set, the lack of discussion on limitations, and the need for a more comprehensive explanation of theoretical assumptions and implementation considerations. It also suggests discussing the relative improvement of ODER over RED (Unfold) or RED (Denoising) and how the training time compares with online learning alternatives. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or what aspects of the limitations should be discussed in detail. Overall, the comment is mostly helpful as it guides the authors toward improving the comprehensiveness and depth of their discussion, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the paper regarding the bound on the 2-Wasserstein, noting that it is stated as $O(\\\\epsilon^2)$ but is actually the bound on the 2-Wasserstein squared. While the comment identifies the issue, it does not provide explicit guidance on how to correct this mistake or suggest a way to clarify the error. The authors are left to infer that they need to correct the error, but without specific instructions or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 216 and 217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the paper regarding the bound on the 2-Wasserstein, noting that it is stated as $O(\\\\epsilon^2)$ but is actually the bound on the 2-Wasserstein squared. This provides clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the bound on the 2-Wasserstein is stated incorrectly as $O(\\\\epsilon^2)$ but is actually the bound on the 2-Wasserstein squared. This claim is somewhat verifiable as it provides a specific example of a discrepancy in the paper, which could be challenging for the authors to verify without additional context or explanation. However, the comment lacks detailed reasoning or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific discrepancy in the paper regarding the bound on the 2-Wasserstein, noting that it is stated as $O(\\\\epsilon^2)$ but is actually the bound on the 2-Wasserstein squared. This is a clear and actionable point that the authors can address to improve the accuracy and clarity of their work. However, the comment could be more helpful if it provided suggestions on how to correct this error or explained why this discrepancy is important. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the difference between the proposed multi-scale hierarchical predictor and other methods, such as IEConv, CDConv, and others. It suggests that the authors should provide a comparison between their method and these existing methods. However, the comment does not explicitly instruct the authors on how to conduct this comparison or what specific aspects to focus on. While the action is implied, it is not concrete, as the authors need to infer the details of how to address the comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"multi-scale hierarchical predictor\" and \"IEConv, CDConv, and other methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for a comparison between the proposed method and these existing methods, providing a clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification and comparison with other methods. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the difference between the proposed multi-scale hierarchical predictor and other methods, such as IEConv, CDConv, and others. It suggests that the authors should provide a comparison between their method and these existing methods. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct the comparison or what aspects to focus on. The authors are left with a general direction but no detailed instructions or examples on how to address the issue. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the paper does not read well and suggests that more careful proofreading is needed. However, it does not provide specific guidance on what aspects of the paper need improvement or how to address the issue of poor readability. The authors are left to infer that they need to improve the readability of their paper, but without concrete suggestions or examples, they may struggle to know where to focus their efforts. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper does not read well and needs more careful proofreading. However, it does not specify which parts of the paper are problematic or how the proofreading should be conducted. Without explicit references to sections, figures, or specific issues, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are problematic or how to improve the readability. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not read well and suggests that more careful proofreading is needed. However, the comment does not provide any specific examples or reasoning to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper does not read well and needs more careful proofreading. However, it lacks specificity and does not provide any guidance on what aspects of the paper are problematic or how to improve the readability. Without actionable feedback or examples, the authors are left without a clear understanding of what changes are needed to enhance the readability of their paper. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should analyze the distribution of addressing coefficients (Betas) with and without sequential addressing bias. It also questions the value of the trade-off parameter (Theta) and its selection process. Additionally, the reviewer inquires about the baseline performance if the attention from the previous question was simply used. While the comment provides specific actions for the authors to take, such as analyzing the distribution of Betas and explaining the selection of Theta, it lacks concrete details on how to conduct the analysis or what specific aspects of the analysis should be addressed. The suggestion to compare the baseline with the use of previous question attention is somewhat vague. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the distribution of addressing coefficients (Betas) and the trade-off parameter (Theta), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for analysis on the distribution of Betas with and without sequential addressing bias, as well as the value of Theta and its selection process. Additionally, it raises a question about the baseline performance with a simple attention mechanism. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should analyze the distribution of addressing coefficients (Betas) with and without sequential addressing bias, and questions the value of the trade-off parameter (Theta). It also asks about the baseline performance with a simple attention mechanism. While the comment provides a logical basis for these inquiries, it lacks specific examples or references to support the claim that these analyses are necessary or that the trade-off parameter is crucial. The suggestion to compare the baseline with a simple attention mechanism is somewhat vague, as it does not specify how this would be done or what specific aspects of the analysis should be addressed. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claims but lacks detailed evidence or references to fully substantiate them.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors analyze the distribution of addressing coefficients (Betas) with and without sequential addressing bias. It also questions the value of the trade-off parameter (Theta) and its selection process, which is important for understanding the synthetic task. Additionally, the comment inquires about the baseline performance with a simple attention mechanism, which could be a valuable comparison. This feedback is specific and offers detailed guidance on areas for improvement, making it highly helpful for the authors to enhance their draft. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is appropriate. The reviewer also expresses a personal opinion that decorative math is not needed, as the paper is already interesting. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the reviewer\\'s concerns or suggestions for improvement. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is appropriate. However, it does not specify which part of the paper discusses Proposition 1 or where it is located, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspect of Proposition 1 is problematic or how it could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is appropriate. The reviewer also expresses a personal opinion that decorative math is not needed, as the paper is already interesting. However, the comment lacks specific reasoning or evidence to support why Proposition 1 is unnecessary or how it detracts from the paper. Without detailed justification or references, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is appropriate. The reviewer also expresses a personal opinion that decorative math is not needed, as the paper is already interesting. However, the comment lacks specificity and actionable suggestions for improvement. It does not provide guidance on how the authors might address the reviewer\\'s concerns or improve the paper. As a result, the comment is not helpful, as it does not offer constructive feedback or direction for the authors to enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the evaluation of defense techniques, specifically in the context of backdooring classification. It suggests that the evaluation of defenses relying on input perturbation is crucial for a comprehensive understanding of the attacks. The reviewer provides specific references to relevant works by Doan et al. (Lira: Learnable, imperceptible and robust backdoor attacks, ICCV 2021; Backdoor attack with imperceptible input and latent modification, NeurIPS 2021) to support the claim. This explicit reference and suggestion for further evaluation make the action clear and concrete, providing the authors with a direct path to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"backdooring classification\" and the \"proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the limited evaluation of defense techniques and the importance of evaluating defenses relying on input perturbation. The comment provides specific references to relevant works by Doan et al. (Lira: Learnable, imperceptible and robust backdoor attacks, ICCV 2021; Backdoor attack with imperceptible input and latent modification, NeurIPS 2021), which further clarifies the need for evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a limited evaluation of defense techniques in the context of backdooring classification. The reviewer supports this claim by referencing specific works by Doan et al. (Lira: Learnable, imperceptible and robust backdoor attacks, ICCV 2021; Backdoor attack with imperceptible input and latent modification, NeurIPS 2021) that demonstrate the importance of evaluating defenses relying on input perturbation. This provides a solid foundation for the claim, as it references well-known and relevant works in the field. However, the comment could be strengthened by further explaining why these specific works are relevant or how they relate to the current paper. Overall, the claim is mostly verifiable, as it is supported by relevant references but could benefit from additional justification or explanation.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of defense techniques, specifically in the context of backdooring classification. It suggests that the evaluation of defenses relying on input perturbation is crucial for a comprehensive understanding of the attacks. The reviewer provides specific references to relevant works by Doan et al. (Lira: Learnable, imperceptible and robust backdoor attacks, ICCV 2021; Backdoor attack with imperceptible input and latent modification, NeurIPS 2021) to support the claim. This feedback is clear and actionable, as it directs the authors to consider evaluating these defenses in their work. By incorporating this suggestion, the authors can enhance their draft and provide a more comprehensive understanding of the defense techniques. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the related work section should be more focused and include similar datasets for non-English and underrepresented languages. It also points out that the context and evidence-based methods are presented inadequately in the related work. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to achieve this focus or what specific datasets should be included. The action is explicit but somewhat vague in terms of execution, as the authors know they need to enhance the related work section but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the related work section should be more focused and include similar datasets for non-English and underrepresented languages. It also critiques the presentation of context and evidence-based methods in the related work. However, the comment does not specify which part of the paper this related work section is located in, making it weakly grounded. The suggestion to include similar datasets is specific, but without full grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the related work section is not focused and lacks similar datasets for non-English and underrepresented languages. It also criticizes the presentation of context and evidence-based methods as being too shallow. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim borderline verifiable, as it requires more information to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the related work section, suggesting that it should be more focused and include similar datasets for non-English and underrepresented languages. It also points out that the context and evidence-based methods are presented inadequately in the related work. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their related work section and improve the depth of their analysis. However, the comment could be more helpful if it offered specific examples or guidance on how to present these datasets or methods more effectively. Overall, the comment is mostly helpful as it provides a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the authors\\' argument that BN can be folded into conv layers. It questions the logic of this claim, suggesting that BN after ReLU can be folded into the next Conv op because all activation in the same conv feature map shares the same mean, variance, scale, and offset in BN implementation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their argument. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to respond. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific paragraph (Table 2) and the experiment, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the authors\\' argument about folding BN into conv layers, questioning the logic of this claim. The comment provides a clear critique of the authors\\' reasoning and suggests an alternative explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' argument that BN can be folded into conv layers, suggesting that BN after ReLU can be folded into the next Conv op because all activation in the same conv feature map shares the same mean, variance, scale, and offset in BN implementation. However, the comment lacks specific examples or references to support this claim or to substantiate the authors\\' argument. Without additional context or evidence, the claim remains somewhat verifiable, as it requires the authors to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' argument regarding the folding of BN into conv layers. It questions the logic of this claim, suggesting that BN after ReLU can be folded into the next Conv op because all activation in the same conv feature map shares the same mean, variance, scale, and offset in BN implementation. This feedback is somewhat helpful as it points out a potential weakness in the authors\\' argument and provides a counterargument. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their argument. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should conduct experiments with larger networks to show a trend indicating whether the results from small-scale experiments will extend to larger scale experiments. This is a clear and concrete action for the authors to take, as it provides a specific direction for improving the paper by including larger-scale experiments. The comment is highly actionable because it clearly identifies what needs to be done and how to implement it.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of large-scale experiments and the need for experiments that vary the size of the network to show a trend indicating whether the results from small-scale experiments will extend to larger scale experiments. This provides clear guidance on what the authors need to do to improve their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the models used in the experiments are too small and suggests that larger-scale experiments would be beneficial. However, the comment does not provide specific examples or references to support this claim, such as data or studies that demonstrate the importance of larger-scale experiments. The lack of detailed evidence or reasoning makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of large-scale experiments and suggesting that the authors should conduct experiments with varying network sizes to show a trend indicating whether the results from small-scale experiments will extend to larger scale experiments. This feedback is clear and actionable, providing a specific direction for improvement that could enhance the robustness and generalizability of the results. However, the comment could be more helpful if it included examples of how such experiments might be conducted or what specific aspects of the results should be examined. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about what happens when W is an identity matrix and how the results compare with prior work in the spherical case. While the comment implies that the authors should address this issue, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications of W being an identity matrix and compare their results with prior work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about what happens when W is an identity matrix and how the results compare with prior work in the spherical case. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this discussion might be relevant. Without explicit references or clear indications, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the results should be compared or how the comparison should be conducted. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about what happens when W is an identity matrix and how the results compare with prior work in the spherical case. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about what happens when W is an identity matrix and how the results compare with prior work in the spherical case. While it identifies a potential area for further exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this question or what aspects of the results should be compared. The comment is somewhat helpful as it points out a potential area for improvement, but it does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive and actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the work focuses on CO problems on graphs rather than general MILP or QUBO problems, which limits its application scope. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or broaden the scope of their work. There is no guidance on whether the authors should consider expanding their focus to include other types of optimization problems or how they might do so. As a result, the comment lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the work focuses on CO problems on graphs rather than general MILP or QUBO problems, which limits its application scope. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue with the scope of the work, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work focuses on CO problems on graphs rather than general MILP or QUBO problems, which limits its application scope. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion and how it affects the scope of their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a limitation in the scope of the work, noting that it focuses primarily on CO problems on graphs rather than general MILP or QUBO problems. This feedback highlights an area where the authors could broaden the applicability of their work by considering other optimization problems. However, the comment does not provide specific suggestions or guidance on how to address this limitation or expand the scope of the research. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that learning both low- and high-frequency information in balance is not novel and suggests that the authors should analyze and compare their work with related works that promote uniformly learning various frequency domains by randomly masking frequency segments. The reviewer provides specific references to several related works, including the most recent one, which could guide the authors in their analysis and comparison. The comment is explicit in its request for analysis and comparison, providing concrete details on what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific aspect of the paper being addressed, which is the learning of low- and high-frequency information in balance. It also specifies the issue by pointing out that this is not a novel approach and suggests that the authors should analyze and compare their work with related works that promote uniformly learning various frequency domains by randomly masking frequency segments. The references provided are specific and relevant, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that learning both low- and high-frequency information in balance is not novel, citing several references to works that promote uniformly learning various frequency domains by randomly masking frequency segments. The reviewer provides specific references to these works, which supports the claim by demonstrating that the approach is not original. However, the comment could be strengthened by providing a more detailed analysis or critique of the originality of the approach, such as how it differs from the existing works. Despite this, the references provide a solid foundation for the claim, making it mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the novelty of the approach, noting that learning both low- and high-frequency information in balance is not novel. It provides a detailed list of references to related works that promote uniformly learning various frequency domains by randomly masking frequency segments. This feedback is clear and actionable, as it directs the authors to conduct an analysis and comparison with these related works to strengthen the originality of their approach. By suggesting specific references, the comment offers a concrete direction for the authors to enhance the novelty and impact of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends comparing the compression bandwidth of PC+IDF with IDF for Section 5. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve their draft. The comment is specific and leaves no ambiguity about the task, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of the compression bandwidth of PC+IDF with IDF. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the recommendation for comparing the compression bandwidth of PC+IDF with IDF for Section 5. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the recommendation or how it could be implemented. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improvement by recommending a comparison of the compression bandwidth of PC+IDF with IDF for Section 5. This feedback is clear and direct, guiding the authors on how to enhance their draft by including a relevant comparison. However, the comment could be more helpful if it explained why this comparison is important or how it would benefit the paper. Despite this, the suggestion is still valuable and offers a concrete step for the authors to take, making it mostly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model names T5-ind and T5-seq are misleading and proposes alternative names, such as Desc-ind/seq, Eg-ind, and Demo-ind/seq. While the comment provides specific suggestions for alternative names, it does not explain why the current names are misleading or how the proposed names would be more appropriate. The action is explicit but lacks concrete details on why the current names are problematic or how the proposed names would improve clarity. Therefore, the comment is somewhat actionable, as the authors know they need to consider alternative names but may not fully understand the rationale behind the suggestion.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the model names \"T5-ind\" and \"T5-seq,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests alternative names for the models, providing clear guidance on what needs to be changed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model names \"T5-ind\" and \"T5-seq\" are misleading. However, it does not provide any reasoning or evidence to support this claim, such as explaining why these names are misleading or suggesting alternative names that would be more appropriate. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the model names T5-ind and T5-seq, suggesting that they are misleading. It proposes alternative names, such as Desc-ind/seq, Eg-ind, and Demo-ind/seq, which could be more descriptive and informative. While the comment provides a specific suggestion for improvement, it lacks detailed reasoning or explanation as to why the current names are misleading or how the proposed names would be more appropriate. This limits the comment\\'s helpfulness, as it provides a clear action but does not fully guide the authors on why this change is necessary or how to implement it effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and notes its reuse in line 055. While the comment raises a concern about consistency, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should consider changing the acronym or ensuring consistency in its usage. The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the acronym \"AR\" for \"artificial intelligence\" and its reuse in line 055, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of acronym and its reuse, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and its reuse in line 055. However, it does not provide any reasoning or evidence to support why this choice is problematic or why it should be changed. The comment lacks any justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the choice of the acronym \"AR\" for \"artificial intelligence\" and its reuse in line 055. While it identifies a potential inconsistency in the paper, it does not provide any reasoning or explanation as to why this choice is problematic or how it might impact the clarity or coherence of the paper. The comment lacks depth and does not offer suggestions for improvement or alternative solutions, leaving the authors without clear guidance on how to address the issue. Therefore, the feedback is somewhat helpful, as it points out a potential problem but does not provide actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the core idea of the paper is to find a parameter to control the ratio of task-specific features to task-shared features, but it questions the motivation for the gating design in MTL. It also notes that the gating mechanism is not a new concept in MTL. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of unclear motivation or suggestions for improving the explanation of the gating design. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the core idea of the paper, which is to find a parameter to control the ratio of task-specific features to task-shared features. It also questions the motivation of the gating design for MTL and notes that the gating mechanism is not a new concept in MTL. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the motivation and the gating mechanism. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the core idea of the paper is to find a parameter to control the ratio of task-specific features to task-shared features, and questions the motivation of the gating design for MTL. The reviewer notes that the gating mechanism is not a new concept in MTL. However, the comment lacks specific examples or references to support the claim that the gating design is not novel. Without such evidence, the authors may find it challenging to address the critique effectively. Therefore, the claim is considered borderline verifiable, as it provides some reasoning but lacks detailed justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the motivation of the gating design for MTL. It points out that the gating mechanism is not a new concept in MTL, which could be problematic for the paper\\'s contribution. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their motivation. While it highlights a potential weakness, it lacks actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the practical applicability of the model due to the strong assumptions required for training, such as the availability of ground truth and DMs decisions. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate these assumptions or what specific steps to take to improve the practicality of the model. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practical applicability of the model, specifically highlighting the strong assumptions required for training, such as the availability of ground truth and DMs decisions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the assumptions required for training and how they impact the practicality of the model. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the practical applicability of the model is impaired by the strong assumptions required for training, such as the availability of ground truth and DMs decisions. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the practical applicability of the model due to the strong assumptions required for training, such as the availability of ground truth and DMs decisions. It highlights the challenges posed by these assumptions, which could impact the model\\'s effectiveness in real-world scenarios. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the practicality of their model. While it points out a relevant concern, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental part is less convincing, particularly regarding the comparison of LR and SVM-based baselines with deep learning approaches. However, it does not provide specific guidance on how the authors should address this issue or what changes they should make to improve the experimental part. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental part of the paper, specifically mentioning the comparison of LR and SVM-based baselines with deep learning approaches. However, it does not specify which part of the experimental section is less convincing or where the weaknesses lie. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in identifying the issue with the baselines being too weak compared to deep learning approaches, but it lacks grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental part is less convincing due to the weakness of LR and SVM-based baselines compared to deep learning approaches. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or comparisons to deep learning approaches that would help the authors understand the basis of the critique. As a result, the claim is somewhat verifiable, as it provides a general observation but lacks the necessary evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental part of the paper, noting that the LR and SVM-based baselines are too weak compared to deep learning approaches. This feedback is valuable as it highlights a potential weakness in the experimental design, which the authors can address to enhance the credibility and robustness of their results. However, the comment lacks detailed guidance or suggestions on how to improve the experimental design or strengthen the baselines. While it points out an area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation of the GLASU algorithm is to save communication, but neither the theorem nor the experiment discuss the communication cost. This implies that the authors should include a discussion on the communication cost in their paper. However, the comment does not explicitly instruct the authors to add this discussion, nor does it provide specific guidance on how to approach it. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on communication cost. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"communication-efficient\" and \"GLASU algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the theorem and experiment do not discuss the communication cost, which undermines the contribution of the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of the GLASU algorithm is to save communication, but neither the theorem nor the experiment discuss the communication cost. This is a subjective claim that lacks specific examples or references to support the assertion that the communication cost is not discussed. The comment does not provide detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the motivation of the GLASU algorithm is to save communication but that neither the theorem nor the experiment discuss the communication cost. This feedback highlights a gap in the paper that undermines the contribution, as the communication cost is an important aspect of the algorithm's efficiency. However, the comment does not provide suggestions or guidance on how the authors might address this issue or improve the discussion of communication cost. While it points out a critical area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explicitly state the contributions of their paper. This is a clear and direct action that the authors can take to improve their draft. The comment provides a concrete suggestion on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly states that the contributions of the paper should be explicitly stated, providing a clear indication of what needs to be addressed. However, it does not specify which part of the paper should include these contributions, making it weakly grounded. The comment is specific in its request for explicit contributions, but without grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the contributions of the paper should be explicitly stated. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area for improvement by suggesting that the contributions of the paper should be explicitly stated. This feedback is clear and actionable, as it provides a direct and concrete suggestion for enhancing the paper\\'s clarity and impact. By addressing this point, the authors can ensure that their work is more transparent and easily understood by readers. However, the comment could be more helpful if it offered additional guidance on how to effectively present the contributions or examples of how other papers have done so. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation of the work is not clear and that the explanation is not convincing. It suggests that the authors should justify the claim \"different densities directly will cause semantic conflicts\" either experimentally or theoretically. While the comment provides a clear action\u2014to justify the claim\u2014it does not specify how this should be done or what kind of evidence would be sufficient. The authors are left with a general idea of what needs to be addressed but without detailed guidance on how to implement the suggested improvements. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"different densities directly causing semantic conflicts\" and suggests that this should be justified experimentally or theoretically. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the clarity and justification of the claim. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of the work is not clear and that the explanation is not convincing. It suggests that the authors should justify the claim \"different densities directly will cause semantic conflicts\" either experimentally or theoretically. While the comment identifies a potential issue with the clarity of the motivation and the explanation, it lacks specific examples or references to support the claim that the explanation is not convincing. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity and persuasiveness of the motivation and explanation in the paper. It points out that the claim \"different densities directly will cause semantic conflicts\" is not adequately justified, either experimentally or theoretically. This feedback is valuable as it highlights a critical area for improvement in the paper, namely the need for a more robust justification of the claim. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue, such as recommending particular experiments or theoretical frameworks to explore. Overall, the comment is somewhat helpful as it directs the authors to a key area for improvement but lacks detailed guidance on execution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the training method of the transformer modules in the proposed approach, asking whether they are trained iteratively or in an end-to-end manner. It also points out that Figure 5 shows a similar visualization to Figure 1 and suggests that repeating visualizations is unnecessary if no new point is demonstrated. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the training method and possibly provide additional information or analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"the proposed approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the training method of the transformer modules and suggests that Figure 5 may be unnecessary if no new point is demonstrated. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training method of the transformer modules in the proposed approach, asking whether they are trained iteratively or in an end-to-end manner. It also questions the necessity of repeating visualizations if no new point is demonstrated. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper\\'s overall quality. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the training method of the transformer modules in the proposed approach, asking whether they are trained iteratively or in an end-to-end manner. It also points out that Figure 5 shows a similar visualization to Figure 1 and suggests that repeating visualizations is unnecessary if no new point is demonstrated. While the comment identifies a potential issue with the paper\\'s presentation, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. The feedback is somewhat helpful as it highlights a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides specific points for improvement, such as clarifying the terms \"parameters of BFNs\" versus \"parameters of BFN-produced distributions.\" It also suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that aren\\'t due to BFNs. These points are explicit and provide concrete guidance on how to improve the clarity and precision of the writing. The authors know exactly what needs to be done to enhance their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific points for improvement, such as \"parameters of BFNs\" versus \"parameters of BFN-produced distributions,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be clarified, providing clear guidance on how to improve the precision and clarity of the writing. Additionally, it suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that aren\\'t due to BFNs. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the writing could benefit from greater precision and clarity, providing specific examples of areas that need improvement, such as the terms \"parameters of BFNs\" versus \"parameters of BFN-produced distributions.\" It also suggests that the proposed method is closely related to infoDiffusion, with the main adaptation being its application to BFNs. The reviewer recommends that the authors clarify the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that aren\\'t due to BFNs. This claim is mostly verifiable as it provides logical reasoning and specific examples to support the need for clarity and precision in the writing. However, it could be strengthened by referencing external works or providing more detailed examples of where clarity is needed. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the clarity and precision of the writing, identifying areas where the authors could improve their draft. It highlights the need for clarity in terms like \"parameters of BFNs\" versus \"parameters of BFN-produced distributions\" and suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that aren\\'t due to BFNs. This feedback is clear and provides a concrete direction for the authors to enhance the clarity and precision of their writing. By addressing these points, the authors can significantly improve the quality of their draft, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the discussion in lines 60-74 and the text, suggesting that the authors may have implied a focus on a situation where the gradient of the sum is not the sum of individual gradients. The reviewer provides specific lines (70-74) where this issue is discussed and suggests that this could be discussed in less space. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to do so. While the action is implicit, it is clear that the authors need to reconsider their discussion in this section to ensure clarity and consistency with their claims. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lines 60-74 (beginning of Section 2), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a discrepancy between the discussion and the text, suggesting that the authors may have implied a focus on a situation where the gradient of the sum is not the sum of individual gradients. This is a clear and specific critique, providing the authors with a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors imply a focus on a situation where the gradient of the sum is not the sum of individual gradients, which is not communicated in the text. The reviewer supports this claim by referencing specific lines (70-74) where this issue is discussed, suggesting that it could be discussed in less space. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to carefully review the text to understand the basis of the claim and address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the discussion in lines 60-74 and the text, suggesting that the authors may have implied a focus on a situation where the gradient of the sum is not the sum of individual gradients. The reviewer provides specific lines (70-74) where this issue is discussed and suggests that it could be discussed in less space. This feedback is valuable as it points out a potential inconsistency in the paper that the authors should address to clarify their claims. However, the comment could be more helpful if it offered suggestions on how to rephrase or clarify the text to better align with the discussion. Overall, the comment is mostly helpful as it provides actionable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the proposed question-rewrite strategy, specifically questioning whether it covers a sufficiently large number of questions. The reviewer provides data from Table 4 in the appendix to support their claim, noting that 23% of passages become invalid and 44% are attributed to unresolved coreference. Additionally, the reviewer points out that the proposed method rewrites only 12% of questions for all models, which they deem insignificant. While the comment identifies a specific issue with the proposed method, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should improve the method to cover more questions or address the concerns raised. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed question-rewrite strategy\" and provides specific data from Table 4 in the appendix to support the claim. It also mentions the method\\'s effectiveness, which allows the authors to accurately identify the part of the paper being addressed. The comment is specific because it details the concerns about the method\\'s coverage and effectiveness, providing a clear rationale for the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed question-rewrite strategy does not cover a sufficiently large number of questions, as 23% of passages become invalid and 44% are attributed to unresolved coreference. The reviewer supports this claim by referencing data from Table 4 in the appendix, which provides a detailed breakdown of the number of questions that become invalid or unresolved. Additionally, the reviewer cites a specific line in the paper (L373) to support their claim about the method\\'s effectiveness. This provides a robust and verifiable basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific concern with the proposed question-rewrite strategy, questioning its effectiveness in covering a sufficiently large number of questions. The reviewer provides data from Table 4 in the appendix to support their claim, noting that 23% of passages become invalid and 44% are attributed to unresolved coreference. Additionally, the reviewer points out that the proposed method rewrites only 12% of questions for all models, which they deem insignificant. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and suggests that the authors should address this issue to improve the paper. However, the comment could be more helpful if it provided suggestions on how to improve the method or addressed the concerns raised by the data. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the use of L2 distance in equation (4) and suggests that earth mover's distance is more common in OT. It does not provide explicit guidance on what the authors should do, but it implies that they should consider the benefits of using earth mover's distance instead of L2 distance. While the action is implied, it is not stated directly, and the authors may need to infer the necessary steps to address the comment. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (4)\" and \"L2 distance,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of L2 distance in the context of OT and suggests that earth mover's distance is more common. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of L2 distance in equation (4) and suggests that earth mover's distance is more common in OT. However, it does not provide any supporting evidence, reasoning, or references to justify why earth mover's distance is preferable or why L2 distance is not appropriate. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of L2 distance in equation (4) and suggests that earth mover's distance is more common in OT. While it identifies a potential issue with the choice of distance metric, it does not provide any guidance or suggestions on how the authors might address this concern or why earth mover's distance might be preferable. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward. Therefore, it is rated as barely helpful, as it points out a potential weakness but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the description of related work is scattered throughout the paper and recommends a broader discussion on how the algorithm compares to other offline RL algorithms. While the comment implies that the authors should expand their discussion of related work, it does not provide specific guidance on how to structure this discussion or which aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"description of the related work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a broader discussion on how the algorithm compares to other offline RL algorithms, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the description of related work is scattered throughout the paper, with most relevant papers mentioned but not discussed comprehensively. The reviewer expresses a desire for a broader discussion on how the algorithm compares to other offline RL algorithms. However, the comment lacks specific examples or references to support the claim that the current discussion is insufficient. Without detailed evidence or comparisons, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary justification to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the description of related work is scattered throughout the document. It highlights the inclusion of most relevant papers, such as [14,15], but suggests a broader discussion on how the algorithm compares to other offline RL algorithms. This feedback is clear and actionable, as it provides a direction for the authors to expand their discussion of related work and enhance the paper\\'s comparative analysis. However, the comment could be more helpful if it offered specific suggestions on how to structure this broader discussion or what aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and depth of their related work discussion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how the final solution would change if all increments are available at the same time. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this question should be addressed in the paper, nor is there any suggestion for how the authors might respond to it. As a result, the comment lacks actionability, leaving the authors without any clear direction on how to proceed. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about how the final solution would change if all increments are available at the same time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspect of the solution would change or how this change would impact the paper. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the impact of having all increments available at the same time on the final solution. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment poses a question about the impact of having all increments available at the same time on the final solution. While it highlights an area of interest, it does not provide any guidance or suggestions for the authors to address this question or explore its implications in their work. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the use of multiple feature spaces in the paper, specifically mentioning the 25-feature space of Mitchell et al. and the full/pruned glove model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of circularity or how to simplify the technique. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the technique of using multiple feature spaces, including the 25-feature space of Mitchell et al. and the full/pruned glove model. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the technique, describing it as convoluted and potentially circular. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technique of using multiple feature spaces is convoluted and potentially circular. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples to substantiate the critique, making it difficult for the authors to understand and address the issue. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the technique used in the paper, specifically the use of multiple feature spaces. It points out that the method could be convoluted and potentially circular, which could lead to confusion or misunderstandings. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to address this issue. Without detailed feedback or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but does not offer enough detail for the authors to effectively improve their work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include comparisons with other works that use MobileNetV3 search space, such as AtomNAS, in Table 7. It also questions why the results of OFA with progressive shrink are not included in the table. This feedback provides clear and concrete actions for the authors to take, specifying exactly what needs to be added to the table and why. The explicit nature of the request and the detailed guidance on what to include make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with other works that use MobileNetV3 search space, such as AtomNAS, and the inclusion of results of OFA with progressive shrink in the table. This provides clear guidance on what needs to be added or clarified in the table. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 7 should include comparisons with other works that use MobileNetV3 search space, such as AtomNAS, and questions why the results of OFA with progressive shrink are not included in the table. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why these comparisons are necessary or how they would enhance the table. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement in the paper, namely the inclusion of comparisons with other works that use MobileNetV3 search space, such as AtomNAS. It also questions why the results of OFA with progressive shrink are not included in the table. This feedback is clear and actionable, as it provides the authors with a concrete direction for enhancing their work by including additional comparisons and context. However, the comment could be more helpful if it offered suggestions on how to present these comparisons or what specific insights they might provide. Overall, the comment is valuable in guiding the authors towards improving their draft, but it could be more comprehensive with additional details. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors include a brief discussion explaining why hallucinations are undesirable and point to existing work on this topic. While the comment implies that the authors should provide this additional information, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors need to infer the exact details of what is expected. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a brief discussion on why hallucinations are undesirable and points to existing work. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. The authors can infer that it relates to the discussion on hallucinations, but this inference is not direct. The comment is specific in suggesting a discussion on the undesirability of hallucinations and referencing existing work, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a brief discussion on why hallucinations are undesirable and points to existing work on this topic would be useful. However, the comment does not provide any specific reasoning or evidence to support why hallucinations are undesirable or how existing work addresses this issue. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors include a brief discussion on why hallucinations are undesirable and point to existing work on this topic. This feedback is somewhat helpful as it identifies a potential gap in the paper that could be addressed by providing additional context and references. However, the comment lacks specific guidance on how to structure this discussion or what aspects of hallucinations should be discussed. While it points out an area for improvement, it does not offer detailed suggestions or examples to help the authors effectively incorporate this information into their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that lines 50-54 mention terms like Type-1 error, Type-2 error, and false positive rate before clearly stating the null hypothesis. This comment implies that the authors should clarify the null hypothesis before introducing these terms. While the action is implicit, it is concrete because it specifies the need to clarify the null hypothesis before introducing these terms. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (50-54), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of mentioning terms like Type-1 error, Type-2 error, and false positive rate before clearly stating the null hypothesis. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that lines 50-54 mention terms like Type-1 error, Type-2 error, and false positive rate before clearly stating the null hypothesis. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is an issue or how it affects the clarity of the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that lines 50-54 mention terms like Type-1 error, Type-2 error, and false positive rate before clearly stating the null hypothesis. This feedback is clear and actionable, as it points out a potential confusion or lack of clarity in the paper that the authors can address to improve the readability and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the null hypothesis or how to better integrate these terms into the context of the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the uncertainty introduced by estimating a continuous importance weight function and the potential impact on the model's reliability. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the model's reliability. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the uncertainty introduced by estimating a continuous importance weight function and its potential impact on the model\\'s reliability. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of uncertainty and its potential impact, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the uncertainty introduced by estimating a continuous importance weight function and its potential impact on the model\\'s reliability. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliability of the model due to the uncertainty introduced by estimating a continuous importance weight function. It raises a valid concern about the impact of this uncertainty on the model\\'s performance. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending alternative methods or providing examples of how to mitigate the uncertainty. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the correlation between human judgments and the SFAM scorers used in the LISA embedding. It suggests that this may make the LISA more content-focused than style-focused. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks actionable details, such as recommending specific changes to the SFAM scorers or suggesting ways to improve their correlation with human judgments. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the SFAM scorers and the LISA embedding, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy in correlation between human judgments and the SFAM scorers, suggesting that this may make the LISA more content-focused than style-focused. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the SFAM scorers used in the LISA embedding do not correlate well with human judgments on more linguistics-relevant styles, such as simplification and linguistic acceptability. This claim is somewhat verifiable as it provides a logical reasoning based on the correlation with human judgments on semantics-relevant styles like sentiment and emotion. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the SFAM scorers used in the LISA embedding, noting that they do not correlate well with human judgments on more linguistics-relevant styles, such as simplification and linguistic acceptability. This feedback highlights a potential limitation in the LISA system and suggests that it may be more content-focused than style-focused. While the comment points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. Providing more detailed advice or examples on how to improve the correlation with human judgments could enhance the helpfulness of the comment. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a relevant issue but could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should also evaluate on other real-world datasets like DexYCB with more recent hand-object pose estimation pipelines to predict the initial hand-object poses. While the comment implies that the authors should include this evaluation, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors need to infer the specifics of how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests evaluating the experiments on other real-world datasets like DexYCB with more recent hand-object pose estimation pipelines to predict the initial hand-object poses. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results or methodology, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting an additional evaluation. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should also evaluate on other real-world datasets like DexYCB with more recent hand-object pose estimation pipelines to predict the initial hand-object poses. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this evaluation is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the experiments should also evaluate on other real-world datasets like DexYCB with more recent hand-object pose estimation pipelines to predict the initial hand-object poses. This feedback is somewhat helpful as it identifies a potential area for improvement in the experimental evaluation. However, the comment lacks specific guidance on how to implement this suggestion or what specific aspects of the evaluation should be considered. While it points out a potential gap in the study, it does not provide detailed instructions or examples on how to address it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of explicit explanation on important components like the design of sequential models and the attention model update. This feedback implies that the authors should provide more detailed information on these aspects to enhance the understanding of their work. However, the comment does not specify which parts of the paper should include this additional explanation or how it should be presented. While the action is implied, it is not as concrete as it could be, leaving the authors with a general idea of what needs to be addressed but without specific guidance on how to implement the changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of explicit explanation on important components, such as the design of sequential models and the attention model update, which are critical for understanding the rationale of the proposed work. However, it does not specify which sections of the paper these components are discussed in, making it difficult for the authors to pinpoint the exact parts that need improvement. While the authors might have an idea of where these components are discussed, the comment lacks full grounding. It is specific about the need for more detailed explanation, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks explicit explanation on important components, such as the design of sequential models and the attention model update, which are critical for understanding the rationale of the proposed work. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of explicit explanation on important components like the design of sequential models and the attention model update. This feedback is clear and actionable, as it points out specific areas where the authors need to provide more detailed information to enhance the understanding of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as recommending specific sections where these explanations should be included or providing examples of how similar components have been explained in other works. Despite this, the comment still provides valuable insight into what the authors need to improve, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be helpful to make the entire code accessible in case the paper is accepted. This is an explicit action that the authors can directly implement by providing the code. The comment is clear and provides a concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that it would be helpful to make the entire code accessible in case the paper is accepted. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the code should be made accessible or how this would enhance the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it would be helpful to make the entire code accessible in case the paper is accepted. However, it does not provide any reasoning, evidence, or examples to support why this would be beneficial or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that it would be helpful to make the entire code accessible in case the paper is accepted. This is a clear and actionable piece of feedback that could significantly enhance the reproducibility and transparency of the work. By providing access to the code, readers can better understand and verify the results presented in the paper. However, the comment could be more helpful if it included specific reasons why making the code accessible is important or how it would benefit the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It also recommends including pseudo-code or flow diagrams to enhance the reader\\'s understanding of the model\\'s operation. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be improved and how to do it. The suggestion is specific and actionable, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the hybrid architecture, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion. The comment suggests including pseudo-code or flow diagrams to enhance the reader\\'s understanding of the model\\'s operation. This level of detail provides clear guidance on what needs to be improved, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It recommends including pseudo-code or flow diagrams to enhance the reader\\'s understanding of the model\\'s operation. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that these explanations are unclear or insufficient. The suggestion is logical and reasonable, but without detailed evidence or examples, the claim is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the clarity of explanations for specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion. It suggests that including pseudo-code or flow diagrams could enhance the reader\\'s understanding of the model\\'s operation. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the clarity and comprehensibility of their explanations. By addressing this point, the authors can significantly improve the readability and accessibility of their work, making the comment highly helpful. Therefore, it deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a critique of the proposed method, noting that it is an incremental improvement on existing AutoAugment but that the performance gains are not significant compared to recent methods. It specifically points out that the improvement over ResNet-50 on ImageNet is only 0.3, and that the standard deviation (std) is very large, which raises concerns about generalizability. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the method. The authors are left to infer that they need to improve the performance gains and address the std issue, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides a critique of the proposed method, noting that it is an incremental improvement on existing AutoAugment but that the performance gains are not significant compared to recent methods. It specifically mentions the improvement over ResNet-50 on ImageNet, which is only 0.3, and the large standard deviation (std), which raises concerns about generalizability. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the issues with the performance gains and the std, but without explicit references to sections or figures, the authors may struggle to identify where these improvements are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is an incremental improvement on existing AutoAugment but that the performance gains are not significant compared to recent methods. It specifically mentions the improvement over ResNet-50 on ImageNet, which is only 0.3, and the large standard deviation (std), which raises concerns about generalizability. The comment provides some support by referencing the specific performance metric (0.3) and the std, which helps substantiate the claim. However, it could be strengthened by providing additional context or references to similar studies or methods that support the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critical analysis of the proposed method, noting that it is an incremental improvement on existing AutoAugment but that the performance gains are not significant compared to recent methods. It specifically points out that the improvement over ResNet-50 on ImageNet is only 0.3, which is a minor improvement. Additionally, the comment highlights the large standard deviation (std), which raises concerns about the generalizability of the method. While the comment identifies areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left with a general understanding of the problem but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it provides insight into potential weaknesses but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a weakness in the comparison section, noting the lack of reference to existing prior art and the significant performance gaps between the proposed method and the latest methods. However, it does not provide explicit guidance on how to address this issue, such as suggesting specific references or methods to include in the comparison. The action is implicit and somewhat vague, as the authors can infer that they need to include references and address the performance gaps, but the comment does not offer detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"comparison\" and \"performance gaps,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of reference to existing prior art and the significant performance gaps between the proposed method and the latest methods. This provides clear guidance on what needs to be improved in the comparison section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison is weak due to the lack of reference to existing prior art and the significant performance gaps between the proposed method and the latest methods. However, the comment does not provide specific references to the prior art or examples of the performance gaps, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or examples, the claim is not fully verifiable, as it lacks the necessary support to substantiate the critique. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of reference to existing prior art and the significant performance gaps between the proposed method and the latest methods. This feedback is clear and actionable, as it points out a critical area that needs attention and improvement. However, the comment could be more helpful if it provided specific references to existing works or examples of performance gaps, which would guide the authors in addressing these issues more effectively. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors argue for the diversity of the data gathered but do not provide quantification, which is considered a minor issue. The reviewer suggests that even a simple types vs. token statistic would be useful. This feedback is explicit in its request for quantification, providing a clear and concrete action for the authors to take. The suggestion is specific and actionable, as it guides the authors on how to enhance their draft by including quantitative data. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the authors\\' argument for the diversity of the data gathered, specifically mentioning the lack of quantification. However, it does not specify which part of the paper this argument is made in, making it weakly grounded. The comment is specific in its suggestion to include a simple types vs. token statistic, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors argue for the diversity of the data gathered but do not provide quantification, which is considered a minor issue. The reviewer suggests that even a simple types vs. token statistic would be useful. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s presentation of data diversity, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for a simple statistic is a logical point, but without further elaboration, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of quantification to support the authors\\' argument for the diversity of the data gathered. It suggests that even a simple statistic, such as types vs. token, would be useful to provide evidence for this claim. This feedback is clear and actionable, as it directs the authors to include quantitative data to strengthen their argument. However, the comment could be more helpful if it provided additional guidance on how to present this data or what specific metrics might be relevant. Overall, the comment is mostly helpful as it points out a critical area for improvement and offers a concrete suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims to create a more diverse set of positive instance pairs but lacks a suggested measure of diversity and no comparison with earlier works regarding the diversity of examples. This implies that the authors should provide a method or metric to measure diversity and compare their results with existing work. However, the comment does not explicitly instruct the authors to include these elements, leaving the action somewhat implicit. The authors can infer that they need to address these points, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim made in the paper regarding the creation of a more diverse set of positive instance pairs. It points out that the paper lacks a suggested measure of diversity and no comparison with earlier works regarding the diversity of examples. However, the comment does not specify which part of the paper this claim is made in, nor does it provide details on what specific measures or comparisons should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the lack of diversity measures and comparisons, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s claim of creating a more diverse set of positive instance pairs is not supported by a suggested measure of diversity or a comparison with earlier works regarding diversity. The reviewer provides a logical reasoning by pointing out the absence of these elements, which is a valid observation. However, the comment lacks specific examples or references to earlier works that could substantiate the claim further. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or references to fully support the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s claim of creating a more diverse set of positive instance pairs. It points out that the paper lacks a suggested measure of diversity and no comparison with earlier works regarding the diversity of examples. This feedback is clear and actionable, as it highlights a critical gap in the paper that needs to be addressed to provide a more robust evaluation of the method. However, the comment could be more helpful if it suggested specific measures or comparisons that the authors could use to enhance the diversity analysis. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the approach would compare to other inputs, specifically mentioning structured information and AUCROC. While it implies that the authors should consider this comparison, it does not provide explicit instructions or suggestions on how to conduct the comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should address this comparison but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about how the approach would compare to other inputs, specifically mentioning structured information and AUCROC. However, it does not specify which part of the paper this comparison should be discussed in, nor does it provide details on what aspects of the approach should be compared or how the authors should conduct the comparison. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about how the approach would compare to other inputs, specifically mentioning structured information and AUCROC. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that AUCROC is high in other models in literature. Without such evidence or justification, the claim remains unverifiable, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about how the approach would compare to other inputs, specifically mentioning structured information and AUCROC. It highlights a potential area for comparison that could provide valuable insights into the strengths and limitations of the approach. However, the comment lacks specific guidance or suggestions on how the authors might conduct this comparison or what aspects to focus on. While it identifies a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a relevant area for consideration but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides several explicit and implicit actions for the authors to take. First, it explicitly suggests stating the objective function in experiments, which is a clear and actionable point. Additionally, it raises a question about the reverse inequality sign in Eq. 7 and suggests that the gap definition may need clarification. This feedback is concrete and provides specific guidance on what needs to be addressed. The comment also suggests that some parts of Section 3 are too technical and could be improved by leaving more space in Section 4 to explain the training procedure. While the comment does not provide detailed instructions on how to implement these changes, it offers clear actions for the authors to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"section 3\" and \"section 4,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues with the objective function in experiments, the reverse inequality sign in Eq. 7, and the technicality of Section 3. The comment provides clear guidance on what needs to be addressed, making it specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the objective function in experiments, suggesting that it should be stated explicitly. It also questions the reverse inequality sign in Eq. 7 and the gap definition, providing a logical basis for the claim. However, the comment lacks specific examples or references to support the reasoning behind these questions. While the claim is somewhat verifiable, it could be strengthened with additional evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improving the paper. It explicitly suggests stating the objective function in experiments, which is a clear and concrete action for the authors to take. Additionally, it raises questions about the reverse inequality sign in Eq. 7 and the gap definition, prompting the authors to clarify these points. The comment also acknowledges that some parts of Section 3 are technical and could be improved by providing more space for explanation in Section 4. This feedback is specific and offers a clear direction for the authors to enhance the clarity and accessibility of their work. However, the comment notes that this is a matter of personal taste, which could be seen as a minor critique. Overall, the comment is mostly helpful as it provides actionable guidance and constructive feedback.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for an explanation of why the Disc. reward for SPACE and f-PCPO is decreasing in the Grid (Fig.3, top right plot). This is a clear and direct request, providing the authors with a specific action to take. The comment is specific in identifying the plot and the issue, making it highly actionable. Authors know exactly what needs to be addressed and how to provide an explanation.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Grid (Fig.3, top right plot),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely an explanation for the decrease in Disc. reward for SPACE and f-PCPO in the Grid. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the decrease in Disc. reward for SPACE and f-PCPO in the Grid (Fig.3, top right plot). However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it should be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to respond to it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the decrease in Disc. reward for SPACE and f-PCPO in the Grid (Fig.3, top right plot), prompting the authors to explain this phenomenon. This feedback is somewhat helpful as it identifies a potential area for clarification and explanation in the paper. However, it lacks depth and does not provide suggestions on how the authors might address this issue or what specific aspects of the explanation should be emphasized. While it points out a potential gap in the paper, it does not offer detailed guidance on how to improve the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that key implementation details, such as the resolutions at which images successfully achieve adversarial effects, are missing. This implies that the authors should include this information in their paper. However, the comment does not specify which resolutions should be included or how they should be presented, leaving the authors with a general direction but without concrete guidance on execution. The action is explicit but vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of key implementation details, specifically mentioning the resolutions at which images achieve adversarial effects. However, it does not specify which part of the paper this information is missing from, making it weakly grounded. The comment is specific in identifying the missing information regarding resolutions, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that key implementation details, such as the resolutions at which images successfully achieve adversarial effects, are missing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the absence of key implementation details, such as the resolutions at which images successfully achieve adversarial effects. This feedback is clear and actionable, as it points out a specific area where the authors need to provide more detailed information to enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific resolutions should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explore improvements to the motion guidance strategy to enhance training efficiency, rather than relying solely on DDIM Inversion for data preprocessing. While the comment implies that the authors should consider alternative approaches, it does not provide specific guidance on what these improvements might entail or how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative methods to improve the motion guidance strategy. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section on data preprocessing, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the approach, which is that it does not significantly simplify the overall complexity and suggests exploring improvements to the motion guidance strategy to enhance training efficiency. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach in the section on data preprocessing is effective in reducing training time but does not significantly simplify the overall complexity. It suggests that exploring improvements to the motion guidance strategy would enhance training efficiency. The comment provides a logical reasoning by pointing out the limitations of the current approach and suggesting an alternative direction for improvement. However, it lacks specific examples or references to support the claim about the effectiveness of the motion guidance strategy. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the approach described in the section on data preprocessing, specifically noting that while the use of DDIM Inversion effectively reduces training time, it does not significantly simplify the overall complexity. It suggests that exploring improvements to the motion guidance strategy itself could enhance training efficiency. This feedback is somewhat helpful as it points out a potential area for improvement and provides a direction for the authors to consider. However, it lacks specific suggestions or examples of alternative approaches to explore, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the statistics of relation phrases and how often rarer relation phrases are predicted in a sentence. It also mentions the potential issue of heavy tail in relations, which could be more severe than heavy tail in words. However, the comment does not provide explicit instructions or concrete suggestions on how the authors should address these issues. It lacks actionable details, such as recommending specific analyses or experiments to conduct. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the statistics of relation phrases and how often rarer relation phrases are predicted in a sentence. It also mentions the potential issue of heavy tail in relations, which could be more severe than heavy tail in words. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the statistics and the issue of heavy tail in relations, but without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the statistics of relation phrases and how often rarer relation phrases are predicted in a sentence. It also mentions the potential issue of heavy tail in relations, which could be more severe than heavy tail in words. However, the comment lacks specific examples, data, or references to support these claims. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the concerns raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises important questions about the statistics of relation phrases and how often rarer relation phrases are predicted in a sentence. It also highlights the potential issue of heavy tail in relations, which could be more severe than heavy tail in words. While the comment identifies a critical area for analysis and potential improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out a relevant area for exploration, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the robustness of the method in dynamic regions, specifically in edge cases like the Bonn dataset where moving objects like humans can occupy over 50% of the image. It suggests two potential solutions: masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to implement these solutions or provide detailed guidance on how to implement them. The action is explicit but somewhat vague, as the authors need to determine the best approach to implement the suggestions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Dynamic Regions\" and the \"Bonn dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the robustness of the method in dynamic regions, particularly in edge cases like the Bonn dataset, where moving objects like humans can occupy over 50% of the image. The comment suggests potential solutions, such as masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement about the robustness of the method in dynamic regions is generally true but highlights edge cases where more robust approaches are needed. The reviewer provides a specific example of the Bonn dataset, where moving objects like humans can occupy over 50% of the image. The comment suggests potential solutions, such as masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. This provides a clear and specific example of an edge case that requires more robustness, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim that these solutions are necessary. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the robustness of the method in dynamic regions, specifically in edge cases like the Bonn dataset where moving objects like humans can occupy over 50% of the image. It suggests two potential solutions: masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. This feedback is clear and actionable, providing the authors with specific guidance on how to address the identified weakness. By suggesting potential solutions, the comment empowers the authors to make meaningful improvements to their draft. However, it could be more helpful if it provided additional context or examples of how these solutions have been successfully implemented in similar scenarios. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only compare the models proposed by the authors and do not include a comparison with other methods. This implies that the authors should include additional comparisons to other methods in their experiments. However, the comment does not provide specific guidance on which methods to include or how to structure these comparisons. While the action is implied, it is not explicitly stated, and the authors are left to infer the details of how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experiments, noting that they only compare models proposed by the authors and lack comparisons with other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of comparison with other methods, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments only compare models proposed by the authors and lack comparisons with other methods. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, noting that the experiments only compare models proposed by the authors and lack comparisons with other methods. This feedback highlights an area where the paper could be improved by including additional comparisons to other methods, which would enhance the comprehensiveness and relevance of the experiments. However, the comment does not provide specific guidance on which methods to include or how to structure these comparisons, leaving the authors with a general direction but without detailed steps to follow. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a minor issue with the use of asterisks in Tables 3 and 4, noting that while some models are labeled as \"math specialists,\" the MAVIS models themselves are not similarly labeled. The reviewer suggests that the MAVIS models should also be labeled as math specialists. While the comment identifies a specific issue, it does not provide explicit guidance on how to address it, such as suggesting which models should be labeled or how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should label the MAVIS models as math specialists. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 and 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of asterisks, noting that some models are labeled as \"math specialists\" but not the MAVIS models themselves. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of asterisks in Tables 3 and 4 is inconsistent, as some models are labeled as \"math specialists\" but not the MAVIS models. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a minor issue with the presentation of data in Tables 3 and 4, noting that some models are labeled as \"math specialists\" but not the MAVIS models themselves. This feedback is somewhat helpful as it points out a specific inconsistency that could be addressed to improve the clarity and completeness of the tables. However, the comment lacks depth and does not provide suggestions on how to resolve this issue or why it is important. While it highlights a potential oversight, it does not offer actionable guidance or detailed advice for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the technical novelty of the paper is limited, as KNN-based methods are widely studied in LM and MT. It points out that the paper provides few insights into a non-parametric method for text classification. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or enhance the novelty of their work. The action is implicit and vague, as the authors are left to infer that they need to provide more insights or innovations to justify the novelty of their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the technical novelty of the paper is limited, as KNN-based methods are widely studied in LM and MT. It points out that the paper provides few insights into a non-parametric method for text classification. However, the comment does not specify which part of the paper discusses KNN-based methods or how the novelty is limited. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical novelty of the paper is limited, as KNN-based methods are widely studied in LM and MT. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical novelty of the paper is limited, as KNN-based methods are widely studied in LM and MT. It points out that the paper provides few insights into a non-parametric method for text classification. While the comment identifies a potential limitation, it lacks specific suggestions or guidance on how the authors could address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it highlights a potential weakness, but it does not provide actionable advice for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overstates the extensive enhancement of IM for existing RL algorithms and lacks a comparison with the latest work, especially non-pixel-based approaches. While the comment identifies a specific issue with the claim about enhancement and suggests a need for comparison, it does not provide explicit guidance on how to address these concerns. The authors are left to infer that they should include a comparison with the latest work or provide more detailed evidence to support their claims. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"extensive enhancement of the IM for most existing RL algorithms\" and the \"most recent description of the mainstream RL algorithms in related work,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper overstates the enhancement and lacks a comparison with the latest work, especially non-pixel-based approaches. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper overstates the extensive enhancement of IM for existing RL algorithms and lacks a comparison with the latest work, especially non-pixel-based approaches. The comment provides a specific observation about the claim of enhancement and suggests that it is an overstatement. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. The lack of specific examples or comparisons makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some indication of an issue but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it overstates the extensive enhancement of IM for existing RL algorithms and lacks a comparison with the latest work, especially non-pixel-based approaches. This feedback is valuable as it highlights a potential overstatement and suggests a gap in the paper\\'s discussion of related work. However, the comment could be more helpful if it provided specific examples or references to recent non-pixel-based approaches that could be used for comparison. While it points out a critical area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and actionable suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to expand the background discussion in Section 2 and related work by providing further background knowledge on adversarial examples, white-box, grey-box, and black-box threat models in the context of poisoning. It suggests referencing relevant surveys to clarify the threat model and position at the state-of-the-art (SoA) and to facilitate understanding for non-expert readers. This feedback is clear and provides specific actions for the authors to take, making it highly actionable. The authors know exactly what additional information to include and how to reference it, ensuring they can effectively improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2 and related work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely expanding the background discussion on adversarial examples, white-box, grey-box, and black-box threat models in the context of poisoning. The comment provides a clear direction for improvement by suggesting the authors reference relevant surveys to clarify their threat model and position at the state-of-the-art (SoA). This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests expanding the background discussion on adversarial examples, white-box, grey-box, and black-box threat models in the context of poisoning. It recommends referencing relevant surveys to clarify the threat model and position at the state-of-the-art (SoA) to facilitate understanding for non-expert readers. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these additions would be beneficial. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to identify and integrate the suggested references to fully address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors expand the background discussion in Section 2 and related work to include further background knowledge on adversarial examples, white-box, grey-box, and black-box threat models in the context of poisoning. It recommends referencing relevant surveys to clarify the threat model and position at the state-of-the-art (SoA) and to facilitate understanding for non-expert readers. This feedback is specific and provides a clear direction for improvement, guiding the authors on how to enhance their draft to better align with the expectations of the reviewers. By addressing these points, the authors can significantly improve the clarity and comprehensiveness of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses a lack of clarity regarding the importance of the proposed multiple-span answer setting in real-world applications. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might clarify this aspect or what specific steps they could take to improve the explanation. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a lack of clarity regarding the importance of the proposed multiple-span answer setting in real-world applications. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this setting is discussed. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the setting are unclear or how they could be clarified. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed multiple-span answer setting is unclear in its relevance to real-world applications. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses a lack of clarity regarding the importance of the proposed multiple-span answer setting in real-world applications. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the explanation of the setting\\'s relevance. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests mixing the train set examples with hypernyms and non-hypernyms. While the suggestion is clear, it lacks specific guidance on how to implement this mixing or what criteria to use for selecting hypernyms and non-hypernyms. The authors are left with a general idea of what to do but without detailed instructions on how to execute it. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests mixing the train set examples with hypernyms and non-hypernyms. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where this mixing could be implemented. The authors cannot confidently determine the exact part of the paper being addressed, making it weakly grounded. The comment is specific in suggesting a potential improvement by mixing train set examples, but without clear grounding, it is difficult for the authors to effectively address the suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests mixing the train set examples with hypernyms and non-hypernyms. However, it does not provide any supporting evidence, reasoning, or examples to justify why this mixing would be beneficial or how it would improve the study. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making changes to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests mixing the train set examples with hypernyms and non-hypernyms. While it identifies a potential area for improvement, it lacks specific guidance or detailed instructions on how to implement this suggestion. The comment does not explain why this mixing would be beneficial or how it could be achieved, leaving the authors with a general idea of what to do but without actionable steps. Therefore, the comment is somewhat helpful, as it points out a potential improvement but does not provide enough detail for the authors to effectively address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the inclusion of results for the AdpCLR_full approach for the ResNet-50 architecture, similar to the results provided for AdpCLR_pre in Table 1. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed and where it should be included. The comment is specific and provides concrete guidance on how to implement the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table-1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what additional information is needed, namely the results for the AdpCLR_full approach for the ResNet-50 architecture. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information, specifically the results for the AdpCLR_full approach for the ResNet-50 architecture. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a normal statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area where the authors need to provide additional information. By requesting the results for the AdpCLR_full approach for the ResNet-50 architecture, the comment prompts the authors to include a missing piece of data that could enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided context or justification for why these results are important or how they might impact the overall analysis. Despite this, the feedback is clear and actionable, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the similarity between \"N trajectories\" and the concept of replay in the Dyna model. However, it does not provide any guidance or suggestions for the authors to address this question or clarify their understanding. The comment lacks explicit or implicit actions for the authors to take, leaving them without direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the similarity between \"N trajectories\" and the concept of replay in the Dyna model. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the similarity between these concepts, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the similarity between \"N trajectories\" and the concept of replay in the Dyna model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the similarity between \"N trajectories\" and the concept of replay in the Dyna model. While it identifies a potential area of confusion or misunderstanding, it does not provide any guidance or suggestions for the authors to address this issue or clarify their explanation. The comment lacks actionable feedback or constructive advice, leaving the authors without direction on how to improve their draft. Therefore, it is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some experiment results are suspicious, specifically mentioning Tables 16 and 17, which share the same result despite changing the 2-hop EG into 3-hop EG. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. It lacks actionable details, such as recommending specific changes or clarifications to be made to the tables or results. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 16 and 17,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the experiment results, noting that the tables share the same result despite changing the 2-hop EG into 3-hop EG. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some experiment results are suspicious, specifically mentioning Tables 16 and 17. However, the comment does not provide any specific examples or detailed reasoning to support this claim. It lacks context and does not offer any evidence or references to substantiate the suspicion. As a result, the claim is not verifiable, as it does not provide sufficient information for the authors to understand or address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, specifically mentioning Tables 16 and 17, which share the same result despite changing the 2-hop EG into 3-hop EG. This observation highlights a potential inconsistency or error in the experimental setup, which could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the transparency and accuracy of their results. While it points out a potential problem, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the experimental results, which show some advantages of the proposed algorithms, but notes that these advantages are not very significant. It also states that the algorithms are still competitive with state-of-the-art algorithms. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their draft. It lacks guidance on how to address the issue of insignificant advantages or how to improve the competitiveness of the algorithms. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"experimental results\" and \"state-of-art algorithms,\" which provides some context for the authors to identify the part of the paper being addressed. However, it does not specify which specific results or algorithms are being discussed, making it weakly grounded. The comment is specific in its observation that the advantages are not very significant and that the algorithms are still competitive with state-of-the-art algorithms. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results show some advantages of the proposed algorithms but are not very significant, and that the algorithms are still competitive with state-of-the-art algorithms. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some indication but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the experimental results, which show some advantages of the proposed algorithms, but notes that these advantages are not very significant. It also states that the algorithms are still competitive with state-of-the-art algorithms. While the comment provides some insight into the performance of the algorithms, it lacks specific suggestions or guidance on how the authors might improve the significance of their results or enhance their competitiveness. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the per-sentence assessment protocol, noting that it may be prone to overconfidence from LLMs. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to modify the protocol or what specific steps to take to mitigate overconfidence. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the per-sentence assessment protocol, which is a specific aspect of the paper. However, it does not explicitly mention which section of the paper discusses this protocol, making it weakly grounded. The comment is specific in pointing out a potential issue with the protocol, namely the overconfidence of LLMs, which could lead to incorrect predictions. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the per-sentence assessment protocol may be prone to overconfidence from LLMs, which could lead to incorrect predictions. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the per-sentence assessment protocol, noting that it may be prone to overconfidence from LLMs. This is a relevant observation that could impact the reliability and accuracy of the assessment. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the protocol. It does not provide actionable steps or examples of how to mitigate overconfidence, which would be beneficial for the authors to consider. As a result, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the distinction between non-semantic and semantic diversity in the context of the paper. It implies that the authors should clarify this distinction, but it does not provide explicit instructions or suggestions on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the distinction but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W6.3\" and \"App. C,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the distinction between non-semantic and semantic diversity, which is a clear and specific point of inquiry. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the distinction between non-semantic and semantic diversity, asking for clarification on why the former is emphasized but not the latter. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the distinction between non-semantic and semantic diversity in the context of the paper. It highlights a potential gap in the explanation provided, which could lead to confusion for readers. While the comment identifies an area for clarification, it does not offer specific suggestions or guidance on how to address this issue. The authors are left with a clear direction for improvement but without detailed guidance on how to achieve it. Therefore, the comment is somewhat helpful, as it points out a potential weakness but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the promising experimental result is due to the superiority of the method or an accidental result from a specific kernel function and feature map. While it implies that the authors should clarify this point, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the nature of the promising experimental result, whether it is due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the nature of the experimental result, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the nature of the promising experimental result, questioning whether it is due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the question effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the nature of the promising experimental result, questioning whether it is due to the superiority of the method or an accidental result from a specific kernel function and feature map. This is a valuable point that could prompt the authors to clarify their experimental setup and results, ensuring that their findings are robust and reliable. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional experiments or analyses. While it identifies a potential area for improvement, it could be more helpful with more detailed feedback. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not provide any guidance on how the authors should address this issue or what specific information should be included. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what needs to be addressed or improved regarding this absence, making the comment specific but weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their work. However, the comment lacks depth and does not provide suggestions on how to incorporate this information or what specific aspects of the estimation process should be addressed. While it highlights an important area for improvement, the feedback could be more helpful with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the computational costs associated with training the proposed method, which involves modified Gromov-Hausdorff distances and hypergraph structures. While the comment implies that the authors should include this discussion, it does not explicitly instruct them to do so. The action is concrete, as it points out a specific area that needs attention, but it is somewhat vague because it does not provide detailed guidance on how to conduct this discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion of the computational costs associated with training the method involving modified Gromov-Hausdorff distances and hypergraph structures. This provides clear guidance on what the authors need to consider in order to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is complex, involving modified Gromov-Hausdorff distances and hypergraph structures, which may increase time complexity. The reviewer supports this claim by mentioning that the time complexity of each component is theoretically analyzed and addressed in Appendix B. However, the comment lacks specific examples or detailed analysis of the computational costs associated with training, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but could be more fully supported with additional details or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the complexity of the proposed method, which involves modified Gromov-Hausdorff distances and hypergraph structures. It suggests that this complexity could increase time complexity, and it acknowledges that the time complexity of each component is theoretically analyzed in Appendix B. However, the comment points out that a discussion of the computational costs associated with training the method is missing. This feedback is somewhat helpful as it highlights an area that could be improved, but it lacks specific suggestions or guidance on how to address the issue. The authors are given a clear direction to consider discussing computational costs, but the comment could be more actionable with additional details or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern that the proposed method may not represent a groundbreaking innovation within the field, as it effectively builds upon existing strategies. It points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, which could lead to a lack of clarity for readers regarding the unique contributions and advantages of the new approach. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting ways to differentiate their method or highlighting specific aspects that could be improved. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the unique contributions and advantages of their method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s contribution and suggests that the proposed method may not represent a groundbreaking innovation within the field. It points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, which could lead to a lack of clarity for readers regarding the unique contributions and advantages of the new approach. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely, the need to distinguish the proposed method from existing techniques. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may not represent a groundbreaking innovation within the field, as it effectively builds upon existing strategies. The reviewer suggests that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, which could lead to a lack of clarity for readers regarding the unique contributions and advantages of the new approach. However, the comment lacks specific examples or references to existing techniques that could be used to distinguish the proposed method. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s contribution, suggesting that the proposed method may not represent a groundbreaking innovation within the field. It points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, which could lead to a lack of clarity for readers regarding the unique contributions and advantages of the new approach. While the comment highlights an important area for improvement, it does not provide specific suggestions or guidance on how the authors could address this issue or enhance the clarity of their contribution. The feedback is somewhat helpful as it directs the authors\\' attention to a potential weakness, but it lacks actionable advice or detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 4\\'s tabular representation of node agent interactions is not intuitive. However, it does not provide any explicit or implicit suggestions for how the authors might improve the figure or make it more intuitive. There is no guidance on what specific changes could be made or how the authors might address this issue. As a result, the comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve the figure. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, stating that the tabular representation of node agent interactions is not intuitive. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4\\'s tabular representation of node agent interactions is not intuitive. However, it does not provide any specific reasoning or examples to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that the tabular representation of node agent interactions is not intuitive. This feedback is somewhat helpful as it points out a clear area for improvement, allowing the authors to enhance the clarity and accessibility of the figure. However, the comment lacks depth and does not provide suggestions on how to improve the figure or what specific changes could be made to make it more intuitive. While it highlights an issue, it does not offer actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: whether the benefit of the proposed method is prioritizing learning on examples with less irreducible uncertainty and how the use of the PU loss impacts calibration. It also questions the appropriateness of other frameworks besides PU as baselines, suggesting noise-aware losses as an example. Additionally, it highlights the importance of uncertainty estimation for downstream use cases of AI text detectors. While the comment implies that the authors should consider these questions and provide more information, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two main questions: whether the benefit of the proposed method is prioritizing learning on examples with less irreducible uncertainty and how the use of the PU loss impacts calibration. It also questions the appropriateness of other frameworks besides PU as baselines, suggesting noise-aware losses as an example. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its questions about the impact of the PU loss on calibration and the importance of uncertainty estimation for downstream use cases. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the appropriateness of using PU as a baseline and the impact of the PU loss on calibration. It also questions the importance of uncertainty estimation for downstream use cases of AI text detectors. While the comment suggests that other frameworks might be more appropriate as baselines, it lacks specific examples or references to support this claim. The mention of noise-aware losses is a specific suggestion, but it is not fully developed or substantiated with evidence or reasoning. Overall, the comment is somewhat verifiable, as it provides some insight but lacks detailed justification or examples to fully support the claims. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two main questions that are relevant to the paper\\'s content and contribution. First, it questions whether the proposed method prioritizes learning on examples with less irreducible uncertainty, suggesting that other frameworks besides PU might be more appropriate as baselines. This is a thoughtful observation that prompts the authors to consider alternative approaches and benchmarks. Second, it inquires about the impact of the PU loss on calibration and the importance of uncertainty estimation for downstream use cases of AI text detectors. This is a valuable point that highlights a potential area for improvement and further exploration. However, the comment could be more helpful if it provided specific suggestions or examples of alternative frameworks or methods to consider. Overall, the comment is mostly helpful as it prompts the authors to reconsider their approach and provides a direction for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL). It suggests that TL is a broader term for the phenomenon of learning from one task benefiting another, while Fine-tuning is a sequential approach. The reviewer implies that the authors should reconsider their characterization of these concepts. However, the comment does not provide explicit guidance on how to revise the characterization or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their characterization. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL), suggesting that TL is a broader term and that Fine-tuning is a sequential approach. The comment provides a clear rationale for why the characterization is inaccurate and offers a more accurate description. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL). The reviewer provides a logical reasoning by explaining that TL is a broader term for the phenomenon of learning from one task benefiting another, while Fine-tuning is a sequential approach. This explanation is based on a clear understanding of the concepts and their distinctions, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the distinction between TL and MTL. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable critique of the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential Multi-Task Learning (MTL) in the introduction. It offers a more accurate description of TL as a broader term for the phenomenon of learning from one task benefiting another, and distinguishes it from Fine-tuning, which is a sequential approach. This feedback is valuable as it helps the authors clarify their terminology and improve the accuracy of their description. However, the comment could be more helpful if it provided specific suggestions on how to revise the characterization or offered examples of how these concepts are typically described in the literature. Overall, the comment is mostly helpful as it guides the authors toward a clearer and more accurate representation of these concepts in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks a Limitation section, which is important. This provides a clear and direct action for the authors to take, as it instructs them to include a Limitation section in their draft. The comment is specific and provides a concrete action for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the absence of a \"Limitation\" section, which provides full grounding as it clearly identifies the part of the paper being addressed. However, it does not specify what needs to be addressed or improved in the Limitation section, leaving the authors to infer the details. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper lacks a \"Limitation\" section, which is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary justification to guide the authors in addressing the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, namely the absence of a \"Limitation\" section. This is an important point, as it highlights a potential gap in the paper that could impact its comprehensiveness and credibility. However, the comment does not provide any further guidance or suggestions on what should be included in the Limitation section or how it could be structured to enhance the paper. While it points out a critical area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It suggests that the theory behind diffusion models needs more detailed explanations in Section 2.1 and that the captions of figures are not explanatory. Additionally, it mentions specific figures that need more explanation, such as Figures 3, 4, 7, and 8. These explicit actions and concrete details give the authors clear guidance on what to improve in their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Section 2.1: theory behind diffusion models\" and \"Section 3.2: works of (Choi et al. 2021, Meng et al. 2021),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as the need for more detailed explanations in Section 2.1 and the lack of explanatory captions for figures like Figures 3, 4, 7, and 8. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the theory behind diffusion models needs more detailed explanations in Section 2.1 and that the captions of figures are often not explanatory. While the comment identifies specific sections and issues, it lacks detailed reasoning or examples to support why these explanations are necessary or how they could be improved. The mention of specific figures like Figures 3, 4, 7, and 8 suggests that the reviewer has a good understanding of the paper, but the lack of detailed justification makes the claim somewhat verifiable. The authors would need to make a significant effort to understand and address the feedback, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on multiple aspects of the paper. It identifies areas where the theory behind diffusion models needs more detailed explanations in Section 2.1, and it points out that the captions of figures are often not explanatory, providing examples like Figures 3, 4, 7, and 8. This feedback is clear and directs the authors to improve the clarity and comprehensiveness of their explanations, which is valuable for enhancing the paper\\'s understanding and impact. Additionally, the mention of specific works by Choi et al. (2021) and Meng et al. (2021) suggests that the authors should provide more detailed explanations of their contributions. Overall, the comment is mostly helpful as it offers concrete guidance on how to improve the draft, making it somewhat helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the title should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This is a clear and direct action for the authors to take, as it provides a specific recommendation for improving the title to better reflect the content of the paper. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the title should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. However, it does not specify which part of the paper discusses this application, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific about the need to include the term \"tensor completion\" in the title, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the title should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this term is necessary or how it would enhance the title. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the title of the paper should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This feedback is somewhat helpful as it identifies a specific area for improvement in the title, which could help clarify the focus of the paper for readers. However, the comment lacks depth and does not provide detailed guidance on how to effectively incorporate the term into the title or why it is important. Additionally, it does not address other aspects of the paper, such as the methodology or results. Overall, the comment is somewhat helpful as it points out a specific issue but could be more comprehensive to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison of their proposed method with other prior methods. It explicitly states that the current evaluation is insufficient and recommends implementing a simple baseline, such as character frequencies, to enhance the persuasiveness of the paper. The comment provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to the evaluation section. This level of detail makes the comment highly actionable, as the authors know exactly what steps to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"empirical evaluation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison with other prior methods and the suggestion to implement a simple baseline. This provides clear guidance on how to enhance the paper\\'s persuasiveness by including a comparison with other methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison with other prior methods and suggests implementing a simple baseline, such as character frequencies, to enhance the persuasiveness of the work. The reviewer provides a logical reasoning that a comparison with other methods would strengthen the paper\\'s contribution. However, the comment does not provide specific examples or references to other methods that could be compared, which would make the claim more verifiable. As it stands, the authors are left with a general suggestion but without detailed guidance on how to implement it. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks specific examples or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the proposed method is interesting but lacks a comparison with other prior methods. It suggests that the authors should implement a simple baseline, such as character frequencies, to enhance the persuasiveness of their work. This feedback is clear and actionable, as it provides a specific and concrete suggestion for improvement. By addressing this point, the authors can strengthen their evaluation and demonstrate the novelty and effectiveness of their method. However, the comment could be more helpful if it provided examples of how such a comparison might be conducted or what specific aspects of the prior methods should be considered. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the practicality of the proposed method in reducing computational load. It identifies specific challenges, such as the difficulty in applying a uniform activation pattern across all tokens due to different tokens activating different channels. The reviewer suggests that the method may not generalize well to other tokens, which could negate the intended efficiency gains. However, the comment does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the method. The authors are left to infer that they need to consider these challenges and possibly explore alternative approaches. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"computational load,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the challenges in reducing computational load, such as the difficulty in applying a uniform activation pattern across all tokens and the potential limitations of the method due to its reliance on precomputed PPL and activation patterns. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method faces challenges in reducing computational load due to the difficulty in applying a uniform activation pattern across all tokens. It also suggests that the method may not generalize well to other tokens, as it relies on precomputed PPL and activation patterns. The comment provides logical reasoning by explaining the challenges in applying a uniform activation pattern and the potential limitations of the method due to its reliance on precomputed patterns. However, it lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but could be improved with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the practicality of the proposed method in reducing computational load. It highlights specific challenges, such as the difficulty in applying a uniform activation pattern across all tokens due to different tokens activating different channels. The comment also points out that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens. This feedback is valuable as it provides the authors with a clear understanding of the limitations of their method and areas for improvement. However, the comment could be more helpful if it offered suggestions on how to address these challenges or provided examples of alternative approaches. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical issue and provides a starting point for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the core motivation of the paper is not clear, specifically mentioning that the abstract does not effectively convey the main problem to be solved. It suggests that the stacked statements in the abstract do not effectively capture the core motivation. However, the comment does not provide explicit guidance on how to clarify the motivation or what specific changes should be made to the abstract. While the authors can infer that they need to improve the clarity of the motivation, the lack of concrete suggestions makes the action implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the core motivation of the paper is not clear, particularly regarding the difficulty in demarcating task boundaries. The comment further suggests that the abstract\\'s stacked statements do not effectively capture the main problem to be solved. This provides clear guidance on what needs to be addressed to improve the clarity of the motivation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the core motivation of the paper is not clear, specifically mentioning that the abstract does not effectively convey the main problem to be solved. The reviewer suggests that the stacked statements in the abstract do not capture the core motivation. However, the comment lacks specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors may understand the general idea but may need more detailed guidance to fully address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s core motivation, noting that the abstract does not effectively convey the main problem to be solved. It points out that the stacked statements in the abstract do not capture the core motivation, which is a critical observation that can help the authors improve the clarity and focus of their paper. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a different structure or approach for the abstract. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the sequence inference classifier used to filter data, noting that the task seems different from the original MNLI distribution. It suggests that examples of the filtered data would be helpful to understand the filtering process. While the comment implies that the authors should provide examples of the filtered data, it does not explicitly instruct them to do so. The action is concrete, as it specifies what the authors need to do (provide examples), but it is somewhat vague because it does not provide detailed guidance on how to present these examples. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"sequence inference classifier\" and the \"filtering data\" process, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity about what kind of data passes the filter and how it differs from the original MNLI distribution. The comment suggests providing examples of the filtered data, which is a clear and specific action for the authors to take. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the sequence inference classifier used to filter data, noting that the task seems different from the original MNLI distribution. The reviewer suggests that examples of the filtered data would be helpful to understand the filtering process. However, the comment lacks specific examples or detailed reasoning to support the claim that the task is different or how it affects the filtering process. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern about the sequence inference classifier used to filter data, noting that the task seems different from the original MNLI distribution. It suggests that examples of the filtered data would be helpful to understand the filtering process. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to address the issue by providing examples of the filtered data. However, the comment could be more helpful if it offered additional guidance on how to present these examples or what specific aspects of the filtering process should be highlighted. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the potential for biases in the application experiments due to the limited dataset and reliance on a single model. It suggests that the paper requires an in-depth editorial review to address these concerns. The comment provides specific guidance on what the authors should consider, such as examining structure, argumentation, and language clarity. Additionally, it points out issues with the equation numbering and the format of Algorithm 1, which are concrete areas for improvement. While the comment is explicit in its suggestions, it could be more actionable by providing examples of how to address these issues. Overall, the comment is mostly actionable as it clearly identifies areas for improvement and provides concrete details on how to implement them.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the application experiments, the evaluation on a single model (DALL-E), and the small dataset (30 famous paintings and 30 generated paintings). It also specifies the issue with the chaotic equation numbering and the format of Algorithm 1, providing clear guidance on what needs to be addressed. This level of detail allows the authors to identify the specific parts of the paper being addressed and what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the application experiments may have biases due to the limited dataset and reliance on a single model (DALL-E). It suggests that the experiment results are difficult to be convincing without comprehensive experiments. The reviewer provides some justification by pointing out that the paper lacks comprehensive experiments and recommends an in-depth editorial review to address these concerns. However, the comment could be strengthened by providing specific examples or references to studies that have demonstrated the importance of comprehensive experiments in similar contexts. Despite this, the claim is mostly verifiable as it logically points out the potential issue and suggests a need for further investigation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the application experiments may be biased due to the limited dataset and reliance on a single model (DALL-E). It suggests that the experiment results are difficult to be convincing without comprehensive experiments. The comment provides actionable feedback by recommending an in-depth editorial review to address these concerns. It also points out specific areas for improvement, such as examining structure, argumentation, and language clarity. Additionally, it highlights issues with the equation numbering and the format of Algorithm 1, which are concrete suggestions for improvement. Overall, the comment is highly helpful as it provides clear and detailed guidance on how the authors can enhance the quality and credibility of their work.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should comment on the practical applications of their work, specifically regarding the use of datasets that are constructed by concatenating manipulated samples. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comment on the practical applications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should comment on the practical applications of their work, specifically regarding the use of datasets that are constructed by concatenating manipulated samples. However, it does not specify which part of the paper this comment pertains to, such as the experimental section or the discussion. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its request for a comment on practical applications, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments in the paper are based on datasets constructed by concatenating manipulated samples, which is a claim about the nature of the datasets used. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it affects the paper\\'s validity. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the experiments are based on datasets constructed by concatenating manipulated samples. It suggests that there may be real tasks with available data that would benefit from using such a model. While the comment highlights an area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue or explore practical applications. The feedback is somewhat helpful as it points out a potential gap in the paper, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the selection of m' in the CAL-MIR method, specifically asking whether it is done exhaustively over all loss minimizer subsets. The reviewer implies that this might be prohibitively expensive or time-consuming. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the draft. The authors are left to infer that they might need to clarify or justify the selection process, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the selection of m\\' in the CAL-MIR method, specifically asking whether it is done exhaustively over all loss minimizer subsets. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the selection process and the potential prohibitive nature of this approach. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the selection of m\\' in the CAL-MIR method, specifically asking whether it is done exhaustively over all loss minimizer subsets. The comment implies that this might be prohibitively expensive or time-consuming. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the selection of m\\' in the CAL-MIR method, specifically asking whether it is done exhaustively over all loss minimizer subsets. This is a relevant point that could impact the efficiency and scalability of the method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the explanation in their paper. While it identifies a potential area for clarification, it does not offer actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider including other backdoor detection methods that are input data-free, such as detecting backdoors with weight matrix statistics or matrix factorization. While the comment implies that the authors should add this information to their analysis, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Robustness\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including other backdoor detection methods that are input data-free, such as detecting backdoors with weight matrix statistics or matrix factorization. This provides clear guidance on what additional information should be considered in the analysis of algorithm performance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the \"Robustness\" section should consider other backdoor detection methods that are input data-free, such as detecting backdoors with weight matrix statistics or matrix factorization. While the comment provides a logical reasoning for why these methods should be considered, it lacks specific examples or references to support the claim that these methods are effective or relevant. This makes the claim somewhat verifiable, as the authors would need to further explore and evaluate these methods to fully understand their relevance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the \"Robustness\" section by suggesting that the authors consider other backdoor detection methods that are input data-free, such as detecting backdoors with weight matrix statistics or matrix factorization. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the analysis of algorithm performance. By including these additional methods, the authors can broaden their understanding of robustness and potentially improve the robustness of their approach. However, the comment could be more helpful if it included examples or references to these methods, which would guide the authors in implementing the suggestion more effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues with the paper: the incompleteness of the \"relation works\" section and the need to clarify the problem definition methodology, particularly regarding the view of the knowledge graph used in the assumption. While the comment highlights these areas for improvement, it does not provide explicit instructions on how to address them. The authors are left to infer that they need to expand the \"relation works\" section and clarify the knowledge graph view used in the methodology. The actions are implicit and somewhat vague, as the authors need to infer the specific details to be added or clarified. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"relation works\" section and the problem definition methodology, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the incompleteness of the \"relation works\" section and the need to clarify the problem definition methodology, particularly regarding the view of the knowledge graph used in the assumption. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"relation works\" section is incomplete and that the problem definition methodology needs clarification regarding the view of the knowledge graph used in the assumption. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim borderline verifiable, as the authors may find it challenging to fully understand and address the feedback without additional information. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper: the incompleteness of the \"relation works\" section and the need to clarify the problem definition methodology, particularly regarding the view of the knowledge graph used in the assumption. By pointing out these gaps, the comment provides actionable feedback that can help the authors enhance the clarity and completeness of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as by providing examples of what should be included in the \"relation works\" section or how to clarify the knowledge graph view. Overall, the comment is mostly helpful as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison of their method's accuracy on a specific task (regression) against strong baselines. It highlights that the optimization is a downstream task that should not be affected by the mechanism of regression. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to determine which specific baselines to use and how to conduct the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the problem setup and the contribution of the paper, specifically mentioning the use of black box optimization techniques and the focus on regression to make predictions on $\\\\hat{y}$. It suggests comparing the accuracy of the method against strong baselines, which is a specific suggestion for improvement. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as specific sections or results. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific about what needs to be addressed, but it is not grounded in detail. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the paper revolves around regression to make predictions on $\\\\hat{y}$ and suggests comparing the accuracy of the method against strong baselines. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to be fully substantiated. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s contribution, noting that the contribution revolves around regression to make predictions on $\\\\hat{y}$ rather than being part of the problem setup involving black box optimization techniques. It suggests that the authors should include a comparison of their method\\'s accuracy against strong baselines, which is a relevant and actionable suggestion. However, the comment could be more helpful if it provided specific examples of strong baselines or detailed guidance on how to conduct the comparison. Despite this, the feedback is mostly helpful as it points out a critical area for improvement and offers a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical design lacks theoretical support, specifically mentioning the update derivation for the intrinsic reward parameters (Eq.7-10). However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the theoretical support. The comment implies that the authors should provide more justification for the update derivation, but it does not offer concrete steps or suggestions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.7-10,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the technical design, particularly the lack of theoretical support and the need for more justification for the update derivation of the intrinsic reward parameters. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical design lacks theoretical support, specifically mentioning the update derivation for the intrinsic reward parameters (Eq.7-10) as being \"hardly convincing.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the technical design, specifically the lack of theoretical support for the update derivation of the intrinsic reward parameters (Eq.7-10). It points out that even if the design is accepted, the justification for the update derivation is not convincing. This feedback is valuable as it highlights a critical area for improvement in the paper, which could enhance the theoretical foundation and credibility of the work. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or what additional theoretical support might be needed. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it lacks detailed guidance on how to achieve it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the adaptive variance reduction property claimed by the authors is based on choosing a \"small enough\" \u03b2 parameter, which undermines the adaptivity claim. The reviewer suggests that this approach is not applicable to adaptive methods like AdaGrad. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the adaptivity claim. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to variance reduction, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"adaptive variance reduction property\" and the \"small enough\" \u03b2 parameter, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this approach is not adaptive, as it does not consider the adaptive methods like AdaGrad. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the adaptive variance reduction property is not adaptive because it relies on choosing a \"small enough\" \u03b2 parameter, which is not applicable to adaptive methods like AdaGrad. This claim is somewhat verifiable as it provides a logical reasoning based on the comparison to AdaGrad, which is a well-known adaptive method. However, the comment lacks specific examples or references to AdaGrad or other relevant literature to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim of adaptive variance reduction in the paper. It points out that the approach relies on choosing a \"small enough\" \u03b2 parameter, which undermines the adaptivity claim. The reviewer compares this approach to adaptive methods like AdaGrad, highlighting the difference in adaptivity. This feedback is valuable as it prompts the authors to reconsider their approach to variance reduction and potentially explore more adaptive methods. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of alternative methods that could be considered. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the value of different augmentation techniques is unclear and points out that DINOv2 seems to be the best-performing model. It recommends further investigation into why DINOv2 performs well and how to improve it further. While the comment provides a clear direction for the authors to explore and investigate the best-performing model, it does not specify which techniques to investigate or how to conduct the investigation. The action is explicit but somewhat vague in terms of detail, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the value of different augmentation techniques, specifically mentioning DINOv2 as the best-performing model. However, it does not specify which part of the paper discusses these techniques or where the authors should further investigate. This makes it weakly grounded, as the authors cannot confidently determine which section is being addressed. The comment is specific in suggesting that further investigation into why DINOv2 performs well and how to improve it is needed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the value of different augmentation techniques is unclear and suggests that DINOv2 is the best-performing model. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion that DINOv2 is the best-performing model, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the value of different augmentation techniques. It points out that DINOv2 seems to be the best-performing model and suggests further investigation into why this is the case and how to improve it. This feedback is clear and actionable, as it directs the authors to explore and understand the performance of different models. However, the comment could be more helpful if it provided specific suggestions on how to conduct the investigation or what aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the acronym \"follow the top perturbed leader\" (FTL) is unfortunate because it is similar to the common acronym \"follow the leader\" (FTL) in literature. The reviewer implies that a change of acronym might be necessary. However, the comment does not provide specific guidance on how to change the acronym or what alternative acronyms might be more appropriate. The action is implicit and somewhat vague, as the authors need to infer that they should consider changing the acronym but are not given concrete suggestions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the acronym \"follow the top perturbed leader\" (FTL), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the acronym, suggesting that it might be confusing due to its similarity to the common acronym \"follow the leader\" (FTL) in literature. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the acronym \"follow the top perturbed leader\" (FTL) is unfortunate because it is similar to the common acronym \"follow the leader\" (FTL) in literature. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this similarity is problematic or how it affects the clarity or understanding of the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the acronym \"follow the top perturbed leader\" (FTL), noting that it is similar to the common acronym \"follow the leader\" (FTL) in literature. This feedback is somewhat helpful as it points out a potential source of confusion and suggests a change in the acronym to avoid this issue. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue or what alternative acronyms might be more appropriate. While it highlights a potential problem, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the selection of attacks in Table 1 appears arbitrary and suggests that the authors should consider using state-of-the-art attacks, such as MIDIFGSM. It also requests that the authors mention the number of iterations the attacks are run for and provide additional details. This feedback is clear and provides specific actions for the authors to take, making it highly actionable. The authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"attacks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of attacks, suggesting that they are not state-of-the-art and providing examples of better attacks like MIDIFGSM. Additionally, it requests additional information, such as the number of iterations the attacks are run for, making the comment clear and specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of attacks in Table 1 is arbitrary and suggests that the authors should consider using state-of-the-art attacks like MIDIFGSM. The reviewer provides a reference to a survey that includes an extensive analysis of attacks, which supports the claim. However, the comment could be strengthened by providing specific examples or detailed reasoning from the survey to substantiate the claim. Despite this, the reference to the survey adds some verifiability to the claim, making it mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the selection of attacks in Table 1, noting that they are not state-of-the-art and suggesting that the authors consider using better attacks like MIDIFGSM. It also requests additional information, such as the number of iterations the attacks are run for, providing clear and actionable feedback. This feedback is valuable as it guides the authors to improve the quality and relevance of their experimental evaluation. However, the comment could be more helpful if it explained why MIDIFGSM is considered state-of-the-art or why this is important. Overall, the comment is mostly helpful as it directs the authors to make improvements that can enhance the paper\\'s rigor and relevance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the method's effectiveness, specifically noting that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this limitation or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"method\" and the \"limitations and conclusion\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the method may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the claim or how to address it. Without detailed evidence or reasoning, the authors may find it challenging to verify and address the claim effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the method's effectiveness, specifically noting that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This feedback is somewhat helpful as it highlights a potential weakness in the methodology, which the authors should consider addressing or explaining in the paper. However, the comment could be more helpful if it provided suggestions on how to address this limitation or examples of how other self-supervised methods might be integrated. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the qualitative analysis, specifically regarding the determination of two input sentences for qualitative analysis (Sec 4.5.5, Figure 1) and the attribution values in Fig. 1. It suggests that the authors should mention whether these examples occurred during the fine-tuning process and whether the attribution map for the input examples that failed to be classified works well. While the comment provides specific questions and requests for clarification, it does not offer explicit guidance on how to address these issues. The authors can infer that they need to provide more detailed information about the qualitative analysis and the attribution values, but the action is implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 4.5.5, Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the qualitative analysis, such as the determination of input sentences and the attribution values in Fig. 1. The comment also raises questions about the normalization of vector norms and the attribution map for input examples that failed to be classified. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the qualitative analysis, specifically asking for more information about the determination of input sentences and the attribution values in Figure 1. It also questions whether the attribution map for input examples that failed to be classified works well. While the comment identifies areas for clarification, it does not present a subjective claim or opinion that requires verification. It is a request for additional information and does not make a claim that needs justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement in the qualitative analysis section, particularly regarding the determination of input sentences and the attribution values in Figure 1. It asks whether these examples occurred during the fine-tuning process and whether the attribution map for input examples that failed to be classified works well. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about their methodology and results. By addressing these questions, the authors can enhance the clarity and robustness of their analysis. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and completeness of their qualitative analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors include examples of practical applications where specific types of tensors need to be equivariant and clarify how these scenarios validate the advantages of using equivariant tensor functions. While the comment provides a clear action\u2014to include examples and clarify the advantages\u2014it does not specify which types of tensors should be equivariant or how to present these examples. The authors are left to infer the specific details, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, it does not specify which parts of the paper should include these examples or how they should be presented. The authors can infer that it relates to sections discussing equivariant tensor functions, but this inference is not direct. The comment is specific in suggesting the inclusion of examples and clarification, but it lacks full grounding as it does not explicitly mention the sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that these examples are necessary or how they would validate the advantages. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It recommends including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. This feedback is valuable as it guides the authors to enhance their draft by providing concrete examples and explanations that can strengthen the paper\\'s argument. However, the comment could be more helpful if it included specific types of tensors or scenarios to consider, which would provide even more detailed guidance. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the tables, including Table 2, where the methods ERM, cRT, and LWS are not referenced properly. It also points out that Section 3.2.3 does not fully align with the table. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to clarify the references and align the sections with the tables. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Section 3.2.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the tables, such as the lack of proper references for methods like ERM, cRT, and LWS, and the misalignment between the section and the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are issues with the tables, specifically mentioning Table 2, where methods like ERM, cRT, and LWS are not referenced properly. Additionally, it points out that Section 3.2.3 does not fully align with the table. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the issues. Without additional context or evidence, the claim is not fully verifiable, as it lacks the necessary detail to be substantiated. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific issues with the tables, particularly Table 2, where the methods ERM, cRT, and LWS are not referenced properly. It also points out that Section 3.2.3 does not fully align with the table. This feedback is clear and actionable, as it directs the authors to clarify the references and align the sections with the tables. By addressing these issues, the authors can improve the clarity and accuracy of their paper. However, the comment could be more helpful if it provided suggestions on how to improve the referencing or alignment process. Overall, the comment is mostly helpful as it effectively guides the authors on how to enhance the clarity and completeness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that the authors should provide more details on the suitability of the model for sarcastic/non-sarcastic utterances and explain why the eye-movement data is useful for sentiment classification beyond textual features. These actions are clear and specific, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as providing more details on the suitability of the model for sarcastic/non-sarcastic utterances and explaining the usefulness of eye-movement data for sentiment classification beyond textual features. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of requests for clarification and additional information. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying areas where the authors could improve their work. It points out that the model's suitability for sarcastic/non-sarcastic utterances is not addressed and suggests that the authors should provide more details for further analysis. Additionally, it questions the usefulness of eye-movement data for sentiment classification beyond textual features and suggests that the authors should provide more explanations. This feedback is clear and constructive, offering the authors a clear path to enhance their draft. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results are limited to two small-scale/resolution datasets and that the tables (table1 and table2) are professionally unprofessional, with DDIM being a sampler method instead of a model. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to expand the experimental results or improve the presentation of the tables. Without specific suggestions or actions, the authors are left without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table1\" and \"table2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the experimental results being limited to two small-scale/resolution datasets and the inappropriate labeling of DDIM as a model instead of a sampler method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results are limited to two small-scale/resolution datasets and that the tables (table1 and table2) are professionally unprofessional, with DDIM being a sampler method instead of a model. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental results, noting that the paper only conducts experiments on two small-scale/resolution datasets. It also points out that the tables (table1 and table2) are professionally unprofessional, with DDIM being labeled as a model instead of a sampler method. While the comment highlights a potential weakness, it does not provide specific suggestions or guidance on how to address these issues or expand the experimental results. The feedback is somewhat helpful as it directs the authors\\' attention to areas that need improvement, but it lacks actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide more clarification about why the proposed method is important, specifically by addressing the influence on privacy levels. It implies that the authors should explain what is lost in terms of privacy and what is gained in terms of utility. While the comment does not explicitly instruct the authors to add this information, it clearly outlines what needs to be clarified and provides a direction for improvement. The action is explicit and concrete, as it specifies the need for additional clarification on the importance of the proposed method. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and suggests that more clarification is needed about its importance. It specifies the issue by questioning whether the method is just adjusting the variance level of DPSGD and what implications this has on privacy levels. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the importance of the proposed method, suggesting that it may be limited to adjusting the variance level of DPSGD and does not address the impact on privacy levels. The reviewer implies that the authors should present what is lost in terms of privacy and what is gained in terms of utility. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the reasoning behind the claim and potentially conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more clarification about the importance of their proposed method. It points out that the method may be limited to adjusting the variance level of DPSGD and questions whether it influences privacy levels. The comment implies that the authors should address this issue by explaining what is lost in terms of privacy and what is gained in terms of utility. While the comment highlights an important area for clarification, it does not provide specific guidance or examples on how to present this information. This limits the comment\\'s helpfulness, as it offers a direction for improvement but lacks detailed guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical result is illustrative rather than demonstrative and recommends conducting a bigger-scale experiment. It specifically mentions a longer-horizon example that could be tabular. While the comment provides a clear direction for improvement, it does not offer detailed guidance on how to implement this suggestion or what specific aspects of the experiment should be expanded. The action is explicit but somewhat vague, as the authors know they need to conduct a larger-scale experiment but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the empirical result, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be improved: conducting a bigger-scale experiment and including a longer-horizon example. The suggestion to use a tabular format for the longer-horizon example provides clear guidance on how to enhance the empirical result. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the empirical result is illustrative rather than demonstrative and recommends conducting a bigger-scale experiment with a longer-horizon example. The comment provides a specific suggestion for improvement, which is to include a tabular representation of the longer-horizon example. However, the comment lacks detailed reasoning or evidence to support why a bigger-scale experiment or a longer-horizon example would be beneficial. While the suggestion is logical, it could be strengthened with more detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides a clear direction but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the empirical result, noting that it is illustrative rather than demonstrative. It suggests that a bigger-scale experiment would be beneficial and recommends including a longer-horizon example. The comment is specific in its suggestion for improvement, providing a clear direction for the authors to enhance the empirical results. However, it could be more helpful if it offered additional guidance on how to conduct the larger-scale experiment or what specific aspects of the empirical result should be emphasized. Overall, the comment is mostly helpful as it provides actionable feedback that can significantly improve the draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that Equation (13) does not have a closed-form solution and suggests that providing details about how it is solved in the experiments and on computational complexity would be helpful. This feedback is clear and direct, giving the authors a specific action to take by requesting additional information about the solution process. The comment is concrete, as it specifies exactly what needs to be added to the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (13),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a closed-form solution and the need for details about how it is solved in the experiments and on computational complexity. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equation (13) does not have a closed-form solution and suggests that providing details about how it is solved in the experiments and on computational complexity would be helpful. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Equation (13) by pointing out that it does not have a closed-form solution. It suggests that providing details about how it is solved in the experiments and on computational complexity would be helpful. This feedback is clear and actionable, as it directs the authors to include additional information that could enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided specific suggestions on how to present this information or what aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and comprehensiveness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should discuss the choice of \"proximity\" and the nature of the task. It provides a specific example of how proximity in the solution space does not always align with proximity in the Euclidean metric, particularly in complex tasks like mazes or robotic navigation. The reviewer suggests that the paper should analyze which tasks have reasonable proximity metrics and demonstrate failures on those that don\\'t. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of discussion on the choice of \"proximity\" and the nature of the task, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper should analyze tasks with reasonable proximity metrics and demonstrate failures on those that don\\'t. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks discussion on the choice of \"proximity\" and the nature of the task. It provides a specific example of how proximity in the solution space does not always align with proximity in the Euclidean metric, particularly in complex tasks like mazes or robotic navigation. This claim is somewhat verifiable as it logically explains the issue but lacks specific examples or references to substantiate the claim fully. The authors would need to further explore the relationship between proximity and task complexity to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of discussion on the choice of \"proximity\" and the nature of the task. It provides a clear and actionable suggestion by recommending that the paper analyze tasks with reasonable proximity metrics and demonstrate failures on those that don\\'t. This feedback is valuable as it guides the authors to address a critical aspect of their work that could impact its validity and applicability. However, the comment could be more helpful if it offered specific examples or references to similar studies that have addressed this issue, which would enhance the authors\\' understanding and action. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments lack implementation details, which are necessary for readers to fully understand and reproduce the results. However, it does not provide specific guidance on what these details should include or how they should be presented. The comment refers to \"Questions\" for more information, but this does not offer a clear action for the authors to take. The feedback is vague and lacks concrete instructions, leaving the authors uncertain about how to address the issue. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of implementation details in the experiments, which are necessary for readers to fully understand and reproduce the results. However, it does not specify which experiments or sections are lacking these details, making it difficult for the authors to pinpoint the exact areas that need improvement. The reference to \"Questions\" suggests that the authors should seek additional information, but this does not provide clear guidance on what specific details are missing. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, and it is not specific in detailing what needs to be added. This aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experiments lack implementation details, which are necessary for readers to fully understand and reproduce the results. However, the comment does not provide specific examples or detailed reasoning to support this claim. It refers to \"Questions\" for more information, but this does not constitute a fully verifiable claim. The authors would need to follow up on the questions to understand the specific details lacking. Therefore, the comment is considered borderline verifiable, as it provides some indication of an issue but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the experiments lack implementation details necessary for readers to fully understand or reproduce the results. While it highlights a critical area for improvement, the comment does not provide specific guidance on what details are missing or how they should be addressed. It refers to \"Questions\" for more information, which may not be immediately apparent to the authors. This lack of detailed feedback limits the comment\\'s usefulness in helping the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but lacks depth and actionable suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the comparison between SSUL and the paper, specifically regarding the use of off-the-shelf saliency-map detectors versus the pretrained Mask2Former model. It suggests that this comparison may be unfair due to differences in data and model size. The reviewer poses two questions: \"What if SSUL also adopts Mask2Former to detect unseen classes?\" and \"What if SSUL can generate object proposals in an unsupervised way without additional data or heavy models?\" These questions imply that the authors should consider adopting Mask2Former or exploring unsupervised methods for object detection. While the comment does not explicitly instruct the authors to take these actions, it provides clear and concrete suggestions for improvement. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of the off-the-shelf saliency-map detector and the pretrained Mask2Former model, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of an unfair comparison due to differences in data and model size, and it raises questions about whether SSUL could adopt Mask2Former or explore unsupervised methods for object detection. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison between SSUL and the paper, specifically regarding the use of off-the-shelf saliency-map detectors versus the pretrained Mask2Former model. The reviewer questions whether this comparison is fair due to differences in data and model size. The comment suggests that SSUL could adopt Mask2Former or explore unsupervised methods for object detection. While the comment provides a logical reasoning for the potential unfairness, it lacks specific examples or references to substantiate the claim fully. The suggestion to explore unsupervised methods is a valid point, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between SSUL and the paper, specifically regarding the use of off-the-shelf saliency-map detectors versus the pretrained Mask2Former model. It raises a valid concern about the fairness of the comparison due to differences in data and model size. The comment suggests that SSUL could adopt Mask2Former or explore unsupervised methods for object detection, which are actionable suggestions that could improve the paper. However, the comment could be more helpful if it provided more detailed guidance on how to implement these suggestions or why they are important. Overall, the comment is somewhat helpful as it points out a potential issue and offers some actionable suggestions, but it could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the metrics used to validate the performance of the proposed approach. It suggests that the style accuracy, which is based on a style classifier, may not accurately capture the styleness of the proposed algorithm. Additionally, it points out that for cases with a styled motion input, the transfer result based on the stylized input may not be easily verifiable. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific metrics or modifications should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the metrics used and possibly explore alternative methods for validation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of metrics used for the experiments, specifically mentioning the style accuracy and its reliance on a style classifier. It also points out a potential problem with verifying the transfer result based on a stylized input. However, the comment does not specify which part of the paper discusses these metrics or where the issue is located, making it weakly grounded. The comment is specific in detailing the potential problem with the metrics, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metrics used to validate the performance of the proposed approach may not accurately capture the styleness of the algorithm. It provides a specific example of the style accuracy, which is based on a style classifier, and suggests that this may not be sufficient for verifying the transfer result based on a stylized input. The comment logically reasons that the style classifier may not be able to accurately capture the styleness of the proposed algorithm. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the issue and potentially conduct additional experiments to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the metrics used to validate the performance of the proposed approach. It points out that the style accuracy, which is based on a style classifier, may not accurately capture the styleness of the proposed algorithm. Additionally, it highlights a challenge in verifying the transfer result based on a stylized input. This feedback is somewhat helpful as it prompts the authors to reconsider the metrics used and potentially explore alternative methods for validation. However, the comment could be more helpful if it provided specific suggestions or examples of alternative metrics that could be used to address this issue. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how individual preferences are generated and interpreted in the proposed method. It explicitly asks the authors to clarify how preferences are generated and whether they are based on rules or policies learned from experiences. This feedback provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be clarified in the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors argue that the proposed method considers individual preferences when simulating agents. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified, namely, how individual preferences are generated and interpreted. The authors are given clear guidance on what needs to be addressed to improve the clarity of their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how individual preferences are generated and interpreted in the proposed method. It suggests that the authors need to clarify how certain agents are more risk-averse than others. The comment is somewhat verifiable as it highlights a potential gap in the explanation of the method, but it does not provide specific examples or references to support the claim. The authors would need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely, the clarity of how individual preferences are generated and interpreted in the proposed method. It points out that the authors need to clarify how certain agents are more risk-averse than others, and whether the interpretation of \"preference\" is based on rules or policies learned from experiences. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or clarifications in the paper. By addressing this issue, the authors can improve the clarity and comprehensibility of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about Figure 4, including the meaning of \"1-200 frames,\" how values are computed, and the changing precision and recall with trajectory length. It also asks about \"action repeat.\" While the comment identifies specific areas of confusion, it does not provide explicit instructions or concrete guidance on how the authors should address these issues. The authors are left to infer that they need to clarify these points, but the comment lacks detailed suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the meaning of \"1-200 frames,\" how values are computed, and the changing precision and recall with trajectory length. Additionally, it asks about \"action repeat,\" providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the meaning of \"1-200 frames\" and how values are computed, as well as the changing precision and recall with trajectory length. It also asks about \"action repeat.\" While the comment identifies areas of confusion, it does not provide specific examples or references to support the claims. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific areas of confusion in Figure 4, such as the meaning of \"1-200 frames\" and how values are computed. It also questions the changing precision and recall with trajectory length and asks about \"action repeat.\" This feedback is clear and actionable, as it directs the authors to clarify these points in their paper. By addressing these questions, the authors can improve the clarity and understanding of their results. However, the comment could be more helpful if it provided suggestions on how to present this information or offered examples of how similar issues have been addressed in similar studies. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and comprehensibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the arbitrary nature of some design decisions, such as the number of initial ground truth examples and the number of labeled examples. It suggests that the performance of LLaMAA versus finetuning could be compared if finetuning was performed on a number of samples equivalent in cost to the additional samples from the LLM. The reviewer also requests justification for these design decisions to increase their soundness score. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to perform the suggested comparison or provide justification. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the design decisions related to the number of initial ground truth examples and the number of labeled examples, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the comparison of LLaMAA versus finetuning and the justification for these design decisions. This provides clear guidance on what the authors need to address to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the arbitrary nature of some design decisions, such as the number of initial ground truth examples and the number of labeled examples. It suggests that a comparison between LLaMAA and finetuning could be more meaningful if finetuning was performed on a number of samples equivalent in cost to the additional samples from the LLM. The reviewer also requests justification for these design decisions to increase their soundness score. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that cost-effectiveness is a primary motivation. This makes the claim somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the design decisions regarding the number of initial ground truth examples and the number of labeled examples, suggesting that these choices may be arbitrary. It proposes a comparison between LLaMAA and finetuning, which could provide insight into the cost-effectiveness of the approach. The comment also requests justification for these design decisions to increase the authors\\' soundness score. While the feedback highlights a potential weakness in the paper, it lacks specific guidance on how to address the issue or what specific justification should be provided. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the motivation for investigating a graph-structured model and questions the complexity of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify the motivation or simplify the approach. The authors are left without any direction on how to address the reviewer\\'s concerns, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the motivation for investigating a graph-structured model and questions the complexity of the approach. However, it does not specify which part of the paper this discussion pertains to, such as a particular section or figure where the motivation or complexity is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in detailing the confusion regarding the motivation and the use of Transformer-based models, but without clear grounding, it lacks actionable guidance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation for investigating a graph-structured model and suggests that the complexity of the approach is unclear. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or references to substantiate the confusion about the approach. As a result, the claim is not verifiable, making it difficult for the authors to understand and address the reviewer\\'s concerns. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the motivation for investigating a graph-structured model and questions the complexity of the approach. It points out that the encoder and decoder are based on Transformer, which can draw global dependencies in a sentence. However, the comment does not provide specific suggestions or guidance on how the authors might clarify the motivation or simplify the approach. While it identifies a potential area of confusion, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide videos showing different policies controlling cars on different tracks to enhance understanding of their methods. It also points out that some implementation details are missing from the main paper, making it difficult to reproduce the results. However, the comment does not specify which implementation details are missing or how they should be addressed. While the action of providing videos is explicit, the lack of concrete guidance on the missing implementation details makes the comment somewhat actionable. The authors are left to infer what specific details are missing and how to address them, which reduces the actionability of the comment.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests providing videos showing different policies controlling cars on different tracks to enhance understanding of the methods. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. Additionally, it mentions the lack of implementation details, but it does not specify which details are missing or how they affect reproducibility. This makes the comment weakly grounded because the authors cannot confidently determine which part of the paper is being addressed, and it is under-specific because it does not provide detailed guidance on what needs to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that providing videos showing different policies controlling cars on different tracks would enhance understanding of the methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand the basis of the suggestion. Additionally, the comment mentions the lack of implementation details, which is a factual observation but does not provide specific examples or reasoning to support the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that the authors should include videos showing different policies controlling cars on different tracks to enhance the reader\\'s understanding of the methods. This is a clear and actionable suggestion that could significantly improve the clarity and accessibility of the paper. Second, it points out that some implementation details are missing from the main paper, making it difficult to reproduce the results. This is a relevant observation that could help the authors improve the reproducibility of their work. However, the comment could be more helpful if it specified which implementation details are missing or how they affect the results. Overall, the comment is mostly helpful as it provides actionable suggestions for improving the clarity and reproducibility of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the approximation in Equation 11 and suggests that the authors should conduct more experiments and theoretical analyses to explore the effect of the order of layers with the same parameters on the approximation. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct these experiments or what specific analyses should be conducted. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 11\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the approximation in Equation 11 and suggesting that the authors should conduct more experiments and theoretical analyses to explore the effect of the order of layers with the same parameters on the approximation. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the approximation in Equation 11 and suggests that the authors should conduct more experiments and theoretical analyses to explore the effect of the order of layers with the same parameters on the approximation. The comment provides a logical reasoning by pointing out that the approximation only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters in the network. However, the comment lacks specific examples or references to support the claim that the approximation is insufficient. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approximation in Equation 11 and suggests that the authors should conduct more experiments and theoretical analyses to explore the effect of the order of layers with the same parameters on the approximation. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their work by conducting additional analyses. However, the comment could be more helpful if it offered specific suggestions on which experiments or analyses to conduct or how to interpret the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that addressing offline-to-online learning adaptation appears to be incremental, as most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. The reviewer implies that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment does not provide explicit guidance on how to implement this fine-tuning or what specific aspects of the existing benchmarks need to be adapted. The action is implicit and somewhat vague, as the authors can infer that they need to consider online fine-tuning but are not given detailed instructions on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of offline-to-online learning adaptation, suggesting that it appears to be incremental due to the nature of previous offline RL benchmarks based on simulation environments and rule-based reward functions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the feasibility of implementing online fine-tuning on existing benchmarks, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that addressing offline-to-online learning adaptation appears to be incremental due to the nature of previous offline RL benchmarks based on simulation environments and rule-based reward functions. The comment suggests that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors may find it challenging to understand the basis of the claim without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper regarding the feasibility of addressing offline-to-online learning adaptation. It suggests that the approach may be incremental due to the nature of previous offline RL benchmarks based on simulation environments and rule-based reward functions. The comment also implies that implementing online fine-tuning on top of existing benchmarks is feasible. While the comment highlights a relevant issue, it lacks specific suggestions or guidance on how the authors might address this limitation or improve their approach. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a contradiction in the evidence presented in Table 6, specifically regarding the F1 scores for AT, BERTsynth, and GAS. It suggests that the results do not support the claim that emotion-awareness is useful for synthetic text detection. While the comment identifies a specific issue with the evidence, it does not provide explicit guidance on how the authors should address this contradiction or improve their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should re-evaluate their evidence and potentially revise their claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the contradiction in the evidence presented, specifically pointing out that AT achieves a worse F1 score than BERTsynth and that GAS achieves the lowest F1 score despite fine-tuning with multiple emotion classification datasets. This provides clear guidance on what needs to be addressed, namely the contradiction in the evidence and the need to re-evaluate the claim that emotion-awareness is useful for synthetic text detection. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 6 provides contradicting evidence, specifically noting that AT achieves a worse F1 score than BERTsynth and that GAS achieves the lowest F1 score despite fine-tuning with multiple emotion classification datasets. This suggests that emotion-awareness might not be useful for synthetic text detection. The comment provides logical reasoning by pointing out the discrepancy in the F1 scores, which supports the claim. However, it could be strengthened by providing specific examples or references to the data or studies that led to these conclusions. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evidence presented in Table 6, noting contradictory results that suggest emotion-awareness might not be useful for synthetic text detection. It points out that AT achieves a worse F1 score than BERTsynth and that GAS achieves the lowest F1 score despite fine-tuning with multiple emotion classification datasets. This feedback is clear and actionable, as it prompts the authors to re-evaluate their evidence and potentially revise their claims about the usefulness of emotion-awareness. By highlighting these discrepancies, the comment provides the authors with a concrete direction for improving their draft. Therefore, it is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting more experiments to address the research question and provides specific guidance on testing with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models, such as multiplicative distortions. These suggestions are explicit and provide concrete actions for the authors to take, including which models to test and what types of noise to consider. The comment is clear and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments to address the research question and provides specific guidance on testing with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models, such as multiplicative distortions. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or results. The comment is specific in detailing what additional experiments should be conducted and how they would enhance the evaluation. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments to address the research question and provides a specific recommendation to test with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models, such as multiplicative distortions. While the comment provides a logical basis for the suggestion, it lacks specific examples or references to support the claim that these additional experiments would enhance the evaluation. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and implement the suggestions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors conduct more experiments to address the research question. It specifically recommends testing with various models, such as Vision Transformers (ViT), and including results under more complex input noise models, such as multiplicative distortions. This guidance is valuable as it offers a concrete direction for the authors to enhance their experimental evaluation and demonstrate the method's generalizability. However, the comment could be more helpful if it provided additional context or examples of how these additional experiments could be conducted or what specific aspects of the research question they address. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the number of human annotators mentioned in the D.2 appendix should be increased from two to four, based on the author responses. This is a clear and direct action for the authors to take, as it specifies the exact change needed to be made. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"D.2 appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the number of human annotators, which should be increased from two to four based on the author responses. This provides clear guidance on what needs to be corrected in the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of human annotators mentioned in the D.2 appendix should be increased from two to four, based on the author responses. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it should be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the D.2 appendix, noting that the number of human annotators mentioned should be increased from two to four, based on the author responses. This is a clear and actionable piece of feedback that can help the authors improve the accuracy and completeness of their work. However, the comment could be more helpful if it provided additional context or explanation about why this change is necessary or how it might impact the overall quality of the appendix. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, making it a valuable contribution to the review process.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a better motivation for the encoder and decoder structure would be beneficial in understanding the value of the proposed approach. However, it does not provide specific guidance on what kind of motivation would be more effective or how to incorporate it into the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed explanation of the motivation but are not given concrete steps on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a better motivation for the encoder and decoder structure would help to better understand the value of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, methodology, or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need to be addressed. The comment is specific in suggesting a need for a better motivation but lacks grounding, making it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a better motivation for the encoder and decoder structure would help to better understand the value of the proposed approach. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential weakness in the paper, specifically the lack of a clear motivation for the encoder and decoder structure. It suggests that providing a better motivation would help the authors and readers better understand the value of the proposed approach. While the comment highlights an important area for improvement, it does not offer specific guidance or examples on how to enhance the motivation or what kind of motivation would be beneficial. This limits the comment\\'s helpfulness, as it points out a potential issue but does not provide actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the novelty of the explored loss functions, the nature of the attacks, and the lack of black-box evaluation. It suggests that the paper should consider targeted attacks and extend the analysis to showcase the strength of the proposed attack method. While the comment identifies areas for improvement, it does not provide explicit instructions on how to implement these changes or what specific aspects of the analysis should be expanded. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to address the concerns. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several concerns regarding the novelty of the explored loss functions, the nature of the attacks, and the absence of black-box evaluation. It suggests that the paper should consider targeted attacks and extend the analysis to showcase the strength of the proposed attack method. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the novelty of the loss functions and the need for black-box evaluation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the novelty of the explored loss functions and the nature of the attacks, suggesting that they are not new and appear to be a simple \"plug and play\" of existing loss functions. The reviewer also criticizes the absence of black-box evaluation and the limited scope of the analysis to untargeted attacks. However, the comment lacks specific examples or references to support the claim that the loss functions are not novel or that the attacks are not innovative. The suggestion to consider targeted attacks is logical but not fully substantiated by evidence or detailed reasoning. Therefore, the claim is somewhat verifiable, as it provides some basis but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the novelty of the explored loss functions, the nature of the attacks, and the absence of black-box evaluation. It suggests that the paper should consider targeted attacks and extend the analysis to showcase the strength of the proposed attack method. While the comment highlights important weaknesses, it lacks specific suggestions on how to address these issues or what specific aspects of the analysis should be expanded. The feedback is somewhat helpful as it points out areas for improvement but could be more actionable with additional guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. It also mentions the desire to see results for CIFAR100. While the comment implies that the authors should conduct a direct comparison and provide results for CIFAR100, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison and provide additional results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results for CIFAR10, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of impressiveness of the results and the need for a direct comparison with other approaches. Additionally, it suggests including results for CIFAR100. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the results are considered unimpressive. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results for CIFAR10, noting that they are not impressive and suggesting that a direct comparison with other approaches is necessary. It also suggests including results for CIFAR100. While the comment highlights a potential weakness in the paper, it lacks depth and does not provide specific suggestions or guidance on how to improve the results or conduct the comparison. The feedback is somewhat helpful as it points out an area for improvement but could be more actionable with additional details. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while hyperbolic space is well suited for hierarchical datasets, the experiments do not clearly demonstrate this. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to conduct experiments that would clearly demonstrate the suitability of hyperbolic space for hierarchical datasets. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of demonstrating the suitability of hyperbolic space for hierarchical datasets, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or experiment is being referred to, making the comment weakly grounded. However, it is specific in detailing what needs to be addressed, namely the lack of clear demonstration of the suitability of hyperbolic space for hierarchical datasets. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that hyperbolic space is well suited for hierarchical datasets but that the experiments do not clearly demonstrate this. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that while hyperbolic space is well suited for hierarchical datasets, the experiments do not clearly demonstrate this. This feedback highlights a gap in the paper that the authors should address to strengthen their claims. However, the comment does not provide specific suggestions or guidance on how to improve the demonstration of hyperbolic space\\'s suitability for hierarchical datasets. While it points out an area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the main strength of MixBoost, specifically whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide a clearer explanation of the strengths of MixBoost, but the comment does not specify how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the main strength of MixBoost, specifically whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the main strength of MixBoost, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the main strength of MixBoost. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a valid question about the main strength of MixBoost, specifically whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. This is an important point that could help the authors clarify the contributions of their work and improve its clarity. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending which aspect to emphasize or providing examples of how to present this information. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the statement \"Unlike previous works which use the test set for hyperparameter tuning\" is surprising and suggests that the wording is difficult. It also mentions that the \"smaller training set\" (line 245) could be avoided by training the network with optimal parameters on the complete train+val set. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should revise the wording and consider training with optimal parameters on the complete train+val set. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement these changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 243\" and \"line 245,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely the wording of the statement regarding hyperparameter tuning and the suggestion to avoid the \"smaller training set\" by training with optimal parameters on the complete train+val set. This level of detail provides clear direction for the authors to make improvements. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement \"Unlike previous works which use the test set for hyperparameter tuning,\" suggesting that the wording is difficult and that the smaller training set could be avoided by training with optimal parameters on the complete train+val set. The reviewer provides a logical reasoning for the suggestion, noting that proper hyperparameter tuning is essential in ML. However, the comment lacks specific examples or references to support the claim that the wording is difficult or that the smaller training set is problematic. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording in the paper, noting that the statement \"Unlike previous works which use the test set for hyperparameter tuning\" is surprising and difficult to understand. It suggests that the wording could be improved by rephrasing it to better convey the intended meaning. Additionally, the reviewer points out that the smaller training set (line 245) could be avoided by training with optimal parameters on the complete train+val set. This feedback is somewhat helpful as it provides specific suggestions for improving the clarity and accuracy of the text. However, it could be more helpful if it included examples of alternative wordings or detailed guidance on how to implement the suggested changes. Overall, the comment offers some actionable advice but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s writing needs improvement, particularly in the introduction, which is described as obscure and high-level. The reviewer recommends that the authors provide more detailed information about how they tokenize parameters and use DDPM to predict actual parameters. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft. The suggestion is clear and specific, giving the authors a clear path to enhance the clarity and depth of their introduction. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" and \"high-level\" aspects of the writing, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, such as providing more detailed information on how the authors tokenize parameters and use DDPM to predict actual parameters. This level of detail provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the writing of the paper needs improvement, particularly in the introduction, which is described as obscure and high-level. The reviewer suggests that the authors should provide more detailed information about how they tokenize parameters and use DDPM to predict actual parameters. This claim is somewhat verifiable as it provides a logical reasoning for improvement, but it lacks specific examples or references to support the claim. The authors might find it challenging to fully understand the exact details needed to improve the introduction without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s writing, particularly in the introduction, which is described as obscure and high-level. It suggests that the authors provide more detailed information about how they tokenize parameters and use DDPM to predict actual parameters, which could help clarify the paper\\'s content. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve the clarity and depth of their introduction. By addressing these points, the authors can enhance the comprehensibility and effectiveness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the presentation is not good and suggests that the authors should name a few examples to improve it. However, it does not provide specific guidance on what aspects of the presentation are problematic or how the authors should address these issues. The action is implicit and vague, as the authors are left to infer that they need to identify and improve the presentation without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the presentation is not good and suggests that the authors should name a few examples to improve it. However, it does not specify which part of the presentation is problematic or what specific examples should be included. Without explicit references to sections, figures, or other elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the presentation are lacking or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation is not good, but it does not provide any specific examples or reasoning to support this claim. Without detailed feedback or evidence, the authors are left without a clear understanding of what aspects of the presentation are problematic or how they could improve it. As a result, the claim is unverifiable, as it lacks the necessary justification or examples to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the presentation is not good and implies that the authors should provide examples to improve it. However, it does not specify which aspects of the presentation are problematic or what specific examples should be included. Without detailed guidance or examples, the authors are left with a vague suggestion that lacks actionable feedback. This makes the comment barely helpful, as it provides some direction but not enough detail for the authors to effectively address the issue. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing reference to the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. This provides a clear and direct action for the authors to include this reference in their paper. The comment is specific and concrete, as it specifies the exact part of the paper that needs revision and the missing reference. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the correlation of topological complexity with generalization ability, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the missing reference to the work by Rieck et al. [2], which is relevant to the discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have missed a relevant reference, specifically the work by Rieck et al. [2], when discussing the correlation of topological complexity with generalization ability. However, the comment does not provide any supporting evidence or reasoning to justify why this reference is important or how it relates to the discussion. Without additional context or explanation, the authors may find it challenging to understand the significance of the reference or how it could enhance their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific oversight in the related work section, noting that the authors have missed a relevant reference to the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. This feedback is clear and actionable, as it directs the authors to include the missing reference in their paper. By addressing this point, the authors can enhance the comprehensiveness and accuracy of their literature review. However, the comment could be more helpful if it provided additional context or explanation about why this reference is important or how it relates to the discussion. Overall, the comment is mostly helpful as it guides the authors to a specific improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the usefulness of the exploration parameter gamma, given that only upper bounds on the pseudo-regret are provided. It suggests that the choice of gamma=0 might be optimal and questions the role of gamma in the analysis. The reviewer also mentions the possibility of extending the analysis to high-probability bounds on the regret. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should consider these points and potentially revise their analysis, but the comment lacks detailed guidance on how to implement these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Alg 1\" and \"Thm 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the pseudo-regret bounds and suggests that the exploration parameter gamma might be unnecessary. The comment also raises a question about the role of gamma and whether the analysis can be extended to high-probability bounds on the regret. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the usefulness of the exploration parameter gamma, given that only upper bounds on the pseudo-regret are provided. The reviewer questions whether the choice of gamma=0 is optimal and suggests that a remark on high-probability upper bounds and the role of gamma might be interesting. The comment also asks whether the analysis, which is heavily based on expectations, can be extended to high-probability bounds on the regret. While the comment provides logical reasoning and questions the current analysis, it lacks specific examples or references to support the claim about the optimal value of gamma or the feasibility of extending the analysis. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the pseudo-regret bounds provided in the paper, suggesting that the exploration parameter gamma might be unnecessary due to the upper bounds. It raises a question about the role of gamma and whether the analysis can be extended to high-probability bounds on the regret. This feedback is somewhat helpful as it points out a potential weakness in the paper and prompts the authors to consider whether their analysis is robust enough. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or extend their analysis. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to either restate the definition of the LCA relaxation from Wang et al. in the body of the paper or add a description to the appendix. This provides a clear and direct action for the authors to take, ensuring that the definition is included in the paper. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 150,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a direct definition of the LCA relaxation and suggests either restating the definition from Wang et al. in the body of the paper or adding a description to the appendix. This provides clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the LCA relaxation is referenced on line 150 but not directly defined. It suggests adding a restatement of the definition from Wang et al. or a description in the appendix. This claim is somewhat verifiable as it provides a specific line number and references a potential source for the definition, which could help the authors locate the relevant information. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the LCA relaxation is referenced on line 150 but not directly defined. It provides a clear and actionable suggestion by recommending either restating the definition from Wang et al. in the body of the paper or adding a description to the appendix. This feedback is valuable as it directs the authors to a specific area needing clarification, ensuring that the definition is included in the paper. However, the comment could be more helpful if it explained why this clarification is important or how it affects the overall understanding of the paper. Overall, the comment is mostly helpful as it guides the authors to improve the clarity and completeness of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not explicitly instruct the authors to include this information or provide guidance on how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to include this information but may not be entirely sure of the specific details or format. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. The comment is specific in suggesting the need for more information but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks the necessary evidence or justification to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more information on how validation and test splits influence model training could strengthen reproducibility. This feedback is clear and actionable, as it points out a potential gap in the paper that could enhance its robustness and transparency. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the scope of the study and suggests exploring additional regularization techniques beyond dropout. It implies that the authors should consider other regularization methods like L2 regularization, data augmentation, and adding noise. The reviewer also questions the use of a single regularization technique and suggests that the authors might want to investigate the combination of these techniques with ZeroLiers. While the comment provides a clear direction for the authors to expand their scope and consider alternative methods, it does not explicitly instruct them to do so. The action is implicit but concrete, as it specifies the additional techniques to explore and the need to consider their combination with ZeroLiers. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"overfitting problem\" and suggests exploring other regularization techniques beyond dropout, such as L2 regularization, data augmentation, and adding noise. It also questions the use of a single regularization technique and suggests investigating the combination of these techniques with ZeroLiers. This provides clear guidance on what aspects of the paper need further exploration or consideration. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the scope of the study and suggests exploring alternative regularization techniques beyond dropout. It questions the use of a single regularization technique and suggests investigating the combination of these techniques with ZeroLiers. While the comment provides a logical basis for the critique, it lacks specific examples or references to support the claim that other techniques should be considered. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the scope of the study and the use of a single regularization technique. It suggests exploring alternative regularization methods like L2 regularization, data augmentation, and adding noise, which could enhance the robustness and generalizability of the results. The comment also questions the use of dropout as the sole regularization technique and suggests investigating the combination of these techniques with ZeroLiers. This feedback is valuable as it encourages the authors to broaden their scope and consider a wider range of regularization methods. However, the comment could be more helpful if it provided specific examples or references to support the suggestion. Overall, the comment is mostly helpful as it offers actionable guidance for improving the study\\'s scope and depth.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should discuss the generalization of Assumption A (overlap) from a tabular setting to a function approximation setting. It points out that the authors mention this in the section about consistency, implying that the authors should expand on this discussion. The comment provides a clear and concrete action for the authors to take, which is to discuss the generalization of the assumption in the context of function approximation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption A (overlap)\" and \"the section about consistency,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the generalization of Assumption A from a tabular setting to a function approximation setting. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the assumption of overlap in Assumption A is reasonable in a tabular setting but raises a question about its generalization to a function approximation setting. The reviewer provides a logical reasoning by pointing out that the authors mention this in the section about consistency, implying that it should be discussed further. However, the comment lacks specific examples or references to support the claim that the assumption is not valid in a function approximation setting. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific assumption (Assumption A) and questions its generalizability from a tabular setting to a function approximation setting. It suggests that the authors should discuss this assumption in the context of consistency, which is a valuable point for the authors to consider. However, the comment could be more helpful if it provided examples or references to similar situations where this assumption has been tested or discussed in the literature. While it offers a clear direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It explicitly states that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width. Additionally, it acknowledges that the paper was difficult to understand during the first read and suggests that major improvements could be achieved by straightening up the content. These specific actions and suggestions are clear and provide the authors with a direct path to enhance the clarity and readability of their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"figures 3, 5, and 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width. Additionally, it acknowledges that the paper was difficult to understand during the first read and suggests that major improvements could be achieved by straightening up the content. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width. It also claims that the paper was difficult to understand during the first read and suggests that major improvements could be achieved by straightening up the content. However, the comment lacks specific examples or detailed reasoning to support these claims. The suggestion to improve the layout of the figures is somewhat vague, and the claim about the paper\\'s understandability is not substantiated with specific examples or detailed analysis. Therefore, the comment is somewhat verifiable, as it provides some support but lacks the necessary depth and specificity to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the layout of tables and figures in the paper, suggesting that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width. This feedback is clear and can help the authors improve the readability and clarity of their draft. Additionally, the comment acknowledges that the paper was difficult to understand during the first read and suggests that major improvements could be achieved by straightening up the content. This feedback is valuable as it identifies a potential area for improvement and provides a clear direction for the authors to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it provided additional suggestions on how to improve the content or structure of the paper. Overall, the comment is mostly helpful as it offers actionable guidance for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests repeating the Text-DPO baseline but with the generated images used for DPO as images for additional image-question-answer triplets. It also speculates that training with perturbed images is providing the additional performance benefit for the method, rather than the specific DPO objective. While the comment provides a clear action to take, it lacks specific guidance on how to implement this suggestion or what specific changes should be made to the baseline. The authors are left with a general idea of what to do but without detailed instructions on how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests repeating the Text-DPO baseline with the generated images used for DPO as images for additional image-question-answer triplets. It also speculates on the role of training with perturbed images in providing additional performance benefits. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential modification to the baseline and providing a rationale for the change, but without clear grounding, it is difficult for the authors to fully understand and address the suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests repeating the Text-DPO baseline with the generated images used for DPO as images for additional image-question-answer triplets. The reviewer provides a rationale based on their suspicion that training with perturbed images is providing the additional performance benefit for the method, rather than the specific DPO objective. This reasoning is logical and provides a plausible explanation, but it lacks specific examples or references to support the claim fully. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by repeating the Text-DPO baseline with the generated images used for DPO as images for additional image-question-answer triplets. This is a clear and actionable piece of feedback that could help the authors explore the impact of using perturbed images on the performance of their method. Additionally, the comment offers a rationale based on the reviewer\\'s suspicion that training with perturbed images is providing the additional performance benefit, rather than the specific DPO objective. This insight could lead to a deeper understanding of the method\\'s strengths and weaknesses, and potentially guide the authors to refine their approach. However, the comment could be more helpful if it provided additional guidance on how to implement this suggestion or what specific aspects of the method might be affected by using perturbed images. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, but it could be further enhanced with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a final assumption that there is no difference in expertise between Alice and Bob, which could lead to non-linear interactions between success-rate and speed-up due to different levels of expertise. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this assumption or what specific changes should be made to account for the potential non-linear interactions. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a final assumption regarding the expertise of Alice and Bob, suggesting that there could be non-linear interactions between success-rate and speed-up due to different levels of expertise. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue with the assumption and the potential consequences of non-linear interactions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that there is no difference in expertise between Alice and Bob, suggesting that this assumption could lead to non-linear interactions between success-rate and speed-up due to different levels of expertise. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumption that there is no difference in expertise between Alice and Bob, suggesting that this could lead to non-linear interactions between success-rate and speed-up due to different levels of expertise. This is a relevant point that could impact the validity of the results and the applicability of the assumptions made. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or test for non-linear interactions. While it highlights an important consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the generalizability of the mitigation strategies, specifically mentioning that they are data set specific and might not be applicable more broadly. It acknowledges that the framework demonstrates the possibility of data leakage but points out that its applicability to other LLMs and datasets is limited. However, the comment does not provide explicit guidance or suggestions on how to address this issue or improve the generalizability of the framework. The authors are left to infer that they might need to consider broader applicability or provide more detailed explanations of the mitigation strategies. Therefore, the comment is somewhat actionable, as it identifies a potential issue but lacks concrete steps for improvement.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the mitigation strategies, specifically mentioning the issue of data set specificity and its applicability to other LLMs and datasets. However, it does not specify which part of the paper discusses these strategies or where the issue is located. The authors can infer that it relates to sections discussing data leakage or mitigation strategies, but this inference is not direct. The comment is specific in detailing the issue of generalizability, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the mitigation strategies, specifically sanitizing the data, are data set specific and might not be applicable more broadly. The reviewer acknowledges that the framework demonstrates the possibility of data leakage but questions its generalizability to other LLMs and datasets. However, the comment lacks specific examples or references to support the claim that the mitigation strategies are not applicable more broadly. Without detailed evidence or examples, the authors may find it challenging to address the issue effectively. Therefore, the claim is somewhat verifiable, as it provides a logical argument but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the generalizability of the mitigation strategies, specifically mentioning that they are data set specific and might not be applicable more broadly. It acknowledges that the framework demonstrates the possibility of data leakage but points out that its applicability to other LLMs and datasets is limited. This feedback is somewhat helpful as it highlights a potential weakness in the framework\\'s generalizability, which the authors should consider when refining their work. However, the comment could be more helpful if it provided suggestions on how to address this limitation or examples of how other LLMs might apply the framework. Overall, the comment offers some insight but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the paper is not clear in certain aspects and provides a list of questions. However, it does not explicitly instruct the authors on how to address these issues or clarify what specific changes are needed. The action is implicit and vague, as the authors are left to infer that they need to improve the clarity of their paper. Without concrete guidance or detailed suggestions, the authors may find it challenging to know exactly how to apply the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that the paper is not sufficiently clear in certain aspects and provides a list of questions. However, it does not specify which parts of the paper are unclear or where the questions arise, making it difficult for the authors to pinpoint the exact areas that need clarification. Additionally, the comment lacks specificity in detailing what needs to be addressed or improved in these unclear sections. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not sufficiently clear in certain aspects, but it does not provide specific examples or detailed reasoning to support this claim. The list of questions is not sufficient to guide the authors on what aspects need clarification or improvement. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand and address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the paper and provides a list of questions that could help the authors address this issue. However, the comment lacks specificity and does not provide detailed guidance on how to improve the clarity or what specific aspects need clarification. While it points out a potential weakness, it does not offer actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2. It also asks about the specific task that participants are performing. While the comment implies that the authors should clarify these aspects, it does not provide explicit instructions or concrete guidance on how to address these questions. The authors can infer that they need to provide more information or clarification, but the comment lacks detailed suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2. Additionally, it raises a question about the task participants are performing, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2. It also asks about the specific task that participants are performing, which could be crucial for understanding the context and significance of the work. While the comment identifies areas that need clarification, it does not provide specific guidance or suggestions on how to address these questions. The authors are left with a clear understanding of what needs to be clarified but may not have a clear path forward on how to do so. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors did not address specific problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, it does not provide any explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable details, such as recommending specific approaches or methods to incorporate these aspects into the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion on specific problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the missing aspects of the paper, such as memory and personalization, and reasoning over common sense and facts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not address specific problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that it does not address specific problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. This feedback highlights an important area for improvement, as these topics are relevant to the field and could enhance the paper\\'s contribution. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or incorporate them into their work. While it points out a critical area for improvement, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the paper regarding the lack of statistical distribution on paper venues, specifically the number of papers from ACL and EMNLP versus those from Arxiv. It also raises concerns about the inclusion of Arxiv papers in the study, noting that Arxiv papers are not peer-reviewed and may not be considered formal publications. The reviewer expresses skepticism about the significance of the results presented in the paper due to this issue. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to improve the paper. The feedback is somewhat actionable as it identifies a problem but lacks concrete steps for the authors to take, leaving them to infer the necessary actions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of statistical distribution on paper venues, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the inclusion of Arxiv papers in the study and expressing concerns about their significance. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks statistical distribution on paper venues, specifically the number of papers from ACL and EMNLP versus those from Arxiv. The reviewer also expresses skepticism about the significance of the results presented in the paper due to the inclusion of Arxiv papers, which are not peer-reviewed and considered less formal. The comment provides a logical reasoning for the skepticism, based on the general understanding that Arxiv papers are not considered as formal publications. However, it lacks specific examples or references to support the claim about the quality of Arxiv papers. This makes the claim somewhat verifiable, as it provides a reasonable basis but could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper regarding the lack of statistical distribution on paper venues, specifically the number of papers from ACL and EMNLP versus those from Arxiv. It raises concerns about the inclusion of Arxiv papers in the study, noting that they are not peer-reviewed and may not be considered formal publications. The reviewer expresses skepticism about the significance of the results presented in the paper due to this issue and questions the credibility of the findings. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this concern or improve the paper. The feedback is somewhat helpful as it points out a significant problem but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on the proposed problem and framework, rather than spending too much space on applications. While the comment implies that the authors should prioritize the former, it does not provide specific guidance on how to achieve this balance or what aspects of the applications should be reduced. The action is implicit and somewhat vague, as the authors need to infer that they should focus more on the problem and framework. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should focus more on the proposed problem and framework, rather than spending too much space on applications. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its suggestion to prioritize the problem and framework over applications, but without clear references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should focus more on the proposed problem and framework, rather than spending too much space on applications. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this focus is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should focus more on the proposed problem and framework, rather than spending too much space on applications. While it identifies a potential imbalance in the paper, it lacks specific guidance or suggestions on how to achieve this focus or what aspects of the applications should be reduced. The feedback is somewhat helpful as it points out an area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper is \"marginally above acceptance threshold\" and acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There are no suggestions for further revisions, clarifications, or additional analyses that could be conducted to strengthen the paper. As a result, the authors are left without any guidance on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the paper is \"marginally above acceptance threshold,\" which suggests that it is close to being accepted but not quite there. However, it does not specify which part of the paper is being addressed, such as the introduction, methodology, results, or discussion sections. Additionally, it does not provide any details on what aspects of the paper are considered above the acceptance threshold or how the authors have addressed the limitations and potential negative societal impact of their work. Without specific references or detailed feedback, the authors cannot effectively identify the areas that need improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is \"marginally above acceptance threshold\" and acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment does not provide any specific details or evidence to support these claims. It lacks specific examples or references to substantiate the claim about the acceptance threshold or the authors\\' handling of limitations and societal impact. As a result, the claim is not verifiable, making it difficult for the authors to understand and address the feedback. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper is \"marginally above acceptance threshold\" and notes that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not provide any specific feedback or suggestions for improvement. Without actionable guidance or detailed insights into what aspects of the paper could be strengthened or revised, the authors are left without a clear path forward. The comment lacks depth and specificity, making it barely helpful for the authors in enhancing their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the current dataset is simple and could be solved by an agent translating natural language into <source, path, destination> triples, followed by using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve their draft. The action is implied but not clearly stated, leaving the authors to infer that they need to consider the potential impact of using simpler datasets and explore alternative methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the current dataset is simple and could be solved by an agent translating natural language into <source, path, destination> triples, followed by using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the paper may have limited research impact due to the simplicity of the dataset and the potential use of simpler methods like PAL or LLMs with code interpreters. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the current dataset is simple and could be solved by an agent translating natural language into <source, path, destination> triples, followed by using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. However, the comment lacks specific examples or references to support the claim that the dataset is simple or that the suggested methods would be effective. The reasoning is based on logical reasoning and common knowledge, but it does not provide detailed evidence or references to substantiate the claim. Therefore, the comment is considered somewhat verifiable, as it provides a logical argument but lacks the necessary evidence to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the current dataset is simple and could be solved by an agent translating natural language into <source, path, destination> triples, followed by using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. While the comment identifies a potential limitation of the dataset, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their research. The feedback lacks actionable advice or detailed insights into how the authors might enhance their work, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors might need to revise a statement about the maximum likelihood estimation, specifically questioning the limitations of the proposed measure and its theoretical connection to generalization. The reviewer points out that the measure does not provide a stronger theoretical connection or experimental outperformance compared to competing measures. While the comment identifies areas for potential revision, it does not provide explicit guidance on how to revise the statement or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the necessary revisions themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"25: masures 242,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the statement about maximum likelihood estimation lacks a discussion of its limitations and theoretical connection to generalization. The reviewer provides specific examples of what needs to be addressed, such as the lack of a stronger theoretical connection and experimental outperformance compared to competing measures. This level of detail provides clear guidance on what needs to be revised, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement about maximum likelihood estimation lacks a discussion of its limitations and theoretical connection to generalization. The reviewer supports this claim by referencing the presentation, which allegedly does not provide a stronger theoretical connection or experimental outperformance compared to competing measures. However, the comment does not provide specific examples or references to substantiate these claims, making it somewhat verifiable. The authors would need to infer the exact issues and potential solutions from the comment, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the statement about maximum likelihood estimation, noting that it lacks a discussion of its limitations and theoretical connection to generalization. It also points out that the presentation does not provide a stronger theoretical connection or experimental outperformance compared to competing measures. This feedback is clear and actionable, as it directs the authors to address these concerns by revising the statement or providing additional context to strengthen the discussion. However, the comment could be more helpful if it offered suggestions on how to improve the discussion or provided examples of alternative approaches. Overall, the comment is mostly helpful as it effectively highlights a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of results for fine-tuned open-source LLMs, which is considered important for a domain-specific benchmark. However, it does not provide explicit guidance on what specific results should be included or how to address this gap. The authors are left to infer that they need to include these results, but without concrete instructions or examples, the action remains vague. Therefore, this comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of results for fine-tuned open-source LLMs, which is important for a domain-specific benchmark. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where these results should be included. Without explicit references, the authors cannot confidently determine the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what kind of results are missing or how they would enhance the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the lack of results for fine-tuned open-source LLMs is important for a domain-specific benchmark. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this omission and how it affects the paper\\'s contribution. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of results for fine-tuned open-source LLMs, which is considered important for a domain-specific benchmark. This feedback highlights a critical area for improvement, as the inclusion of these results could enhance the paper\\'s contribution and credibility. However, the comment lacks specific guidance on how to address this gap, such as suggesting which open-source LLMs should be considered or how to present the results effectively. While it points out an important issue, the lack of detailed instructions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the regression model, including how it is trained, what the input and output are, and how the parameter space differs between models with different feature sizes. It also questions whether the model performance is affected by the number of parameters. While these questions imply that the authors should provide more detailed information about the model, they do not explicitly instruct the authors to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more information about the model. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the regression model, specifically asking about the input and output, how the parameter space differs between models with different feature sizes, and whether the model performance is affected by the number of parameters. However, it does not specify which part of the paper these questions pertain to, such as a specific section or figure where these details are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its inquiry about the regression model. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions about the regression model, specifically asking for clarification on how it is trained, what the input and output are, and how the parameter space differs between models with different feature sizes. The reviewer also questions whether the model performance is affected by the number of parameters. These questions are factual and seek clarification, rather than making subjective claims or suggestions. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several pertinent questions about the regression model, including how it is trained, what the input and output are, and how the parameter space differs between models with different feature sizes. It also questions whether the model performance is affected by the number of parameters. These questions are clear and actionable, as they prompt the authors to provide more detailed information about the model and its performance. However, the comment could be more helpful if it offered suggestions on how to address these questions or what specific aspects to focus on. Overall, the comment is mostly helpful as it guides the authors to provide more comprehensive information about the regression model, but it could be more detailed in its guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g, which is an operator between a scalar and a tensor, rather than just between two scalars. This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq 6 and related equations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the operator after w_i, suggesting that it should be the multiplication of the underlying vector space rather than \\cross_g. This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g, which is an operator between a scalar and a tensor. The reviewer provides a logical reasoning by explaining the distinction between these two operators, suggesting that the current operator is incorrect. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the issue, but the reasoning is sound. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the equations, specifically equation 6 and related equations, suggesting that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g. This is a clear and actionable suggestion that can help the authors improve the accuracy and clarity of their equations. However, the comment could be more helpful if it provided additional context or explanation for why this correction is necessary or how it affects the overall understanding of the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, which can enhance the clarity and correctness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add more ablation experiments to demonstrate the effectiveness of their proposed model. It specifies two potential areas for exploration: the role of different updating methods in decoupling the selecting and weighting outputs and the role of reweighting after selection. While the comment provides clear guidance on what additional experiments should be conducted, it does not offer specific instructions on how to implement these experiments or what specific aspects to focus on. The action is concrete, as it identifies specific areas for improvement, but it lacks detailed guidance on execution. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods in decoupling the selecting and weighting outputs and the role of reweighting after selection. However, it does not specify which part of the paper these experiments should be added to, making it weakly grounded. The comment is specific in detailing what additional experiments should be conducted, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should add more ablation experiments to demonstrate the effectiveness of their proposed model. The comment provides a specific suggestion for additional experiments, such as the role of different updating methods in decoupling the selecting and weighting outputs and the role of reweighting after selection. However, the comment lacks detailed justification or evidence to support why these additional experiments are necessary or how they would enhance the paper. The suggestion is somewhat verifiable, as it provides a direction for improvement but lacks the depth and specificity needed to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should conduct additional ablation experiments to demonstrate the effectiveness of their proposed model. It identifies two potential areas for exploration: the role of different updating methods in decoupling the selecting and weighting outputs and the role of reweighting after selection. This feedback is clear and offers concrete suggestions for improving the draft, guiding the authors on how to enhance the experimental evaluation and substantiate the claims made in the paper. However, the comment could be more helpful if it provided additional context or examples of how these experiments could be conducted or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers valuable guidance for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental results could be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also mentions specific works by Phan et al. (2017; 2019; 2020) and other related works as potential baseline approaches for comparison. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these changes or which datasets to use. The authors are given a general idea of what needs to be done but are not provided with detailed steps or examples. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete instructions on how to achieve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the datasets used in the experiments, such as \"dim=24 in power consumption, dim=6 in real estate valuation, and dim=30 in breast cancer detection,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks, and suggests considering Phan et al. (2017; 2019; 2020) and other related works as baseline approaches for comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental results could be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. The reviewer provides a specific example of Phan et al. (2017; 2019; 2020) and other related works as potential baseline approaches for comparison. This provides a logical basis for the claim, as it suggests that the current experiments may not fully capture the complexity of the learning tasks. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experimental results by suggesting that the datasets used in the experiments are limited in their dimensions. It proposes using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks, to enhance the robustness of the results. The comment also provides specific examples of works by Phan et al. (2017; 2019; 2020) and other related works as potential baseline approaches for comparison. This feedback is clear and actionable, as it guides the authors on how to improve the experimental design and enhance the robustness of their results. However, it could be more helpful if it included detailed guidance on how to implement these changes or which specific datasets to consider. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be expanded to be fully comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the experimental results, specifically questioning the effectiveness of PRESENCE. It points out that the relationship between temperature $\\\\tau$ and downstream performance in Figure 5 does not justify the two-stage pre-training and suggests that using a positive or negative $\\\\tau$ could yield improvement over no reweighting. Additionally, the reviewer questions the importance of reweighting using a positive or negative $\\\\tau$ based on the results from Table 4. While the comment identifies areas of concern, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they should reconsider the effectiveness of PRESENCE and the role of reweighting. Therefore, the comment is somewhat actionable, as it implies a need for further exploration but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the relationship between temperature $\\\\tau$ and downstream performance, suggesting that using a positive or negative $\\\\tau$ could yield improvement over no reweighting. Additionally, it questions the advantage of using PRESENCE in cross-lingual zero-shot transfer. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the experimental results, specifically questioning the effectiveness of PRESENCE. It suggests that the relationship between temperature $\\\\tau$ and downstream performance in Figure 5 does not justify the two-stage pre-training and that using a positive or negative $\\\\tau$ could yield improvement over no reweighting. The reviewer also questions the advantage of using PRESENCE in cross-lingual zero-shot transfer, as shown in Table 4. While the comment identifies potential issues, it lacks specific examples or detailed reasoning to fully substantiate the claims. The authors would need to further explore the data and results to fully understand and address the concerns. Therefore, the comment is somewhat verifiable, as it provides a starting point for investigation but requires more detailed evidence or explanation to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the experimental results, questioning the effectiveness of PRESENCE and the relationship between temperature $\\\\tau$ and downstream performance. It suggests that using a positive or negative $\\\\tau$ could yield improvement over no reweighting, which is a relevant point for the authors to consider. Additionally, the comment questions the advantage of using PRESENCE in cross-lingual zero-shot transfer, as shown in Table 4. This feedback is somewhat helpful as it highlights areas where the authors could improve their experimental design and analysis. However, it could be more helpful if it provided more detailed guidance on how to address these issues or suggested specific experiments to conduct. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with Table 2, noting that the results for k=1 are already better than the baselines, suggesting that the performance gain might be due to a reason different from applying Eq.10. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to investigate the cause of the performance gain. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the results for k=1, suggesting that the performance gain might be due to a reason different from applying Eq.10. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for k=1 in Table 2 are already better than the baselines, suggesting that the performance gain might be due to a reason different from applying Eq.10. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 2, noting that the results for k=1 are already better than the baselines, suggesting that the performance gain might be due to a reason different from applying Eq.10. This observation is valuable as it points out a potential area for further investigation or explanation in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or explore alternative explanations. While it highlights an important observation, it could be more helpful if it offered actionable advice or detailed analysis. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method lacks solid grounding, specifically mentioning the choice of mixed-integer programming and its advantages over alternative approaches. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to justify the choice of mixed-integer programming or how to demonstrate its advantages over alternative approaches. Without actionable steps or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed method for lacking solid grounding, specifically mentioning the choice of mixed-integer programming and its unclear advantages over alternative approaches. However, it does not specify which part of the paper discusses these aspects, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specificity in identifying the issue, it lacks full grounding as it does not explicitly mention the sections or elements of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks solid grounding, specifically mentioning the choice of mixed-integer programming and its unclear advantages over alternative approaches. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without detailed justification or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, specifically noting that the choice of mixed-integer programming is not fully justified and its advantages over alternative approaches are unclear. This feedback highlights a critical area for improvement in the paper, as the authors need to provide a more robust justification for their method and demonstrate its advantages over other approaches. However, the comment does not offer specific suggestions or guidance on how to address these issues, such as recommending additional experiments or analyses. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the confusing notation in Equation 1 and the missing reference to Pedersen et al 2007 in the reference section. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should clarify the notation and add the missing reference, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1\" and \"Line 361,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the notation in Equation 1 and the missing reference to Pedersen et al 2007 in the reference section. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation in Equation 1 is confusing due to the use of \"c\" instead of \"o.\" However, it does not provide any reasoning or explanation as to why this is confusing or how it affects the clarity of the paper. Additionally, the comment mentions the missing reference to Pedersen et al 2007 in the reference section, but it does not explain why this reference is important or how it relates to the paper. These elements lack sufficient justification or evidence to support the claim, making it difficult for the authors to understand and address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues: the confusing notation in Equation 1 and the missing reference to Pedersen et al 2007 in the reference section. By pointing out these discrepancies, the comment provides actionable feedback that can help the authors improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to clarify the notation or provided guidance on how to include the missing reference. Overall, the feedback is somewhat helpful as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the proposed combination of SSMs with Attention is not new and has been previously proposed in MEGA and Block-state Transformer. It also notes that the architecture in Figure 5 looks similar to the proposed architecture in Mega. The reviewer suggests that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. This feedback provides a clear and specific action for the authors to take, which is to discuss and compare their work with existing literature. The explicit nature of the suggestion and the concrete details on what needs to be addressed make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"second contribution of the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed combination of SSMs with Attention is not new and has been previously proposed in MEGA and Block-state Transformer. The comment further details the similarities and differences between S++ and the existing work, suggesting that these should be discussed thoroughly and ablated. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed combination of SSMs with Attention is not new and has been previously proposed in MEGA and Block-state Transformer. The reviewer supports this claim by referencing the works cited in the results section but not discussed, which provides some evidence that the combination has been explored before. However, the comment could be strengthened by providing specific examples or detailed comparisons between the proposed work and the existing literature. While the reference to external works helps substantiate the claim, the comment could be more fully verifiable with additional details or comparisons. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s second contribution, which is the proposal to combine SSMs with Attention. The reviewer points out that this combination is not new and has been previously proposed in MEGA and Block-state Transformer, as evidenced by references to these works. Additionally, the comment notes that the architecture in Figure 5 looks very similar to the proposed architecture in Mega, suggesting that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. This feedback is clear and actionable, as it directs the authors to address the novelty and comparability of their work with existing literature. By providing specific guidance on what needs to be discussed and improved, the comment offers valuable insight for the authors to enhance the clarity and originality of their contribution. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the specific reason for reporting results on knowledge transfer only in a few select environments. While it does not explicitly instruct the authors to provide a specific reason, it implies that the authors should address this issue by providing a rationale for their choice of environments. The action is implicit but concrete, as the authors can infer that they need to provide a justification for their selection. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reason for reporting results on knowledge transfer only in a few select environments. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about the specific reason for reporting results on knowledge transfer only in a few select environments. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the specific reason for reporting results on knowledge transfer only in a few select environments. This is a relevant point that could help the authors clarify their methodology and provide a more comprehensive understanding of their results. However, the comment does not offer any suggestions or guidance on how to address this issue or what specific information should be included in the explanation. While it points out a potential area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of specific ablation experiments and suggests that the performance improvement might be due to the pre-trained weights rather than the method proposed in the manuscript. It points out the absence of detailed ablation comparisons, which could lead to confusion. While the comment identifies an area for improvement, it does not provide explicit guidance on how to conduct these ablation experiments or what specific comparisons should be included. The authors are left to infer the necessary actions, such as conducting additional experiments or providing detailed comparisons. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of specific ablation experiments and suggests that the performance improvement might be due to pre-trained weights rather than the method proposed in the manuscript. It also points out the absence of detailed ablation comparisons, which could lead to confusion. However, the comment does not specify which part of the paper lacks these experiments or comparisons, making it weakly grounded. The comment is specific in detailing what is missing and why it is important, but without explicit references to sections or figures, the authors cannot confidently determine where to address these issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance improvement might be due to pre-trained weights rather than the method proposed in the manuscript. It suggests that the absence of detailed ablation comparisons could lead to confusion. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without concrete evidence or detailed reasoning, the claim is not fully verifiable, making it challenging for the authors to understand and respond to the feedback. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of specific ablation experiments and detailed comparisons. It suggests that the performance improvement might be attributed to pre-trained weights rather than the method proposed in the manuscript, which could lead to confusion. This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, the comment could be more helpful if it provided specific suggestions on how to conduct these ablation experiments or what comparisons should be included. Overall, the comment is mostly helpful as it highlights a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the lemmatizer that removes suffixes from words that are already lemmas but end with a suffix substring. This is identified as a major concern for real-world texts with evolving vocabularies. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. It lacks actionable details, such as recommending specific changes or experiments to mitigate this issue. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation in the lemmatizer, which removes suffixes from words that are already lemmas but end with a suffix substring. This is a concern for real-world texts with evolving vocabularies. However, the comment does not specify which part of the paper discusses this limitation, making it weakly grounded. It is specific in detailing the concern but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lemmatizer's limitation, where it removes suffixes from words that are already lemmas but end with a suffix substring, is a major concern for real-world texts with evolving vocabularies. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the lemmatizer, which removes suffixes from words that are already lemmas but end with a suffix substring. This is a concern for real-world texts with evolving vocabularies. However, the comment does not provide any actionable feedback or suggestions on how the authors might address this issue or improve their draft. It lacks depth and does not guide the authors on potential solutions or experiments to explore. As a result, the comment is somewhat helpful, as it points out a potential problem but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison of semantic segmentation metrics in Table 2 is not meaningful because it only shows that the segmentation of methods + DGCNN is worse than the proposed method. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to improve the comparison. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison of semantic segmentation metrics, noting that the comparison is not meaningful due to the use of pre-trained DGCNN. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison of semantic segmentation metrics in Table 2 is not meaningful because it only shows that the segmentation of methods + DGCNN is worse than the proposed method. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison of semantic segmentation metrics in Table 2, noting that the use of pre-trained DGCNN for each completion method makes the comparison uninformative. It points out that the comparison only shows that the segmentation of methods + DGCNN is worse than the proposed method, rather than providing meaningful insights into the performance of the different methods. While the comment highlights a potential weakness in the paper, it does not offer specific suggestions or guidance on how the authors might address this issue or improve the comparison. This limits the comment\\'s helpfulness, as it provides some insight but lacks actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the difficulty in obtaining rules in real-world applications and suggests that statistical rules learned from data may be feasible. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of obtaining rules or how to improve the feasibility of statistical rules learned from data. As a result, the authors are left without any clear direction on how to apply this feedback to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the difficulty in obtaining rules in real-world applications and suggests that statistical rules learned from data may be feasible. However, it does not specify which part of the paper this issue is discussed in, nor does it provide any details on what specific aspects of the rules or statistical rules need attention. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges the difficulty in obtaining rules in real-world applications and suggests that statistical rules learned from data may be feasible. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this suggestion or how to apply it to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the difficulty in obtaining rules in real-world applications and suggests that statistical rules learned from data may be feasible. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without guidance on how to address the issue or what aspects of the paper need attention, the authors are left without a clear path forward. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison with dynamic sparse training-based and other sparsity-based methods. While the action is explicit, it is somewhat vague as it does not specify which specific methods should be compared or how to conduct the comparison. The authors are given a clear direction to include a comparison but are left to determine the details of execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting the inclusion of a comparison, but without explicit references to sections or specific methods, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by suggesting that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. This feedback is somewhat helpful as it points out an area where the paper could be expanded to provide a more comprehensive analysis. However, the comment lacks specific guidance on how to conduct this comparison or which methods should be included, making it somewhat helpful but not fully actionable. The authors are given a direction to consider but are left to determine the specifics of implementation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the assertion that the intractability of $p_\\\\theta(y|x)$ in a latent variable model is due to the intractability of $p_\\\\theta(z|x)$, suggesting that this may not be the only reason. It points out that both the posterior and the likelihood can be tractable, while $p_\\\\theta(y|x)$ may still be intractable. The reviewer does not provide specific guidance on how the authors should address this issue or what alternative explanation might be considered. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence \"The intractability of $p_\\\\theta(y|x)$ in a latent variable model is due to the intractability of $p_\\\\theta(z|x)$, since $p_\\\\theta(y|x, z)$ is tractable.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it challenges the assertion that the intractability of $p_\\\\theta(y|x)$ is solely due to the intractability of $p_\\\\theta(z|x)$, suggesting that other factors could be at play. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the assertion that the intractability of $p_\\\\theta(y|x)$ in a latent variable model is due to the intractability of $p_\\\\theta(z|x)$. The reviewer provides a logical reasoning by suggesting that both the posterior and the likelihood can be tractable, while $p_\\\\theta(y|x)$ may still be intractable. This reasoning is based on the idea that a Bernoulli likelihood with a Gaussian posterior could lead to tractable $p_\\\\theta(y|x)$. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors might find it challenging to fully understand and address the critique without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critical analysis of the paper\\'s assertion that the intractability of $p_\\\\theta(y|x)$ in a latent variable model is due to the intractability of $p_\\\\theta(z|x)$. The reviewer challenges this assertion by suggesting that the intractability of $p_\\\\theta(y|x)$ could be due to factors other than the intractability of $p_\\\\theta(z|x)$. This feedback is valuable as it prompts the authors to reconsider their reasoning and potentially explore alternative explanations for the intractability of $p_\\\\theta(y|x)$. However, the comment could be more helpful if it provided specific examples or references to support the alternative explanation or suggested ways to address the critique. Overall, the comment is somewhat helpful as it encourages the authors to reconsider their argument but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the reproducibility of the work due to the inaccessibility of the collected datasets outside of the associated groups. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the datasets more accessible or how to ensure their reproducibility. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the reproducibility of the work due to the inaccessibility of the collected datasets outside of the associated groups. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the datasets\\' accessibility are problematic or how they could be made more accessible. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is irreproducible due to the inaccessibility of the collected datasets outside of the associated groups. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the reproducibility of the work due to the inaccessibility of the collected datasets outside of the associated groups. This is a critical concern that could impact the credibility and impact of the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending ways to make the datasets more accessible or discussing potential solutions. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether there is a missing equation before \"where p is the firing rate\" in section 3.4.1. While it implies that the authors should check their manuscript for this missing equation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should verify their manuscript for this specific issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sec 3.4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about whether there is a missing equation before \"where p is the firing rate.\" This provides clear guidance on what needs to be addressed in the manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking whether there is a missing equation before \"where p is the firing rate\" in section 3.4.1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about a missing equation in section 3.4.1, which could be an oversight or a formatting issue. While it identifies a potential problem, it does not provide any guidance or suggestions on how to address this issue or improve the manuscript. The comment is somewhat helpful as it points out a specific area that needs attention, but it lacks actionable advice or context for the authors to improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the evaluation of sentiment word detection and correction is missing, which is a clear and direct action for the authors to take. It also provides a rationale for why this evaluation is necessary, as it relates to the key ideas of SWRM, which are the detection and correction of possible sentiment word errors. The comment is specific in identifying the need for experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This level of detail makes the action explicit and concrete, ensuring that the authors know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"detection of sentiment word errors\" and the \"key ideas of SWRM,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of sentiment word detection and correction, and why it is important for the validation of the model. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of sentiment word detection and correction is missing, which is a subjective claim based on the reviewer\\'s interpretation of the paper\\'s focus on sentiment word errors. The comment provides a logical reasoning by stating that the detection and correction of sentiment word errors are key ideas in SWRM, which supports the claim. However, the comment lacks specific examples or references to substantiate the claim further, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the claim, but the reasoning provided is sound. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation of sentiment word detection and correction, which is a crucial aspect of the SWRM model. It provides a clear and actionable suggestion for the authors to conduct experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This feedback is valuable as it directs the authors to a specific area that needs attention and improvement, ensuring that the model\\'s key features are adequately tested and evaluated. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific metrics or analyses should be considered. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on the results of KMLM-XLM-R_{large} (ours) in all the result tables, noting that the authors have not reported all the performance of KMLM-large without logical reasoning. This is a clear and direct request for additional information, providing the authors with a specific action to take. The comment is explicit and concrete, as it specifies exactly what needs to be added to the tables and why. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"all the result tables,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the results of KMLM-XLM-R_{large} (ours) and the lack of reporting all the performance of KMLM-large without logical reasoning. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the absence of results for KMLM-XLM-R_{large} (ours) in the result tables and notes that the authors have not reported all the performance of KMLM-large without logical reasoning. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in the paper, noting the absence of results for KMLM-XLM-R_{large} (ours) in the result tables. It also points out that the authors have not reported all the performance of KMLM-large without logical reasoning. This feedback is clear and actionable, as it directs the authors to include the missing results and provide a logical explanation for their absence. By addressing this issue, the authors can improve the clarity and completeness of their results section. However, the comment could be more helpful if it provided additional guidance on how to present these results or what specific aspects should be highlighted. Overall, the comment is mostly helpful as it effectively points out a gap in the paper that the authors can address to enhance its clarity and comprehensiveness.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the results of the in-context learning baselines, specifically noting that they underperform the backbone in many items. It suggests that this may be due to large variance or uncareful design of the baselines. The reviewer implies that more explanations are needed to support the reliability of the claims. However, the comment does not provide specific guidance on how to address this issue or what additional explanations are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"mysterious results\" and \"in-context learning baselines,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that many baselines underperform the backbone and suggests that this may be due to large variance or uncareful design. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results of in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone in many items. The reviewer suggests that this may be due to large variance or uncareful design of the baselines. However, the comment lacks specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the results of the in-context learning baselines, noting that many underperform the backbone in many items. It suggests that this may be due to large variance or uncareful design of the baselines. The comment highlights the need for more explanations to support the reliability of the claims. While it points out a critical area for improvement, it does not provide specific suggestions or guidance on how to address the issue or what additional explanations are needed. This limits the comment\\'s helpfulness, as it provides insight but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the lack of clarity regarding the key innovation driving the claims about GFNSeqEditor\\'s ability to produce novel sequences with improved properties. It suggests that the paper should better articulate what novel techniques or insights lead to these improvements, thereby enhancing the reader\\'s understanding of the method\\'s unique value. This feedback provides a clear and concrete action for the authors to take, which is to clarify the key innovation and its impact on the method. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Key Innovation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the key innovation driving the claims about GFNSeqEditor\\'s ability to produce novel sequences with improved properties. The comment suggests that the paper should better articulate the novel techniques or insights leading to these improvements, thereby enhancing the reader\\'s understanding of the method\\'s unique value. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding the key innovation driving the claims about GFNSeqEditor\\'s ability to produce novel sequences with improved properties. The reviewer suggests that the paper should better articulate what novel techniques or insights lead to these improvements, thereby enhancing the reader\\'s understanding of the method\\'s unique value. This claim is somewhat verifiable as it logically points out a potential gap in the paper\\'s explanation, but it lacks specific examples or references to support the assertion that the innovation is unclear. The authors would need to further develop the rationale to fully substantiate the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of ambiguity in the paper regarding the key innovation driving the claims about GFNSeqEditor\\'s ability to produce novel sequences with improved properties. It suggests that the paper should better articulate what novel techniques or insights lead to these improvements, thereby enhancing the reader\\'s understanding of the method\\'s unique value. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve the clarity and comprehensibility of their claims. By addressing this issue, the authors can significantly enhance the reader\\'s understanding of the method and its contributions. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment. This explicit request provides a clear and concrete action for the authors to take, as it specifies the need for an experiment to substantiate their claim. The comment is specific in detailing what needs to be demonstrated, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors need to demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for an experiment to demonstrate the faithfulness, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment. However, the comment does not provide any specific reasoning or evidence to support why this claim is necessary or how it would address the issue of bias. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to address the claim that their method is less susceptible to biases than other methods. However, the comment could be more helpful if it offered additional guidance on what kind of experiment would be appropriate or how to design it. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is limited to operating with discrete state-action spaces, which is not ideal for real-world applications that are continuous in nature. It suggests that the sentence about motivation is not the best choice, but it does not provide explicit guidance on how to improve the motivation or suggest alternative phrasing. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the motivation section, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sentence about motivation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the limitation of the proposed method to discrete state-action spaces and the need for a better motivation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is limited to operating with discrete state-action spaces, which is not ideal for real-world applications that are continuous in nature. The reviewer supports this claim by pointing out that most real-world applications are continuous in nature and difficult to discretize or solve with discrete state-action spaces. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed method, noting that it is limited to operating with discrete state-action spaces, which is not ideal for real-world applications that are continuous in nature. It suggests that the sentence about motivation is not the best choice, as it does not effectively convey the relevance of the proposed method to continuous applications. While the comment highlights an important issue, it lacks specific suggestions or guidance on how to address this limitation or improve the motivation section. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that the experiment results are not competitive with SOTA methods and that the presentation of the main results table is unclear. The reviewer recommends moving the baseline to the ablation study and only showing the proposed method. This feedback is clear and specific, giving the authors a direct path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experiment results\" and \"main result Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the results, such as the lack of competitiveness compared to SOTA methods and the unclear presentation of the main results table. The comment also suggests moving the baseline to the ablation study and only showing the proposed method, providing clear guidance on how to improve the presentation of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment results are not competitive with SOTA methods and that the presentation of the main results table is unclear. It suggests that the baseline should be moved to the ablation study and only show the proposed method. While the comment provides some reasoning by mentioning the lack of competitiveness and the unclear presentation, it lacks specific examples or references to support the claim that the results are not competitive. Additionally, it does not provide detailed guidance on how to improve the presentation or what specific aspects of the results are unclear. Therefore, the claim is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental results, noting that they are not competitive with SOTA methods and mostly show minor improvements. It also points out that the presentation of the main results table is unclear, with different backbones compared to prior methods. The reviewer provides actionable feedback by suggesting that the baseline should be moved to the ablation study and that only the proposed method should be shown. This feedback is clear and constructive, offering specific guidance on how to improve the presentation and competitiveness of the results. By addressing these points, the authors can significantly enhance the clarity and impact of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the manuscript would benefit from a clearer delineation of the copyright scenario, specifically by specifying whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. While the comment implies that the authors should clarify this distinction, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the copyright scenario. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically by specifying whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. However, it does not specify which part of the manuscript this delineation should be included in, making it weakly grounded. The comment is specific in suggesting a clear distinction between the interests of the model owner and end-users, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically by specifying whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this clarification is necessary or how it would improve the manuscript. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the manuscript, suggesting that the copyright scenario should be clarified to specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity and comprehensiveness of their manuscript. However, the comment could be more helpful if it offered additional guidance on how to achieve this clarification or provided examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful as it effectively points out a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of theoretical justification or intuitive explanation for why the low-rank adapter acquires domain-agnostic information, while the high-rank adapter collects domain-specific knowledge. However, it does not provide any guidance on how the authors should address this issue or what specific theoretical or intuitive explanations should be included. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the theoretical justification or intuitive explanation for why the low-rank adapter acquires domain-agnostic information, while the high-rank adapter collects domain-specific knowledge. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the difference in behavior between the two adapters and what is expected from them. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the low-rank adapter acquires domain-agnostic information, while the high-rank adapter collects domain-specific knowledge. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the theoretical justification or intuitive explanation for the behavior of the low-rank adapter and the high-rank adapter. It points out that the low-rank adapter acquires domain-agnostic information, while the high-rank adapter collects domain-specific knowledge, which is not explained in the paper. This feedback highlights an important area for clarification and improvement, as it could help the authors better articulate the rationale behind their methodology. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional theoretical or experimental justifications. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the statement in line 154 regarding local explanations, specifically questioning why the data point x must be in the vicinity of a decision boundary for the local models to be nontrivial. The reviewer asks why differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y,\" cannot be measured. While the comment implies that the authors should provide a rationale for this statement, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification or explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the statement about local explanations and asks for clarification on why differences in probabilities cannot be measured. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement in line 154 regarding local explanations, specifically questioning why the data point x must be in the vicinity of a decision boundary for the local models to be nontrivial. The reviewer seeks clarification on why differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y,\" cannot be measured. This question is based on logical reasoning and common knowledge about how local models work, but it lacks specific examples or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the question but requires more detailed justification to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the statement in line 154 regarding local explanations, specifically questioning why the data point x must be in the vicinity of a decision boundary for the local models to be nontrivial. The reviewer seeks clarification on why differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y,\" cannot be measured. This feedback is somewhat helpful as it prompts the authors to clarify their reasoning or provide additional explanation for the statement. However, it lacks specific suggestions or guidance on how to address the issue, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only report results on ImageNet and do not include results on classic datasets like CIFAR-10 and CIFAR-100. This implies that the authors should include results on these additional datasets to provide a more comprehensive evaluation. However, the comment does not explicitly instruct the authors to include these results or specify how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include results on additional datasets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments and the specific datasets (ImageNet, CIFAR-10, and CIFAR-100) that are not included in the results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing\u2014the inclusion of results on classic datasets\u2014and why it is important for a more comprehensive evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments only report results on ImageNet and do not include results on classic datasets like CIFAR-10 and CIFAR-100. This claim is somewhat verifiable as it highlights a potential limitation in the experimental setup, but it lacks specific reasoning or evidence to support why these additional datasets are necessary or how their inclusion would impact the results. The comment could be strengthened by providing examples of how these datasets might be relevant or how their inclusion could enhance the study\\'s conclusions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental setup, noting that the experiments only report results on ImageNet and do not include results on classic datasets like CIFAR-10 and CIFAR-100. This feedback is valuable as it highlights an area where the authors could enhance the comprehensiveness and generalizability of their results. By including results on additional datasets, the authors can demonstrate the robustness and applicability of their method across different benchmarks. However, the comment could be more helpful if it provided suggestions on how to incorporate these additional datasets or why they are important for the study. Overall, the comment is mostly helpful as it points out a clear area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the DinoSR part in Figure 1 is confusing because the softmax layer is not clearly shown, despite the text description indicating that the encoder does not include that layer. The reviewer suggests that the figure in the original DinoSR paper is clearer. While the comment identifies a specific issue with the figure, it does not provide explicit guidance on how to address it or improve the clarity. The authors are left to infer that they need to make the figure more clear, but the comment lacks concrete details on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the softmax layer is not clearly shown and suggesting that the figure in the original DinoSR paper is clearer. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the DinoSR part in Figure 1 is confusing because the softmax layer is not clearly shown, despite the text description indicating that the encoder does not include that layer. The reviewer compares the figure in the original DinoSR paper, which is described as clear, to the current figure. This claim is somewhat verifiable as it provides a logical reasoning for the confusion, but it lacks specific examples or references to the original DinoSR paper to fully substantiate the comparison. The authors would need to make a concerted effort to understand and address the issue, which is not as straightforward as it could be. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the DinoSR part in Figure 1, noting that the softmax layer is not clearly shown despite the text description indicating that the encoder does not include it. The reviewer compares the figure in the original DinoSR paper, which is described as clear, to the current figure. This feedback is valuable as it highlights a potential source of confusion for readers and suggests a way to improve the clarity of the figure. However, the comment could be more helpful if it provided specific suggestions on how to make the figure clearer or how to address the discrepancy between the text and the figure. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should review related work on causal inference, specifically mentioning three references ([1], [2], [3]). This explicit suggestion provides a clear and concrete action for the authors to take, as it directly identifies the need for additional literature review and specifies specific references to consider. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that related work on causal inference needs to be reviewed, specifically mentioning three references ([1], [2], [3]). However, it does not specify which part of the paper this review should be integrated into, such as the literature review or methodology sections. While the references are provided, the comment lacks full grounding as it does not clearly indicate where in the paper these references should be discussed. The specificity of the comment is high, as it clearly identifies the need for additional work on causal inference, but the lack of grounding makes it challenging for the authors to pinpoint the exact location for incorporating this feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that related work on causal inference needs to be reviewed, specifically mentioning three references ([1], [2], [3]). However, the comment does not provide any reasoning or explanation as to why these references are relevant or how they relate to the paper. Without additional context or justification, the claim lacks verifiability, as it does not provide sufficient evidence or rationale to support the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should review related work on causal inference, specifically mentioning three references ([1], [2], [3]). This feedback is somewhat helpful as it identifies a potential gap in the literature review and provides specific references for the authors to consider. However, the comment lacks depth and does not explain why these references are particularly relevant or how they could enhance the paper. Additionally, it does not offer suggestions on how to integrate this related work into the paper or what specific aspects of causal inference should be addressed. While the comment provides a starting point for the authors, it could be more helpful with additional guidance or rationale. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should use the LLM2Vec encoder, which is already cited in the paper, instead of sections 3.1 and 3.2. It also points out that the reasoning for not adopting this approach remains unclear and recommends conducting ablation studies to validate the decision. This feedback provides clear and concrete actions for the authors to take, specifying exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sections 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of the LLM2Vec encoder and the need for ablation studies to validate the decision not to use it. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that sections 3.1 and 3.2 could be avoided by using the LLM2Vec encoder, which is already cited in the paper. The reviewer suggests that the reasoning for not adopting this approach remains unclear and recommends conducting ablation studies to validate the decision. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors would need to conduct additional research to understand the implications of using the LLM2Vec encoder and validate the decision. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improvement by recommending the use of the LLM2Vec encoder, which is already cited in the paper. It points out that the reasoning for not adopting this approach remains unclear and suggests conducting ablation studies to validate the decision. This feedback is clear and offers a concrete step for the authors to take, making it highly helpful in guiding them toward a more robust and comprehensive analysis of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and do not include real-world problems. This implies that the authors should consider including real-world problems in their experiments to better evaluate the method. However, the comment does not provide specific guidance on how to incorporate real-world problems or which ones to use. The action is implicit and somewhat vague, as the authors need to infer the specifics of how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments comparing the proposed Batch BORE method with existing baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of using only synthetic objective functions and the lack of real-world problems in the experiments. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and do not include real-world problems. This claim is somewhat verifiable as it highlights a potential limitation in the experimental setup, but it lacks specific examples or references to real-world problems that could be used. The authors might need to infer the relevance of real-world problems and how they could be integrated into the experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and do not include real-world problems. This feedback highlights a potential limitation in the evaluation of the method, as real-world problems could provide a more comprehensive understanding of its performance. However, the comment does not offer suggestions on how to incorporate real-world problems or which ones to consider. While it points out an important area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a detailed analysis of benchmark sentence differences between explanation and listener-focused parts could clarify the findings regarding the challenges of distinguishing roles using explanation-focused cues. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a detailed analysis to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify the findings regarding the challenges of distinguishing roles using explanation-focused cues. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting a detailed analysis of benchmark sentence differences, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that distinguishing roles using explanation-focused cues is challenging due to LLMs relying more on language style than on informational depth. The comment suggests that a detailed analysis of benchmark sentence differences between explanation and listener-focused parts could clarify these findings. However, the comment lacks specific examples or references to support the claim that LLMs rely more on language style than on informational depth. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the challenges of distinguishing roles using explanation-focused cues. It suggests that the reliance of LLMs on language style rather than informational depth may be a contributing factor to this challenge. The comment provides a clear and actionable suggestion for further analysis, recommending a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. This feedback is valuable as it guides the authors to conduct a specific analysis that could enhance the understanding and clarity of their work. However, the comment could be more helpful if it included examples or references to similar studies that have explored this issue. Overall, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the use of acronyms in the paper, noting that the acronym \"DU\" is mentioned without a clear definition. This provides a clear and explicit action for the authors to take, which is to clarify the definition of the acronym \"DU.\" The comment is concrete because it specifies the exact issue and provides a direct action for the authors to address. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of acronyms, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the acronym \"DU\" being mentioned without a clear definition, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s use of acronyms affects readability, specifically mentioning the acronym \"DU\" without a clear definition. However, the comment does not provide any supporting evidence or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the heavy use of acronyms affects readability. It highlights the problem of an acronym being mentioned without a clear definition, which is a critical point for clarity in the paper. This feedback is clear and actionable, as it directs the authors to provide definitions for the acronyms used in the paper. By addressing this issue, the authors can improve the readability and accessibility of their work. Therefore, the comment is mostly helpful, as it provides a clear and constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the estimation of variance in the distribution p(q|s) and the determination of the complete covariance matrix. It suggests that the authors should clarify how they estimate the variance and whether they use a diagonal or complete covariance matrix. While the comment implies that the authors should provide more information or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they need to address these questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the estimation of variance in the distribution p(q|s) and the determination of the complete covariance matrix. The comment is specific because it asks for clarification on how the variance is estimated and whether a diagonal or complete covariance matrix is assumed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the estimation of variance and the determination of the covariance matrix in a specific section of the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the estimation of variance and the determination of the covariance matrix in a specific section of the paper. It seeks clarification on how the variance is estimated and whether a diagonal or complete covariance matrix is assumed. These questions are relevant and could help the authors improve the clarity and accuracy of their methodology. However, the comment could be more helpful if it provided suggestions on how to address these questions or offered additional context or examples to guide the authors in their response. Overall, the comment is somewhat helpful as it identifies a potential area for clarification and improvement, but it lacks depth and actionable guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific steps they should consider to improve the accuracy of their models. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the initial accuracy of the MIL-based baseline model compared to the converged models, particularly for the NSCLC dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. However, it does not provide any supporting evidence, reasoning, or references to justify why this observation is significant or how it affects the paper\\'s conclusions. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the initial accuracy of the MIL-based baseline model being higher than the converged models, particularly for the NSCLC dataset. This observation could be a significant finding that the authors should address or explain. However, the comment does not provide any guidance or suggestions on how the authors might investigate or explain this observation. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. While the action is implicit, it is clear that the authors need to expand their analysis to include additional datasets. However, the comment does not provide specific suggestions on which datasets to use or how to conduct the analysis, leaving some ambiguity. Therefore, the action is somewhat actionable, as it identifies a potential area for improvement but lacks concrete guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper primarily focuses on the MuAViC dataset and recommends considering other datasets to explore the generalization of the proposed method across diverse data sources. However, it does not specify which part of the paper discusses the MuAViC dataset or where the authors should consider other datasets. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides a clear suggestion for improvement, it lacks specificity in terms of grounding. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper primarily focuses on the MuAViC dataset and recommends considering other datasets to explore the generalization of the proposed method across diverse data sources. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would benefit the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it primarily focuses on the MuAViC dataset. It suggests that the authors should consider other datasets to explore the generalization of their proposed method across diverse data sources. This feedback is valuable as it encourages the authors to broaden their analysis and consider the applicability of their method in different contexts. However, the comment could be more helpful if it provided specific suggestions on which datasets to consider or how to conduct the analysis. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the expectation of systems not being Bayes-optimal on the problems investigated in the paper. It suggests that more work is needed to establish alternative hypotheses and gear the analyses and results towards ruling them out. The reviewer implies that the current analysis is mostly confirmatory and lacks exploration of alternative hypotheses. However, the comment does not provide explicit guidance on how to address these concerns or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors can infer that they need to expand their analyses and experiments to test alternative hypotheses, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the expectation of systems not being Bayes-optimal on the problems investigated in the paper, suggesting that more work is needed to establish alternative hypotheses and gear the analyses and results towards ruling them out. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the analysis being confirmatory and the need for alternative hypotheses and experiments to be explored. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the expectation of systems not being Bayes-optimal on the problems investigated in the paper. It suggests that more work is needed to establish alternative hypotheses and gear the analyses and results towards ruling them out. The reviewer provides a logical reasoning by pointing out that the current analysis is mostly confirmatory and lacks exploration of alternative hypotheses. However, the comment lacks specific examples or references to support the claim that the current analysis is confirmatory. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the expectation of systems not being Bayes-optimal on the relatively straightforward problems investigated. It suggests that more work is needed to establish alternative hypotheses and gear the analyses and results towards ruling them out. The reviewer points out that the current analysis is mostly confirmatory and lacks exploration of alternative hypotheses. This feedback is somewhat helpful as it highlights an area where the paper could be strengthened by providing more depth and analysis. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what alternative hypotheses should be considered. Overall, the comment provides some guidance but lacks detailed actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add confidence intervals to their results in Table 1, which provides performance data for different fairness improvement techniques. This is a clear and direct action for the authors to take, as it provides a specific way to enhance the clarity and usefulness of their results. The comment is specific in detailing what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reported values being very close, making it difficult to draw conclusions, and suggests adding confidence intervals to improve the clarity of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reported values in Table 1 are very close, making it difficult to draw conclusions. The reviewer suggests adding confidence intervals to improve the clarity of the results. This claim is somewhat verifiable as it logically points out a potential issue with the reported values, but it lacks specific examples or references to support the claim that the values are indeed very close. The suggestion to add confidence intervals is a reasonable one, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 1, noting that the reported values are very close, making it difficult to draw conclusions. It suggests a clear and actionable improvement by recommending the addition of confidence intervals to enhance the clarity and usefulness of the results. This feedback is valuable as it provides a concrete step for the authors to take in order to improve the presentation of their findings. However, the comment could be more helpful if it explained why confidence intervals are important or how they could be effectively incorporated into the table. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that certain choices are not justified or clear, but it does not specify which choices are in question. The reviewer suggests that the authors should address these issues by referring to the questions mentioned elsewhere. However, the comment lacks explicit guidance on which specific choices need clarification or justification, leaving the authors uncertain about what specific actions to take. The lack of concrete details makes it difficult for the authors to know exactly what changes are needed to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that certain choices are not justified or clear, but it does not specify which choices are being referred to. It mentions \"questions for the authors,\" which could imply that the questions are related to the paper, but this is not explicitly stated. Without explicit references to specific sections, figures, or elements of the paper, the authors cannot confidently determine which parts need attention. The comment is not specific about what needs to be addressed or clarified, making it weakly grounded. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that certain choices are not justified or clear. However, it does not provide any specific examples or reasoning to support this claim. Without detailed explanations or references, the authors may find it challenging to understand which choices are in question and how they could be improved. As a result, the comment lacks verifiability, making it difficult for the authors to address the issue effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that certain choices are not justified or clear, but it does not specify which choices are being referred to. It mentions \"questions for the authors,\" which could imply that the questions are related to the paper, but this is not explicitly stated. Without specific guidance or examples, the authors are left without actionable feedback on how to address the issue. The comment lacks depth and clarity, making it barely helpful as it does not provide the authors with a clear path to improvement. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about hyperparameter tuning, specifically regarding the use of two hyperparameters in the polarization regularizer and the difficulty in navigating the hyperparameter space for tuning. It suggests that there should be multiple solutions that achieve the same FLOPs, which makes the tuning process challenging. The reviewer also notes that the current presentation lacks detailed information on how the grid search is conducted, and requests more discussion on this issue for reproducibility. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the grid search process and discuss the hyperparameter tuning challenges. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of hyperparameter tuning and the use of two hyperparameters in the polarization regularizer. It also specifies the concern regarding the difficulty in navigating the hyperparameter space for tuning and the need for detailed discussions on the grid search process for reproducibility. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the difficulty in hyperparameter tuning due to the use of two hyperparameters in the polarization regularizer. It suggests that there should be multiple solutions that achieve the same FLOPs, making the tuning process challenging. The reviewer also questions the clarity of the grid search process and requests more detailed discussions for reproducibility. While the comment identifies a potential issue with the tuning process, it lacks specific examples or references to support the claim about the difficulty in navigating the hyperparameter space. The suggestion for more detailed discussions is logical but not fully substantiated by evidence or examples. Therefore, the claim is somewhat verifiable, as it provides a reasonable basis for the authors to address the issue but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the hyperparameter tuning process in the paper, noting that the use of two hyperparameters in the polarization regularizer makes it challenging to navigate the hyperparameter space for tuning. It suggests that there should be multiple solutions that achieve the same FLOPs, which could make the tuning process difficult. The comment also highlights the need for more detailed discussions on the grid search process and its reproducibility. While the comment provides a clear direction for improvement by suggesting that the authors should address the hyperparameter tuning issue and provide more details on the grid search process, it lacks specific suggestions or examples on how to improve the tuning process or what aspects of the grid search should be discussed. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, which makes it unclear about the difference between known and unknown attacks. This feedback provides a clear and direct action for the authors to take, which is to include these accuracies in the figure. The comment is specific and provides concrete guidance on what needs to be added to the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of accuracies of the target model using different defenses against the FGSM attack. This provides clear guidance on what the authors need to add to the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, which makes it unclear about the difference between known and unknown attacks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1. This lack of information makes it unclear about the difference between known and unknown attacks. The comment is clear and actionable, as it directs the authors to include this information in the figure to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific types of attacks should be included. Overall, the comment is mostly helpful as it highlights an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors consider using a log-scale for the y-axis in some figures, which is a clear and direct action. This guidance provides a concrete step for the authors to take in order to improve the readability of their figures. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figures being hard to read and suggests using a log-scale for the y-axis. This provides clear guidance on what needs to be addressed to improve the readability of the figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that some figures are hard to read and recommends using a log-scale for the y-axis. However, it does not provide any specific examples or detailed reasoning to support why the log-scale is necessary or how it would improve the readability of the figures. The comment lacks supporting evidence or references, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the readability of some figures, noting that they are hard to read. It provides a clear and actionable suggestion by recommending the use of a log-scale for the y-axis. This feedback is valuable as it directly addresses a potential obstacle to the clarity and accessibility of the figures, offering a straightforward way for the authors to improve the presentation of their data. However, the comment could be more helpful if it explained why a log-scale is beneficial or provided examples of how it might improve the figures. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the authors\\' claims about the usefulness of augmentation information and the lack of validation in the experiments. It suggests that the authors should use fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate their claims. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but implicit, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"Introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the validation of the authors\\' claims about the usefulness of augmentation information and the lack of validation in the experiments. The comment suggests using specific datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate the claims. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is motivated by the case where \"augmentation information is useful\" but lacks validation in the experiments. The reviewer suggests using specific datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate the claims. However, the comment does not provide detailed reasoning or examples to support why these datasets are necessary or how they would validate the claims. The lack of specific examples or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of these datasets to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the authors\\' claims about the usefulness of augmentation information and the lack of validation in the experiments. It suggests that the authors should use specific datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate their claims. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by addressing a critical aspect of the methodology. However, the comment could be more helpful if it explained why these datasets are particularly relevant or how they would impact the validation process. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of theoretical analysis and empirical evidence to support the claim that GEMS converges to the Nash equilibrium. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should provide theoretical analyses or empirical evidence to substantiate their claim, but it lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement about opponents evolving toward the Nash equilibrium, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of theoretical analyses and empirical evidence to support the claim that GEMS converges to the Nash equilibrium. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks theoretical analyses and empirical evidence to support the claim that GEMS converges to the Nash equilibrium. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of theoretical analyses and empirical evidence to support the claim that GEMS converges to the Nash equilibrium. This is a critical point that could impact the validity and credibility of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional analyses or theoretical frameworks to support their claims. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with Equation (1), including the purpose of defining a loss function or the optimization problem, the definition of the optimization variable, and the unusual constraints notation. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to clarify the purpose and definition of the optimization variable and constraints notation. The actions are implicit and somewhat vague, as the authors need to infer the necessary changes to make the equation clearer. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the equation, such as the purpose of defining a loss function or optimization problem, the definition of the optimization variable, and the unusual constraints notation. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several issues with Equation (1), questioning the purpose and definition of the optimization variable and constraints notation. The reviewer provides logical reasoning by pointing out that the equation seems to mix both the loss function and the optimization problem, and that the optimization variable is defined in R^n but might be meant for R^k. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to infer the exact nature of the issues and how to address them, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with Equation (1), including the purpose of defining a loss function or the optimization problem, the definition of the optimization variable, and the unusual constraints notation. These points are clear and provide specific areas for improvement, offering the authors actionable feedback on how to clarify and improve the equation. By addressing these issues, the authors can enhance the clarity and accuracy of their work. However, the comment could be more helpful if it provided suggestions on how to resolve these issues or offered examples of how similar equations have been clarified in similar contexts. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for more discussions or explanations regarding the observation that including the collected LIV-EN parallel data for finetuning actually makes the NMT system perform worse. This is a clear and direct request for the authors to provide additional information or analysis to clarify this issue. The action is explicit and concrete, as it specifies exactly what the authors need to address. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 257,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the observation that including the collected LIV-EN parallel data for finetuning makes the NMT system perform worse and requests more discussions or explanations. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the observation that including the collected LIV-EN parallel data for finetuning actually makes the NMT system perform worse. It suggests that more discussions or explanations are needed to understand this phenomenon. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific observation regarding the inclusion of LIV-EN parallel data for finetuning, which appears to negatively impact the NMT system's performance. It requests more discussions or explanations on this phenomenon, prompting the authors to provide additional insights or analysis to clarify this issue. While the comment highlights an area for improvement, it does not offer specific suggestions or guidance on how to address the problem or what kind of discussions would be beneficial. This limits the comment\\'s helpfulness, as it points out a potential issue but lacks actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs,\" noting that the authors lack adequate reasoning or references to support this claim. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should provide more detailed reasoning or references to substantiate their claims, but it does not specify what exactly is missing or how to improve the draft. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s conjectures about \"fine-tuning as exposure of existing capabilities in LMs,\" indicating that the authors lack adequate reasoning or references to support this claim. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for more substantiation or references to support the conjectures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs.\" However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without such information, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of substantiation or references for the claim that \"fine-tuning is exposure of existing capabilities in LMs.\" This is a critical observation that could impact the credibility and clarity of the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending additional references or examples to support their claims. While it points out a significant weakness, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that using FACodec might benefit from including NaturalSpeech 3 as a baseline for voice cloning tasks. While the comment implies that the authors should consider this baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a baseline. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering the use of FACodec and suggests including NaturalSpeech 3 as a baseline for voice cloning tasks. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this baseline could be added. The authors can infer that it relates to the experimental setup or methodology, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting a potential baseline, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using FACodec might benefit from including NaturalSpeech 3 as a baseline for voice cloning tasks. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this baseline is beneficial or how it would improve the results. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests considering the use of FACodec and includes a specific suggestion to include NaturalSpeech 3 as a baseline for voice cloning tasks. This feedback is somewhat helpful as it provides a concrete suggestion for improving the experimental setup by adding a baseline that could potentially enhance the results. However, the comment could be more helpful if it explained why NaturalSpeech 3 is a beneficial baseline or how it might impact the results. Overall, the comment offers a clear and actionable suggestion, but it could be more comprehensive with additional context or explanation. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the experiments, specifically questioning whether the proposed method can be trained with the first 4 weeks of data used for inference by other methods. The reviewer seeks clarification on whether this is a valid concern or if there is a misunderstanding regarding the experimental setting. While the comment identifies an issue, it does not provide explicit guidance on how to address it or what specific changes should be made to ensure fairness. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the experimental setting to ensure fairness. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a concern about the fairness of the experiments, specifically questioning whether the proposed method can be trained with the first 4 weeks of data used for inference by other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the fairness of the experiments and the need for clarification on the experimental setting. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experiments, specifically questioning whether the proposed method can be trained with the first 4 weeks of data used for inference by other methods. The reviewer seeks clarification on whether this is a valid concern or if there is a misunderstanding regarding the experimental setting. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the experiments are not fair. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the fairness of the experiments, specifically questioning whether the proposed method can be trained with the first 4 weeks of data used for inference by other methods. It suggests that this might be an issue with the experimental setting and requests clarification. While the comment identifies a potential problem, it lacks specific guidance or suggestions on how the authors might address this concern or improve the fairness of their experiments. The feedback is somewhat helpful as it points out a potential issue but does not provide actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors need to infer the exact steps to take to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these results should be included. The authors can infer that it relates to the results or evaluation section, but this inference is not direct. The comment is specific in detailing what needs to be addressed, but it lacks full grounding as it does not explicitly mention the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). This feedback is somewhat helpful as it identifies a specific area for improvement, namely the inclusion of comparative results that could enhance the paper\\'s contribution. However, the comment lacks depth and does not provide detailed guidance on how to implement these comparisons or why they are important. Additionally, it does not address other aspects of the paper, such as its theoretical contributions or methodological rigor. While the suggestion is actionable, the comment could be more comprehensive to fully support the authors in improving their draft. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of sequential bias on the VisDial results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the VisDial results are affected by sequential bias. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of sequential bias on the VisDial results, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the VisDial results are affected by sequential bias or how this impact should be addressed. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the impact of sequential bias on VisDial results. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the impact of sequential bias on the VisDial results, which could be an important area for exploration or discussion. However, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the VisDial results might be affected by sequential bias. Without actionable feedback or direction, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the experimental results and the stated goal of the LTAP method. It suggests that LTAP achieves a larger performance improvement for head classes than for tail classes, which contradicts the stated goal of strengthening parameter protection for tail classes. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to align their results with their stated goals. The authors are left to infer that they need to reconsider their experimental setup or analysis to resolve this discrepancy. Therefore, the comment is somewhat actionable, as it identifies an issue but lacks concrete details on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ImageNet-LT dataset\" and the \"ATO and RReg\" methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a discrepancy between the experimental results and the stated goal of the LTAP method, which is to strengthen parameter protection for tail classes. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on the ImageNet-LT dataset contradict the stated goal of the LTAP method, which is to strengthen parameter protection for tail classes. The reviewer supports this claim by comparing the performance improvement for head and tail classes, suggesting that LTAP achieves a larger performance improvement for head classes than for tail classes. However, the comment lacks specific references or detailed analysis to fully substantiate the claim. While the comparison to ATO and RReg provides some context, the reasoning could be strengthened with additional evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but requires more detailed support to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the experimental results and the stated goal of the LTAP method, which is to strengthen parameter protection for tail classes. By pointing out that LTAP achieves a larger performance improvement for head classes than for tail classes, the comment highlights an issue that the authors need to address. This feedback is somewhat helpful as it prompts the authors to reconsider their experimental setup and analysis to ensure that their results align with their stated goals. However, the comment could be more helpful if it provided specific suggestions on how to resolve this discrepancy or what aspects of the experimental design might be contributing to the observed results. Overall, the comment offers valuable insight but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the reliability of the search process due to the use of LLM-based evaluation. It suggests that the reliance on LLMs for evaluation may introduce biases or inconsistencies in the quality assessment of generated documentations. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to mitigate the issue. The authors are left to infer that they need to consider the potential impact of LLMs on the evaluation process and possibly explore alternative methods for assessing quality. While the comment identifies a concern, it lacks concrete steps for the authors to take, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"reward computation\" and the \"LLM-based evaluation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern about the reliability of the search process due to the use of LLMs for evaluation, and it points out the potential biases or inconsistencies that may arise from this dependency. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reward computation relies on LLM-based evaluation, which raises concerns about the reliability of the search process. The comment suggests that this dependency on LLMs for evaluation may introduce biases or inconsistencies in the quality assessment of generated documentations. However, the comment lacks specific examples or references to support the claim that LLMs may generate inaccurate scores. Without such evidence or detailed reasoning, the claim is somewhat verifiable, as it provides a logical basis but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential concern regarding the reliability of the search process due to the use of LLM-based evaluation. It highlights the dependency on LLMs for evaluation and suggests that this may introduce biases or inconsistencies in the quality assessment of generated documentations. While the comment points out a relevant issue, it lacks specific suggestions or guidance on how the authors might address this concern or mitigate the potential biases. The feedback is somewhat helpful as it prompts the authors to consider the implications of their methodology, but it could be more beneficial with additional actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more empirical examples and compare their results to those of state-of-the-art (SOTA) methods. It also mentions that Equation 12 is unclear, but does not provide specific guidance on how to clarify it. While the comment implies that the authors should include more empirical evidence and clarify Equation 12, it does not provide explicit instructions or concrete details on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that the process described is surprisingly effective, suggesting that more empirical examples and comparisons to SOTA performance from referenced papers would be beneficial. It mentions Equation 12 as being unclear, but does not specify which part of the paper this equation is located in. While the authors might have an idea of where Equation 12 is discussed, the comment lacks full grounding as it does not explicitly mention the section or figure where this equation is presented. The comment is specific in suggesting the need for more empirical evidence and clarification of Equation 12, but without full grounding, it is weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the process described is surprisingly effective and suggests that more empirical examples and comparisons to state-of-the-art (SOTA) methods would be beneficial. The reviewer also mentions that Equation 12 is unclear, but does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to substantiate the claim about the effectiveness or clarity of the process. As a result, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that the process described is surprisingly effective, but lacks empirical evidence to support this claim. It also points out that Equation 12 is unclear, which is a specific area that needs clarification. While the comment provides a clear direction for improvement by suggesting the inclusion of more empirical examples and clarification of Equation 12, it does not offer detailed guidance on how to implement these changes or what specific aspects of the process should be emphasized. The feedback is somewhat helpful as it highlights areas for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the difficulty of the problem and questions the assumption that the adversary cannot pick arbitrary S. It provides a detailed explanation of the assumption and its implications, suggesting that the problem is still solvable if m = O(k log n). However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their assumptions and potentially revise their analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the difficulty of the problem and the assumption that the adversary cannot pick arbitrary S. The comment provides a detailed explanation of the assumption and its implications, which is specific and clear. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the difficulty of the problem and questions the assumption that the adversary cannot pick arbitrary S. The reviewer provides a detailed explanation of the assumption and its implications, suggesting that the problem is still solvable if m = O(k log n). This explanation is logical and provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific literature or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the difficulty of the problem and questions the assumption that the adversary cannot pick arbitrary S. It provides a detailed explanation of the assumption and its implications, suggesting that the problem is still solvable if m = O(k log n). This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s assumptions and offers a logical explanation for why the problem might still be solvable. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or improve their analysis. Overall, the comment offers some insight but lacks actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a contradiction between Figure 1 and Table 1, specifically noting that NNGS increases as k increases, which contradicts the comparison in the last two columns of Table 1. However, the comment does not provide explicit guidance on how the authors should address this contradiction or what specific changes should be made to resolve it. The action is implicit and somewhat vague, as the authors can infer that they need to reconcile the contradiction but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the contradiction between Figure 1 and Table 1 regarding the relationship between NNGS and the number of selected k-nearest neighbors. The comment provides a clear direction for the authors to address this contradiction, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 1 contradicts the comparison in the last two columns of Table 1, specifically stating that NNGS increases as k increases. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific contradiction between Figure 1 and Table 1, noting that NNGS increases as k increases, which contradicts the comparison in the last two columns of Table 1. This is a clear and actionable observation that prompts the authors to reconcile the contradiction or clarify the discrepancy in their results. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining the implications of the contradiction or offering guidance on how to resolve it. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the extensibility of the proposed method to a large number of tasks and questions the impact on the shared parameters. It explicitly asks the authors to address this question, providing a clear direction for improvement. The comment is explicit in its request for an explanation of the impact of a large number of tasks on the proposed approach, making it highly actionable. The authors know exactly what needs to be done to improve their draft, which is to provide a detailed analysis or discussion of the impact of a large number of tasks on the shared parameters.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the concern about the extensibility of the proposed method to a large number of tasks, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the impact of a large number of tasks on the shared parameters and requests an explanation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the extensibility of the proposed method to a large number of tasks, questioning its impact on the shared parameters. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The suggestion to address the question regarding the effect of the number of tasks is a logical one, but without detailed evidence or reasoning, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the extensibility of the proposed method to a large number of tasks, which is an important consideration for its applicability. It questions the impact of a large number of tasks on the shared parameters and suggests that the experiments should be expanded to include more tasks. This feedback is actionable as it prompts the authors to address this issue in their draft, which could significantly impact the robustness and generalizability of their approach. However, the comment could be more helpful if it provided specific suggestions on how to conduct the additional experiments or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the eyetracking data selection and filtering appears perplexing, as it seems to analyze everything with some exclusions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what aspects of the data selection or filtering are unclear or how they could be improved. Without specific suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"eyetracking data selection/filtering,\" which provides some grounding as it relates to a specific aspect of the paper. However, it does not specify which part of the paper this pertains to, such as a particular section or figure. The comment is specific in pointing out the perplexing nature of the data selection and filtering, but it lacks detailed guidance on what needs to be addressed or improved. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the eyetracking data selection and filtering is perplexing, as it appears to analyze everything with some exclusions. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the eyetracking data selection and filtering, noting that it appears to analyze everything with some exclusions. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the data selection or filtering are problematic or how they could be addressed. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the credibility of the Appendix results for InitNO, specifically questioning the reported improved text-image alignment on StableDiffusion-v1-4. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to improve the credibility of the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix results for InitNO\" and \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the credibility of the results, noting that the reported improved text-image alignment on StableDiffusion-v1-4 is lower than that of StableDiffusion-v1-4 in Table 6. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the credibility of the Appendix results for InitNO is questionable, based on the reported improved text-image alignment on StableDiffusion-v1-4 and the lower alignment in Table 6. However, the comment does not provide specific evidence or references to support this claim, such as data or comparisons that demonstrate the discrepancy. Without detailed justification or examples, the claim remains somewhat verifiable, as it requires further elaboration for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the credibility of the Appendix results for InitNO, specifically questioning the reported improved text-image alignment on StableDiffusion-v1-4. It points out that Table 6 shows InitNO's alignment is lower than that of StableDiffusion-v1-4, which could undermine the credibility of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the credibility of their results. While it highlights a potential problem, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete suggestions for improving the writing style. It suggests that the language usage could be more consistent and that the notation in equations might be too complex, recommending the consideration of dropping some sub/superscripts for convenience. The comment also advises the authors to note that they are making such changes. These actions are clear and specific, providing the authors with a direct path to enhance their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the writing style, specifically mentioning that it is uneven and could use additional editing. It also mentions the notation in equations, suggesting that it might be too complex and could be improved by dropping some sub/superscripts for convenience. However, the comment does not specify which parts of the paper these issues are present in, making it weakly grounded. The suggestion to consider dropping sub/superscripts is specific, but without full grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing is uneven and could benefit from additional editing, particularly regarding language usage and type perspective. It also mentions that the notation in equations is exact but unwieldy, suggesting that dropping some sub/superscripts for convenience might be considered. The comment provides a logical reasoning for the suggestion to simplify the notation, but it lacks specific examples or references to support the claim about the complexity of the notation. Therefore, the comment is somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the writing style, suggesting that it could be improved by adding additional editing and simplifying the notation in equations. It highlights the unevenness in the writing and points out that the notation might be too complex, recommending the consideration of dropping some sub/superscripts for convenience. The comment is clear and constructive, offering a concrete way for the authors to enhance the clarity and readability of their draft. However, it could be more helpful if it provided examples of specific sections or equations where the notation is particularly complex, which would guide the authors in prioritizing their editing efforts. Overall, the comment is mostly helpful, as it offers valuable insights and suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the size of the dataset relative to the development cost, specifically mentioning the cost of image acquisition and the type of manual collection used. It also suggests that the authors should explain these aspects. Additionally, it points out a minor issue with the formatting of Line 79, which contains two questions. The comment provides specific guidance on what needs to be addressed, making it clear and actionable. However, it does not offer detailed instructions on how to implement these changes. Overall, the comment is mostly actionable as it provides clear and concrete actions for the authors to take, but it could be more detailed in its guidance.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the dataset size and the cost of image acquisition, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for an explanation of the image acquisition cost and the type of manual collection used. Additionally, it raises a minor issue with the formatting of Line 79 and asks for clarification on the content of \"regulatory requirements\" in Line 263. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the size of the dataset relative to the development cost, specifically mentioning the cost of image acquisition and the type of manual collection used. It suggests that the authors should explain these aspects. The comment also points out a minor formatting issue with Line 79 and requests clarification on the content of \"regulatory requirements\" in Line 263. While the comment identifies a potential issue with the dataset size, it lacks specific examples or references to support the claim about the cost of image acquisition or the type of manual collection used. The minor formatting issue is not relevant to the main concern. Therefore, the claim is somewhat verifiable, as it provides some basis but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the size of the dataset relative to the development cost, specifically mentioning the cost of image acquisition and the type of manual collection used. This is a relevant concern that could impact the feasibility and scalability of the study. The comment also points out a minor formatting issue with Line 79 and requests clarification on the content of \"regulatory requirements\" in Line 263. While the feedback highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The comment is somewhat helpful as it provides some direction for improvement but could be more comprehensive with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses curiosity about how the third column of Fig. 7 is generated, noting that the visualizations appear not to be normalized. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to ensure normalization. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the generation of the third column in Fig. 7 and the lack of normalization in the visualizations. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment expresses curiosity about the generation of the third column in Fig. 7, noting that the visualizations appear not to be normalized. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses curiosity about the generation of the third column in Fig. 7, noting that the visualizations appear not to be normalized. While it identifies a potential issue, it lacks depth and does not provide any actionable suggestions or guidance on how the authors might address this concern. Without further explanation or advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate the advantages of using assignment entropy maximization in the ablation experiment, which is already mentioned in the paper. It also points out that the authors have described the limitations of their work but have not discussed any potential negative societal impacts. While the comment provides a clear action for the authors to take, it does not specify how to conduct the evaluation or what specific aspects of the work should be discussed regarding societal impacts. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"section of benefit of assignment entropy maximization,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the advantages of using assignment entropy maximization and the potential negative societal impacts of the work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the investigation into assignment entropy maximization is heuristic and suggests that the authors should evaluate the advantages of using this method in the ablation experiment. The comment also notes that the authors have described the limitations of their work but have not discussed any potential negative societal impacts. While the comment provides a logical reasoning for the need to evaluate the advantages and discuss societal impacts, it lacks specific examples or references to support the claim about the heuristic nature of the investigation. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should evaluate the advantages of using assignment entropy maximization in the ablation experiment. It also points out that the authors have described the limitations of their work but have not discussed any potential negative societal impacts. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by including a discussion of the benefits and limitations. However, the comment could be more helpful if it offered specific suggestions on how to conduct the evaluation or what aspects of the work should be considered for societal impact assessment. Overall, the comment is mostly helpful as it guides the authors toward improving their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that there is only one baseline model in the experimental section, which is a factual observation. However, it does not provide any guidance or suggestions on how the authors might address this issue, such as suggesting the inclusion of additional baselines or explaining why this is insufficient. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of having only one baseline model in the experimental section, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is only one baseline model in the experimental section. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a problem or how it affects the paper\\'s conclusions. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a specific issue with the experimental section, noting that there is only one baseline model included. While this observation highlights a potential limitation, it does not provide any guidance or suggestions on how the authors might address this issue or improve their experimental design. Without actionable feedback or context, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of baselines and literature comparisons, specifically mentioning traditional QAT, LLM-based QAT work, and recent PTQ baselines like SpinQuant. It suggests that understanding the benefits of using extra memory for QAT is important. However, the comment does not provide explicit instructions on how to include these comparisons or what specific aspects to focus on. While the action is implied, it lacks concrete guidance on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements, such as \"baselines and literature comparisons,\" \"traditional QAT,\" \"LLM-based QAT work,\" and \"recent PTQ baseline such as SpinQuant.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely the inclusion of these comparisons, and why they are important for understanding the benefits of using extra memory for QAT. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that baselines and literature comparisons are missing, specifically mentioning traditional QAT, LLM-based QAT work, and recent PTQ baselines like SpinQuant. The reviewer suggests that understanding the benefits of using extra memory for QAT is important. However, the comment lacks specific examples or detailed reasoning to support why these comparisons are necessary or how they would benefit the paper. While the claim is logical, it is not fully substantiated with evidence or references, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of baselines and literature comparisons, particularly in the context of traditional QAT, LLM-based QAT work, and recent PTQ baselines like SpinQuant. It highlights the importance of understanding the benefits of using extra memory for QAT, which is a valuable insight for the authors. However, the comment could be more helpful by providing specific suggestions on how to incorporate these comparisons or what aspects to focus on in the analysis. While it points out a critical area for improvement, the lack of detailed guidance limits its utility. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for more detailed instructions on how to define attributes and the differences between them. This is a clear and direct request for clarification, providing the authors with a specific action to take. The comment is explicit and concrete, as it specifies exactly what needs to be added to the draft to improve it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for more detailed instructions on how to define attributes and the differences between them. This allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. However, the comment lacks specificity as it does not provide detailed guidance or examples on what kind of instructions should be included. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point consists of factual questions asking for clarification on how to define attributes and the differences between them. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the paper regarding the definition and differences between attributes. It explicitly requests more detailed instructions on how to define attributes and what the differences are. This feedback is clear and actionable, as it provides a specific area for improvement that can help the authors clarify their work. However, the comment could be more helpful if it offered examples or suggestions on how to provide these detailed instructions. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the theory in the paper does not provide sufficient guidance on whether it can help train a model robust to adversarial perturbations. However, it does not offer any explicit or implicit actions for the authors to take. There is no suggestion for how to address this issue or what specific steps to consider. Without actionable advice or guidance, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the theory in the paper does not provide sufficient guidance on whether it can help train a model robust to adversarial perturbations. However, it does not specify which part of the paper this issue pertains to, such as a particular section or discussion. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the theory are insufficient or how they could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theory in the paper does not provide sufficient guidance on whether it can help train a model robust to adversarial perturbations. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential weakness in the paper, suggesting that the theory does not provide sufficient guidance on whether it can help train a model robust to adversarial perturbations. However, it lacks specificity and actionable suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear path forward to address this issue or enhance their work. Therefore, the comment is barely helpful, as it identifies a weakness but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaning of \"scenario\" in the paper, specifically whether it refers to classes or instances, and where the \"agnostic\" part fits in. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should clarify this aspect in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of \"scenario\" and the role of \"agnostic\" in the context of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of \"scenario\" in the paper, specifically whether it refers to classes or instances, and where the \"agnostic\" part fits in. However, it does not specify which part of the paper this confusion is related to, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors might have an idea of where the term \"scenario\" is used, the comment lacks full grounding. It is specific in questioning the meaning of \"scenario\" and the role of \"agnostic,\" but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the meaning of \"scenario\" and the role of \"agnostic\" in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the clarity of the term \"scenario\" in the paper, specifically asking whether it refers to classes or instances, and where the \"agnostic\" part fits in. While this question highlights a potential area of confusion, it does not provide any actionable guidance or suggestions for how the authors might clarify this aspect in their draft. The comment identifies a potential source of confusion but lacks depth and specificity, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the method being named \"Maestro\" and questions its introduction and relevance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or suggest improvements. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the method being named \"Maestro\" and questions its introduction and relevance. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the method is introduced. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity in detailing what is problematic about the method being named \"Maestro\" or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the appropriateness of the method being named \"Maestro\" and expresses confusion about its introduction and relevance. However, it does not provide any supporting evidence, reasoning, or examples to justify why this naming is problematic or unclear. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary information to support the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the method being named \"Maestro\" and questions its introduction and relevance. However, it does not provide any context or explanation as to why this naming is problematic or how it might impact the paper. Without additional information or suggestions for improvement, the authors are left without a clear understanding of the issue or guidance on how to address it. Therefore, the comment is not helpful, as it lacks depth and actionable feedback.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to define what \"best\" means within the context of the paper, clarifying whether it refers to candidates most relevant for prediction, those with the highest confidence scores, or some other criteria. This feedback is clear and provides a specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is concrete, as it specifies the exact part of the paper to address and the exact issue to clarify. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of \"best\" in the context of the paper and whether it refers to candidates most relevant for prediction, those with the highest confidence scores, or some other criteria. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors clarify the definition of \"best\" in the context of the paper, specifically questioning whether it refers to candidates most relevant for prediction, those with the highest confidence scores, or some other criteria. This is a request for clarification rather than a claim or opinion, as it does not express an opinion or judgment but rather seeks additional information. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area of ambiguity in the paper, specifically the use of the term \"best\" in the context of candidate selection. By explicitly defining what \"best\" means within the context of the paper, the authors can clarify their methodology and ensure that their readers understand the criteria used for evaluating candidates. This feedback is actionable and provides a clear direction for improving the draft, making it mostly helpful. However, the comment could be more helpful if it offered suggestions on how to clarify the definition or provided examples of how other criteria might be defined. Overall, the comment is valuable in guiding the authors to improve the clarity and precision of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some claims in the paper are over-claimed, specifically mentioning that the proposed method does not consider feed-forward layers but is described as if it does. The reviewer does not provide explicit guidance on how to address this issue, such as suggesting specific changes to the text or clarifying the scope of the method. The action is implicit and somewhat vague, as the authors need to infer that they should correct the claims or clarify the scope of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"some points\" and \"the proposed method,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that some claims are over-claimed, particularly regarding the consideration of feed-forward layers. The comment provides a clear direction for the authors to address the over-claiming issue by suggesting they clarify the scope of their method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some points in the paper are over-claimed, specifically mentioning that the proposed method does not consider feed-forward layers but is described as if it does. This claim is somewhat verifiable as it highlights a discrepancy in the paper\\'s claims and provides a specific example of an over-claim. However, the comment lacks detailed reasoning or references to support the claim, making it somewhat verifiable. The authors would need to further investigate the claims and provide additional evidence or clarification to fully substantiate the reviewer\\'s point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claims made in the paper, noting that some points are over-claimed. It points out that the proposed method does not consider feed-forward layers, yet some text suggests that it does. This feedback is clear and actionable, as it directs the authors to clarify or correct their claims to avoid misleading readers. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present the method\\'s scope more accurately. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments are not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific variations or explaining why these methods are not well-motivated. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"experiments design\" and \"no variations\" and \"Up to 18 games\" finetuning methods, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue of lack of motivation for the experiments, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental design, noting that the \"no variations\" and \"Up to 18 games\" finetuning methods are not clearly motivated. This feedback is somewhat helpful as it points out a potential weakness in the paper, but it lacks depth and does not provide suggestions on how the authors might address this issue or improve the motivation for their experiments. While it highlights an area for improvement, the comment could be more helpful with additional guidance or examples on how to enhance the motivation for the finetuning methods. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate the method performance under missing modality cases, such as testing sets with different missing ratios. It also provides specific references to external works that could be relevant to this evaluation. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for additional evaluation and provides examples of relevant works, but it is somewhat vague in terms of how to implement these suggestions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1/2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of method performance under missing modality cases, such as testing sets with different missing ratios. The comment provides examples of relevant external works, \"A\" and \"B,\" which further clarifies the need for additional evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in table 1/2 is incomplete because it only shows Miss-V and Miss-A results. It suggests that testing sets with different missing ratios should be evaluated to better understand the method's performance under missing modality cases. The comment provides a logical reasoning by pointing out the need for a more comprehensive evaluation, but it lacks specific examples or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation in the paper, noting that only Miss-V and Miss-A results are shown in table 1/2. It suggests that a more comprehensive evaluation is needed, including testing sets with different missing ratios to better understand the method's performance under missing modality cases. The comment provides a clear and actionable suggestion for improvement by recommending additional experiments. However, it could be more helpful if it offered specific guidance on how to conduct these additional experiments or what specific missing ratios should be tested. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an ablation study on the effect of using image features is needed. While it implies that the authors should conduct this study, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment somewhat actionable. The authors can infer that they need to conduct an ablation study, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study on the effect of using image features, but it does not specify which part of the paper this suggestion pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what aspects of the ablation study should be conducted or how it would be conducted. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests conducting an ablation study on the effect of using image features, which is a logical suggestion given the context of the paper. However, the comment does not provide specific reasoning or evidence to support why this study is necessary or how it would benefit the paper. Without additional details or examples, the claim is somewhat verifiable, as it provides a direction for improvement but lacks the necessary justification to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting an ablation study on the effect of using image features, which is a relevant and actionable suggestion. It highlights a potential area for improvement by recommending a specific experiment that could enhance the understanding of the paper\\'s contribution. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the ablation study or what specific aspects to focus on. Despite this, the feedback is mostly helpful as it directs the authors to a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning the Transformer Big and deep Transformers. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this concern or what specific steps they should consider to test the approach in challenging settings. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the approach in challenging settings, specifically mentioning the Transformer Big and deep Transformers. However, it does not specify which part of the paper this question pertains to, such as the experimental setup or results section. Without explicit references to sections or figures, the authors cannot confidently determine where to address this concern. Additionally, the comment lacks specificity regarding what aspects of the approach need to be tested in challenging settings or how the authors should conduct these tests. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning the Transformer Big and deep Transformers. However, it does not provide any supporting evidence, reasoning, or references to justify why these settings are considered challenging or how the approach might perform in them. Without such information, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of the approach in challenging settings, specifically mentioning the Transformer Big and deep Transformers. While it identifies a potential area for improvement, it lacks specificity and actionable guidance on how the authors might address this concern. The comment does not provide suggestions on how to test the approach in challenging settings or what specific aspects of the approach might need to be improved. Without detailed feedback or suggestions, the authors are left without a clear path forward. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors' understanding of identifiability is incorrect, specifically stating that it is a property of a model assuming infinite data. The reviewer clarifies that one cannot say a model is not identifiable due to insufficient data. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors should revise their understanding or correct their claims regarding identifiability. As a result, the comment is unactionable, as it does not offer any direction for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' understanding of identifiability, specifically pointing out that it is a property of a model assuming infinite data. However, it does not specify which part of the paper this understanding is discussed in, making it weakly grounded. The comment is specific in detailing the correct understanding of identifiability, but without explicit references to sections or specific claims, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' understanding of identifiability is incorrect, specifically stating that it is a property of a model assuming infinite data. The reviewer provides a logical reasoning by explaining that one cannot say a model is not identifiable due to insufficient data. This claim is supported by a clear explanation of the concept, making it fully verifiable. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' understanding of identifiability, which is a critical concept in the field. It points out that the authors cannot claim a model is not identifiable due to insufficient data, as identifiability is a property of a model assuming infinite data. This feedback is clear and actionable, as it directs the authors to correct their understanding and avoid misleading claims. However, the comment could be more helpful if it provided additional context or examples to help the authors better understand the concept and its implications. Overall, the comment is mostly helpful as it highlights a critical issue and offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the results do not show a significant benefit compared to the simple baseline mentioned in the paper. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their results. There is no guidance on potential modifications to the methodology, additional analyses, or alternative baselines that could be considered. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the results do not show a significant benefit compared to the simple baseline mentioned in the paper. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on what specific aspects of the results are lacking. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the results are not beneficial or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results do not show a significant benefit compared to the simple baseline mentioned in the paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the results, noting that there is no significant benefit shown compared to the simple baseline mentioned in the paper. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue or improve their results. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two issues related to the efficiency of the method. First, it points out that the method requires a pre-trained vocoder for training, which is not described in terms of time cost. Second, it notes that the inference process incorporates a diffusion-based vocoder, which may result in slower inference speed compared to other methods. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to provide more information about the time cost of the pre-training process and consider the impact of the diffusion-based vocoder on inference speed. However, the lack of concrete suggestions or detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"training process\" and \"inference process,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the method, such as the requirement for a pre-trained vocoder and the potential impact on inference speed due to the use of a diffusion-based vocoder. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method requires a pre-trained vocoder for training and that the inference process incorporates a diffusion-based vocoder, which may result in slower inference speed. The comment provides some reasoning by mentioning the GPU hours of the pre-training process and the potential impact on inference speed due to the diffusion-based vocoder. However, it lacks specific examples or detailed evidence to fully substantiate the claim about the time cost or inference speed. While the reasoning is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues related to the efficiency of the method. First, it points out that the method requires a pre-trained vocoder for training, which is not described in terms of time cost. Second, it notes that the inference process incorporates a diffusion-based vocoder, which may result in slower inference speed compared to other methods. This feedback is valuable as it highlights areas where the authors need to provide more detailed information and consider the impact on the efficiency of their method. However, the comment could be more helpful if it suggested ways to address these issues, such as providing guidance on how to measure and report the time cost or suggesting alternative approaches to improve efficiency. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper mentions the generalizability of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, but this generalization is not explored. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to explore generalization. The comment lacks concrete suggestions or detailed instructions on how to improve the paper in this regard. As a result, the authors are left without a clear understanding of what actions to take to enhance the generalizability of their framework. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the scoring function s(\u00b7; G) and its potential generalization for multiple goal documents or without any gold document. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not detail what aspects of the generalization are questionable or how the authors could explore this further. Without specific guidance or examples, the authors may struggle to understand how to address the issue. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the generalization of the scoring function s(\u00b7; G) is not explored, which makes the generalization of the framework questionable. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document. It points out that while the paper mentions this generalization, it does not explore it, which raises questions about the generalizability of the framework. However, the comment lacks specific suggestions or guidance on how the authors might explore this generalization or what aspects of the framework should be addressed. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including information on the success rate at each conversation turn would provide valuable insights into the framework's performance throughout the recommendation process. It explicitly states that this data can help readers assess the effectiveness of the approach in a more nuanced manner. The comment provides a clear and concrete action for the authors to take, which is to include this information in their paper. The suggestion is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including information on the success rate at each conversation turn to provide insights into the framework\\'s performance throughout the recommendation process. However, it does not specify which part of the paper this information should be included in, such as a particular section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. The comment is specific in detailing what additional information is needed, but it lacks full grounding as it does not explicitly mention the relevant section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including information on the success rate at each conversation turn would provide valuable insights into the framework\\'s performance throughout the recommendation process. This claim is somewhat verifiable as it logically follows that such data could offer a more nuanced understanding of the framework\\'s effectiveness. However, the comment lacks specific examples or references to similar studies that have used this approach, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides a reasonable suggestion but could be further substantiated with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of information on the success rate at each conversation turn. This data would offer valuable insights into the framework\\'s comparative performance throughout the recommendation process, allowing readers to assess its effectiveness in a more nuanced manner. The comment is specific and provides a concrete action for the authors to take, making it highly helpful in guiding the improvement of their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is dense and recommends breaking up numbered lists within paragraphs into separate lists for easier readability. While the action is implicit, it is concrete because it provides a clear suggestion for improving the organization and readability of the paper. The authors know that they should consider separating numbered lists into separate lists when appropriate, but the comment does not provide specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the paper being dense and suggests that the authors might consider breaking up numbered lists within paragraphs into separate lists for easier readability. However, it does not specify which parts of the paper are particularly dense or where the numbered lists are located, making it difficult for the authors to pinpoint the exact areas that need improvement. While the comment provides a general direction for improvement, it lacks specificity and is not grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is dense and suggests that the authors might consider breaking up numbered lists within paragraphs into separate lists for easier readability. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s density, suggesting that the authors might consider breaking up numbered lists within paragraphs into separate lists for easier readability. While the comment provides a clear and actionable suggestion, it lacks depth and does not offer specific examples or guidance on how to implement this change effectively. The feedback is somewhat helpful as it points out a potential improvement but could be more comprehensive with additional details. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether other \"fake image detectors\" are using the same spectral cues as the simple classifier, suggesting that the simplicity of the classifier might indicate a fundamental similarity in their approaches. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this question or explore the implications of this similarity. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fundamental nature of other \"fake image detectors\" and whether they are using the same spectral cues as the simple classifier. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the use of spectral cues, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the fundamental nature of other \"fake image detectors\" and whether they are using the same spectral cues as the simple classifier. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this question or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises an interesting question about the fundamental nature of other \"fake image detectors\" and whether they are using the same spectral cues as the simple classifier. This prompts the authors to consider the broader implications of their work and potentially explore the limitations or assumptions of their approach. However, the comment lacks specific guidance or suggestions on how the authors might address this question or explore the implications further. While it points out a relevant area for consideration, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the visualization results are terrible and recommends analyzing both satisfied and terrible cases. It also mentions that class-incremental learning for semantic segmentation does not reuse old data or labels. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct the analysis or what aspects of the visualization should be analyzed. The authors are given a general idea of what needs to be done but without concrete steps or detailed instructions, making the action somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the visualization results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the visualization results, suggesting that the authors should analyze both satisfied and terrible cases. Additionally, it provides a specific critique of class-incremental learning for semantic segmentation, noting that it does not reuse old data or labels. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the visualization results are \"terrible\" and suggests analyzing both satisfied and terrible cases. It also mentions that class-incremental learning for semantic segmentation does not reuse old data or labels. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of specific evidence or references makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the visualization results, describing them as \"terrible.\" It suggests that the authors should analyze both satisfied and terrible cases, which is a clear and actionable suggestion. Additionally, it points out a specific problem with class-incremental learning for semantic segmentation, noting that it does not reuse old data or labels. This feedback is valuable as it highlights areas that need improvement and provides a direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct the analysis or what aspects of the visualization should be analyzed. Overall, the comment is mostly helpful as it provides clear and actionable feedback, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper, noting that its relevance is based on building upon a large body of previous work. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to ensure the validity and effectiveness of TIW, nor is there any suggestion for how to mitigate the potential impact of issues in previous works. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the paper\\'s relevance, noting that it builds upon a large body of previous work. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. Additionally, the comment lacks specificity regarding what aspects of the previous work could affect the validity and effectiveness of TIW. Without clear guidance on which parts of the paper need attention or how to address the issue, the authors cannot effectively improve their draft. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper\\'s relevance is based on building upon a large body of previous work, which could affect the validity and effectiveness of TIW. However, the comment does not provide any specific examples or references to the previous works that could impact the paper\\'s validity. Without detailed reasoning or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s relevance, noting that it builds upon a large body of previous work. While this acknowledges the paper\\'s significance, it also highlights the potential for limitations or issues in those previous works to affect the validity and effectiveness of TIW. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern or mitigate the potential impact of previous work. Without actionable feedback or detailed advice, the authors are left without clear direction on how to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a relevant concern but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the selection of policies for each sub-group and the use of information during the partitioning step. It suggests that if there is information, like patient characteristics, that is used to cluster participants but not used in training the policy, it should be incorporated in the first place. However, the comment does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors can infer that they should consider incorporating additional information into the policy training process, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the idea of selecting a policy out of many for each sub-group and questions whether any information unavailable to the policy is used during the partitioning step. It also suggests that if there is information, like patient characteristics, that is used to cluster participants but not used in training the policy, it should be incorporated in the first place. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its questioning of the policy selection and information use, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the selection of policies for each sub-group and the use of information during the partitioning step. It suggests that if there is information, like patient characteristics, that is used to cluster participants but not used in training the policy, it should be incorporated in the first place. The comment provides a logical reasoning by questioning the use of available information and suggesting a potential improvement. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning and potential benefits of incorporating patient characteristics to fully understand and address the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the selection of policies for each sub-group and the use of information during the partitioning step. It suggests that if there is information, like patient characteristics, that is used to cluster participants but not used in training the policy, it should be incorporated in the first place. This feedback is somewhat helpful as it identifies a potential weakness in the methodology and offers a suggestion for improvement. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate patient characteristics into the policy training process. Overall, the comment offers some insight but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the rendering quality of NeRF compared to other models, specifically NeuS and Geo NeuS. However, it does not provide any guidance or suggestions on how the authors should address this question or improve the rendering quality. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the rendering quality of NeRF compared to other models, such as NeuS and Geo NeuS. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about the rendering quality of NeRF compared to other models, specifically NeuS and Geo NeuS. However, it does not provide any evidence, reasoning, or comparisons to support the claim that NeRF has worse rendering quality. Without such information, the claim lacks verifiability, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rendering quality of NeRF compared to other models, specifically NeuS and Geo NeuS. While it identifies a potential area for improvement, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or improve the rendering quality. The comment is somewhat helpful as it points out a potential weakness, but it does not offer actionable advice or detailed insights that could help the authors improve their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific claim in Section 3.7 of the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. The reviewer questions the assumption and expresses confusion about how it can be concluded from the proposed evaluation approach. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or clarify their reasoning. As a result, the comment is unactionable, as it does not offer any direction for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the assumption that purely unsupervised large-scale pretraining might not be suitable for NLP applications, and it points out the reviewer's confusion regarding the conclusion drawn from the proposed evaluation approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim made in Section 3.7 regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. The reviewer expresses confusion about how this conclusion can be drawn from the proposed evaluation approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or the reviewer\\'s confusion. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or the reviewer\\'s skepticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific claim in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. It questions the assumption and expresses confusion about how this conclusion can be drawn from the proposed evaluation approach. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or clarify their reasoning. Without actionable feedback or additional context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues: the lack of discussion on recent related work and the absence of DCN in Table 3. It explicitly states that the paper should discuss recent related work, including [A], which achieves higher performance on SUN, and DCN, which is better than other prior work on CUB. Additionally, it mentions that [B] is relevant with respect to transductive label propagation. While the comment provides specific examples of missing content, it does not offer detailed guidance on how to incorporate these discussions or what aspects should be emphasized. The actions are clear but somewhat vague in terms of execution, as the authors know what needs to be added but may not be entirely sure of the exact approach or depth of discussion required. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Related work 2.1\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on recent related work, the absence of DCN in Table 3, and the relevance of [B] with respect to transductive label propagation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper misses discussions on recent related work, specifically mentioning [A] and DCN, which achieve higher performance on SUN and CUB, respectively. The reviewer also notes that [B] is relevant with respect to transductive label propagation. While the comment provides specific examples of missing content, it lacks detailed reasoning or references to support why these discussions are important or how they would enhance the paper. The absence of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the significance of these discussions themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper is lacking, particularly in the discussion of recent related work and the inclusion of certain references in Table 3. It highlights the omission of [A], which achieves higher performance on SUN, and DCN, which is better than other prior work on CUB. Additionally, it notes the relevance of [B] with respect to transductive label propagation. While the comment provides clear and actionable feedback, it could be more helpful if it offered suggestions on how to incorporate these discussions or what aspects of the related work should be emphasized. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to replace the \"add\" operator in Figure 2 with a Hadamard product between the DAG and Attention. This is a clear and direct action, as it specifies the exact change needed to be made in the figure. The authors know exactly what to do to address the comment, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the operator, suggesting that it should be a Hadamard product instead of an add operation in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the operator should be a Hadamard product instead of an add operation in Figure 2. However, the comment does not provide any reasoning or evidence to support this claim. It lacks specific examples or references to justify why the change is necessary or beneficial. As a result, the claim is unverifiable, as it does not provide sufficient justification for the authors to understand or address the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a specific and actionable suggestion to improve the clarity and accuracy of the paper. By pointing out that the operator should be a Hadamard product instead of an add operation in Figure 2, the reviewer offers a clear and precise correction that can enhance the understanding and correctness of the presented work. This guidance is valuable for the authors, as it directly addresses a potential source of confusion and ensures that the figures accurately reflect the intended methodology. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the authors have addressed the reviewer\\'s concerns in their revision and response. It provides specific feedback on the improvement in achieving optimal rates for SOBA under additional smoothness assumptions, which led to an increased score from 7 to 8. However, it also points out that the limitations are only partially addressed, specifically mentioning the non-standard finite sum assumption discussed in the theoretical analysis section but not in the abstract. Additionally, it notes the discrepancy between the theoretical and practical updates of SABA, which is briefly mentioned but not adequately addressed. While the comment provides some guidance on what aspects need further attention, it does not offer explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the theoretical and practical updates of SABA and consider including the finite sum assumption in the abstract. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No. 7. 2022\" and \"Post authors\\\\u0027 response,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concerns that were addressed, such as the improvement in achieving optimal rates for SOBA under additional smoothness assumptions and the partial addressing of limitations. The comment also highlights specific issues, like the non-standard finite sum assumption discussed in the theoretical analysis section but not in the abstract, and the discrepancy between theoretical and practical updates of SABA. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review comment acknowledges that the authors have addressed the reviewer\\'s concerns in their revision and response, specifically mentioning the improvement in achieving optimal rates for SOBA under additional smoothness assumptions. This claim is supported by the reviewer\\'s observation that the authors have addressed the weaknesses raised earlier. However, the comment also points out that the limitations are only partially addressed, specifically mentioning the non-standard finite sum assumption discussed in the theoretical analysis section but not in the abstract. Additionally, it notes the discrepancy between the theoretical and practical updates of SABA, which is briefly mentioned but not adequately addressed. While the comment provides some justification for the score change, it could be strengthened by providing more detailed reasoning or examples to support the claim about the limitations. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the authors have addressed the reviewer\\'s concerns in their revision and response, specifically mentioning the improvement in achieving optimal rates for SOBA under additional smoothness assumptions. This is a positive aspect of the feedback, as it indicates that the authors have taken the reviewer\\'s feedback into account and made significant improvements. However, the comment also points out that the limitations are only partially addressed, specifically mentioning the non-standard finite sum assumption discussed in the theoretical analysis section but not in the abstract. Additionally, it notes the discrepancy between the theoretical and practical updates of SABA, which is briefly mentioned but not adequately addressed. While the comment provides some constructive feedback on areas that need further attention, it could be more helpful by offering specific suggestions on how to address these limitations or improve the clarity of the abstract. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that UnKE's cause-driven optimization does not preserve pre-trained knowledge during the editing process, as evidenced by the results in Tables 2 and 3. It references a specific baseline, MMLU, and compares UnKE's performance to Src-Acc and Tgt-Acc. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their results. It lacks actionable steps or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that UnKE's cause-driven optimization does not preserve pre-trained knowledge during the editing process, as evidenced by the results in the tables. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that UnKE's cause-driven optimization does not preserve pre-trained knowledge during the editing process, as evidenced by the results in Tables 2 and 3. The reviewer references a specific baseline, MMLU, and compares UnKE's performance to Src-Acc and Tgt-Acc in these tables. This provides a clear and specific basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or references to the specific experiments or methods used to compare UnKE with the baseline. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s claim that UnKE\\'s cause-driven optimization preserves pre-trained knowledge during the editing process. It points out that the experiments in Tables 2 and 3 show otherwise, with UnKE performing worse than the baseline (MMLU) in terms of retaining original knowledge. This feedback is valuable as it highlights a critical discrepancy between the paper\\'s claims and the experimental results, prompting the authors to reconsider their methodology or interpretation. However, the comment could be more helpful if it provided suggestions on how to address this issue or improve the experimental setup. Overall, the comment is mostly helpful as it directs the authors\\' attention to a significant gap in their work, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the explanation for the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. However, it does not provide explicit guidance on how to improve the explanation or suggest specific changes to the paper. The action is implicit and vague, as the authors are left to infer that they need to provide a clearer explanation or reorganize the information in the main text. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the explanation for the intention of BWTP/GLBW and mentions that many details are in the appendix, making it difficult to understand at first sight. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing what needs to be improved, namely the clarity of the explanation and the location of relevant information. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanation for the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. However, the comment does not provide specific examples or references to support this claim, nor does it offer suggestions for improvement. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the explanation for the intention of BWTP/GLBW, noting that many details are in the appendix, making it difficult to understand at first sight. This feedback is somewhat helpful as it points out a clear area for improvement, namely providing a clearer and more accessible explanation of the concepts. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of how other similar concepts are explained in the literature. While it highlights an important issue, the feedback lacks depth and actionable guidance, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a proof for the lack of space, either in the main paper or as supplementary material. This is a clear and direct action, providing the authors with a specific task to address the omission. The comment also suggests that the proof might fit into the main paper, offering a potential alternative. The action is concrete, as it specifies where the proof should be included, and it is explicit, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a proof for the lack of space. The comment provides guidance on where the proof might fit, either in the main paper or as supplementary material. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a proof for the lack of space is missing at the end of Section 3. It provides a clear request to include the proof, either in the main paper or as supplementary material. However, the comment does not provide any supporting evidence or reasoning to justify why this proof is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of including this proof. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to fully support the suggestion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific omission in the paper, namely the lack of a proof for the lack of space at the end of Section 3. It provides a clear and actionable suggestion to include this proof, either in the main paper or as supplementary material. This feedback is valuable as it helps the authors ensure that their draft is complete and accurate. However, the comment could be more helpful if it explained why this proof is important or how it contributes to the overall understanding of the paper. Despite this, the feedback is still valuable as it directs the authors to a specific area for improvement, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide specific experimental results or references to support their claim that NPPs perform worse than ETAS. This feedback is explicit and provides a clear action for the authors to take, which is to include specific data or references to substantiate their argument. The comment is concrete because it specifies what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that specific experimental results or references should be provided to support the claim that NPPs perform worse than ETAS. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the results are discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for specific experimental results or references, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that specific experimental results or references should be provided to support the claim that NPPs perform worse than ETAS. However, the comment does not provide any reasoning or evidence to substantiate why this claim is valid or how it could be improved with specific results or references. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide specific experimental results or references to support their claim that NPPs perform worse than ETAS. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s argumentation, which could be addressed by providing more concrete evidence. However, the comment does not provide specific guidance on what kind of results or references would be most beneficial or how they could be integrated into the paper. While it points out an area for improvement, the lack of detailed suggestions limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the implementation details, specifically regarding the connectivity patterns between layers and their application to complex architectures like UNet, ResNet, and MobileNet. It points out that these details are not provided in the methodology section or the appendix, which raises concerns about understanding the paper. However, the comment does not explicitly instruct the authors on how to address this issue or provide specific guidance on how to incorporate these details. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed implementation information but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, including the methodology section, Equations 3 and 4, and Tables 1, 4, and 5. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the lack of clarity in the implementation details, particularly regarding the connectivity patterns between layers and their application to complex architectures like UNet, ResNet, and MobileNet. It also points out that these details are not included in the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the implementation details are unclear, specifically regarding the connectivity patterns between layers and their application to complex architectures like UNet, ResNet, and MobileNet. The reviewer notes that these details are not provided in the methodology section or the appendix, which raises concerns about understanding the paper. However, the comment lacks specific examples or references to support the claim that these details are necessary or how they would improve the clarity of the paper. Without detailed justification or examples, the claim is somewhat verifiable, as it provides a general observation but lacks the necessary evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the implementation details, particularly regarding the connectivity patterns between layers and their application to complex architectures like UNet, ResNet, and MobileNet. It points out that these details are not provided in the methodology section or the appendix, which raises concerns about understanding the paper. This feedback is valuable as it highlights a critical area for improvement in the paper, particularly for readers who may be unfamiliar with the specific architectures. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific sections or details to include in the methodology or appendix. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance on how to implement the suggested changes.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the scalability of the calculation of HTER label, which relies on automatic scripts, and suggests that the authors should experiment on other languages and annotations to verify its scalability. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors need to determine which other languages and annotations to test. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the calculation of HTER label, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the scalability of the calculation relying on automatic scripts and suggests that the authors should experiment on other languages and annotations to verify scalability. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the calculation of HTER label relies on automatic scripts, which may not be scalable to other annotations like MQM or DA. The reviewer suggests that the authors should experiment on other languages and annotations to verify the scalability. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the need for additional experiments based on the comment alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the calculation of HTER label, which relies on automatic scripts. It suggests that the authors should experiment on other languages and annotations to verify the scalability. This feedback is somewhat helpful as it points out a potential limitation in the methodology and provides a direction for improvement. However, the comment could be more helpful if it offered specific suggestions on which languages or annotations to test or how to conduct these experiments. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the dependence of overall performance on $m$ in $G_m$. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the performance dependence should be explored. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the dependence of overall performance on $m$ in $G_m$, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this question fits within the context. Additionally, the comment lacks specificity regarding what aspect of the performance dependence should be explored or how it could be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the dependence of overall performance on $m$ in $G_m$. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the dependence of overall performance on $m$ in $G_m$. While it highlights a potential area of interest, it does not provide any guidance or suggestions for how the authors might address this question or what aspects of the performance dependence should be explored. Without actionable feedback or context, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap between theory and practice in deep learning, specifically regarding the difficulty of fitting sparse neural networks. It suggests that the authors should comment on this issue to help readers understand the key elements that enable Causal-Stonet to learn sparse neural networks. While the comment implies that the authors should provide a comment or explanation, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the theoretical works on deep learning and the specific issue of sparse neural networks, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the theory-practice gap regarding the difficulty of fitting sparse neural networks and the need for the authors to comment on this issue to help readers understand the key elements that enable Causal-Stonet to learn sparse neural networks. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that theoretical works on deep learning do not reflect practice, specifically regarding the difficulty of fitting sparse neural networks. The reviewer supports this claim by referencing Farrell, Liang, and Misra ECTA 2021, which provides a specific example of the challenge in fitting sparse neural networks. This reference adds credibility to the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or additional references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a gap between theory and practice in deep learning, specifically regarding the difficulty of fitting sparse neural networks. It highlights this issue by referencing Farrell, Liang, and Misra ECTA 2021, which provides a persuasive argument for the challenge in fitting sparse neural networks. The comment recommends that the authors comment on this issue to help readers understand the key elements that enable Causal-Stonet to learn sparse neural networks. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could impact its applicability and relevance. However, it could be more helpful if it provided specific suggestions on how to address the gap or what aspects of the theory-practice gap should be emphasized. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and relevance of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors consider reducing the size of certain figures, such as Figure 2, and relocating tables to the Appendix, such as Table 1. It also mentions that these changes can be made in the camera-ready version if the paper is accepted. The action is clear and concrete, as it provides specific suggestions for improvement, and the authors know exactly what changes to make. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as reducing the size of certain figures and relocating tables to the Appendix. This level of detail provides the authors with clear instructions on how to improve the layout and presentation of their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the manuscript is densely packed in terms of space, with figures and tables positioned closely to the text, making the paper appear cluttered and condensed. The reviewer provides a specific example of Figure 2, suggesting it could be reduced in size. The comment also mentions the possibility of relocating tables to the Appendix, such as Table 1. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that this issue affects the readability or comprehension of the paper. Therefore, the claim is somewhat verifiable, as it provides a logical basis but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the layout and presentation of the manuscript, noting that the figures and tables are positioned too closely to the text, making the paper appear cluttered and condensed. It provides a clear and actionable suggestion to address this issue by considering the possibility of making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. This feedback is valuable as it offers a concrete way for the authors to improve the readability and clarity of their paper. However, the comment could be more helpful if it provided examples of how to achieve these changes or suggested alternative layout options. Overall, the comment is mostly helpful as it effectively guides the authors on how to enhance the presentation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should strengthen their article by providing stronger theoretical guarantees for their proposed ReCPE method. It also points out a minor issue with the spelling of \"real word\" in Note 2 on page 7. While the comment implies that the authors should address the theoretical aspect, it does not provide specific guidance on how to do so or what kind of theoretical guarantees would be sufficient. The suggestion to correct the spelling is explicit but not particularly actionable. Overall, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Note 2 on page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of strong theoretical guarantees for the ReCPE method and the need to strengthen the article from this perspective. The comment also mentions a minor issue with the spelling of \"real word\" in Note 2, providing clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ReCPE method proposed in the article is too strategic and lacks strong theoretical guarantees. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of \"intuitively\" suggests that the method may not be rigorous, but without further elaboration or references, the claim remains somewhat vague. The suggestion to strengthen the article by providing stronger theoretical guarantees is logical but lacks specific guidance on how to achieve this. Therefore, the comment is somewhat verifiable, as it provides a general direction but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the ReCPE method proposed is too strategic and lacks strong theoretical guarantees. It suggests that the authors could strengthen the article by providing stronger theoretical guarantees. Additionally, it points out a minor issue with the spelling of \"real word\" in Note 2 on page 7. While the comment highlights important areas for improvement, it lacks specific guidance on how to address the theoretical aspect or what kind of theoretical guarantees would be sufficient. The suggestion to correct the spelling is helpful but not central to the feedback. Overall, the comment provides some actionable feedback but could be more comprehensive and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the applicability of the method beyond NLU tasks, specifically asking if it can be applied to generation tasks. While this question implies that the authors should consider this aspect, it does not provide explicit guidance or suggestions on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider the applicability to generation tasks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the method beyond NLU tasks, specifically asking if it can be applied to generation tasks. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the applicability of the method to generation tasks, providing some guidance on what the authors should consider. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the applicability of the method beyond NLU tasks, specifically asking if it can be applied to generation tasks. However, it does not provide any supporting evidence, reasoning, or references to justify why this question is relevant or how it could impact the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the applicability of the method beyond NLU tasks, specifically asking if it can be applied to generation tasks. This is a relevant point that could prompt the authors to consider the broader applicability of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or explore the applicability to generation tasks. While it points out an area for consideration, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that $N_d$ is not defined and suggests that the authors should state explicitly that there could be a different number of observations per task. This feedback provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to address the issue. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.145ff,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of definition for $N_d$ and the potential for different numbers of observations per task. This provides clear guidance on what needs to be clarified or added to the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"$N_d$ is not defined\" and suggests that the authors should state explicitly that there could be a different number of observations per task. This is a factual observation about the content of the paper, which does not require an opinion or subjective judgment. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that $N_d$ is not defined and suggesting that the authors should state explicitly that there could be a different number of observations per task. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending a specific clarification that could enhance the paper\\'s clarity. By addressing this point, the authors can ensure that their work is more accessible and understandable to readers. Therefore, the comment is mostly helpful, as it offers a concrete and constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the appendix is not cut from the main paper and that the PDF provided for the main paper is a 14-page document. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Appendix\" and the \"main paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the appendix is not cut from the main paper and that the PDF provided for the main paper is a 14-page document. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the appendix is not cut from the main paper and that the PDF provided for the main paper is a 14-page document. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the formatting of the paper, noting that the appendix is not cut from the main paper and that the PDF provided for the main paper is a 14-page document. While this feedback highlights a potential problem, it does not provide any actionable suggestions or guidance on how the authors might address this issue. Without additional context or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide more information on the ternary potential, which appears to be the main source of improvement in the proposed model. It highlights that without the ternary potential, the model does not outperform existing models for a two-modality setup, except for HieCoAtt. This feedback is clear and directs the authors to focus on the ternary potential, providing a specific area for further exploration or explanation. The action is explicit and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the main improvement in the proposed model seems to come from the ternary potential, and that without it, the model does not outperform existing models for a two-modality setup, except for HieCoAtt. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main improvement in the proposed model comes from the ternary potential, and that without it, the model does not outperform existing models for a two-modality setup, except for HieCoAtt. This claim is somewhat verifiable as it is based on the results presented in Table 1, which provides some evidence for the claim. However, the comment lacks specific examples or detailed analysis of the ternary potential or how it contributes to the model\\'s performance. Providing more detailed reasoning or references to support the claim would strengthen its verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the performance of the proposed model, particularly in relation to the ternary potential. It points out that without the ternary potential, the model does not outperform existing models for a two-modality setup, except for HieCoAtt. This feedback is valuable as it highlights a potential weakness in the model\\'s performance and encourages the authors to explore the role of the ternary potential further. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific aspects of the ternary potential should be investigated. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide additional information in the tables to help assess the degree of apples-to-applesness of the comparisons. It explicitly states that the authors should note which methods use data augmentations, what architecture they use, and what objective they perform. This feedback is clear and provides concrete details on what the authors need to add to their tables to improve clarity. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"tables\" and suggests specific improvements to be made, such as noting which methods use data augmentations, what architecture they use, and what objective they perform. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what additional information is needed to enhance the comparisons in the tables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide additional information in the tables to help assess the degree of apples-to-applesness of the comparisons. It provides a specific request for details, such as noting which methods use data augmentations, what architecture they use, and what objective they perform. This claim is somewhat verifiable as it logically suggests that such information could enhance the clarity of the comparisons, but it lacks specific examples or references to support the need for these details. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the clarity of the tables by noting which methods use data augmentations, what architecture they use, and what objective they perform. This feedback is specific and detailed, offering the authors a concrete way to enhance the comparisons in their tables and improve the overall understanding of their work. By addressing these points, the authors can significantly improve the clarity and comprehensiveness of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the paper\\'s claims regarding the superiority of hyperpruning methods over state-of-the-art architectures, specifically mentioning the use of LSTM and LSH networks. It suggests that the authors should explore how LSH would perform on more recent state-of-the-art models and benchmarks, such as the PTB benchmark, which is described as a small data set. The comment also points out that the results may not generalize to other architectures or datasets. While the comment provides a clear direction for the authors to address these concerns, it does not explicitly instruct them to conduct these experiments or provide detailed guidance on how to do so. The action is implicit but concrete, as the authors can infer the need to conduct additional experiments and clarify their claims. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"hyperpruning methods\" and the \"LSTM and LSH networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the validity of the paper\\'s claims regarding the superiority of hyperpruning methods over state-of-the-art architectures, and suggests exploring how LSH would perform on more recent state-of-the-art models and benchmarks. Additionally, it points out the limitations of the PTB benchmark as a small data set. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the paper\\'s claims regarding the superiority of hyperpruning methods over state-of-the-art architectures, specifically mentioning the use of LSTM and LSH networks. The reviewer questions the validity of these claims by pointing out that these architectures are not state-of-the-art for language modeling. The comment suggests exploring how LSH would perform on more recent state-of-the-art models and benchmarks, such as the PTB benchmark, which is described as a small data set. The reviewer acknowledges that the result is still of academic interest. The claim is mostly verifiable as it provides logical reasoning and references to common practices in the field, but it lacks specific examples or references to recent models or benchmarks to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the paper\\'s claims regarding the superiority of hyperpruning methods over state-of-the-art architectures, specifically questioning the use of LSTM and LSH networks as benchmarks. It suggests that the authors should explore how LSH would perform on more recent state-of-the-art models and benchmarks, such as the PTB benchmark, which is described as a small data set. This feedback is valuable as it highlights a potential weakness in the paper\\'s claims and offers a clear direction for the authors to address it. However, the comment could be more helpful if it provided specific suggestions on how to conduct these additional experiments or what specific benchmarks to use. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance the robustness of their claims.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include more experimental details, specifically mentioning neural networks and hyperparameters used, in the appendix. This provides a clear and direct action for the authors to take, ensuring they know exactly what information to add to their draft. The comment is specific and provides concrete guidance on how to enhance the transparency and reproducibility of their experiments. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more experimental details, specifically neural networks and hyperparameters used, should be included in the appendix. However, it does not specify which part of the paper this information is currently lacking or where it should be added. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. The comment is specific in its request for additional details but lacks full grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experimental details, specifically neural networks and hyperparameters used, should be included in the appendix. However, it does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more experimental details, specifically neural networks and hyperparameters used, should be included in the appendix. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending additional transparency and reproducibility. However, the comment lacks specific guidance on how to present this information or why it is crucial for the paper. While it points out a potential gap, it does not provide detailed suggestions or examples on how to address it effectively. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Section 5.1 does not provide sufficient information regarding why the new model is superior. However, it does not explicitly instruct the authors on what specific information should be included or how to present it. The comment lacks concrete guidance on how to address this issue, leaving the authors uncertain about what actions to take. As a result, the comment is somewhat actionable, as it identifies a gap but does not provide detailed instructions on how to fill it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information regarding why the new model is superior. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 5.1 does not provide useful information regarding why the new model is superior. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Section 5.1, noting that it does not provide sufficient information regarding why the new model is superior. This feedback is somewhat helpful as it points out a gap in the paper that the authors need to address. However, the comment lacks depth and does not offer specific suggestions or examples of what information should be included to make the section more comprehensive. While it highlights an area for improvement, it does not provide actionable guidance, making it somewhat helpful but not fully comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the single-IMP might have transferability, but not as strong as the original IMP. It implies that a comparison is necessary to evaluate this transferability. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the single-IMP might have transferability, but not as strong as the original IMP. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the comparison is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the transferability should be compared or how the comparison should be conducted. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the single-IMP might have transferability, but not as strong as the original IMP. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the single-IMP might have transferability, but not as strong as the original IMP. It implies that a comparison is necessary to evaluate this transferability. However, the comment lacks specificity and does not provide guidance on how to conduct this comparison or what aspects to focus on. Without detailed instructions or examples, the authors may find it challenging to understand and implement the suggested improvement. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider checking human-factors literature to address the practical challenges of interacting with humans. While the comment implies that the authors should conduct additional research, it does not provide specific guidance on which human-factors literature to consult or how to integrate this literature into their work. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.03. 2020,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of specific ethical concerns with the proposed methods and the need to consider human-factors literature to address practical challenges. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are no specific ethical concerns with the proposed methods and that the limitations are related to practical challenges in interacting with humans. The reviewer supports this claim by mentioning some limitations and suggesting that the authors should consider human-factors literature to address these challenges. However, the comment lacks specific examples or references to the limitations or human-factors literature that would strengthen the claim. While the suggestion is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of ethical concerns related to the proposed methods. It also highlights some limitations and practical challenges in interacting with humans, which are discussed in the weaknesses and suggestions section. The reviewer suggests that the authors should consider checking human-factors literature to address these challenges. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific examples of human-factors literature or guidance on how to integrate this literature into the paper. Overall, the comment is mostly helpful as it points out a critical area for improvement but could be more actionable with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the scalability of the proposed model selection approach beyond MNIST-like datasets and suggests comparing it with other neural network pruning methods. While it implies that the authors should consider these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments being conducted in \"MNIST-fashion\" datasets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scalability of the proposed model selection approach beyond MNIST-like datasets and suggesting a comparison with other neural network pruning methods. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the scalability of the proposed model selection approach beyond MNIST-like datasets and suggests comparing it with other neural network pruning methods. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the results. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the scalability of the proposed model selection approach beyond MNIST-like datasets. It suggests that the authors should consider whether the approach can be applied to other datasets and questions the need for a comparison with other neural network pruning methods. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address these concerns. The authors are left with a general idea of what needs to be explored but without detailed instructions on how to do so. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide actionable steps for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several mathematical formulation issues and inconsistencies in the paper, providing specific examples and suggestions for improvement. It explicitly points out errors in line 345, 347, and 374, suggesting corrections such as \"$max$\" and \"$i$-th objective\" for clarity. Additionally, it highlights inconsistencies in index notation and the use of \"$i$\" in different contexts. The comment also questions the use of \"$x'$\" in the hypervolume formula and suggests it might be redundant. Each of these points is clear and actionable, providing the authors with specific guidance on how to correct errors and improve the clarity of their mathematical formulations. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also provides detailed and specific feedback on each issue, such as the incorrect use of \"$max$\" in line 345, the inconsistent use of \"$i$\" in different contexts, and the redundancy of \"$x'$\" in the hypervolume formula. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies several mathematical formulation issues and inconsistencies in the paper, providing specific examples and suggestions for correction. These claims are supported by detailed explanations of the errors, such as the incorrect use of \"$max$\" and \"$i$-th objective,\" and the inconsistent use of \"$i$\" in different contexts. The reviewer also questions the use of \"$x'$\" in the hypervolume formula, suggesting it might be redundant. This level of detail and specificity makes the claims mostly verifiable, as the authors can easily identify and correct the errors. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies several mathematical formulation issues and inconsistencies in the paper, providing specific examples and suggestions for correction. It highlights errors such as the incorrect use of \"$max$\" and \"$i$-th objective,\" inconsistent index notation, and the redundancy of \"$x'$\" in the hypervolume formula. By pointing out these errors, the comment offers clear and actionable feedback that can help the authors improve the clarity and accuracy of their mathematical formulations. However, the comment could be more helpful if it provided additional guidance on how to address these issues or explained why they are important for the paper. Overall, the comment is mostly helpful as it directs the authors to specific areas needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include experiments demonstrating the effect of using different numbers of particles. This feedback is explicit, as it directly instructs the authors to include such experiments. However, it does not provide specific guidance on how to conduct these experiments or what specific aspects to focus on. While the action is clear, the lack of detailed instructions on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that experiments demonstrating the effect of using different numbers of particles would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of experiments, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that experiments demonstrating the effect of using different numbers of particles would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this would be important or how it would impact the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that experiments demonstrating the effect of using different numbers of particles would be beneficial. It highlights the current lack of clarity regarding the importance of this choice. However, the comment does not provide specific guidance on how to conduct these experiments or what aspects to focus on. While it identifies a potential area for improvement, the feedback is incomplete and lacks actionable details, making it somewhat helpful. The authors are given a direction but not enough information to fully address the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks a comparison of the methods on plasticity evaluation metrics, specifically mentioning the covariance metric [1]. This provides a clear and direct action for the authors to take, which is to include such a comparison in their paper. The comment is specific and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comparison of methods on plasticity evaluation metrics, specifically referencing the covariance metric [1]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added, namely a comparison of methods on plasticity evaluation metrics. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric [1]. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this comparison and how it could improve their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, namely the absence of a comparison of methods on plasticity evaluation metrics, such as the covariance metric [1]. This feedback is clear and actionable, as it points out a specific gap in the paper that the authors can address to enhance its comprehensiveness and rigor. By including this comparison, the authors can demonstrate the effectiveness and relevance of their methods in the context of plasticity evaluation. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or suggested specific metrics to consider. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide better explanations for Table 5, specifically asking for clarification on the meaning of A, B, C, and D in the table and why positive paths lead to monotonic solutions under certain scenarios. This feedback is clear and concrete, as it specifies exactly what needs to be addressed and provides a clear direction for the authors to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of A, B, C, and D in Table 5 and the reason why positive paths lead to monotonic solutions under certain scenarios. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of explanation in Table 5 and questions the meaning of A, B, C, and D. It also suggests that the authors should provide an explanation for why positive paths lead to monotonic solutions under certain scenarios. While the comment identifies specific areas that need clarification, it does not provide detailed reasoning or examples to support the claim that these explanations are necessary. The lack of specific examples or references makes the claim somewhat verifiable, as the authors would need to infer the importance of these explanations themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 5, noting that it lacks an explanation for the terms A, B, C, and D. It also questions why positive paths lead to monotonic solutions and under what scenarios. This feedback is clear and actionable, as it directs the authors to provide a better explanation for the table and its content. By addressing these points, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this explanation or provided examples of how similar tables have been explained in other works. Overall, the comment is mostly helpful as it effectively guides the authors on how to enhance the clarity of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the long time it takes to obtain a single US accuracy and suggests exploring proxy/surrogate ways to estimate this cost. It also questions the reliability of early predictions of US accuracy for model selection, referencing Figure 1 and Appendix Figures F6-F9. However, the comment does not provide explicit guidance on how to implement these suggestions or what specific steps to take. The authors are left to infer that they should explore proxy/surrogate methods and consider the reliability of early predictions, but without concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Appendix Figures F6-F9,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the reliability of early predictions of US accuracy for model selection, given the saturation of the curve in Figure 1. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the long time it takes to obtain a single US accuracy and suggests exploring proxy/surrogate ways to estimate this cost. It questions the reliability of early predictions of US accuracy for model selection, referencing Figure 1 and Appendix Figures F6-F9. However, the comment lacks specific examples or detailed reasoning to support the claim that early predictions are unreliable. While it highlights a potential issue, the lack of detailed evidence or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the long time it takes to obtain a single US accuracy and suggests exploring proxy/surrogate ways to estimate this cost. It also questions the reliability of early predictions of US accuracy for model selection, referencing Figure 1 and Appendix Figures F6-F9. This feedback is somewhat helpful as it identifies a potential issue with the accuracy estimation process and suggests a direction for further exploration. However, the comment could be more helpful if it provided specific suggestions or examples of proxy/surrogate methods that could be used. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct ablation studies to isolate the impact of specific factors underlying epsilon sampling's strong performance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific suggestion for additional analysis, which is concrete and leaves no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. However, it does not specify which part of the paper should include these studies or which factors should be analyzed. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding which factors should be analyzed or how they should be isolated. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests conducting ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. However, it does not provide any supporting evidence, reasoning, or examples to justify why these ablation studies are necessary or how they would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. This is a clear and actionable suggestion that could help the authors understand and improve the performance of their method. By providing detailed guidance on how to conduct these studies, the comment offers a concrete step for the authors to take in order to enhance their draft. However, the comment could be more helpful if it provided specific examples of which factors to analyze or how to conduct the ablation studies. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate the proposed attack against the mode connectivity-based defense proposed in the ICLR paper. This is an explicit action that the authors can directly implement by referencing the ICLR paper and conducting the requested evaluation. The comment provides a clear direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the ICLR publication \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is evaluating the proposed attack against the mode connectivity-based defense proposed in the ICLR paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the effectiveness of Fine-Tuning in recovering backdoor models, referencing the ICLR publication \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness.\" However, the comment does not provide specific details or evidence from the referenced work to support this claim. It suggests that the proposed attack should be evaluated against the mode connectivity-based defense proposed in the ICLR paper, but without further explanation or examples, the claim remains somewhat verifiable. The authors would need to conduct additional research to fully understand and address the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by referencing a previous work that suggests Fine-Tuning may not be the most effective approach for recovering backdoor models. It suggests that the authors should evaluate the proposed attack against the mode connectivity-based defense proposed in the ICLR paper. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their work by conducting an additional evaluation. However, the comment could be more helpful if it offered guidance on how to conduct this evaluation or provided examples of what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors\\' decision to not include the codes during the review process makes their claims less transparent. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should include the codes, how they should present them, or what potential benefits this might have. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' decision to not include the codes during the review process, which affects the transparency of their claims. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the presentation of results or methodology, but this inference is not direct. The comment is specific in identifying the issue of transparency due to the absence of codes, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' decision to not include the codes during the review process makes their claims less transparent. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the transparency of their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the transparency of the authors\\' claims due to their decision not to include the codes during the review process. This is a relevant point that could impact the credibility and reproducibility of their work. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue, such as explaining the rationale behind the decision or proposing ways to improve transparency. While it points out a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should validate their proposed approach in Waymax, which provides more traffic scenarios than the current version. This is an explicit action for the authors to take, as it clearly specifies the need for validation and the potential benefits of using a larger dataset. However, the comment does not provide detailed guidance on how to implement this validation or what specific aspects of the approach should be tested. While the action is clear, the lack of concrete details on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should validate their proposed approach in Waymax, which provides more traffic scenarios than the current version. However, it does not specify which part of the paper this validation should be included in, such as a specific section or experiment. Additionally, it lacks specificity regarding what aspects of the approach should be tested or how the validation should be conducted. Without clear guidance on where to integrate this suggestion, the authors may struggle to effectively address the feedback. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should validate their proposed approach in Waymax, which provides more traffic scenarios than the current version. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this validation is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should validate their proposed approach in Waymax, which provides more traffic scenarios than the current version. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a larger dataset for validation. However, the comment lacks specific guidance on how to implement this validation or what aspects of the approach should be tested. Additionally, it does not provide detailed reasoning or examples of how this validation would benefit the paper. While the suggestion is actionable, the lack of depth and specificity limits its usefulness for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the technical contribution of the paper, noting that the transformer-based TAPG method has been studied in previous works like RTD-Net (ICCV2021). It points out that the main difference between RTD-Net and the proposed method is the visual features, and that the paper considers 3D pose and action features obtained by Laban Movement Analysis (LMA). However, the reviewer suggests that the use of additional features is not surprising and may not bring significant insights to the community. While the comment identifies a potential issue with the novelty of the contribution, it does not provide explicit guidance on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should focus on demonstrating the novelty and significance of their contribution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the paper, specifically mentioning the transformer-based TAPG method and its relation to previous works like RTD-Net (ICCV2021). It highlights the main difference between RTD-Net and the proposed method, which is the visual features, and notes that the paper considers 3D pose and action features obtained by Laban Movement Analysis (LMA). However, the reviewer suggests that the use of additional features is not surprising and may not bring significant insights to the community. While the comment is specific in its critique of the technical contribution, it does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is not significant, as the transformer-based TAPG method has been studied in previous works like RTD-Net (ICCV2021). The reviewer suggests that the main difference between RTD-Net and the proposed method is the visual features, and that the paper considers 3D pose and action features obtained by Laban Movement Analysis (LMA). However, the reviewer argues that the use of additional features is not surprising and may not bring significant insights to the community. The claim is somewhat verifiable as it provides a logical reasoning for why the contribution might not be groundbreaking, but it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the technical contribution of the paper, noting that the transformer-based TAPG method has been studied in previous works like RTD-Net (ICCV2021). It points out that the main difference between RTD-Net and the proposed method is the visual features, and that the paper considers 3D pose and action features obtained by Laban Movement Analysis (LMA). However, the reviewer suggests that the use of additional features is not surprising and may not bring significant insights to the community. This feedback highlights a potential weakness in the paper\\'s contribution, suggesting that the authors should consider whether their method offers novel insights or improvements over existing works. While the comment identifies a specific area for improvement, it lacks detailed guidance or suggestions on how the authors might address this issue or enhance their contribution. Therefore, the comment is somewhat helpful, as it provides some direction but could be more comprehensive to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the implementation of tree construction requires more experimental comparisons, specifically regarding the different design choices of merging nodes among adjacent layers. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on which comparisons to make or how to conduct them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the implementation of tree construction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for more experimental comparisons regarding the different design choices of merging nodes among adjacent layers. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the implementation of tree construction requires more experimental comparisons, specifically regarding the different design choices of merging nodes among adjacent layers. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these comparisons are necessary or how they would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the implementation of tree construction, particularly regarding the different design choices of merging nodes among adjacent layers. It suggests that more experimental comparisons are needed to fully explore the implications of these design choices. While the comment highlights an important aspect of the paper that could be strengthened, it lacks specific guidance on which comparisons to conduct or how to present the results. This limits the comment\\'s helpfulness, as it provides a general direction but does not offer detailed suggestions for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that Table 2 in the paper is incomplete and suggests that the authors should include several baselines that outperform their work, as reported in the Re-BART paper. This feedback provides a clear and direct action for the authors to take, which is to include these baselines in the table. The comment also mentions that the results are slightly weak, but this does not affect the actionability of the suggestion. Therefore, the comment is highly actionable as it provides a specific and concrete action for the authors to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Re-BART paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of several baselines that outperform the paper, and it suggests that the paper should report them for completeness, even though their results are slightly weak. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 2 in the paper is incomplete and suggests that the authors should include several baselines that outperform their work, as reported in the Re-BART paper. The comment provides a logical reasoning by pointing out the omission of these baselines and the need for completeness. However, it lacks specific examples or references to the Re-BART paper, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but could be more robust with additional evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 2 in the paper, noting that it is incomplete and that several baselines that outperform the paper are not included. It suggests that the authors should include these baselines for completeness, even though their results are slightly weak. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that can enhance the comprehensiveness and accuracy of the paper. However, the comment could be more helpful if it explained why the inclusion of these baselines is important or how it would impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluations on real datasets could be more thorough and questions why only three scenes are chosen from the HS-ERGB dataset. It also asks about the performance on other sequences. While the comment implies that the authors should expand their evaluation to include more scenes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the evaluations on real datasets could be more thorough and questions why only three scenes are chosen from the HS-ERGB dataset. It also asks about the performance on other sequences. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its request for more thorough evaluations and the inclusion of other sequences, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the thoroughness of the evaluations on real datasets and specifically inquires about the choice of only three scenes from the HS-ERGB dataset. It suggests that the performance on other sequences should be considered. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these additional sequences are necessary or how they would impact the evaluation. Without such justification, the claim remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the evaluation section, specifically questioning the thoroughness of the evaluations on real datasets. It suggests that the choice of only three scenes from the HS-ERGB dataset could be expanded to include other sequences, which could provide a more comprehensive understanding of the model's performance. This feedback is clear and actionable, as it prompts the authors to consider expanding their evaluation to include additional sequences. However, the comment could be more helpful if it provided specific guidance on which sequences to include or how to conduct the expanded evaluation. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the size of 44 and suggests that there is plenty of room to use more bits. It also questions the interpretation of bit-embeddings, noting that the model is predicting the rank of words and suggesting that this might be due to the model's power. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The feedback lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the size of 44 and the potential for using more bits, as well as the interpretation of bit-embeddings and the role of the model in predicting word ranks. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the interpretation of bit-embeddings and the role of the model in predicting word ranks. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the size of 44 and suggests that there is plenty of room to use more bits. It also questions the interpretation of bit-embeddings, noting that the model is predicting the rank of words, which is counter-intuitive. The reviewer suggests that this might be due to the model's power, rather than semantic relations between words. While the comment identifies potential issues and questions, it lacks specific examples or references to support the claims about the model's behavior or the interpretation of bit-embeddings. This makes the claim somewhat verifiable, as it provides some insight but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the size of 44 and suggests that there is plenty of room to use more bits. It also questions the interpretation of bit-embeddings, noting that the model is predicting the rank of words, which is counter-intuitive. The reviewer raises a valid point about the potential impact of the model's power on the interpretation of bit-embeddings. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. While it highlights areas for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the practical use of the method, specifically the requirement for human annotation to provide semantically meaningful information. It points out that the authors mention this limitation in the appendix but do not provide a solution for mitigation. While the comment highlights a gap in the paper, it does not explicitly instruct the authors on what steps to take to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider providing a solution for mitigation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed solution, which requires human annotation for semantically meaningful information, and points out the lack of a solution for mitigation. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed solution requires human annotation, which can be subjective, and that the authors mention this limitation in the appendix but do not provide a solution for mitigation. The comment is somewhat verifiable as it highlights a potential issue with the practicality of the method, but it lacks specific examples or references to support the claim about the subjectivity of human annotation. The mention of the appendix suggests that the authors have acknowledged the issue, but the comment could be strengthened by providing more detailed reasoning or examples to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the practicality of the proposed solution, specifically the requirement for human annotation to provide semantically meaningful information. It points out that this limitation is acknowledged in the appendix but that no solution for mitigation is provided. This feedback is somewhat helpful as it highlights a gap in the paper that the authors should address to improve the practicality and applicability of their method. However, the comment could be more helpful if it suggested specific ways to mitigate this limitation or provided examples of alternative approaches. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests two actions for the authors: pretrain a CausalLM using a specific dataset and compare its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. While the actions are explicit, the comment lacks concrete details on how to implement these tasks, such as which dataset to use or how to compare performance. The authors are left with a clear direction but without specific guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests two specific actions: pretraining a CausalLM using a mixed dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, it does not specify which part of the paper these actions should be implemented in, making it weakly grounded. The comment is specific in detailing what needs to be done, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests two actions: pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these actions are necessary or how they would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides two specific and actionable suggestions for the authors to improve their draft. First, it recommends pretraining a CausalLM using a specific dataset and mixed with others used by ObscuraCoder, except for obfuscated ObscuraX. This suggestion could help the authors explore and compare different approaches to achieving their goals. Second, it suggests comparing the performance of the pretrained CausalLM against ObscuraCoder to attribute any improvements to the deobfuscation objective. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their work. However, the comment could be more helpful if it provided additional context or examples of how to implement these suggestions effectively. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a minor issue with the loss equation in the paper, specifically noting that the geometric loss should be added to the reconstruction loss, rather than itself. This is a clear and direct action for the authors to take, as it provides a specific correction to make in the draft. The comment is explicit and concrete, giving the authors a clear idea of what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific lines \"L264-L266,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the loss equation, suggesting that the geometric loss should be added to the reconstruction loss rather than itself. This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the loss equation in the paper has an issue with the geometric loss being added to the reconstruction loss, rather than itself. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a minor issue with the loss equation in the paper, specifically noting that the geometric loss should be added to the reconstruction loss, rather than itself. This is a clear and actionable suggestion that can help the authors improve the accuracy and clarity of their presentation. However, the comment could be more helpful if it provided additional context or explanation on why this correction is necessary or how it affects the overall understanding of the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, which can enhance the clarity and correctness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method should be employed in autoregressive language models, which are used more in real-world applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to implement this suggestion or what specific aspects of the method should be applied to autoregressive language models. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make or how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method should be employed in autoregressive language models, which are used more in real-world applications. However, it does not specify which part of the paper discusses the method or where it should be applied. The authors cannot confidently determine which section or aspect of the paper is being addressed, making this comment weakly grounded. The comment is specific in suggesting that the method should be applied to autoregressive language models, but without clear grounding, it lacks actionable guidance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method should be employed in autoregressive language models, which are used more in real-world applications. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the method should be employed in autoregressive language models, which are used more in real-world applications. This is a relevant point as it highlights the potential applicability of the method to a broader range of applications. However, the comment lacks specific guidance or suggestions on how to implement this suggestion or what aspects of the method should be adapted for autoregressive language models. Without actionable advice or detailed reasoning, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim the GAN is difficult to optimize and use adversarial gradient updating, but it does not provide a clear explanation of why the proposed idea is better than GAN. Additionally, it notes that the method section lacks discussion on how to avoid the issue of vanishing gradient and model collapsing. While the comment identifies areas for improvement, it does not offer specific guidance on how to address these issues or what aspects of the method should be expanded upon. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations and examples in the method section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim about the difficulty of optimizing and using adversarial gradient updating with a GAN, as well as the lack of discussion on how to avoid vanishing gradient and model collapsing. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for more explanation and discussion on these topics in the method section. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the GAN is difficult to optimize and use adversarial gradient updating, suggesting that the proposed idea is not better than GAN. It also points out the lack of discussion on how to avoid vanishing gradient and model collapsing in the method section. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support its claims. The authors may find it challenging to understand the basis of the critique without additional context or evidence. Therefore, the comment is somewhat verifiable, as it highlights areas for improvement but lacks comprehensive justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the claim that the GAN is difficult to optimize and use adversarial gradient updating. It points out that the authors have not provided a clear explanation of why their proposed idea is better than GAN, which is a crucial aspect of the paper. Additionally, the comment highlights the lack of discussion on how to avoid the issue of vanishing gradient and model collapsing in the method section. This feedback is valuable as it directs the authors to clarify their claims and provide more detailed explanations in the method section. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of alternative approaches. Overall, the comment is mostly helpful as it identifies important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the design of the ablation study, specifically asking why the ablations are conducted on BART and BART+Longformer instead of the original model, GraphSum. While the comment implies that the authors should reconsider their choice of models for the ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their model selection but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study\" and the specific models involved, \"BART and BART+Longformer,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of models for the ablation study, asking why the original model, GraphSum, is not used. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of models for the ablation study, specifically asking why BART and BART+Longformer are used instead of the original model, GraphSum. However, the comment does not provide any reasoning or evidence to support why this choice might be problematic or inappropriate. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the choice of models for the ablation study, specifically questioning why BART and BART+Longformer are used instead of the original model, GraphSum. This feedback prompts the authors to reconsider their model selection, which could lead to a more comprehensive and informative ablation study. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative models might be more appropriate. While it identifies a potential area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the removal of the previous report on SciBERT and notes that this exacerbates an earlier problem in the first version where the analyses of the outcomes were cursory and unsupported by deeper analyses. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of the cursory analyses or how to improve the depth of the analyses. The comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the removal of the previous report on SciBERT and notes that this exacerbates a problem in the first version where the analyses of the outcomes were cursory and unsupported by deeper analyses. However, it does not specify which part of the paper this issue is related to, such as the sections where the analyses are discussed or the specific analyses that need improvement. The comment is specific in identifying the issue of cursory analyses, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the removal of the previous report on SciBERT exacerbates a problem in the first version where the analyses of the outcomes were cursory and unsupported by deeper analyses. However, the comment does not provide any specific examples or references to support this claim. It lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the removal of the previous report on SciBERT and notes that this exacerbates an earlier problem in the first version where the analyses of the outcomes were cursory and unsupported by deeper analyses. However, it does not provide any actionable feedback or suggestions for improvement. The comment highlights an issue but lacks guidance on how the authors might address it or what specific changes could be made to improve the depth and rigor of the analyses. Without actionable advice or constructive feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the \"Functional connectivity encoder\" section, specifically questioning the origin of the connectivity graph $\\\\cal{G}_{F}$ and the source of patches and their mixing process. While the comment identifies areas that need clarification, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or examples, but the comment lacks concrete steps or suggestions on how to improve the clarity. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Functional connectivity encoder\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the origin of the connectivity graph $\\\\cal{G}_{F}$ and the source of patches and their mixing process. This provides clear guidance on what needs to be clarified in the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the origin of the connectivity graph $\\\\cal{G}_{F}$ and the source of patches and their mixing process in the \"Functional connectivity encoder\" section. However, it does not provide any supporting evidence, reasoning, or references to justify why these aspects are unclear or problematic. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the origin of the connectivity graph $\\\\cal{G}_{F}$ and the source of patches and their mixing process in the \"Functional connectivity encoder\" section. This feedback is clear and actionable, as it points out areas where the authors need to provide more detailed explanations or examples to improve the clarity of their work. However, the comment could be more helpful if it suggested specific ways to address these issues, such as providing examples of how the connectivity graph is generated or how patches are mixed. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a longer discussion of related work, which could help substantiate the claim that the proposed method results in faster training. However, it does not explicitly instruct the authors to include this discussion or provide specific guidance on what aspects of related work should be covered. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of related work to address the reviewer's concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4(b)\" and \"the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that the proposed method results in faster training, suggesting that the figure does not provide sufficient evidence. Additionally, the comment suggests a need for a longer discussion of related work, which is specific in terms of what the authors should address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that Figure 4(b) indicates faster training results with the proposed method. The reviewer suggests that the figure does not provide sufficient evidence and points out that all networks are trained for the same number of epochs. Additionally, the reviewer mentions that pruning is a large field and suggests that a longer discussion of related work would benefit the paper. While the comment provides logical reasoning and references to the field of pruning, it lacks specific examples or references to support the claim that Figure 4(b) does not provide sufficient evidence. This makes the claim somewhat verifiable, as the authors would need to further explore the evidence themselves to fully address the reviewer\\'s concerns.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, questioning the claim that Figure 4(b) indicates faster training results with the proposed method. It points out that all networks are trained for the same number of epochs, which undermines the claim of faster training. Additionally, the reviewer suggests that the paper would benefit from a longer discussion of related work in the field of pruning. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a way to enhance the paper\\'s credibility by addressing the related work issue. However, the comment could be more helpful if it offered specific examples or references to related work that should be included in the discussion. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear path for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific error in the derivative calculation of the Lagrangian, noting that the correct derivative should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. This is a clear and explicit correction, providing the authors with a direct action to take. The comment is specific and concrete, giving the authors a precise calculation to correct, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"derivative of the 'Lagrangian'\" and the specific calculation involving \"n^{-1/2}\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the correct calculation for the derivative, providing a clear direction for the authors to make a correction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivative of the Lagrangian is incorrect, specifically stating that the correct derivative should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. The reviewer provides a correct calculation to support the claim, which is a clear and logical reasoning. This makes the claim mostly verifiable, as it is based on a specific mathematical calculation and is not overly subjective. However, the comment could be strengthened by providing a reference or explanation of why this specific calculation is important or how it affects the overall analysis. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific error in the calculation of the derivative of the Lagrangian, noting that the correct value should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. This is a clear and actionable piece of feedback that can help the authors correct a mistake in their calculations. However, the comment could be more helpful if it provided additional context or explanation about why this error occurred or how it affects the overall analysis. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing correction, which can improve the accuracy and credibility of their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is not clear and points out that the introduction lacks background information about cognitive models. It implies that the authors should refine their writing to provide more context and background. However, the comment does not specify what aspects of the writing need improvement or how to address the lack of background information. While the action is implied, it is not explicit, and the authors are left to infer what changes are needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is not clear and points out that the introduction lacks background information about cognitive models. However, it does not specify which part of the paper this issue is related to, such as the introduction or a particular section. The authors can infer that it relates to the introduction, but this inference is not direct. The comment is specific in suggesting that the writing needs refinement, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not clear due to a lack of background information about cognitive models in the introduction. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specificity and does not offer guidance on how the authors might address the issue of clarity. As a result, the claim is not verifiable, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly in the introduction section. It points out that the background information about cognitive models is lacking, suggesting that the authors may need to refine their writing to provide more context. While the comment highlights an area for improvement, it does not offer detailed guidance or suggestions on how to address this issue. The authors are given a general direction but lack specific steps to take, making the feedback somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the performance of DFA and backprop on the NLP task, suggesting that the authors should emphasize this issue more clearly. However, it does not provide specific guidance on how to address this discrepancy or what aspects of the paper should be revised to better emphasize the performance gap. The comment implies that the authors should make a stronger case for the performance of DFA, but it lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"NLP task,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the DFA performance lags behind backprop performance on this task and suggests that this is not sufficiently emphasized in the paper. The comment further highlights the discrepancy between the abstract and the actual performance, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of DFA on the NLP task is not sufficiently emphasized in the paper, particularly in comparison to backprop performance. The reviewer provides a specific example of the abstract, which gives the impression that DFA works at near-backprop levels on this task. However, the comment lacks detailed evidence or references to support the claim that DFA performance is significantly behind backprop performance. Without specific data or comparisons, the claim is somewhat verifiable, as it requires the authors to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of DFA on the NLP task, noting that it lags behind backprop performance. This is a critical observation that could impact the authors\\' claims about the effectiveness of their method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or emphasize it more effectively in the paper. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation. It suggests including specific methods, such as SRW and FROT, as baselines. This feedback provides clear and concrete guidance on what the authors need to do to improve their draft, namely, to include these methods as baselines. The action is explicit and the authors know exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"baseline\" and \"dimensional reduction methods in optimal transport estimation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of specific methods like SRW and FROT as baselines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation. The reviewer suggests including specific methods, such as SRW and FROT, as baselines. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these methods are necessary or how they would improve the baseline. Without additional context or explanation, the claim remains somewhat verifiable, as the authors may find it challenging to understand the basis of the suggestion without further elaboration. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the baseline, particularly in the context of dimensional reduction methods in optimal transport estimation. It suggests that the inclusion of specific methods, such as SRW and FROT, would enhance the baseline. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that can help the authors strengthen their work. However, the comment could be more helpful if it explained why these methods are important or how they would contribute to the baseline. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not discuss the advantages and disadvantages of transductive learning. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this omission or what specific aspects of transductive learning should be discussed. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the paper does not discuss the advantages and disadvantages of transductive learning. However, it does not specify which part of the paper this omission is in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of transductive learning should be discussed or how they could be integrated into the paper. Without clear guidance, the authors may struggle to address the issue effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not discuss the advantages and disadvantages of transductive learning. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a gap in the paper regarding the discussion of the advantages and disadvantages of transductive learning. However, it does not provide any specific suggestions or guidance on how the authors might address this omission or what aspects of transductive learning should be discussed. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally. While it implies that the authors should include this information in their draft, it does not provide specific guidance on how to present it or what form it should take. The action is implicit and somewhat vague, as the authors need to infer that they should include a formal statement about the invariance of the contractivity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally, but it does not specify which part of the paper this suggestion pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what aspects of the contractivity should be formalized or how this would enhance the paper. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the invariance of the contractivity should be stated formally. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally. While it identifies a potential area for improvement, it lacks specific guidance on how to achieve this or what aspects of the contractivity should be formalized. The comment is somewhat helpful as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to address this issue. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential contribution of uncertainty saliency maps but expresses concern about their significance without an application or evaluation. It also questions the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve their draft. It lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the potential contribution of uncertainty saliency maps and questions the significance without an application or evaluation. It also disagrees with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to sections discussing the contribution or evaluation of uncertainty saliency maps, but this inference is not direct. The comment is specific in its critique of the claim about trustworthiness, providing a clear rationale for the authors to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the significance of uncertainty saliency maps without an application or evaluation, questioning the trustworthiness of the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the contribution is unclear or untrustworthy. Without such evidence or examples, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides a logical argument but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential contribution of uncertainty saliency maps but expresses concern about their significance without an application or evaluation. It also questions the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. While the comment highlights a potential issue with the paper\\'s contribution, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is somewhat helpful as it points out a potential weakness, but it lacks actionable advice or detailed critique to fully support the authors in making improvements. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of using the diffusion model in style transfer, asking what unique benefits it provides compared to other methods. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for the use of the diffusion model. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the importance of using the diffusion model in style transfer, specifically asking what unique benefits it provides compared to other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an explanation of the benefits of using the diffusion model, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of using the diffusion model in style transfer, asking what unique benefits it provides compared to other methods. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this question is relevant or how it could be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to respond to it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the importance of using the diffusion model in style transfer, asking what unique benefits it provides compared to other methods. This is a valuable point that could prompt the authors to reconsider the rationale behind their methodology and potentially enhance the paper by addressing this issue. However, the comment lacks specific guidance or suggestions on how to address this question or what specific benefits the diffusion model might offer. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a relevant area for exploration but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a discussion or comparison with related work would enhance the understanding of the multi-view approach. While it implies that the authors should include such a discussion or comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion or comparison section. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a discussion or comparison with related work would enhance the understanding of the multi-view approach. However, it does not specify which part of the paper this discussion should be included in, such as the related work section or a specific section discussing the methodology. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the multi-view latent attack enhances the model's meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. The reviewer supports this claim by comparing the multi-view approach to task augmentation meta-learning methods, which are mentioned as references. This provides a logical basis for the claim, but the comment could be strengthened by including specific references or detailed comparisons to substantiate the claim fully. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that a discussion or comparison with related work would enhance the understanding of the multi-view approach. It provides a rationale by comparing the multi-view training to task augmentation meta-learning methods, which are mentioned as references. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a discussion or comparison that could clarify the methodology and its effectiveness. However, the comment could be more helpful if it provided specific examples or references to related work that would be relevant for this discussion. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the impact of Age and FaceID features is not studied in the ablation. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether the authors should include this analysis or how to conduct it. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of study on the impact of Age and FaceID features. This provides clear guidance on what the authors need to include in their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the impact of Age and FaceID features is not studied in the ablation. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, noting that the impact of Age and FaceID features is not studied in the ablation. This is a clear and actionable point that the authors can address to enhance the robustness and comprehensiveness of their analysis. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects of the Age and FaceID features should be studied. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the Table 2 and Fig. 5 were not mentioned in the manuscript and asks for clarification on the values in Table 2 and Fig. 5. It also suggests moving the detailed discussion from the appendix to the main manuscript. This provides clear and direct actions for the authors to take, such as including the missing tables and figures in the main manuscript and relocating the discussion to improve the flow of the paper. The explicit nature of the suggestions and the concrete details on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the missing tables and figures in the main manuscript and the relocation of the detailed discussion from the appendix to the main manuscript. This provides clear guidance on what needs to be corrected and improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the inclusion of Table 2 and Fig. 5 in the manuscript and asks for clarification on the values in Table 2 and Fig. 5. It also suggests moving the detailed discussion from the appendix to the main manuscript. While the comment raises valid questions, it lacks specific examples or references to support the claim that the inclusion of these figures is necessary or beneficial. The suggestion to move the discussion to the main manuscript is logical, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that Table 2 and Fig. 5 were not mentioned in the main text. It also questions the purpose of the detailed discussion in the appendix and suggests moving it to the main manuscript. This feedback is clear and actionable, as it provides the authors with a direct and concrete suggestion to improve the organization and flow of their paper. By addressing these points, the authors can enhance the clarity and accessibility of their work. However, the comment could be more helpful if it offered additional guidance on how to integrate the discussion into the main text or provided examples of how similar discussions have been effectively incorporated into other papers. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should include more LLM-related results in the paper experiment, specifically mentioning the models llama-3-70B, Mistral-7B, and others. This feedback provides a clear and concrete action for the authors to take, as it specifies exactly what additional results are expected and why they are important. The comment is specific and direct, giving the authors a clear path to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction, where the author states the main purpose of the Lorta method is to solve the problem of efficient finetune of LLM. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what additional LLM-related results are expected, such as llama-3-70B, Mistral-7B, etc. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks LLM-related results, specifically mentioning models like llama-3-70B and Mistral-7B. The reviewer expects more LLM-related experiments to be included in the paper. However, the comment does not provide any supporting evidence or reasoning to justify why these specific models are important or how they would enhance the paper. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the importance of these models themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that the paper lacks LLM-related results, particularly mentioning models like llama-3-70B and Mistral-7B. This feedback is clear and actionable, as it directs the authors to include more LLM-related experiments in their paper. By doing so, the authors can enhance the relevance and comprehensiveness of their work, which is valuable guidance for improving the draft. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate these results effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the proposed \"Depth First Search-based Decision Tree\" (DFSDT) technique, noting its similarity to self-consistency + CoT and Tree-of-thoughts. It also questions how DFSDT will perform for other types of LLMs not in the category of LLaMA / GPT / Claude. While the comment identifies potential issues, it does not provide explicit guidance on how the authors should address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the novelty and applicability of DFSDT, but the comment does not offer specific steps or examples on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed \"Depth First Search-based Decision Tree\" (DFSDT) technique and its performance compared to ReAct prompting. It also questions how DFSDT will perform for other types of LLMs not in the category of LLaMA / GPT / Claude. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these techniques are discussed. The comment is specific in detailing what needs to be addressed, such as the novelty and applicability of DFSDT, and how it compares to other techniques. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty and applicability of the proposed \"Depth First Search-based Decision Tree\" (DFSDT) technique, noting its similarity to self-consistency + CoT and Tree-of-thoughts. It also raises concerns about how DFSDT will perform for other types of LLMs not in the category of LLaMA / GPT / Claude. While the comment identifies potential issues, it lacks specific examples or references to substantiate the claim that DFSDT is not novel or that it may not perform well for other LLMs. The lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to further explore and substantiate these claims themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed \"Depth First Search-based Decision Tree\" (DFSDT) technique, noting its similarity to self-consistency + CoT and Tree-of-thoughts. It also raises a concern about how DFSDT will perform for other types of LLMs not in the category of LLaMA / GPT / Claude. This feedback is somewhat helpful as it points out a potential limitation of the proposed technique and highlights areas that need further exploration. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these concerns or improve the clarity of their work. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the acknowledgment of people's contributions in the paper, specifically mentioning the issue of proposing an identical method while claiming originality. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to acknowledge contributions properly. The comment lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a concern about the acknowledgment of people\\'s contributions in the paper, specifically mentioning the issue of proposing an identical method while claiming originality. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. The authors can infer that it relates to the discussion of originality and contributions, but this inference is not direct. The comment is specific in its critique of the claim of originality, but it lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is inappropriate to propose an identical method while claiming originality. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper regarding the acknowledgment of people\\'s contributions and the claim of originality. It points out that proposing an identical method while claiming originality is inappropriate. This feedback is somewhat helpful as it highlights a specific area where the authors may need to clarify or address their claims. However, the comment could be more helpful if it provided suggestions on how to acknowledge contributions or how to substantiate the originality claim. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of MMV compared to XDC, noting that MMV outperforms XDC but does not exceed its fully-supervised baseline. It suggests that the authors might explain why this is the case and whether MMV's better performance is due to its backbone architecture. While the comment implies that the authors should provide an explanation or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"XDC outperformed its R(2+1)D-18 fully-supervised pertaining baseline, but MMV did not exceed its fully-supervised pertaining baseline.\" This allows the authors to accurately identify the specific parts of the paper being addressed, such as the comparison between XDC and MMV. The comment also specifies the issue by asking the authors to explain why MMV outperforms XDC and whether it is due to a better backbone architecture. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that MMV outperforms XDC, but does not provide any supporting evidence or reasoning to substantiate this claim. The comment suggests that the authors might explain why this is the case, but it lacks specific details or examples to support the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an interesting observation about the performance of MMV compared to XDC, noting that MMV outperforms XDC but does not exceed its fully-supervised baseline. It questions whether MMV's better performance is due to its backbone architecture, prompting the authors to explain this observation. This feedback is somewhat helpful as it encourages the authors to provide an explanation or analysis of the performance differences between MMV and XDC. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address this issue. Overall, the comment provides a starting point for the authors to explore, but it lacks depth and actionable guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing is too verbose and hard to follow, and it recommends focusing on a main idea or two and showing analyses of why they work. This feedback provides a clear and explicit action for the authors to take, which is to simplify the writing and prioritize the main ideas. The comment also specifies that the focus should be on theoretical or general advancements rather than a well-engineered system with many functions. This guidance is concrete and provides a clear direction for the authors to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of verbose and hard-to-follow writing, suggesting that it resembles an implementation paper rather than a theoretical or general advancement. It provides a specific critique by mentioning that the paper lacks a main idea or two and instead focuses on a well-engineered system with many functions. This feedback is clear and specific, as it identifies the issue of excessive detail and suggests a more focused approach. However, the comment does not explicitly mention which sections or parts of the paper are problematic, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing is too verbose and hard to follow, suggesting that it resembles an implementation paper rather than a theoretical or general advancement. The reviewer provides a specific critique by mentioning that the paper lacks a main idea or two and focuses on a well-engineered system with many functions. This critique is somewhat verifiable as it highlights a potential issue with the paper\\'s structure and content, but it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to focus on a main idea or two and provide analyses of why they work is logical but could be strengthened with more specific guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper\\'s writing style, noting that it is too verbose and hard to follow. It suggests that the paper resembles an implementation paper rather than a theoretical or general advancement. The reviewer provides a specific critique by recommending that the authors focus on a main idea or two and show analyses of why they work, rather than presenting a well-engineered system with many functions. This feedback is clear and actionable, as it guides the authors on how to simplify their writing and improve the clarity of their paper. However, the comment could be more helpful if it provided examples of what constitutes a main idea or how to effectively present analyses. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks code and supplementary documentation, which are crucial for enhancing clarity and reproducibility. It clearly identifies the missing resources and suggests that their provision would be beneficial for readers. The action is direct and concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of code and supplementary documentation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the provision of code and supplementary documentation to enhance clarity and reproducibility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks code and supplementary documentation, which are crucial for enhancing clarity and reproducibility. This claim is somewhat verifiable as it logically suggests that these resources would be beneficial for readers to understand and replicate the methodology. However, the comment does not provide specific examples or references to support the claim, such as explaining how these resources would enhance clarity or detailing the importance of code availability in the field. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of code and supplementary documentation. This feedback is clear and actionable, as it directly points out an area where the paper could be improved to enhance clarity and reproducibility. Providing code and supplementary documentation would be beneficial for readers to understand and replicate the methodology. However, the comment could be more helpful if it offered suggestions on how to present these resources effectively or provided examples of best practices in this area. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should discuss ensembles and uncertainty estimation, particularly in the context of offline RL, where random ensembles (REM) have been found to outperform DQN/naive ensembling. The reviewer also recommends empirically comparing the proposed method to REM to incorporate value uncertainty in offline RL. While the comment provides a clear action to take, it lacks specific guidance on how to incorporate this discussion or comparison into the paper. The authors are given a general direction but may need to infer the exact steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ensembles and uncertainty estimation\" and \"offline RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the comparison of random ensembles (REM) to DQN/naive ensembling in the offline setting. The comment provides a clear direction for the authors to incorporate this discussion and comparison into their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ensembles have been studied in the context of offline RL, specifically in the discrete Atari games, where random ensembles (REM) significantly outperformed DQN/naive ensembling. The reviewer suggests that this should be discussed in the paper and empirically compared to the proposed method. The claim is supported by a reference to a previous study, which provides a logical basis for the suggestion. However, the comment could be strengthened by providing more detailed comparisons or examples of how REM outperforms DQN/naive ensembling. Despite this, the claim is mostly verifiable, as it provides a clear rationale and reference to support the suggestion.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to discuss ensembles and uncertainty estimation in the context of offline RL, particularly in the discrete Atari games. It references a previous study where random ensembles (REM) were found to outperform DQN/naive ensembling, suggesting that this should be discussed and empirically compared in the paper. This feedback is clear and offers a concrete direction for the authors to enhance their draft by incorporating this relevant information. By addressing this suggestion, the authors can improve the comprehensiveness and depth of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors have combined two methods in a clever way but lack novelty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of lacking novelty or suggestions for enhancing the novelty of the combined methods. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second paragraph of the introduction and the proposed methodology, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the two methods have been combined in a clever way but lack novelty. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the two methods have been combined in a clever way but lack novelty. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks the necessary evidence or justification to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors have combined two methods in a clever way but lack novelty. While it identifies a potential issue with the novelty of the combined methods, it does not provide specific suggestions or guidance on how to address this concern. The comment lacks actionable feedback or detailed insights into how the authors might enhance the novelty of their work. As a result, it offers limited value to the authors in terms of improving their draft. Therefore, the comment is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scalability of the proposed approach, noting that it appears to require a different model to be finetuned for each target language. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the scalability or suggest alternative approaches. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the scalability of the proposed approach, specifically questioning whether it will be effective for each target language. However, it does not specify which part of the paper this concern is based on, such as the methodology or results sections. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the scalability are questionable or how the authors might address these concerns. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the scalability of the proposed approach, suggesting that it may require a different model to be finetuned for each target language. However, the comment lacks specific examples or detailed reasoning to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the scalability of the proposed approach, noting that it appears to require a different model to be finetuned for each target language. This is an important consideration for the authors to address, as scalability is a key factor in the practicality and applicability of their work. However, the comment lacks specific suggestions or guidance on how the authors might improve the scalability of their approach or address this concern. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in making improvements to their draft. Therefore, it is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more details are needed for readers unfamiliar with bAbI or question answering regarding the term \"valid words\" in Eq. 20. It explicitly asks for clarification on what \"valid words\" mean in the context of the given story and question. This feedback provides a clear and direct action for the authors to take, which is to clarify the meaning of \"valid words\" in their work. The comment is explicit and concrete, as it specifies exactly what needs to be clarified, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 20,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the term \"valid words\" in the context of bAbI or question answering. The comment provides a clear request for additional details, which is a specific and actionable suggestion for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more details are needed for readers unfamiliar with bAbI or question answering regarding the term \"valid words\" in Eq. 20. The reviewer provides a clarification request by asking what \"valid words\" mean in the context of the given story and question. This is a request for clarification rather than a claim or opinion, as it does not express an opinion or judgment. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where more details are needed for readers unfamiliar with bAbI or question answering. It points out that the term \"valid words\" in Eq. 20 might be confusing for those not familiar with the context, and it asks for clarification on what \"valid words\" mean in the given story and question. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity of the paper. By addressing this point, the authors can enhance the accessibility and understanding of their work for a broader audience. Therefore, the comment is mostly helpful, as it offers a concrete way to improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the interested-region-based adversarial attacking is not a novel idea, as it has been proposed earlier by Yao et al. in their work on Trust Region Based Adversarial Attack on Neural Networks at CVPR 2019. However, the comment does not provide any guidance on how the authors should address this issue or what specific changes they should make to their draft. It lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about how to respond to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"interested-region-based adversarial attacking\" and references a specific work by Yao et al. from CVPR 2019, allowing the authors to accurately identify the part of the paper being addressed. This provides full grounding. The comment is specific because it clearly specifies what is considered a non-novel idea and references a specific work that has already explored this concept. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the interested-region-based adversarial attacking is not a novel idea, as it has been proposed earlier by Yao et al. in their work on Trust Region Based Adversarial Attack on Neural Networks at CVPR 2019. This claim is supported by a specific reference to an external work, which provides a clear basis for the assertion. However, the comment could be strengthened by providing more detailed analysis or comparison with the original work, such as how the current work differs or builds upon the previous work. Despite this, the reference to an external source makes the claim mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed method, noting that the interested-region-based adversarial attacking has been previously proposed by Yao et al. in their work on Trust Region Based Adversarial Attack on Neural Networks at CVPR 2019. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s originality, which the authors should address to strengthen their contribution. However, the comment lacks specific suggestions on how to differentiate their work from the existing literature or how to improve the novelty of their approach. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed methods are comprised of multiple well-known components, which may not contribute significantly to the field. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the novelty or impact of the proposed methods, nor are there suggestions for additional experiments or analyses that could strengthen the contribution. As a result, the authors are left without any clear direction on how to enhance the significance of their work. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed methods are comprised of multiple well-known components, which may not contribute significantly to the field. However, it does not specify which part of the paper discusses these methods or which components are mentioned. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the methods are considered well-known or how they could be improved to enhance their contribution. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed methods are comprised of multiple well-known components, which may not contribute significantly to the field. However, the comment lacks specific examples or references to these well-known components, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or reasoning, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the proposed methods may not contribute significantly to the field due to their reliance on well-known components. However, it does not provide any specific examples or detailed reasoning to support this claim. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of how to address the issue or enhance the novelty of their work. Therefore, the comment is not helpful, as it lacks depth and specificity in guiding the authors towards improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the test set, specifically the inclusion of multi-turn data and the use of publicly available history conversation data for training models. While it acknowledges that this data still provides some assistance in answering the final question, it also notes a risk of data leakage. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue, such as recommending specific steps to mitigate data leakage or suggesting alternative approaches to training models. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the test set, specifically mentioning the inclusion of multi-turn data and the use of publicly available history conversation data for training models. This provides some grounding as it allows the authors to identify the part of the paper being discussed, namely the test set and its components. However, the comment lacks specificity as it does not detail what aspects of the test set or the use of publicly available data are problematic or how they might impact data leakage. Without specific guidance or examples, the authors may struggle to understand and address the issue effectively. Therefore, this comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the test set, which includes multi-turn data and publicly available history conversation data, still provides some assistance in answering the final question, which indicates a risk of data leakage. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is considered borderline verifiable, as it requires more detailed justification to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the test set, specifically the inclusion of multi-turn data and the use of publicly available history conversation data for training models. It acknowledges that this data still provides some assistance in answering the final question, which could lead to data leakage. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate the risk of data leakage. Without actionable advice or detailed feedback, the authors may struggle to understand and implement the necessary changes to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a potential problem but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests that a comparison with VSD + TTUR would be more convincing. While the comment implies that the authors should include such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison with VSD + TTUR. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison with VSD + TTUR. The comment provides a clear suggestion for improvement by recommending a comparison that could enhance the paper\\'s persuasiveness. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests that a comparison with VSD + TTUR would be more convincing. The comment does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where a comparison could be more convincing, suggesting that a comparison with VSD + TTUR would be more effective than the current comparison with VSD. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the paper\\'s persuasiveness. However, the comment could be more helpful if it explained why TTUR is a relevant comparison or how it might impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the theoretical result presented in the paper, specifically questioning the merit of the result given the assumption that out-of-distribution (OOD) actions are not present. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific changes could be made to improve the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 109\" and \"Assumption 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the theoretical result presented in the paper, asking for clarification on the merit of the result given the assumptions about OOD actions. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the theoretical result presented in the paper, specifically questioning the merit of the result given the assumption that out-of-distribution (OOD) actions are not present. The reviewer points out a discrepancy between the definition of OOD actions in the paper and the assumption made in Assumption 3.1. However, the comment lacks specific examples or references to support the claim that the assumption is invalid or unjustified. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a logical basis for questioning the result but does not fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the theoretical result presented in the paper, questioning the merit of the result given the assumption that out-of-distribution (OOD) actions are not present. It points out a discrepancy between the definition of OOD actions in the paper and the assumption made in Assumption 3.1. While the comment identifies a potential issue with the paper\\'s theoretical foundation, it does not provide specific suggestions or guidance on how the authors might address this concern. The feedback is somewhat helpful as it highlights a potential weakness in the paper, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper\\'s analysis is shallow and lacks clear takeaways or conclusions. It advises that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, it recommends that essential details, such as dataset splitting justifications, should be integrated into the main text. This feedback provides clear and concrete actions for the authors to take, specifying what needs to be improved and how to do it. The explicit nature of the suggestions and the detailed guidance on integration make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"shallow linguistic dataset analysis\" and suggests that it might be better suited for the appendix. It also provides specific guidance on what needs to be addressed, such as integrating essential details like dataset splitting justifications into the main text. This level of detail allows the authors to accurately identify the parts of the paper being addressed and what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s analysis is \"shallow\" and lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. The comment also advises that essential details, such as dataset splitting justifications, should be integrated into the main text. While the comment provides a logical reasoning for its claim, it lacks specific examples or references to support the assertion that the analysis is shallow. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s analysis, noting that it is shallow and lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, it provides actionable advice by recommending that essential details, such as dataset splitting justifications, should be integrated into the main text. This feedback is clear and offers a concrete direction for improvement, making it mostly helpful for the authors. However, it could be more helpful if it provided additional guidance on how to integrate these details effectively or how to improve the analysis\\'s depth and impact. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the metric of Table 1 is not clearly stated and that the experimental details, such as the backbone choice, learning rate, and optimization schedules, are missing. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the metric and provide more detailed experimental information. The action is implicit and somewhat vague, as the authors need to infer the specific details that need to be added. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"experimental details like backbone choice, learning rate, and optimization schedules,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the metric in Table 1 and the lack of detailed experimental information. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metric of Table 1 is not clearly stated and that the experimental details, such as the backbone choice, learning rate, and optimization schedules, are missing. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim unverifiable, as it does not provide sufficient support for the authors to understand and improve their work. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the metric of Table 1 is not clearly stated and that the experimental details, such as the backbone choice, learning rate, and optimization schedules, are missing. This feedback is clear and actionable, as it points out specific areas where the authors need to provide more detailed information to enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to clarify the metric or provide the missing experimental details. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper, noting that the advantage of POMDPs is not leveraged in the discussion. It suggests that the paper should discuss how previous decisions affect the data observable to the decision-maker, as only outcomes are observed when a positive decision is given. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to address this issue or what specific aspects of the data observable should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the impact of previous decisions on the observable data. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"advantage of POMDPs\" and the \"assumption that the decision-maker does not directly observe the target variable Y,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not discuss how previous decisions affect the data observable to the decision-maker, despite the assumption of POMDPs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not leverage the advantage of POMDPs, specifically the assumption that the decision-maker does not directly observe the target variable Y. The reviewer supports this claim by pointing out that the paper does not discuss how previous decisions affect the data observable to the decision-maker, as only outcomes are observed when a positive decision is given. This logical reasoning and specific example provide a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing additional examples or references to similar works that discuss this aspect of POMDPs. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by discussing the advantage of POMDPs, particularly the assumption that the decision-maker does not directly observe the target variable Y. It points out that the paper does not address how previous decisions affect the data observable to the decision-maker, despite the assumption of POMDPs. This feedback is clear and actionable, as it directs the authors to consider discussing this aspect of the model in their paper. However, the comment could be more helpful if it provided suggestions on how to integrate this discussion into the existing framework or what specific aspects of the data observable should be addressed. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a direction for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the pretraining tokens per sample are extremely small (256) and suggests that this may not be enough for a regular-sized program. Additionally, it questions whether using batch size=64 for pretraining is sufficient. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors can infer that they need to increase the pretraining tokens per sample and consider larger batch sizes, but the comment lacks concrete suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the pretraining tokens per sample, which is a specific aspect of the paper\\'s methodology. However, it does not explicitly mention which section of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the small size of the pretraining tokens and questioning whether it is sufficient for a regular-sized program. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the pretraining tokens per sample are extremely small (256) and that this may not be enough for a regular-sized program. The reviewer also questions whether using batch size=64 for pretraining is sufficient. However, the comment lacks specific reasoning or evidence to support these claims, such as data or references to similar studies that demonstrate the impact of these parameters on performance. Without additional context or justification, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the pretraining process, specifically the small number of tokens per sample (256) and the use of a batch size of 64 for pretraining. This feedback highlights a potential limitation in the methodology that could impact the performance and scalability of the model. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending an increase in the number of tokens per sample or exploring alternative pretraining strategies. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper lacks ablation experiments and provides specific examples of what could be tested, such as replacing the clustering algorithm with K-Means. It also asks how the model performs when applied to different-sized descendant models. These actions are clear and concrete, providing the authors with direct guidance on how to enhance their draft. The comment is highly actionable as it offers specific steps for improvement, ensuring that the authors know exactly what changes to make.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for ablation experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear examples of what could be tested, such as replacing the clustering algorithm with K-Means and evaluating the model on different-sized descendant models. This level of detail provides the authors with clear guidance on how to enhance their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks ablation experiments to help readers understand the proposed method. It provides specific examples of what could be tested, such as replacing the clustering algorithm with K-Means and evaluating the model on different-sized descendant models. This claim is somewhat verifiable as it logically points out the need for additional experiments to enhance the understanding of the method. However, it lacks detailed justification or references to support the importance of these experiments or how they would impact the paper\\'s conclusions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of ablation experiments to help readers understand the proposed method. It provides specific examples of what could be tested, such as replacing the clustering algorithm with K-Means and evaluating the model on different-sized descendant models. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft. By addressing these points, the authors can enhance the comprehensiveness and robustness of their evaluation. However, the comment could be more helpful if it provided additional context or rationale for why these experiments are important or how they would impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it effectively guides the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the Talking Heads Transformer should be the de-facto baseline for all tasks in the paper. It points out that while there is a comparison to it in Table 1, a comparison for all tasks would be beneficial. The reviewer also highlights the importance of understanding the benefits of the proposed interaction modules and many-to-many formulation compared to a simple linear transform. This feedback provides clear and concrete actions for the authors to take, such as expanding the baseline comparison to include the Talking Heads Transformer and conducting a more comprehensive analysis of the benefits of the proposed interaction modules. The suggestion is explicit and provides specific guidance on how to enhance the paper\\'s comparative analysis. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Talking Heads Transformer, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a comparison to the Talking Heads Transformer as the de-facto baseline for all tasks. This provides clear guidance on what the authors should add to their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Talking Heads Transformer should be the de-facto baseline for all tasks in the paper. While it acknowledges that there is a comparison to it in Table 1, it argues that a comparison for all tasks would be beneficial to understand the benefits of the proposed interaction modules and many-to-many formulation. The comment provides a logical reasoning for why the Talking Heads Transformer should be considered the baseline, but it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to make a logical inference to understand the importance of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It points out that the Talking Heads Transformer should be the de-facto baseline for all tasks in the paper, as it is relevant and has been previously used in similar contexts. The reviewer acknowledges that there is a comparison to the vanilla transformer in Table 1, but argues that a comparison against the Talking Heads Transformer would be more beneficial. This feedback is valuable as it guides the authors to include a more comprehensive comparison, which could help them better understand the benefits of their proposed interaction modules and many-to-many formulation. The suggestion is clear and constructive, making it highly helpful for the authors to enhance their analysis and evaluation. Therefore, the comment is rated as 5: Highly Helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should check the scenario simulation and benchmark at least speaker identification on datasets like HI-MIA, which is recorded in real-time environments with noise setup and microphone array. While the comment implies that the authors should verify the scenario and perform benchmarking, it does not provide explicit instructions on how to do so or what specific aspects of the scenario should be checked. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Following 2) and the scenario is simulated while there are datasets such as HI-MIA, which is recorded in the real-time environment with noise setup and microphone array [1].\" This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, which is to check the scenario simulation and benchmark at least speaker identification on datasets like HI-MIA. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the scenario simulation should be checked and benchmarked with datasets like HI-MIA, which is recorded in real-time environments with noise setup and microphone array. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should verify the scenario simulation and benchmark at least speaker identification on datasets like HI-MIA, which is recorded in real-time environments with noise setup and microphone array. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by checking the scenario simulation and benchmarking speaker identification on relevant datasets. However, the comment could be more helpful if it explained why this verification is important or how it would enhance the paper\\'s contribution. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a minor reframing of the introduction to focus on the loss function and its applications rather than solely on breast cancer. It highlights that the paper's primary contribution is a loss function that can be applied to any semantic segmentation network and that it can be extended to solve other problems in semantic segmentation, such as handling distribution shifts. The comment provides a clear and explicit action for the authors to consider reframing the introduction to better align with the paper's contributions. This guidance is concrete and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the framing of the paper, suggesting that it should focus more on the loss function and its applications rather than solely on breast cancer. The comment provides a clear direction for improvement by recommending an alternative framing that focuses on the loss function and its applications. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the introduction focuses on breast cancer but does not align with the paper\\'s contributions, which are broader. It provides a logical reasoning by pointing out that the paper evaluates the loss function over multiple datasets and that its primary contribution is a loss function applicable to any semantic segmentation network. The comment also suggests an alternative framing that focuses on the loss function and its applications. This reasoning is somewhat verifiable as it provides a logical basis for the claim but lacks specific examples or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the framing of the paper. It points out that the introduction focuses on breast cancer, which may not align with the broader contributions of the paper. The reviewer suggests an alternative framing that emphasizes the loss function and its applications, which are more central to the paper\\'s contributions. This feedback is valuable as it guides the authors to reframe their introduction to better reflect the paper\\'s focus and highlight its significance. By addressing this suggestion, the authors can improve the clarity and impact of their introduction, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to include agreement statistics for the corpus in either section 3.1 or 3.2. This is a clear and direct action, as it specifies the exact location where the statistics should be included and provides a concrete step for the authors to take. The comment is highly actionable because it provides a specific and detailed instruction on how to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly requests the inclusion of agreement statistics for the corpus in either section 3.1 or 3.2. This provides full grounding as it clearly identifies the part of the paper being addressed, allowing the authors to accurately pinpoint the sections where these statistics should be included. The comment is also specific because it specifies the exact location where the statistics should be included, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests the inclusion of agreement statistics for the corpus in either section 3.1 or 3.2. This is a factual request for additional information, not an opinion or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area for improvement by requesting the inclusion of agreement statistics for the corpus in either section 3.1 or 3.2. This feedback is clear and actionable, as it provides a concrete step for the authors to take in order to enhance the clarity and completeness of their draft. However, the comment could be more helpful if it explained why these statistics are important or how they could impact the understanding of the paper. Overall, the comment is valuable but could be more comprehensive with additional context or explanation. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the novelty of the instruction aggregation and the use of LLMs but points out that existing LLMs are already used. It also considers the use of consecutive sub-trajectories as straightforward and notes that cross-trajectory chaining has novelty, albeit with techniques inspired by goal-conditioned RL approaches. However, the comment does not provide explicit guidance on how the authors should address these observations or improve their draft. It lacks actionable steps or suggestions for enhancing the novelty or clarifying the novelty of the techniques. As a result, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the instruction aggregation and the use of LLMs, as well as the use of consecutive sub-trajectories and cross-trajectory chaining. However, it does not specify which part of the paper these aspects are discussed in, making it weakly grounded. The comment is specific in detailing the novelty of cross-trajectory chaining and its relation to goal-conditioned RL approaches, but it does not provide guidance on how to address this issue or improve the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the novelty of the instruction aggregation and the use of LLMs, noting that existing LLMs are used. It also considers the use of consecutive sub-trajectories as straightforward and cross-trajectory chaining as having novelty, albeit with techniques inspired by goal-conditioned RL approaches. The comment provides a logical reasoning by referencing existing work, which supports the claim about the novelty of cross-trajectory chaining. However, it could be strengthened by providing specific examples or references to the goal-conditioned RL approaches mentioned in the paper. Overall, the claim is mostly verifiable, as it is based on logical reasoning and reference to external work, but it could be further substantiated with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the novelty of the instruction aggregation and the use of LLMs, noting that existing LLMs are used. It also considers the use of consecutive sub-trajectories as straightforward and the cross-trajectory chaining as having novelty, albeit with techniques inspired by goal-conditioned RL approaches. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty or clarify the novelty of the techniques. It does not provide actionable feedback or insights into how the authors might address the issues raised. As a result, the comment is barely helpful, as it identifies potential weaknesses but does not offer concrete steps for improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It suggests that more discussion is needed to explore this topic. However, the comment does not provide explicit guidance on how the authors should conduct this discussion or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more discussion but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the identity of the attention map and its impact on the expressive power of the attention module. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the attention map is discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what aspects of the identity of the attention map should be discussed or how it could improve the expressive power of the attention module. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It suggests that more discussion is needed to explore this topic. However, the comment lacks any supporting evidence, reasoning, or references to justify why the identity of the attention map is important or how it could improve the expressive power of the attention module. Without such justification, the claim remains unverifiable, as it does not provide sufficient evidence or explanation to support the suggestion for further discussion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It suggests that more discussion is needed to explore this topic. However, the comment lacks specificity and does not provide guidance on what aspects of the attention map should be discussed or how it could be improved. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explain why they are considering decoder-only transformers. This is a direct and concrete action that the authors can take to improve their draft. The comment provides a clear and specific request, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely an explanation for considering decoder-only transformers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the consideration of decoder-only transformers. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area where the authors need to provide additional explanation. By pointing out the lack of explanation regarding the consideration of decoder-only transformers, the comment prompts the authors to clarify their rationale for this choice. However, the comment could be more helpful if it provided suggestions on how to present this explanation or what specific aspects should be addressed. While it guides the authors toward a meaningful improvement, it lacks depth and specificity, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a gap in the qualitative analysis, specifically the lack of proportion of each error category, and suggests that the contribution could be strengthened by including more detailed discussions or speculations about the underlying causes and potential mitigation strategies. However, it does not provide specific guidance on how to incorporate these discussions or what aspects to focus on. The comment implies that the authors should expand their analysis to include these details, but it lacks concrete steps or examples on how to achieve this. Therefore, the comment is somewhat actionable, as it provides a general direction but lacks specificity in execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the qualitative analysis, specifically mentioning the lack of proportion of each error category and the need for more detailed discussions or speculations about the underlying causes and potential mitigation strategies. However, it does not specify which part of the paper this analysis is located in, making it weakly grounded. The comment is specific in its critique of the analysis and its suggestions for improvement, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the qualitative analysis lacks important details, such as the proportion of each error category, and suggests that more fruitful thoughts or speculations about the underlying causes and potential mitigation strategies could strengthen the contribution. The reviewer references an external work, \"Language Models Don\\'t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting,\" which provides a basis for the claim about the importance of including these details. However, the comment does not provide specific examples or detailed reasoning from the external work to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides some support but lacks comprehensive evidence or detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the qualitative analysis, specifically the lack of proportion of each error category, and suggests that the contribution could be strengthened by including more detailed discussions or speculations about the underlying causes and potential mitigation strategies. This feedback is somewhat helpful as it points out an area for improvement and provides a direction for enhancing the analysis. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these discussions or what aspects to focus on. Additionally, the reference to an external work, \"Language Models Don\\'t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting,\" could be more relevant if it were integrated into the comment to provide a more comprehensive context. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should attempt to apply Reinforcement Learning, RNNs, Wasserstein GANs with data filled by simple methods to empirically validate that these methods are not suitable for incomplete, small data. This is an explicit action that provides a clear direction for the authors to follow. The comment is specific in detailing the methods to be applied and the purpose of the validation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors mention the typical MTTP baselines and their inapplicability to their proposed approach. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests a potential experiment to validate the applicability of the mentioned methods with data filled by simple methods. This provides clear guidance on what the authors should address in this section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should apply Reinforcement Learning, RNNs, Wasserstein GANs with data filled by simple methods to empirically validate that these methods are not suitable for incomplete, small data. The comment provides a logical reasoning by explaining the limitations of these baselines and suggests an experiment to test their applicability. However, it lacks specific examples or references to support the claim that these methods are not suitable for small datasets. This makes the claim somewhat verifiable, as the authors would need to conduct the suggested experiment themselves to fully understand the validity of the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for the authors to conduct an empirical validation of the applicability of Reinforcement Learning, RNNs, Wasserstein GANs with data filled by simple methods. This feedback is actionable and constructive, as it offers a clear path for the authors to test the limitations of these baselines and demonstrate the suitability of their proposed approach. By following this suggestion, the authors can strengthen their argument and provide a more robust evaluation of their data generation technique. However, the comment could be more helpful if it included additional context or examples of how this validation might be conducted. Overall, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of baseline comparison in the paper, specifically noting that the G-EVAL method is entirely based on GPT-3.5 and GPT-4 but does not demonstrate their performance using the simplest prompts. The reviewer implies that the authors should include a baseline comparison to enhance the paper\\'s validity. However, the comment does not provide explicit instructions on how to conduct this comparison or what specific aspects to focus on. While the action is implied, it is not detailed enough for the authors to know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"G-EVAL method\" and \"GPT-3.5 and GPT-4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: a baseline comparison demonstrating the performance of these models using the simplest prompts. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a baseline comparison, specifically mentioning that the G-EVAL method is entirely based on GPT-3.5 and GPT-4 but does not demonstrate their performance using the simplest prompts. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s evaluation, but it lacks specific examples or references to support the claim. The authors would need to infer the importance of including a baseline comparison and the potential impact on the paper\\'s validity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of a baseline comparison for the G-EVAL method. It highlights that the method is entirely based on GPT-3.5 and GPT-4 but does not demonstrate their performance using the simplest prompts. This feedback is clear and actionable, as it points out a critical area for improvement in the paper. By addressing this issue, the authors can enhance the validity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to conduct the baseline comparison or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the methodology, specifically the need to compute expected rewards or NE gaps for different perturbations in multiagent environments. It also notes that this requires full knowledge of the game payoffs and policies of the other agents. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve their methodology. The action is implicit and somewhat vague, as the authors can infer that they need to consider the implications of full knowledge and the need to compute NE gaps, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the methodology used to update weights in multiagent environments, specifically mentioning the need to compute expected rewards or NE gaps for different perturbations. It also highlights the requirement for full knowledge of game payoffs and policies of other agents. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with computing NE gaps and the need for full knowledge, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that computing expected rewards or NE gaps for different perturbations in multiagent environments requires full knowledge of the game payoffs and policies of other agents. This claim is somewhat verifiable as it logically follows that computing NE gaps would require knowledge of the game payoffs and policies of other agents. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors may need to infer the full extent of the claim and its implications, which could lead to some uncertainty. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the methodology used to update weights in multiagent environments, specifically the need to compute expected rewards or NE gaps for different perturbations. It highlights the requirement for full knowledge of the game payoffs and policies of other agents, which is a critical consideration for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what specific changes they should make to their methodology. While it points out a potential weakness, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies a critical area for improvement but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the comparison or what specific aspects of the comparison should be addressed. Without any suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the paper primarily compares the proposed methods with DiffUCO, but it does not specify which part of the paper this comparison is discussed in. Without explicit references to sections or figures, the authors cannot confidently determine where this comparison is made. Additionally, the comment lacks specificity regarding what aspects of the comparison are problematic or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper\\'s content. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the paper primarily compares the proposed methods with DiffUCO. While this observation is relevant, it lacks depth and does not provide any specific suggestions or guidance on how the authors might improve the comparison or address any issues with the comparison. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of explicit definition and explanation of the local subtasks and their corresponding policies, as well as the relationship between them and the global optimal policy. It also points out that the paper is too repetitive and superficial in its exposition of the decomposition method. While the comment highlights areas for improvement, it does not provide specific guidance on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and possibly provide a proof of the equivalence, but the comment lacks concrete steps or examples on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks explicit instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the contribution section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper is too repetitive and superficial in its exposition of the decomposition method, particularly in the lack of explicit definition of local subtasks and their corresponding policies, as well as the relationship between them and the global optimal policy. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is too repetitive and superficial in its exposition of the decomposition method, particularly in the lack of explicit definition of local subtasks and their corresponding policies, as well as the relationship between them and the global optimal policy. The comment suggests that the paper lacks depth and does not provide a complete proof of the equivalence. However, the comment does not provide specific examples or references to support these claims, making it somewhat verifiable. The authors would need to infer the basis of the critique and potentially conduct additional analysis to fully understand and address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of explicit definition and explanation of the local subtasks and their corresponding policies, as well as the relationship between them and the global optimal policy. It points out that the paper is too repetitive and superficial in its exposition of the decomposition method, which is a critical area for clarity and understanding. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. This limits the comment\\'s helpfulness, as it identifies a problem but does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance curve of each algorithm during the training is missing. This implies that the authors should include this information in their paper. However, the comment does not provide specific guidance on how to present this information or what aspects of the performance curve should be included. While the action is clear in terms of what needs to be added, the lack of concrete details on how to implement it makes the comment somewhat actionable. Authors can infer that they need to include performance curves but may not know exactly how to present them or what specific aspects to focus on.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"performance curve of each algorithm during the training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of performance curves. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance curve of each algorithm during the training is missing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, namely the absence of performance curves for each algorithm during the training. This is a clear and actionable point that the authors can address to enhance the comprehensiveness and transparency of their work. However, the comment could be more helpful if it provided suggestions on how to present these curves or what aspects of the performance should be highlighted. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed Gaussian kernel-based graph construction method, noting that it requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs with O(N^2) time complexity. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might optimize the method or suggest alternative approaches to reduce computational complexity. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed Gaussian kernel-based graph construction method, noting that it requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs with O(N^2) time complexity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed Gaussian kernel-based graph construction method requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs with O(N^2) time complexity. This claim is somewhat verifiable as it provides a logical reasoning based on the time complexity of the method. However, it lacks specific examples or references to support the claim, such as detailed calculations or comparisons with alternative methods. This makes the claim somewhat verifiable, as it provides a reasonable basis but could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed Gaussian kernel-based graph construction method, noting that it requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs with O(N^2) time complexity. This is a relevant observation that could impact the scalability and practicality of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative methods or optimizing the current approach. While it points out a potential weakness, it does not provide actionable advice for improvement, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the paper regarding the choice of loss reweighting case (1) by default in Eq. (5) despite case (3) achieving the best performance for most widths. The reviewer disagrees with the authors\\' explanation for using case (1) and questions the rationale behind the choice. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choice of loss reweighting case and provide a more robust justification for their decision. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 8\" and \"Table 2e,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the choice of loss reweighting case (1) by default in Eq. (5) despite case (3) achieving the best performance for most widths. The comment further disagrees with the authors\\' explanation and questions the rationale behind the choice. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that case (3) achieves the best performance for most widths but is not used by default in Eq. (5). The reviewer disagrees with the authors\\' explanation for using case (1) by default, asserting that all sub-networks with different widths should be equally important. The comment provides a logical reasoning by questioning the rationale behind the choice of loss reweighting case, which is based on the authors\\' explanation. However, it lacks specific examples or references to support the claim that case (3) is indeed the best performer. Therefore, the comment is somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the paper regarding the choice of loss reweighting case (1) by default in Eq. (5) despite case (3) achieving the best performance for most widths. The reviewer disagrees with the authors\\' explanation for using case (1) by default, asserting that all sub-networks with different widths should be equally important. This feedback is clear and actionable, as it points out a potential issue with the paper\\'s methodology and provides a logical argument for why the authors should reconsider their choice. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what alternative approaches might be considered. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims to address fine-tuning multiplicity specifically for tabular LLMs, but the main results are general and do not leverage any unique characteristics of tabular data or LLMs. The reviewer suggests that the main result is irrelevant to the paper scope. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to ensure the results are relevant to the paper scope. The action is implicit and somewhat vague, as the authors need to infer that they should focus on the unique aspects of tabular LLMs and tailor their results accordingly. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the paper\\'s claim about addressing fine-tuning multiplicity specifically for tabular LLMs, noting that the main results are general and do not leverage any unique characteristics of tabular data or LLMs. However, it does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing what is missing\u2014the need to focus on unique aspects of tabular data and LLMs\u2014but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s main results are general and do not leverage any unique characteristics of tabular data or LLMs, despite claiming to address fine-tuning multiplicity specifically for tabular LLMs. The reviewer supports this claim by pointing out that the main results are irrelevant to the paper scope. However, the comment lacks specific examples or references to support the claim that the main results are irrelevant, making it somewhat verifiable. The authors would need to infer the specific aspects that need to be addressed to improve the paper, which adds a level of complexity to the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s claim of addressing fine-tuning multiplicity specifically for tabular LLMs. It points out that the main results are general and do not leverage any unique characteristics of tabular data or LLMs, making the paper\\'s scope irrelevant. This feedback is valuable as it highlights a critical gap in the paper\\'s contribution, which the authors can address by focusing on the unique aspects of tabular data and LLMs. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what aspects of tabular data or LLMs should be emphasized. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggests improvements, but it does not provide explicit instructions or concrete actions for the authors to take. The reviewer questions whether a double summation is needed, suggests separating the summations into one over multi-layered garments and another over vertices, and asks about the function \"f()\" in the line just above equation 3. Additionally, the reviewer mentions existing works and suggests providing details on the challenges of simulating multiple layers compared to single-layered clothing. While the comment identifies areas for improvement, it lacks specific guidance on how to implement these changes or what specific details should be included. The authors are left to infer the actions they need to take, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 3\" and \"the line just above eq. 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the summation, the function \"f()\", and the challenges of simulating multiple layers compared to single-layered clothing. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the summation in the paper and suggests that it should be separated into one over multi-layered garments and another over vertices. It also asks about the function \"f()\" in the line just above equation 3 and references existing works like TailorNet and Patel et al. 2021 that use PBS to drape garments on the human body. The comment is somewhat verifiable as it provides logical reasoning and references to existing works, which could help the authors understand the context and potential issues. However, it lacks specific examples or detailed explanations, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several specific questions and suggestions that can help the authors improve their draft. It raises concerns about the summation in the paper, suggesting that it should be separated into one over multi-layered garments and another over vertices. This feedback is actionable and can guide the authors in clarifying their methodology. Additionally, the reviewer questions the function \"f()\" in the line just above equation 3, which could lead to further clarification or explanation. The mention of existing works like TailorNet and Patel et al. 2021 also prompts the authors to provide more context or comparison with related literature. Finally, the comment asks for details on the challenges of simulating multiple layers compared to single-layered clothing, which could help the authors justify their approach or methodology. Overall, the comment is mostly helpful as it provides clear and actionable feedback that can significantly improve the clarity and comprehensiveness of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the definition of the supremum in Definition 1 and asks how the proposed GRADE reduces it. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the definition and its implications, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 1\" and \"supremum,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of the supremum and asks for clarification on how the proposed GRADE reduces it. This provides clear guidance on what needs to be addressed in the theoretical analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the definition of the supremum in Definition 1 and how the proposed GRADE reduces it. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the definition of the supremum in Definition 1 and how the proposed GRADE reduces it. This is a clear and actionable point that could help the authors clarify their theoretical analysis and provide a more robust foundation for their work. By addressing this question, the authors can improve the clarity and coherence of their theoretical section. However, the comment could be more helpful if it offered suggestions on how to present this information or provided additional context to aid in understanding. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include results and analysis on the lengthy dialogue samples, specifically asking whether the performance will drop on these samples. While the comment implies that the authors should conduct such analysis, it does not provide explicit instructions on how to do so or what specific aspects to focus on. The action is clear but somewhat vague, as the authors know they need to include results and analysis but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results and analysis on lengthy dialogue samples, specifically asking whether performance will drop on these samples. However, it does not specify which part of the paper this analysis should be included in, such as a specific section or table. The authors can infer that it relates to the results or analysis section, but this inference is not direct. The comment is specific in its request for analysis on lengthy dialogues, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include results and analysis on the lengthy dialogue samples, specifically asking whether the performance will drop on these samples. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include results and analysis on the lengthy dialogue samples, specifically asking whether the performance will drop on these samples. This feedback is somewhat helpful as it identifies a potential area for further exploration and analysis in the paper. However, the comment lacks specific guidance on how to conduct this analysis or what specific aspects to focus on. While it points out a potential weakness, it does not provide detailed instructions or examples on how to address it. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include natural modalities, such as audio and visual, for better evaluation. While it references specific works that discuss the importance of multi-modal evaluation, it does not provide explicit instructions on how to incorporate these modalities or what specific aspects of the paper need to be revised to include them. The action is implicit and somewhat vague, as the authors need to infer that they should include additional modalities but are not given specific guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include natural modalities, such as audio and visual, for better evaluation. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on evaluation methods. The references to external works, [1], [2], and [3], provide some context but do not fully ground the comment. The authors can infer that it relates to the evaluation section, but this inference is not direct. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include natural modalities, such as audio and visual, for better evaluation. The reviewer supports this claim by referencing three external works that discuss the importance of multi-modal evaluation in computer vision tasks. These references provide a logical basis for the suggestion, as they demonstrate the benefits of incorporating multiple modalities in evaluating models. However, the comment could be strengthened by providing more detailed analysis or examples of how these modalities could enhance the evaluation. Overall, the claim is mostly verifiable, as it is supported by relevant references but could be further substantiated with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the paper should include natural modalities, such as audio and visual, for better evaluation. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper\\'s evaluation methodology. However, the comment lacks specific guidance on how to incorporate these modalities or what aspects of the evaluation would benefit from this addition. While the references to external works provide some context, they do not offer detailed suggestions on how to implement this change. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide actionable steps for the authors to follow.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the oracle-context model is similar to prompt tuning works, such as Visual Prompt Tuning and Prompt Learning for Vision-Language Models, but these works are not discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether these works should be discussed, how they might be integrated into the paper, or what potential benefits or drawbacks of this comparison might be. As a result, the authors are left without any clear direction on how to address this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"oracle-context model\" and \"prompt tuning works,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the similarity between the oracle-context model and prompt tuning works like Visual Prompt Tuning and Prompt Learning for Vision-Language Models, and it suggests that these works should be discussed in the paper. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the oracle-context model is similar to prompt tuning works like Visual Prompt Tuning and Prompt Learning for Vision-Language Models, but these works are not discussed in the paper. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the comparison and how it relates to their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the oracle-context model is similar to prompt tuning works like Visual Prompt Tuning and Prompt Learning for Vision-Language Models, but these works are not discussed in the paper. This feedback highlights a gap in the literature review and suggests that the authors should consider discussing these related works to provide a more comprehensive understanding of their approach. However, the comment does not offer specific guidance on how to integrate these works into the paper or what aspects of the comparison should be emphasized. While it points out an area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of depth in the paper, specifically noting that it only discusses the observed phenomenon without exploring how to use the insights gained to design better resilient systems. It suggests that the paper could provide more insights into how to use these observations to design better systems, such as by proposing a defense method that resembles a hierarchical system. While the comment implies that the authors should consider these suggestions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these ideas further. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discussed the observed phenomenon, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of exploration into how to use the insights gained from the observations to design better resilient systems. The comment suggests that the paper could provide more insights into how to use these observations to design better systems, such as by proposing a defense method that resembles a hierarchical system. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks depth in exploring how to use the insights gained from the observed phenomenon to design better resilient systems. It suggests that the paper could provide more insights into how to use these observations to design better systems, such as by proposing a defense method that resembles a hierarchical system. The comment provides a logical reasoning for the need to explore these insights, but it lacks specific examples or references to support the claim. While the suggestion is reasonable, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that it only discusses the observed phenomenon without exploring how to use the insights gained to design better resilient systems. It suggests that the paper could provide more insights into how to use these observations to design better systems, such as by proposing a defense method that resembles a hierarchical system. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in order to enhance the depth and significance of their work. However, the comment could be more helpful if it offered examples or detailed guidance on how to implement these suggestions. Overall, the comment is mostly helpful as it effectively points out a gap in the paper and provides a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors are evaluating a form of reliability or trust by looking at what LLMs \"know,\" but no rigorous definitions are provided. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific definitions should be included. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the evaluation of reliability or trust in the context of LLMs and mentions the lack of rigorous definitions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the absence of rigorous definitions, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors are evaluating a form of reliability or trust by looking at what LLMs \"know\" but do not provide rigorous definitions. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the authors are evaluating a form of reliability or trust by looking at what LLMs \"know\" but do not provide rigorous definitions. This is a relevant observation that could impact the clarity and robustness of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of definitions or providing examples of what rigorous definitions might entail. While it points out a potential weakness, the feedback does not offer actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also questions the impact on computational efficiency, given the apparent larger forecasting horizons compared to history lengths in experiments from Appendix E.2. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to provide a rationale for the choice of masked self-attention and address the computational efficiency concerns, but the comment lacks specific guidance on how to present this information. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Y-Future encoder and Appendix E.2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the questions about the necessity of masked self-attention and the preference for ProbSparse, as well as the potential impact on computational efficiency. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also questions the impact on computational efficiency, given the apparent larger forecasting horizons compared to history lengths in experiments from Appendix E.2. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. While it highlights potential issues, the lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is somewhat verifiable, as it provides a starting point for the authors to explore but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the necessity of masked self-attention in the Y-Future encoder and the preference for ProbSparse, as well as the potential impact on computational efficiency given the apparent larger forecasting horizons compared to history lengths in experiments from Appendix E.2. These questions prompt the authors to reconsider their choices and provide a rationale for their decisions. However, the comment could be more helpful if it offered specific suggestions or examples to support the authors in their analysis or provided guidance on how to address the computational efficiency concerns. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific theoretical frameworks or methods to explore, or suggesting ways to integrate the analysis into the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the theoretical analysis of deep layer parameters and their suitability for distillation, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspects of the theoretical analysis are lacking or how the authors should address this issue. The comment is specific in identifying the need for a theoretical analysis but lacks detailed guidance on how to improve it. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the theoretical analysis of why deep layer parameters are more suitable for distillation. This is a relevant and actionable point that could help the authors enhance their draft by providing a more comprehensive theoretical justification for their claims. However, the comment lacks specific suggestions or guidance on how to conduct this analysis or what aspects to focus on. While it highlights an important area for improvement, it could be more helpful with additional details or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that important paper details are in the appendix, indicating that the paper is not self-contained. However, it does not provide specific guidance on how to address this issue or what changes should be made to make the paper more self-contained. The authors are left to infer that they need to integrate more information into the main text, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment points out that important paper details are in the appendix, indicating that the paper is not self-contained. However, it does not specify which details are in the appendix or where they should be integrated into the main text. Without specific references or examples, the authors cannot confidently determine which parts need to be addressed. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that important paper details are in the appendix, indicating that the paper is not self-contained. However, it does not provide specific examples or reasoning to support this claim, nor does it offer suggestions on how to improve the self-containment. Without detailed evidence or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that important details are relegated to the appendix, making the paper less self-contained. This is a critical observation that could impact the readability and comprehensiveness of the paper. However, the comment lacks specific guidance on how to address this issue, such as suggesting which details should be integrated into the main text or how to improve the self-containment. While it points out a problem, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the argument that gradient descent-based methods allow scaling to large datasets but questions the authors\\' choice of dataset size, suggesting that 50K points might not be considered large enough. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific aspects of the dataset size should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the argument that gradient descent-based methods allow scaling to large datasets, but it questions the authors\\' choice of dataset size, suggesting that 50K points might not be considered large enough. However, it does not specify which part of the paper this critique is based on, such as the methodology or results sections. The authors might infer that it relates to the dataset used in the experiments, but this inference is not direct. The comment is specific in its critique of the dataset size but lacks grounding as it does not explicitly mention where in the paper this issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim that their dataset size of 50K points is considered large enough for gradient descent-based methods. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges the argument that gradient descent-based methods allow scaling to large datasets but questions the authors\\' choice of dataset size, suggesting that 50K points might not be considered large enough. This feedback highlights a potential weakness in the paper\\'s methodology, as it implies that the authors might need to justify their choice of dataset size or consider larger datasets for their analysis. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what criteria they should use to determine dataset size. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the assumptions and questions the difficulty of overloading the library with ASD subroutines (assumption 3.2). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps the authors should consider to validate the assumptions. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"assumption 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the practicality of the assumption and the difficulty of overloading the library with ASD subroutines. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the practicality of the assumptions and the difficulty of overloading the library with ASD subroutines (assumption 3.2). However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of the assumptions and questions the difficulty of overloading the library with ASD subroutines (assumption 3.2). While it identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or validate the assumptions. The comment could be more helpful if it provided examples or references to similar studies that have successfully addressed similar challenges or offered suggestions on how to demonstrate the practicality of the assumptions. As it stands, the comment provides some insight but lacks actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the paper lacks excitement by utilizing a methodology commonly used in data augmentation. However, it does not provide any specific guidance or suggestions on how to address this issue or what aspects of the methodology could be improved to generate more excitement. The comment is vague and lacks actionable details, leaving the authors uncertain about how to enhance their draft to increase excitement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks excitement due to the use of a methodology commonly used in data augmentation. However, it does not specify which part of the paper this issue is related to, such as the methodology section or the results section. Without explicit references to specific sections or details, the authors cannot confidently determine where to address this feedback. The comment is not grounded and lacks specificity, making it difficult for the authors to understand and act upon the suggestion. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper lacks excitement due to the use of a methodology commonly used in data augmentation. However, it does not provide any specific examples, references, or reasoning to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper lacks excitement due to the use of a methodology commonly used in data augmentation. However, it does not provide any specific guidance or suggestions on how to address this issue or what aspects of the methodology could be improved to generate more excitement. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with a claim made in the paper, stating that the results presented in Fig. 4 show that multi-image IMP does not significantly improve the quality of LIPs in the cross-domain setting. However, the comment does not provide any guidance on how the authors should address this issue or what changes should be made to the paper. It lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4\" and \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made in section 4, stating that the results presented in Fig. 4 show that multi-image IMP does not significantly improve the quality of LIPs in the cross-domain setting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some statements in the paper are incorrect, specifically mentioning a claim in section 4 about the performance of multi-image IMP. The reviewer supports this claim by referencing Fig. 4, which supposedly shows that multi-image IMP does not significantly improve the quality of LIPs in the cross-domain setting. However, the comment does not provide detailed analysis or reasoning to support why this claim is incorrect or how it affects the overall conclusion. This lack of explanation makes the claim somewhat verifiable, as the authors would need to further investigate the data and analysis presented in the paper to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, pointing out that some statements are incorrect. It provides a detailed example by referencing Fig. 4, where the authors claim that multi-image IMP significantly improves the quality of LIPs in the cross-domain setting. However, the reviewer notes that the figure actually shows that multi-image IMP performs essentially the same as other methods. This feedback is valuable as it highlights a clear error in the paper that the authors need to correct. By addressing this issue, the authors can improve the accuracy and credibility of their results. Therefore, the comment is mostly helpful as it provides actionable feedback for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the rank in the VLN Leaderboard is 22-th and that the results of the proposed method are not better than existing methods, specifically mentioning [1,2,3]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the results or what aspects of the method need to be addressed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the VLN Leaderboard rank and the specific methods being compared, such as [1,2,3]. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies that the results of the proposed method are not better than existing methods, providing examples of these methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rank in the VLN Leaderboard is 22-th and that the results of the proposed method are not better than existing methods, specifically mentioning [1,2,3]. The reviewer provides references to specific works, such as [1] Zhu F, Zhu Y, Chang X, et al. Vision-language navigation with self-supervised auxiliary reasoning tasks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 10012-10022, [2] Tan, Hao, Licheng Yu, and Mohit Bansal. \"Learning to navigate unseen environments: Back translation with environmental dropout.\". [3] Ke, Liyiming, et al. \"Tactical rewind: Self-correction via backtracking in vision-and-language navigation.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019. This provides a strong basis for the claim, as it references well-known works in the field. However, the comment could be strengthened by providing a more detailed analysis or critique of the methodology or results compared to these existing methods. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out that the rank in the VLN Leaderboard is 22-th and that the results of the proposed method are not better than existing methods, specifically mentioning [1,2,3]. This feedback is somewhat helpful as it highlights a potential weakness in the paper\\'s results, which could be a concern for the authors. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the method\\'s performance. It lacks actionable advice or detailed analysis, which would help the authors understand how to improve their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion in section 2.2 regarding the modeling of semantic similarity is not convincing. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on what specific aspects of the discussion need improvement or how to improve it. Without actionable advice or suggestions, the authors are left without a clear path forward to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the discussion on semantic similarity modeling with the proposed approach. This provides clear guidance on what aspect of the paper needs improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in section 2.2 is not convincing regarding the modeling of semantic similarity with the proposed approach. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the discussion in section 2.2 regarding the modeling of semantic similarity is not convincing. However, it does not provide any guidance or suggestions on how the authors might improve this section or what specific aspects of the discussion need clarification or enhancement. Without actionable feedback or detailed feedback, the authors are left without a clear path forward to address the issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and guidance on how to address it. The comment is concrete in its instructions, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SEPAI3R3O model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the model, which introduces over 10 parameters and the challenges of estimation from limited real-world observations. The comment suggests discussing the uncertainty in fitted parameter values and providing sensitivity analysis, providing clear guidance on how to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the SEPAI3R3O model introduces over 10 parameters, which may be difficult to estimate reliably given limited real-world observations. It suggests that modeling these parameters as time-varying exacerbates the estimation challenge from scarce data. The comment provides a logical reasoning by highlighting the potential challenges in estimating these parameters and recommends discussing the uncertainty in fitted parameter values and conducting sensitivity analysis. However, the comment lacks specific examples or references to support the claim about the difficulty of estimation or the benefits of sensitivity analysis. This makes the claim somewhat verifiable, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed SEPAI3R3O model, noting that it introduces over 10 parameters, which may be difficult to estimate reliably given limited real-world observations. It suggests that modeling these parameters as time-varying exacerbates the estimation challenge from scarce data. The comment provides a clear and actionable suggestion for the authors to discuss the uncertainty in fitted parameter values and conduct sensitivity analysis. This feedback is valuable as it highlights a critical aspect of the model that could impact its reliability and suggests a method for addressing this issue. However, the comment could be more helpful if it provided specific examples or references to similar models or studies that have addressed similar challenges. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the assumption that causal parameters across domains are random samples, suggesting that it may not be a consequence of not having latent confounders in the system. It also points out that the performance of the proposed method and the relative performances of other methods could depend on how the parameters change across domains. The reviewer raises a valid concern about the trustworthiness of the output and the methods used, but does not provide specific guidance on how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the assumption that causal parameters across domains are random samples, suggesting that it may not be a consequence of not having latent confounders in the system. It also discusses the performance of the proposed method and the relative performances of other methods, such as MC, IB, and HSIC test, in relation to how parameters change across domains. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in questioning the assumption and its implications, but without clear references to specific sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the assumption that causal parameters across domains are random samples, suggesting that it may not be a consequence of not having latent confounders in the system. The reviewer also raises concerns about the performance of the proposed method and the relative performances of other methods, such as MC, IB, and HSIC test, in relation to how parameters change across domains. The comment is somewhat verifiable as it provides a logical reasoning for questioning the assumption and highlights the potential impact on the results. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the assumption that causal parameters across domains are random samples, suggesting that it may not be a consequence of not having latent confounders in the system. It also raises a valid concern about the performance of the proposed method and the relative performances of other methods, such as MC, IB, and HSIC test, in relation to how parameters change across domains. The reviewer points out that if the parameters are not changing, the output and the methods used may not be trustworthy. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. While it identifies potential weaknesses and areas for consideration, it does not provide actionable feedback or detailed advice. Therefore, the comment is somewhat helpful, as it highlights important issues but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the novelty of the structural optimization method, suggesting that it may not be new. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of novelty or how to clarify the method's novelty in the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of the structural optimization method, suggesting that it may not be new. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the novelty claim, but it lacks grounding as it does not identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the structural optimization method, suggesting that it may not be new. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient evidence or justification to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the novelty of the structural optimization method, suggesting that it may not be new. However, it does not provide any specific examples or reasoning to support this claim, nor does it offer suggestions for how the authors might address this issue. Without actionable feedback or detailed guidance, the comment does not assist the authors in improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proof, noting that the assumption of lambda not being 0.5 may not be correct, as standard mixup can generate mixed samples even with lambda being 0.5. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the proof. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider the assumption but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proof,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proof assumes lambda not to be 0.5, which is a standard value in mixup generation. This specificity helps the authors understand the problem and address it effectively. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof assumes lambda not to be 0.5, which is a standard value in mixup generation. However, it does not provide any supporting evidence or references to substantiate this claim. The comment lacks detailed reasoning or examples to justify why this assumption might be incorrect, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proof, noting that the assumption of lambda not being 0.5 may not be correct, as standard mixup can generate mixed samples even with lambda being 0.5. This is a relevant observation that could impact the validity of the proof. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the proof. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests that the authors highlight which set of equations has the same form as the Riccati equation and suggests extracting some inlined math into environments to facilitate looking up symbols. These are clear and concrete actions that the authors can take to improve the clarity and accessibility of their draft. The comment provides specific guidance on what to highlight and where to extract the math, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paragraph above Theorem 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be highlighted (the set of equations with the same form as the Riccati equation) and suggests extracting some inlined math into environments to facilitate looking up symbols. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of requests for clarification and suggestions for improvement. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by requesting that the authors highlight which set of equations has the same form as the Riccati equation and suggesting the extraction of some inlined math into environments to facilitate looking up symbols. This guidance is clear and constructive, as it directly addresses issues of clarity and accessibility in the paper. By following these suggestions, the authors can enhance the readability and usability of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete suggestions for improving the clarity of the writing. It explicitly mentions specific sections that could benefit from clearer structure and transitions, such as line 257, and suggests that subjective terms like \"significant\" would be clearer with statistical evidence like p-values. This feedback is clear and actionable, as it directly instructs the authors on what changes to make to improve the clarity of their writing. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"line 257,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for clearer structure and transitions in certain sections and the clarification of subjective terms like \"significant\" with statistical evidence like p-values. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that certain sections of the paper could benefit from clearer structure and transitions, and that subjective terms like \"significant\" could be clarified with statistical evidence like p-values. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to clarify subjective terms with statistical evidence is logical, but the comment could be strengthened with more specific examples or references to similar studies. Therefore, the claim is somewhat verifiable, as it provides a clear direction but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on improving the clarity of the writing. It identifies specific sections that could benefit from clearer structure and transitions, such as line 257, and suggests that subjective terms like \"significant\" could be clarified with statistical evidence like p-values. This feedback is clear and directs the authors to make specific improvements that can enhance the readability and comprehensibility of their paper. However, the comment could be more helpful if it provided examples of how to implement these improvements or offered additional guidance on how to present statistical evidence. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve the clarity of their writing.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of detailed information on graph construction, specifically mentioning the need for guidance on defining edges and constructing graphs for non-euclidean datasets. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is specific and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for detailed information on graph construction, specifically mentioning the need for guidance on defining edges and constructing graphs for non-euclidean datasets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what information is missing and what needs to be included. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the detailed information for graph construction is missing, specifically mentioning the need for guidance on defining edges and constructing graphs for non-euclidean datasets. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of detailed information on graph construction, particularly for non-euclidean datasets. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their work. By addressing this issue, the authors can enhance the understanding and applicability of their method for non-euclidean datasets. However, the comment could be more helpful if it provided suggestions on how to present this information or examples of how it might be addressed. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$ are determined, referencing a specific paper by En-Hui Yang et al. This is an explicit question that prompts the authors to clarify their methodology or provide additional information. However, the comment does not offer specific guidance on how to address this issue or what additional details should be included. While the action is clear, the lack of concrete suggestions on how to implement it makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific hyper-parameters $\\\\alpha$ and $\\\\beta$ and references a specific paper by En-Hui Yang et al. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for clarification on how these hyper-parameters are determined, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on how the default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$ are determined. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the determination of default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$, which is a relevant and important aspect of the methodology. By asking for clarification, the reviewer prompts the authors to provide more detailed information about their experimental setup and methodology. This feedback is somewhat helpful as it encourages the authors to clarify their approach, potentially improving the transparency and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context on why this clarification is important. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on the visual and textual representations used in each method, which is crucial for understanding the end-to-end performance gain. This feedback is clear and direct, providing a specific action for the authors to take. By addressing this question, the authors can improve the clarity and comprehensibility of their paper, ensuring that the reader can better understand the results. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the visual and textual representations used in each method and how they relate to the end-to-end performance gain. This provides clear guidance on what the authors need to clarify or expand upon in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the visual and textual representations used in each method. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the visual and textual representations used in each method, which is crucial for understanding the end-to-end performance gain. By asking for clarification on this point, the comment provides actionable feedback that can help the authors improve the clarity and comprehensibility of their paper. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the convergence analysis, including the lack of clarity in the main part of the paper and the appendix, as well as the absence of a clear presentation of notations and assumptions. It also points out that the proof is not clear and that Eq. (15) is not well justified. While the comment highlights specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to improve the clarity and presentation of the convergence analysis, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"convergence analysis\" and \"appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the convergence analysis, such as the lack of clarity in the main part and the appendix, the absence of a clear presentation of notations and assumptions, and the unclear justification of Eq. (15). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the convergence analysis is unclear and lacks clarity in the main part of the paper and the appendix. It specifically mentions the lack of clear presentation of notations and assumptions, as well as the unclear justification of Eq. (15). The comment provides some logical reasoning by pointing out the absence of a clear connection between the convergence analysis and the main part of the paper. However, it does not provide specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the convergence analysis, including the lack of clarity in the main part of the paper and the appendix, the absence of a clear presentation of notations and assumptions, and the unclear justification of Eq. (15). It provides specific feedback on what needs to be addressed, such as the need for a clearer presentation of notations and assumptions, and the need for a more detailed justification of Eq. (15). This feedback is actionable and can help the authors improve the clarity and rigor of their convergence analysis. However, the comment could be more helpful if it offered suggestions on how to present these elements more effectively or provided examples of how similar analyses have been presented in other works. Overall, the comment is mostly helpful as it identifies specific areas for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of clear and well-driven problems, insufficient description of uncertainty calibration, and the need to organize and summarize the studied issues. While the comment highlights specific areas that need improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they should organize and summarize the studied issues, but without detailed guidance on how to do so, the action remains vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues with the paper, such as the lack of well-driven and illustrated problems, insufficient description of uncertainty calibration, and the need to organize and summarize the studied issues. However, it does not explicitly mention which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need to organize and summarize the studied issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the studied problems are not well-driven and illustrated, specifically mentioning the insufficient description of uncertainty calibration. The comment suggests that the issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the specifics of what needs to be improved, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several weaknesses in the paper, including the lack of well-driven and illustrated problems, insufficient description of uncertainty calibration, and the need to organize and summarize the studied issues. It provides specific suggestions for improvement, such as organizing and summarizing the studied issues, which can help the authors clarify and strengthen their work. However, the comment could be more helpful if it offered additional guidance on how to effectively organize and summarize the content. Overall, the feedback is somewhat helpful as it points out areas for improvement but lacks detailed guidance, making it somewhat actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the exploration of the incorporation of PAC-tuning with other fine-tuning techniques, such as pruning and data augmentation. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider including results on the incorporation of PAC-tuning with other techniques, but it lacks concrete steps or detailed instructions on how to conduct these experiments or what specific aspects to focus on. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of results exploring the incorporation of PAC-tuning with other fine-tuning techniques, such as pruning and data augmentation. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what is missing, namely the exploration of PAC-tuning with other fine-tuning techniques. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no results exploring the incorporation of PAC-tuning with other fine-tuning techniques, such as pruning and data augmentation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the exploration of the incorporation of PAC-tuning with other fine-tuning techniques, such as pruning and data augmentation. This is a relevant and important area for further investigation, as it could potentially enhance the paper\\'s contribution and impact. However, the comment lacks specific guidance or suggestions on how the authors might address this gap, such as which techniques to explore or how to integrate them into their work. While it points out a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to validate their experimental analysis on more models, providing a specific reference to the fourth question below. This direct suggestion gives the authors a clear action to take, ensuring they know exactly what needs to be done to improve their draft. The comment is explicit and provides concrete guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental analysis\" and the \"fourth question below,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficiency of the experimental analysis and the need to validate it on more models. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental analysis is insufficient and should be validated on more models. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental analysis, noting that it is insufficient and should be validated on more models. It provides a clear and actionable suggestion by referencing the fourth question below, which suggests that the authors should expand their validation efforts. This feedback is valuable as it directs the authors to a specific area that needs improvement, offering a concrete step to enhance the robustness and credibility of their work. However, the comment could be more helpful if it provided additional guidance on how to select the additional models or what specific aspects of the analysis should be validated. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed method improves over the original initialization but only shows marginal improvement in the ImageNet experiments. It references external works that discuss the limitations of BN and the challenges of training very deep networks. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their method. It lacks specific suggestions or actions for the authors to take, leaving them without clear direction on how to enhance their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the improvement of the proposed method over the original initialization and the limitations in the ImageNet experiments. It references external works, such as [1] and [2], which provide context and background information. However, the comment does not specify which part of the paper discusses the improvement or the ImageNet experiments, making it weakly grounded. The comment is specific in detailing the limitations of the proposed method and the need for further improvement, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method improves over the original initialization but only shows marginal improvement in the ImageNet experiments. It supports this claim by referencing external works, such as [1] and [2], which discuss the limitations of BN and the challenges of training very deep networks. However, the comment does not provide detailed analysis or specific examples from these references to substantiate the claim. While the references offer some context, the comment lacks sufficient explanation and evidence to fully support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed method, noting that it only shows marginal improvement over the baselines in the ImageNet experiments. It also references external works that discuss the challenges of training very deep networks and the limitations of BN normalization. While the comment highlights a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their method. The references to external works are helpful, but the comment could be more actionable by offering concrete steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add a discussion comparing the robustness and immunizability of their proposed method and the method proposed in Yu et al. 2021. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and guidance on how to address it. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a discussion comparing the robustness and immunizability of the proposed method and the method proposed in Yu et al. 2021. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular comparison to be made, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should add a discussion comparing the robustness and immunizability of their proposed method and the method proposed in Yu et al. 2021. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should add a discussion comparing the robustness and immunizability of their proposed method and the method proposed in Yu et al. 2021. This feedback is somewhat helpful as it identifies a specific area for improvement, namely the inclusion of a comparison that could enhance the paper\\'s contribution. However, the comment lacks depth and does not provide detailed guidance on how to conduct this comparison or what specific aspects to focus on. While it points out a potential gap in the paper, it could be more helpful if it offered more detailed suggestions or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the proposed algorithm for adaptive top-k decoding and requests clarification. It suggests that the reviewer is open to revising their assessment based on the answers to the questions raised. However, it does not provide explicit guidance on what specific questions need to be addressed or how to address them. The comment also mentions the need for a plot of time complexity as a function of m, but this is not a direct action for the authors to take. While the comment implies that the authors should provide clarification or additional information, it lacks concrete steps for how to do so. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3) this work proposes an algorithm for adaptive top-k decoding,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the proposed algorithm and requests clarification, as well as suggesting a plot of time complexity as a function of m. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the proposed algorithm for adaptive top-k decoding, suggesting that it may produce \"better\" samples. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed analysis to justify the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the proposed algorithm for adaptive top-k decoding, suggesting that it may produce \"better\" samples. It acknowledges that the reviewer is open to revising their assessment based on the authors\\' response. However, the comment lacks specificity and does not provide any detailed feedback or suggestions on how the authors might address the question or improve their work. While it prompts the authors to clarify their claims, it does not offer actionable guidance or constructive feedback. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the postprocessing effort mentioned in footnote 2. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the postprocessing effort, but it lacks concrete instructions or examples on how to do so. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to implement the suggested improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"footnote 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the postprocessing effort. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the postprocessing effort mentioned in footnote 2. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the effort is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the postprocessing effort mentioned in footnote 2. It points out that the authors need to provide more information on this aspect, which is a valid observation. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might clarify this aspect or what specific information should be included. While it highlights an area for improvement, it does not provide actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to run their codes for multiple seeds and report the mean. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific step to follow, ensuring that the authors know exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions running the codes for multiple seeds and reporting the mean, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely running the codes for multiple seeds and reporting the mean. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should run their codes for multiple seeds and report the mean. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should run their codes for multiple seeds and report the mean. This is a clear and actionable piece of feedback that can help the authors improve the robustness and generalizability of their results. By suggesting this, the reviewer provides a straightforward way for the authors to enhance the quality and credibility of their work. However, the comment could be more helpful if it explained why running the codes for multiple seeds is important or how it would impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for BCI and IHC4BC in the paper. It specifically mentions that Table 3 lacks results for models like InceptionV3 and ResNet, while Table 2 includes them. While the comment identifies areas that need clarification or additional information, it does not provide explicit instructions or suggestions on how to address these issues. The authors can infer that they need to provide more detailed information about the datasets and the experimental setup, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of results for models like InceptionV3 and ResNet in Table 3, while they are included in Table 2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for BCI and IHC4BC in the paper. It specifically mentions that Table 3 lacks results for models like InceptionV3 and ResNet, while Table 2 includes them. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these differences are significant or how they impact the results. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the differences between the BCI and IHC4BC datasets and the experimental setup for BCI and IHC4BC in the paper. It specifically points out that Table 3 lacks results for models like InceptionV3 and ResNet, while Table 2 includes them. This feedback highlights a potential inconsistency in the experimental setup and datasets used, which could impact the validity and comparability of the results. By identifying these discrepancies, the comment provides the authors with a clear direction for improving the clarity and completeness of their experimental setup and results. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar discrepancies have been handled in similar studies. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more thorough description of the results shown in Figure 4. This is a direct and concrete action, as it clearly specifies what needs to be done to improve the draft. The authors know exactly what additional information is required and how to present it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a more thorough description of the results shown in Figure 4. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results shown in Figure 4 need a more thorough description. However, it does not provide any specific reasoning or examples to support why this is necessary or how a more thorough description would benefit the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area for improvement, namely the need for a more thorough description of the results shown in Figure 4. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the understanding and interpretation of the results. However, the comment could be more helpful if it offered specific suggestions on what aspects of the results should be elaborated upon or how the additional description could be structured. Overall, the comment provides a clear direction for improvement, but it could be more comprehensive to fully support the authors in enhancing their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the most relevant literature is [11] and recommends comparing it with the work in the method section or in more detail. While the comment implies that the authors should include a comparison with [11], it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the most relevant literature is [11] and recommends comparing it with the work in the method section or in more detail. However, it does not specify which part of the paper this comparison should be made, such as a specific section or table where the comparison should be included. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in recommending a comparison with [11], but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the most relevant literature is [11] and recommends comparing it with the work in the method section or in more detail. However, the comment does not provide any supporting evidence, reasoning, or references to justify why [11] is considered the most relevant literature or how it should be compared. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the most relevant literature is [11] and recommends comparing it with the work in the method section or in more detail. While this feedback provides a specific suggestion for improvement, it lacks depth and does not offer detailed guidance on how to conduct the comparison or what aspects to focus on. The authors are given a direction but not enough detail to fully understand and implement the suggested changes. Therefore, the comment is somewhat helpful, as it provides a starting point but could be more actionable with additional context and specifics.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the justification of the paper\\'s process of removing words with identical English counterparts in the class label translation and cleaning, suggesting that there may be legitimate shared words between the English and language-specific vocabulary. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the process. The reference to an external work, [1] Ten Years of BabelNet: A Survey, provides some context but does not offer detailed instructions on how to apply this information to improve the paper. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the justification for the process and potentially revise it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the justification of the paper\\'s process of removing words with identical English counterparts in the class label translation and cleaning, suggesting that there may be legitimate shared words between the English and language-specific vocabulary. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or methodology. Additionally, it lacks specificity regarding what aspects of the justification are questionable or how the authors should address this issue. Without clear guidance on the part of the paper being addressed, the authors cannot effectively identify and address the concern. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the justification of the paper\\'s process of removing words with identical English counterparts in the class label translation and cleaning, suggesting that there may be legitimate shared words between the English and language-specific vocabulary. The reviewer provides a reference to an external work, [1] Ten Years of BabelNet: A Survey, which supports the claim that there can be shared words between the two vocabularies. However, the comment does not provide detailed reasoning or examples from the external work to fully substantiate the claim. While the reference adds some credibility, the comment lacks sufficient explanation and evidence to fully verify the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the justification of the paper\\'s process of removing words with identical English counterparts in the class label translation and cleaning, suggesting that there may be legitimate shared words between the English and language-specific vocabulary. While the comment identifies a potential weakness in the paper\\'s methodology, it lacks specific guidance or suggestions on how the authors might address this issue or improve the justification for the process. The reference to an external work, [1] Ten Years of BabelNet: A Survey, provides some context but does not offer actionable advice for the authors. Overall, the comment highlights a potential area for improvement but does not provide detailed guidance or suggestions for enhancing the paper. Therefore, it is somewhat helpful, as it points out a weakness but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the study should focus on more models to verify the findings. While it implies that the authors should expand their study to include additional models, it does not provide specific guidance on which models to include or how to conduct the additional studies. The action is implicit and somewhat vague, as the authors need to infer the need for additional models and determine which ones to study. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the study focuses too much on LLaVA and InstructBLIP and draws conclusions for large vision-language models. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the study should include more models to verify the findings, but without explicit references to sections or figures, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the study focuses too much on LLaVA and InstructBLIP and draws conclusions for large vision-language models. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the study focuses too much on LLaVA and InstructBLIP and draws conclusions for large vision-language models. It recommends studying more models to verify the findings. While the comment identifies a potential limitation in the study\\'s scope, it lacks specific guidance on which models to include or how to conduct the additional studies. This limits the comment\\'s helpfulness, as it provides a general direction but does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the norm reduction shown in Figure 7 and the lack of significant improvement for object localization in Table 3. It suggests that an explanation or exploration of the reason behind this discrepancy would be helpful for wider adoption. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation, but it is clear that this is what is expected. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the discrepancy in the norm reduction shown in Figure 7 and the lack of significant improvement for object localization in Table 3, suggesting that an explanation or exploration of the reason behind this discrepancy would be beneficial for wider adoption. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the norm shows significant reduction for OpenCLIP in Figure 7 but does not show significant improvement for object localization, which is the main benefit of using register. The reviewer suggests that an explanation or exploration of the reason behind this discrepancy would be helpful for wider adoption. However, the comment lacks specific examples or references to support the claim that the norm reduction is significant or that the lack of improvement in object localization is unexpected. Without detailed evidence or reasoning, the claim is somewhat verifiable, as it requires the authors to make a leap of faith to understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the norm reduction shown in Figure 7 and the lack of significant improvement for object localization in Table 3, which is the main benefit of using register. It suggests that an explanation or exploration of the reason behind this discrepancy would be helpful for wider adoption. While the comment highlights an important issue, it does not provide specific guidance on how the authors might address this discrepancy or what kind of explanation would be beneficial. The feedback is somewhat helpful as it points out a potential problem but lacks detailed suggestions for improvement, making it somewhat helpful for the authors to understand the issue but not fully actionable. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the use of 3D renders in conjunction with GANs, specifically mentioning Section 3.3. It suggests that more details about how the 3D rendering and GAN objective are combined would be helpful. While the comment implies that the authors should provide more information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details but may not be entirely sure of what specific information is missing. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of 3D renders in conjunction with GANs and the lack of details about how the Point cloud is used in this stage. The comment provides a clear direction for improvement by suggesting that more details about the combination of 3D rendering and GAN objectives would be helpful. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how 3D renders are used in conjunction with GANs, specifically mentioning Section 3.3. It suggests that more details about the use of 3D renders and the GAN objective are needed. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that the current explanation is unclear. The authors are left to infer the need for more details, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the use of 3D renders in conjunction with GANs, particularly in Section 3.3. It points out that while the latent code z is used to modulate the weights of the rendering network, the use of the Point cloud in this stage is unclear. The comment suggests that more details about the combination of 3D rendering and GAN objectives would be helpful. This feedback is clear and actionable, as it provides a specific area for improvement and offers a direction for enhancing the clarity of the paper. However, it could be more helpful if it included suggestions on how to present this information or examples of how similar concepts have been addressed in related work. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and comprehensibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the increased complexity of the QIF model compared to the traditional LIF model, noting that the supporting evidence for parameter insensitivity relies heavily on simple architectures and datasets. However, it does not provide specific guidance on how the authors should address this issue or what additional evidence or analysis would be needed to strengthen their claims. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the increased complexity of the QIF model compared to the traditional LIF model, specifically noting the introduction of additional hyperparameters and the claim of parameter insensitivity. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the reliance on simple architectures and datasets for supporting evidence, which provides some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the supporting evidence for parameter insensitivity in the QIF model is insufficient, as it relies heavily on simple architectures and datasets. However, the comment does not provide specific examples or references to these architectures or datasets, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or examples, the claim remains vague and unverifiable, as it lacks the necessary support to substantiate the critique. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the increased complexity of the QIF model compared to the traditional LIF model, specifically noting the introduction of additional hyperparameters. It points out that the supporting evidence for parameter insensitivity relies heavily on simple architectures and datasets, which is not convincing. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the evidence presented. While it highlights a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements might be possible with other PLMs. It also suggests discussing the meaningful aspects of the proposed method and experiments in the context of LLMs. While the comment implies that the authors should consider these points, it does not provide explicit instructions or concrete steps on how to address them. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the computational costs and real-world scenarios. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of marginal improvements over baselines and suggests that further improvements might be achievable with other PLMs. It also mentions specific PLMs like RoBERTa, T5, vicuna, and llama-2. However, it does not specify which part of the paper discusses these improvements or where these PLMs are mentioned. The authors can infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in suggesting improvements and discussing the context of LLMs, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements might be possible with other PLMs. The reviewer provides a logical reasoning by mentioning specific PLMs like RoBERTa, T5, vicuna, and llama-2, which could potentially achieve better results. However, the comment lacks specific examples or detailed evidence to support the claim that these PLMs would lead to better results. While the suggestion is logical, the lack of detailed justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements might be possible with other PLMs. It also encourages the authors to discuss the meaningful aspects of their proposed method and experiments in the context of LLMs, such as computational costs or real-world scenarios. While the comment identifies a potential area for improvement and provides a direction for further exploration, it lacks specific suggestions or guidance on how to address these issues. The authors are given a general direction but may need to infer the exact steps to take. Therefore, the comment is somewhat helpful, as it provides a starting point for the authors to consider but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the explanation of using soft assignment instead of hard assignment is discussed in the methodology section but lacks an experiment to prove the conjecture. However, it does not provide explicit guidance on what kind of experiment should be conducted or how to conduct it. The authors are left to infer that they need to include an experiment to address this issue, but without specific instructions or examples, the action remains vague. Therefore, the comment is somewhat actionable, as it identifies a gap but lacks concrete details on how to implement the suggested action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"methodology\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the explanation of using soft assignment instead of hard assignment is discussed but lacks an experiment to prove the conjecture. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of an experiment to prove the conjecture regarding the use of soft assignment instead of hard assignment. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the lack of an experiment to prove the conjecture about using soft assignment instead of hard assignment. This is a relevant point that could impact the validity and robustness of the methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what kind of experiment would be appropriate. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the methods presented make sense in the cross-silo setting but points out that their applicability is limited to general federated learning problems with a larger number of clients. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation or improve the applicability of their methods. There is no guidance on how to expand the methods to accommodate a broader range of clients or how to enhance their generalizability. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the applicability of the methods presented in the paper, specifically noting that they are mostly effective in the cross-silo setting. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment provides some insight into the applicability issue, it lacks specificity regarding what aspects of the methods need improvement or how they could be adapted to address the limitation. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the methods presented are mostly effective in the cross-silo setting, as mentioned in the paper, and that this limits their applicability to general federated learning problems with a larger number of clients. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the methods presented in the paper are mostly effective in the cross-silo setting, as mentioned in the paper. It points out that this limitation in applicability extends to general federated learning problems with a larger number of clients, suggesting that the methods could benefit from generalization to new clients. While the comment identifies a potential issue with the applicability of the methods, it does not provide specific suggestions or guidance on how to address this limitation or improve the generalizability of the methods. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks actionable advice or detailed guidance for the authors to follow. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the concept of distributional generalization in the context of regression, suggesting that it might not be as surprising as initially thought. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of distributional generalization should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the concept of distributional generalization in the context of regression, suggesting that it might not be as surprising as initially thought. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its question about distributional generalization, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the concept of distributional generalization in the context of regression, suggesting that it might not be as surprising as initially thought. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it relates to their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the concept of distributional generalization in the context of regression, suggesting that it might not be as surprising as initially thought. However, it does not provide any actionable feedback or suggestions for the authors to address this question or improve their draft. Without specific guidance or examples, the authors are left without a clear path forward. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the references and baselines are out of date and recommends including more recent research. It also mentions that the authors could easily find relevant results by searching for specific terms like \"Item Frequencies of Data Streams.\" While the comment provides a general direction for improvement, it does not offer specific guidance on how to update the references or what specific recent research should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the references and baselines are out of date and recommends including more recent research. However, it does not specify which parts of the paper these references are in, making it difficult for the authors to pinpoint the exact sections that need updating. Additionally, the comment lacks specificity regarding what recent research should be included or how it should be integrated into the paper. Without clear guidance on the exact parts of the paper that need revision, the authors may struggle to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the references and baselines are out of date and suggests that more recent research should be included. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the current references are outdated. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the references and baselines are out of date. It suggests that the authors should include more recent research to provide a more comprehensive overview of the field. Additionally, it points out that the authors could easily find relevant results by searching for specific terms like \"Item Frequencies of Data Streams.\" While the comment highlights an important area for improvement, it lacks specific guidance on which recent studies should be included or how to effectively integrate them into the paper. This limits the comment\\'s helpfulness, as it provides a general direction but does not offer detailed suggestions for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the introduction, which focuses on computational challenges in scaling quadratic programs to high-dimensional action spaces, and the experimental analysis in Section 5, which primarily explores action constraints in lower-dimensional spaces. It suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. While the comment implies that the authors should conduct additional experiments in high-dimensional action spaces, it does not provide explicit instructions on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" and \"Section 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the discrepancy between the introduction, which highlights computational challenges in high-dimensional action spaces, and the experimental analysis in Section 5, which focuses on lower-dimensional spaces. The comment suggests that more in-depth analysis of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would be beneficial. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental analysis in Section 5 primarily explores action constraints in relatively lower-dimensional spaces, while the introduction highlights the computational challenges of scaling quadratic programs to high-dimensional action spaces. The comment suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This claim is somewhat verifiable as it logically points out a discrepancy between the introduction and the experimental analysis. However, it lacks specific examples or references to support the claim that the current analysis is insufficient for high-dimensional action spaces. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the introduction, which highlights the computational challenges of scaling quadratic programs to high-dimensional action spaces, and the experimental analysis in Section 5, which primarily explores action constraints in lower-dimensional spaces. It suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This feedback is somewhat helpful as it points out an area where the paper could be strengthened by expanding the experimental analysis to include high-dimensional action spaces. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of information regarding the extra computation required to achieve the experimental results. It suggests that the extra performance might be due to the extra parameters or extra computation needed. The reviewer implies that if the model were made to have the same floats, the performance might be similar to the original transformers. While the comment implies that the authors should provide more information about the extra computation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the extra computation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results and suggests that there is a lack of information on the extra computation required to achieve the good results. It implies that the extra performance might be due to extra parameters or extra computation, and suggests that if the model had the same floats, the performance might be similar to the original transformers. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion that the authors should provide more information about the extra computation required. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results are good but lacks information on the extra computation required to achieve such results. The reviewer suggests that the extra performance might be due to extra parameters or extra computation, implying that if the model had the same floats, the performance would be similar to the original transformers. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the extra computation. This makes the claim somewhat verifiable, as it provides a plausible argument but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the extra computation required to achieve the experimental results. It suggests that the extra performance might be due to the extra parameters or extra computation needed, and implies that if the model had the same floats, the performance might be similar to the original transformers. This feedback is somewhat helpful as it points out a potential area for improvement by suggesting that the authors should provide more information about the extra computation required. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of how similar models have been evaluated. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation and results are not convincing, as they do not show consistent trends and some improvements may not be statistically significant. However, it does not provide specific guidance on how to address these issues or what changes should be made to improve the results. The comment lacks actionable details, such as recommending additional analyses or statistical tests to strengthen the results. As a result, the authors are left without clear direction on how to improve the draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the evaluation and results, specifically mentioning that they are not convincing due to inconsistent trends and questionable statistical significance. However, it does not specify which parts of the paper these issues pertain to, such as specific sections or figures where these trends are discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in identifying issues with the results but lacks grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation and results are not convincing due to inconsistent trends and questionable statistical significance. However, it does not provide specific examples or detailed reasoning to support these claims. The comment lacks specific references or detailed analysis to substantiate the critique, making it difficult for the authors to understand and address the issues. As a result, the claim is considered borderline verifiable, as it provides some basis but lacks sufficient evidence or explanation to fully support the assertion. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation and results, noting that they are not convincing due to inconsistent trends and questionable statistical significance. This feedback is valuable as it highlights a critical area for improvement in the paper, which could impact the credibility and impact of the findings. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending additional analyses or statistical tests to strengthen the results. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should highlight the percentage of the error rate that is made up of subjective questions, as determined by the agreement among humans. This is a clear and explicit action that the authors can take to improve their draft. The comment provides a specific suggestion for how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of subjective questions and suggests that the authors highlight the percentage of the error rate made up of such questions. This allows the authors to identify the specific part of the paper being addressed, making it fully grounded. The comment is also specific because it provides a clear suggestion for addressing the issue by highlighting the percentage of subjective questions and their impact on the error rate. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that several questions require subjective answers and proposes a method to determine the percentage of the error rate made up of such questions. The reviewer provides a logical reasoning by suggesting that if the percentage is significantly high, it could be problematic. However, the comment lacks specific examples or references to support the claim that the error rate is significantly high due to subjective questions. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that several questions require subjective answers. It suggests a method for determining the percentage of the error rate that is made up of subjective questions, such as by looking at agreement among humans. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by addressing the issue of subjectivity in the error rate. By highlighting the potential problem of a high percentage of subjective questions, the comment offers a constructive way for the authors to enhance the clarity and reliability of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and named-entity recognition, in addition to the current evaluation on a single dataset. While the comment implies that the authors should consider these tasks, it does not explicitly instruct them to do so or provide specific guidance on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider additional tasks but may not be entirely sure how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks a comprehensive evaluation by only considering a single dataset and limited NLP tasks, specifically mentioning intent recognition. It suggests that additional tasks such as sentiment classification and named-entity recognition would improve the paper. However, the comment does not specify which part of the paper this critique pertains to, such as the methodology or results sections. While the authors might infer that it relates to the evaluation or experimental sections, the comment is not fully grounded as it does not explicitly mention these sections. The suggestion to consider additional tasks is specific, but the lack of grounding makes it challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comprehensive evaluation due to its focus on a single dataset and limited NLP tasks, specifically mentioning intent recognition. The comment suggests that additional tasks such as sentiment classification and named-entity recognition would improve the paper. However, the comment does not provide specific examples or references to support the claim that these additional tasks are necessary or how they would enhance the evaluation. The reasoning is somewhat verifiable, as it points out a potential limitation but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the evaluation is limited to a single dataset and a narrow set of NLP tasks, specifically mentioning intent recognition. It suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and named-entity recognition, to enhance the evaluation. This feedback is clear and actionable, as it provides specific tasks that could be included to improve the comprehensiveness and relevance of the evaluation. However, the comment could be more helpful if it offered guidance on how to integrate these additional tasks into the paper or provided examples of how they might be addressed. Overall, the comment is mostly helpful as it effectively points out a gap in the evaluation and suggests a way to improve it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the label for the \"class semantic feature\" in Figure 3 should be changed from \"c\" to \"s.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in the figure. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the label for the \"class semantic feature\" in Figure 3. The comment provides clear guidance on what needs to be changed, making it fully grounded and specific. Therefore, this comment is labeled as 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests changing the label for the \"class semantic feature\" in Figure 3 from \"c\" to \"s.\" However, the comment does not provide any reasoning, explanation, or evidence to support this suggestion. Without additional context or justification, the authors may find it difficult to understand why this change is necessary or beneficial. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is specific and actionable, as it points out a minor but important detail in the figure labeling. By suggesting that the label for the \"class semantic feature\" should be changed from \"c\" to \"s,\" the reviewer provides clear guidance on how to improve the clarity and accuracy of the figure. This feedback is valuable as it helps the authors ensure that their figures are correctly labeled and easy to understand, which is an important aspect of scientific communication. However, the comment could be more helpful if it explained why this change is necessary or how it might impact the overall understanding of the figure. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their method with state-of-the-art face swapping algorithms to clarify the distinction between de-identification and face swapping. This feedback provides a clear and explicit action for the authors to take, which is to conduct a comparison that can help establish a clearer boundary between the two approaches. The comment is specific in its request for a comparison, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the distinction between de-identification and face swapping, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to compare the proposed method with state-of-the-art face swapping algorithms to clarify the distinction between the two approaches. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method proposed in the paper is essentially a form of face swapping, similar to deepfake technology. The reviewer supports this claim by explaining the key difference between the two approaches, namely the target face in deepfake technology versus the target face derived from a 3DMM in the current work. However, the comment lacks specific examples or references to deepfake technologies or state-of-the-art face swapping algorithms to fully substantiate the claim. While the reasoning is logical, the lack of detailed evidence or references makes the claim somewhat verifiable, as it requires further elaboration to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the distinction between de-identification and face swapping. It points out that the method proposed in the paper appears to be a form of face swapping, similar to deepfake technology. The reviewer suggests that the authors should compare their method with state-of-the-art face swapping algorithms to clarify the distinction between the two approaches. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance the clarity and novelty of their work. By addressing this point, the authors can improve the understanding and impact of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results on word embeddings in Tables 1 and 2 are not compelling compared to Gaussian embeddings, the chief baseline from the literature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the results or what specific aspects need attention. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the experimental results on word embeddings are not compelling compared to Gaussian embeddings, the chief baseline from the literature. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on word embeddings in Tables 1 and 2 are not compelling compared to Gaussian embeddings, the chief baseline from the literature. However, the comment does not provide any specific examples, comparisons, or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results on word embeddings in Tables 1 and 2, noting that they are not compelling compared to Gaussian embeddings, the chief baseline from the literature. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s experimental design, which could be improved by providing more detailed analysis or comparisons. However, the comment lacks specific suggestions on how to address this issue or what aspects of the results are lacking. While it highlights an area for improvement, it does not offer actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method does not seem to differ significantly from previous studies mentioned in the paper, except for the task change to text summarization and the reward function change. It acknowledges that the finding that IRL is effective in text summarization is a positive contribution, but questions the significance of this contribution given the lack of novelty in the method. The comment suggests that the authors should provide more details on how the proposed method differs from previous work, which could help the authors understand the need for further development or differentiation. However, the comment does not explicitly instruct the authors to do so, leaving it somewhat vague. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"methods in the previous studies mentioned in the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not differ significantly from previous studies, except for the task change to text summarization and the reward function change. The comment suggests that the contribution is somewhat small due to the lack of novelty. However, it does not provide specific suggestions for improvement or examples of how the method could be differentiated. Therefore, the comment is fully grounded and under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the proposed method does not differ significantly from previous studies, except for the task change to text summarization and the reward function change. The reviewer references two specific studies, Shi et al. (2018) and Ghosh et al. (2021), to support this claim. However, the comment lacks detailed analysis or comparison of the methods to substantiate the claim fully. While the references provide some context, the comment could benefit from more detailed explanation or examples to fully support the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed method, noting that it does not differ significantly from previous studies mentioned in the paper, except for the task change to text summarization and the reward function change. The reviewer acknowledges the finding that IRL is effective in text summarization but questions the contribution's significance given the lack of novelty. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their method from previous work. While it points out a potential weakness, the feedback lacks actionable advice or detailed critique, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the novelty or how to present the dataset in a more compelling way. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not specify which part of the paper this assessment is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the novelty or dataset are lacking, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide details on why the novelty is limited or how the dataset is innovative, nor does it reference external sources or comparisons to similar works. Without these details, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not provide any specific feedback or suggestions on how the authors might enhance the novelty or the dataset. Without actionable advice or constructive criticism, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks an ablation study related to query embedding, which would provide insights into the significance and impact of this component. This feedback is clear and directs the authors to include such a study in their paper. The action is explicit and concrete, as it specifies exactly what needs to be added to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study\" related to query embedding, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of an ablation study related to query embedding. This provides clear guidance on what the authors need to add to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study related to query embedding, which would provide insights into the significance and impact of this component. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this study is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of an ablation study related to query embedding. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by adding a study that would provide insights into the significance and impact of this component. By addressing this point, the authors can enhance the comprehensiveness and depth of their analysis, which could lead to a stronger paper. However, the comment could be more helpful if it explained why an ablation study is necessary or how it would contribute to the paper\\'s overall contribution. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment expresses an opinion that the contribution is marginal compared to previous works in [1, 2, 3]. However, it does not provide any specific guidance or suggestions on how the authors could address this perception or improve their contribution. There is no explicit or implicit action for the authors to take, such as referencing these works or suggesting ways to enhance the contribution. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the contribution being marginal compared to previous works in [1, 2, 3]. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the contribution are considered marginal. Without specific references to sections, figures, or elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution is marginal compared to previous works in [1, 2, 3]. However, it does not provide any specific references or detailed comparisons to these works, making it difficult for the authors to understand the basis of the claim. Without specific examples or evidence, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses an opinion that the contribution is marginal compared to previous works in [1, 2, 3]. However, it does not provide any specific examples, comparisons, or reasoning to support this claim. Without detailed feedback or suggestions on how the authors could improve their contribution, the comment offers limited value to the authors in terms of actionable guidance or direction. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of a question asking the authors to clarify their reasoning for the loss of performance of w2gm against w2g in the analysis of SWCS. While the comment explicitly requests an explanation, it does not provide specific guidance on how to address this issue or what aspects of the explanation should be emphasized. The action is clear but lacks concrete details on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"analysis of SWCS,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for an explanation of the loss of performance of w2gm against w2g. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification regarding the loss of performance of w2gm against w2g in the analysis of SWCS. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of a question asking for clarification regarding the loss of performance of w2gm against w2g in the analysis of SWCS. While it prompts the authors to provide an explanation, it does not offer any guidance or suggestions on how to address this issue or improve the draft. The comment lacks actionable feedback or constructive advice, making it barely helpful for the authors in terms of improving their draft. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the paper\\'s claims about overoptimization and the lack of direct evaluation for overoptimization. It suggests that the paper should evaluate for overoptimization instead of calibration and human evaluation, and mentions a potential solution in the form of not doing early stopping. The reviewer also points out that current works address the overoptimization issue with early stopping, which is not discussed in the paper. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement this change or what specific aspects of the evaluation should be addressed. The action is explicit but somewhat vague, as the authors know they need to evaluate overoptimization but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the paper discusses overoptimization as the motivation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not directly evaluate for overoptimization and instead focuses on calibration and human evaluation. The comment suggests that the paper should evaluate overoptimization without early stopping and discuss the benefits of this approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not directly evaluate for overoptimization, which is a subjective claim. The reviewer suggests that the paper should evaluate overoptimization without early stopping and discuss the benefits of this approach. However, the comment lacks specific examples or references to support the claim that current works address the overoptimization issue with early stopping. Without these details, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that while the paper discusses overoptimization as a motivation, it does not directly evaluate for overoptimization. It suggests that the paper should evaluate overoptimization without early stopping and discuss the benefits of this approach. The reviewer also points out that current works address the overoptimization issue with early stopping, which is not discussed in the paper. This feedback is clear and actionable, providing the authors with a specific direction for improvement by suggesting a more comprehensive evaluation approach. However, the comment could be more helpful if it included examples or references to current works that address overoptimization without early stopping. Overall, the comment is mostly helpful as it guides the authors toward a more comprehensive evaluation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed TW model is equivalent to TR by noting that if the core tensor C is represented by a TR, then fusing this TR with the cores G_n can lead to a TR representation equivalent to the former TW model. The reviewer expresses a desire to see this analysis in the paper and a discussion justifying TW over TR. While the comment implies that the authors should include this analysis and discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this analysis and discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed TW model\" and the \"TR\" model, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the analysis and justification of the TW model over TR. The comment provides a clear direction for the authors to include an analysis and discussion of the equivalence between the TW and TR models. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed TW model is equivalent to TR by noting that if the core tensor C is represented by a TR, then fusing this TR with the cores G_n can lead to a TR representation equivalent to the former TW model. The reviewer suggests that this analysis and justification should be included in the paper. However, the comment lacks specific examples or references to support the claim that the TW model is indeed equivalent to TR. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors may find it challenging to fully understand and address the critique without additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential equivalence between the proposed TW model and TR, suggesting that the TW model can be considered equivalent to TR by noting that if the core tensor C is represented by a TR, then fusing this TR with the cores G_n can lead to a TR representation equivalent to the former TW model. The reviewer expresses a desire to see this analysis and justification included in the paper, which could provide valuable insights for the authors. However, the comment lacks specific guidance on how to conduct this analysis or what aspects of the TW model should be compared to TR. While it points out a potential area for improvement, the feedback is somewhat helpful as it highlights a gap in the paper that the authors could address with additional analysis and discussion. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the transferability of the toolset, noting that the toolset for the VQA task and the toolset for the reasoning task are not the same. The reviewer suggests that the authors might experiment to create a general toolset for all tasks and observe the results. While the comment implies that the authors should conduct an experiment, it does not provide explicit instructions on how to do so or what specific aspects to focus on. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"toolset for the VQA task and the toolset for the reasoning task,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests discussing the transferability of the toolset and provides a specific suggestion to experiment with creating a general toolset for all tasks. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the transferability of the toolset should be discussed, as the toolset for the VQA task and the toolset for the reasoning task are not the same. The reviewer provides a logical reasoning by pointing out the difference in toolsets and suggests that the authors might experiment to create a general toolset for all tasks. However, the comment lacks specific examples or references to support the claim that the toolset transferability is an issue. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the toolset for the VQA task and the toolset for the reasoning task are not the same. It suggests that the authors might experiment to create a general toolset for all tasks and observe the results. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by addressing the issue of toolset transferability. However, the comment could be more helpful if it offered additional guidance on how to conduct the experiment or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests evaluating the model's performance using multiple random feature orders to assess the impact of feature order variability without the need for a complex controller. This implies that the authors should consider implementing this baseline to determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. While the comment provides a clear action to take, it does not specify how to implement the baseline or what specific aspects of the model should be evaluated. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests evaluating the model's performance using multiple random feature orders to assess the impact of feature order variability without the need for a complex controller. It provides a specific suggestion for a baseline that could help determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the model evaluation or methodology sections, the lack of explicit grounding makes it weakly grounded. The suggestion is specific, as it clearly outlines a potential baseline for evaluating the model. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the model's performance using multiple random feature orders to assess the impact of feature order variability without the need for a complex controller. The claim is based on logical reasoning, as it proposes a method to test the model's robustness to feature order variability. However, the comment lacks specific examples or references to support the claim, such as how this baseline would be implemented or what specific metrics would be used to assess the impact. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed justification to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It recommends evaluating the model's performance using multiple random feature orders to assess the impact of feature order variability without the need for a complex controller. This baseline would help determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. The comment is specific and provides a concrete suggestion for improving the experimental design, which is valuable for the authors. However, it could be more helpful if it included additional details on how to implement this baseline or what specific metrics should be used to assess the impact. Overall, the comment is mostly helpful as it offers a clear direction for enhancing the paper\\'s experimental evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the related work section is severely lacking, specifically mentioning the omission of lexically constrained decoding methods as both related work and baselines for comparison. This provides a clear and concrete action for the authors to take, which is to include these references in the related work section. The comment is specific about what is missing and how it should be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the related work section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of lexically constrained decoding methods as both related work and baselines for comparison. This provides clear guidance on what needs to be addressed in the related work section. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work section is severely lacking, specifically mentioning the omission of lexically constrained decoding methods as both related work and baselines for comparison. This claim is somewhat verifiable as it highlights a specific gap in the paper, but it lacks detailed justification or examples of how this omission impacts the paper\\'s analysis or conclusions. The reviewer could provide more context or references to support the claim, making it more robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the related work section, specifically noting the omission of lexically constrained decoding methods as both related work and baselines for comparison. This is a critical observation that highlights a gap in the paper\\'s literature review, which could impact the validity and comprehensiveness of the analysis. By pointing out this oversight, the comment provides the authors with a clear and actionable step to enhance the quality of their work. However, the comment could be more helpful if it offered suggestions on how to address this gap, such as recommending specific references or approaches to include. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison is not comprehensive due to the absence of important baseline models and datasets. It explicitly mentions two specific models, SimVLM and OFA, as examples of what is missing. However, the comment does not provide any guidance on how the authors should address this issue, such as suggesting which models or datasets should be included or how to improve the comprehensiveness of the comparison. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific models, \"SimVLM\" and \"OFA,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the comparison is not comprehensive due to the absence of these models and datasets. However, the comment does not provide further details on what specific aspects of the comparison are lacking or how the authors might address this issue. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison is not comprehensive due to the absence of important baseline models and datasets. The reviewer supports this claim by explicitly mentioning two specific models, \"SimVLM\" and \"OFA,\" as examples of what is missing. This provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing additional examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the comprehensiveness of the comparison, noting the absence of important baseline models and datasets. It explicitly mentions two specific models, \"SimVLM\" and \"OFA,\" as examples of what is missing. This feedback is clear and actionable, as it highlights a critical area for improvement in the paper. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional models or datasets to include. Overall, the comment is mostly helpful as it points out a significant gap in the paper but lacks detailed guidance on how to improve it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the manuscript is framed as a dataset paper but does not present any new data collection or release. It highlights that the paper actually presents derivative data, such as 3D pose estimates from existing datasets, which is disappointing for readers who were hoping for a new, potentially useful data source. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they could take to improve the paper. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the framing of the manuscript as a dataset paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not present any new data collection or release, but rather presents derivative data from existing datasets. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the manuscript is framed as a dataset paper but does not present any new data collection or release. It further states that the paper actually presents derivative data, such as 3D pose estimates from existing datasets, which is disappointing for readers who were hoping for a new, potentially useful data source. This claim is somewhat verifiable as it highlights a potential issue with the paper\\'s framing and content, but it lacks specific examples or references to support the disappointment felt by readers. The authors might need to infer the disappointment and consider it a valid point, but the comment could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the manuscript, noting that it is framed as a dataset paper but does not present any new data collection or release. It points out that the paper actually presents derivative data, such as 3D pose estimates from existing datasets, which is disappointing for readers who were hoping for a new, potentially useful data source. This feedback is clear and actionable, as it highlights a critical weakness in the paper that the authors can address by either presenting new data or clarifying the nature of the existing data. However, the comment could be more helpful if it provided suggestions on how to present the existing data in a more compelling way or how to justify the use of derivative data. Overall, the comment is mostly helpful as it directs the authors\\' attention to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the authors for criticizing L-softmax and A-softmax for requiring an annealing-like training procedure, but it also points out that the method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this critique or what specific changes they should make to their approach. As a result, the comment is unactionable, as it does not offer any direction for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors for criticizing L-softmax and A-softmax for requiring an annealing-like training procedure, but it also points out that the method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing the issue with the critique and the specific learning rate schedule, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the authors for criticizing L-softmax and A-softmax for requiring an annealing-like training procedure, but it also points out that the method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. This claim is somewhat verifiable as it provides a logical reasoning for the critique, but it lacks specific examples or references to support the assertion about the learning rate schedule. The authors might need to further explore the details of the learning rate schedule to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors for criticizing L-softmax and A-softmax for requiring an annealing-like training procedure, but it also points out that the method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. This feedback highlights a potential inconsistency in the authors\\' critique and provides a specific example of the learning rate schedule. However, the comment does not offer actionable suggestions or guidance on how the authors might address this issue or improve their critique. While it identifies a potential weakness, it lacks depth and specificity, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the focus of the quantitative and qualitative analysis, which is mainly on the comparison between AE and diffusion. It suggests that the analysis should focus more on the results themselves, specifically questioning what insights can be drawn from the visualizations regarding the crucial elements for detecting a chair, such as the handle. The reviewer also raises questions about the consistency of these elements across a wide range of chairs and their prominence. While the comment provides a clear direction for improvement by suggesting a shift in focus, it does not offer specific guidance on how to implement this change or what specific aspects to focus on. The action is explicit but somewhat vague, as the authors need to determine the exact aspects to address and how to apply the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the quantitative and qualitative analysis, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the focus of the analysis, which is mainly on the comparison between AE and diffusion, and suggests that the analysis should focus more on the results themselves. The comment raises questions about what insights can be drawn from the visualizations regarding the crucial elements for detecting a chair, such as the handle, and whether these elements are consistent across a wide range of chairs. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the focus of the quantitative and qualitative analysis, which is mainly on the comparison between AE and diffusion, rather than the analysis of the results themselves. The reviewer questions what insights can be drawn from the visualizations about the crucial elements for detecting a chair, such as the handle, and whether these elements are consistent across a wide range of chairs. The comment suggests that the analysis should be more profound, focusing on the results themselves. However, the comment lacks specific examples or references to support the claim that the current analysis is insufficient. While it highlights a potential issue, the lack of detailed justification or evidence makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the focus of the quantitative and qualitative analysis, which is mainly on the comparison between AE and diffusion. It suggests that the analysis should be more profound, focusing on the results themselves and the crucial elements for detecting a chair, such as the handle. The reviewer raises important questions about the consistency and prominence of these elements across a wide range of chairs. This feedback is clear and actionable, as it prompts the authors to reconsider the scope and depth of their analysis. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or what aspects to focus on in the analysis. Overall, the comment is somewhat helpful as it directs the authors to consider a broader perspective on their analysis, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the phrasing of a statement in Section 2.2, suggesting that it should be revised to exclude the word \"at least.\" The reviewer provides a logical explanation of why the current phrasing is incorrect and suggests an alternative. However, the comment does not explicitly instruct the authors on how to make the change or provide specific guidance on the wording or formatting. While the action is implicit, it is clear and concrete, as the authors can infer the need to revise the statement to exclude \"at least.\" Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the beginning of Section 2.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the phrasing of a statement, suggesting that it should be revised to exclude the word \"at least\" and provide a more accurate description of the competitive ratio. This feedback is clear and provides a clear direction for improvement, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the phrasing of a statement in Section 2.2, suggesting that it should be revised to exclude the word \"at least.\" The reviewer provides a logical explanation of why the current phrasing is incorrect and suggests an alternative. This reasoning is based on a clear understanding of the statement and its implications, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the reasoning, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the phrasing of a statement in Section 2.2, suggesting that it should be revised to exclude the word \"at least.\" The reviewer provides a logical explanation of why the current phrasing is incorrect and offers a more accurate alternative. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and accuracy of their statement. However, the comment could be more helpful if it included suggestions for alternative phrasing or provided examples of how the statement could be revised. Overall, the comment is mostly helpful as it effectively points out a specific issue and offers a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the notation used in Theorem.1, specifically asking about the meaning of D^{alpha}_{x}. The reviewer does not provide any explicit or implicit actions for the authors to take, nor does it suggest any improvements or clarifications. Without guidance on how the authors should address this question or what changes to make, the comment lacks actionability. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the meaning of \"D^{alpha}_{x}\" and whether it denotes the derivatives of the probabilistic measure \\mu. This level of detail provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the notation used in Theorem.1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the notation used in Theorem.1, specifically asking about the meaning of D^{alpha}_{x}. This is a clear and specific question that could help the authors clarify their notation and improve the clarity of their paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the explanation. While it identifies a potential area for clarification, it lacks actionable feedback that would help the authors make significant improvements to their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that there is a missing proper expression for the third face image in Figure 2. This provides a clear and direct action for the authors to take, which is to add the proper expression to the figure. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing proper expression for the third face image in Figure 2. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing proper expression for the third face image in Figure 2. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figure, noting that there is a missing proper expression for the third face image in Figure 2. This is a clear and actionable point that the authors can address to improve the clarity and accuracy of their figure. However, the comment could be more helpful if it provided additional context or suggestions on how to correct the issue, such as explaining what the proper expression should be or suggesting a way to label the image more accurately. Despite this, the comment is mostly helpful as it directs the authors to a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This is an explicit action that the authors can directly implement by adding this comparison to their draft. The comment provides a clear and concrete suggestion for enhancing the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of an example comparison, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison would be beneficial or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This feedback is somewhat helpful as it provides a specific suggestion for enhancing the paper by adding a comparison that could help illustrate the strengths and weaknesses of the proposed model. However, the comment lacks depth and does not explain why this comparison is important or how it would benefit the paper. Additionally, it does not provide guidance on how to implement this suggestion or what specific aspects of the comparison should be emphasized. While it offers a clear action, the lack of detailed justification and context limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the dataset size of Vault and CSN should be the same in order to demonstrate that Vault is better in terms of data quality than CSN. This is a clear and direct action for the authors to take, as it provides a specific requirement for the experimental setup. The comment is concrete, as it specifies the exact condition that needs to be met, and it is also somewhat vague, as it does not provide detailed guidance on how to implement this change. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the tasks of code summarization and code search, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the dataset size of Vault and CSN should be the same to demonstrate that Vault is better in terms of data quality than CSN. This provides clear guidance on what the authors need to do to improve their experimental setup. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the dataset size of Vault and CSN should be the same to demonstrate that Vault is better in terms of data quality than CSN. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the evaluation of data quality. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered actionable advice. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup for the code summarization and code search tasks, noting that the dataset size of Vault and CSN should be the same to demonstrate that Vault is better in terms of data quality than CSN. This is a clear and actionable suggestion that could significantly impact the authors\\' ability to compare and evaluate their results. However, the comment could be more helpful if it provided additional context or examples on how to achieve this equality in dataset size, or how it might affect the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies specific terms that are not explained well in the paper, such as \"action-repeat\" and \"dithering phenomenon.\" It clearly states that these terms should be explained more carefully, providing a direct action for the authors to take. The comment is specific and provides concrete guidance on what needs to be improved, making it highly actionable. Authors know exactly what needs to be done to enhance the clarity of their paper in these areas.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific terms, \"action-repeat\" and \"dithering phenomenon,\" which allows the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation for these terms. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some important concepts are not explained well, specifically mentioning \"action-repeat\" and \"dithering phenomenon.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why these terms are crucial or how they are not explained adequately. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of explanation for certain terms, such as \"action-repeat\" and \"dithering phenomenon.\" By pointing out these terms and their recurrence in the paper, the comment highlights an area where the authors need to provide more detailed explanations. This feedback is clear and actionable, as it directs the authors to clarify these concepts to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it offered suggestions on how to explain these terms or provided examples of how similar concepts have been explained in other works. Overall, the comment is mostly helpful as it effectively guides the authors on a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion for improving the paper by proposing a different approach to handling instructions. It suggests creating an instruction embedding g(f(s)) from state encoding f(s) and passing it directly to the executor. Additionally, it suggests adding an auxiliary objective to bring the instruction embedding closer to the gold encoding. This feedback is explicit and provides concrete steps for the authors to follow, making it highly actionable. The authors know exactly what changes to make to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the process of generating text using the instruction model and re-encoding it using an encoder. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed suggestion for improving the process by creating an instruction embedding g(f(s)) and passing it directly to the executor. The comment also suggests adding an auxiliary objective to bring the instruction embedding closer to the gold encoding, which is a clear and actionable recommendation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a specific improvement to the methodology by proposing a different approach to handling instructions. The reviewer provides a logical reasoning for this suggestion, explaining that it avoids discretization in between, which could fail due to a single wrong decoding. The comment is mostly verifiable as it provides a clear and actionable suggestion for improvement, supported by a logical argument. However, it could be strengthened by referencing specific examples or studies that demonstrate the benefits of this approach. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by proposing an alternative approach to handling instructions. It suggests creating an instruction embedding g(f(s)) from state encoding f(s) and passing it directly to the executor, rather than using generated text. Additionally, it suggests adding an auxiliary objective to bring the instruction embedding closer to the gold encoding. This feedback is clear and provides a concrete direction for the authors to improve their draft, making it highly helpful. By following these suggestions, the authors can enhance the robustness and accuracy of their methodology. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the novelty of the proposed model is not significant, but it does not provide any further guidance or suggestions on how the authors might address this issue. There is no explicit or implicit action for the authors to take, such as suggesting ways to enhance the novelty or providing examples of similar models. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the novelty of the proposed model is not significant, but it does not specify which part of the paper discusses the model or where the novelty is lacking. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the model are considered unoriginal or lacking in novelty. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the proposed model is not significant. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment states that the novelty of the proposed model is not significant, which is a critical observation that could impact the paper\\'s impact and contribution. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or detailed insights, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but does not offer constructive advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proportion of each class used for the pool subset may make the dataset easier by removing ambiguity between numbers that look alike. It points out that the accuracy metric may not be a good measure of quality in this case, as it could be high even if smaller classes are poorly classified. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve the dataset or the evaluation metrics. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their evaluation metrics and potentially adjust the dataset composition. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the dataset used for evaluation and suggests that the proportion of each class used for the pool subset may make the dataset easier by removing ambiguity between numbers that look alike. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the accuracy metric as a measure of quality, suggesting that it may not be appropriate due to the uneven distribution of classes. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dataset used for evaluation may be easier due to the proportion of each class used for the pool subset, which removes ambiguity between numbers that look alike. The reviewer provides a specific example of the distribution of numbers, such as the few observations of 9 and 6, and the five times fewer observations of 7 compared to 1. This logical reasoning supports the claim that the dataset may not be representative of the true difficulty of the classification task. However, the comment could be strengthened by providing more detailed examples or references to similar studies that have addressed this issue. Therefore, the comment is somewhat verifiable, as it provides a logical argument but lacks comprehensive evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset used for evaluation, suggesting that the proportion of each class used for the pool subset may make the dataset easier by removing ambiguity between numbers that look alike. It provides a specific example of the distribution of numbers, such as the few observations of 9 and 6, and the five times fewer observations of 7 compared to 1. This feedback highlights a potential limitation in the dataset and suggests that the accuracy metric may not be a good measure of the quality, as it could be high even if smaller classes are poorly classified. While the comment identifies a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve their evaluation metrics. Therefore, the comment is somewhat helpful, as it provides insight into a potential problem but does not offer actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the statement about prediction not being done in isolation but questions the \"main\" contribution of showing that the task of prediction may have strategic aspects. It also asks about the \"true\" payoff in Table 1 and suggests exploring the work by Vapnik about teaching a learner with side information. While the comment implies that the authors should clarify the main contribution and consider the implications of the work by Vapnik, it does not provide explicit instructions on how to address these points. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the main contribution of the paper, specifically the idea that the task of prediction may have strategic aspects. It questions the \"main\" contribution and asks about the \"true\" payoff in Table 1, suggesting that it should include the test set payoff or population empirical payoff. Additionally, the reviewer mentions the work by Vapnik about teaching a learner with side information, which could be relevant to the paper. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the discussion of the main contribution and the payoff in Table 1. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the \"main\" contribution of the paper, specifically the idea that the task of prediction may have strategic aspects. The reviewer acknowledges the statement about prediction not being done in isolation but seeks clarification on the \"true\" payoff in Table 1 and the relevance of the work by Vapnik. The comment suggests exploring the work by Vapnik about teaching a learner with side information, which could be relevant to the paper. However, the comment lacks specific examples or detailed reasoning to support the claim that the \"main\" contribution is unclear. While it raises valid points, the lack of detailed justification makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the statement about prediction not being done in isolation but questions the \"main\" contribution of showing that the task of prediction may have strategic aspects. It also seeks clarification on the \"true\" payoff in Table 1 and suggests exploring the work by Vapnik about teaching a learner with side information. These questions and suggestions provide the authors with actionable feedback on how to enhance the clarity and impact of their main contribution. However, the comment could be more helpful if it offered specific guidance on how to address these points or provided examples of how the work by Vapnik could be integrated into the paper. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explore another unsupervised domain adaptation (UDA) method based on self-training. While it implies that the authors should consider this approach, it does not provide specific guidance on which method to use or how to integrate it into the existing work. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring another unsupervised domain adaptation (UDA) method based on self-training. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or methodology. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in recommending an approach to consider, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that self-training is a prominent and effective approach within the field of unsupervised domain adaptation (UDA) and suggests that the proposed method should explore another UDA method based on self-training. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors explore another unsupervised domain adaptation (UDA) method based on self-training. This feedback is clear and actionable, as it provides a concrete direction for the authors to consider an alternative approach that could enhance their work. However, the comment could be more helpful if it included specific examples or references to other UDA methods that use self-training, which would guide the authors in selecting a suitable approach. Overall, the comment is mostly helpful as it directs the authors to a promising area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the reliability diagrams, specifically the accuracy vs confidence plots, and questions whether this reflects dataset pathologies or variance/unpredictability in the proposed methods. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable details, such as recommending specific improvements or alternative analyses to be conducted. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 1, top,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reliability of the diagrams, particularly the accuracy vs confidence plots, and whether this reflects dataset pathologies or variance/unpredictability in the proposed methods. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reliability of the diagrams, specifically the accuracy vs confidence plots, and raises concerns about notable pathologies observed in the data. However, the comment lacks specific examples or detailed reasoning to support the claim that these pathologies are due to dataset issues or variance in the proposed methods. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliability diagrams, specifically the accuracy vs confidence plots, and questions whether this reflects dataset pathologies or variance/unpredictability in the proposed methods. It raises a valid concern about the reliability of the results, which could impact the credibility of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the reliability of their results. While it points out a potential problem, it does not provide actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper, noting that the attacker could perform more advanced attacks than those evaluated in the paper. It suggests that the authors should consider evaluating the impact of fine-tuning on a partial subset of the dataset, as this could lead to the presence of a backdoor. Additionally, the comment points out that the paper only focuses on detection and does not discuss SOTA methods for backdoor removal. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to implement these changes or what specific methods should be considered. The action is explicit but somewhat vague in terms of execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"partial subset of D\" and the \"backdoor,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of more advanced attacks and the consideration of SOTA methods for backdoor removal. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not evaluate more advanced attacks and only focuses on detection, while not discussing SOTA methods for backdoor removal. The reviewer supports this claim by referencing the authors\\' mention of fine-tuning on a partial subset of the dataset, which could lead to the presence of a backdoor. However, the comment lacks specific examples or references to SOTA methods that could be considered, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but could be more robust with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that it does not evaluate more advanced attacks beyond those evaluated in the study. It points out that the authors mention the possibility of fine-tuning on a partial subset of the dataset, which could lead to the presence of a backdoor. The comment also highlights the lack of discussion on SOTA methods for backdoor removal, suggesting that this is an important area for consideration. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific suggestions on how to address these gaps or what additional experiments could be conducted. Overall, the comment is mostly helpful as it directs the authors to consider important aspects of their work that could be expanded upon.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice to not use the conventional graph convolutional operation in the original GCN, suggesting that an explanation or ablation study might be necessary. However, it does not provide explicit guidance on what kind of explanation or study would be beneficial or how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation or conduct an ablation study but may not be entirely sure of the specifics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the original GCN (Kipf and Welling) and the use of the original adjacency matrix without explanation or ablation study. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises a question about the choice to not use the conventional graph convolutional operation and suggests that an explanation or ablation study might be necessary. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice to not use the conventional graph convolutional operation in the original GCN, suggesting that an explanation or ablation study might be necessary. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or how it affects the paper\\'s results or conclusions. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to substantiate the claim. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the choice to not use the conventional graph convolutional operation in the original GCN, suggesting that an explanation or ablation study might be necessary. This is a relevant point that could prompt the authors to consider the implications of their choice and potentially improve the clarity and robustness of their work. However, the comment lacks specific guidance or suggestions on how to address this issue, such as what kind of explanation or study would be beneficial. While it identifies a potential area for improvement, it could be more helpful with additional details. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the inclusion of a link for WMT\\'15 training corpora but not for WMT\\'14. While it highlights an inconsistency, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this inconsistency should be addressed or how it might impact the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the inclusion of a link for WMT\\'15 training corpora but not for WMT\\'14. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where the issue is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or clarified regarding the inconsistency in the links. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for an explanation regarding the inclusion of a link for WMT\\'15 training corpora but not for WMT\\'14. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about the inconsistency in the inclusion of a link for WMT\\'15 training corpora but not for WMT\\'14. While it identifies a potential issue, it does not provide any actionable feedback or suggestions for the authors to address this inconsistency. Without guidance on how to resolve the issue or what impact it might have on the paper, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to provide upper and lower bounds for adaptive matrices A t and B t in order to determine other hyperparameters. This is an explicit action that the authors can directly implement by including these bounds in their paper. The comment is clear and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors need to provide upper and lower bounds for adaptive matrices A t and B t in order to determine other hyperparameters. However, it does not specify which part of the paper this information should be included in, such as a specific section or table. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to provide upper and lower bounds for adaptive matrices A t and B t in order to determine other hyperparameters. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these bounds are necessary or how they would impact the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors need to provide additional information, namely the upper and lower bounds for adaptive matrices A t and B t. This feedback is clear and actionable, as it directly points out a gap in the paper that needs to be addressed in order to fully understand the hyperparameters and their impact. By providing this information, the authors can enhance the clarity and completeness of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how it might be incorporated into the paper. Overall, the comment is mostly helpful as it effectively guides the authors on a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is not particularly high, as most techniques used were proposed and demonstrated before. It also mentions the PDBbind dataset and suggests that experimental results on this dataset could be beneficial. However, the comment does not provide explicit guidance on how to improve the novelty or what specific aspects of the paper should be revised to enhance its novelty. The action is implied, as the authors can infer that they should consider the novelty of their work and potentially include experimental results on the PDBbind dataset. However, the comment lacks concrete details on how to implement these suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the paper is not particularly high, as most techniques used were proposed and demonstrated before. It also mentions the PDBbind dataset and suggests that experimental results on this dataset could be beneficial. However, the comment does not specify which part of the paper discusses the novelty or the techniques used, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are lacking in novelty or how the authors could enhance it. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is not particularly high, as most techniques used were proposed and demonstrated before. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The mention of the PDBbind dataset suggests a potential area for improvement, but without further elaboration or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the novelty of the paper is not particularly high, as most techniques used were proposed and demonstrated before. It also mentions the PDBbind dataset and suggests that experimental results on this dataset could be beneficial. While the comment identifies a potential issue with the novelty of the paper, it lacks specific guidance or suggestions on how to address this issue or improve the novelty. The mention of the PDBbind dataset is a somewhat helpful suggestion, but without further elaboration or actionable advice, the comment does not provide comprehensive feedback for the authors to improve their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that adding error bars to the results would enhance the clarity and credibility of the comparisons between pairs of models. This is a clear and concrete action for the authors to take, as it provides a specific way to improve the presentation of their results. The comment is specific in detailing what needs to be added (error bars) and how it would benefit the results (by demonstrating the significance of the differences). Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding error bars to the results of comparisons between pairs of models to demonstrate the significance of the differences. However, it does not specify which part of the paper this suggestion pertains to, such as specific figures or tables where these comparisons are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the addition of error bars to enhance the clarity and credibility of the results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that adding error bars to the results of comparisons between pairs of models would enhance the clarity and credibility of the findings. However, the comment does not provide specific reasoning or examples to support why error bars are necessary or how they would improve the results. Without detailed justification or references to similar studies, the claim remains somewhat vague and lacks sufficient evidence to be fully verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a logical suggestion but requires more detailed explanation or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that adding error bars to the results of comparisons between pairs of models would enhance the clarity and credibility of the findings. This is a specific and actionable suggestion that can help the authors demonstrate the significance of their results more effectively. By including error bars, the authors can show that the differences between models are indeed exceeding what would be expected from noise when comparing equally performant models. This feedback is clear and provides a concrete step for the authors to improve their draft, making it mostly helpful. However, it could be more helpful if it included examples or references to studies that have successfully used error bars in similar contexts. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the full state is not defined properly and asks what is included in a full state. While the comment identifies a specific issue with the definition of the full state, it does not provide any guidance on how to address this issue or what specific elements should be included in a full state. The action is implicit and vague, as the authors are left to infer that they need to clarify the definition of the full state. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, line 81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of the full state, asking what is included in a full state. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the definition of the full state, specifically asking what is included in a full state. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the full state is not defined properly. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definition of the full state in the paper, noting that it is not defined properly. This is a clear and actionable point that can help the authors clarify their definition and ensure that their work is more precise and understandable. However, the comment could be more helpful if it provided additional guidance on what elements should be included in a full state or how to improve the definition. Overall, the comment is mostly helpful as it directs the authors to a critical area for clarification, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the strengths of the empirical study but points out the lack of new proposals for neural architecture encoding. While it highlights the importance of including new proposals, it does not provide specific guidance on how to incorporate them or what kind of proposals would be beneficial. The comment lacks explicit instructions or concrete suggestions on how to enhance the paper with new proposals. As a result, the authors are left without clear direction on how to improve their draft in this area. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the strengths of the empirical study and points out the lack of new proposals for neural architecture encoding. However, it does not specify which part of the paper this issue pertains to, such as the sections discussing the neural architecture or the results section where new proposals could be introduced. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is specific in identifying the need for new proposals but lacks grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the empirical study is \"good\" but lacks new proposals for neural architecture encoding. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the current state of neural architecture encoding or how the study could be improved, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the strengths of the empirical study but points out the lack of new proposals for neural architecture encoding. It highlights the importance of including new initial proposals based on the analysis, which could enhance the paper's contribution. However, the comment does not provide specific guidance or suggestions on how to incorporate these proposals or what kind of neural architecture encoding would be beneficial. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends that the paper be evaluated as \"Marginally above the acceptance threshold\" due to the lack of empirical comparison with existing algorithms. It also provides specific suggestions for improvement, such as including empirical results and theoretical comparisons with existing algorithms. The comment further details the need to address the practical usefulness of the algorithm, noting that SGD requires many iterations until convergence, which could impact communication costs. However, the comment does not provide detailed guidance on how to conduct the empirical comparison or how to address the practical usefulness concern. While the action is clear, the lack of specific instructions on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors should include empirical comparisons with existing algorithms, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the need for empirical results and theoretical comparisons with existing algorithms. The comment also provides detailed feedback on the practical usefulness of the algorithm, such as the communication costs between the master and workers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks empirical comparison with existing algorithms and recommends it be evaluated as \"Marginally above the acceptance threshold.\" The reviewer supports this claim by pointing out that the paper is theoretical and does not include empirical results. They also provide a detailed critique of the practical usefulness of the algorithm, specifically noting that SGD requires many iterations until convergence, which could impact communication costs. However, the comment lacks specific examples or references to existing algorithms or empirical studies that could substantiate the claim further. While the reasoning is logical and the critique is detailed, the lack of external references or specific examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable critique of the paper, noting that it lacks empirical comparison with existing algorithms and recommending it be evaluated as \"Marginally above the acceptance threshold.\" This is a valuable point as it highlights a significant gap in the paper\\'s contribution, which is the lack of empirical validation. The comment also offers a detailed critique of the practical usefulness of the algorithm, specifically noting that SGD requires many iterations until convergence, which could impact communication costs. This feedback is particularly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance the paper\\'s contribution. However, the comment could be more helpful if it offered suggestions on how to conduct the empirical comparison or how to address the practical usefulness concern. Overall, the comment is mostly helpful as it provides actionable feedback that can significantly improve the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed approach performs well in simulations but not in real data, questioning the practical advantage of the method. It implies that including more real data analyses or comparisons could help support the method. While the comment provides a direction for improvement, it does not explicitly instruct the authors to include more real data analyses or comparisons. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed approach in simulations and real data, questioning the practical advantage of the method. It suggests that including more real data analyses or comparisons could help support the method. However, the comment does not specify which part of the paper discusses the approach or where the real data analyses should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of more real data analyses or comparisons, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed approach performs well in simulations but not in real data, questioning the practical advantage of the method. The comment suggests that including more real data analyses or comparisons could help support the method. However, the comment lacks specific examples or detailed reasoning to substantiate the claim about the performance in real data. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is somewhat verifiable, as it provides a direction for improvement but lacks sufficient justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the proposed approach performs well in simulations but not in real data. This observation raises a question about the practical advantage of the method. The comment suggests that including more real data analyses or comparisons could help support the method. While the comment highlights an important area for improvement, it lacks specific guidance on how to conduct these analyses or what aspects of the real data should be considered. This limits the comment\\'s helpfulness, as it provides a direction for improvement but does not offer detailed guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim their solution has a low discrimination risk while minimally sacrificing utility, and that the underlying data distribution should be held after imputation. However, it does not provide explicit guidance on how the authors should address these issues or what specific steps they should take to improve the fairness of their models. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to apply the feedback to enhance their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' claims about the low discrimination risk and the improvement in fairness of their solution, as well as the importance of holding the underlying data distribution after imputation. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in detailing what needs to be addressed, it lacks grounding as it does not specify where in the paper these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' solution has a low discrimination risk while minimally sacrificing utility and improving fairness. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a claim made by the authors regarding the low discrimination risk and improved fairness of their solution, as well as the importance of holding the underlying data distribution after imputation. However, it lacks specificity and actionable guidance on how the authors should address these issues or what aspects of the solution need improvement. The comment highlights potential areas for improvement but does not provide detailed suggestions or examples to help the authors enhance their draft. As a result, the feedback is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors could exploit ReferIt more by using more of its data before moving on to other datasets. While the comment implies that the authors should consider using more data from ReferIt, it does not provide specific guidance on how to implement this suggestion or what additional data to use. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors could exploit ReferIt more by using more of its data before moving on to other datasets. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where ReferIt is used. The authors can infer that it relates to the dataset selection or usage, but this inference is not direct. The comment is specific in suggesting an additional use of ReferIt, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors could exploit ReferIt more by using more of its data before moving on to other datasets. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this suggestion would be beneficial or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making changes. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors could exploit ReferIt more by using more of its data before moving on to other datasets. This feedback is somewhat helpful as it identifies an area for potential improvement, specifically in the use of data sources. However, the comment lacks specific guidance on how to implement this suggestion or what additional data could be used. It also does not provide context on why this suggestion is important or how it would impact the paper\\'s results or conclusions. While it points out a potential area for enhancement, the lack of detailed guidance limits its usefulness for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the explanation in sections 243-245, specifically questioning why the method is implemented as 5*3 instead of 5*2, as in the case of beta-vae. It also asks for elaboration on why k-NN was used and what the k and distance metric are. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it points out areas that need improvement but does not offer detailed instructions on how to implement those improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, \"243-245,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues by questioning the clarity of the explanation and asking for elaboration on the methodology, such as why 5*3 was used instead of 5*2 and why k-NN was chosen over other classifiers. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the clarity of the explanation in sections 243-245, specifically questioning why the method is implemented as 5*3 instead of 5*2, as in the case of beta-vae. It also asks for elaboration on why k-NN was used, and not other classifiers, and what the k and distance metric are. While the comment identifies specific areas that need clarification, it lacks detailed reasoning or references to support the claim that these explanations are unclear. The authors are left to infer that they need to provide more detailed explanations, but the comment does not offer sufficient justification or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks the necessary evidence or reasoning to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas of the paper that are unclear, particularly regarding the explanation of the methodology in sections 243-245. It asks for clarification on why the method is implemented as 5*3 instead of 5*2, as in the case of beta-vae, and why k-NN was used instead of other classifiers. The comment also seeks information on the k and distance metric used. By providing clear and actionable feedback, the reviewer helps the authors understand what aspects of their work need further explanation and elaboration. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the explanation or provided examples of how similar concepts have been explained in other works. Overall, the comment is mostly helpful as it directs the authors to specific areas needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a detailed description of the background of Sharpness-Aware Minimization (SAM). This is a clear and direct action that the authors can take to improve their draft. The comment is specific in what needs to be added, ensuring that the authors know exactly what is expected of them. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sharpness-Aware Minimization (SAM),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the background of SAM. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, it does not provide any supporting evidence, reasoning, or examples to justify why this background is important or how it should be described. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the background of Sharpness-Aware Minimization (SAM) should be described in detail. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by expanding on the background of SAM. By addressing this point, the authors can improve the clarity and comprehensiveness of their draft, which is beneficial for both the reviewer and the authors. However, the comment could be more helpful if it included specific suggestions on how to present the background or what aspects should be covered. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental setup lacks comprehensive comparisons, particularly between language-assisted and vision-assisted approaches. It provides specific examples of how to enhance the comparisons, such as incorporating image guidance using related reference normal images and color-augmentation for the kNN baseline. The comment also recommends a thorough examination of both language-based and vision-based assistance to strengthen the evaluation of LAFT\\'s efficacy. While the action is explicit and concrete, it could be further clarified by specifying which specific comparisons should be included or how to implement the image guidance and color-augmentation suggestions. Overall, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental setup\" and the \"comprehensive comparisons\" between language-assisted and vision-assisted approaches. It provides specific suggestions for improvement by recommending the inclusion of image guidance using related reference normal images and color-augmentation for the kNN baseline. Additionally, it suggests a thorough examination of both language-based and vision-based assistance to strengthen the evaluation of LAFT\\'s efficacy. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup lacks comprehensive comparisons, particularly between language-assisted and vision-assisted approaches. It suggests incorporating image guidance using related reference normal images and color-augmentation for the kNN baseline to provide valuable insights. The comment also recommends a thorough examination of both language-based and vision-based assistance to strengthen the evaluation of LAFT\\'s efficacy. While the comment provides a logical reasoning for the need for comprehensive comparisons, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to further develop the rationale themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the experimental setup, specifically the lack of comprehensive comparisons between language-assisted and vision-assisted approaches. It provides specific suggestions for improvement, such as incorporating image guidance using related reference normal images and color-augmentation for the kNN baseline. Additionally, it recommends a thorough examination of both language-based and vision-based assistance to strengthen the evaluation of LAFT\\'s efficacy. This feedback is clear and actionable, offering the authors concrete steps to enhance their experimental design and evaluation. However, it could be more helpful if it included examples of how these comparisons could be implemented or why they are important. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of related work, specifically mentioning collective entity linking as a closely related line of work. It suggests that the proposed model is a special case of collective entity linking and implies that the paper should include this work. However, the comment does not provide explicit instructions on how to incorporate this related work or what specific aspects of collective entity linking should be discussed. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of related work, specifically mentioning \"collective entity linking\" as a closely related line of work. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of related work on collective entity linking. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed model is a special case of collective entity linking, which is a closely related line of work. The reviewer supports this claim by mentioning collective entity linking as a specific area of research. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as specific examples of how the proposed model aligns with collective entity linking. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully support the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant oversight in the paper, noting the absence of related work on collective entity linking. It suggests that the proposed model is a special case of collective entity linking, which is a closely related line of work. This feedback is valuable as it highlights a potential gap in the literature review and provides a clear direction for the authors to consider. However, the comment could be more helpful if it offered specific suggestions on how to incorporate this related work or what aspects of collective entity linking should be discussed in the paper. Overall, the comment is mostly helpful as it points out a critical area for improvement and provides a direction for the authors to explore, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the effect of truncating the log likelihood function on sensitivity. It also raises a minor issue with the query functions in Algorithm 1, noting that they are the same for all data sources, despite the general framework stating they can be different. The reviewer suggests designing customized query functions for each data source or removing the subscript to improve clarity. While the comment provides a clear action to take, it lacks specific guidance on how to design these customized query functions or what aspects of the framework should be clarified. The action is explicit but somewhat vague in terms of execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"the query functions for all d data sources,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of truncating the log likelihood function and the issue with the query functions in Algorithm 1. The comment also provides a minor suggestion regarding the design of customized query functions for each data source. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests comparing the effect of truncating the log likelihood function on sensitivity. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is important or how it would be conducted. The minor comments about the query functions in Algorithm 1 and the customized query function design are also not fully developed, leaving the authors without clear guidance on how to address these issues. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific suggestion to compare the effect of truncating the log likelihood function on sensitivity. This is a valuable point as it highlights an area for further exploration and analysis. Additionally, the comment raises a minor issue with the query functions in Algorithm 1, noting that they are the same for all data sources, despite the general framework stating that they can be different. The reviewer suggests designing customized query functions for each data source or clarifying the subscript. While the comment identifies a potential area for improvement, it lacks detailed guidance on how to implement these suggestions. Therefore, the comment is somewhat helpful, as it provides some actionable feedback but could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation should be expanded to include a larger and more diverse dataset, including more complex molecules and materials. This feedback implies that the authors should conduct additional experiments to demonstrate the method's applicability on a broader range of molecules. However, it does not provide specific guidance on how to conduct these experiments or which datasets to use. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the comment. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"MD17 dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the evaluation should be expanded to include a larger and more diverse dataset, including more complex molecules and materials. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation is limited to a small set of molecules from the MD17 dataset and recommends expanding it to include a larger and more diverse dataset. However, the comment does not provide specific examples or references to support why this expansion is necessary or how it would benefit the evaluation. The reasoning is based on a general assumption that a larger dataset would be beneficial, but it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical suggestion but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation by pointing out that it is limited to a small set of molecules from the MD17 dataset. It suggests that expanding the evaluation to include a larger and more diverse dataset would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the scope and relevance of their evaluation. By addressing this suggestion, the authors can demonstrate the method's applicability to a broader range of molecules and materials, which could strengthen the overall impact of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is similar to the StreamingLLM paper and points out that the sink tokens in the current paper may correspond to $C_{special}$ and $C_{punct}$. It also mentions that the StreamingLLM paper has recently been uploaded, making it unlikely to compare this paper with it. However, the comment implies that the authors should clarify the differences in their paper. While the action is implicit, it is clear that the authors need to clarify the differences between their work and the StreamingLLM paper. The comment provides a specific area for improvement, but it lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the StreamingLLM paper, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the similarities between the current paper and the StreamingLLM paper, particularly the use of sink tokens and local attention. The comment also suggests that the differences in the current paper should be clarified, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current paper is similar to the StreamingLLM paper, specifically mentioning the use of sink tokens and local attention. The reviewer suggests that the differences in the current paper should be clarified, as the StreamingLLM paper has recently been uploaded. However, the comment lacks specific examples or detailed comparisons to substantiate the claim of similarity. While it points out a potential issue, the lack of detailed evidence or references makes the claim somewhat verifiable. The authors would need to make a significant effort to understand and address the claim, so the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential similarity between the current paper and the StreamingLLM paper, specifically mentioning the use of sink tokens and local attention. It suggests that the differences in the current paper should be clarified, as the StreamingLLM paper has recently been uploaded. This feedback is somewhat helpful as it points out a potential issue and provides a direction for improvement. However, the comment lacks specific guidance on how to clarify the differences or what aspects of the paper need attention. While it highlights an area for improvement, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which is also capable of handling more than two concepts. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the qualitative results of the paper, specifically comparing them to ConceptWeaver, which is mentioned by reference. This provides full grounding as it allows the authors to identify the specific part of the paper being discussed. However, the comment lacks specificity as it does not detail what aspects of the qualitative results are lacking or how they compare to ConceptWeaver. Without specific guidance or suggestions for improvement, the authors may find it challenging to address the issue effectively. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that there is no significant improvement in qualitative results compared to ConceptWeaver, which is also capable of handling more than two concepts. The reviewer supports this claim by referencing a specific work, \"ConceptWeaver: Enabling Multi-Concept Fusion in Text-to-Image Models,\" which provides a comparison between the two systems. This reference adds credibility to the claim by referencing a well-known work in the field. However, the comment could be strengthened by providing more detailed analysis or specific examples of where the improvements are lacking. Overall, the claim is mostly verifiable due to the reference to a well-known work, but it could be further substantiated with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which is also capable of handling more than two concepts. While it references a specific work, \"ConceptWeaver: Enabling Multi-Concept Fusion in Text-to-Image Models,\" it does not provide detailed feedback or suggestions on how the authors might address this issue or improve their results. The comment lacks actionable guidance or specific insights into what aspects of the qualitative results need improvement, leaving the authors without clear direction on how to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the problem reduces to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, it does not provide explicit instructions or concrete steps on how to implement this approach or what specific modifications are needed. The action is implicit and vague, as the authors are left to infer that they should explore matrix completion and subspace clustering as a solution. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the problem reduces to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to explore matrix completion and subspace clustering as a solution, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the problem reduces to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach is effective or how it would solve the problem. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the problem reduces to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. While this is an interesting observation, the comment lacks depth and does not provide specific guidance or suggestions on how to implement this approach or what aspects of the paper need to be revised to incorporate this idea. The feedback is somewhat helpful as it points out a potential solution, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the performance of CCKT-Det++ and its reliance on teacher models. It suggests that if the teacher model has limitations or biases, these could affect the performance of CCKT-Det++ and introduce unintended biases. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to mitigate the risks of biases. The action is implicit and somewhat vague, as the authors can infer that they need to consider the quality and alignment of teacher models but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"CCKT-Det++,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the model, which is its reliance on teacher models and the potential risks of biases if the teacher models have limitations or biases. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that CCKT-Det++ is heavily reliant on the quality and alignment of teacher models, which could lead to performance issues and unintended biases. While the comment highlights a potential concern, it does not provide specific examples or references to support the claim about the impact of teacher model limitations or biases on CCKT-Det++ performance. This lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the performance of CCKT-Det++ and its reliance on teacher models. It highlights the importance of ensuring the quality and alignment of these teacher models to avoid performance issues and unintended biases. This is a valuable observation that could prompt the authors to consider the implications of their model's reliance on external models and to explore ways to mitigate potential risks. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these concerns, such as recommending methods for evaluating or improving teacher model quality. Despite this, the feedback is mostly helpful as it directs the authors\\' attention to an important aspect of their model that could impact its performance and fairness.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison objects used in the comparison experiment are outdated and that the performance has not significantly improved. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the relevance of their comparison objects. There is no guidance on whether the authors should update their comparison objects, consider more recent studies, or provide a rationale for why the current objects are still relevant. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the selection of comparison objects in the comparison experiment, noting that they are outdated and that performance has not significantly improved. However, it does not specify which part of the paper this critique is based on, such as the experimental section or the discussion of results. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the comparison objects are outdated or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the comparison objects used in the experiment are outdated and that performance has not significantly improved. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or data to demonstrate the age or lack of improvement in the comparison objects, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the selection of comparison objects in the experiment, noting that they are outdated and that performance has not significantly improved. This feedback highlights a potential weakness in the paper\\'s experimental design, which could impact the relevance and applicability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending more recent comparison objects or explaining why the current ones are still relevant. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how masks are handled in CNN layers (representation block), indicating that the authors need to clarify this aspect of their work. However, it does not provide explicit guidance on how to address this question or what specific information should be included in the response. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about mask handling in CNN layers. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"masks handled in CNN layers (representation block),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the handling of masks in CNN layers. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about how masks are handled in CNN layers (representation block). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a specific question about the handling of masks in CNN layers (representation block), which is a technical aspect that could impact the understanding and interpretation of the paper. By asking for clarification on this point, the reviewer highlights an area where the authors may need to provide more detailed information or explanation. However, the comment does not offer suggestions or guidance on how to address this issue or what specific details should be included in the response. While it identifies a potential gap in the paper, it lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for an explanation regarding the larger training loss in \"without dropout\" compared to \"with dropout,\" suggesting that activation clipping may be reducing the model capacity. This is a clear and direct request for clarification, providing the authors with a specific action to take. The comment is specific and actionable, as it guides the authors on what aspect of the results needs further explanation and how to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation regarding the larger training loss in \"without dropout\" compared to \"with dropout,\" and it suggests that activation clipping may be reducing the model capacity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the larger training loss in \"without dropout\" compared to \"with dropout,\" suggesting that activation clipping may be reducing the model capacity. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the results presented in Figure 8, specifically the larger training loss in \"without dropout\" compared to \"with dropout.\" It suggests that activation clipping may be reducing the model capacity, which could explain the difference. This feedback is clear and actionable, as it prompts the authors to provide an explanation for this observation. By addressing this point, the authors can improve the clarity and understanding of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to address the issue. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by discussing the significance of establishing a large-scale matting dataset, which is not mentioned in the paper. However, it does not provide specific guidance on how to incorporate this discussion or what aspects of the dataset should be highlighted. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the dataset, but it lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could be improved by discussing the significance of establishing a large-scale matting dataset, which is not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, such as a specific section or discussion where the dataset is mentioned. The authors can infer that it relates to the discussion or results sections, but this inference is not direct. The comment is specific in suggesting the importance of discussing the dataset, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could be improved by discussing the significance of establishing a large-scale matting dataset, which is not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it relates to the paper\\'s contributions. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the paper could be improved by discussing the significance of establishing a large-scale matting dataset, which is not mentioned in the paper. This feedback is somewhat helpful as it identifies a potential area for improvement, but it lacks specific guidance or suggestions on how to incorporate this discussion into the paper. The authors are given a direction to consider but are not provided with detailed instructions on how to address the issue or what specific aspects of the dataset should be highlighted. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the number of adversarial examples is too small to demonstrate some distribution. However, it does not provide any guidance on how the authors should address this issue or suggest ways to increase the number of adversarial examples. The action is implicit and vague, as the authors are left to infer that they need to increase the number of adversarial examples but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of the number of adversarial examples being too small to demonstrate some distribution. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the adversarial examples are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the distribution are not being demonstrated or how the authors might address this issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the number of adversarial examples is too small to demonstrate some distribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the number of adversarial examples being too small to demonstrate some distribution. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the demonstration. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the proposed channel-sparse gradients, noting that they may not save time or memory in practice. It suggests that frameworks typically only support dense gradients for inputs and parameters, and that zeroing out a particular channel may not alter the computation. The reviewer also points out that the analysis experiments or \"Qualitative Studies\" in Section 5.2 are conducted with a subset of common corruptions, which may not generalize to the full set. The reviewer recommends conducting these experiments with the full set to ensure thoroughness and comparability with other results. While the comment provides a clear action for the authors to take, it does not specify how to conduct the full set of experiments or what specific aspects should be included. The action is explicit but lacks concrete details on execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed channel-sparse gradients, noting that they may not save time or memory in practice and that frameworks typically only support dense gradients. The comment further specifies that the analysis experiments or \"Qualitative Studies\" in Section 5.2 are conducted with a subset of common corruptions, which may not generalize to the full set. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed channel-sparse gradients may not save time or memory in practice, as frameworks typically only support dense gradients for inputs and parameters. The reviewer supports this claim by noting that zeroing out a particular channel may not alter the computation performed. Additionally, the comment suggests that the analysis experiments or \"Qualitative Studies\" in Section 5.2 are conducted with a subset of common corruptions, which may not generalize to the full set. This reasoning is somewhat verifiable as it provides a logical basis for the claim but lacks specific examples or references to substantiate the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed channel-sparse gradients, noting that they may not save time or memory in practice. It provides a logical reasoning by pointing out that frameworks typically only support dense gradients for inputs and parameters, and that zeroing out a particular channel may not alter the computation performed. The comment also highlights a limitation in the analysis experiments or \"Qualitative Studies\" in Section 5.2, which are conducted with a subset of common corruptions. The reviewer suggests that conducting these experiments with the full set would be more thorough and comparable with other results. This feedback is clear and actionable, as it guides the authors on how to improve their analysis and experiments to ensure thoroughness and generalizability. However, it could be more helpful if it provided specific suggestions on how to conduct the full set of experiments or what aspects should be included. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the claim of not considering low rank, suggesting that it is not as strong as it seems due to the use of concentration-of-measure. It also mentions that the results are similar to existing results in [39][42][44]. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2) even the authors do not consider sparsity or low rank,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim of not considering low rank and referencing existing results in [39][42][44]. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim of not considering low rank, suggesting that it is not as strong as it seems due to the use of concentration-of-measure. The reviewer also mentions that the results are similar to existing results in [39][42][44], implying that the claim of novelty is not entirely valid. However, the comment lacks specific references or detailed reasoning to support these claims, making it somewhat verifiable. The authors would need to infer the basis of the reviewer\\'s argument and potentially conduct further research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the claim of not considering low rank, suggesting that it is not as strong as it seems due to the use of concentration-of-measure. It also mentions that the results are similar to existing results in [39][42][44], implying that the claim of novelty is not entirely valid. While the comment identifies a potential weakness in the paper\\'s claims, it lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is somewhat helpful as it points out a potential flaw but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the Limitations section is too concise compared to the clear and detailed writing style in the main body of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to expand the section or what specific details should be included. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Limitations section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the section is too concise compared to the clear and detailed writing style in the main body of the paper, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Limitations section is too concise, contrasting it with the clear and detailed writing style in the main body of the paper. However, the comment does not provide any specific examples or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the Limitations section is too concise compared to the clear and detailed writing style in the main body. This feedback is valuable as it highlights an area where the paper could be improved, particularly in terms of consistency and comprehensiveness. However, the comment lacks specific suggestions or guidance on how to expand or enhance the Limitations section to better align with the rest of the paper. While it points out a potential weakness, it does not provide actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the proposed method is weak, suggesting that it is a modified version of previous work, PatchCore, with the addition of a denoising process. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the novelty or differentiate the method from existing work. As a result, the authors are left without any clear direction on how to enhance the originality of their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"proposed method\" and \"PatchCore,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out that the novelty of the proposed method is weak, as it appears to be a modified version of PatchCore with the addition of a denoising process. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is weak, suggesting that it is a modified version of previous work, PatchCore, with the addition of a denoising process. However, the comment does not provide any specific examples or references to support this claim, nor does it explain why the addition of a denoising process makes the method less novel. Without detailed reasoning or evidence, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a weakness in the novelty of the proposed method, suggesting that it appears to be a modified version of previous work, PatchCore, with the addition of a denoising process to the memory bank. While the comment highlights a potential issue, it lacks specificity and does not provide actionable guidance on how the authors might address this concern or enhance the originality of their work. Without detailed suggestions or examples, the feedback does not offer much value to the authors in terms of improving their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that the authors should provide more detailed instructions on how to install and run the software, similar to what is done in the binpwn project. Additionally, it recommends listing all the prompts used in the evaluation, either in the appendix or on the GitHub repository. These suggestions are clear and specific, giving the authors a direct path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with the repository lacking clear instructions on how to install and run the software, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending the inclusion of more detailed instructions in an extensive version of Table 1 or the appendix, similar to the binpwn project. Additionally, it suggests listing all the prompts used in the evaluation in the appendix or on the GitHub repository. This level of detail provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the repository lacks clear instructions on how to install and run the software, which is a factual observation. It suggests providing more detailed instructions similar to those in the binpwn project. The comment is somewhat verifiable as it provides a logical suggestion for improvement but lacks specific examples or references to the binpwn project. This makes it somewhat verifiable, as the authors would need to infer the specifics of the suggestion themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the repository, noting that it lacks clear instructions on how to install and run the software. It provides a clear and actionable suggestion by recommending the inclusion of more detailed instructions, similar to those in the binpwn project. Additionally, it suggests listing all the prompts used in the evaluation in the appendix or on the GitHub repository. This feedback is valuable as it guides the authors on how to improve the clarity and accessibility of their work, making it more actionable and beneficial for the authors. However, the comment could be more helpful if it provided specific examples of what kind of detailed instructions are needed or how the binpwn project handles this issue. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, where correct answers are anchored on correct visual content. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to align the results with the claim. The comment implies that the authors should reconsider the importance of the global representation g_v, but it lacks concrete steps or suggestions for improvement. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a discrepancy between the model ablation results and the major claim of interpretable VQA, where correct answers are anchored on correct visual content. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the global representation g_v is more crucial than other components in the model ablation results, which slightly contradicts the major claim of interpretable VQA. However, the comment does not provide specific evidence or reasoning to support this claim, such as data or comparisons with other models. The lack of detailed justification or references makes it difficult for the authors to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it requires more detailed support to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, where correct answers are anchored on correct visual content. It points out that the global representation g_v seems more crucial than other components, which could be a significant finding. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or interpret the results. While it highlights an area of concern, it does not offer actionable advice or detailed analysis, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a specific issue with the notation in section 3, where it suggests that the notation $f^{-1} = g$ should be avoided. It provides a clear rationale for this suggestion, explaining that when $d<D$, $f$ cannot be an invertible function, as it is defined on a domain of $\\\\mathbb{R}^D$. The reviewer suggests using the language of left inverses instead. This feedback is explicit and provides concrete guidance on how to revise the notation to avoid confusion. The authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the notation paragraph in sec 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, suggesting that the notation $f^{-1} = g$ should be avoided and recommending the use of the language of left inverses. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation $f^{-1} = g$ should be avoided because it is not accurate when $d<D$, as $f$ cannot be an invertible function. The reviewer provides a logical reasoning by explaining that the domain of $f$ is $\\\\mathbb{R}^D$, making it impossible for $f$ to be invertible. However, the comment does not provide specific examples or references to support this claim, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation in section 3, suggesting that the notation $f^{-1} = g$ should be avoided. It provides a clear rationale for this suggestion, explaining that when $d<D$, $f$ cannot be an invertible function, as it is defined on a domain of $\\\\mathbb{R}^D$. The reviewer suggests using the language of left inverses instead. This feedback is actionable and provides the authors with a clear direction for improving the clarity and accuracy of their notation. However, the comment could be more helpful if it included suggestions on how to rephrase the notation or provided examples of alternative formulations. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in their ablation studies on the motion tokenizer. This is a clear and direct action for the authors to take, as it provides a specific recommendation for enhancing the comprehensiveness of their analysis. The comment is concrete, as it specifies the exact comparisons that should be made, and it is also somewhat actionable because it does not provide detailed guidance on how to implement these comparisons. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"ablation studies on the motion tokenizer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in the ablation studies. This provides clear guidance on how to enhance the comprehensiveness of the analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ablation studies on the motion tokenizer should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1]. This claim is somewhat verifiable as it logically suggests that such comparisons would provide a more comprehensive understanding of the model's relative effectiveness. However, the comment lacks specific examples or references to the studies that have already compared RVQ-VAE models with MoMask, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It points out that the ablation studies on the motion tokenizer should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], to provide a more comprehensive understanding of the model\\'s relative effectiveness. This feedback is clear and direct, offering a concrete way for the authors to enhance the comprehensiveness and robustness of their analysis. By addressing this suggestion, the authors can significantly improve the clarity and depth of their results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"primary-secondary\" relationship is mentioned frequently in the paper but that its difference with the concept of nuclearity is unclear and not precisely defined. While the comment identifies a potential issue with the clarity of the relationship, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to clarify the relationship or provide more detail, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"primary-secondary\" relationship, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity and definition of the relationship with the concept of nuclearity. This provides clear guidance on what the authors need to improve to enhance the clarity of their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"primary-secondary\" relationship is mentioned frequently but is unclear and not precisely defined in relation to the concept of nuclearity. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity and definition regarding the \"primary-secondary\" relationship in relation to the concept of nuclearity. This is an important point as it affects the overall understanding and interpretation of the paper. However, the comment does not provide specific suggestions or guidance on how to clarify or define this relationship, leaving the authors with only a general direction to improve. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the mask ratio, noting that its effect varies across different datasets, which could lead to more tuning. It also points out that the insight about the impact of mask ratio is missing from the discussions and suggests that an intuitive guide for choosing this ratio would be helpful. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to create an intuitive guide or what aspects should be included. The action is implicit and somewhat vague, as the authors need to infer the specific guidance needed to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effect of mask ratio on different datasets and its impact on tuning, as mentioned in the limitations section. It also suggests that the insight about the impact of mask ratio is missing from the discussions and proposes an intuitive guide for choosing the mask ratio. However, the comment does not specify which part of the paper discusses the mask ratio or where the missing insight is located. While the authors might have an idea of where these sections are, the comment lacks full grounding. It is specific about the need for an intuitive guide and the missing insight, but without explicit references, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effect of mask ratio varies across different datasets, which could lead to more tuning, as mentioned in the limitations section. It also suggests that the insight about the impact of mask ratio is missing from the discussions and proposes an intuitive guide for choosing the mask ratio. The comment provides a logical reasoning for the need to address the issue of mask ratio variability and its impact on tuning. However, it lacks specific examples or references to support the claim about the missing insight in the discussions. This makes the claim somewhat verifiable, as it provides a reasonable basis but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the mask ratio, noting that its effect varies across different datasets, which could lead to more tuning. It also points out that the insight about the impact of mask ratio is missing from the discussions, and suggests that an intuitive guide for choosing this ratio would be helpful. This feedback is clear and actionable, as it provides specific guidance on how to address the issue of mask ratio variability and enhance the discussions. By suggesting a guide for choosing the mask ratio, the comment offers a concrete way for the authors to improve their draft. However, it could be more helpful if it provided examples or detailed guidance on what an intuitive guide might entail. Overall, the comment is mostly helpful as it effectively directs the authors to a specific area for improvement and offers a clear suggestion for enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from another round of proofreading, as there are several sections that are difficult to follow. While the comment implies that the authors should improve the clarity of these sections, it does not provide specific guidance on which sections are problematic or how to address these issues. The action is implicit and somewhat vague, as the authors are left to infer the need for improvement but without concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from another round of proofreading, indicating that there are sections that are difficult to follow. However, it does not specify which sections are problematic or provide examples of what needs to be improved. Without explicit references to specific sections or issues, the authors cannot confidently determine which parts of the paper need attention. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from another round of proofreading due to sections that are difficult to follow. However, it does not provide specific examples or detailed reasoning to support this claim. Without specific examples or references to sections that are challenging to understand, the authors may find it difficult to identify and address the issues. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from another round of proofreading, as there are several sections that are difficult to follow. While this feedback identifies a potential issue with the clarity of the paper, it lacks specificity and does not provide examples or guidance on which sections are problematic or how to improve them. Without detailed feedback or suggestions, the authors are left with a general recommendation to improve the readability without specific guidance on how to achieve it. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not provide actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the manuscript regarding the term \"STG layer\" in Figure 2, noting that it has not been mentioned elsewhere in the paper. The reviewer acknowledges that they are uncertain about the exact meaning of \"STG layer\" and suggests that it might refer to stochastic gates. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting a clarification or explanation in the manuscript. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the term, but it is not detailed enough to be fully actionable. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue with the term \"STG layer\" not being mentioned elsewhere in the manuscript and speculates that it might refer to stochastic gates. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"STG layer\" in Figure 2 has not been mentioned elsewhere in the manuscript, and the reviewer speculates that it might refer to stochastic gates. However, the comment lacks specific references or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the reviewer\\'s uncertainty. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript regarding the term \"STG layer\" in Figure 2, noting that it has not been mentioned elsewhere in the paper. The reviewer acknowledges that they are uncertain about the exact meaning of \"STG layer\" and speculates that it might refer to stochastic gates. This feedback is somewhat helpful as it points out a potential inconsistency in the manuscript that the authors should address. However, the comment lacks depth and does not provide specific suggestions on how to clarify or explain the term, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed methodology's improvements appear limited in some instances and underperforms compared to the baseline in the cases of FiQA and CONALA. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the methodology or what specific aspects need attention. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed methodology, specifically mentioning that the improvements appear limited and that it underperforms compared to the baseline in the cases of FiQA and CONALA. However, it does not specify which sections of the paper these results are discussed in, making it weakly grounded. The comment is specific in detailing the issue of limited improvements and underperformance, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed methodology\\'s improvements appear limited and that it underperforms compared to the baseline in the cases of FiQA and CONALA. However, the comment does not provide specific examples, data, or references to support these claims. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed methodology, noting that the improvements appear limited and that it underperforms compared to the baseline in specific cases, such as FiQA and CONALA. This feedback highlights an area where the authors may need to improve their methodology or provide additional evidence to support their claims. However, the comment lacks specific suggestions or guidance on how to address these issues or improve the performance. While it points out a potential weakness, it does not offer actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparisons with [1] are not clear and questions the contributions and advantages beyond [1]. However, it does not provide specific guidance on how the authors should clarify these comparisons or what aspects of [1] should be highlighted. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison with [1], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the contributions and advantages beyond [1], which is a differentially private model personalization. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of comparisons with [1] and seeks to understand the contributions and advantages beyond [1]. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that the comparisons are unclear. Without such evidence or justification, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of comparisons made with [1], which is a differentially private model personalization. It questions the contributions and advantages beyond [1] and highlights the need for more detailed explanations. However, the comment lacks specific suggestions or guidance on how the authors might clarify these comparisons or what aspects of [1] should be emphasized. While it points out a potential area for improvement, the feedback is somewhat helpful as it directs the authors to consider the clarity of their comparisons but does not provide actionable steps to enhance them. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a well-explained rationale for using the average feature of previous samples to stop the training of the uni-modal branch. This is a clear and concrete action, as it specifies exactly what needs to be added to the paper. The authors know exactly what information is missing and how to address it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"re-balancing step method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation and analysis of the method used to make multi-modal learning less greedy. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the re-balancing step method, which is used to make multi-modal learning less greedy, is not well described or analyzed in the full text. The reviewer suggests that the authors should provide a well-explained rationale for using the average feature of previous samples to stop the training of the uni-modal branch. However, the comment lacks specific examples or references to support the claim that the method is not well-described or analyzed. Without such evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that lacks explanation and analysis, namely the re-balancing step method used to make multi-modal learning less greedy. It suggests that the authors should provide a well-explained rationale for using the average feature of previous samples to stop the training of the uni-modal branch. This feedback is clear and actionable, as it directs the authors to a specific area that needs further elaboration and justification. However, the comment could be more helpful if it provided examples or references to similar methods or techniques that have been used successfully. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and depth of their explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the differences and advantages of the \"Reduce\" part compared to EATA and suggests using the entropy metric instead of the energy one to identify harmful OOD instances. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed comparison with EATA and clarify the use of entropy metrics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the differences and advantages of the \"Reduce\" part compared to EATA, and suggests using the entropy metric instead of the energy one to identify harmful OOD instances. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the differences and advantages of the \"Reduce\" part compared to EATA, and suggests using the entropy metric instead of the energy one to identify harmful OOD instances. This feedback is clear and actionable, as it prompts the authors to provide a detailed comparison with EATA and to clarify the use of entropy metrics. By addressing these points, the authors can enhance the clarity and rigor of their analysis. However, the comment could be more helpful if it provided specific examples or references to support the use of entropy metrics. Overall, the comment is mostly helpful as it guides the authors toward improving their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the proposed method with deterministic control, which is a potential area for further exploration. However, it does not provide explicit instructions or guidance on how to conduct this comparison or what specific aspects to focus on. The action is implied and somewhat vague, as the authors are left to infer the details of how to implement this suggestion. Therefore, the comment is somewhat actionable, as it points to a potential area for improvement but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed method with deterministic control, which is a specific suggestion for further exploration. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison but lacks grounding as it does not explicitly mention where in the paper this should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the proposed method with deterministic control, which is a suggestion for further exploration. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is relevant or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the proposed method with deterministic control, which could provide insight into the performance of the method. This is a valuable suggestion that could enhance the paper by offering a more comprehensive evaluation. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but without detailed instructions. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the naming of the 3r column in Table 4, suggesting that it should not be named ATE. It also mentions that Corr is also Cau-Ant. While the comment implies that the authors should reconsider the naming of the column, it does not provide explicit instructions or concrete guidance on how to address this issue. The authors are left to infer that they need to make a change, but without specific details on what to change or how to implement it, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"3r column,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the naming of the 3r column, suggesting that it should not be named ATE and that Corr is also Cau-Ant. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the naming of a column in Table 4 and a suggestion to change it. It does not contain any subjective opinions, judgments, or claims that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific issue with the naming of the 3r column in Table 4, suggesting that it should not be named ATE. It also mentions that Corr is also Cau-Ant, providing some context for the authors to understand the naming convention. While the comment identifies a potential inconsistency, it lacks depth and does not offer suggestions or guidance on how to address this issue. The feedback is somewhat helpful as it points out a specific area for clarification, but it could be more beneficial with additional explanation or actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues: the lack of clear anchoring in prior work and the difficulty in understanding the significance of the differences in the figures. It suggests that more clarity is needed in both areas. Regarding the lack of clear anchoring, the comment implies that the authors should provide more explicit references to prior work in the experiments section. However, it does not specify which parts of the paper should include these references or how they should be presented. Similarly, it suggests that the figures should be annotated or zoomed in to provide a clearer understanding of the differences, but it does not specify which figures or how to achieve this. While the comment provides some guidance, it lacks concrete details on how to implement these suggestions, making them somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"mechanism\" and the \"experiments section,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of the mechanism not being clearly anchored in prior work and suggests that more clarity is needed in the figures. The comment provides specific guidance on how to address the issue by suggesting that the authors should provide more explicit references to prior work in the experiments section and annotate or zoom in on the figures to ground them quantitatively. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mechanism is not clearly anchored in prior work and suggests that more clarity is needed in the figures. The reviewer provides a specific example of the methods section where the methods are clearly anchored, implying that more of this clarity should be applied throughout the paper. However, the comment lacks specific references to prior work or detailed examples of how the mechanism could be better anchored. While the suggestion is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues: the lack of clear anchoring in prior work and the difficulty in understanding the significance of the differences in the figures. It suggests that the authors should provide more explicit references to prior work in the experiments section and that annotating or zooming in on the figures could help ground them quantitatively. While the comment highlights areas for improvement, it lacks specific guidance on how to address these issues, such as which prior works to reference or how to effectively annotate the figures. The feedback is somewhat helpful as it points out areas for improvement, but it could be more comprehensive with additional details. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the limited novelty of the paper, specifically mentioning that the key contribution is the pre-trained mechanism applied to few-shot graph learning. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the novelty or how to make the contribution more exciting or less complicated. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a concern about the limited novelty of the paper, specifically mentioning the pre-trained mechanism applied to few-shot graph learning as the key contribution. However, it does not specify which part of the paper this concern is based on, such as a particular section or figure where the pre-trained mechanism is discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment does specify the issue of limited novelty, it lacks specificity in identifying the exact part of the paper that needs improvement. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, specifically mentioning that the key contribution is the pre-trained mechanism applied to few-shot graph learning. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. It does not reference any specific examples or comparisons to other works that might support the assertion of limited novelty. Without such evidence or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern about the limited novelty of the paper, specifically mentioning that the key contribution is the pre-trained mechanism applied to few-shot graph learning. While the comment acknowledges that the main idea seems plausible, it notes that it is not exciting and feels complicated. However, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their contribution. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper empirically validates which setups/parameters are useful for test time training but lacks theoretical understanding of why they do not collapse. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific theoretical understanding is needed. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the lack of theoretical understanding regarding the empirical validation of test time training setups and parameters. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of theoretical understanding, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks theoretical understanding regarding the empirical validation of test time training setups and parameters. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper, specifically the lack of theoretical understanding regarding the empirical validation of test time training setups and parameters. It points out that while the paper provides empirical evidence, it does not explain the theoretical basis for why these setups and parameters do not collapse. This feedback is somewhat helpful as it highlights an area where the paper could be improved by providing a theoretical understanding. However, the comment could be more helpful if it suggested specific ways to address this gap, such as referencing relevant literature or proposing a theoretical framework. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the method, noting that it does not require pose estimation in inference, which could affect the test image's pose maps. It also questions the visual analysis presented in Section 4.4, asking if it is based on training images or test images. While the comment identifies a potential problem and raises a question, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the visual analysis and consider the impact of the pose estimation on test images. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"Sec. 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the method, noting that it does not require pose estimation in inference and questioning the visual analysis presented in Section 4.4. The comment provides clear guidance on what needs to be addressed, namely clarifying the visual analysis and the impact of the pose estimation on test images. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not require pose estimation in inference, which affects the test image's pose maps. It also questions the visual analysis presented in Section 4.4, asking if it is based on training images or test images. The comment provides some logical reasoning by pointing out the potential impact of the pose estimation on test images, but it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that it does not require pose estimation in inference, which could affect the test image's pose maps. It also questions the visual analysis presented in Section 4.4, asking if it is based on training images or test images. This feedback is somewhat helpful as it points out a potential weakness in the methodology and encourages the authors to clarify the visual analysis. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or clarified the implications of the pose estimation on test images. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests exploring the application of the DEER method to other methods, such as LEM or UnICORNN, to determine whether they could maintain the same performance or achieve better performance with the DEER method. The reviewer also suggests that this exploration could strengthen the paper and broaden its impact. While the comment implies that the authors should conduct this exploration, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this additional analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the application of the DEER method to other methods, such as LEM or UnICORNN, to determine whether they could maintain the same performance or achieve better performance with the DEER method. However, it does not specify which part of the paper this exploration should be added to, making it weakly grounded. The comment is specific in suggesting that exploring this could strengthen the paper and broaden its impact. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests exploring the application of the DEER method to other methods, such as LEM or UnICORNN, to determine whether they could maintain the same performance or achieve better performance with the DEER method. The comment provides a logical reasoning for this exploration, as it could potentially lead to better performance and faster training. However, the comment lacks specific examples or references to support the claim that the DEER method would improve performance. This makes the claim somewhat verifiable, as it provides a reasonable basis but requires more detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to explore the application of the DEER method to other methods, such as LEM or UnICORNN, to determine whether they could maintain the same performance or achieve better performance with the DEER method. This suggestion is based on logical reasoning and could potentially lead to a broader impact and stronger contribution to the field. However, the comment could be more helpful if it provided specific guidance on how to conduct this exploration or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any specific guidance on how to address this issue, such as suggesting which notations should be simplified or explaining how to improve the presentation. The action is implicit and vague, leaving the authors without a clear understanding of what steps to take to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the presentation is difficult to follow due to the use of too many notations. However, it does not specify which part of the presentation is problematic or which notations are causing the issue. Without specific references to sections, figures, or tables, the authors cannot effectively identify the areas that need improvement. The comment lacks both grounding and specificity, making it not grounded and not specific. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The comment claims that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any specific examples or reasoning to support this claim, nor does it offer suggestions for improvement. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the presentation, noting that it is difficult to follow due to the use of too many notations. However, it lacks depth and does not provide any suggestions or guidance on how to address this issue, such as recommending which notations could be simplified or offering advice on how to improve the presentation. Without actionable feedback, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it points out a problem but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results of GPT-4V, despite the API not being released yet. The reviewer acknowledges that ChatGPT's UI can provide sufficient results for quick experiments. This feedback is explicit in its request for inclusion of GPT-4V results, providing a clear action for the authors to take. However, it does not specify which specific results should be included or how to conduct the experiments through ChatGPT\\'s UI. While the action is clear, the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GPT4-V,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of results from GPT-4V, despite the API not being released yet. The comment suggests conducting quick experiments through ChatGPT\\'s UI as a workaround. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that including results of GPT-4V would be beneficial, despite the API not being released yet. The reviewer acknowledges that ChatGPT\\'s UI can provide sufficient results for quick experiments. However, the comment lacks specific examples or references to support the claim that including GPT-4V results would be valuable. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors include results of GPT-4V, despite the API not being released yet. The reviewer acknowledges that ChatGPT\\'s UI can provide sufficient results for quick experiments. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of GPT-4V results, which could enhance the paper\\'s contribution. However, the comment lacks specific guidance on how to conduct these experiments or which results to include, making it somewhat helpful but not comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors discuss the implications of their extensive theoretical analysis, specifically comparing their results with baselines and explaining why CoPur could do better. While the comment implies that the authors should provide more detailed analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a deeper discussion of their results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper provides an extensive theoretical analysis and suggests discussing the implications of this analysis, specifically comparing it to baselines and explaining why CoPur could do better. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors should discuss the implications of their analysis and compare it to baselines, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper provides an extensive theoretical analysis but lacks discussion on the implications of this analysis. It specifically recommends discussing the comparison with baselines and explaining why CoPur could do better. While the comment identifies a potential area for improvement, it does not provide specific examples or references to support the claim that the analysis is lacking in depth. The suggestion is somewhat verifiable as it points out a potential gap in the paper, but the lack of detailed justification or examples makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, suggesting that the extensive theoretical analysis could be more meaningful if it were accompanied by a discussion of its implications. It specifically recommends that the authors discuss the comparison with baselines and explain why CoPur could do better. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the depth and relevance of their analysis. However, the comment could be more helpful if it offered examples or suggestions on how to structure this discussion or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues with the results and evaluation section: 1) the reported metrics are mostly for 3D NVS, and 2) the evaluation protocol is not clear, specifically questioning whether camera parameters are the same for all frames when generating videos. The reviewer suggests that the keypoint distance metric only assesses the size of motions but not their quality, and that the camera motion could produce large keypoint distance. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the evaluation protocol and consider metrics beyond keypoint distance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Result/eval\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the reported metrics, particularly the focus on 3D NVS and the lack of metrics related to dynamics, such as keypoint distance. The comment further questions the evaluation protocol, asking whether camera parameters are the same for all frames when generating videos. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reported metrics are mostly for 3D NVS and that the evaluation protocol is unclear. The reviewer questions whether camera parameters are the same for all frames when generating videos, suggesting that this could affect the keypoint distance metric. While the comment identifies specific issues with the metrics and evaluation protocol, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the importance of these points and determine how to address them. Therefore, the comment is somewhat verifiable, as it provides some basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues with the results and evaluation section of the paper. First, it points out that the reported metrics are mostly for 3D NVS, which limits the applicability of the results to other domains. Second, it questions the clarity of the evaluation protocol, specifically asking whether camera parameters are the same for all frames when generating videos. This feedback is valuable as it highlights areas where the authors need to improve the clarity and relevance of their results. However, the comment could be more helpful if it provided specific suggestions on how to address these issues, such as recommending alternative metrics or clarifying the evaluation protocol. Overall, the comment is somewhat helpful as it directs the authors to important areas for improvement, but it lacks detailed guidance on how to implement these changes.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the presentation of pretraining and regularization as separate components appears disjointed and detracts from the coherence of the paper. However, it does not provide explicit guidance on how to address this issue or suggest specific actions to improve the integration of these components. The comment implies that the authors should consider reorganizing their presentation or providing more context to enhance the coherence, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the presentation of pretraining and regularization as separate components, suggesting that this disjointed approach detracts from the coherence of the paper. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where this disjointed presentation is discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what changes or improvements are needed to enhance the coherence. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the presentation of pretraining and regularization as separate components appears disjointed and detracts from the coherence of the paper. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific sections of the paper where this disjointed presentation is observed, making it difficult for the authors to understand and address the issue. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of pretraining and regularization as separate components, suggesting that this disjointed approach detracts from the coherence of the paper. This feedback is valuable as it points out a potential weakness in the organization and integration of the paper\\'s content. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending ways to integrate these components more effectively or providing examples of how other papers have successfully integrated related concepts. While it highlights an area for improvement, the comment could be more helpful with additional details or examples. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the importance of Renyi divergence is not well explained and that it is not clear why it is special for readers unfamiliar with differential privacy. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific ways to clarify the importance or suggesting how to present the concept more effectively. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Renyi divergence,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation for the importance of Renyi divergence and its relevance to differential privacy. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the importance of Renyi divergence is not well explained and that it is not clear why it is special for readers unfamiliar with differential privacy. However, the comment lacks specific examples or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the explanation of the importance of Renyi divergence, particularly in the context of differential privacy. It points out that the current explanation may not be clear enough for readers who are not familiar with the concept. However, the comment does not provide any suggestions or guidance on how the authors might improve the explanation or what specific aspects should be clarified. While it highlights an important issue, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it provides insight but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should prioritize simplicity and clarity over the inclusion of \"mathematical theories.\" While it implies that the authors should reconsider their focus, it does not provide specific guidance on how to achieve this simplicity or what aspects of the paper should be simplified. The comment lacks concrete details on how to implement this suggestion, leaving the authors uncertain about the exact actions to take. Therefore, the comment is somewhat actionable, as it provides an implicit suggestion but lacks concrete guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should prioritize simplicity and clarity over the inclusion of \"mathematical theories.\" However, it does not specify which part of the paper this suggestion pertains to, such as specific sections, figures, or equations where mathematical theories are discussed. Without explicit references or detailed guidance, the authors cannot confidently determine which parts of the paper need attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should prioritize simplicity and clarity over the inclusion of \"mathematical theories.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this suggestion is necessary or how it would improve the paper. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should prioritize simplicity and clarity over the inclusion of \"mathematical theories.\" While it identifies an area for improvement, it lacks specificity and does not provide actionable guidance on how to achieve this simplicity or what aspects of the paper should be simplified. The comment does not offer examples or suggestions on how to streamline the content or improve the clarity, leaving the authors without a clear path for enhancing their draft. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the ablation study in the paper is limited and suggests that the impact of the pre-defined threshold \u03f5 should be further studied. This provides a clear and direct action for the authors to take, which is to conduct additional studies on the threshold. The comment is specific in identifying the issue and provides a concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the impact of the pre-defined threshold \u03f5 and the need for further studies on this aspect. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study in the paper is limited, specifically mentioning the impact of the pre-defined threshold \u03f5. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the ablation study, specifically the impact of the pre-defined threshold \u03f5. It suggests that this aspect should be further studied. While the comment highlights an area for improvement, it lacks depth and does not provide specific guidance on how to conduct the additional studies or what aspects to focus on. The feedback is somewhat helpful as it points out a potential weakness but does not offer detailed suggestions for improvement, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that only using Rouge-L for evaluation makes the results less reliable, especially for classification tasks where Rouge-L may not be sensitive enough. However, it does not provide explicit guidance on what alternative evaluation methods could be used or how to address this issue. The action is implicit, as the authors can infer that they need to consider using additional evaluation metrics, but it is vague because it does not specify which metrics should be used or how to implement the change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of Rouge-L for evaluation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with using only Rouge-L for evaluation, particularly for classification tasks where Rouge-L may not be sensitive enough. This provides clear guidance on what needs to be addressed in terms of evaluation methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using only Rouge-L for evaluation makes the results less reliable, especially for classification tasks where Rouge-L may not be sensitive enough. However, the comment does not provide specific examples or references to support this claim, such as data or studies that demonstrate the limitations of Rouge-L in these contexts. Without such evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation method used in the paper, noting that only Rouge-L is used for evaluation, which may not be reliable for some classification tasks. It highlights a potential limitation of Rouge-L in these contexts, suggesting that alternative metrics could be more sensitive. While the comment points out a relevant concern, it lacks specific suggestions on which metrics or methods could be used instead of Rouge-L. This limits the comment\\'s helpfulness, as it provides insight but does not offer actionable guidance for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the definitions of variables and the formula (Equation 3), specifically mentioning the absence of \"n_k\" in Equation 3. However, it does not provide any guidance on how the authors should address this issue, such as suggesting corrections or alternative approaches. The comment lacks explicit instructions or concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 580-588,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of variables not matching the formula (Equation 3) and points out the absence of \"n_k\" in Equation 3. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definitions of variables do not match the formula (Equation 3), specifically mentioning the absence of \"n_k\" in Equation 3. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definitions of variables not matching the formula (Equation 3), particularly the absence of \"n_k\" in Equation 3. This is a clear and actionable observation that the authors can address to improve the accuracy and consistency of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve this issue, such as suggesting alternative variable names or explaining the implications of this mismatch. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of a single vector for each class in the context of large semantic variances, suggesting that this strategy might conflict with the sample-specific assumption of the paper. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific experiments might be missing. The comment lacks actionable details, such as recommending alternative approaches or suggesting specific experiments to include. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the use of a single vector for each class in the context of large semantic variances, suggesting that this strategy might conflict with the sample-specific assumption of the paper. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its question about the conflict between the use of a single vector and the sample-specific assumption, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of a single vector for each class in the context of large semantic variances, suggesting that this strategy might conflict with the sample-specific assumption of the paper. However, the comment lacks any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the use of a single vector for each class in the context of large semantic variances, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also points out that some key experiments are missing, which could further support the paper\\'s claims. While the comment identifies a potential issue and highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might address these concerns or what experiments could be included. The feedback is somewhat helpful as it prompts the authors to consider the implications of their methodology and the need for additional evidence, but it could be more actionable with more detailed guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a key limitation of the work, specifically the assumption of known number of intent classes during graph construction. It points out that the IntenDD experiments reported in Table 1 may not be comparable to the cited baselines due to this assumption. The reviewer acknowledges that the authors have acknowledged this as a limitation but suggests that further clarification is needed to determine if the reported SOTA is fair in comparison with baselines. While the comment implies that the authors should clarify the intent discovery experiment setting, it does not provide explicit instructions on how to do so. The action is concrete but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the IntenDD experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the assumption of known number of intent classes during graph construction and questions the comparability of the IntenDD experiments with the cited baselines. The comment provides a clear direction for the authors to address the limitation by suggesting further clarification on the intent discovery experiment setting. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the assumption of known number of intent classes during graph construction is a key limitation of the work, specifically for the intent discovery evaluation. The reviewer questions whether the IntenDD experiments reported in Table 1 are comparable to the cited baselines due to this assumption. While the comment acknowledges that the authors have acknowledged this as a limitation, it suggests that further clarification is needed to determine if the reported SOTA is fair in comparison with baselines. This claim is somewhat verifiable as it provides a logical basis for the concern but lacks specific examples or references to support the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a key limitation of the work, specifically the assumption of known number of intent classes during graph construction. It points out that this assumption may impact the comparability of the IntenDD experiments reported in Table 1 with the cited baselines. The reviewer acknowledges that the authors have acknowledged this as a limitation but suggests that further clarification is needed to determine if the reported SOTA is fair in comparison with baselines. This feedback is clear and actionable, as it directs the authors to clarify the intent discovery experiment setting to ensure fair comparison with baselines. By addressing this issue, the authors can significantly improve the robustness and credibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the rigorous experimentation in the work but points out the limitations in the significance of the results due to the application of d-separation criteria in a known causal graph. It also mentions the need for corruption labels in the experiments on corrupted CIFAR and ImageNet. However, the comment does not provide explicit guidance on how to address these limitations or suggest specific actions to improve the paper. The references provided are relevant but do not offer direct instructions on how to apply them. As a result, the comment is somewhat actionable, as it identifies issues but lacks concrete steps for the authors to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment appreciates the rigorous experimentation in the work but points out the limitations in the significance of the results due to the application of d-separation criteria in a known causal graph. It also mentions the need for corruption labels in the experiments on corrupted CIFAR and ImageNet. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the limitations and suggesting improvements, such as the need for corruption labels. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the significance of the results is limited due to the application of d-separation criteria in a known causal graph and the need for corruption labels in the experiments on corrupted CIFAR and ImageNet. The reviewer supports this claim by referencing two external works, [1] and [2], which provide theoretical foundations for the limitations mentioned. However, the comment could be strengthened by further explaining why these references are relevant or how they directly impact the significance of the results. As it stands, the claim is mostly verifiable due to the inclusion of references, but it could be more robust with additional justification or explanation.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the rigorous experimentation in the work but points out the limitations in the significance of the results due to the application of d-separation criteria in a known causal graph and the need for corruption labels in the experiments on corrupted CIFAR and ImageNet. It references two external works, [1] and [2], which provide theoretical foundations for the limitations mentioned. While the comment identifies a significant issue with the applicability of the results, it does not offer specific suggestions or guidance on how the authors might address these limitations or improve their work. The references provided are relevant but do not directly address the critique. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but lacks actionable advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that it may not align with the underlying feature selection mechanisms in the human brain. However, it does not provide explicit guidance on how the authors should address this issue or what alternative methods they should consider. The comment lacks concrete suggestions or detailed instructions on how to improve the evaluation process. As a result, the authors are left without clear actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that it may not align with the underlying feature selection mechanisms in the human brain. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue with the evaluation method, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the reliance on gradient-based saliency methods to evaluate the importance of feature map channels may not align with the underlying feature selection mechanisms in the human brain. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliance on gradient-based saliency methods to evaluate the importance of feature map channels, suggesting that it may not align with the underlying feature selection mechanisms in the human brain. This is a relevant point that could impact the validity and applicability of the evaluation method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what alternative methods could be considered. While it highlights a potential weakness, it does not provide actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the choice of model, specifically mentioning that Pythia is not state-of-the-art (SOTA) but has the advantage of available checkpoints. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their model choice. The comment lacks actionable guidance, such as recommending alternative models or discussing the trade-offs between available checkpoints and SOTA status. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of Pythia, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the model choice, noting that Pythia is not state-of-the-art (SOTA) but has the advantage of available checkpoints. This provides clear guidance on what needs to be addressed regarding the model choice. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Pythia, the model used in the paper, is not state-of-the-art (SOTA) but has the advantage of available checkpoints. This claim is somewhat verifiable as it provides a logical reasoning based on the current state of the field. However, it lacks specific references or examples to support the assertion that Pythia is not SOTA, which would strengthen the claim. Additionally, the comment does not provide details on how the authors might address this issue or improve their model choice. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies a specific issue with the model choice in the paper, noting that Pythia is not state-of-the-art (SOTA) but has the advantage of available checkpoints. This feedback highlights a potential limitation of the model choice and suggests that the authors might consider alternative models with better SOTA status. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue or improve the model choice. While it points out a potential weakness, it does not offer actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions and suggests that more information or resources should be provided to challenge the community to solve the image observation version of Franka Kitchen. It also questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment implies that the authors should provide additional resources or clarify the limitations of their work. However, it does not explicitly instruct the authors on what specific information or resources should be provided or how to address the questions raised. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the image observation version of Franka Kitchen and suggests that more information or resources should be provided to challenge the community. It also questions the failure of existing works and whether it is due to the incompleteness of offline RL algorithms or the lack of image representation learning. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for additional information or resources, but without clear grounding, it is difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the image observation version of Franka Kitchen and suggests that more information or resources should be provided to challenge the community. It also questions the failure of existing works and whether it is due to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment seeks clarification on whether the task can be completed solely with the provided offline data and if not, whether there is an alternative data source. While the comment raises valid questions, it lacks specific examples or references to support the claims about the failure of existing works or the need for additional resources. This makes the claim somewhat verifiable, as it provides a logical basis for the questions but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the image observation version of Franka Kitchen and suggests that more information or resources should be provided to challenge the community. It questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment also asks whether the task can be completed solely with the provided offline data and, if not, whether there is an alternative data source that the community can leverage. These questions are insightful and prompt the authors to consider the limitations and potential solutions for their work. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or improve their work. Overall, the comment is somewhat helpful as it encourages the authors to think critically about their work and its implications, but it could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for an explanation of why the multilingual model is \"noticeably weaker\" on the ET\u2192En and LV\u2192EN evaluations. This request is clear and direct, providing the authors with a specific action to take: providing an explanation or analysis to address the issue. The comment is concrete because it specifies the exact part of the paper where the issue is discussed (line 236) and what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 236,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why the multilingual model is \"noticeably weaker\" on the ET\u2192En and LV\u2192EN evaluations. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the \"noticeably weaker\" performance of the multilingual model on specific evaluations. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific issue with the paper, namely the noticeable weakness of the multilingual model on certain evaluations. By asking for an explanation of this issue, the comment prompts the authors to provide a deeper understanding of their model's performance, which could lead to improvements in the draft. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of potential explanations. Overall, the feedback is actionable and provides a clear direction for the authors to improve their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of the numbers in brackets (1) and (4) in tables #1 and #2. While it implies that the authors should clarify this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"tables #1,2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by asking about the meaning of the numbers in brackets (1) and (4) in these tables. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the meaning of numbers in brackets (1) and (4) in tables #1 and #2. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the meaning of numbers in brackets (1) and (4) in tables #1 and #2. This is a clear and actionable request for clarification, as it prompts the authors to provide additional information or explanation about these numbers. By addressing this question, the authors can improve the clarity and comprehensibility of their tables, which could enhance the overall understanding and usability of their work. Therefore, the comment is mostly helpful, as it directs the authors to a specific area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the connection between the presented RDRO results and the listed limitations, specifically questioning how these results relate to the paper\\'s claims about long-term fairness. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific steps they should take to clarify the connection between the results and the limitations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the connection between the presented RDRO results and the listed limitations, specifically questioning how these results relate to the paper\\'s claims about long-term fairness. However, it does not specify which part of the paper this connection is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the connection between the results and the limitations, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the connection between the presented RDRO results and the listed limitations, specifically questioning how these results relate to the paper\\'s claims about long-term fairness. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this connection is unclear or how it might be addressed. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically questioning the connection between the presented RDRO results and the listed limitations regarding long-term fairness. It highlights a gap in the paper\\'s explanation of how these results relate to the broader context of fairness notions. While the comment points out a specific area for improvement, it does not provide detailed guidance or suggestions on how the authors might address this issue or what specific steps they could take to clarify the connection. The feedback is somewhat helpful as it directs the authors\\' attention to a potential weakness, but it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the low accuracy of 29 percent with table assembly tasks and questions the high Euclidean distance error units in Table 1. It suggests that the errors might be normalized to per datapoint position errors, and if so, an error of 5 cm with HDR-IL seems unreasonably high. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors can infer that they need to clarify the normalization of the errors and potentially adjust the results, but the lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Euclidean distance error units,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the high error units and suggests that they might be normalized to per datapoint position errors. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the low accuracy of 29 percent with table assembly tasks and questions the high Euclidean distance error units in Table 1. It suggests that the errors might be normalized to per datapoint position errors, which could explain the high values. However, the comment lacks specific examples or references to support the claim that the errors are unreasonably high. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is somewhat verifiable, as it provides a logical basis but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the accuracy of table assembly tasks, noting that 29 percent is considered low. It also questions the high Euclidean distance error units in Table 1, suggesting that they might be normalized to per datapoint position errors. This feedback is somewhat helpful as it points out a potential problem in the results section, prompting the authors to investigate and clarify the normalization of these errors. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to interpret the results. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing attention, but it lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the article does not reach a conclusion and implies that it suggests existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable details, such as recommending specific changes or improvements to the conclusion or methodology sections. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the article does not reach a conclusion and implies that it suggests existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the article\\'s conclusion, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the article does not reach a conclusion and suggests that it implies existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some indication but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the article, suggesting that it does not reach a conclusion and implies that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it lacks specificity and actionable guidance on how the authors might address this issue or improve their conclusion. Without detailed feedback or suggestions on how to enhance the article\\'s conclusion or methodology sections, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it points out a potential weakness but does not offer actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical results are not surprising and have limited contribution to algorithm design, as the algorithm design is mainly based on a pre-defined labeler's strategy. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes could be made to enhance the contribution of the theoretical results. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the theoretical results are not surprising and have limited contribution to algorithm design, as the algorithm design is mainly based on a pre-defined labeler's strategy. However, it does not specify which part of the paper this critique is based on, such as the theoretical results section or the algorithm design section. Without explicit references to specific sections or elements, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theoretical results are not surprising and have limited contribution to algorithm design, as the algorithm design is mainly based on a pre-defined labeler's strategy. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the theoretical results are not surprising and have limited contribution to algorithm design, as the algorithm design is mainly based on a pre-defined labeler's strategy. However, it does not provide specific guidance or suggestions on how the authors might address this issue or enhance the contribution of their theoretical results. Without actionable feedback or detailed reasoning, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the article does not provide a detailed explanation of how reverse chain proved to be effective in multi-API planning. It also criticizes the article for focusing on comparing multiple tools or methods in API calling and planning, which reduces its research contribution. However, the comment does not offer specific guidance on how to address these issues or what additional details should be included. The authors are left to infer that they need to provide more detailed explanations and potentially reframe the focus of the paper. The lack of explicit instructions or concrete suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues with the article, such as the lack of detailed explanation regarding the effectiveness of reverse chain in multi-API planning and the focus on comparing multiple tools or methods in API calling and planning. However, it does not specify which sections of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for more detailed explanations and a reframing of the focus. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the article does not provide a detailed explanation of the effectiveness of reverse chain in multi-API planning and that it focuses on comparing multiple tools or methods in API calling and planning, which reduces its research contribution. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the article, noting that it lacks detailed explanation regarding the effectiveness of reverse chain in multi-API planning. It also critiques the article for focusing on comparing multiple tools or methods in API calling and planning, which reduces its research contribution. This feedback is somewhat helpful as it points out areas where the article could be improved, but it does not provide detailed guidance or suggestions on how to address these issues. The authors are left with a general understanding of the problem but without actionable steps to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly recommends the paper for rejection, citing weaknesses in experimental rigor that cannot be fixed in time, content space, or degree. It also mentions the significant editing required to address other issues, which the reviewer considers unrealistic in time and space. While the comment provides a clear recommendation for rejection, it does not offer specific guidance on how to address the weaknesses or improve the experimental rigor. The authors are left without actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment recommends the paper for rejection, citing weaknesses in experimental rigor that cannot be fixed in time, content space, or degree. However, it does not specify which parts of the paper these weaknesses are found in, making it difficult for the authors to pinpoint the exact issues that need to be addressed. Additionally, the comment lacks specificity regarding the nature of the weaknesses or how they could be addressed. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point recommends the paper for rejection, citing weaknesses in experimental rigor that cannot be fixed in time, content space, or degree. The reviewer does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the nature of the issues and how to address them. The lack of specific examples or references to support the claim makes it challenging for the authors to verify the claim and improve their draft. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment recommends the paper for rejection, citing weaknesses in experimental rigor that cannot be fixed in time, content space, or degree. It also mentions the significant editing required to address other issues, which the reviewer considers unrealistic in time and space. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how to address the weaknesses or improve the experimental rigor. Without actionable feedback or detailed advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is barely helpful, as it points out a significant issue but does not provide the authors with a way to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about unfair competition between standalone Medusa and Medusa+ParallelSpec, noting that the original Medusa setup uses an MLP-like architecture, while the adapted Medusa+ParallelSpec uses a single-layer Transformer model. The reviewer suggests that the speedup gain might be due to the change in draft model architecture rather than parallel prediction. They recommend providing a baseline with only the draft model architecture change to clarify the impact of the architecture change. Additionally, they suggest giving the modified setting a different name to avoid confusion regarding the draft model architecture. The comment is explicit in its suggestions and provides concrete guidance on how to address the issue. Therefore, it is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 266-267), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unfair competition between standalone Medusa and Medusa+ParallelSpec, and it provides a clear suggestion to address this issue by providing a baseline with only the draft model architecture change. The comment also suggests renaming the modified setting to avoid confusion regarding the draft model architecture. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about unfair competition between standalone Medusa and Medusa+ParallelSpec, noting that the original Medusa setup uses an MLP-like architecture, while the adapted Medusa+ParallelSpec uses a single-layer Transformer model. The reviewer suggests that the speedup gain might be due to the change in draft model architecture rather than parallel prediction. The comment provides a logical reasoning by questioning the fairness of the comparison and suggests providing a baseline with only the draft model architecture change to clarify the impact. However, the comment lacks specific examples or references to support the claim that the change in architecture is the primary cause of the speedup. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue of unfair competition between standalone Medusa and Medusa+ParallelSpec, noting that the original Medusa setup uses an MLP-like architecture, while the adapted Medusa+ParallelSpec uses a single-layer Transformer model. The reviewer suggests that the speedup gain might be due to the change in draft model architecture rather than parallel prediction. To address this concern, the comment recommends providing a baseline with only the draft model architecture change to clarify the impact of the architecture change. Additionally, it suggests giving the modified setting a different name to avoid confusion regarding the draft model architecture. This feedback is clear and actionable, providing the authors with specific guidance on how to improve their draft by addressing the issue of fairness in the comparison. However, the comment could be more helpful if it included examples or additional details on how to implement the suggested changes. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the focus on Masked Language Models (MLMs) in the paper, suggesting that experiments with autoregressive LMs might not have worked out. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or if it is relevant to the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the focus on Masked Language Models (MLMs) in the paper, suggesting that experiments with autoregressive LMs might not have worked out. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the choice of MLMs, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the focus on Masked Language Models (MLMs) in the paper, suggesting that experiments with autoregressive LMs might not have worked out. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this might be the case or why MLMs are preferred over autoregressive LMs. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the focus on Masked Language Models (MLMs) in the paper, suggesting that experiments with autoregressive LMs might not have worked out. This is an interesting point that could prompt the authors to reconsider their choice of models or provide a rationale for why MLMs are preferred. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their work. While it points out a potential area for consideration, it does not provide actionable feedback or detailed advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: how the map is encoded and the effectiveness of the method on experiments proposed in YNet. While the first question seeks clarification on the encoding process, the second question explicitly suggests that the authors should demonstrate the effectiveness of their method on the experiments proposed in YNet. The second part of the comment provides a clear action for the authors to take, which is to conduct experiments and demonstrate the method's effectiveness. However, the first part of the comment is implicit and lacks explicit guidance, making it somewhat actionable. Overall, the comment is mostly actionable, as it provides a concrete suggestion for the authors to address the second part of the comment, but the first part lacks explicit guidance.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises two questions: how the map is encoded and the effectiveness of the method on experiments proposed in YNet. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its request for the authors to demonstrate the effectiveness of their method on the experiments proposed in YNet, but it lacks grounding as it does not reference specific sections or experiments. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions: \"How is the map encoded?\" and \"The authors should have shown the effectiveness of their method on the experiments proposed in YNet.\" These questions are factual in nature and do not contain subjective claims or opinions that require verification. They are purely requests for clarification or additional information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions: how the map is encoded and the effectiveness of the method on experiments proposed in YNet. While the first question seeks clarification on a technical aspect, the second question suggests that the authors should demonstrate the effectiveness of their method on the experiments proposed in YNet. This feedback is somewhat helpful as it identifies areas where the authors could improve their draft, particularly by providing more detailed information on the methodology and results. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point makes a claim about the proposed model not being significantly better than MSA Transformer in terms of r2. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their model or what specific aspects of the MSA Transformer they should aim to surpass. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a comparison between the proposed model and MSA Transformer, specifically mentioning \"r2.\" However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its claim about the model not being significantly better than MSA Transformer, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model is not significantly better than MSA Transformer in terms of r2. However, it does not provide any supporting evidence, comparisons, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand or address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment makes a claim about the proposed model not being significantly better than MSA Transformer in terms of r2. However, it does not provide any context, analysis, or suggestions for improvement. Without additional information or guidance, the authors are left without actionable feedback or direction on how to address this claim or improve their model. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of mathematical details in the explanation of the hypothesis that large chunks of the final representation of wide DNNs behave like an ensemble of independent measures of the full feature space. It explicitly requests more mathematical details to be included, which provides a clear and direct action for the authors to take. The comment is specific in its request for additional mathematical details, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Top of page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mathematical details in the explanation of the hypothesis that large chunks of the final representation of wide DNNs behave like an ensemble of independent measures of the full feature space. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity and mathematical details of the explanation provided regarding the hypothesis that large chunks of the final representation of wide DNNs behave like an ensemble of independent measures of the full feature space. The reviewer expresses confusion about the concept and its relevance to the observed scaling, indicating a need for more mathematical details. However, the comment does not provide specific examples or references to support the claim that the explanation is unclear or lacks detail. This makes the claim somewhat verifiable, as it highlights a potential issue but lacks the necessary evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity and mathematical details of the explanation provided regarding the hypothesis that large chunks of the final representation of wide DNNs behave like an ensemble of independent measures of the full feature space. It points out that the authors have not provided sufficient mathematical details to support this claim, which is crucial for understanding the theoretical basis of their work. By highlighting this gap, the comment provides clear and actionable feedback for the authors to enhance the clarity and rigor of their explanation. This guidance is valuable for improving the draft, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors have tried using BlenderBot 2.0 with incorporated knowledge and suggests that using domain ontologies from the SGD dataset could improve dialogs. While the comment implies that the authors should consider this approach, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the authors have tried using BlenderBot 2.0 with incorporated knowledge and suggests using domain ontologies from the SGD dataset to improve dialogs. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting a potential improvement by incorporating domain ontologies, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking whether the authors have tried using BlenderBot 2.0 with incorporated knowledge and suggests using domain ontologies from the SGD dataset to improve dialogs. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises an interesting question about the authors\\' potential use of BlenderBot 2.0 with incorporated knowledge and suggests incorporating domain ontologies from the SGD dataset to improve dialogs. This feedback is somewhat helpful as it prompts the authors to consider a novel approach that could enhance their work. However, the comment lacks specific guidance or detailed suggestions on how to implement this suggestion or what specific aspects of the dialogs could be improved. While it points out a potential area for improvement, it does not provide actionable steps for the authors to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation are not clearly stated. The reviewer assumes that the samples should overlap, given that the paper calculates Krippendorff $\\\\alpha$. While the comment identifies a potential issue, it does not provide explicit instructions or concrete guidance on how the authors should address this. The authors are left to infer that they should clarify the overlap of samples, but without specific suggestions on how to do so, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the calculation of Krippendorff $\\\\alpha$, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation are not clearly stated. The reviewer assumes that the samples should overlap, given that the paper calculates Krippendorff $\\\\alpha$. However, the comment lacks specific examples or references to support this assumption, making it somewhat verifiable. The authors would need to infer the importance of clarifying the overlap, as the comment does not provide a clear rationale or evidence for why this is crucial. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper regarding the clarity of information about the number of samples rated by GPT-4 and whether they overlap with the samples used in the human evaluation. The reviewer assumes that the samples should overlap, given that the paper calculates Krippendorff $\\\\alpha$. This feedback is somewhat helpful as it points out a potential gap in the paper\\'s presentation, but it lacks detailed guidance or suggestions on how the authors might address this issue. While it highlights an area for improvement, the comment could be more actionable with additional details or examples. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the difference between \"arg-wise consistency\" and \"accuracy,\" and suggests that the label annotation agreement should be lower due to low pred-wise consistency. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions to take. The comment lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the consistency and accuracy of the paper, specifically questioning the difference between \"arg-wise consistency\" and \"accuracy.\" It suggests that the label annotation agreement should be lower due to low pred-wise consistency. However, the comment does not specify which part of the paper discusses these concepts, making it weakly grounded. The comment is specific in its questioning of the difference and the implications for label annotation agreement, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the difference between \"arg-wise consistency\" and \"accuracy\" and suggests that the label annotation agreement should be lower due to low pred-wise consistency. However, the comment lacks specific examples or references to support the claim that the difference between these terms is unclear or that the label annotation agreement should be lower. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the difference between \"arg-wise consistency\" and \"accuracy,\" which is a critical point for understanding the consistency and accuracy of the paper. It suggests that the label annotation agreement should be lower due to low pred-wise consistency, which is an insightful observation. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the distinction between the two concepts. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing more details on the neural network parametrization of the reverse process, particularly how position embeddings are provided, could enhance reproducibility. It also recommends providing the code of the implementation, which is considered a standard for ensuring reproducibility. While the comment implies that the authors should provide more details and code, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors know they need to provide more details and code but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests providing more details on the neural network parametrization of the reverse process, particularly how position embeddings are provided, to enhance reproducibility. It also recommends providing the code of the implementation, which is considered a standard for ensuring reproducibility. However, the comment does not specify which part of the paper these details should be added to, making it weakly grounded. The suggestion to provide code is specific, but without grounding, the authors cannot confidently determine which part of the paper this pertains to. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, particularly how position embeddings are provided, could enhance reproducibility. It also recommends providing the code of the implementation, which is considered a standard for ensuring reproducibility. The claim is somewhat verifiable as it logically suggests that providing more details and code could improve reproducibility. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should provide more details on the neural network parametrization of the reverse process, particularly how position embeddings are provided, to enhance reproducibility. It also recommends providing the code of their implementation, which is a standard for ensuring reproducibility. This feedback is clear and offers a concrete direction for the authors to improve the clarity and transparency of their work. By addressing these points, the authors can significantly enhance the reproducibility and robustness of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a repeated paragraph in the first paragraph of section 3.3. While it identifies the issue, it does not provide any guidance on how to resolve it. The authors are left to infer that they should remove the repeated content, but no specific instructions or suggestions are given. The action is implicit and vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the first paragraph of section 3.3, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of a repeated paragraph, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a repeated paragraph in the first paragraph of section 3.3. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, namely a repeated paragraph in the first paragraph of section 3.3. This is a clear and actionable observation that the authors can address to improve the clarity and coherence of their draft. However, the comment lacks depth and does not provide suggestions on how to revise or restructure the paragraph to avoid repetition. While it points out a problem, it does not offer guidance on how to resolve it, making it somewhat helpful. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reusability and sustainability of synthetic data generated on-the-fly. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this concern or what specific steps they should consider to ensure the sustainability and reusability of their synthetic data. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the reusability and sustainability of synthetic data generated on-the-fly, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what aspects of the synthetic data generation process are being questioned or how the authors might address these concerns. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the reusability and sustainability of synthetic data generated on-the-fly. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it might impact the paper\\'s findings. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the reusability and sustainability of synthetic data generated on-the-fly. It highlights an important aspect of the paper\\'s contribution that could impact its practical applicability. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what aspects of the synthetic data generation process should be considered for sustainability. Without actionable advice or detailed feedback, the authors may find it challenging to improve their draft in response to this feedback. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not provide a clear path for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues with the paper. First, it points out that the authors do not examine the likelihood of alternative RNA structures arising, which is a significant oversight. Second, it suggests that the authors should consider RNA abundance when building datasets. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to consider alternative RNA structures and RNA abundance, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction of the ProbTransfomer model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of examination of alternative RNA structures and the importance of considering RNA abundance when building datasets. This provides clear guidance on what the authors need to address to improve their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not examine the likelihood of alternative RNA structures arising, which is a significant oversight. It also suggests that the authors should consider RNA abundance when building datasets. While the comment identifies a potential gap in the paper, it lacks specific examples or references to support the claim that the authors should examine alternative RNA structures or consider RNA abundance. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper. First, it points out that the authors do not examine the likelihood of alternative RNA structures arising, which is a critical oversight. This feedback highlights a gap in the paper that the authors need to address to provide a more comprehensive understanding of the problem. Second, it suggests that the authors should consider RNA abundance when building datasets, which is another important aspect that could impact the model's performance. By addressing these issues, the authors can significantly enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions on how to examine alternative RNA structures or incorporate RNA abundance into the dataset construction process. Overall, the comment is mostly helpful as it identifies critical areas for improvement but lacks detailed guidance on execution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a potential issue with the numerical results, specifically the use of a single entropic regularization coefficient (\\xce\\x94=1200). The reviewer suggests that this might be a weak regularization term, which could lead to sparse couplings and favor the method. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to acknowledge it. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the potential impact of this choice on their results and methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the numerical results, specifically the use of a single entropic regularization coefficient (\\xce\\x94=1200). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the use of a single regularization coefficient and suggests that this might be a weak regularization term. It also points out the need to acknowledge this issue in the paper and not sweep it under the rug. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of a single entropic regularization coefficient (\\xce\\x94=1200) might be a weak regularization term, leading to sparse couplings and favoring the method. The reviewer suggests that this is okay if the method is not beneficial in strong-regularization regimes. However, the comment does not provide specific evidence or references to support this claim, such as data or comparisons with other regularization methods. The reasoning is based on a logical assumption but lacks detailed justification or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the numerical results, specifically the use of a single entropic regularization coefficient (\\xce\\x94=1200). It suggests that this might be a weak regularization term, which could lead to sparse couplings and favor the method. The reviewer acknowledges that this might not be problematic if the method is not beneficial in strong-regularization regimes. However, the comment points out that this issue should be acknowledged in the paper and not swept under the rug. This feedback is somewhat helpful as it highlights a potential weakness in the numerical results and suggests that the authors should address it. However, it could be more helpful if it provided specific guidance on how to acknowledge this issue or what aspects of the method might be affected by the choice of regularization coefficient. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the information provided in Table 1 and the paper regarding the sources used for the analysis. It explicitly points out that the Vlachos and Riedel 2014 dataset is stated as having no evidence in Table 1, while the paper claims to have collected sources used by journalists. The comment implies that the authors should clarify this inconsistency in their paper. However, it does not provide specific guidance on how to address this issue, such as suggesting a revised statement or clarification in the text. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to resolve the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the Vlachos and Riedel 2014 dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the information provided in Table 1 and the paper regarding the sources used for the analysis. The comment clearly specifies what needs to be addressed, namely the inconsistency between the information in Table 1 and the paper regarding the sources used for the analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about a discrepancy between the information provided in Table 1 and the paper regarding the sources used for the analysis. The reviewer points out that the table states that the Vlachos and Riedel 2014 dataset has no evidence, while the paper claims to have collected sources used by journalists. This is a factual observation that highlights a potential inconsistency in the paper. However, the comment does not provide further explanation or evidence to support why this discrepancy is significant or how it affects the paper\\'s credibility. As a result, the claim is somewhat verifiable, as it points out a potential issue but lacks detailed justification or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the information provided in Table 1 and the paper regarding the sources used for the analysis. It points out that the table states that the Vlachos and Riedel 2014 dataset has no evidence, while the paper claims to have collected sources used by journalists. This is a clear and actionable observation that prompts the authors to clarify this inconsistency in their paper. By addressing this issue, the authors can improve the accuracy and consistency of their work. However, the comment could be more helpful if it provided suggestions on how to resolve the discrepancy or offered guidance on how to present the sources in a more coherent manner. Overall, the comment is mostly helpful as it highlights a critical area for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include details about the parameters used for each simulator, such as whether they used the GPU pipeline in IsaacGym or just the CPU pipeline, the substeps for physics simulation, and the number of total vertices in the simulation. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what information to include in their draft. The explicit nature of the request and the detailed guidance on what to include make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of different simulators and their parameters, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is missing, such as the details of the parameters used for each simulator, including whether the GPU pipeline was used in IsaacGym or just the CPU pipeline, the substeps for physics simulation, and the number of total vertices in the simulation. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors include details about the parameters used for each simulator, such as whether they used the GPU pipeline in IsaacGym or just the CPU pipeline, the substeps for physics simulation, and the number of total vertices in the simulation. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors include details about the parameters used for each simulator. This feedback is clear and actionable, as it provides a concrete step for the authors to take in order to enhance the transparency and reproducibility of their work. By including the requested information, the authors can ensure that their methodology is fully understood and replicable by others. However, the comment could be more helpful if it provided examples of what kind of details should be included or how they might be presented. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the choice of hyperparameters $s$ and $k$ in the proposed sparse-CL and k-NL method, noting that these hyperparameters are crucial for the effectiveness of the method. However, it does not provide explicit guidance on how the authors should address this issue. The comment suggests that the choice of $s$ and $k$ is important, but it does not provide specific suggestions on how to improve the generalizability of the proposed loss function or what alternative methods could be considered. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the generalizability of their method and explore alternative hyperparameter choices. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Supplementary Material A.3, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of hyperparameters $s$ and $k$, noting that the empirical selection reduces the generalizability of the proposed loss function. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the choice of hyperparameters $s$ and $k$ in the proposed sparse-CL and k-NL method is crucial for its effectiveness. It supports this claim by noting that the Supplementary Material A.3 only states that $s$ and $k$ are chosen based on cross-validation, which reduces the generalizability of the proposed loss function. This reasoning is somewhat verifiable as it highlights a potential issue with the method's generalizability, but it lacks specific examples or references to support the claim more robustly. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the proposed method, specifically the choice of hyperparameters $s$ and $k$ in the sparse-CL and k-NL masking technique. It points out that the Supplementary Material A.3 only states that these hyperparameters are chosen based on cross-validation, which reduces the generalizability of the proposed method. This feedback is valuable as it highlights a potential weakness in the methodology that the authors should address to improve the generalizability and robustness of their approach. However, the comment could be more helpful if it provided suggestions on how to improve the choice of hyperparameters or how to address the issue of reduced generalizability. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests comparing the optimization times of the current work with OpenTuner, which uses adaptive search techniques. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"OpenTuner,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison of optimization times with OpenTuner. The comment provides a clear direction for improvement by suggesting a comparison with OpenTuner, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors only use simulated annealing in OpenTuner and suggests comparing the optimization times with OpenTuner, which can adaptively use different search techniques. However, the comment lacks specific examples or references to support the claim that OpenTuner is superior in terms of optimization times. Without such evidence or detailed reasoning, the claim is not fully verifiable, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting a comparison between the current work and OpenTuner, which uses adaptive search techniques. This feedback is clear and actionable, as it prompts the authors to conduct a comparison that could enhance the robustness and generalizability of their work. By addressing this suggestion, the authors can potentially improve the quality and impact of their research. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks novelty, as many works have already introduced diffusion models into the anomaly detection area. It specifically mentions three references ([1] [2] [3]) that have introduced diffusion models for anomaly detection. The reviewer also notes that the work only makes minor adjustments to an existing model (NCSN) and does not introduce any new ideas or innovations. While the comment identifies a lack of novelty, it does not provide explicit guidance on how the authors could address this issue or suggest ways to enhance the novelty of their work. The action is implicit and somewhat vague, as the authors need to infer that they should explore new directions or innovations to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific works ([1] [2] [3]) that have introduced diffusion models into the anomaly detection area, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of limited novelty, as the work only makes minor adjustments to an existing model (NCSN) and does not introduce any new ideas or innovations. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, as many works have already introduced diffusion models into the anomaly detection area. The reviewer supports this claim by referencing specific works ([1] [2] [3]) that have introduced diffusion models for anomaly detection. However, the comment does not provide detailed reasoning or analysis of why these works are relevant to the current paper or how the authors could address the issue of lacking novelty. While the references provide some support, the comment could be strengthened by explaining why these works are directly relevant to the current paper or how the authors could differentiate their work from existing literature. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it lacks novelty as many works have already introduced diffusion models into the anomaly detection area. It provides specific references to three works ([1] [2] [3]) that have introduced diffusion models for anomaly detection, which is a valuable piece of information for the authors. The comment also highlights that the work only makes minor adjustments to an existing model (NCSN) and does not introduce any new ideas or innovations. While the feedback identifies a critical weakness, it does not offer specific suggestions or guidance on how the authors could address this issue or enhance the novelty of their work. The comment is somewhat helpful as it points out a significant limitation but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including grammar errors and the lack of labeling on Figure 2\\'s axes. While the comment identifies specific errors, it does not provide explicit guidance on how to correct them. The authors are left to infer that they need to review and correct the grammar errors and label the axes in Figure 2. The action is implicit and somewhat vague, as it lacks concrete details on how to implement the corrections. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific errors in the paper, such as \"The teacher and the student are jointly trained to make the teacher\u2019s knowledge more friendly to the students called online distillation\" and \"Our approach achieves better parameter-efficient and student-friendly KD\u2026\". Additionally, it mentions the lack of labeling on Figure 2\\'s axes, providing clear guidance on what needs to be addressed. This level of detail allows the authors to accurately identify the parts of the paper being addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual observations about grammar errors and the lack of labeling on Figure 2\\'s axes. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including grammar errors and the lack of labeling on Figure 2\\'s axes. While it points out specific errors, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it highlights areas that need attention, but it lacks depth and actionable advice. The authors are left with a general understanding of the problems but without clear steps to improve their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more quantitative error analysis in section 5.2, which is a clear and direct action. It specifies the need for a more detailed analysis, making it easy for the authors to understand and implement the suggested improvement. The comment is specific and provides concrete guidance on what needs to be done to enhance the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the \"crappy\" error analysis and the need for more quantitative error analysis. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis in section 5.2 is \"crappy\" and suggests that more quantitative error analysis would be beneficial. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the error analysis in section 5.2, describing it as \"crappy\" and suggesting that more quantitative error analysis would be beneficial. This feedback is clear and actionable, as it directly points out a weakness in the paper and provides a concrete suggestion for improvement. By addressing this issue, the authors can enhance the credibility and rigor of their analysis. However, the comment could be more helpful if it provided additional guidance on how to conduct the quantitative error analysis or examples of how it could be implemented. Overall, the comment is mostly helpful as it effectively directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider measuring the Proxy-A distance between the distributions in addition to using t-SNE for evaluation. It also points out that Fig. 6c and 6d appear to be the same, prompting the authors to verify if the Proxy-A distance is close. While the comment provides explicit actions to take, such as measuring the Proxy-A distance and verifying Fig. 6c and 6d, it does not offer detailed guidance on how to implement these actions. The authors are left with a clear understanding of what needs to be done but may need to infer the specifics of how to execute these tasks. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 6c, 6d,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of t-SNE for distribution alignment and the suggestion to measure the Proxy-A distance. The comment provides a clear direction for improvement by recommending an additional method for evaluation and highlighting a potential issue with the figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that relying solely on t-SNE for evaluating distribution alignment is insufficient and recommends measuring the Proxy-A distance between the distributions. The comment provides a logical reasoning by suggesting that t-SNE may not be sufficient for evaluating distribution alignment, and it provides a specific suggestion to measure the Proxy-A distance. However, the comment lacks detailed justification or examples of how the Proxy-A distance could be used or why it is a better metric. This makes the claim somewhat verifiable, as the authors would need to further explore the rationale behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to improve the evaluation of distribution alignment. It recommends measuring the Proxy-A distance between the distributions, which is a different metric from t-SNE, and points out that Fig. 6c and 6d appear to be the same. This feedback is clear and offers a concrete step for the authors to enhance the robustness and comprehensiveness of their evaluation. By addressing this suggestion, the authors can improve the quality and credibility of their results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and suggests exploring the performance of using a reinforcement algorithm for all phrases. While the comment implies that the authors should provide an explanation or comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L216-217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and suggests exploring the performance of using a reinforcement algorithm for all phrases. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for clarification and additional information regarding the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and the performance of using a reinforcement algorithm for all phrases. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and suggests exploring the performance of using a reinforcement algorithm for all phrases. This feedback is valuable as it prompts the authors to clarify their methodology and potentially improve their results by considering alternative approaches. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these questions or improve the methodology. Overall, the comment is mostly helpful as it directs the authors to consider important aspects of their methodology, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed cross-modality adaptation has been validated in two external works, BEVDepth [1] and 2DPASS [2], but that the paper did not discuss these works in the related work section. This feedback implies that the authors should include a discussion of these works in their related work section to provide a more comprehensive overview of the state of the art. However, the comment does not explicitly instruct the authors to do so, leaving the action somewhat implicit. The authors can infer that they need to add a discussion of these works, but the lack of explicit guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"BEVDepth [1] and 2DPASS [2],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on these external works in the related work section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed cross-modality adaptation has been validated in external works, specifically mentioning BEVDepth [1] and 2DPASS [2]. However, the comment does not provide any further context or explanation about these works or how they relate to the paper under review. Without additional information or references, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the proposed cross-modality adaptation has been validated in external works, such as BEVDepth [1] and 2DPASS [2], but is not discussed in the related work section. This feedback is clear and actionable, as it prompts the authors to include a discussion of these works in their related work section to provide a more comprehensive overview of the state of the art. However, the comment could be more helpful if it offered suggestions on how to integrate this discussion into the paper or provided examples of how similar works have been discussed in other papers. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Table 1 only presents test loss as a metric for performance degradation and does not include any generation results, such as BLEU scores, to assess the quality of the output. This feedback implies that the authors should include additional metrics to provide a more comprehensive assessment of the paper\\'s results. However, the comment does not explicitly instruct the authors to include these metrics or specify which ones should be used. While the action is implied, it is not as clear as it could be, as the authors may not be entirely sure which metrics to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of generation results such as BLEU scores to assess the quality of the output. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 only presents test loss as a metric for performance degradation and does not include any generation results, such as BLEU scores, to assess the quality of the output. This claim is somewhat verifiable as it highlights a specific omission in the paper\\'s evaluation metrics. However, the comment lacks detailed reasoning or examples to fully substantiate why the inclusion of BLEU scores is necessary or how it would improve the assessment of the paper\\'s results. Providing more context or examples would strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that Table 1 only presents test loss as a metric for performance degradation and does not include any generation results, such as BLEU scores, to assess the quality of the output. This feedback is clear and actionable, as it points out a gap in the paper\\'s evaluation metrics that could be addressed to provide a more comprehensive assessment of the results. By suggesting the inclusion of additional metrics, the comment offers a concrete way for the authors to improve the clarity and depth of their analysis. However, it could be more helpful if it provided examples of how these metrics could be used or why they are important for assessing the paper\\'s contributions. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including experiments to validate the analysis, particularly for discussions on different regimes, would be beneficial. While the comment implies that the authors should consider conducting experiments, it does not provide specific guidance on how to design or conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer that they should include experiments to validate their analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that including experiments to validate the analysis, particularly for discussions on different regimes, would be appreciated. However, it does not specify which part of the paper this suggestion pertains to, such as the sections discussing different regimes or the analysis itself. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of experiments to validate the analysis, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including experiments to validate the analysis, particularly for discussions on different regimes, would be appreciated. However, it does not provide any specific reasoning or evidence to support why this is necessary or how it would enhance the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including experiments to validate the analysis, particularly for discussions on different regimes, would be appreciated. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, which could strengthen the theoretical analysis by providing empirical evidence. However, the comment lacks specific guidance on how to design or conduct these experiments, or which regimes should be considered. While it points out a potential enhancement, it does not fully support the authors in making that improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. While the comment implies that the authors should consider adding these baselines, it does not explicitly instruct them to do so or provide detailed guidance on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer that they should add these baselines and understand the potential benefits. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. Without explicit references to sections or specific elements, the authors cannot confidently determine the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what insights the authors should expect from these baselines or how they would be implemented. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these baselines would be beneficial or how they would contribute to the study. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. This suggestion could potentially offer valuable information about the performance of the baselines and the benchmark itself. However, the comment lacks depth and does not explain why these baselines would be beneficial or how they would contribute to the study. Additionally, it does not provide specific guidance on how to implement these changes or what specific insights the authors should expect from these baselines. While the suggestion is somewhat helpful, it could be more actionable and detailed to be fully beneficial for the authors. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the description of advantage-weighted regression, specifically mentioning the missing explanation of the Q function being w.r.t. \\u03b4, which is crucial for solving the constrained optimization of Eq. 4. This feedback provides a clear and explicit action for the authors to take, which is to clarify the Q function and its relationship to \\u03b4. The comment is specific and actionable, giving the authors a direct path to improve the clarity of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"description of advantage-weighted regression,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the explanation of the Q function being w.r.t. \\u03b4, which is crucial for understanding the constrained optimization of Eq. 4. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of advantage-weighted regression is unclear, specifically mentioning the missing explanation of the Q function being w.r.t. \\u03b4. This claim is somewhat verifiable as it highlights a specific aspect of the paper that requires clarification, but it lacks detailed reasoning or examples to fully substantiate the claim. The reviewer could provide more context or examples to strengthen the argument, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of clarity that is missing in the paper, specifically the description of advantage-weighted regression. It points out that the Q function is w.r.t. \\u03b4, which is crucial for understanding the constrained optimization of Eq. 4. This feedback is clear and actionable, as it directs the authors to provide a missing piece of information that could enhance the clarity and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided additional context to better situate the Q function within the broader context of the paper. Overall, the comment is mostly helpful as it effectively guides the authors to improve the clarity of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed method is effective in each part but notes that the overall algorithm is still cumbersome due to its multiple stages. It compares this to existing pruning methods that do not require fine-tuning. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to simplify the algorithm or suggestions for streamlining the method. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the overall algorithm of the proposed method, specifically mentioning that it is cumbersome due to its multiple stages. It compares this to existing pruning methods that do not require fine-tuning. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the overall algorithm and the comparison to existing methods, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the overall algorithm is cumbersome due to its multiple stages, which is a subjective observation. It compares this to existing pruning methods that do not require fine-tuning, providing a logical basis for the claim. However, the comment lacks specific examples or references to support the claim that existing methods do not require fine-tuning. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed method, noting that the overall algorithm is cumbersome due to its multiple stages. It compares this to existing pruning methods that do not require fine-tuning, highlighting a potential area for improvement. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending simplification or streamlining of the algorithm. While it points out a weakness, it does not provide actionable advice for the authors to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the advantage of the new quantile function (3) over the existing function (2) is not adequately justified. It highlights that the change from multiplicative factors to an additive term makes the function less sensitive to tail parameters when they are large. However, the comment does not provide specific guidance on how the authors should address this issue or what data or analysis would be needed to justify the advantage. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional justification or data to support the claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"new quantile function (3)\" and the \"existing function (2),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the advantage of the new function is not adequately justified, particularly regarding the change from multiplicative factors to an additive term. The comment further highlights the need for supporting data to justify the reduced sensitivity to tail parameters. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the advantage of the new quantile function (3) over the existing function (2) is not adequately justified. It suggests that the change from multiplicative factors to an additive term makes the function less sensitive to tail parameters when they are large. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the need for additional justification or data to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the advantage of the new quantile function (3) over the existing function (2) is not adequately justified. It points out that the change from multiplicative factors to an additive term makes the function less sensitive to tail parameters when they are large. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide additional justification for the advantage of the new function. While it highlights a potential weakness, the feedback does not offer actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It points out that Figure 3 is confusing and suggests improving the contribution section, specifically mentioning the low contribution over SWE-Bench. The reviewer also highlights the authors\\' claim about their benchmark having new additions, such as testing fault localization and LLMs\\' capability of discovering issues. The reviewer questions these claims by pointing out that if a model can fix a bug, it would need to perform fault localization, and that passing a failed unit test to an LLM does not require LLM for issue generation. The comment provides clear guidance on what needs to be improved, making it highly actionable. The authors know exactly what changes to make to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and the \"contribution over SWE-Bench,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the confusion in Figure 3 and the low contribution over SWE-Bench. The comment provides detailed feedback on the authors\\' claims about their benchmark and the implications of their findings, such as the redundancy of fault localization and the automated handling of failed unit tests. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is confusing and that the contribution over SWE-Bench is low. The reviewer questions the authors\\' claims about their benchmark\\'s new additions, such as testing fault localization and LLMs\\' capability of discovering issues. The comment provides logical reasoning by pointing out that if a model can fix a bug, it would need to perform fault localization, and that passing a failed unit test to an LLM does not require LLM for issue generation. This reasoning is based on common knowledge and logical deduction, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claims. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the clarity and relevance of Figure 3, suggesting that it is confusing and recommending improvements. It also critiques the authors\\' claims about their benchmark, pointing out that the contribution over SWE-Bench is low and questioning the necessity of testing fault localization and LLMs\\' issue-generation capabilities. The comment is detailed and constructive, offering specific guidance on how to enhance the clarity and relevance of the paper. By addressing these points, the authors can significantly improve the clarity and impact of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing aspect in the paper, specifically the lack of key descriptions regarding the selection of topics for the complementary attribute in topic control experiments. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include this information, but it lacks concrete details on what specific aspects need to be included or how to present them. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a missing aspect in the paper regarding the selection of topics for the complementary attribute in topic control experiments. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what is missing, namely the selection process for the complementary attribute, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the missing descriptions regarding the selection of topics for the complementary attribute in topic control experiments. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that these descriptions are necessary or how they would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper is lacking, specifically the absence of key descriptions regarding the selection of topics for the complementary attribute in topic control experiments. This is a critical point that could impact the clarity and completeness of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific details should be included. While it points out a gap in the paper, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the real-world manipulation only contains a single case, which is not enough to convince the authors that their system identification method will improve sim-to-real policy deployment. However, it does not provide any guidance on how the authors might address this issue or suggest ways to improve the demonstration of their method. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the real-world manipulation section, which is a specific part of the paper. However, it does not explicitly mention which part of the section is being referred to, such as specific experiments or results. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in pointing out the issue of only having a single case for real-world manipulation and questioning the general applicability of the system identification method. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the real-world manipulation only contains a single case, which is not enough to convince the authors that their system identification method will improve sim-to-real policy deployment. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the real-world manipulation only contains a single case. This is a relevant observation that could impact the authors\\' ability to demonstrate the effectiveness of their system identification method in sim-to-real policy deployment. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or improve their demonstration. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the quality of the ShortcutQA and suggests providing details about how \"answerable\" the distracted texts are. It also requests examples and qualitative results to support the claim. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples and results to address the reviewer\\'s concerns. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ShortcutQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the quality of the ShortcutQA, suggesting that the authors provide details about how \"answerable\" the distracted texts are, and requests examples and qualitative results. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a skepticism about the quality of the ShortcutQA, questioning whether it adds ambiguity to the texts, leading to degradation in performance. The reviewer suggests providing details about how \"answerable\" the distracted texts are and requests examples and qualitative results. While the comment identifies a concern, it lacks specific examples or references to support the claim that ambiguity is introduced by the ShortcutQA. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or reasoning to fully address the reviewer\\'s concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the quality of the ShortcutQA, questioning whether it introduces ambiguity into the texts, leading to a degradation in performance. It suggests that the authors provide details about how \"answerable\" the distracted texts are and requests examples and qualitative results to support their claims. This feedback is somewhat helpful as it prompts the authors to address a potential weakness in their methodology. However, the comment could be more helpful if it provided specific suggestions on how to improve the ShortcutQA or what aspects to focus on in terms of answerability. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the use of the term \"deep\" could be clarified by providing a forward pointer to its definition. This is an explicit request for the authors to include a reference or definition for the term \"deep,\" which is a clear and direct action. The comment provides a specific suggestion for improvement, making it highly actionable. Authors know exactly what needs to be done to address the issue, which is to include a forward pointer to the definition of \"deep.\"', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the use of the term \"deep\" could be clarified by providing a forward pointer to its definition. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the term is used. Without explicit references, the authors cannot confidently determine the exact part of the paper that needs clarification. The comment is specific in suggesting a potential improvement but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the use of the term \"deep\" could be clarified by providing a forward pointer to its definition. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered a valid suggestion for improvement. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the use of the term \"deep\" could be clarified by providing a forward pointer to its definition. This is a specific and actionable suggestion that can help the authors improve the clarity and accessibility of their work. However, the comment does not provide additional context or explanation about why this clarification is necessary or how it would benefit the readers. While it identifies a potential area for improvement, it could be more helpful if it included more detailed guidance on how to implement the suggested clarification. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the method of model selection in the presented framework to identify an appropriate value for the number of archetypes, k. While it implies that the authors should consider model selection, it does not provide explicit instructions or concrete steps on how to implement this. The action is implicit and somewhat vague, as the authors need to infer that they should address model selection. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"framework\" and the \"number of archetypes k,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the method of model selection to identify an appropriate value for k. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification about the method of model selection in the framework to identify an appropriate value for the number of archetypes, k. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a practical question about the method of model selection in the presented framework to identify an appropriate value for the number of archetypes, k. This is a relevant point that could help the authors improve the clarity and robustness of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue. While it identifies an area for improvement, it does not offer actionable steps or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of Theorem 1 and suggests that it should be included at the beginning of page 6, along with Theorem 2. It also instructs the authors to separate counting between Assumptions, Lemmas, and Theorems. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to address the issue. The explicit nature of the comment and the detailed guidance on how to implement the changes make it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"the beginning of page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of Theorem 1 and the separation of counting between Assumptions, Lemmas, and Theorems. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the presence of Theorem 1 and the separation of counting between Assumptions, Lemmas, and Theorems. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific issue with the paper, namely the absence of Theorem 1 and the lack of separation between Assumptions, Lemmas, and Theorems. By pointing out this oversight, the comment provides the authors with clear and actionable feedback on how to improve the organization and presentation of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as providing examples of how other papers typically present similar material. Despite this, the feedback is valuable as it directs the authors to a critical area for improvement, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, specifically questioning its generalizability to long document summarization tasks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific steps they could take to ensure the generalizability of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, specifically questioning its generalizability to long document summarization tasks. However, it does not specify which part of the paper this assumption is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the assumption but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, specifically questioning its generalizability to long document summarization tasks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, specifically questioning its generalizability to long document summarization tasks. This is an important point that could impact the applicability and effectiveness of the approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or test the generalizability of their approach. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the novelty and clarity of the proposed method, specifically questioning how the method can generate multiple different graphs and whether having different weights for each edge would be too many parameters. While the comment identifies areas of uncertainty, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to clarify these points, but the comment lacks concrete suggestions or examples on how to improve the clarity or novelty of the method. Therefore, the comment is somewhat actionable, as it points out areas that need attention but does not offer specific steps for improvement.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 180,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning how the method can generate multiple different graphs and whether having different weights for each edge would be too many parameters. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the novelty and clarity of the proposed method, specifically mentioning that some parts are not clear, such as how the method can generate multiple different graphs and whether having different weights for each edge would be too many parameters. However, the comment lacks specific examples or detailed reasoning to support these claims. The reviewer does not provide references or detailed explanations to substantiate their concerns, making it difficult for the authors to understand the basis of the critique. As a result, the claim is somewhat verifiable, as it highlights areas of uncertainty but lacks the necessary evidence or reasoning to fully support the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty and clarity of the proposed method, specifically questioning how the method can generate multiple different graphs and whether having different weights for each edge would be too many parameters. This feedback is somewhat helpful as it points out areas where the authors need to clarify their methodology, but it lacks depth and specific suggestions on how to address these concerns. The comment could be more helpful if it provided examples or detailed guidance on how to improve the clarity or novelty of the method. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the scope of the experiments, specifically noting that the experiments are limited to two simulation experiments on a unit sphere and spiral curves, and a third example using time of travel by taxis. The reviewer suggests that it would be beneficial to include an example of learning the geometry of a more complicated manifold. While the comment implies that the authors should expand their experimental scope, it does not provide specific guidance on how to do so or which types of manifolds to consider. The action is implicit and somewhat vague, as the authors need to infer the need for more diverse examples and determine which ones to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments, specifically mentioning the two simulation experiments on a unit sphere and spiral curves, and the third example using time of travel by taxis. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the limited scope of the experiments and the need for examples of learning the geometry of more complicated manifolds. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are limited in scope, specifically mentioning two simulation experiments on a unit sphere and spiral curves, and a third example using time of travel by taxis. The reviewer suggests that it would be beneficial to include an example of learning the geometry of a more complicated manifold. While the comment identifies a limitation in the experimental scope, it does not provide specific examples or references to support the claim that a more complex manifold is necessary. The reasoning is somewhat verifiable, as it highlights a potential limitation but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, specifically noting that the experiments are limited to two simulation experiments on a unit sphere and spiral curves, and a third example using time of travel by taxis. The reviewer suggests that it would be beneficial to include an example of learning the geometry of a more complicated manifold. This feedback is somewhat helpful as it points out a potential limitation in the experimental scope and suggests a way to enhance the study by including a more diverse range of examples. However, the comment could be more helpful if it provided specific examples or suggestions for more complex manifolds to consider. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the authors\\' observation about the limitations of the current knowledge, which relies on a specific template that lacks naturalness and does not fully utilize the capabilities of the LLM. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the naturalness or utilization of the LLM, nor are there suggestions for potential improvements or alternative approaches. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the authors\\' observation about the limitations of the current knowledge, which relies on a specific template that lacks naturalness and does not fully utilize the capabilities of the LLM. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of naturalness and the lack of full utilization of the LLM, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the current knowledge relies on a specific template that lacks naturalness and does not fully utilize the capabilities of the LLM. This claim is somewhat verifiable as it logically follows the observation that the current knowledge is limited by its reliance on a specific template. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the specific aspects of the template that lack naturalness and how the LLM could be better utilized. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the authors\\' observation about the limitations of the current knowledge, which relies on a specific template that lacks naturalness and does not fully utilize the capabilities of the LLM. This is an obvious weakness for the paper, as it highlights a critical area for improvement. However, the comment does not provide specific suggestions or guidance on how the authors might address this weakness or improve the naturalness of their approach. While it identifies a significant issue, it lacks actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the number of baselines used in the study is small, which affects the universality and generality of the results. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue, such as suggesting additional baselines or explaining why the current number is insufficient. The lack of actionable guidance leaves the authors without a clear path forward, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the number of baselines used in the study, which affects the universality and generality of the results. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of a small number of baselines, but it lacks detailed guidance on how to address this issue or what specific changes could be made to improve the universality and generality of the results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of baselines used in the study is small, which affects the universality and generality of the results. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples of how the small number of baselines impacts the study\\'s conclusions or applicability. As a result, the claim is not verifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential weakness in the study, noting that the number of baselines used is small, which could impact the universality and generality of the results. However, it does not provide specific suggestions or guidance on how the authors might address this issue, such as suggesting additional baselines or explaining why the current number is insufficient. The feedback is somewhat helpful as it points out a potential limitation but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of information about the tokenizer training process, including the mixture of corpus size used and the software stack. While it identifies a specific area that needs attention, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include this information, but without concrete steps or examples, the action remains vague. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the lack of information about the tokenizer training process, including the mixture of corpus size used and the software stack. However, it does not specify which part of the paper this information should be included in, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what is missing, but it is weakly grounded as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no information about the tokenizer training process, including the mixture of corpus size used and the software stack. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the paper\\'s results. Without such details, the claim remains unverifiable, as it lacks the necessary justification to guide the authors in addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of information about the tokenizer training process, including the mixture of corpus size used and the software stack. This is a critical point, as the tokenizer training process is a crucial aspect of the methodology that can impact the results and interpretation of the study. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending the inclusion of these details or explaining their importance. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant oversight but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed method is intuitive, the results are good, but it questions whether the additional complexity of the co-training, positive mining, and alternate optimization steps is necessary. However, it does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to justify the additional complexity. The comment lacks actionable details, such as suggesting ways to demonstrate the necessity of these steps or providing examples of how they could be improved. As a result, the authors are left without clear direction on how to address the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the positive mining framework, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the additional complexity of the co-training, positive mining, and alternate optimization steps is necessary, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the additional complexity of the co-training, positive mining, and alternate optimization steps is necessary, suggesting that the results are good but not fully justified. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, questioning whether the additional complexity of the co-training, positive mining, and alternate optimization steps is necessary. It acknowledges that the results are good but highlights the lack of a clear justification for the additional complexity. While the comment provides some insight into a potential area for improvement, it does not offer specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a gap in the paper, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the scalability of the approach due to the computational complexity of multi-marginal OT and spline calculations. It suggests that a more comprehensive discussion is needed to address this concern. However, the comment does not provide specific guidance on how to conduct this discussion or what aspects should be covered. The action is implicit and somewhat vague, as the authors can infer that they need to include a discussion on scalability but may not be entirely sure of the exact content or depth of this discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"computational complexity of multi-marginal OT and spline calculations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of scalability and the need for a more comprehensive discussion on this topic. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the computational complexity of multi-marginal OT and spline calculations may limit the scalability of the approach for large datasets, which could be problematic for real-world applications. This claim is somewhat verifiable as it provides a logical reasoning based on the computational complexity of the methods, which could impact scalability. However, the comment lacks specific examples or references to support the claim, such as detailed calculations or comparisons with other methods. This makes the claim somewhat verifiable, as it provides a reasonable basis but requires more detailed evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the approach due to the computational complexity of multi-marginal OT and spline calculations. It suggests that a more comprehensive discussion is required to address this concern, which is a valuable point for the authors to consider. However, the comment lacks specific suggestions on how to conduct this discussion or what aspects should be covered, such as potential solutions or trade-offs. While it highlights an important area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claimed that non-uniform label noise is not common in practice, but it contradicts the evidence from real-world noise datasets like Clothing1M, where non-uniform label noise has been observed. The reviewer provides a specific reference to a paper by Kun Yi and Jianxin Wu, which supports the existence of non-uniform label noise. This feedback is explicit and provides a clear contradiction to the authors\\' claim, giving them a direct action to reconsider their statement. The authors are given concrete guidance on where to find evidence that supports the existence of non-uniform label noise, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about non-uniform label noise being not common in practice, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim by referencing the existence of non-uniform label noise in real-world datasets like Clothing1M, which contradicts the authors\\' statement. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the authors\\' claim that non-uniform label noise is not common in practice, by referencing a specific study that contradicts this claim. The reviewer provides a reference to a paper by Kun Yi and Jianxin Wu, which supports the existence of non-uniform label noise in real-world datasets like Clothing1M. This reference provides a clear and specific example of evidence that contradicts the authors\\' claim, making the comment fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the authors\\' claim and evidence from real-world datasets, specifically Clothing1M, where non-uniform label noise has been observed. By referencing a specific study by Kun Yi and Jianxin Wu, the reviewer provides a clear and actionable piece of feedback that challenges the authors\\' claim. This feedback is valuable as it prompts the authors to reconsider their assertion and potentially revise their methodology or analysis to account for non-uniform label noise. However, the comment could be more helpful if it offered suggestions on how to address this issue or what specific aspects of the paper need to be revised. Overall, the comment is mostly helpful as it highlights a critical point that the authors should consider in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation in Section 6.2 is based on only 10 samples, which could lead to biased findings due to the small scale of the experiment. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting a larger sample size or a more robust evaluation method. The action is implied, as the authors can infer that they need to expand their sample size, but it is not clearly stated. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, which is based on a limited sample size of only 10 samples. This provides clear guidance on what needs to be addressed, namely the need to increase the sample size to avoid biased findings. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in Section 6.2 is based on a limited sample size of only 10 samples, which could lead to biased findings due to the small scale of the experiment. This claim is somewhat verifiable as it logically suggests that a smaller sample size could impact the validity of the results. However, the comment lacks specific examples or references to support the claim, such as studies that have demonstrated the impact of sample size on experiment results. This makes the claim somewhat verifiable, as it provides a reasonable basis but requires more detailed evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation in Section 6.2, noting that it is based on a limited sample size of only 10 samples. This observation highlights a potential limitation in the study's findings, as a small sample size could lead to biased results. However, the comment does not provide suggestions or guidance on how the authors might address this issue, such as recommending a larger sample size or discussing potential strategies for mitigating the impact of a small sample size. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential limitation of the method's generalizability to significantly different combinatorial optimization problems, as acknowledged by the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to conduct experiments or what specific aspects of the method should be tested to improve its generalizability. Without actionable advice or suggestions, the authors are left without a clear path forward to enhance their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the method\\'s generalizability to significantly different combinatorial optimization problems, which is acknowledged in the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential limitation of the method\\'s applicability to different combinatorial optimization problems. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is tailored to similar MILP tasks, which could limit its generalizability to significantly different combinatorial optimization problems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the method\\'s generalizability to significantly different combinatorial optimization problems, which the paper acknowledges but does not address experimentally. This feedback is valuable as it highlights a gap in the experimental evaluation that the authors should consider filling to enhance the robustness and applicability of their method. However, the comment could be more helpful if it provided specific suggestions on how to address this limitation or what aspects of the method should be tested to demonstrate its generalizability. Overall, the comment is somewhat helpful as it points out an important area for improvement but lacks detailed guidance on how to achieve it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors attempt to bridge a gap in their baseline description in the Results section, but the reviewer struggles to understand how these baselines work, their relation to InterFair, or their competitiveness. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific details should be included to clarify the baselines. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the baselines. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section \"Results\" and the specific lines \"L256-261,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the authors attempt to bridge a gap in their baseline description but struggle to understand how these baselines work, their relation to InterFair, or their competitiveness. This provides clear guidance on what needs to be addressed in the Results section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors attempt to bridge a gap in their baseline description but struggles to understand how these baselines work, their relation to InterFair, or their competitiveness. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the difficulty in understanding the baselines, making it challenging for the authors to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the baseline description in the Results section, noting that the authors attempt to bridge a gap but struggle to understand how the baselines work, their relation to InterFair, or their competitiveness. This feedback is somewhat helpful as it points out a potential area for improvement in the paper, but it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The comment highlights a gap in the explanation but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any explicit guidance or suggestions on how the authors should improve this comparison. The comment lacks actionable details, such as recommending specific improvements or additional analyses that could be conducted. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the comparison to other baselines on cycle counting and ZINC, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what is lacking in the comparison or how it could be improved, making the comment weakly grounded but specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the insufficiency of the comparison to other baselines on cycle counting and ZINC. This is a clear and actionable point that the authors can address to improve the quality and comprehensiveness of their analysis. However, the comment lacks depth and does not provide suggestions on how to enhance the comparison or what specific aspects should be considered. While it highlights an area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. This feedback implies that the authors should provide a detailed rationale or analysis to support their choice of mask snippets and their effectiveness. However, the comment does not explicitly instruct the authors to do so, leaving some ambiguity about the exact steps to take. While the action is implied, it is not as concrete as it could be, as the authors may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, it does not specify which part of the paper this explanation should be provided in, nor does it provide details on what aspects of the mask snippets are particularly effective or why. This lack of specificity makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for a more detailed explanation of the rationale behind the choice of mask snippets. However, the comment lacks specific guidance on how to provide this explanation or what aspects of the mask snippets should be emphasized. While it points out a potential weakness, it does not offer detailed suggestions or examples to help the authors address it effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a perceived limitation in the performance of SLQ compared to previous CRD methods, specifically noting that SLQ shows worse performance in Figure 3 and only minor improvement over ACL in Figure 4. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance of SLQ. The comment lacks actionable details, such as recommending specific modifications or experiments to improve the performance. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the limited competitiveness of SLQ compared to the CRD method and the small improvement over ACL. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of SLQ is limited compared to the CRD method, as evidenced by the F1 score and conductance values. It also notes that SLQ shows worse performance in Figure 3 and only minor improvement over ACL in Figure 4. While the comment provides some evidence by referencing specific figures, it lacks detailed analysis or specific examples to fully substantiate the claim. The authors would need to conduct their own analysis to verify the claim, making the comment somewhat verifiable. Therefore, the score is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the performance of SLQ compared to previous CRD methods, specifically noting that SLQ shows worse performance in Figure 3 and only minor improvement over ACL in Figure 4. This feedback highlights an area where the authors may need to improve the competitiveness of their method. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional experiments or modifications to the method. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly encourages the authors to add more baselines to perform robust performance comparisons. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific suggestion for enhancing the study by including additional baselines, which is concrete and actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the selection of baselines, specifically noting that it is limited to naive/old models. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to add more baselines for robust performance comparisons. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the selection of baselines is limited to naive/old models and suggests adding more baselines for robust performance comparisons. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the current selection is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically the limited selection of baselines, which are mostly naive or old models. It encourages the authors to add more baselines to perform robust performance comparisons. This feedback is clear and actionable, as it provides a specific direction for improvement. However, the comment could be more helpful if it offered examples of additional baselines that could be considered or explained why the current selection is insufficient. Despite this, the feedback is mostly helpful as it guides the authors toward enhancing the robustness and comprehensiveness of their study.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should either justify their choice of target structure or provide additional experiments demonstrating the method's adaptability to a variety of target structures. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what steps to take to improve their draft. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and the choice of target structure, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the justification for choosing only one target structure and the need for additional experiments to demonstrate adaptability. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of only one target structure for evaluation and suggests that additional experiments are needed to demonstrate the method's adaptability to different target structures. This claim is somewhat verifiable as it logically points out the need for broader applicability, but it lacks specific examples or references to support the argument. The authors might find it challenging to fully understand the basis of the claim without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of target structure in Table 2, questioning why the authors have chosen only one structure for evaluation. It suggests that the authors either justify this choice or conduct additional experiments to demonstrate the method's adaptability to different target structures. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft. By addressing this issue, the authors can enhance the generalizability and applicability of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these additional experiments. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the paper\\'s scope, noting that it primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. The reviewer suggests that exploring applications in critical areas like healthcare could significantly enhance the paper\\'s impact and relevance. While the comment implies that the authors should consider expanding their scope, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their application scope. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"research primarily concentrates on the knapsack problem,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper should explore applications in more realistic scenarios, such as medical diagnosis, to enhance its impact and relevance. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the research primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. This claim is somewhat verifiable as it logically suggests that expanding the application scope could enhance the paper\\'s impact and relevance. However, the comment lacks specific examples or references to support the claim that medical diagnosis is a more realistic scenario. Providing such examples or references would strengthen the claim, making it more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s scope, noting that it primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare could significantly enhance the paper\\'s impact and relevance. This feedback is clear and actionable, as it directs the authors to broaden their application scope and consider more practical and impactful scenarios. However, the comment could be more helpful if it provided specific examples or guidance on how to integrate healthcare applications into the paper. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the method does not seem to improve on robustness and sensitivity as claimed in the motivation section. It also notes that the new method is noisier in two domains and equally noisy as the competitors in the rest. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the robustness and sensitivity of their method. It lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method does not seem to improve on robustness and sensitivity as claimed in the motivation section, and that the new method is noisier in two domains and equally noisy as the competitors in the rest. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method does not improve on robustness and sensitivity as claimed in the motivation section. It provides a specific observation by comparing the new method to the competitors in Figure 3, noting that the new method is noisier in two domains and equally noisy as the competitors in the rest. This claim is somewhat verifiable as it provides a specific observation and comparison, but it lacks detailed reasoning or references to support the claim fully. The authors might need to conduct further analysis to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method, noting that it does not seem to improve on robustness and sensitivity as claimed in the motivation section. It provides a specific observation by comparing the new method to the competitors in Figure 3, noting that the new method is noisier in two domains and equally noisy as the competitors in the rest. This feedback is somewhat helpful as it points out a discrepancy between the method\\'s claims and its performance, but it lacks depth and does not offer suggestions on how the authors might address this issue or improve the method\\'s robustness and sensitivity. The comment could be more helpful if it provided additional insights or guidance on how to improve the method. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the conclusion of the paper, specifically asking whether it holds against more sophisticated or aggressive removal methods. While this question implies that the authors should consider the robustness of their conclusion against such methods, it does not provide explicit guidance on how to address this issue or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to consider the robustness of their conclusion but may not be entirely sure of the exact approach to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the conclusion of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. This provides clear guidance on what aspect of the conclusion needs further exploration or discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point poses a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification or additional analysis, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a relevant question about the robustness of the conclusion against more sophisticated or aggressive removal methods. This is a thoughtful inquiry that could prompt the authors to consider the limitations of their analysis and explore the impact of different removal methods on their results. However, the comment does not provide specific guidance or suggestions on how to address this issue or what aspects of the conclusion might be vulnerable to such methods. While it points out an important area for consideration, it lacks actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper introduces explainable AI in the introduction but does not explain the difference between this and interpretable methods. It also notes that the authors do not provide work in this line. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the definitions and differences between these concepts, as well as provide relevant work in this area. The action is implicit and somewhat vague, as it lacks concrete steps or examples on how to implement these improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of not explaining the difference between explainable AI and interpretable methods, as well as the lack of work in this line. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper introduces explainable AI in the introduction but does not explain the difference between this and interpretable methods. It also notes that the authors do not provide work in this line. The comment is somewhat verifiable as it highlights a discrepancy in the paper\\'s content and suggests a need for clarification. However, it lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the topic of the paper is interpretable methods, but the introduction introduces the concept of explainable AI. This is a critical oversight as the authors do not explain the definition of interpretability or the difference between these two concepts. Additionally, the comment points out that the authors do not provide work in this line, which further undermines the paper\\'s contribution. The feedback is clear and actionable, as it directs the authors to clarify the definitions and differences between these concepts and provide relevant work in this area. This level of detail and guidance is highly beneficial for the authors to improve their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the training data for the probes in the compositionality and transitivity experiments. While it does not explicitly instruct the authors to provide this information, it implies that the authors should include this detail in their paper. The action is implicit but concrete, as the authors can infer that they need to include this information to address the reviewer\\'s concern. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"compositionality and transitivity experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for information about the training data for the probes in these experiments. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for information about the training data for the probes in the compositionality and transitivity experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a specific question about the training data for the probes in the compositionality and transitivity experiments. This is a clear and actionable request for information that the authors should include in their paper to provide transparency and detail about their methodology. By addressing this question, the authors can improve the clarity and completeness of their experimental setup. However, the comment could be more helpful if it included suggestions on how to present this information or why it is important for the reader to know. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors need to clarify what is meant by \"not only the complete captions but also parts thereof,\" and questions the convincingness of the argument around why filling in the blanks is difficult. The reviewer suggests that there are ways to perform bi-directional beam search for fill-in-the-blank applications, referencing example C. While the comment identifies areas that need clarification and suggests a potential solution, it does not provide explicit instructions on how to address these issues or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning and provide more convincing arguments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L133-134,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the argument around why filling in the blanks is hard and the suggestion to use bi-directional beam search for fill-in-the-blank applications. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the argument around why filling in the blanks is difficult and suggests that there are ways to perform bi-directional beam search for fill-in-the-blank applications. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the argument is unconvincing. While it points out a potential issue, the lack of detailed justification or evidence makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is somewhat verifiable, as it highlights a potential weakness but lacks the necessary support to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the argument regarding the difficulty of filling in the blanks, suggesting that the authors need to clarify their meaning. It also points out that there are ways to perform bi-directional beam search for fill-in-the-blank applications, referencing example C. This feedback is somewhat helpful as it highlights a potential area for improvement and provides a specific suggestion for addressing the issue. However, the comment could be more helpful if it offered more detailed guidance on how to clarify the argument or how to implement the bi-directional beam search approach. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the use of reverse KL for training flows and questions the realism of assuming differentiability of the function $g$. It also points out that the reverse KL is mode-seeking and suggests that it may be a limitation for rare event sampling applications. The reviewer provides a specific reference to recent work on normalizing flows that addresses this issue. While the comment identifies potential issues, it does not explicitly instruct the authors on how to address them or provide guidance on how to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of using reverse KL and explore alternative methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of reverse KL for training flows, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the assumption of differentiability of the function $g$ and the mode-seeking nature of the reverse KL. Additionally, it provides a specific reference to recent work on normalizing flows, which adds further context and specificity to the comment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the use of reverse KL for training flows, questioning the realism of assuming differentiability of the function $g$. It also notes that the reverse KL is mode-seeking and suggests that it may be a limitation for rare event sampling applications. The reviewer provides a specific reference to recent work on normalizing flows, which addresses this issue. This reference provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of reverse KL for training flows, questioning the realism of assuming differentiability of the function $g$. It also points out that the reverse KL is known to be mode-seeking, which could be a limitation for rare event sampling applications. The reviewer provides a specific reference to recent work on normalizing flows that addresses this issue, offering a constructive suggestion for improvement. However, the comment could be more helpful by providing additional context or examples to further explain the implications of this limitation. Overall, the comment is somewhat helpful as it highlights a potential weakness and suggests an area for further exploration, but it could be more actionable with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the annotations in the visual event detection stage of the ViStruct Suite might contain noise due to their reliance on an off-the-shelf semantic role labeling system. It implies that a detailed analysis of the curated dataset is needed. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects to focus on. The action is implied and somewhat vague, as the authors are left to infer the necessary steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ViStruct Suite\" and the \"visual event detection stage,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the annotations in the visual event detection stage, noting that they might contain noise due to their reliance on an off-the-shelf semantic role labeling system. The comment suggests a detailed analysis of the curated dataset is needed, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that annotations in the visual event detection stage of the ViStruct Suite might contain noise due to their reliance on an off-the-shelf semantic role labeling system. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the annotations in the visual event detection stage of the ViStruct Suite, noting that they might contain noise due to their reliance on an off-the-shelf semantic role labeling system. This is a relevant observation that could impact the accuracy and reliability of the dataset. However, the comment lacks specific guidance on how to address this issue, such as suggesting methods for noise reduction or a detailed analysis of the dataset. While it points out a potential problem, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model implementation should be better justified, particularly regarding the stopping rule with n consecutive identical samples. It points out that this rule seems arbitrary and lacks discussion on its sensitivity with regard to n. While the comment implies that the authors should provide a more detailed justification or discussion of this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed justification or discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the model implementation and the stopping rule with n consecutive identical samples, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the justification for the stopping rule and the sensitivity with regard to n. This provides clear guidance on what the authors need to improve in their model implementation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the model implementation should be better justified, particularly regarding the stopping rule with n consecutive identical samples. The reviewer questions the arbitrariness of this rule and the lack of discussion on its sensitivity with regard to n. However, the comment does not provide specific examples or references to support the claim that the rule is arbitrary or lacks sensitivity. This makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique and potentially conduct additional analysis to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the model implementation, particularly the stopping rule with n consecutive identical samples. It points out that this rule seems arbitrary and lacks discussion on its sensitivity with regard to n. This feedback is valuable as it highlights a potential weakness in the paper\\'s justification and suggests that the authors should provide a more detailed justification or discussion of this aspect. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar rules have been justified in other works. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues: the lack of time complexity analysis and running time reporting for the proposed method, and the absence of a comparison with state-of-the-art algorithms regarding search time. While the comment identifies these areas for improvement, it does not provide explicit instructions on how to address them. The authors are left to infer that they should include time complexity analysis and running time results, as well as conduct a comparison with existing methods. The suggestion to explore the impact on search time is implicit and lacks concrete guidance on how to conduct this analysis. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the maximum common subgraph detection problem being NP-hard, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of time complexity analysis and running time results for the proposed method, as well as the absence of a comparison with state-of-the-art algorithms regarding search time. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks time complexity analysis and running time results for the proposed method, as well as a comparison with state-of-the-art algorithms regarding search time. While the comment identifies a potential gap in the paper, it does not provide specific examples or references to support the claim that these elements are necessary or how they would impact the paper\\'s conclusions. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of these elements and the potential impact on the paper\\'s conclusions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper. First, it points out the absence of time complexity analysis and running time results for the proposed method, which is a critical aspect of the paper\\'s evaluation. Second, it notes the lack of a comparison with state-of-the-art algorithms regarding search time, despite mentioning the use of heuristics node pair selection policy. This feedback is clear and actionable, as it directs the authors to include these elements in their analysis to strengthen the paper\\'s rigor and comprehensiveness. By addressing these issues, the authors can significantly enhance the quality and credibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of quality control or manual evaluation on the data collected through an automatic model-based approach. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on what specific quality control measures or manual evaluations should be implemented, nor is there any indication of how these might be implemented. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights the absence of quality control or manual evaluation on the data collected through an automatic model-based approach. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of quality control and manual evaluation, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no quality control or manual evaluation on the data collected through an automatic model-based approach. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of quality control or manual evaluation on the data collected through an automatic model-based approach. This is a critical point that could impact the reliability and validity of the results. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue, such as recommending particular quality control measures or manual evaluations. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing a confidence interval from a small development set with the Frechet bound. While it provides a specific suggestion for an additional analysis, it does not explicitly instruct the authors to perform this comparison or explain how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this analysis and determine the best way to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"a small set of labeled data\" and \"snorkel,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comparison between a confidence interval from a small development set and the Frechet bound. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests comparing a confidence interval from a small development set with the Frechet bound. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is relevant or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue related to the availability of labeled data for most tasks and suggests a potential comparison between a confidence interval from a small development set and the Frechet bound. This feedback is somewhat helpful as it points out a relevant aspect of the paper that could be further explored or discussed. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to conduct this comparison or what specific insights it might reveal. While it highlights an area for potential improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is only applicable to problems with low dimensional input spaces, specifically mentioning that the largest dimensionality in the experiments is 3. It attributes this limitation to the curse of dimensionality caused by the use of a finite set of points that cover the region of interest in the surrogate modeling of the shape constraint. While the comment identifies a limitation, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method to accommodate higher dimensional input spaces. The action is implicit and somewhat vague, as the authors can infer that they need to consider dimensionality but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the method is only applicable to problems with low dimensional input spaces, due to the curse of dimensionality caused by the use of a finite set of points that cover the region of interest in the surrogate modeling of the shape constraint. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is only applicable to problems with low dimensional input spaces, specifically mentioning that the largest dimensionality in the experiments is 3. This claim is supported by the explanation that the curse of dimensionality caused by the use of a finite set of points that cover the region of interest in the surrogate modeling of the shape constraint is responsible for this limitation. However, the comment could be strengthened by providing more detailed reasoning or examples to further substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but lacks comprehensive evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the proposed method, noting that it is only applicable to problems with low dimensional input spaces. This is a critical observation, as it highlights a potential weakness in the method's applicability. The comment further explains the reason for this limitation, attributing it to the curse of dimensionality caused by the use of a finite set of points that cover the region of interest in the surrogate modeling of the shape constraint. This feedback is valuable as it points out a specific area where the authors need to improve their method to broaden its applicability. However, the comment could be more helpful if it provided suggestions on how to address this limitation or examples of how other methods have successfully tackled similar issues. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the results of all methods presented in Tables 1 and 2 are within their standard deviations, which undermines the claim that the presented method is significantly better than others. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to improve the claim. The comment lacks actionable details, such as suggesting alternative analyses or presenting evidence to support the claim. As a result, the authors are left without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the results of all methods are within their standard deviations, which undermines the claim that the presented method is significantly better than others. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results of all methods presented in Tables 1 and 2 are within their standard deviations, which undermines the claim that the presented method is significantly better than others. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the results of all methods presented in Tables 1 and 2 are within their standard deviations. This observation challenges the claim that the presented method is significantly better than others, which is a critical aspect of the paper\\'s contribution. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their claims. Without actionable feedback or additional context, the authors are left without a clear path forward. Therefore, the comment is rated as barely helpful, as it points out a potential weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the complexity of generating synthetic tabular data due to factors such as multiple entries in a table being associated with the same entity, leading to additional relationships. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to handle this complexity or suggestions for improving the generation process. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of generating synthetic tabular data, specifically mentioning the common occurrence of multiple entries in a table being associated with the same entity, which leads to additional relationships in the table. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with generating synthetic data, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that generating synthetic tabular data is non-trivial due to factors such as multiple entries in a table being associated with the same entity, leading to additional relationships in the table. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with generating synthetic tabular data, noting that it can be complex due to factors such as multiple entries in a table being associated with the same entity, leading to additional relationships. This feedback highlights a potential challenge in the paper\\'s methodology and suggests that the authors should consider this complexity when designing their experiments. However, the comment does not provide detailed guidance or suggestions on how to address this issue or improve the methodology. While it points out a relevant concern, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper, specifically the overemphasis on the AmbiQT benchmark without broader context or validation on other datasets. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should consider validating their results on other datasets, but it lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the creation of the AmbiQT benchmark and its potential overemphasis without broader context or validation on other datasets. However, it does not specify which part of the paper discusses the AmbiQT benchmark, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this issue is discussed, the comment lacks full grounding. It is specific in pointing out the potential issue of overemphasis and the need for broader context or validation, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the overemphasis on the AmbiQT benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the overemphasis on the AmbiQT benchmark without broader context or validation on other datasets. This is a valuable observation that could lead to questions about the benchmark's applicability and relevance to other scenarios. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets for validation or discussing the implications of focusing solely on the AmbiQT benchmark. While it points out a relevant concern, the feedback lacks actionable steps for the authors to improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for consideration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of annotation training details and guidelines, as well as the lack of information about the tool used. While it identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include these details and provide information about the tool, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the absence of annotation training details and guidelines, as well as the lack of information about the tool used. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what is missing, such as the need for training details and information about the tool. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the absence of annotation training details and guidelines is important, as professional translators often struggle with non-standard tasks. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the claim. Additionally, the mention of the tool used is vague, as it does not specify which tool is being referred to. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of annotation training details and guidelines, as well as the lack of information about the tool used. This is important feedback as it highlights a critical aspect of the paper that could impact its usability and practicality. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending the inclusion of training details or suggesting tools that could be used. While it points out a significant oversight, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the presentation of data in Table 1, specifically questioning whether the values \"EX/NORB\" should be bold-faced and whether the difference between 0.59+/-0.12 is statistically significant compared to 0.58+/-0.11. While the comment implies that the authors should reconsider the presentation of these values, it does not provide explicit instructions on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the presentation of the data. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the presentation of data, specifically whether the values \"EX/NORB\" should be bold-faced and whether the difference between 0.59+/-0.12 is statistically significant compared to 0.58+/-0.11. This provides clear guidance on what needs to be addressed in the table presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions about the presentation of data in Table 1, specifically questioning whether the values \"EX/NORB\" should be bold-faced and whether the difference between 0.59+/-0.12 is statistically significant compared to 0.58+/-0.11. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the presentation of data in Table 1, specifically questioning whether the values \"EX/NORB\" should be bold-faced and whether the difference between 0.59+/-0.12 is statistically significant compared to 0.58+/-0.11. While the comment identifies potential issues with the presentation of data, it does not provide specific guidance or suggestions on how to address these concerns. The feedback is somewhat helpful as it points out areas that need attention, but it lacks actionable advice or detailed reasoning to fully support the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on the metric used for the video level supervision experiment, noting that it does not appear to be using tracklet-based metrics. This is a direct request for information that the authors can easily address by providing details on the metric used. The action is clear and concrete, as the authors know exactly what information is needed to clarify the experiment. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"video level supervision experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the metric used in the experiment and notes that it does not appear to be using tracklet-based metrics. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification about the metric used in the video level supervision experiment. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where clarification is needed, specifically regarding the metric used in the video level supervision experiment. It points out that the paper does not provide details on the metric and suggests that it may not be using tracklet-based metrics. This feedback is clear and actionable, as it directs the authors to provide more information about the metric used in the experiment. By addressing this point, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it suggested alternative metrics or provided additional context on the significance of the metric used. Overall, the comment is mostly helpful as it guides the authors toward improving the transparency and comprehensiveness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of \"person blocking\" on the models, specifically asking for a comment on the potential undesirable learning of person-related features. While the comment implies that the authors should provide an explanation or comment on this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this point. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the impact of \"person blocking\" on the models and suggesting that models might learn person-related features, which is undesirable. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of \"person blocking\" on the models, suggesting that models might learn person-related features, which is undesirable. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the impact of \"person blocking\" on the models, suggesting that models might learn person-related features, which could be undesirable. This prompts the authors to consider whether this effect is a concern and, if so, how to address it. While the comment identifies a potential issue, it lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or mitigate this effect. The feedback is somewhat helpful as it points out a potential area for improvement but could be more actionable with additional details. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the authors have tried a combination of TF-IDF and dense retrieval for evidence sentence extraction. While it implies that the authors should consider this approach, it does not provide explicit instructions or guidance on how to implement it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should explore this combination. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"TF-IDF and dense retrieval,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about whether the authors have tried a specific combination of techniques for evidence sentence extraction. This provides clear guidance on what aspect of the paper needs attention. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking whether the authors have tried a specific combination of techniques for evidence sentence extraction. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about whether the authors have tried a specific combination of techniques for evidence sentence extraction, specifically mentioning TF-IDF and dense retrieval. While it does not provide any guidance or suggestions for improvement, it could prompt the authors to consider this approach or justify why they did not explore it. However, without additional context or explanation, the comment lacks depth and does not offer actionable feedback. Therefore, it is rated as barely helpful, as it provides some insight but not enough to significantly aid the authors in improving their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should mention or provide examples of cases where time-series prediction did not perform well, specifically referencing the COVID-19 dataset. It also asks for examples of countries where predictions were not great and how their trajectories related to the top eigenvectors of the Laplacian. While the comment provides a clear direction for the authors to include these examples, it does not explicitly instruct them on how to present this information or what specific details to include. The action is concrete but somewhat vague in terms of execution, as the authors know what to include but may need to determine the exact format or context for these examples. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper should mention or provide examples of cases where time-series prediction did not perform well, specifically referencing the COVID-19 dataset. It also asks for examples of countries where predictions were not great and how their trajectories related to the top eigenvectors of the Laplacian. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or discussion sections where time-series prediction is discussed. The comment is specific in its request for examples and detailed analysis, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should mention or provide examples of cases where time-series prediction did not perform well, specifically referencing the COVID-19 dataset. The reviewer provides a specific example of the UK and Russia being highly correlated, despite not being neighboring countries, as evidence that the prediction did not perform well. However, the comment lacks detailed reasoning or references to support why this example is relevant or how it relates to the paper\\'s focus. While the example is somewhat illustrative, the lack of detailed justification or broader context makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for the paper, which is to mention or provide examples of cases where time-series prediction did not perform well, specifically referencing the COVID-19 dataset. The reviewer provides a concrete example of the UK and Russia being highly correlated despite not being neighboring countries, which is a clear and actionable point. Additionally, the comment asks for examples of countries where predictions were not great and how their trajectories related to the top eigenvectors of the Laplacian. This feedback is valuable as it encourages the authors to address a potential weakness in their analysis and provide more context for their results. However, the comment could be more helpful if it offered additional guidance on how to present these examples or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides clear and actionable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the claims of proposing a \"learning framework\" are overblown, as it is not a new framework but a modified loss and architecture. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to rephrase the claims or what specific aspects of the framework need clarification. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claims of proposing a \"learning framework\" as overblown, suggesting that it is not a new framework but a modified loss and architecture. However, it does not specify which parts of the paper make these claims or where the authors should address this issue. Without explicit references to sections or specific claims, the authors cannot confidently determine which parts of the paper need revision. The comment is not grounded and lacks specificity, making it difficult for the authors to understand and address the critique. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the claims of proposing a \"learning framework\" are overblown, as it is not a new framework but a modified loss and architecture. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the claims of proposing a \"learning framework\" are overblown, as it is not a new framework but a modified loss and architecture. This feedback is somewhat helpful as it identifies a potential overstatement in the paper\\'s claims, which could be clarified or revised for accuracy. However, the comment lacks specific suggestions on how to address this issue or what aspects of the framework need clarification. While it highlights a potential weakness, it does not provide actionable guidance for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential limitation in the customization of learned prompts for individual transformer-based architectures, such as CLIP and DINOv2, which may not be effective for other model types or slight architectural variations. It suggests that exploring prompts with more universal features or optimizing them independently of the model architecture could improve cross-model generalization. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore universal prompts or model-agnostic prompt optimization. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the learned prompts and their customization for individual transformer-based architectures, such as CLIP and DINOv2. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of customization for individual models, which may limit cross-model generalization. The comment suggests exploring prompts with more universal features or optimizing them independently of the model architecture to improve applicability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the customization of learned prompts for individual transformer-based architectures, such as CLIP and DINOv2, may limit cross-model generalization. It suggests that exploring prompts with more universal features or optimizing them independently of the model architecture could improve applicability. The comment provides a logical reasoning by pointing out the specificity of customization for individual models and the potential need for broader applicability. However, it lacks specific examples or references to support the claim that customization limits cross-model generalization. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the customization of learned prompts for individual transformer-based architectures, such as CLIP and DINOv2, which may not be effective for other model types or slight architectural variations. It suggests that exploring prompts with more universal features or optimizing them independently of the model architecture could improve cross-model generalization. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for the authors to consider. However, the comment could be more helpful if it offered specific suggestions or examples of how to implement these changes or how to evaluate the impact of universal prompts. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of baselines in the paper and raises a concern about the model architecture being outdated. It suggests that without comparisons to other models, there is no evidence of the current methodology being more effective or novel for fMRI forecasting. The reviewer provides a specific suggestion to consider using advanced time-series forecasting models available in the \"Time-Series Library\" repository as potential baselines for evaluation. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft. The action is clear and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the absence of baselines in the paper and raises a concern about the model architecture being outdated. It suggests that without comparisons to other models, there is no evidence of the current methodology being more effective or novel for fMRI forecasting compared to contemporary time-series forecasting architectures. The comment provides a specific suggestion to consider using advanced time-series forecasting models available in the \"Time-Series Library\" repository as potential baselines for evaluation. This explicit mention of the repository provides full grounding, as the authors can easily identify the specific part of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed regarding the baselines and model architecture. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absence of baselines in the paper raises a concern about the model architecture being outdated and suggests that without comparisons to other models, there is no evidence of the current methodology being more effective or novel for fMRI forecasting compared to contemporary time-series forecasting architectures. The reviewer provides a specific suggestion to consider using advanced time-series forecasting models available in the \"Time-Series Library\" repository as potential baselines for evaluation. This suggestion is based on logical reasoning and common knowledge about the availability of such models, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific models in the repository. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting the absence of baselines and suggesting that the model architecture used appears outdated. It highlights the need for comparisons to other models to demonstrate the effectiveness and novelty of the current methodology for fMRI forecasting. The comment provides a specific suggestion to consider using advanced time-series forecasting models available in the \"Time-Series Library\" repository as potential baselines for evaluation. This feedback is clear and actionable, guiding the authors to address a critical gap in their work. However, it could be more helpful if it provided additional guidance on how to select and apply these models. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be further enhanced with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include at least one strong baseline in one of the tasks, implying that the current inclusion of only standard MLPs is insufficient. However, it does not provide specific guidance on which task should include the additional baseline or how to select a strong baseline. The action is implicit and somewhat vague, as the authors can infer that they need to add a stronger baseline but may not be entirely sure how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include at least one strong baseline in one of the tasks, indicating that the current inclusion of only standard MLPs is insufficient. However, it does not specify which task or which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for a stronger baseline, but without clear grounding, the authors may struggle to identify the exact area that needs improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include at least one strong baseline in one of the tasks, implying that the current inclusion of only standard MLPs is insufficient. However, the comment does not provide any specific reasoning or evidence to support why a stronger baseline is necessary or how it would enhance the paper. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the only baselines presented are standard MLPs. While it acknowledges that this is a theoretical work, it suggests that the inclusion of at least one strong baseline in one of the tasks would enhance the paper. This feedback is somewhat helpful as it highlights an area for improvement, but it lacks specific guidance on which tasks should include a stronger baseline or how to select one. The authors are given a general direction but may need to infer the details of implementation. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to more clearly compare their proposed method to the two prior works mentioned, and to include them in the tables of experimental results. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the two prior works cited by the authors, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for a clearer comparison of the proposed method to the prior works and their inclusion in the tables of experimental results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is similar to two prior works cited by the authors. However, it does not provide specific details or examples from the prior works to substantiate this claim. The comment suggests that the paper should more clearly compare the proposed method to these prior works and include them in the tables of experimental results. While the suggestion is logical, the lack of specific references or detailed reasoning makes the claim somewhat verifiable. The authors would need to make a significant effort to verify the claim themselves by reviewing the prior works and incorporating them into their analysis. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the proposed method is similar to two prior works cited by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them in the tables of experimental results. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improvement. By addressing this point, the authors can enhance the originality and comprehensiveness of their work. However, the comment could be more helpful if it included specific examples or guidance on how to effectively compare the methods. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors\\' claim about the lack of visualization systems for interpretable reinforcement learning is unclear because the broader goals identified are not specified. However, it does not provide any guidance on how the authors should clarify these goals or what specific aspects of the visualization systems should be addressed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the lack of visualization systems for interpretable reinforcement learning, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what the broader goals are that have been identified, making it under-specific. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that there is a lack of visualization systems for interpretable reinforcement learning that effectively address the broader goals identified. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific claim about the lack of visualization systems for interpretable reinforcement learning that effectively address the broader goals identified. However, it points out that the broader goals themselves are not clearly defined, making it difficult for the authors to evaluate the claim. While the comment highlights an area for improvement, it does not provide any suggestions or guidance on how the authors might clarify or address the broader goals. This limits the comment\\'s usefulness in helping the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but lacks actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the independence of AAL and SLS and questions whether applying them separately still provides a stable improvement. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps the authors should consider to validate the stability of the improvements. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table (1-4),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the independence of AAL and SLS and whether applying them separately still provides a stable improvement. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the independence of AAL and SLS and whether applying them separately still provides a stable improvement. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the independence of AAL and SLS and questions whether applying them separately still provides a stable improvement. While it identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern. The comment could be more helpful if it offered insights into how the authors might validate the stability of the improvements or suggested ways to integrate AAL and SLS more effectively. As it stands, the comment provides some direction but does not fully support the authors in improving their draft. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be expanded to explore the effects on different tasks and utilize multiple datasets for the same task. This feedback provides a clear and explicit action for the authors to take, which is to broaden the scope of their experiments by including additional tasks and datasets. The comment is specific in detailing what needs to be done to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"limited task and dataset\" and the specific tasks and datasets involved, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need to explore the effects on different tasks and utilize multiple datasets for the same task, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experiments are limited to only one task and dataset, namely sentiment classification and SST2. The comment recommends exploring the effects on different tasks or utilizing multiple datasets for the same task to gain deeper insights. While the suggestion is logical and reasonable, it lacks specific examples or references to support the claim that these changes would significantly enhance the insights gained. This makes the claim somewhat verifiable, as it provides a clear direction but requires more detailed justification to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, specifically the narrow focus on sentiment classification and the SST2 dataset. It suggests that exploring the effects on different tasks or utilizing multiple datasets for the same task could provide deeper insights. This feedback is clear and actionable, as it directs the authors to broaden the scope of their experiments to enhance the depth and generalizability of their findings. However, the comment could be more helpful if it provided specific examples of tasks or datasets that could be considered, or if it detailed how this broader scope might impact the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the experimental design, specifically asking whether the heat equation, damped wave, and Navier-Stokes are simulated or based on real-world data. It suggests that simulated data would be easier to fit. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their experimental design. The action is implicit and somewhat vague, as the authors can infer that they need to clarify their experimental setup but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Heat Equation: Damped Wave: Navier-Stokes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the experimental design, suggesting that simulated data might be easier to fit and implies that the current experimental setup might be problematic. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the experimental design, specifically asking whether the heat equation, damped wave, and Navier-Stokes are simulated or based on real-world data. The comment suggests that simulated data would be easier to fit, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the experimental design, specifically asking whether the heat equation, damped wave, and Navier-Stokes are simulated or based on real-world data. It suggests that simulated data might be easier to fit, which could be a valid point for consideration. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve their experimental design. While it identifies a potential issue, it does not offer actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests the inclusion of a dedicated image quality metric, such as inter-class or intra-class Frechet Inception Distance (FID), to enhance the comprehensiveness of the evaluation and comparison between different models. This is a clear and concrete action for the authors to take, as it provides a specific metric to consider and a rationale for its inclusion. The comment is highly actionable because it directly instructs the authors on how to improve their draft by adding a new evaluation metric.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of a dedicated image quality metric for evaluating the performance of image generation models. This allows the authors to accurately identify the part of the paper being addressed, which is the evaluation section. The comment is also specific because it suggests the inclusion of a specific metric, such as inter-class or intra-class Frechet Inception Distance (FID), to enhance the comprehensiveness of the evaluation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the absence of a dedicated image quality metric for evaluating the performance of image generation models is a limitation. It proposes the inclusion of metrics like inter-class or intra-class Frechet Inception Distance (FID) as a means to enhance the comprehensiveness of the evaluation. While the comment provides a logical reasoning for the need of such metrics, it lacks specific examples or references to support the claim that these metrics would significantly improve the evaluation. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and implement the suggested metrics.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests the inclusion of metrics like inter-class or intra-class Frechet Inception Distance (FID) to enhance the comprehensiveness of the evaluation and comparison between different models. This feedback is clear and actionable, as it provides a specific and meaningful suggestion for improvement. By addressing this limitation, the authors can significantly enhance the rigor and comprehensiveness of their evaluation, which is valuable guidance for improving the draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the potential applicability of the mechanism in vision transformers. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should explore this possibility, conduct additional research, or provide a specific analysis. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses. It is a question asking about the potential applicability of a mechanism in vision transformers, but it does not provide any context or reference to a specific section, figure, or discussion in the paper. As a result, the authors cannot confidently determine which part of the paper this comment pertains to, making it not grounded. Additionally, the comment is not specific as it does not provide details on what aspect of the mechanism is being questioned or how it could be applied in vision transformers. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking about the potential applicability of a mechanism in vision transformers. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment poses a question about the potential applicability of a mechanism in vision transformers, which could be a relevant area for exploration. However, it lacks depth and does not provide any context or explanation for why this question is relevant or how it could be addressed. Without additional information or guidance, the authors may find it challenging to understand the significance of this inquiry or how to incorporate it into their work. Therefore, the comment is somewhat helpful as it points out a potential area for exploration but does not offer actionable advice or detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the superiority of the precision of IMLE compared to the proposed Adaptive IMLE and inquires if the authors have applied the method to different domains. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or experiment to address these questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the superiority of the precision of IMLE compared to the proposed Adaptive IMLE and inquires if the authors have applied the method to different domains. However, it does not specify which part of the paper these questions pertain to, such as a specific section or table where the comparison is discussed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its inquiry about the method's application to different domains, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the superiority of the precision of IMLE compared to the proposed Adaptive IMLE and inquires if the authors have applied the method to different domains. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the superiority of the precision of IMLE compared to the proposed Adaptive IMLE and inquires if the authors have applied the method to different domains. This feedback prompts the authors to consider the limitations and potential advantages of their method in comparison to others. However, the comment lacks specific guidance or suggestions on how to address these questions or improve the paper. While it points out areas for further exploration, it does not provide actionable steps or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results are lacking, specifically questioning whether all the modules are necessary. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks actionable details, such as recommending specific modifications or additional experiments to justify the necessity of each module. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether all the modules are necessary, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of all the modules in the experimental results. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experimental results, specifically questioning whether all the modules are necessary. This is a relevant point that could impact the validity and reliability of the results. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or what modifications could be made to improve the experimental design. Without actionable suggestions or detailed feedback, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider exploring the behavior of their network with more layers, specifically 32 and 64, as it is known that many GNNs tend to oversmooth as more layers are added. While the comment implies that the authors should conduct additional experiments with these additional layers, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these experiments to address the issue of oversmoothing. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the consideration of a few number of layers, up to 8 layers, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue of oversmoothing as more layers are added, suggesting that the authors should explore the behavior of their network with more layers like 32 and 64. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider exploring the behavior of their network with more layers, specifically 32 and 64, as it is known that many GNNs tend to oversmooth as more layers are added. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the number of layers used in the network, suggesting that the authors should consider exploring the behavior of their network with more layers, specifically 32 and 64. This feedback is somewhat helpful as it points out a potential limitation in the current setup and provides a direction for further investigation. However, the comment lacks specific guidance on how to implement this exploration or what specific aspects of the network behavior should be examined. To be more helpful, the comment could provide suggestions on how to conduct these experiments, what metrics to use, or how to interpret the results. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to perform significance tests to ensure the reliability of their experimental results. This is a clear and direct action that the authors can take to address the issue of limited improvement of MT over ST. The comment provides a specific suggestion for improving the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the improvement of MT over ST, suggesting that the authors should perform significance tests to ensure the reliability of their experimental results. However, it does not specify which part of the paper discusses the improvement of MT over ST, making it weakly grounded. The comment is specific in suggesting the need for significance tests, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement of MT over ST is limited and suggests that the authors should perform significance tests to ensure the reliability of their experimental results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the limited improvement of MT over ST. It suggests that the authors should perform significance tests to ensure the reliability of their experimental results. This feedback is clear and actionable, as it provides a direct suggestion for improving the paper by addressing a potential weakness in the experimental design. However, the comment could be more helpful if it explained why significance tests are necessary or how they could be conducted effectively. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement that could enhance the reliability and robustness of their findings.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the authors\\' claim that their framework is model-agnostic, as it is only evaluated under different GCN architectures. The reviewer raises a question about how the framework would perform on different GNN blocks, specifically mentioning GAT, GraphSAGE, GIN, Geniepath, and others that employ LSTM-like aggregation. This feedback implies that the authors should conduct additional evaluations to address this concern. However, it does not provide explicit instructions on how to conduct these evaluations or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the authors\\' claim that the framework is model-agnostic, as it is only evaluated under different GCN architectures. The comment further raises a question about how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' claim that their framework is model-agnostic, as it is only evaluated under different GCN architectures. The reviewer suggests that the framework should be tested on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, which employ LSTM-like aggregation. This claim is somewhat verifiable as it points out a potential limitation in the evaluation process and suggests a direction for further exploration. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the authors\\' claim that their framework is model-agnostic, as it is only evaluated under different GCN architectures. It raises a valid point by questioning how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, which employ LSTM-like aggregation. This feedback is valuable as it prompts the authors to consider a broader range of models for evaluation, which could enhance the robustness and generalizability of their framework. However, the comment could be more helpful if it provided specific suggestions on how to conduct these additional evaluations or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the complexity of the method and suggests that an error analysis should be conducted to understand how the approach would perform if one of its components, such as GPT-4o, misses details. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an error analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the complexity of the method and suggests an error analysis to understand how the approach would perform if one of its components, such as GPT-4o, misses details. However, it does not specify which part of the paper this analysis should be conducted in, nor does it provide detailed guidance on what specific aspects of the method should be analyzed. While the authors might have an idea of where this analysis should be conducted, the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the complexity of the method and suggests that an error analysis should be conducted to understand how the approach would perform if one of its components, such as GPT-4o, misses details. However, the comment lacks specific examples or detailed reasoning to support the claim that an error analysis is necessary. Without such evidence or references, the authors may find it challenging to fully understand the basis of the suggestion. Therefore, the claim is considered borderline verifiable, as it provides some rationale but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the complexity of the method and suggests that an error analysis should be conducted to understand how the approach would perform if one of its components, such as GPT-4o, misses details. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for the authors to explore. However, the comment lacks depth and does not offer detailed guidance on how to conduct the error analysis or what specific aspects to focus on. While it highlights an important area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the practicality of the reversible version due to its higher computational cost during training. It suggests that the authors should consider whether this cost is justified given the cheapness of memory. Additionally, the comment recommends including perplexity/BLEU scores to verify the necessity of the gating mechanism. While the action is implicit, it is clear that the authors need to consider the computational cost and include additional metrics to verify the gating mechanism. The comment provides concrete suggestions for improvement, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the computational cost during training, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of the reversible version being slower and questions the practicality of the approach. Additionally, it suggests including perplexity/BLEU scores to verify the necessity of the gating mechanism. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reversible version of the model is slower due to its computational cost during training, which is acknowledged in the paper. The reviewer questions the practicality of this approach given the cheapness of memory. However, the comment does not provide specific examples or detailed reasoning to support this claim, such as comparisons with other models or detailed calculations. This lack of supporting evidence makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the practicality of the reversible version of the model due to its higher computational cost during training. It questions whether this cost is justified given the cheapness of memory. This feedback is valuable as it prompts the authors to consider the trade-offs between computational cost and memory usage, which is an important aspect of the model\\'s practicality. Additionally, the comment suggests including perplexity/BLEU scores to verify the necessity of the gating mechanism, which is a constructive suggestion that could help the authors validate their approach. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to implement these suggestions. Overall, the comment is mostly helpful as it highlights important considerations for the authors to address in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of an error analysis, which is a critical component for understanding the limitations of SetCSE in certain scenarios. This feedback provides a clear and direct action for the authors to include an error analysis in their draft. The comment is specific in identifying what is missing and how it could be addressed, making it highly actionable. Authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of an error analysis, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of an error analysis to understand the limitations of SetCSE in certain scenarios. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an error analysis is missing, which would be beneficial in understanding the limitations of SetCSE in certain scenarios. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why an error analysis is necessary or how it would enhance the understanding of SetCSE. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the absence of an error analysis to understand the limitations of SetCSE in certain scenarios. This is a critical point that could significantly impact the comprehensiveness and robustness of the paper. By pointing out this omission, the comment provides the authors with a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct an error analysis or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about measuring tool-knowledge using prompting and suggests that a bit of unintentional fine-tuning might recover the tool-knowledge in a scenario where model weights are shared. It also mentions the possibility of using other prompts to elicit the model\\'s ability to use a tool. While the comment implies that the authors should consider alternative methods for measuring tool-knowledge, it does not provide explicit instructions or concrete suggestions on how to implement these alternatives. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about measuring tool-knowledge using prompting and suggests that a bit of unintentional fine-tuning might recover the tool-knowledge in a scenario where model weights are shared. It also mentions the possibility of using other prompts to elicit the model\\'s ability to use a tool. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to consider alternative methods for measuring tool-knowledge, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about measuring tool-knowledge using prompting and suggests that a bit of unintentional fine-tuning might recover the tool-knowledge in a scenario where model weights are shared. The comment also mentions the possibility of using other prompts to elicit the model\\'s ability to use a tool. While the suggestion is logical and provides a plausible explanation, it lacks specific examples or references to support the claim. The authors would need to make a significant effort to understand and address the issue, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the method used to measure tool-knowledge, suggesting that prompting might not be sufficient and that unintentional fine-tuning or other prompts might be more effective. This is a valuable observation that could lead to a more robust and accurate assessment of the tool-knowledge. However, the comment lacks specific suggestions or guidance on how to implement these alternative methods or what prompts might be effective. While it identifies a potential weakness, it does not provide actionable steps for the authors to address it. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a detailed critique of the experimental results, suggesting that the improvement of HA3C over the baseline algorithms on MuJoCo control tasks is marginal and that the algorithm may not be effective in this environment. The reviewer provides a rationale for this claim, explaining that the complexity of the causal relationship based on the current state may be challenging for HA3C, while the causal relationship based on history could be simpler. The reviewer also suggests that the authors should explore other tasks or even artificial tasks to demonstrate the effectiveness of HA3C. This feedback is explicit and provides concrete suggestions for the authors to address the critique by exploring alternative environments or tasks. The action is clear and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental results and the improvement of HA3C over the baseline algorithms on MuJoCo control tasks. It also specifies the issue with the marginal improvement and provides a rationale for why this may not indicate ineffectiveness. The comment suggests finding other tasks or artificial tasks to demonstrate the effectiveness of HA3C. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the improvement of HA3C over the baseline algorithms on MuJoCo control tasks is marginal, suggesting that this does not indicate ineffectiveness. The reviewer provides a rationale based on the complexity of the causal relationship based on the current state versus the history, which could affect the performance of HA3C. However, the comment lacks specific examples or references to support the claim that MuJoCo tasks may not be suitable for HA3C. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the experimental results, suggesting that the improvement of HA3C over the baseline algorithms on MuJoCo control tasks is marginal and that the algorithm may not be effective in this environment. The reviewer provides a rationale for this claim, explaining that the complexity of the causal relationship based on the current state may be challenging for HA3C, while the causal relationship based on history could be simpler. This reasoning is logical and provides a clear direction for the authors to explore alternative tasks or even artificial tasks to demonstrate the effectiveness of HA3C. The comment is mostly helpful as it offers actionable suggestions for improvement, making it somewhat helpful. However, it could be more helpful if it provided specific examples or guidance on which tasks or artificial tasks might be suitable for HA3C. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of focus on the insights derived from the data, which is a key aspect of the paper. It suggests that the authors should focus on presenting key takeaways and insights from their experiments that are generalizable and hold broader significance for the community. While the comment implies that the authors should provide more detailed analysis and interpretation of their results, it does not specify exactly what insights or takeaways should be included. The action is implicit and somewhat vague, as the authors need to infer the exact details of what is expected. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"key contributions\" and \"insights derived from the data,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper does not fully address the insights derived from the data, and it suggests that the authors should present key takeaways and insights that are generalizable and hold broader significance for the community. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not fully address the insights derived from the data, which is a key aspect of the paper. The reviewer suggests that the authors should focus on presenting key takeaways and insights that are generalizable and hold broader significance for the community. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the exact insights or takeaways that should be included, which could be challenging without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting that the novelty does not lie in the dataset itself but rather in the insights derived from the data. It suggests that the paper should focus on presenting key takeaways and insights from the experiments that are generalizable and hold broader significance for the community. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by highlighting the importance of the insights derived from the data. However, the comment could be more helpful if it offered specific examples or suggestions on what kind of insights or takeaways would be valuable. Overall, the comment is mostly helpful as it guides the authors toward a more impactful and meaningful presentation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the claim in Section 3.1 about GAN being the de facto choice for vocoders is false and ignores a large array of active and important works in the community. It suggests that other popular vocoder choices like WaveNet, WaveRnn, and diffusion-based approaches should be considered instead. This provides a clear and concrete action for the authors to take, which is to revise the claim and include these alternative choices. The comment is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the claim about GAN being the de facto choice for vocoders, pointing out that it ignores a large array of active and important works in the community. The comment suggests alternative vocoder choices like WaveNet, WaveRnn, and diffusion-based approaches. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement in Section 3.1 about GAN being the de facto choice for vocoders is false and ignores a large array of active and important works in the community. The reviewer provides a logical reasoning by suggesting that other popular vocoder choices like WaveNet, WaveRnn, and diffusion-based approaches should be considered instead. However, the comment lacks specific examples or references to these alternative works, which would strengthen the claim. As it stands, the comment provides a somewhat verifiable basis for the claim, as it highlights a potential issue but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a false claim in Section 3.1 about GAN being the de facto choice for vocoders, noting that it ignores a large array of active and important works in the community. It suggests that other popular vocoder choices like WaveNet, WaveRnn, and diffusion-based approaches should be considered instead. This feedback is clear and actionable, as it points out a specific inaccuracy in the paper and provides concrete suggestions for improvement. By addressing these issues, the authors can enhance the accuracy and comprehensiveness of their work. However, the comment could be more helpful if it provided examples or references to these alternative works, which would further substantiate the claim. Overall, the comment is mostly helpful as it effectively guides the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the approach contains design choices that are not fully explained or empirically justified, specifically mentioning the choice of token similarity metric. However, it does not provide specific guidance on how to address this issue or what aspects of the design choices need further explanation or justification. The comment implies that the authors should provide more detailed explanations or evidence to support their design choices, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the approach and its design choices, specifically mentioning the choice of token similarity metric. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of unexplained or unjustified design choices, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach contains design choices that are not fully explained or empirically justified, specifically mentioning the choice of token similarity metric. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approach, noting that while it is straightforward and sensible, it contains design choices that are not fully explained or empirically justified, including the choice of token similarity metric. This feedback is somewhat helpful as it points out a potential weakness in the paper that the authors should address. However, the comment lacks specific suggestions or guidance on how to improve the explanation or justification of these design choices, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, as it provides insight but could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific inconsistencies in the notation, such as the absence of \"j\" on the right-hand side (RHS) of Equation (6) and the presence of \"T\" and \"W\" on the left-hand side (LHS) of Equation (4). While the comment points out these inconsistencies, it does not provide explicit guidance on how to address them. The authors are left to infer that they should correct these inconsistencies, but the comment lacks concrete details on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations, \"Equation (4)\" and \"Equation (6),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the notation, noting the presence of \"T\" and \"W\" on the left-hand side (LHS) of Equation (4) and the absence of \"j\" on the right-hand side (RHS) of Equation (6). This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific inconsistencies in the notation, such as the presence of \"T\" and \"W\" on the left-hand side (LHS) of Equation (4) and the absence of \"j\" on the right-hand side (RHS) of Equation (6). This claim is somewhat verifiable as it points out specific discrepancies in the notation, which can be easily verified by the authors. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific inconsistencies in the notation, particularly in Equation (4) and Equation (6), noting the presence of \"T\" and \"W\" on the left-hand side (LHS) of Equation (4) and the absence of \"j\" on the right-hand side (RHS) of Equation (6). This feedback is clear and actionable, as it directs the authors to correct these inconsistencies in their notation. However, the comment could be more helpful if it provided suggestions on how to standardize the notation across equations or explained why these inconsistencies are important to address. Overall, the comment is mostly helpful as it effectively points out a specific issue that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the evaluation section of the paper. It points out that the number of models constructed during the evaluations is insufficient to demonstrate the effectiveness of the approach. Additionally, it notes the lack of evaluation regarding the distortion of the image after the warping and the absence of discussion on potential countermeasures against the proposed approach. While the comment highlights areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand their evaluation and include more models, discuss distortion, and consider countermeasures. However, the lack of concrete suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the insufficient number of models constructed and the lack of evaluation regarding the distortion of the image after the warping. Additionally, it points out the absence of discussion on potential countermeasures against the proposed approach. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is insufficient, as it involves constructing less than 20 models during the evaluations, which is not enough to demonstrate the effectiveness of the approach. It also notes the lack of evaluation regarding the distortion of the image after the warping and the absence of discussion on potential countermeasures against the proposed approach. While the comment identifies specific issues with the evaluation, it does not provide detailed reasoning or examples to support why these aspects are insufficient. This makes the claim somewhat verifiable, as the authors would need to infer the importance of these points and potentially conduct additional evaluations themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several critical issues with the evaluation section of the paper. It points out that the number of models constructed during the evaluations is insufficient to demonstrate the effectiveness of the approach, and it notes the lack of evaluation regarding the distortion of the image after the warping. Additionally, it highlights the absence of discussion on potential countermeasures against the proposed approach. This feedback is clear and actionable, as it directs the authors to expand their evaluation and include more models, address distortion, and consider countermeasures. However, the comment could be more helpful if it provided specific suggestions on how to conduct these evaluations or what aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward improving the evaluation section of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the table (A3) should separate discourse particles from imported vocabulary, and it recommends using separate tables for each. Additionally, it suggests that glosses would be helpful. This feedback provides clear and concrete actions for the authors to take, such as separating the data into different tables and including glosses. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the separation of discourse particles from imported vocabulary and the suggestion to include glosses. This provides clear guidance on how to improve the table and its presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table A3 should separate discourse particles from imported vocabulary and recommends using separate tables for each. It also suggests that glosses would be helpful. While the comment provides a logical suggestion for improving the presentation of the table, it lacks specific examples or references to support the claim that glosses would be beneficial. The suggestion is somewhat verifiable, as it provides a clear direction for improvement but could be strengthened with additional evidence or reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the presentation of Table A3. It suggests that the table should separate discourse particles from imported vocabulary, which is a clear and logical suggestion for improving the clarity and organization of the table. Additionally, it recommends using separate tables for each, which would make the table more manageable and easier to understand. The comment also suggests including glosses, which could help clarify the terminology used in the table. This feedback is highly helpful as it provides concrete steps for the authors to take to improve the clarity and usability of their table. By addressing these points, the authors can enhance the readability and comprehensibility of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the idea behind formula (4) and questions the need for the maximum over all possible pieces for unoccupied squares. However, it does not provide any explicit guidance or suggestions on how the authors might clarify or address this issue. The comment lacks actionable details, such as recommending specific explanations or alternative approaches to consider. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"formula (4),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the need for the maximum over all possible pieces for unoccupied squares, providing clear guidance on what needs to be clarified or addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the need for the maximum over all possible pieces for unoccupied squares in formula (4). However, it does not provide any reasoning or explanation for why this is unclear or problematic. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about the idea behind formula (4) and questions the need for the maximum over all possible pieces for unoccupied squares. While it identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might clarify or address this issue. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the experiments lack a comparison to state-of-the-art subset selection methods. This is a clear and direct action for the authors to take, as it highlights a specific area where the paper could be improved by including such a comparison. The comment provides a concrete suggestion for enhancing the experimental analysis, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the experiments, indicating that it pertains to a specific part of the paper. However, it does not specify which subset selection methods should be compared, leaving the authors to infer which methods are relevant. While the comment identifies a specific area for improvement, it lacks specificity in terms of which methods to compare and how to conduct the comparison. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments lack a comparison to state-of-the-art subset selection methods. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of comparison to state-of-the-art subset selection methods. This feedback is clear and actionable, as it directs the authors to include a comparison that could enhance the experimental analysis and validate their findings. However, the comment could be more helpful if it provided examples of specific methods to compare against or suggested ways to conduct the comparison. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is vague and needs to be more concise. It mentions that the primary components integrate effective elements of previous works, such as SCL, Aligned, and CLNN, among others. However, it does not provide specific guidance on how to improve the clarity or concision of the novelty section. The authors are left to infer that they need to make their novelty more explicit and possibly provide examples of how these elements are integrated. While the comment identifies an area for improvement, it lacks concrete instructions on how to achieve it, making the action implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the paper is vague and needs to be more concise. It mentions that the primary components integrate effective elements of previous works, including SCL, Aligned, and CLNN, among others. However, it does not specify which part of the paper this issue pertains to, such as the introduction, results, or discussion sections. The authors can infer that it relates to the novelty section, but this inference is not direct. The comment is specific in identifying the need for more clarity on the novelty aspect, but it lacks full grounding as it does not explicitly mention the section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is vague and needs to be more concise. It mentions that the primary components integrate effective elements of previous works, such as SCL, Aligned, and CLNN, among others. However, the comment does not provide specific examples or references to these works, nor does it explain how these elements are integrated or how they contribute to the novelty of the paper. Without detailed justification or examples, the claim lacks sufficient verification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the paper, suggesting that it is vague and needs to be more concise. It mentions that the primary components integrate effective elements of previous works, such as SCL, Aligned, and CLNN, among others. However, the comment lacks specific guidance on how to improve the clarity or concision of the novelty section. It does not provide examples or suggestions on how to differentiate the paper from existing works or how to present the novelty more effectively. While it points out a potential weakness, the feedback is incomplete and does not offer actionable steps for the authors to address it. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests using evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This implies that the authors should include such benchmarks in their paper to enhance its usability and accessibility to the community. While the action is implied, it is clear and concrete, as it specifies the need for including these benchmarks. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests using evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where these benchmarks could be included. The authors can infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in suggesting the inclusion of evaluation benchmarks, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. However, it does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the community. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests using evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of benchmarks that could enhance the usability and accessibility of the paper to the community. However, the comment lacks specific guidance on how to implement this suggestion or what specific benchmarks should be used. While it points out a potential improvement, it does not provide detailed instructions or examples, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the impact should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a particular section, figure, or experiment. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the impact should be explored or how it could be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the impact of open-set detectors on the performance of the proposed method. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the impact of open-set detectors on the performance of the proposed method. While it identifies an area for further exploration, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the impact should be considered. Without actionable feedback or direction, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific issues: the use of a star (\\*) next to \"oracle goals\" in Table 1 and the reporting of \"from-scratch\" as a setting in Table 5. The reviewer questions whether the explanation of the symbol is missing and seeks clarification on whether the model was randomly initialized or pre-trained on a text corpus. The comment is explicit in its request for clarification, providing clear guidance on what the authors need to address. However, it does not specify how to implement the clarification or fix, leaving some room for interpretation. Therefore, the comment is mostly actionable, as it provides a clear direction for the authors to take but lacks detailed instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of a star (\\*) next to \"oracle goals\" in Table 1 and the reporting of \"from-scratch\" as a setting in Table 5. The comment provides detailed questions about the explanation of the symbol and the model initialization, which helps the authors understand what needs to be clarified or corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the use of a star (\\*) next to \"oracle goals\" in Table 1 and the reporting of \"from-scratch\" as a setting in Table 5. The reviewer seeks clarification on whether the model was randomly initialized or pre-trained on a text corpus, based on the text. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the inquiry or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues in the paper, namely the use of a star (\\*) next to \"oracle goals\" in Table 1 and the reporting of \"from-scratch\" as a setting in Table 5. It raises questions about the explanation of these symbols and whether the model was randomly initialized or pre-trained on a text corpus, based on the text. The comment is mostly helpful as it provides clear and actionable feedback by asking the authors to clarify or fix these issues. However, it could be more helpful if it offered suggestions on how to address these questions or provided examples of how similar issues have been handled in similar contexts. Overall, the comment is mostly helpful as it directs the authors to important areas for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the results presented in Table 1, suggesting that the observed increase in transferability with higher noise intensity might be due to different neurons being activated to reduce confidence in source samples, leading to increased misclassification. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their results. The comment lacks actionable details, such as recommending specific analyses or experiments to validate the observed trends. As a result, the authors are left without clear direction on how to respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the results presented in the table, suggesting that the observed increase in transferability with higher noise intensity might be due to different neurons being activated to reduce confidence in source samples, leading to increased misclassification. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the results presented in Table 1, suggesting that the observed increase in transferability with higher noise intensity might be due to different neurons being activated to reduce confidence in source samples, leading to increased misclassification. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not provide references or examples to substantiate the argument, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered borderline verifiable, as it requires more detailed justification to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment questions the results presented in Table 1, suggesting that the observed increase in transferability with higher noise intensity might be due to different neurons being activated to reduce confidence in source samples, leading to increased misclassification. While the comment identifies a potential issue with the results, it lacks specific suggestions or guidance on how the authors might address this concern or improve their analysis. The feedback is somewhat helpful as it points out a potential weakness in the results but does not provide actionable steps for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding ablation studies with importance weighting or rejection to understand their effects better. It also points out that the fonts in the figures are too small to read and provides specific feedback on Fig. 6 (a), noting that the results seem a bit weird and questions whether the reward becomes large quickly but decreases along the training. The comment requests an explanation in the paragraph. While the suggestion to include ablation studies is explicit, the comment lacks concrete guidance on how to implement them or what specific aspects to focus on. The feedback on the font size and the results in Fig. 6 (a) is more vague, as it does not provide detailed instructions on how to address these issues. Overall, the comment is somewhat actionable, as it provides a clear suggestion for adding ablation studies but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig. 6 (a)\" and \"the fonts in the figures,\" allowing the authors to accurately identify the areas being addressed. It also specifies the issues with the ablation studies, the font size, and the results in Fig. 6 (a), providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that adding ablation studies with importance weighting or rejection would help understand their effects better. However, it does not provide any evidence or reasoning to support why these studies are necessary or how they would improve the understanding of the effects. The comment also mentions the font size issue and the results in Fig. 6 (a), but it does not provide specific examples or detailed reasoning to support these observations. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the importance of the suggested studies and address the font size issue themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several pieces of feedback that can help the authors improve their draft. First, it suggests adding ablation studies with importance weighting or rejection to better understand the effects of these methods. This is a clear and actionable suggestion that can enhance the paper\\'s analysis and provide valuable insights. Second, it points out that the fonts in the figures are too small to read, which is a practical issue that the authors should address. Finally, it questions the results in Fig. 6 (a), noting that the reward seems to become large quickly but decreases along the training. This feedback prompts the authors to explain the behavior of the reward in more detail, which could help clarify the results and improve the paper\\'s clarity. Overall, the comment is mostly helpful as it offers actionable suggestions and constructive feedback that can significantly enhance the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of technical clarity in the paper, specifically regarding the main learning framework Equantion (18) and how to implement the balancing and penalty terms. While the comment highlights areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take to improve the technical clarity. The authors are left to infer that they need to provide more detailed explanations or examples, but without specific guidance, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the main learning framework \"Equantion (18)\" and the terms \"balancing term\" and \"penalty term,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation for these terms and how they are implemented. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical clarity is weak, specifically mentioning the main learning framework \"Equantion (18)\" and the need for clarification on how to implement the balancing and penalty terms. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the technical clarity of the paper, specifically regarding the main learning framework \"Equantion (18)\" and the implementation of the balancing and penalty terms. This feedback is clear and actionable, as it points out specific areas where the authors need to provide more detailed explanations or examples to improve the technical clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar concepts have been explained in other works. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the decision boundary generation process, noting that the projection results and Voronoi tessellations appear to be fixed across multiple rounds. It suggests that the authors clarify how these fixed tessellations capture the model's behavior and the impact of using 2D projections to represent high-dimensional decision boundaries. The comment provides a clear direction for the authors to address these concerns by explaining the behavior of the model and the limitations of using 2D projections. The explicit nature of the action and the concrete suggestions for improvement make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"figures\" and \"Voronoi tesselation results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the concerns about the decision boundary generation process, including the need to clarify how the fixed tessellations capture the model's behavior and the limitations of using 2D projections to represent high-dimensional decision boundaries. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the decision boundary generation process, noting that the projection results and Voronoi tessellations appear to be fixed across multiple rounds. It suggests that the authors clarify how these fixed tessellations capture the model's behavior and the impact of using 2D projections to represent high-dimensional decision boundaries. The comment provides a logical reasoning by pointing out that the results can vary significantly based on the projection method and parameters. However, it lacks specific examples or references to support the claim about the impact of using 2D projections. This makes the claim somewhat verifiable, as it provides a reasonable basis for the concern but requires further elaboration to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the decision boundary generation process, noting that the projection results and Voronoi tessellations appear to be fixed across multiple rounds. It highlights the need to clarify how these fixed tessellations capture the model's behavior and the limitations of using 2D projections to represent high-dimensional decision boundaries. The comment provides a clear and actionable suggestion for the authors to address this concern by explaining the behavior of the model and the impact of the chosen projection method and parameters. This feedback is valuable as it guides the authors to improve the clarity and accuracy of their results, which is essential for the credibility of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of an ablation study and a comparison to methods in the past decade. While it highlights specific areas that could be improved, it does not provide explicit guidance on how to conduct these studies or what specific methods should be compared. The authors are left with a general understanding of what is missing but without concrete steps to address it. The action is implicit and somewhat vague, as it lacks detailed instructions on how to implement the suggested improvements. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of an ablation study and a comparison to methods in the past decade. However, it does not specify which part of the paper these omissions are discussed in, making it weakly grounded. The comment is specific in identifying what is missing, namely the inclusion of an ablation study and a comparison to past methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no ablation study and no comparison to methods in the past decade. However, it does not provide any supporting evidence, reasoning, or references to justify why these omissions are problematic or how they impact the paper\\'s contribution. Without additional context or explanation, the authors may find it challenging to understand the significance of these claims and how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two significant omissions in the paper: the absence of an ablation study and a comparison to methods in the past decade. These are important aspects that could enhance the paper\\'s contribution and rigor. However, the comment lacks specific guidance on how to conduct an ablation study or what methods should be compared. While it highlights areas for improvement, it does not provide actionable steps or detailed suggestions for the authors to address these gaps. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models, specifically mentioning SVC. While the comment implies that the authors should expand their theoretical results, it does not provide specific guidance on which models or aspects to focus on or how to integrate these results into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include more theoretical results but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more theoretical results on more complicated models, specifically mentioning SVC. However, it does not specify which part of the paper this suggestion pertains to, such as sections or specific theoretical results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to include more theoretical results on more complicated models, but without clear grounding, it is difficult for the authors to effectively address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more theoretical results on more complicated models, specifically mentioning SVC. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models, specifically mentioning SVC. This feedback is somewhat helpful as it identifies a potential area for expansion and improvement in the theoretical aspects of the paper. However, the comment lacks specific guidance on which models or theoretical results should be included, how they should be integrated into the paper, or why these additions are necessary. While it points out a potential gap, the lack of detailed suggestions limits its usefulness for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more ablation studies should be provided, particularly to demonstrate the necessity of the proposed DA Inversion. It also points out that the existing results in Figure 11 are insufficient to demonstrate this necessity. This feedback provides a clear and concrete action for the authors to take, which is to conduct additional ablation studies and present them in a way that effectively demonstrates the necessity of the proposed DA Inversion. The comment is specific about what needs to be added and how it should be presented, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more ablation studies should be provided, particularly to demonstrate the necessity of the proposed DA Inversion. It references \"Fig. 11\" as a point of concern, indicating that the existing results are not sufficient to demonstrate the necessity. However, it does not specify which part of the paper should include these additional studies or how they should be presented. While the authors can infer that it relates to the results section, the comment lacks full grounding as it does not explicitly mention the section or figure. The suggestion is specific in terms of what needs to be addressed, but it is not grounded as it does not provide detailed guidance on where to place the additional studies. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. However, it does not provide any specific reasoning or evidence to support why the existing results in Figure 11 are insufficient or why additional studies are necessary. The comment lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more ablation studies should be provided, particularly to demonstrate the necessity of the proposed DA Inversion. It points out that the existing results in Figure 11 are not enough to substantiate the necessity of the proposed method. This feedback is somewhat helpful as it identifies a specific area where additional evidence could strengthen the paper. However, the comment lacks detailed guidance on what specific ablation studies should be conducted or how they should be presented. While it highlights a potential weakness, it does not provide actionable steps for the authors to address it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should present a clear ablation on the clustering in the second phase of training, specifically questioning whether it is required if a linear regressor is learned on top of the discovered keypoints for evaluation. This feedback provides a direct and concrete action for the authors to take, which is to conduct an ablation study to clarify the necessity of clustering. The comment is specific in detailing what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the clustering in the second phase of training and the necessity of it if a linear regressor is learned on top of the discovered keypoints for evaluation. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of clustering in the second phase of training, suggesting that it may not be required if a linear regressor is learned on top of the discovered keypoints for evaluation. The comment provides a logical reasoning by pointing out that the linear regressor could serve as an alternative to the clustering process. However, it lacks specific examples or references to support the claim that clustering is not necessary. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the necessity of clustering in the second phase of training, specifically questioning whether it is required if a linear regressor is learned on top of the discovered keypoints for evaluation. The comment suggests that a clear ablation on this should be presented, which is a clear and actionable suggestion for the authors to address. By providing a specific area for improvement and a concrete suggestion for how to present it, the comment offers valuable guidance for the authors to enhance their draft. However, it could be more helpful if it provided additional context or examples of how such an ablation might be conducted. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and offers a clear path for addressing it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the results in Fig2a may be affected by the issue mentioned, specifically the forgetting not being as drastic as in class incremental and a slight increase being seen near epoch 150. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the figures. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the results in Fig2a may be affected by the issue mentioned, specifically the forgetting not being as drastic as in class incremental and a slight increase being seen near epoch 150. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on what specific aspects of the figure need attention. The authors can infer that it relates to the results section, but this inference is not direct. The comment is specific in detailing the issue with the forgetting curve, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results in Fig2a may be affected by the issue of forgetting not being as drastic as in class incremental and a slight increase being seen near epoch 150. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the results in Fig2a, suggesting that the forgetting curve may not be as drastic as in class incremental and that a slight increase is seen near epoch 150. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the figure. Without actionable feedback or detailed analysis, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. While the comment implies that this should be done in the abstract, it does not explicitly instruct the authors to do so. The action is clear but not directly stated, making the comment somewhat actionable. The authors can infer that they need to make a change to their abstract, but the exact wording or guidance is not provided.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. However, it does not specify which part of the paper this suggestion pertains to, such as the abstract or a specific section. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a particular aspect to highlight, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it affects the paper\\'s conclusions. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, specifically mentioning the covariance spectrum. This feedback is somewhat helpful as it identifies a potential area for improvement by emphasizing the importance of highlighting the data-dependent aspect of the results. However, the comment lacks specific guidance on how to effectively highlight this aspect or what specific changes should be made to the abstract or results sections. While it points out a potential weakness, it does not provide detailed instructions on how to address it, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify the meaning of RMSD in Figure 3, specifically whether it is the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This request is clear and provides a direct action for the authors to take, ensuring they know exactly what needs to be clarified in their draft. The comment is specific and provides concrete guidance on how to improve the clarity of the figure. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the meaning of RMSD, whether it is between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This provides clear guidance on what the authors need to address in order to improve the clarity of their figure. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the meaning of RMSD in Figure 3, specifically asking whether it is the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, specifically regarding the meaning of RMSD in Figure 3. It asks the authors to clarify whether RMSD is the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This feedback is clear and actionable, as it provides a direct and specific request for clarification that can help the authors improve the clarity and understanding of their figure. By addressing this point, the authors can enhance the readability and comprehensibility of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It explicitly asks the authors to address the question of whether there could be a smooth regret scaling for which the proven bounds still hold. This feedback is clear and provides a direct action for the authors to take, making it highly actionable. The comment is concrete in its request for a more detailed explanation and analysis of the phase transitions, ensuring that the authors know exactly what needs to be done to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"actual regret scaling\" compared to the asymptotic bounds, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the necessity of phase transitions in the actual regret scaling and the question of whether there could be a smooth regret scaling for which the proven bounds still hold. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" is needed. It raises a question about whether there could be a smooth regret scaling for which the proven bounds still hold. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It raises a question about whether there could be a smooth regret scaling for which the proven bounds still hold. This feedback is clear and actionable, as it prompts the authors to provide a more thorough treatment of this topic. By addressing this question, the authors can enhance the clarity and depth of their analysis, which could lead to a more robust and comprehensive understanding of their results. However, the comment could be more helpful if it offered suggestions on how to approach this analysis or provided examples of similar studies that have addressed this question. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of comparisons to previous robust RL methods, specifically mentioning RARL, despite these methods being cited. It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. While the comment implies that the authors should include these comparisons or make explicit references, it does not provide explicit instructions on how to do so. The action is clear but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"comparison to previous robust RL methods\" and \"RARL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the absence of these comparisons despite the citation of these methods. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that comparisons to previous robust RL methods, specifically RARL, are missing despite being cited. The reviewer suggests that if GAD or EG already include these prior works, the authors should be explicit about it. However, the comment lacks specific examples or references to these prior works, making it difficult for the authors to fully understand the basis of the claim. The lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to infer the missing information to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting the absence of comparisons to previous robust RL methods, despite these methods being cited. It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. This feedback is clear and actionable, as it directs the authors to either include these comparisons or clarify their existing references. By addressing this point, the authors can enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided examples of specific comparisons that should be included or detailed guidance on how to present these comparisons. Overall, the comment is mostly helpful as it effectively points out a gap in the paper and offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more details about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. While the comment implies that additional information is needed, it does not specify exactly what details are missing or how they should be presented. The authors are left to infer that they need to provide more information, but without concrete guidance on what aspects to focus on or how to present it, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more details are needed about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. However, it does not specify which part of the paper these details should be provided in, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in what needs to be addressed, it lacks grounding as it does not specify where in the paper these details should be provided. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details are needed about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. However, it does not provide any specific reasoning or evidence to support why these details are necessary or how they would improve the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper lacks details about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. While it identifies areas that could benefit from more explanation, it does not provide specific guidance on what details are missing or how they could be addressed. The comment is somewhat helpful as it points out potential gaps in the paper, but it lacks actionable suggestions or examples to help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between HIS and the negative inverse of mean response time. However, it does not provide any guidance or suggestions on how the authors should address this issue or what specific actions they should take to clarify this relationship. The comment lacks explicit instructions or concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between HIS and the negative inverse of mean response time. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the mathematical relationship, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the relationship between HIS and the negative inverse of mean response time. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relationship between HIS and the negative inverse of mean response time, which could be a significant issue or a misunderstanding in the paper. However, the comment lacks depth and does not provide any context or explanation for why this relationship is surprising or problematic. Without additional information or suggestions for clarification or improvement, the authors are left with a vague question that does not offer actionable guidance. Therefore, the comment is barely helpful, as it identifies a potential issue but does not provide sufficient direction for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about the choice of sparse representation learning method and the inclusion of FTA as a baseline in the experiments. It suggests that the authors should provide a rationale for why the particular method was chosen and clarify the comparison with FTA in both supervised and reinforcement learning settings. The comment also emphasizes the importance of a rigorous comparison in an empirical paper. While the action is explicit, it is somewhat vague in terms of how to implement the comparison, as it does not provide specific guidance on how to conduct the comparison or what specific aspects to focus on. However, the authors can infer that they need to address these points to improve their draft. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"particular sparse representation learning method\" and the \"experiments part,\" allowing the authors to accurately identify the sections being addressed. It also specifies the need for a rationale for the choice of method and the inclusion of FTA as a baseline, as well as the comparison in a reinforcement learning setting. Additionally, it highlights the importance of a rigorous comparison in an empirical paper. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the choice of sparse representation learning method and the inclusion of FTA as a baseline in the experiments. It suggests that a rigorous comparison is necessary, particularly in the context of reinforcement learning. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the current comparison is insufficient. The authors are left to infer the need for a more comprehensive comparison, which may require additional work to address. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks detailed evidence or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, specifically regarding the choice of sparse representation learning method and the inclusion of FTA as a baseline in the experiments. It questions the rationale behind the choice of method and suggests that a rigorous comparison is necessary, particularly in the context of reinforcement learning. The comment highlights the importance of empirical rigor in an empirical paper. While it provides clear guidance on what needs to be addressed, it could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors describe a particular choice of shift and scaling on page 4, line 154, but do not explain why this choice is more appropriate. This implies that the authors should provide an explanation for their choice, which is a clear and explicit action. However, the comment does not specify where in the explanation the authors should provide this information, leaving some ambiguity. While the action is explicit, the lack of concrete guidance on where to include the explanation makes it somewhat vague. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.4, l.154,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it points out that the authors state a particular choice of shift and scaling but do not explain why, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors make a particular choice of shift and scaling but do not explain why. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors describe a particular choice of shift and scaling but do not explain why it is more appropriate. This is a clear and actionable observation that prompts the authors to provide an explanation for their choice, which is crucial for the reader to understand the rationale behind the decision. However, the comment could be more helpful if it suggested how the authors might present this explanation effectively or provided examples of how similar choices have been justified in other works. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should revise the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be revised. The comment is specific and concrete, giving the authors a clear understanding of what changes to make to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests revising the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the issue with the term \"partial inference,\" it lacks grounding as it does not reference specific sections or phrases in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests revising the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere. However, it does not provide any reasoning, examples, or references to support why this change is necessary or how it would improve the paper. Without additional context or justification, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of terminology in the paper, particularly the term \"partial inference of GFlowNets\" in the title and elsewhere. It suggests that this terminology should be revised, which is a clear and actionable piece of feedback. However, the comment lacks depth and does not provide further explanation or suggestions on how to revise the terminology or why it is problematic. While it points out a potential issue, it could be more helpful if it included additional context or examples to guide the authors in making the necessary changes. Therefore, the comment is somewhat helpful, as it provides a starting point for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper only measures BERTscore to illustrate the similarity of the newly generated text, but it suggests that there are other matrices that could measure the stealthiness of the generated content. However, it does not provide specific guidance on which matrices should be used or how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors can infer that they need to consider additional metrics but are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"measurement of BERTscore\" and the \"similarity of the newly generated text,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not discuss other matrices that could measure the stealthiness of the generated content. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only measures BERTscore to illustrate the similarity of the newly generated text, suggesting that there are other matrices that could measure the stealthiness of the generated content. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that it only measures BERTscore to illustrate the similarity of the newly generated text. It suggests that there are other matrices that could measure the stealthiness of the generated content, which is an important aspect to consider. However, the comment does not provide specific examples of these matrices or explain why they are relevant. While it highlights a potential area for improvement, the lack of detailed guidance makes it somewhat helpful. The authors are given a direction to explore but are not provided with the necessary information to fully address the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the need to clearly highlight the issues with existing estimators, the lack of basic notation definition, and the need for clarity about the heuristic nature of the algorithm. However, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to clarify the issues and provide more detailed explanations, but without specific guidance on what aspects need clarification or how to achieve it, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues with the paper, including the need to clearly highlight the issues with existing estimators, the lack of basic notation definition, and the need for clarity about the heuristic nature of the algorithm. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need to clarify the issues with existing estimators and the heuristic nature of the algorithm. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the paper, including the need to clearly highlight issues with existing estimators, the lack of basic notation definition, and the need for clarity about the heuristic nature of the algorithm. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The authors are left to infer the issues and may find it challenging to address them without more explicit guidance. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issues but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the need to clearly highlight the issues with existing estimators and the lack of basic notation definition. It also points out the need for clarity about the heuristic nature of the algorithm. While the comment provides some insight into areas that need improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left to infer the necessary changes, which limits the comment\\'s helpfulness. Therefore, the comment is somewhat helpful, as it provides some direction but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims novelty in the perceptual loss functions for PSR, but the neural network and loss functions used are not unheard of in the field of medical imaging. The reviewer suggests that the authors might elaborate on which parts of the loss functions are new. This feedback is explicit and provides a clear action for the authors to take, which is to clarify the novelty of the perceptual loss functions. The suggestion is concrete, as it specifies what needs to be clarified, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors claim novelty in the perceptual loss functions for PSR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the elaboration of which parts of the loss functions are new. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the novelty of the perceptual loss functions for PSR, noting that the neural network and loss functions used are not unheard of in the field of medical imaging. The comment suggests that the authors might elaborate on which parts of the loss functions are new. This claim is somewhat verifiable as it points out a potential issue with the paper\\'s novelty claim, but it lacks specific examples or references to support the assertion that the loss functions are not novel. The authors would need to provide more detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim of novelty regarding the perceptual loss functions for PSR. It points out that the neural network and loss functions used are not unheard of in the field of medical imaging, suggesting that the authors might elaborate on which parts of the loss functions are new. This feedback is clear and actionable, as it directs the authors to clarify the novelty of their work by specifying the innovative aspects of the loss functions. By addressing this point, the authors can enhance the clarity and originality of their paper. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the experimental results, noting that they do not exhibit significant improvement in real-life datasets and questioning the comparison on the ZINC dataset. However, it does not provide specific guidance on how the authors should address these issues or improve their experimental results. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Experimental Results\" and \"ZINC dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the experimental results do not exhibit significant improvement in real-life datasets and questioning the comparison on the ZINC dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results do not exhibit significant improvement in real-life datasets and questions the comparison on the ZINC dataset. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern about the experimental results, noting that they do not exhibit significant improvement in real-life datasets and questioning the comparison on the ZINC dataset. It specifically points out a lack of improvement in the results and highlights an issue with the comparison on the ZINC dataset. While the comment provides some insight into potential weaknesses in the experimental results, it lacks specific suggestions or guidance on how the authors might address these issues or improve their experimental design. This limits the comment\\'s helpfulness, as it does not provide actionable advice for the authors to enhance their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the SLM's performance compared to larger models, suggesting that it may be convincing if the SLM performs better due to limited data availability. However, the reviewer provides evidence from various experiments, such as Figure 3 (b) and BSM models, where larger models perform better than smaller ones. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the performance of larger models in their analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of the SLM compared to larger models, suggesting that it may be convincing due to limited data availability. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs attention. The comment does provide examples from Figure 3 (b) and BSM models, which could help the authors identify the relevant sections. While the comment is specific in its critique of the SLM's performance, it lacks full grounding as it does not explicitly mention the section where this issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the SLM may be convincing if it performs better than larger models due to limited data availability. However, the comment provides no supporting evidence or references to substantiate this claim. The mention of specific experiments, such as Figure 3 (b) and BSM models, does not directly address the claim about the SLM's performance. Without additional context or detailed reasoning, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the SLM's performance compared to larger models, suggesting that it may be convincing due to limited data availability. However, the reviewer provides evidence from various experiments, such as Figure 3 (b) and BSM models, where larger models consistently outperform smaller ones. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s argument, but it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. The comment highlights a critical area for consideration, but it does not provide actionable advice or detailed feedback to help the authors enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out inconsistencies in the notation, specifically mentioning that the notation in Figures 2 and 3 does not match the notation in Algorithm 1 and changes again on Page 4 and Figure 4. This provides a clear and explicit action for the authors to take, which is to review and correct the notation to ensure consistency across the paper. The comment is specific about the inconsistencies and provides concrete guidance on how to address them, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figures 2 & 3\" and \"Alg 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of inconsistent notation, particularly with \"nu,\" which is a clear indication of the problem. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation is inconsistent, particularly with \"nu,\" and provides specific examples by referencing Figures 2 and 3 and Algorithm 1. This claim is somewhat verifiable as it highlights specific instances of inconsistency, allowing the authors to understand the issue and potentially address it. However, the comment lacks detailed reasoning or references to support the claim that the inconsistency is problematic or impacts the understanding of the paper. Providing more context or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation in the paper, particularly regarding the use of \"nu\" and its inconsistency across different parts of the paper. By pointing out these inconsistencies, the comment provides the authors with clear and actionable feedback on how to improve the consistency and clarity of their notation. This is valuable guidance that can help the authors enhance the readability and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to standardize the notation or provided examples of how to address the inconsistencies. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more experiments should be conducted in challenging tasks, specifically mentioning dexterous manipulations in Adroit. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on which tasks to focus on or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments in challenging tasks, specifically mentioning dexterous manipulations in Adroit. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for more experiments in challenging tasks, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments should be conducted in challenging tasks, specifically mentioning dexterous manipulations in Adroit. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these tasks are considered challenging or how they would validate the proposed method. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more experiments should be conducted in challenging tasks, specifically mentioning dexterous manipulations in Adroit. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting that the authors conduct experiments in more challenging environments to validate their method. However, the comment lacks specific guidance on which tasks to focus on or how to conduct these experiments effectively. While it points out a potential area for improvement, it does not provide detailed instructions or examples, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the summary of previous works in the introduction is not fair, as some papers assume linearly separable data while others make a stronger assumption. It questions whether the statement \"the feature direction of each arbitrary training sample could act as a perfect linear classifier\" refers to orthogonally separable data. While the comment identifies a potential issue with the summary, it does not provide explicit guidance on how to address it. The authors are left to infer that they should clarify or correct the summary, but the action is not directly stated. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the summary of previous works, pointing out that some papers assume linearly separable data while others make a stronger assumption. The comment further questions whether the statement about the feature direction of each training sample acting as a perfect linear classifier refers to orthogonally separable data. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the fairness of the summary of previous works in the introduction, specifically mentioning Williams et al. (2019), Lyu et al. (2021), Boursier et al. (2022), and Wang & Ma (2023). The reviewer points out that some of these papers assume linearly separable data, while others make a stronger assumption. The comment also questions whether the statement about the feature direction of each training sample acting as a perfect linear classifier refers to orthogonally separable data. While the review point raises valid concerns, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to make a significant effort to verify the claim themselves, as the comment does not provide sufficient evidence or examples to support the critique. Therefore, the comment is somewhat verifiable, as it requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the summary of previous works in the introduction, specifically questioning the assumption of linearly separable data. It points out that some papers assume this assumption while others make a stronger assumption. The reviewer also questions whether a statement about the feature direction of each training sample acting as a perfect linear classifier refers to orthogonally separable data. This feedback is somewhat helpful as it highlights a potential oversight in the introduction, prompting the authors to reconsider the fairness and accuracy of their summary. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or clarified the reference to orthogonally separable data. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the paper\\'s per-sample weight tuning method, which relies on the influence function. It highlights that the explanation of the influence function is only valid when the upweight is very close to 0. If the weights are far away from 0 during training iterations, the influence function might not accurately reflect each sample\\'s influence, leading to unreliable weights. The comment implies that the authors should address this issue by ensuring that the upweight is close to 0 during training iterations. However, it does not provide specific guidance on how to achieve this or what steps to take if the upweight is far from 0. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"per-sample weight tuning method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the influence function, explaining that the theoretical approximation of each sample\\'s contribution from Taylor\\'s first-order expansion is not valid when the upweight is far from 0. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s per-sample weight tuning method relies on the influence function, which is only valid when the upweight is very close to 0. The reviewer provides a logical reasoning that if the weights are far away from 0 during training iterations, the influence function might not accurately reflect each sample\\'s influence, leading to unreliable weights. This claim is somewhat verifiable as it provides a logical explanation based on the assumption that the upweight is far from 0. However, it lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s per-sample weight tuning method, which relies on the influence function. It points out that the explanation of the influence function is only valid when the upweight is very close to 0. If the weights are far away from 0 during training iterations, the influence function might not accurately reflect each sample\\'s influence, leading to unreliable weights. This is a critical observation that could impact the reliability and validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their method. While it highlights a potential problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the use of centering in partial shapes and scenes, suggesting that it may not be well-defined. It explicitly instructs the authors to address this issue, providing a clear action for improvement. Additionally, the comment raises a concern about the ground-truth center in the experiment, noting that it may not generalize to partial shapes during training. While the comment is explicit in its request for addressing the issue, it does not provide specific guidance on how to implement this improvement. Therefore, the action is explicit but somewhat vague in terms of execution. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Centering in Partial Shapes and Scenes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of centering in partial shapes and scenes, suggesting that the authors should address this issue. Additionally, it raises a concern about the ground-truth center in the experiment, which is an important point for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of centering in partial shapes and scenes, suggesting that it may not be well-defined. The reviewer provides a logical reasoning by pointing out that centering may not be applicable to partial shapes or scenes. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore and substantiate the issue themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of centering in partial shapes and scenes, suggesting that it may not be well-defined. It provides a clear and actionable suggestion for the authors to address this issue, which is important for ensuring the validity and applicability of their work. Additionally, the comment raises a concern about the ground-truth center in the experiment, noting that it may not generalize to partial shapes during training. This feedback is valuable as it highlights a critical aspect of the methodology that the authors should consider. However, the comment could be more helpful if it provided specific guidance on how to address the issue or suggested alternative approaches. Overall, the comment is mostly helpful as it identifies a significant area for improvement and provides actionable feedback.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should try to ensemble models trained with the proposed negative augmentations and without it to see if this could improve performance. This is an explicit action that the authors can directly implement. The comment provides a clear direction for further experimentation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the proposed method of learning less about texture semantics by adding negative samples that share texture semantic with the anchor images. It suggests trying to ensemble models trained with the proposed negative augmentations and without it to see if this could improve performance. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors might have an idea of where this suggestion fits, it is not explicitly grounded. The comment is specific in suggesting a potential improvement but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper\\'s proposed method of learning less about texture semantics by adding negative samples that share texture semantic with the anchor images might not be effective. The reviewer provides a reference to a similar approach in [1] and suggests trying to ensemble models trained with and without the proposed negative augmentations to see if this could improve performance. This suggestion is based on a logical reasoning and a reference to a similar work, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from [1] to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s approach to learning less about texture semantics by adding negative samples that share texture semantic with the anchor images. It suggests an experiment to ensemble models trained with and without the proposed negative augmentations to determine if this could improve performance. This feedback is clear and actionable, providing a specific direction for the authors to explore and potentially enhance their work. However, the comment could be more helpful if it included additional details or examples of how this ensemble approach has been successfully applied in similar contexts. Overall, the comment is mostly helpful as it guides the authors toward a meaningful experiment that could improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sample efficiency of a particular equation and suggests that the authors might need to address it. However, it does not provide explicit guidance or suggestions on how to address this issue. The comment lacks concrete details or specific actions for the authors to take, such as suggesting ways to improve the sample efficiency or providing examples of how to ensure that D i sufficiently goes through all possible transition probabilities. As a result, the authors are left without clear direction on how to proceed with this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix B\" and \"page 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning whether the authors can guarantee that D i sufficiently goes through all possible transition probabilities, and it references specific pages and equations. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and observations regarding the partitioning method and its implications for the sample efficiency of a particular equation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the sample efficiency of a particular equation and suggests that the authors might need to address it. It also points out a discrepancy between the partitioning method used in the paper and the buffer series in Appendix B. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve the paper. While it identifies potential areas for improvement, it does not provide actionable steps or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on how the authors form clusters for tokens in Figure 1, which is currently unclear in Section 3. This is a direct and concrete request for additional information, providing the authors with a clear action to take. The comment is specific and leaves no ambiguity about what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, the methodology for forming clusters for tokens in Figure 1. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the methodology used to form clusters for tokens in Figure 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the methodology used to form clusters for tokens in Figure 1, which is currently unclear in Section 3. By asking for clarification, the comment provides the authors with a clear and actionable step to improve their draft. However, it could be more helpful if it offered suggestions on how to clarify this aspect or provided additional context to aid understanding. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the SimNPO method, noting that it introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance. This complexity and time cost are seen as limiting the potential application of the method for large language models in real-world settings. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to simplify the method or suggest alternative approaches to reduce complexity. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SimNPO method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the method, which introduces two additional hyperparameters that significantly increase complexity and time cost. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that SimNPO introduces two additional hyperparameters that significantly increase the complexity and time cost of experiments, limiting its potential application in real-world settings. This claim is supported by logical reasoning, as it highlights the additional manual adjustments required to achieve optimal performance. However, the comment could be strengthened by providing specific examples or references to studies that have experienced similar issues with hyperparameter tuning. As it stands, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the SimNPO method, noting that it introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance. This complexity and time cost are seen as limiting the potential application of the method for large language models in real-world settings. While the comment highlights an important concern, it lacks specific suggestions or guidance on how the authors might address this issue or simplify the method. Without actionable advice or examples, the feedback provides some insight but does not fully support the authors in improving their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work places too much emphasis on affordance prompting, which is overengineered, as evidenced by the Pick&place example. However, it does not provide specific guidance on how the authors should address this issue or what changes should be made to improve the demonstration of the advantage of affordance prompting. The comment lacks actionable details, such as suggesting alternative approaches or methods to better showcase the benefits of affordance prompting. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the work for placing too much emphasis on affordance prompting, which is overengineered, as evidenced by the Pick&place example. However, it does not specify which part of the paper this critique is based on, such as the sections discussing affordance prompting or the specific examples mentioned. The authors can infer that it relates to the discussion on affordance prompting, but this inference is not as direct as it could be. The comment is specific in detailing the issue with the Pick&place example, but it lacks full grounding as it does not explicitly mention the section or figure where this example is discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work places too much emphasis on affordance prompting, which is overengineered, as evidenced by the Pick&place example. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that it places too much emphasis on affordance prompting, which is overengineered. The reviewer provides a specific example, the Pick&place example, to illustrate this point. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might address this issue or improve their work. While it highlights a potential weakness, it does not provide actionable feedback or constructive advice that could help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it points out a specific area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that ablation studies are needed to demonstrate the necessity of all parts of the proposed algorithmic pipeline. This is a clear and direct action for the authors to take, as it provides a specific recommendation for improving the draft. The comment is concrete because it specifies the need for ablation studies and highlights the importance of demonstrating the necessity of each part of the proposed methodology. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that ablation studies are needed to demonstrate the necessity of all parts of the proposed algorithmic pipeline. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for ablation studies to demonstrate the necessity of each part of the proposed methodology. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that ablation studies are needed to demonstrate the necessity of all parts of the proposed algorithmic pipeline. However, it does not provide any supporting evidence, reasoning, or examples to justify why these studies are necessary or how they would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that ablation studies are needed to demonstrate the necessity of all parts of the proposed algorithmic pipeline. This is a clear and actionable suggestion that can help the authors validate the robustness and effectiveness of their methodology. By conducting ablation studies, the authors can provide a more comprehensive understanding of the impact of each component on the overall performance. However, the comment could be more helpful if it provided specific guidance on how to conduct these studies or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a critical area for improvement but could be more detailed to fully support the authors.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the necessity of the instruction-tuning stage, questioning whether the performance improvement could come from the additional training and tuning costs. It suggests that the authors should provide a more convincing demonstration of the necessity of this stage. However, the comment does not explicitly instruct the authors to conduct additional experiments or provide specific guidance on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should provide more evidence or analysis to support their conclusion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the necessity of the instruction-tuning stage and questions whether the performance improvement can be attributed to the additional training and tuning costs. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the conclusion and the potential costs of the instruction-tuning stage. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of the instruction-tuning stage and suggests that the performance improvement could be attributed to the additional training and tuning costs. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate the claim that the performance improvement could come from the extra training cost. As a result, the claim is somewhat verifiable, as it requires further elaboration and evidence to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the necessity of the instruction-tuning stage. It questions whether the performance improvement can be attributed solely to this stage, suggesting that additional training and tuning costs may be involved. This is a relevant point that could impact the practicality and cost-effectiveness of the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or demonstrate the necessity of the instruction-tuning stage more convincingly. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the evaluation setup is outdated and suggests testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or any other instruction fine-tuning dataset. This feedback provides a clear and explicit action for the authors to take, which is to update the evaluation setup and consider testing on more challenging datasets. The suggestion is concrete and specific, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the evaluation setup, specifically mentioning the outdated nature of the setup and the release dates of Llama-1 and Mistral-v0.1. It suggests testing on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or any other instruction fine-tuning dataset. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the evaluation or experimental sections. The comment is specific in suggesting a more challenging setup for testing, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation setup is outdated and suggests testing on a more challenging and representative fine-tuning setup. The reviewer provides logical reasoning by mentioning the release dates of Llama-1 and Mistral-v0.1 and the advancements in quality of current models. However, the comment lacks specific examples or references to support the claim that the current models are more advanced. Additionally, the suggestion to test on a more challenging dataset is not fully substantiated with detailed reasoning or evidence. Therefore, the claim is somewhat verifiable, as it provides some support but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation setup, noting that it is outdated due to the release of Llama-1 and Mistral-v0.1 more than a year ago. It suggests testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or any other instruction fine-tuning dataset. This feedback is clear and actionable, providing the authors with a specific direction to improve their evaluation setup and ensure that their approach is tested on more relevant and challenging datasets. By addressing this issue, the authors can enhance the robustness and generalizability of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the second section of the paper lacks logical coherence, resulting in disorganized content. However, it does not provide specific guidance on how to address this issue or what changes should be made to improve the coherence. The comment implies that the authors should work on improving the logical flow and coherence of their content, but it does not offer concrete steps or examples of how to achieve this. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to apply the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the second section of the paper, which is specific, but it does not explicitly mention which part of the section is disorganized or lacks logical coherence. This makes it difficult for the authors to pinpoint the exact issue that needs to be addressed. However, the mention of \"related works\" suggests that the authors should focus on the content related to these works. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the second section of the paper lacks logical coherence, resulting in disorganized content. However, it does not provide specific examples or detailed reasoning to support this claim. The comment suggests that the issue is related to the presentation of related works, but it does not elaborate on how this affects the coherence or organization of the content. Without specific examples or detailed reasoning, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization and coherence of the second section of the paper, noting that the presentation of related works lacks logical coherence. This feedback is somewhat helpful as it highlights a potential weakness in the paper\\'s structure, which could impact the reader\\'s understanding and comprehension. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a particular approach or structure to improve the coherence. While it points out a problem, it lacks actionable advice, making it somewhat helpful but not comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention the language they focus on to retrieve Reddit posts. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific request for information, ensuring that the authors know exactly what needs to be added to their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to mention the language used to retrieve Reddit posts. This allows the authors to accurately identify the part of the paper being addressed, ensuring they can make the necessary changes. However, the comment lacks specificity as it does not provide details on why this information is important or how it could impact the paper. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point is a request for clarification, asking the authors to mention the language used to retrieve Reddit posts. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area where the authors need to provide more information. By requesting the language used to retrieve Reddit posts, the comment highlights a potential gap in the paper that could be clarified to enhance its comprehensiveness. However, the comment lacks depth and does not offer suggestions on how to present this information or why it is important. While it points out a specific area for improvement, it could be more helpful if it provided additional guidance or context. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the paper lacks comparisons with recent works, specifically mentioning [1]. This provides a clear and direct action for the authors to take, which is to include comparisons with recent works in their paper. The comment is specific and concrete, as it identifies the exact area that needs improvement and suggests a specific action to address it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the lack of comparisons with recent works, specifically referencing \"recent works\" and \"recent papers\" in the literature. This provides full grounding as it allows the authors to accurately identify the part of the paper being addressed, which is the lack of comparisons with recent works. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with recent works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons with recent works, specifically mentioning \"recent works\" and \"recent papers.\" However, it does not provide any specific examples or references to these works, nor does it explain why these comparisons are necessary or how they would enhance the paper. Without additional context or justification, the claim is difficult for the authors to verify or address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of comparisons with recent works, specifically mentioning \"recent works\" and \"recent papers.\" This feedback is clear and actionable, as it directs the authors to include comparisons with relevant literature to enhance the paper\\'s contribution and relevance. However, the comment could be more helpful if it provided examples of recent works that should be compared or explained why these comparisons are important. Despite this, the feedback is mostly helpful as it guides the authors toward a significant improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether TSG (likely a specific technique or method) would work in diffusion models that do not embed class labels into timestep, such as UViT. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or suggestions on how to address this question or integrate TSG into such models. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether TSG (likely a specific technique or method) would work in diffusion models that do not embed class labels into timestep, such as UViT. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the applicability of TSG in these models, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about whether TSG (likely a specific technique or method) would work in diffusion models that do not embed class labels into timestep, such as UViT. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of TSG (likely a specific technique or method) in diffusion models that do not embed class labels into timestep, such as UViT. This is a relevant inquiry that could prompt the authors to consider the broader applicability of their work beyond specific models or assumptions. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this question or explore its implications. While it points out a potential area for further exploration, it does not offer actionable advice or detailed insights, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to release their training code, dialogue dataset, and model checkpoints to improve reproducibility. It provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be done to address the issue. The suggestion to submit the code and datasets via anonymous repositories is also specific, providing a direct path for the authors to improve the transparency and verifiability of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of limited reproducibility and suggests that the authors release their training code, dialogue dataset, and model checkpoints to improve reproducibility. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for the authors to release their code and datasets for reviewers to verify the claims and try out the model. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks reproducibility due to the lack of release of training code, dialogue dataset, and model checkpoints. The reviewer suggests that the authors should release these materials to improve reproducibility. However, the comment does not provide specific examples or detailed reasoning to support why these materials are necessary for reproducibility or how the lack of them affects the claims in the paper. While the suggestion is logical, the absence of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the reproducibility of the paper, noting that the lack of release of training code, dialogue dataset, and model checkpoints makes it challenging to verify the claims. The comment provides a clear and actionable suggestion by encouraging the authors to release these materials via anonymous repositories in the paper submission. This feedback is valuable as it directly addresses a critical aspect of the paper\\'s credibility and transparency, empowering the authors to take a concrete step to improve the reproducibility of their work. However, the comment could be more helpful if it included specific examples or guidance on how to effectively present these materials for reviewers. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be further enhanced with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the main result is \"a bit obvious\" because gradient boosting is known to minimize objectives in functional space. However, it does not provide any explicit or implicit actions for the authors to take to address this observation or improve their draft. There is no guidance on how to make the result less obvious or how to present it in a more novel or insightful way. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the main result is \"a bit obvious\" because gradient boosting is known to minimize objectives in functional space. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspect of the result is considered obvious or how it could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main result is \"a bit obvious\" because gradient boosting is known to minimize objectives in functional space. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the main result is \"a bit obvious\" because it is based on gradient boosting, which is known to minimize objectives in functional space. However, it does not provide any specific feedback or suggestions on how the authors might address this issue or improve the originality of their work. Without actionable guidance or constructive criticism, the comment offers limited value to the authors in terms of enhancing the draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the contribution of the work is insufficiently expressed and that the details provided are inadequate. It suggests that the paper lacks appropriate analysis and related work is not mentioned. However, the comment does not provide specific guidance on how to improve the contribution or what aspects of the analysis should be included. The authors are left with a general sense of what needs to be addressed but without concrete steps or examples on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the contribution of the work, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the contribution is insufficiently expressed and that the details provided are inadequate. Additionally, it points out the lack of related work mentioned and the absence of appropriate analysis. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the contribution of the work is insufficiently expressed and that the details provided are inadequate. It suggests that the paper lacks appropriate analysis and related work is not mentioned. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim borderline verifiable, as it requires more information to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, stating that the contribution is insufficiently expressed and that the details provided are inadequate. It points out that the paper lacks appropriate analysis and related work is not mentioned, which is a critical oversight. However, the comment does not provide specific suggestions or guidance on how to improve the contribution or what aspects of the analysis should be included. While it highlights areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify what the training steps refer to in Figure 2b, suggesting that they should provide iterations or training steps as the x-axis in Figure 2a. This feedback is clear and concrete, as it specifies exactly what needs to be done to improve the clarity of the figures. The authors know exactly how to apply this action to enhance the readability and understanding of their results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2a\" and \"Figure 2b,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of \"training steps\" and the label \"item\" on the x-axis in Figure 2b. The comment provides guidance on how to improve the clarity of the figures by suggesting that iterations or training steps should be used as the x-axis in Figure 2a. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the results presented in Figures 2a and 2b, specifically regarding the label \"item\" on the x-axis in Figure 2b and the meaning of \"training steps\" in Figure 2a. The reviewer suggests that the x-axis should be labeled with iterations or training steps to improve clarity. While the comment identifies a potential issue with the figures, it lacks specific examples or references to support the claim that the current labeling is unclear. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to address the issue, but the feedback is not as detailed as it could be. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the results presented in Figures 2a and 2b, noting that the x-axis label \"item\" in Figure 2b is unclear and that the term \"training steps\" in Figure 2a is not explained. The comment provides actionable feedback by suggesting that the x-axis should be labeled with iterations or training steps to improve clarity. This feedback is clear and specific, offering a concrete way for the authors to enhance the readability and understanding of their results. By addressing this issue, the authors can significantly improve the clarity of their figures, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of different costs (flops, latency, and 1/FPS) for different hardware, suggesting that using the same cost for different devices would be more appropriate. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they should consider using a consistent cost metric across devices, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of different costs (flops, latency, and 1/FPS) for different hardware, suggesting that using the same cost for different devices would be more appropriate. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these costs are discussed. The authors can infer that it relates to the discussion of costs in the context of hardware, but this inference is not direct. The comment is specific in its suggestion to use the same cost for different devices, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of different costs (flops, latency, and 1/FPS) for different hardware, suggesting that using the same cost for different devices would be more appropriate. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the use of different costs (flops, latency, and 1/FPS) for different hardware, suggesting that using the same cost for different devices would be more appropriate. This feedback highlights an area where the paper could be improved by simplifying the cost metrics used across different hardware. However, the comment lacks specific guidance or examples on how to implement this suggestion or what the potential benefits might be. While it identifies a potential area for improvement, it does not provide detailed instructions or reasoning to help the authors fully understand and address the issue. Therefore, the comment is somewhat helpful, as it points out a potential weakness but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the maximum iterations used in the experiments and whether they might significantly slow down the training speed. While it implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this detail in their paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"two-dimention Wasserstein distance\" and the \"Sinkhorn algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks about the maximum iterations used in the experiments and whether they might significantly slow down the training speed. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the two-dimensional Wasserstein distance does not have a closed-form solution and that the paper uses the Sinkhorn algorithm to obtain an approximate solution. The reviewer also asks about the maximum iterations used in the experiments and whether they might significantly slow down the training speed. However, the comment lacks specific examples or references to support the claim about the slowing down of the training speed. While it raises a valid concern, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific concern about the use of the Sinkhorn algorithm to approximate the two-dimensional Wasserstein distance, noting that this method does not have a closed-form solution. It also asks about the maximum iterations used in the experiments and whether they might significantly slow down the training speed. This feedback is clear and actionable, as it prompts the authors to address the limitations of their method and provide insights into the impact of the chosen approach on training speed. However, the comment could be more helpful if it offered suggestions on how to mitigate these issues or provided examples of alternative methods that might be more effective. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement and enhances the clarity of their methodology.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a major weakness in the paper's soundness, specifically regarding the teacher policy and its distribution matching. It suggests that the paper lacks theoretical results to support its approach and implies that it may be more of a heuristic than a theoretically sound approach. However, the comment does not provide explicit guidance on how to address this issue or what specific theoretical results should be included. While the authors can infer that they need to provide theoretical results, the lack of concrete steps or examples makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"soundness\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the teacher policy and its distribution matching, providing clear guidance on what needs to be addressed. The comment suggests the inclusion of theoretical results to support the approach, which is a specific and actionable suggestion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks theoretical soundness due to the teacher policy's distribution matching approach. The reviewer suggests that the method appears more like a heuristic than a theoretically sound approach. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper's soundness, specifically regarding the teacher policy and its distribution matching approach. It points out that the method appears more like a heuristic than a theoretically sound approach and suggests that theoretical results are needed to support the approach. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in improving their draft. However, the comment could be more helpful if it offered suggestions on what kind of theoretical results might be relevant or how to present them effectively. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a direction for the authors to take.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the proposed method does not perform well in some classes and suggests that reasons should be analyzed and discussed. This provides a clear and direct action for the authors to take, which is to analyze and discuss the reasons for the performance issues. The comment is specific and provides concrete guidance on what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the performance issues in some classes and the need to analyze and discuss the reasons for these issues. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not perform well in some classes and suggests that reasons should be analyzed and discussed. However, the comment does not provide any specific examples or evidence to support this claim, nor does it offer any suggestions on how to analyze or discuss the reasons. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the proposed method in some classes, noting that the reasons for this should be analyzed and discussed. This feedback is clear and actionable, as it directs the authors to focus on a particular area of the paper that requires further exploration and explanation. However, the comment could be more helpful if it provided specific suggestions on how to analyze and discuss the reasons for the performance issues. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that some experimental settings are not rigorously designed, specifically mentioning the MTT task and the need for testing on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. This feedback provides clear and concrete actions for the authors to take, such as testing on unseen tasks and discussing the results in more detail. The explicit nature of the suggestions and the concrete details on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"MTT task\" and suggests testing on unseen tasks, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of not rigorously designed experimental settings and suggests further discussion or explanation of the results, particularly regarding the variation of model behavior under different datasets/settings. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some experimental settings are not rigorously designed, specifically mentioning the MTT task and the need for testing on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to test on unseen tasks is logical, but the lack of specific examples or detailed explanation makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental design, noting that some settings are not rigorously designed, such as the MTT task. It suggests testing on unseen tasks and provides a clear direction for improvement by recommending further discussion or explanation of the results, particularly regarding the variation of model behavior under different datasets/settings. This feedback is actionable and offers a concrete way for the authors to enhance the rigor and comprehensiveness of their experimental analysis. However, the comment could be more helpful if it provided specific examples or guidance on how to implement these suggestions. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement and offers clear direction for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the randomization of data collection for the five layouts, suggesting that the data may not be randomly ordered, which could lead to learning effects across the different layouts. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure randomization. The comment lacks concrete instructions or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the randomization of data collection for five layouts, suggesting that the data may not be randomly ordered, which could lead to learning effects across the different layouts. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the data collection or experimental design sections, but this inference is not direct. The comment is specific in its concern about the randomization of data collection, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the randomization of data collection for five layouts, suggesting that the data may not be randomly ordered, which could lead to learning effects across the different layouts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the randomization of data collection for five layouts, suggesting that the data may not be randomly ordered, which could lead to learning effects across the different layouts. This is an important point that could impact the validity and reliability of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending a specific method for randomization or discussing potential implications. While it identifies a potential weakness, the feedback could be more helpful with additional details or actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment questions the relevance of node ordering in the context of random atom ordering in a specific point in the composition space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the relevance of node ordering in the context of random atom ordering in a specific point in the composition space. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in questioning the relevance of node ordering, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The comment questions the relevance of node ordering in the context of random atom ordering in a specific point in the composition space. However, it does not provide any supporting evidence, reasoning, or references to justify why node ordering should not play a role. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in understanding or addressing the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the relevance of node ordering in the context of random atom ordering in a specific point in the composition space. However, it does not provide any explanation or reasoning for why node ordering should not play a role or how it might impact the study. Without additional context or suggestions, the authors are left without actionable feedback or guidance on how to address this concern. Therefore, the comment is not helpful at all, as it lacks depth and does not assist the authors in improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which detracts from the novelty of the current work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting ways to differentiate their work or providing additional context to justify the novelty. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a previous work [5] that presents a dexterous manipulation benchmark with musculoskeletal hands, which detracts from the novelty of the current work. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of novelty being detracted by the previous work, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the previous work [5] detracts from the novelty of the current work. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without detailed explanation or examples, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the work, noting that a previous study [5] has also presented a dexterous manipulation benchmark with musculoskeletal hands. This observation highlights a potential challenge in differentiating the current work from existing research. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. While it points out a relevant concern, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more clarity on the selection process of datasets, including the pool of datasets used and the criteria for selection. It also suggests that the splitting procedure and split ratios should be detailed, referencing specific examples like OpenML100 and OpenML CC-18 for classification and Gijsbers et al. and Bischl et al. for benchmarking suites. The comment provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the selection process of datasets, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the need for more clarity on the selection process, including the pool of datasets and criteria for selection. Additionally, it suggests specific examples like OpenML100 and OpenML CC-18 for classification, and Gijsbers et al. and Bischl et al. for benchmarking suites. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection process of datasets is unclear and suggests that more clarity is needed regarding the pool of datasets used and the criteria for selection. The reviewer provides examples of specific datasets like OpenML100 and OpenML CC-18 for classification, as well as references to Gijsbers et al. and Bischl et al. for benchmarking suites. This provides a logical basis for the claim, as it highlights the need for more detailed information about the dataset selection process. However, the comment could be strengthened by providing more detailed reasoning or examples from the literature to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity regarding the selection process of datasets. It points out that if the selection of datasets is a main contribution, the authors should provide more detailed information about the pool of datasets used and the criteria for selection. The comment suggests specific examples, such as OpenML100 and OpenML CC-18 for classification, and references to benchmarking suites like Gijsbers et al. and Bischl et al. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and transparency of their work. By addressing these points, the authors can significantly improve the comprehensibility and credibility of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the ablation study lacks a critical comparison by not including a baseline where an unconditional diffusion model is first refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. It also points out that comparing to a model initiated with random parameters does not provide a relevant benchmark. The comment provides a clear and concrete action for the authors to take, which is to include a baseline comparison with conventional methods. This guidance is specific and actionable, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: a comparison with a baseline where an unconditional diffusion model is first refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. The comment provides a clear direction for improvement by suggesting a specific benchmark to include. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study lacks a critical comparison by not including a baseline where an unconditional diffusion model is first refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. The comment suggests that this comparison would be valuable to determine if the proposed method would outperform conventional baselines under the same computational constraints. The reviewer provides a logical reasoning for the need of this comparison, but it lacks specific examples or references to support the claim fully. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the ablation study, noting that it lacks a critical comparison by not including a baseline where an unconditional diffusion model is first refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their study by including a relevant baseline comparison. By addressing this point, the authors can strengthen the validity and robustness of their findings. However, the comment could be more helpful if it included suggestions on how to design and implement the baseline comparison, such as which specific models or metrics to use. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks in the paper are based on grasping and that the difficulties are too homogeneous. It explicitly recommends referring to specific projects, such as [1] and [2], to design more tasks. This provides a clear and concrete action for the authors to take, as it directly instructs them to explore additional projects for task design. The comment is specific in identifying the need for more diverse tasks and provides concrete examples of potential sources to draw from. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the tasks in the paper are based on grasping and that the difficulties are too homogeneous. It recommends referring to specific projects, such as [1] and [2], to design more tasks. However, the comment does not specify which part of the paper discusses the tasks or where the homogeneity issue is addressed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in recommending external projects to explore, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks in the paper are based on grasping and that the difficulties are too homogeneous. However, it does not provide any specific examples or references to support this claim. The suggestion to refer to external projects like [1] and [2] is vague without context, as it lacks detailed explanation or justification for why these projects would be relevant. This makes the claim unverifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the tasks seem to be based on grasping and that the difficulties are too homogeneous. It suggests that the authors consider referring to external projects, such as [1] and [2], to design more diverse tasks. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for the authors to explore. However, the comment could be more helpful if it elaborated on why these external projects might be relevant or how they could be integrated into the paper. Overall, the comment provides a clear suggestion for improvement but lacks depth and detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an issue with the comparison in Table 2, specifically noting that the training data for LEPA is likely larger than the \"Without Plan/Without Self-Reflection\" settings. The reviewer provides a reference to a specific line in the paper (lines 349-360) and suggests that the settings are aligned with the LEPA training data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the comparison. While the action is implied, it is not detailed enough for the authors to know exactly how to implement the suggested correction. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"lines 349-360,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, noting that the training data for LEPA is likely larger than the \"Without Plan/Without Self-Reflection\" settings. The comment provides a reference to a specific work, \"LUMOS: LEARNING AGENTS WITH UNIFIED DATA, MODULAR DESIGN, AND OPEN-SOURCE LLMS,\" which adds further context and specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Table 2 is unfair because the LEPA training data is likely larger than the \"Without Plan/Without Self-Reflection\" settings, based on a reference to lines 349-360. The reviewer provides a specific reference to the work \"LUMOS: LEARNING AGENTS WITH UNIFIED DATA, MODULAR DESIGN, AND OPEN-SOURCE LLMS,\" which supports the claim by suggesting that the settings are aligned with the LEPA training data. This provides a clear and robust basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison in Table 2, noting that the training data for LEPA is likely larger than the \"Without Plan/Without Self-Reflection\" settings. This is a critical observation that could impact the validity of the comparison. The reviewer provides a specific reference to lines 349-360 and suggests that the settings are aligned with the LEPA training data, which is a valuable piece of information for the authors to consider. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as recommending a revised method for comparing the training data or providing guidance on how to present the data more accurately. Overall, the comment is somewhat helpful as it points out a potential problem and provides a reference for further exploration, but it lacks detailed guidance on how to resolve the issue.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should consider using datasets from the GLUE benchmark, specifically mentioning tasks like QQP, to compute similarity between sentence pairs. It also recommends showing results on real-world diversity datasets. While the comment provides a clear and concrete action, it does not specify which datasets to use or how to implement the suggested changes. The authors are left to infer the specific datasets and methods to use, which slightly reduces the action\\'s clarity. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of synthetic datasets and suggests using datasets from the GLUE benchmark, specifically mentioning tasks like QQP. It also recommends showing results on real-world diversity datasets. This provides clear guidance on what aspects of the paper need attention and improvement. However, the comment does not specify which parts of the paper should include these datasets or how to implement the suggested changes, which could be more detailed. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the authors should use real datasets, specifically mentioning the GLUE benchmark and tasks like QQP, to compute similarity between sentence pairs. It also recommends showing results on real-world diversity datasets. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that using real datasets would be beneficial. The absence of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the benefits of using real datasets themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, noting that the authors only experiment with synthetic datasets and do not include results with real datasets. It suggests using datasets from the GLUE benchmark, specifically mentioning tasks like QQP, to compute similarity between sentence pairs. Additionally, it recommends showing results on real-world diversity datasets. This feedback is clear and actionable, providing the authors with specific suggestions for improving their experimental setup and demonstrating the relevance of their work in a more practical context. However, the comment could be more helpful if it included examples of real-world datasets or detailed guidance on how to implement these changes. Overall, the comment is mostly helpful as it effectively points out a gap in the paper and offers concrete suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add details on how to solve the optimization in the main paper. This is a clear and direct action, as it specifies exactly what needs to be added and why it is important. The comment provides a concrete suggestion for improvement, making it highly actionable. Authors know exactly what information is missing and how to address it.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the need to add details on how to solve the optimization in the main paper, which provides full grounding as it clearly identifies the part of the paper being addressed. It also specifies the issue of lacking details on the optimization, making it specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should add details on how to solve the optimization in the main paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should add details on how to solve the optimization in the main paper. This is a clear and actionable suggestion that can help the authors enhance the clarity and completeness of their work. By addressing this gap, the authors can provide more comprehensive guidance to readers on how to implement the optimization process. However, the comment could be more helpful if it included specific examples or suggestions on how to present these details. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks why LLaVA-series and Qwen-VL are not included in the evaluation, suggesting that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and provides a direct action for the authors to take, which is to include these models in their evaluation. The comment is specific about what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"LLaVA-series\" and \"Qwen-VL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of these models in the evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the omission of LLaVA-series and Qwen-VL from the evaluation, suggesting that their inclusion would provide a more comprehensive comparison across different LVLM architectures and training approaches. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why these models should be included. Without additional context or examples, the authors may find it challenging to understand the importance of including these models. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific omission in the evaluation, noting the absence of LLaVA-series and Qwen-VL models. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and actionable, as it points out a gap in the evaluation that the authors can address to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided additional context or examples of how these models might be relevant or beneficial to include. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include captions or descriptions as well as OCR heavy datasets in their work. While the comment implies that these additions are necessary, it does not provide explicit instructions on how to implement them or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add these elements but are not given concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include captions or descriptions as well as OCR heavy datasets in their work. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of these elements, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include captions or descriptions as well as OCR heavy datasets in their work. However, it does not provide any supporting evidence, reasoning, or examples to justify why these additions are necessary or how they would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include captions or descriptions as well as OCR heavy datasets in their work. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement these additions or why they are necessary. The comment is somewhat helpful as it points out a potential enhancement, but it does not offer actionable steps or examples to help the authors effectively incorporate these elements into their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and Equation 7, noting that the loss of TKD is assumed to be less than IYOR in Assumption 3.1 but is actually greater than IYOR in Equation 7. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to resolve the discrepancy. The action is implicit and somewhat vague, as the authors can infer that they need to reconcile the discrepancy but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 3.1\" and \"eqn.7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the assumptions and the equations, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a discrepancy between Assumption 3.1 and Equation 7, specifically regarding the loss of TKD. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Assumption 3.1 and Equation 7 regarding the loss of TKD. It points out that Assumption 3.1 assumes the loss of TKD to be less than IYOR, while Equation 7 suggests the opposite. This feedback is somewhat helpful as it highlights a potential inconsistency in the paper that the authors should address. However, the comment does not provide specific guidance on how to reconcile this discrepancy or suggest ways to clarify the assumptions in the paper. While it alerts the authors to a potential issue, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that question 3, mentioned earlier in the paper, is unclear about whether it indicates other limitations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify the question or what specific aspects of the question are unclear. Without actionable advice or suggestions, the authors are left without a clear path forward to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"question 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the question indicates other limitations, providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether question 3 indicates other limitations, but it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of question 3, which is mentioned earlier in the paper. It questions whether the question indicates other limitations, suggesting that the authors should clarify this point. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to address the issue. The authors are informed of a potential problem but are not given actionable steps to resolve it. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective at probing. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of the paper need to be revised. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective at probing. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this choice is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the choice or the middle layers might be more effective are being questioned. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective at probing. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify this claim. Without specific examples or comparisons, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the choice of using the last-layer hidden states for the classifier, suggesting that middle layers might be more effective at probing. This is a relevant point that could prompt the authors to reconsider their approach and potentially improve the paper by exploring alternative methods or justifying their choice. However, the comment lacks specific suggestions or guidance on how to address this issue or what aspects of the paper might benefit from a reevaluation of the classifier architecture. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a relevant issue but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks a clear motivation for using the Generative Uncertainty Estimation (GUE) dataset to determine the tokenization, model architecture, and training objective for the generative model. It suggests that the representations learned using these modeling decisions will be optimized for the tasks presented in GUE, which may have limited generalizability. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the motivation. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger rationale for their choices and consider broader applicability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of the Generative Uncertainty Estimation (GUE) dataset to determine the tokenization, model architecture, and training objective for the generative model. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the motivation, noting that the use of GUE may limit the generalizability of the learned representations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation for using the Generative Uncertainty Estimation (GUE) dataset is poorly justified, as it suggests that the modeling decisions are arbitrary and may not generalize well to other tasks. The reviewer provides a logical reasoning by pointing out that the representations learned using these modeling decisions will be optimized for the tasks presented in GUE, which may limit their applicability to other contexts. However, the comment could be strengthened by providing specific examples or references to similar studies that have faced similar issues. As it stands, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s motivation, specifically the use of the Generative Uncertainty Estimation (GUE) dataset to determine the tokenization, model architecture, and training objective for the generative model. It points out that the modeling decisions are arbitrary and may not generalize well to other tasks, as the representations learned will be optimized for the tasks presented in GUE. This feedback is valuable as it highlights a critical weakness in the paper\\'s rationale, which could impact its applicability and relevance to broader audiences. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as by discussing alternative datasets or methods for determining the modeling choices. Overall, the comment is mostly helpful as it directs the authors\\' attention to a crucial area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper is clunky due to significant grammar and spelling errors, and it suggests that a major editing pass is needed. This provides a clear and direct action for the authors to take, which is to revise and edit the paper to improve its readability. The comment is specific in identifying the issue and provides a concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the issue of grammar and spelling errors, which allows the authors to identify the specific part of the paper being addressed. However, it does not provide detailed guidance on what specific errors need to be addressed or how to improve the readability of the paper. The comment lacks specificity in terms of the exact errors or areas that need improvement, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is clunky due to significant grammar and spelling errors, suggesting that it needs a major editing pass. However, the comment does not provide specific examples or details about the errors or how they impact the readability of the paper. Without these details, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely that it is clunky due to significant grammar and spelling errors. This is a clear and actionable observation that the authors can address to improve the readability and professionalism of their work. However, the comment lacks specific examples or suggestions on how to improve the grammar and spelling errors, which would make it more helpful. Overall, the comment provides a clear direction for improvement but could be more comprehensive with additional guidance. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the consistency of SITE as an estimator of the true average ITE and the assumptions required for it to be a valid estimator. It also questions the loss function being only defined over minibatches and whether this oddball objective function could cause issues. While the comment identifies areas of concern, it does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify these points, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the consistency of SITE as an estimator of the true average ITE and the assumptions required for it to be a valid estimator. It also questions the loss function being only defined over minibatches and whether this oddball objective function causes issues. However, the comment does not specify which part of the paper these questions pertain to, such as specific sections, tables, or figures. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the questions about the estimator and the loss function, but without grounding, it lacks full specificity. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the consistency of SITE as an estimator of the true average ITE and the assumptions required for it to be a valid estimator. It also questions the loss function being only defined over minibatches and whether this oddball objective function causes issues. While the comment identifies potential concerns, it lacks specific examples, references, or detailed reasoning to fully substantiate the claims. The authors would need to make a significant effort to address these questions, as the comment does not provide sufficient guidance or evidence to support the claims. Therefore, the comment is considered somewhat verifiable, as it points out areas for further exploration but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the consistency and validity of SITE as an estimator of the true average ITE. It questions the assumptions required for SITE to be a valid estimator and points out that the loss function is only defined over minibatches, which could impact the validity of the objective function. This feedback is valuable as it prompts the authors to consider the robustness and reliability of their method. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or what assumptions might be required for SITE to be a valid estimator. Overall, the comment is somewhat helpful as it identifies potential issues but lacks detailed guidance on how to resolve them, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the ability of Object-level Interaction Segmentation (OIS) to handle interactive segmentation for multiple objects simultaneously, given the constraints from previous masks. It suggests that the method may struggle to shift focus to a new target object due to these constraints. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the method. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Object-level Interaction Segmentation (OIS)\" and \"Object-level Understanding,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the potential limitation of OIS in handling interactive segmentation for multiple objects simultaneously, due to constraints from previous masks. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the ability of Object-level Interaction Segmentation (OIS) to handle interactive segmentation for multiple objects simultaneously, given the constraints from previous masks. The reviewer supports this claim by referencing the limitations of Object-level Understanding, which relies on Mask Guidance from previous interactions. This reasoning provides a logical basis for the claim, but it lacks specific examples or references to external works that could further substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed evidence or references to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the method's practical utility, specifically the ability of Object-level Interaction Segmentation (OIS) to handle interactive segmentation for multiple objects simultaneously. It raises a concern about the constraints from previous masks, which could affect the method's ability to shift focus to a new target object. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the method. The feedback is somewhat helpful as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the realism of the assumption that anomalies would be aligned with concepts, given that anomaly detection systems are typically used in scenarios where the type of anomalies is unknown. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific steps they could take to improve the assumption. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific assumption made in the paper regarding the alignment of anomalies with concepts. It questions the realism of this assumption, given that anomaly detection systems are typically used in scenarios where the type of anomalies is unknown. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and its implications, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the realism of the assumption that anomalies would be aligned with concepts, given that anomaly detection systems are typically used in scenarios where the type of anomalies is unknown. The reviewer provides a logical reasoning by pointing out that anomaly detection systems are often used in situations where the type of anomalies is not known, such as intrusion and fraud detection. However, the comment lacks specific examples or references to support the claim that the assumption is unrealistic. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable, as it requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the assumption made in the paper regarding the alignment of anomalies with concepts. It points out that anomaly detection systems are typically used in scenarios where the type of anomalies is unknown, such as intrusion and fraud detection. The reviewer questions the realism of the assumption that anomalies would be aligned with concepts, given that the user must have a deep understanding of the domain. This feedback is valuable as it prompts the authors to reconsider the basis of their assumption and potentially revise their approach to better align with real-world scenarios. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what alternative assumptions might be more realistic. Overall, the comment is mostly helpful as it identifies a critical assumption and prompts the authors to reconsider their approach, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that there is a lack of discussion on the current limitations and challenges of HLOP and the experimental design, and it suggests that the authors should include a discussion on the potential downsides of HLOP and limitations of the evaluation process. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of discussion on the current limitations and challenges of HLOP and the experimental design, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a discussion on the potential downsides of HLOP and limitations of the evaluation process. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of discussion on the current limitations and challenges of HLOP and the experimental design, making it difficult to assess the tradeoffs between using HLOP and other approaches. The reviewer suggests that the authors should include a discussion on the potential downsides of HLOP and limitations of the evaluation process. While the comment identifies a specific issue with the paper, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion is logical but could be strengthened with more specific examples or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a clear direction but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the lack of discussion on the current limitations and challenges of HLOP and the experimental design. It suggests that the authors should include a discussion on the potential downsides of HLOP and limitations of the evaluation process. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by addressing these critical aspects. By addressing these limitations, the authors can improve the comprehensiveness and depth of their analysis, which is valuable for the readers. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate the effectiveness of the proposed gating scheme on recently released language models, such as FlanT5 and Llama, in addition to GPT-2. This explicit action provides a clear direction for the authors to expand their evaluation to include these models, which could enhance the contribution of their work. The comment is concrete because it specifies the exact models to be evaluated and the potential benefits of doing so. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating the effectiveness of the proposed gating scheme on recently released language models, such as FlanT5 and Llama, in addition to GPT-2. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in suggesting the inclusion of these models and the potential benefits of doing so, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should evaluate the effectiveness of the proposed gating scheme on recently released language models, such as FlanT5 and Llama, in addition to GPT-2. This claim is somewhat verifiable as it provides a logical reasoning for expanding the evaluation to include these models, which could enhance the contribution of the work. However, the comment lacks specific examples or references to these models, making it somewhat challenging for the authors to fully understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the evaluation of the proposed gating scheme on recently released language models, such as FlanT5 and Llama, in addition to GPT-2. This feedback is valuable as it suggests a way to enhance the contribution of the work by demonstrating the effectiveness of the proposed gating scheme on a broader range of models. By addressing this suggestion, the authors can significantly improve the robustness and impact of their study. However, the comment could be more helpful if it provided specific guidance on how to conduct the evaluation or what specific aspects of the gating scheme should be evaluated on these models. Overall, the comment is mostly helpful as it offers a clear and actionable direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should cite and compare recent works that are highly correlated with their proposed method. It provides a specific example of a work that might be relevant, \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This explicit suggestion gives the authors a clear action to take, which is to include this work in their literature review and discuss its similarities with their proposed method. The comment is concrete and provides a specific example, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should cite and compare recent works that are highly correlated with their proposed method. It provides a specific example of a work that might be relevant, \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This explicit mention of a specific work allows the authors to accurately identify the part of the paper that needs attention. However, the comment does not specify what aspects of the proposed method should be compared or how the comparison should be conducted. While the comment is specific in identifying the need for comparison, it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the authors should cite and compare recent works that are highly correlated with their proposed method. The reviewer provides a specific example of a work that might be relevant, \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This suggestion is based on logical reasoning, as it highlights the need to consider related works in the context of the proposed method. However, the comment lacks detailed justification or specific examples of how the comparison would benefit the paper. Therefore, the claim is somewhat verifiable, as it provides a direction for improvement but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors cite and compare recent works that are highly correlated with their proposed method. It offers a concrete example of a work that might be relevant, \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This feedback is actionable and can help the authors enhance the comprehensiveness and relevance of their literature review. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what aspects of the proposed method should be compared with the cited work. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add more detail about the handling of UNKs by the neural decoder or at least provide a citation to the dictionary-based replacement strategy being used. This feedback is explicit, as it clearly instructs the authors to either add more detail or provide a citation. The action is concrete, as it specifies what additional information is needed, making it easy for the authors to understand and implement the suggestion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding more detail about the handling of UNKs by the neural decoder or providing a citation to the dictionary-based replacement strategy being used. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where this information is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the need for more detail or a citation, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from additional detail about the handling of UNKs by the neural decoder or at least a citation to the dictionary-based replacement strategy being used. However, the comment does not provide any specific reasoning or evidence to support why this additional detail or citation is necessary. Without further explanation or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from additional detail about the handling of UNKs by the neural decoder or at least a citation to the dictionary-based replacement strategy being used. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of more detailed information or a reference to relevant work. However, the comment lacks specific guidance on how to implement this suggestion or what specific details should be included. While it points out a potential gap in the paper, it does not provide actionable steps for the authors to address the issue. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their code summarization method with other SOTA methods, specifically mentioning the use of pre-trained models. While the action is explicit, it lacks concrete details on how to implement this comparison or what specific aspects of the SOTA methods should be compared. The authors are given a clear direction to include this comparison but are left without detailed guidance on how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the code summarization method with other SOTA methods, specifically mentioning the use of pre-trained models. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting the inclusion of a comparison with SOTA methods, but without detailed guidance on where to place it or how to conduct the comparison, the authors may struggle to effectively address the suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their code summarization method with other SOTA methods, specifically mentioning the use of pre-trained models. However, the comment does not provide any supporting evidence, examples, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their code summarization method with other SOTA methods, specifically mentioning the use of pre-trained models. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a comparison that could enhance the paper\\'s contribution. However, the comment lacks specific guidance on how to conduct this comparison or what aspects of the SOTA methods should be considered. While it points out a potential gap in the experimental setup, it does not provide detailed instructions on how to address it. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the results in Table 3, specifically asking for an explanation of why AttendOut has lower variance than Scheduled Bernoulli and requesting the statistical significance value when comparing the two methods. While the comment implies that the authors should provide an explanation or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the results in Table 3, specifically asking for an explanation of why AttendOut has lower variance and requesting the statistical significance value when comparing Scheduled Bernoulli and AttendOut. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions asking for an explanation of the results in Table 3 and requesting statistical significance values. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the results in Table 3, specifically questioning the lower variance of AttendOut compared to Scheduled Bernoulli and requesting statistical significance values for the comparison. This feedback is valuable as it prompts the authors to clarify their findings and provide additional context for readers to understand the results. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how to present the statistical significance values. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results show long-term forecasting but questions the choice of prediction lengths, suggesting that they do not reflect a long-term setting. The reviewer provides a specific suggestion to follow the same settings as the original dataset, such as {96, 192, 336, 720}. This feedback is explicit and provides concrete details on what the authors should change to improve their draft. The action is clear and leaves no ambiguity, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"prediction lengths,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the choice of prediction lengths and the suggestion to follow the same settings as the original dataset. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prediction lengths do not reflect a long-term setting, suggesting that the original dataset settings should be followed. However, the comment does not provide specific reasoning or evidence to support this claim, such as data analysis or comparisons with other datasets. The suggestion is based on a logical inference but lacks detailed justification or references, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the claim, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the prediction lengths do not reflect a long-term setting. It provides a clear and actionable suggestion to follow the same settings as the original dataset, which would help improve the consistency and credibility of the results. This feedback is valuable as it guides the authors to make a straightforward adjustment to their experimental design, ensuring that their results align with the intended long-term setting. However, the comment could be more helpful if it explained why the current settings are not appropriate for a long-term forecasting setting. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an issue with the difference between confidence and accuracy for one sample when using it in Equation. However, it does not provide any guidance on how to address this issue or suggest specific actions for the authors to take. The comment lacks explicit instructions or concrete details on how to improve the draft, leaving the authors uncertain about what changes to make. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the equation (Eq.) and the issue with the difference between confidence and accuracy for one sample. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the problem with the difference between confidence and accuracy, providing a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the difference between confidence and accuracy for one sample is not reasonable when using it in Equation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the difference between confidence and accuracy for one sample when using it in Equation. This is a clear and actionable observation that the authors can address to improve the accuracy and reliability of their results. However, the comment lacks depth and does not provide suggestions on how to resolve this issue or improve the explanation in the paper. While it points out a potential problem, it does not offer detailed guidance or examples to help the authors fully understand and address the issue. Therefore, the comment is somewhat helpful, as it provides a starting point for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the method used to calculate the divergence between a sample and the data, specifically questioning whether it can account for shifts in the sample distribution. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they might need to consider a method to account for shifts in the sample distribution, but the comment lacks concrete suggestions or examples on how to implement this. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the methodology used to calculate the divergence between a sample and the data, questioning whether it can account for shifts in the sample distribution. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the methodology and its potential limitations, suggesting a need for adaptation to account for shifts in the sample distribution. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the method used to calculate the divergence between a sample and the data, specifically questioning whether it can account for shifts in the sample distribution. However, the comment lacks specific examples or references to support the claim that the method may fail in such scenarios. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method used to calculate the divergence between a sample and the data, specifically questioning whether it can account for shifts in the sample distribution. This is a relevant concern that could impact the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or adapt the method to account for shifts in the sample distribution. While it points out a potential weakness, it does not provide actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the replacement of words in a context and suggests that it might lead to incoherent text. The reviewer implies that it would be better to replace the whole phrase instead of individual words. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The authors are left to infer that they should consider replacing phrases instead of individual words, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 076-079,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the replacement of words in a context and suggesting that it might lead to incoherent text. The reviewer provides a specific example of replacing \"w_i\" and its potential impact on \"w_{i-1} and w_{i+1}.\" This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the replacement of words in a context and suggests that it might lead to incoherent text. The reviewer provides a specific example of replacing \"w_i\" and its potential impact on \"w_{i-1} and w_{i+1}.\" This reasoning is logical and based on common sense, as it highlights the importance of considering the context when making such replacements. However, the comment lacks references or detailed examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the replacement of words in a context, suggesting that it could lead to incoherent text. It raises a specific question about the replacement of \"w_i\" and its impact on \"w_{i-1} and w_{i+1}.\" The comment implies that it would be better to replace the whole phrase instead of individual words. While the feedback highlights a potential problem, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their draft. The comment is somewhat helpful as it points out a specific area for consideration, but it could be more beneficial with additional actionable advice or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include runtime comparisons of different deep learning-based methods. While the comment implies that the authors should include this information, it does not provide specific guidance on how to conduct the comparisons or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including runtime comparisons of different deep learning-based methods, but it does not specify which part of the paper should include this information. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion to include runtime comparisons, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that runtime comparisons of different deep learning-based methods would be desirable. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include runtime comparisons of different deep learning-based methods. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, which could enhance its comprehensiveness and depth. However, the comment lacks specific guidance on how to conduct these comparisons or what aspects to focus on, leaving the authors with a general suggestion that requires further exploration and elaboration. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explore and compare ECG-specific architectures using SSL or transformer-based architectures to significantly improve the current ECG encoder. This feedback provides a clear and explicit action for the authors to take, which is to explore and compare these architectures. The comment also specifies which parts of the framework should be considered, making it concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ECG encoder,\" \"modality alignment,\" and \"LLM backbone,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the exploration and comparison of ECG-specific architectures using SSL or transformer-based architectures to improve the current ECG encoder. This provides clear guidance on what the authors should consider and how to enhance their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ECG encoder in the MEIT framework is not as advanced as other parts of the framework, such as modality alignment and LLM backbone, and that there are many ECG-specific architectures using SSL or transformer-based architectures that could significantly improve the current ECG encoder. The comment provides a logical reasoning by comparing the current ECG encoder with other parts of the framework and suggesting that exploring ECG-specific architectures could enhance its performance. However, the comment lacks specific examples or references to these architectures, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a logical argument but requires more detailed evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the MEIT framework, specifically the ECG encoder, which is currently limited to using several 1-D CNN layers and average pooling. It suggests that the authors should explore and compare ECG-specific architectures using SSL or transformer-based architectures, similar to how different methods were explored for the other parts of the framework. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their work. By suggesting specific architectures to consider, the comment offers a meaningful and constructive suggestion that can significantly improve the draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rephrase the abstract to accurately reflect the focus of the paper, which is a model-agnostic explainability technique for deep neural networks. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is highly actionable as it specifies the exact change needed in the abstract, making it easy for the authors to implement the suggested revision.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, which suggests that a defense methodology is proposed when the paper actually presents a model-agnostic explainability technique for deep neural networks. The comment provides a clear and detailed suggestion for rephrasing the abstract to avoid confusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract inaccurately suggests a defense methodology is proposed when the paper actually presents a model-agnostic explainability technique for deep neural networks. The reviewer provides a clear and specific critique of the abstract, which is supported by the logical reasoning that the paper does not propose a defense methodology. This claim is fully verifiable as it is based on a clear understanding of the content and structure of the paper, making it easy for the authors to understand and address the issue. Therefore, the comment is labeled as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that it inaccurately suggests a defense methodology is proposed when the paper actually presents a model-agnostic explainability technique for deep neural networks. It provides a clear and actionable suggestion to rephrase the abstract to accurately reflect the focus of the paper. This feedback is valuable as it guides the authors to correct an inaccuracy in the abstract, ensuring that the paper accurately represents its content. However, the comment could be more helpful if it offered additional guidance on how to effectively rephrase the abstract to better convey the paper\\'s focus. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the paper lacks comparisons to recent methods that propose new activation functions for INRs, such as FINER [1], Incode [2], and SL2A-INR [3]. This provides a clear and specific action for the authors to take, which is to include these comparisons in their analysis. The comment is explicit and concrete, as it directly identifies the missing comparisons and suggests how to address them. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific methods (e.g., FINER, Incode, and SL2A-INR) that the paper should compare with. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added, namely comparisons to these recent methods that propose new activation functions for INRs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons to recent methods that propose new activation functions for INRs, specifically mentioning FINER [1], Incode [2], and SL2A-INR [3]. However, the comment does not provide any supporting evidence or references to these methods, making it difficult for the authors to understand the relevance or impact of these comparisons. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that the paper lacks comparisons to recent methods that propose new activation functions for INRs. It mentions specific methods, such as FINER [1], Incode [2], and SL2A-INR [3], which the authors should consider including in their analysis. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by including these comparisons. However, the comment could be more helpful if it explained why these comparisons are important or how they might impact the paper\\'s conclusions. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation setting can be improved by challenging the value of research on length extrapolation, as long as the models are finetuned. However, it does not provide specific guidance on how to improve the evaluation setting or what aspects of the evaluation should be challenged. The comment lacks actionable details, such as recommending specific modifications or experiments to conduct. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the evaluation setting can be improved by challenging the value of research on length extrapolation, as long as the models are finetuned. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the evaluation or methodology sections, but this inference is not direct. The comment is specific in suggesting that the evaluation setting should be challenged, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a straightforward method, such as the one mentioned in the external reference, works well in practice and challenges the value of research on length extrapolation. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim that the method challenges the value of research. As a result, the claim is somewhat verifiable, as it requires more detailed justification to be fully understood and accepted by the authors.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the evaluation setting can be improved by challenging the value of research on length extrapolation, as long as the models are finetuned. It provides a general direction for improvement but lacks specific guidance or suggestions on how to implement this challenge or what aspects of the evaluation should be reconsidered. While it points out a potential area for improvement, the comment does not offer actionable steps or detailed advice on how to address the issue. Therefore, it is somewhat helpful, as it provides a general direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the training and testing environments in Section 2.4, specifically asking which environment is the training one and which are the testing ones. It also suggests that cross-validation testing would be preferable to demonstrate the robustness of the results. While the comment implies that the authors should clarify this information and potentially conduct cross-validation testing, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the training and testing environments, asking which environment is the training one and which are the testing ones. It also suggests that cross-validation testing would be preferable to demonstrate the robustness of the results. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training and testing environments in Section 2.4, specifically asking which environment is the training one and which are the testing ones. It also suggests that cross-validation testing would be preferable to demonstrate the robustness of the results. While the comment does not make a subjective claim or opinion, it does ask for clarification and suggests an improvement. Therefore, it is classified as \"Somewhat Verifiable,\" as it provides a logical request for additional information and a potential enhancement.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, specifically the training and testing environments mentioned in Section 2.4. It raises a question about which environment is the training one and which are the testing ones, and suggests that cross-validation testing would be preferable to demonstrate the robustness of the results. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and robustness of the paper. By addressing this point, the authors can enhance the transparency and credibility of their work. Therefore, the comment is rated as mostly helpful, as it offers valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of comparison to demonstrate the improvement in generation quality due to refinement during inference. It suggests that while the statistic of the number of refinements is informative, it does not necessarily indicate an improvement. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects should be compared. The action is implicit and somewhat vague, as the authors can infer that they need to include a comparison but may not be entirely sure of the exact details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of a comparison to demonstrate the improvement in generation quality due to refinement during inference. It suggests that while the statistic of the number of refinements is informative, it does not necessarily indicate an improvement. However, the comment does not specify which part of the paper should include this comparison or how it should be presented. The authors can infer that it relates to the results or discussion sections, but the lack of explicit grounding makes it weakly grounded. The comment is specific in its critique of the lack of comparison and the need for an improvement in the paper, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of comparison to demonstrate the improvement in generation quality due to refinement during inference. It suggests that while the statistic of the number of refinements is informative, it does not necessarily indicate an improvement. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of a comparison to demonstrate the improvement in generation quality due to refinement during inference. It acknowledges the inclusion of a statistic on the number of refinements but points out that this alone does not necessarily indicate an improvement. The comment provides a clear and actionable suggestion for the authors to include a comparison to show the impact of refinement on generation quality. This feedback is valuable as it guides the authors to enhance their experimental design and presentation, ensuring that their results are more robust and convincing. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct the comparison. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: \"something missing (threshold?)\" regarding a specific section and \"did you do this partitions randomly?\" regarding the methodology. While these questions imply that the authors should clarify or provide additional information, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it addresses, such as a specific section, table, or figure. It lacks specificity because it does not provide details on what is missing or what needs to be clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of questions asking for clarification or additional information. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that could help the authors improve their draft. The first question, \"something missing (threshold?),\" suggests that there might be a missing element or detail in the section regarding \"PMI.\" This prompts the authors to clarify or provide additional information in that section. The second question, \"did you do this partitions randomly?\", asks about the methodology and whether the partitions were randomly generated. While these questions are somewhat helpful in identifying potential areas for improvement, they do not provide specific guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it points out potential gaps in the paper, but it could be more actionable with more detailed guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: \"How long will the MDP take?\" and \"Could you provide the training time comparison of MDP and ImageNet pretraining + individual dataset fine-turning?\" These questions are explicit and ask for specific information to be included in the paper. The first question seeks an estimation of the time required for the MDP, while the second question requests a comparison of training times between the MDP and other methods. While the questions are clear, they do not provide explicit guidance on how to present this information in the paper. However, the authors can infer that they need to include this information in their work, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises two questions about the MDP and its training time comparison with other methods. However, it does not specify which part of the paper these questions pertain to, such as a particular section or figure where this information is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The questions themselves are specific, as they ask for time comparisons and an estimation of the MDP's training time. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for specific information about the MDP and its training time comparison with other methods. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that could be beneficial for the authors to address in their paper. The first question asks for an estimation of the time required for the MDP, which could be relevant for understanding the computational complexity of the model. The second question seeks a training time comparison between the MDP and ImageNet pretraining + individual dataset fine-turning, which could provide valuable insights into the performance of the MDP relative to other methods. While these questions are clear and actionable, the comment could be more helpful if it offered suggestions on how to present this information in the paper or provided additional context on why this comparison is important. Overall, the comment is mostly helpful as it directs the authors to include relevant information that could enhance the clarity and comprehensiveness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the author claims G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE, but it notes that the fundamental structure of G-PDE is an incremental improvement upon GraphCON[1], where the static encoder is substituted by SNN. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific changes should be made to improve the paper. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about G-PDE being intentionally designed to leverage the advantages of both spike ODE and graph ODE. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out that the fundamental structure of G-PDE is an incremental improvement upon GraphCON[1], where the static encoder is substituted by SNN. This provides clear guidance on what needs to be addressed in the paper, namely the comparison with GraphCON and the rationale behind the incremental improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the author claims G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE. However, the reviewer notes that the fundamental structure of G-PDE is an incremental improvement upon GraphCON, where the static encoder is substituted by SNN. This claim is somewhat verifiable as it provides a logical reasoning for the comparison with GraphCON, but it lacks specific references or detailed evidence to fully substantiate the claim. The authors might need to further explore the basis of the incremental improvement and how it relates to the original GraphCON work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim made by the authors regarding the design of G-PDE. It points out that the fundamental structure of G-PDE is an incremental improvement upon GraphCON, where the static encoder is substituted by SNN. This feedback is somewhat helpful as it highlights a potential misrepresentation in the paper\\'s claims, which could be clarified or addressed by the authors. However, the comment lacks specific suggestions on how the authors might clarify or correct this issue, leaving some room for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method does not significantly outperform Jiang et al. in certain metrics, specifically mentioning the differences in Penetration(Dep), CR, and Sim-Disp(Mean). However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it guide the authors on how to address the issue of not outperforming Jiang et al. The comment lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific metrics (Penetration(Dep), CR, and Sim-Disp(Mean)) and the comparison with Jiang et al., allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the proposed method does not significantly outperform Jiang et al. in these metrics. This provides clear guidance on what needs to be improved or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not significantly outperform Jiang et al. in certain metrics, specifically mentioning the differences in Penetration(Dep), CR, and Sim-Disp(Mean). The comment provides specific numerical values for the performance of the proposed method and Jiang et al., which supports the claim by providing concrete evidence. This makes the claim mostly verifiable, as it provides a clear comparison and basis for the claim. However, the comment could be strengthened by including additional context or references to similar studies, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights a significant issue with the proposed method, noting that it does not significantly outperform Jiang et al. in certain metrics. It provides specific numerical values to illustrate the performance gap, which is valuable information for the authors. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue, such as by providing additional context or analysis to explain the performance discrepancy. Despite this, the feedback is still somewhat helpful as it points out a critical area for improvement and provides some guidance for the authors to consider. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of comparison or mention of related work in the context of \"vFSAD\" and suggests that the related work subtitles of \"Policy\" and \"Evaluation tasks\" are not descriptive and unrelated to the actual content. However, it does not provide explicit guidance on how to address these issues, such as suggesting specific works to compare with or how to improve the descriptiveness of the subtitles. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information about related work and the subtitles. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"vFSAD\" and the related work subtitles of \"Policy\" and \"Evaluation tasks,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison or mention of related work in the context of \"vFSAD\" and the unrelatedness of the related work subtitles. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"vFSAD\" refers to OOD detection in time-series data and suggests that there is a lack of comparison or mention of related work in this context. The reviewer provides a specific reference to a related work by Kaur et al., \"CODiT: Conformal Out-of-Distribution Detection in Time-Series Data,\" which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the lack of comparison or mention of related work impacts the paper. Overall, the claim is mostly verifiable due to the reference to a specific work, but it could be further substantiated with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the term \"vFSAD\" is not clearly defined and that related work in the context of OOD detection in time-series data has not been compared or mentioned. It also points out that the related work subtitles of \"Policy\" and \"Evaluation tasks\" are not descriptive and seemingly unrelated to the content. This feedback is somewhat helpful as it highlights areas where the paper could be improved by providing more detailed explanations and references. However, it lacks specific suggestions on how to address these issues, such as recommending specific works to compare with or providing guidance on how to improve the related work subtitles. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but does not fully guide the authors on how to implement those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that an ablation study should be added to clarify the effect of memory size on the model. This provides a clear and direct action for the authors to take, ensuring that they understand the importance of including this additional analysis. The comment is specific in its request for an ablation study and provides a concrete action for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"effect of memory size\" and suggests adding an ablation study to clarify the memory size selection. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of an ablation study to clarify the effect of memory size. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effect of memory size is ambiguous and suggests adding an ablation study to justify the memory size selection. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. It lacks specific examples or references to similar studies that have addressed this issue, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the ambiguity of the effect of memory size. It suggests that an ablation study should be added to justify the memory size selection. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by adding an additional analysis. However, the comment could be more helpful if it explained why an ablation study is necessary or how it would benefit the paper. Despite this, the suggestion is valuable and provides a clear direction for the authors to enhance their draft. Therefore, the comment is rated as mostly helpful, consistent with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the abbreviation \"GNN\" being used without its full definition \"Graph Neural Network (GNN)\" being provided earlier in the paper. This is a clear and explicit action for the authors to take, as it directly instructs them to include the full definition earlier in the paper. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 1\" and \"Section 2, at the end of page 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the full definition of \"Graph Neural Network (GNN)\" earlier in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights an issue with the abbreviation \"GNN\" being used without its full definition \"Graph Neural Network (GNN)\" being provided earlier in the paper. This is a factual observation about the organization and presentation of the paper, which does not contain subjective opinions, judgments, or suggestions. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization and presentation of the paper, noting that the abbreviation \"GNN\" is used without its full definition \"Graph Neural Network (GNN)\" being provided earlier in the paper. This is a clear and actionable feedback that can help the authors improve the clarity and consistency of their paper. By addressing this issue, the authors can ensure that their readers have a better understanding of the concepts and terminology used in their work. However, the comment could be more helpful if it provided suggestions on how to present the full definition earlier in the paper or offered guidance on how to improve the overall flow and organization. Overall, the comment is mostly helpful as it highlights a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the performance of baseline methods on the DAVIS dataset, comparing them to state-of-the-art results. It also notes that the proposed loss function may not be effective on top-performing methods. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or suggestions for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the DAVIS dataset and the performance of baseline methods compared to state-of-the-art results. It also references specific works, such as [1] and [2], which allows the authors to accurately identify the parts of the paper being addressed. The comment is specific because it clearly points out the issue of low performance for baseline methods and the potential ineffectiveness of the proposed loss function on top-performing methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of baseline methods on the DAVIS dataset is low compared to state-of-the-art results, citing specific examples like 65.6% J mean on 2019-val by [1]. The reviewer also references [2] to support the claim about the effectiveness of the proposed loss function on baseline methods. This provides a logical basis for the claim, as it compares the performance of the baseline methods to the state-of-the-art results. However, the comment could be strengthened by providing more detailed analysis or references to specific studies that demonstrate the effectiveness of the proposed loss function on top-performing methods. Overall, the claim is mostly verifiable, as it is supported by relevant references and logical reasoning.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of baseline methods on the DAVIS dataset, noting that it is lower than state-of-the-art results. It also highlights the potential ineffectiveness of the proposed loss function on top-performing methods. This feedback is somewhat helpful as it points out a specific area for improvement, but it lacks detailed guidance or suggestions on how the authors might address this issue. The comment could be more helpful if it provided suggestions on how to improve the performance of the baseline methods or offered insights into how the proposed loss function might be adapted to work better with top-performing methods. Overall, the comment provides some direction but could be more actionable and comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the results for the proposed two-step decoding method, specifically asking if the results are reported in the paper and whether they are included in Table 1 with decoder downsampling. The reviewer also inquires about the performance of the two-step method without the proposed method. While the comment identifies areas of uncertainty, it does not provide explicit instructions or concrete steps for the authors to address these questions. The authors are left to infer that they need to clarify the results and performance of the two-step method, but the comment lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proposed two-step decoding method\" and \"Table 1 with decoder downsampling,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for clarification on whether the results for the two-step method are reported in the paper and whether they are included in Table 1 with decoder downsampling. The comment also inquires about the performance of the two-step method without the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the results for the proposed two-step decoding method, specifically asking if the results are reported in the paper and whether they are included in Table 1 with decoder downsampling. The reviewer also inquires about the performance of the two-step method without the proposed method, asking how much worse it performs. While the comment identifies a potential gap in the paper, it does not provide specific examples or references to support the claim that the results are missing or unclear. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to further investigate the results to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the results for the proposed two-step decoding method, asking if the results are reported in the paper and whether they are included in Table 1 with decoder downsampling. It also inquires about the performance of the two-step method without the proposed method, asking how much worse it performs. This feedback is clear and actionable, as it directs the authors to clarify and potentially expand their results section to address these questions. By doing so, the authors can improve the clarity and completeness of their paper, making it more comprehensible to readers. However, the comment could be more helpful if it provided suggestions on how to present the results or what specific aspects to focus on. Overall, the comment is mostly helpful as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to increase the font size in the figures to improve readability. This is a clear and direct action that the authors can take to address the issue. The comment provides a specific suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"figures,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small and suggests an action to increase it for improved readability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a request to increase the font size in the figures to improve readability. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual statement about the presentation of the figures, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides a specific and actionable suggestion to improve the readability of the figures by increasing the font size. This is a clear and direct piece of feedback that the authors can easily implement to enhance the clarity and accessibility of their figures. By addressing this issue, the authors can significantly improve the presentation and usability of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the experiments only consider synthetic problems, suggesting that the authors should consider real-world problems as well. However, it does not provide specific guidance on how to incorporate real-world problems or which ones to consider. The action is implicit and somewhat vague, as the authors can infer that they need to expand their experiments to include real-world problems but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments only consider synthetic problems, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or experiment is being addressed, making it weakly grounded. However, the comment is specific in pointing out the issue of only considering synthetic problems. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments only consider synthetic problems. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential limitation in the experiments, noting that they only consider synthetic problems. This is a relevant observation that could impact the generalizability and applicability of the results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending the inclusion of real-world problems or providing examples of how to incorporate them. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should compare their natural language explanation (NLE) tool with other NLE interpretability tools. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and provides concrete guidance on how to enhance the comparative analysis of their NLE tool. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"NLE baselines\" and the \"feature attribution type of explanations,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should compare their NLE tool with other NLE interpretability tools. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should compare their natural language explanation (NLE) tool with other NLE interpretability tools. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should compare their natural language explanation (NLE) tool with other NLE interpretability tools. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the comparative analysis of the NLE tool. By addressing this point, the authors can improve the comprehensiveness and rigor of their evaluation. However, the comment could be more helpful if it provided examples of other NLE interpretability tools or detailed guidance on how to conduct the comparison. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the use of only one pertinent positive data point in Eq. (5) and suggests that there are many data points that satisfy Eq. (1) and (2) but are not included in Eq. (5). It points out that these data points contribute equally to Eq. (3) but have different perturbation directions. The comment implies that the authors should include the exhaustive test over the diversity of these data points in Eq. (5). While the action is implicit, it is clear that the authors need to expand their analysis to include these additional data points. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (5)\" and \"pertinent positive data point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more data points that satisfy Eq. (1) and (2) and the need to test the diversity of these data points in Eq. (5). Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that only one pertinent positive data point is used in Eq. (5), while many data points that satisfy Eq. (1) and (2) are not included. The reviewer suggests that these data points contribute equally to Eq. (3) but have different perturbation directions. The comment provides a logical reasoning by pointing out the potential omission of important data points and their contribution to the analysis. However, it lacks specific examples or references to support the claim that these data points are pertinent or how they would impact the analysis. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that only one pertinent positive data point is used in Eq. (5) while many other data points that satisfy Eq. (1) and (2) are not included. It points out that these data points contribute equally to Eq. (3) but have different perturbation directions. The comment suggests that the authors should include the exhaustive test over the diversity of these data points in Eq. (5), which could significantly enhance the robustness and comprehensiveness of the analysis. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft. However, it could be more helpful if it included specific examples or guidance on how to implement this suggestion. Overall, the comment is mostly helpful as it effectively highlights a potential weakness and offers a concrete suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison of the document augmentation method with existing supervised retrievers, such as InPars-V2 and Promptagator. It also recommends showing how this augmentation can enhance the performance of the existing supervised retriever, both with and without augmented queries or documents. While the comment provides a clear direction for the authors to include this comparison, it does not specify how to implement it or what specific aspects to focus on. The action is explicit but somewhat vague in terms of execution, as the authors need to determine the exact methodology and analysis to include in the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results being compared fully without using supervision data, specifically mentioning InPars-V2 and Promptagator as examples. It also suggests including a comparison with existing supervised retrievers, which provides clear guidance on what needs to be addressed. The comment is specific in recommending a comparison of document augmentation with existing supervised retrievers and how it can enhance the performance of the existing retriever model. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results are compared fully without using supervision data and suggests including a comparison with existing supervised retrievers. The reviewer provides a logical reasoning by explaining that it would be beneficial to show how document augmentation can enhance the performance of existing supervised retrievers. However, the comment lacks specific examples or references to support the claim that existing supervised retrievers could be used for comparison. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results section, noting that the results are compared fully without using supervision data. It suggests that it would be beneficial to include a comparison with existing supervised retrievers, such as InPars-V2 and Promptagator, to demonstrate how document augmentation can enhance the performance of existing supervised retrievers. The comment provides a clear and actionable suggestion for improvement, offering a specific direction for the authors to consider. However, it could be more helpful if it included examples or detailed guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the cache hierarchy is not discussed, specifically mentioning the order in which the three dimensions are applied, the data they might share, and how they are applied together. It also notes that the individual levels are discussed in their construction and details but not how they are applied together, except for the independence of their memory benefits. This feedback implies that the authors should provide a more detailed explanation of the cache hierarchy, including its application and the sharing of data across levels. However, the comment does not explicitly instruct the authors to do so, leaving some ambiguity in the action. While the action is clear, it is somewhat vague in terms of execution, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the cache hierarchy, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the cache hierarchy is not discussed, including the order in which the three dimensions are applied, the data they might share, and how they are applied together. The comment also notes that the individual levels are discussed in their construction and details but not how they are applied together, except for their independence in memory benefits. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the cache hierarchy is not discussed, specifically mentioning the order in which the three dimensions are applied, the data they might share, and how they are applied together. The reviewer also notes that the individual levels are discussed in their construction and details but not how they are applied together, except for their independence in memory benefits. This claim is somewhat verifiable as it highlights a gap in the paper\\'s discussion of the cache hierarchy, but it lacks specific examples or references to support the claim fully. The authors would need to make a significant effort to understand and address the issue, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the cache hierarchy, specifically mentioning the order in which the three dimensions are applied, the data they might share, and how they are applied together. It points out that the individual levels are discussed in their construction and details but not how they are applied together, except for their independence in memory benefits. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the cache hierarchy and its application, which is crucial for understanding the paper\\'s claims. By addressing this issue, the authors can significantly improve the clarity and completeness of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors managed to prevent the Out-of-Memory (OOM) issue during pretraining, given that Figure 2 suggests that forward propagation is performed three times before backpropagation. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete suggestions on how to manage GPU memory. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation or solution to this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about how the authors managed to prevent the Out-of-Memory (OOM) issue during pretraining, given the forward propagation pattern in Figure 2. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about how the authors managed to prevent the Out-of-Memory (OOM) issue during pretraining, given the forward propagation pattern in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the methodology used in the paper, specifically regarding the forward propagation pattern in Figure 2 and its implications for managing GPU memory during pretraining. This is a relevant and important point that could impact the performance and scalability of the model. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite and improve the abstract, stating that it is not well written and difficult to understand the contributions. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to enhance the clarity of their abstract. The comment is specific in its request for a rewrite, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Abstract\" and provides a clear direction for improvement by recommending that it be rewritten and better presented. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what needs to be improved, namely the clarity and understanding of the contributions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract is not well written and difficult to understand the contributions. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specificity and does not offer guidance on how to improve the abstract, making it difficult for the authors to address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, stating that it is not well written and difficult to understand the contributions. It provides a clear and actionable suggestion to rewrite and improve the abstract, which is crucial for ensuring that the paper effectively communicates its contributions. However, the comment could be more helpful if it offered specific guidance on how to improve the clarity and structure of the abstract. Overall, the feedback is somewhat helpful as it directs the authors to a critical area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that ADE is a dataset for image parsing, which may be biased and favor the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this potential bias or how to mitigate its impact on the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ADE,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that ADE is a dataset for image parsing, which may be biased and favor the performance of the proposed method. This provides clear guidance on what needs to be addressed regarding potential biases in the dataset. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ADE, a dataset for image parsing, may be biased and favor the performance of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that ADE is a dataset for image parsing, which may be biased and favor the performance of the proposed method. However, it does not provide any actionable feedback or suggestions on how the authors might address this potential bias or mitigate its impact on the results. Without specific guidance or recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the use of two matrices in section 2.1.2 and suggests that the authors might explain why two matrices are used. It also points out that many matrices are not used in the following text. While the comment implies that the authors should clarify the purpose of using two matrices, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of two matrices and points out that many matrices are not used in the following text. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of two matrices in section 2.1.2 and suggests that they might be the same. It also points out that many matrices are not used in the following text. While the comment raises a logical question, it lacks specific examples or references to support the claim that the matrices are the same or that many are unnecessary. This makes the claim somewhat verifiable, as the authors would need to further investigate and clarify the issue themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper regarding the use of two matrices in section 2.1.2 and questions their necessity. It also points out that many matrices are not used in the following text. This feedback is clear and actionable, as it prompts the authors to clarify the purpose of using two matrices and potentially justify their use. By addressing these questions, the authors can improve the clarity and coherence of their paper. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the statement \"the semantics of the upsampled feature map can be stronger than the original one.\" However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to improve the clarity. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of the statement \"the semantics of the upsampled feature map can be stronger than the original one.\" This provides clear guidance on what needs to be clarified or addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the statement \"the semantics of the upsampled feature map can be stronger than the original one,\" indicating a lack of clarity. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that this statement is unclear or misleading. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a lack of clarity regarding the statement \"the semantics of the upsampled feature map can be stronger than the original one.\" This feedback is somewhat helpful as it identifies a potential area of confusion in the paper, which could be clarified to improve the reader's understanding. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as offering alternative explanations or examples. While it highlights an area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify the differences between their method and other methods used to predict user personality, such as the one mentioned in reference [1]. While the comment implies that the authors should provide a comparison, it does not explicitly instruct them to do so or offer specific guidance on how to present this comparison. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison but may not be entirely sure of the exact details or approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to clarify the differences between the method and other methods used to predict user personality, such as the one mentioned in reference [1]. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the need to clarify the differences between the method and other methods used for personality prediction. Therefore, this comment is labeled as fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the differences between their method and other methods used to predict user personality, such as the one mentioned in reference [1]. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these differences need to be clarified. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors clarify the differences between their method and other methods used to predict user personality, such as the one mentioned in reference [1]. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by explaining the unique aspects of their method compared to others. However, the comment could be more helpful if it included specific suggestions on how to present this comparison or what aspects to emphasize. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the rationale behind the choice of tuning parameters in LoRA, specifically the basis and coordinate parameters. It questions the theoretical basis for the acceleration of convergence and suggests that the authors should consider the freedom of vanilla LoRA parameters. Additionally, it points out that constant step size is sufficient in theory but that step size tuning is still needed for experiments. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The authors are left to infer that they need to clarify the rationale behind the tuning parameters and consider step size tuning, but the comment lacks concrete details on how to implement these improvements. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific concerns about the tuning parameters in LoRA, particularly the basis and coordinate parameters, and questions the theoretical basis for the acceleration of convergence. It also mentions the need for step size tuning in experiments. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental setup or theoretical analysis sections. The comment is specific in detailing what needs to be clarified or addressed, such as the theoretical basis for the tuning parameters and the need for step size tuning. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the theoretical basis of the tuning parameters in LoRA and suggests that the authors should consider the freedom of vanilla LoRA parameters compared to constraining $B$ to be on $B^TB=I$. While the comment identifies a potential issue with the theoretical basis, it lacks specific examples or references to support the claim that vanilla LoRA parameters have more freedom. The comment also suggests that constant step size is sufficient in theory but that step size tuning is still needed for experiments. However, it does not provide detailed reasoning or evidence to substantiate these claims, making the comment somewhat verifiable. The authors would need to further explore the theoretical basis and experimental results to fully understand and address the reviewer\\'s concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical basis of the tuning parameters in LoRA, questioning why imposing certain parameters would accelerate convergence. It also points out that constant step size is sufficient in theory but that step size tuning is still needed for experiments. This feedback is somewhat helpful as it highlights a potential weakness in the theoretical justification and suggests a potential area for improvement. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or what additional experiments or analyses might be needed. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct more ablation studies or analyses on problems other than the shortest path problem, which is closely related to the experimental environments. This feedback implies that the authors should expand their experimental scope to include a broader range of problems, which is a clear and explicit action. However, the comment does not provide specific guidance on which problems to focus on or how to conduct these analyses. While the action is clear, the lack of concrete details on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"design of architecture (PathGNN)\" and the \"shortest path problem,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that more ablation studies or analyses should be conducted on problems other than the shortest path problem. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental environments are closely related to the shortest path problem and that the design of the architecture (PathGNN) is biased towards this problem. The comment recommends conducting more ablation studies or analyses on problems other than the shortest path problem to make the work more convincing. While the claim is based on logical reasoning, it lacks specific examples or references to support the claim that other problems are more relevant or beneficial for the analysis. This makes the comment somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the experimental setup, noting that most environments are closely related to the shortest path problem, which may bias the design of the architecture (PathGNN). It suggests that conducting more ablation studies or analyses on problems other than the shortest path problem would make the work more convincing. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental scope and demonstrate the generalizability of their approach. However, the comment could be more helpful if it offered examples of other problems that could be explored or provided guidance on how to conduct these analyses. Overall, the comment is mostly helpful as it effectively points out a potential weakness and suggests a way to address it, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more recent models, especially in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. While the comment implies that the authors should expand their comparison to include additional models, it does not provide specific guidance on which models to include or how to integrate them into the existing comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more recent models, especially in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the comparison section, but this inference is not direct. The comment is specific in suggesting the inclusion of more recent models, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more recent models, especially in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. However, the comment does not provide any specific examples or references to support the claim that these additional models would be beneficial or necessary. Without such evidence or reasoning, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could include more recent models, especially in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting the inclusion of additional models. However, the comment lacks specificity and does not provide guidance on which models to include or how they would enhance the comparison. While it points out a potential gap in the paper, the lack of detailed suggestions limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of visualization for the learned context token, which could help demonstrate the difference in context tokens for different groups. It also notes that the paper is simple and effective but lacks novelty and analysis for the insight of the approach. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include visualizations and conduct additional analysis to enhance the novelty and insight of their work. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement these improvements. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of visualization for the learned context token, which is a specific aspect of the paper. It also mentions that the paper is simple and effective but lacks novelty and analysis, providing a general critique. However, it does not specify which part of the paper should include visualization or analysis, making it weakly grounded. The comment is specific in identifying the need for visualization and analysis, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and analysis, specifically mentioning the absence of visualization for the learned context token. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of visualization for the learned context token, which could help demonstrate the difference in context tokens for different groups. It also notes that the paper is simple and effective but lacks novelty and analysis for the insight of the approach. While the comment highlights areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The authors are left to infer that they should include visualizations and conduct additional analysis, which could enhance the novelty and insight of their work. However, the comment lacks specificity and actionable steps, making it somewhat helpful but not comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should report results for other models besides MetaOptNet in the experimental section. This provides a clear and concrete action for the authors to take, as it directly instructs them to expand their experimental results to demonstrate the generality of their method. The comment also highlights the importance of this action by emphasizing that it would strengthen the paper. Therefore, the comment is highly actionable, as it gives the authors a specific and direct way to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to report results for other models besides MetaOptNet to emphasize the generality of the method and demonstrate its improvement over several baseline models. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental section is a concern because the current results only show small benefits over the baseline model. The reviewer recommends reporting results for other models besides MetaOptNet to emphasize the generality of the method and demonstrate its improvement over several baseline models. This claim is somewhat verifiable as it logically suggests that expanding the experimental results could strengthen the paper. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern in the experimental section, noting that the current results only show small benefits over the baseline model. It suggests that reporting results for other models besides MetaOptNet would strengthen the paper by emphasizing the generality of the method and demonstrating its improvement over several baseline models. This feedback is clear and actionable, providing the authors with a direct and concrete suggestion for enhancing their experimental section. By addressing this point, the authors can significantly improve the robustness and impact of their results. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should include a more extensive comparison by including well-established methods like FTML[1] and LFW[2]. This provides a clear and concrete action for the authors to take, as it specifies exactly what additional comparisons are needed to enhance the evaluation of their proposed method. The comment is specific in identifying the missing elements and provides a direct path for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparison by including well-established methods like FTML[1] and LFW[2]. However, it does not specify which part of the paper this additional comparison should be included in, such as the results or discussion sections. While the authors might infer that it relates to the evaluation or comparison sections, the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of what additional methods should be included, but without clear grounding, it is weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparison by including well-established methods like FTML[1] and LFW[2]. This claim is somewhat verifiable as it logically suggests that a broader comparison would provide a more comprehensive evaluation of the proposed method. However, the comment lacks specific examples or references to these methods, which would strengthen the claim by providing a clearer rationale for why these methods are relevant and how they could enhance the evaluation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically the lack of a more extensive comparison with well-established methods like FTML[1] and LFW[2]. This feedback is clear and actionable, as it suggests that including these methods would provide a more comprehensive evaluation of the proposed method's strengths and weaknesses. By suggesting specific comparisons, the comment offers a concrete direction for improvement that could enhance the paper\\'s rigor and credibility. However, it could be more helpful if it provided additional context or rationale for why these methods are particularly relevant or how they might impact the evaluation. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the proposed CRF variants underperform the hierarchical transformers (HiTRF) in both the main dataset and the dataset discussed in Appendix D. It suggests that the focus of the paper should be downgraded and provides a rationale for this by pointing out the underperformance. Additionally, it notes that location embeddings seem to provide additional information on the main dataset but not in the extra dataset (Appendix D). However, it does not provide specific guidance on how the authors should address this issue or what changes should be made to the paper. The comment is explicit in identifying the problem but lacks concrete details on how to implement the suggested downgrade or discuss the implications of the findings. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed CRF variants\" and \"hierarchical transformers (HiTRF)\" in the main dataset and the dataset discussed in Appendix D, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the CRF variants underperform the hierarchical transformers and that location embeddings seem to provide additional information on the main dataset but not in the extra dataset (Appendix D). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed CRF variants underperform the hierarchical transformers (HiTRF) in both the main dataset and the dataset discussed in Appendix D. It also notes that location embeddings seem to provide additional information on the main dataset but not in the extra dataset (Appendix D). This provides some evidence for the claim, as it suggests that the CRF variants may not be as effective as the hierarchical transformers. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim. The authors would need to conduct their own experiments to verify the claim fully. Therefore, the comment is somewhat verifiable, as it provides some evidence but requires further validation.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed CRF variants, noting that they underperform the hierarchical transformers (HiTRF) in both the main dataset and the dataset discussed in Appendix D. This is a critical finding that challenges the focus of the paper on modeling this task using a CRF. The comment also highlights a potential limitation of location embeddings, suggesting that they may be useful for specific types of datasets only. However, it does not provide specific suggestions or guidance on how the authors might address these issues or discuss the implications of the findings. While the comment identifies important areas for improvement, it lacks actionable advice or detailed feedback, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the impact of the training-testing inconsistency is not clear. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or what specific aspects of the training-testing inconsistency are unclear. There is no guidance on how to clarify the impact or what steps to take to improve the clarity. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the impact of the training-testing inconsistency is not clear, but it does not specify which part of the paper this issue is discussed in. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the training-testing inconsistency are unclear or how they could be clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the impact of the training-testing inconsistency is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, namely the lack of clarity regarding the impact of the training-testing inconsistency. However, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the training-testing inconsistency are unclear. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it points out a weakness but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the unclear condition for y membership and claims that are not backed up. However, it does not provide specific guidance on how to address these issues. The comment implies that the authors should clarify the condition for y membership and provide more detailed explanations or evidence to support their claims, but it does not offer concrete steps or examples of what this clarification should entail. As a result, the authors are left with a general idea of what needs to be improved but without specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the unclear condition for y membership and claims that are not backed up. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified and improved, such as the condition for y membership and the lack of evidence for some claims. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the condition for y membership is unclear and that some claims are not backed up. However, it does not provide specific examples or detailed reasoning to support these claims. The comment lacks specific references or detailed explanations, making it difficult for the authors to understand and address the issues. As a result, the claim is not verifiable, as it does not provide sufficient evidence or justification to support the claims. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues: the unclear condition for y membership and claims that are not adequately supported. It points out that the sets S are disjoint, as defined above, which could lead to confusion regarding the condition for y membership. Additionally, it notes that some claims are not backed up, without further elaboration on which claims are in question. While the comment highlights areas that need clarification and improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are given a general direction to improve their draft but are not provided with detailed steps or examples of how to do so. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not offer actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some key references that are highly related are not compared or explained in the paper. However, it does not specify which references are missing or provide guidance on how to address this issue. The authors are left to infer that they need to compare and explain these references, but without specific examples or detailed instructions, the action remains vague. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of comparison or explanation of key references that are highly related. However, it does not specify which references are missing or where they should be discussed, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. While the authors might have an idea of which references are important, the comment lacks specificity in identifying the exact references or sections that need attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that some key references that are highly related are not compared or explained in the paper. However, it does not provide specific examples or references to these key references, making it difficult for the authors to understand which references are missing or how they could be addressed. Without specific examples or detailed reasoning, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of comparison or explanation of key references that are highly related. This is a relevant point that could enhance the paper\\'s depth and credibility by providing a more comprehensive analysis of the references. However, the comment lacks specificity and does not provide guidance on which references should be compared or how they could be integrated into the paper. Without detailed suggestions or examples, the authors are left with a general idea of what needs to be addressed but without clear direction on how to proceed. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not offer actionable steps for the authors to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a concern with the analysis of SCL in section 5.2, specifically regarding the few-shot ability. It points out that the paper claims a more regularized representation space by SCL may result in better generalization ability in few-shot scenarios, but the results in Figure 7(c) and (d) do not meet the authors\\' expectations. The comment suggests that the authors should check if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. While the comment provides a specific area for improvement, it does not offer detailed guidance on how to address this issue or what specific experiments should be conducted. The action is explicit but somewhat vague, as the authors know they need to investigate the benefits of COCO-LM but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2\" and \"Figure 7(c) and (d),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the analysis of SCL regarding few-shot ability, pointing out that the results in Figure 7(c) and (d) do not meet the authors\\' expectations and suggesting that the authors should check if COCO-LM brings benefits to sentence retrieval tasks. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of SCL in section 5.2 regarding few-shot ability is not convincing. It suggests that the paper\\'s claim about a more regularized representation space by SCL leading to better generalization ability in few-shot scenarios is not supported by the results in Figure 7(c) and (d), where COCO-LM achieves more improvements with fewer labels and the improvements gradually disappear with more labels. The reviewer also suggests that the authors should check if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. The comment provides a logical reasoning and specific examples from the figures to support the claim, making it mostly verifiable. However, it could be strengthened by providing more detailed analysis or references to similar studies that support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis of SCL in section 5.2 regarding few-shot ability, noting that the results in Figure 7(c) and (d) do not meet the authors\\' expectations. It suggests that the paper\\'s claim about a more regularized representation space by SCL leading to better generalization ability in few-shot scenarios is not supported by the results. The comment also provides a specific suggestion for the authors to check if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. This feedback is clear and actionable, as it points out a specific area for improvement and offers a direction for further exploration. However, it could be more helpful if it provided additional context or examples to support the claim or suggested alternative analyses. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that conducting more experiments on other LLMs would demonstrate the generalization of the proposed framework. While the action is implicit, it is clear that the authors should conduct additional experiments to test the framework's applicability to other LLMs. The comment provides a specific direction for improvement, which is to conduct more experiments, but it lacks detailed guidance on how to conduct these experiments or what specific aspects to focus on. Therefore, the action is somewhat actionable, as it identifies a clear need for additional experiments but does not provide detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussion. Without explicit references to sections or specific experiments, the authors cannot confidently determine where to address this suggestion. Additionally, the comment lacks specificity regarding what additional experiments should be conducted or how they would demonstrate the generalization of the framework. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would benefit the paper. Without specific examples or detailed explanations, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. This is a reasonable suggestion that could enhance the paper\\'s contribution by providing a broader validation of the framework\\'s applicability. However, the comment lacks specific guidance on which LLMs to focus on or how to conduct these additional experiments. Without detailed instructions or examples, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to clarify what is meant by \"short\" and \"long\" videos to determine the downsample layers. It also recommends an apple-apple comparison of SOTA VLM/Video-LLM outputs for qualitative examples added. While the comment provides a clear action for the authors to take, it does not specify how to conduct the apple-apple comparison or what specific qualitative examples should be included. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the terms \"short\" and \"long\" videos and suggests an apple-apple comparison of SOTA VLM/Video-LLM outputs for qualitative examples. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to clarify what is meant by \"short\" and \"long\" videos to determine the downsample layers. It also recommends an apple-apple comparison of SOTA VLM/Video-LLM outputs for qualitative examples added. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that such a comparison would be beneficial. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and implement the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors clarify what is meant by \"short\" and \"long\" videos to determine the downsample layers. It also recommends an apple-apple comparison of SOTA VLM/Video-LLM outputs for qualitative examples added, which could help validate the results and provide a more comprehensive understanding of the model's performance. This feedback is specific and offers a concrete direction for improvement, making it mostly helpful for the authors. However, it could be more helpful if it provided additional guidance on how to conduct the apple-apple comparison or suggested specific qualitative examples to include. Overall, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in the efficiency of generating multiple objects, depending on the number of objects, and suggests that this could be a significant issue for scenes with a high number of objects or complex interactions. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the efficiency or what specific changes could be made to mitigate this limitation. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section where the authors discuss the generation of multiple objects, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of potential limitations in efficiency, especially for scenes with a high number of objects or complex interactions. This provides clear guidance on what needs to be addressed in terms of efficiency. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that generating multiple objects takes longer, depending on the number of objects, indicating a potential limitation in terms of efficiency. This is a factual observation based on the paper\\'s content. However, the comment lacks specific examples or detailed reasoning to support the claim that this limitation is significant or how it affects the overall efficiency of the system. Without additional context or evidence, the claim remains somewhat verifiable, as it provides a general observation but lacks depth and specificity. Therefore, the comment is classified as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the efficiency of generating multiple objects, depending on the number of objects, which could be a significant issue for scenes with a high number of objects or complex interactions. This is a valuable observation that highlights a potential weakness in the paper\\'s efficiency claims. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the efficiency of their system. While it points out an important area for consideration, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the technical contribution is thin and recommends that the authors focus on finding additional applications and evaluating the approach more deeply. It also recommends that the authors emphasize additional properties of the representation in future versions. While the comment provides a clear direction for the authors to explore additional applications and evaluate the approach, it does not specify which specific tasks or aspects to focus on. The action is explicit but somewhat vague in terms of execution, as the authors know they need to explore additional applications but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the technical contribution of the paper, specifically mentioning the algorithm proposed and the use of interpolative decomposition. It suggests that the contribution may be considered incremental and recommends focusing on finding additional applications and evaluating the approach more deeply. The comment also recommends exploring additional properties of the representation that may be emphasized in future versions. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the technical contribution or methodology sections. The comment is specific in its suggestion to focus on additional applications and evaluating the approach, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution is thin and suggests that the algorithm proposed may be considered incremental due to the use of interpolative decomposition. The reviewer recommends focusing on finding additional applications and evaluating the approach more deeply to enhance the manuscript's value. While the comment provides a logical reasoning for the suggestion to explore additional applications, it lacks specific examples or references to support the claim that the algorithm is incremental. This makes the claim somewhat verifiable, as the authors would need to make a concerted effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the technical contribution of the paper, suggesting that the algorithm proposed may be considered incremental due to the use of interpolative decomposition. It recommends that the authors focus on finding additional applications and evaluating the approach more deeply to enhance the manuscript's value. The comment provides a clear and actionable suggestion for the authors to explore additional applications and evaluate the approach, which could lead to significant improvements in the paper. However, the comment could be more helpful if it provided specific examples or guidance on which tasks or properties to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for information about the neural network library used for implementing the system, noting the lack of details on the implementation. This is a clear and direct request for additional information, providing the authors with a specific action to take. The comment is specific and concrete, as it identifies the exact information needed and leaves no ambiguity about what needs to be added. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly asks for information about the neural network library used for implementing the system, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of details on the implementation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for information about the neural network library used for implementing the system. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by asking for information about the neural network library used for implementing the system. This is a clear and actionable request that can help the authors provide more detailed information about their methodology, which could enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it suggested how this information might be presented or what specific details should be included. Overall, the comment is somewhat helpful as it points out a gap in the paper but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies that some descriptions are unclear, specifically mentioning undefined math notations and missing details in figure illustrations. It encourages the authors to provide more information by referencing specific sections or figures where these issues are present. However, the comment does not explicitly instruct the authors on how to address these issues or what specific details should be included. While the action is implied, it lacks concrete guidance on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"some of the descriptions\" and \"math notations\" and \"figure illustrations,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the undefined math notations and missing details in figure illustrations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some descriptions are unclear, specifically mentioning undefined math notations and missing details in figure illustrations. However, it does not provide specific examples or references to these issues, making it difficult for the authors to understand the exact nature of the problem. The lack of detailed examples or references makes the claim somewhat verifiable, as the authors would need to infer the specific issues themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, noting that some descriptions are unclear, particularly regarding undefined math notations and missing details in figure illustrations. While it highlights these areas of concern, it does not provide specific examples or guidance on how to address these issues. The comment prompts the authors to seek clarification or provide more detailed explanations, but it lacks actionable steps or suggestions for improvement. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should mention the meaning of the notation \\nu in the text, in addition to its explanation in Algorithm 1. This is a clear and direct action for the authors to take, as it provides a specific instruction on how to enhance the clarity of their draft. The comment is specific and concrete, as it details the exact change needed to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a mention of the meaning of the notation \\nu in the text, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanation of notation \\nu in Algorithm 1 is the only place where its meaning is mentioned. However, it does not provide any reasoning or evidence to support why this is a problem or how it affects the clarity of the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, noting that the explanation of notation \\nu is only found in Algorithm 1. It suggests that the authors should mention the meaning of \\nu in the text as well. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improving the draft. By addressing this point, the authors can enhance the clarity and accessibility of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting observation about the performance of using noise robust loss on pseudo-labels compared to positive learning from Equation 9. It suggests that the model might be underfit due to the accuracy of the pseudo-labels, which could benefit from the noise robust loss. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their model. It lacks actionable details, such as recommending specific modifications or experiments to test the robustness of the model. As a result, the authors are left without clear direction on how to apply this information to enhance their draft. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"appendix A.4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the performance of using noise robust loss on pseudo-labels compared to positive learning from Equation 9, providing clear guidance on what needs to be addressed. The comment raises an interesting observation about the potential benefits of using noise robust loss on pseudo-labels, which adds depth to the discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises an observation about the performance of using noise robust loss on pseudo-labels compared to positive learning from Equation 9. It suggests that the model might be underfit due to the accuracy of the pseudo-labels, which could benefit from the noise robust loss. The comment is somewhat verifiable as it provides a logical reasoning for the observation but lacks specific examples or detailed evidence to fully substantiate the claim. The authors might need to conduct additional experiments or provide more detailed analysis to fully validate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies an interesting observation about the performance of using noise robust loss on pseudo-labels compared to positive learning from Equation 9. It raises a question about whether the model might be underfit due to the accuracy of the pseudo-labels, which could benefit from the noise robust loss. This observation could prompt the authors to explore the potential benefits of using noise robust loss on pseudo-labels and consider alternative approaches to improve their model. However, the comment lacks specific suggestions or guidance on how to address this issue or conduct further experiments. While it provides a valuable insight, it could be more helpful with additional actionable advice. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the claim that an extra exponential would significantly increase runtime, suggesting that the authors should clarify this point. However, it does not provide explicit guidance on how to address this confusion or what specific aspects of the claim need clarification. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information or explanation but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that an extra exponential would significantly increase runtime, indicating that the reviewer is confused about the reasoning behind this claim. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that an extra exponential would significantly increase runtime, expressing confusion about the reasoning behind this claim. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim or clarify the reviewer\\'s confusion. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about a claim made in the paper regarding the impact of an extra exponential on runtime. It questions the reasoning behind this claim and suggests that the authors should clarify this point. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the clarity of their argument. The feedback is somewhat helpful as it points out a potential weakness in the paper, but it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the lack of comparison with related works, specifically mentioning \"Rubi\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" It implies that the authors should include a comparison with these methods to demonstrate the improvements of their proposed methods. However, the comment does not provide explicit instructions on how to conduct this comparison or what specific aspects to focus on. While the action is implied, it is not detailed enough for the authors to know exactly how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Rubi\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison with these related works and the perceived inadequacy of the experiments compared to SOTA methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of comparison with related works, specifically mentioning \"Rubi\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" The reviewer believes that the experiments are inadequate compared to SOTA methods. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of comparison with related works, such as \"Rubi\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" It points out that the experiments are inadequate compared to SOTA methods, which is a critical observation that could significantly impact the paper\\'s impact and credibility. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as which methods to compare or how to improve the experimental setup. While it highlights a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the experiments show the proposed method enhances performance but notes that it is not surprising due to the introduction of more learnable parameters, including the temperature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes, if any, are needed to enhance the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experiments and their results, specifically mentioning that the proposed method enhances performance but is not surprising due to the introduction of more learnable parameters, including the temperature. However, it does not specify which part of the paper this observation is based on, such as the experimental section or the methodology. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing what is expected in the experiments, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method enhances performance but is not surprising due to the introduction of more learnable parameters, including the temperature. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper\\'s conclusions. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment acknowledges that the experiments show the proposed method enhances performance but notes that it is not surprising due to the introduction of more learnable parameters, including the temperature. This observation highlights a potential limitation in the paper, suggesting that the method may not be as innovative as it appears. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the paper. Without actionable feedback or detailed advice, the authors are left with a general understanding of the critique but without clear steps to take. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the inspiration from neuroscience research seems unnecessary to the main processing pipeline of the main work, making it distracting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the integration or relevance of the neuroscience research to the main work. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the inspiration from neuroscience research seems unnecessary to the main processing pipeline of the main work, making it distracting. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure where the inspiration is discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the inspiration are considered unnecessary or distracting. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the inspiration from neuroscience research seems unnecessary to the main processing pipeline of the main work, making it distracting. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without specific examples or detailed explanations, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the inspiration from neuroscience research seems unnecessary to the main processing pipeline of the main work, making it distracting. However, it does not provide any specific examples or detailed reasoning to support this claim. Without further explanation or guidance on how the authors might address this issue, the comment lacks actionable feedback that could help the authors improve their draft. As a result, the comment is not helpful, as it does not offer a clear path for improvement. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add information about the source dataset in the caption of Table 3. It also emphasizes the importance of including all necessary information in the image and table captions to avoid the reader having to search for details in the main text. This feedback is clear and provides concrete guidance on what needs to be done to improve the draft. The authors know exactly what information to add and how to present it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of information about the source dataset in the caption. The comment provides a clear and actionable suggestion for improvement, ensuring that the authors know exactly what needs to be done to enhance the clarity of their work. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the caption of Table 3 is unclear about the source dataset used. It provides a specific recommendation to add information about the source dataset in the caption. This claim is somewhat verifiable as it logically suggests that including this information would enhance the clarity of the table. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the caption in Table 3, noting that it is unclear which source dataset is used. It provides a clear and actionable suggestion to add information about the source dataset in the caption, ensuring that the reader can easily access the necessary details. This feedback is valuable as it directly addresses a potential source of confusion and offers a straightforward solution to improve the clarity of the paper. However, the comment could be more helpful if it provided additional context or examples of how to effectively present this information in the caption. Overall, the comment is mostly helpful as it guides the authors on how to enhance the clarity and accessibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of explicit descriptions of the specific architectures used in the paper, particularly the value network, policy networks, and uncertainty-aware networks. This feedback implies that the authors should provide detailed descriptions of these architectures to enable readers to replicate and evaluate the applicability of the approach. However, the comment does not explicitly instruct the authors to add these descriptions, leaving some ambiguity about the exact actions to take. While the suggestion is clear, the lack of explicit instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific architectures of value network, policy networks, and uncertainty-aware networks, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explicit descriptions of these architectures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks explicit descriptions of the specific architectures used, making it difficult for readers to replicate and evaluate the approach. This claim is somewhat verifiable as it highlights a gap in the paper\\'s description, but it does not provide specific examples or references to similar works that might have included such descriptions. The authors are left to infer the importance of including these details, which could be challenging without additional context or guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, noting the absence of explicit descriptions of the specific architectures used, particularly the value network, policy networks, and uncertainty-aware networks. This lack of detail makes it difficult for readers to replicate and evaluate the applicability of the approach presented in the paper. The comment highlights an important area for improvement, as providing detailed descriptions of these architectures would enhance the reproducibility and understanding of the work. However, the comment does not offer specific suggestions on how to address this issue or what additional details should be included. While it points out a critical weakness, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out several assumptions that may render EMCTS inapplicable to real complex problems. It specifically mentions that the transition model P is assumed to be true, that Theorem 1 requires $Q^{\\pi}$ to be linear, and that learned models are assumed to be consistent. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address these assumptions or what specific modifications could be made to improve the applicability of EMCTS. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific assumptions made in the paper regarding the applicability of EMCTS to real complex problems. It mentions the transition model P, Theorem 1, and the assumption of consistency for learned models. However, it does not specify which part of the paper these assumptions are discussed in, making it weakly grounded. The comment is specific in detailing what assumptions are problematic and why they may not be reasonable in many cases. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some assumptions in the paper may render EMCTS inapplicable to real complex problems. It specifically mentions the assumption that the transition model P is true and the requirement for $Q^{\\pi}$ to be linear in Theorem 1. The reviewer also points out that the learned models are assumed to be consistent, which may not be reasonable in many cases. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several assumptions made in the paper that may render EMCTS inapplicable to real complex problems. It points out specific issues, such as the assumption that the transition model P is true and the requirement for $Q^{\\pi}$ to be linear in Theorem 1. The reviewer also notes that the learned models are assumed to be consistent, which may not be reasonable in many cases. While the comment highlights potential weaknesses in the paper, it does not provide actionable suggestions or guidance on how the authors might address these issues or improve the applicability of their work. The feedback is somewhat helpful as it prompts the authors to reconsider their assumptions, but it lacks depth and specificity, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that explicitness (E) and size (S) may be highly related to the given dataset, and that the different capacity requirements in the third paragraph may be due to input modality differences. It also proposes that evaluating disentanglement should provide enough capacity and training time, which is powerful enough to achieve the DCI evaluation. If the capacity of probing needs to be evaluated, the comment suggests considering the training time, cost, and learning rate as they may influence the final value of DCI. While the comment provides a logical suggestion for evaluating the dataset and capacity requirements, it lacks explicit instructions on how to implement these suggestions. The authors can infer the actions but may need to infer the details of how to execute them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"3rd paragraph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion about the relationship between explicitness (E) and size (S) and the capacity requirements, as well as the need to consider the training time, cost, and learning rate when evaluating disentanglement. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes an observation about the relationship between explicitness (E) and size (S) and the capacity requirements, suggesting that these may be highly related to the given dataset. It also provides a logical explanation for the different capacity requirements in the third paragraph, attributing them to input modality differences. The comment further suggests that evaluating disentanglement should provide enough capacity and training time, which is powerful enough to achieve the DCI evaluation. If the capacity of probing needs to be evaluated, the comment advises considering the training time, cost, and learning rate. While the comment provides logical reasoning and suggestions, it lacks specific examples or references to support the claims. Therefore, the comment is somewhat verifiable, as it provides a foundation for the authors to explore but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed analysis of the relationship between explicitness (E) and size (S) and the capacity requirements, suggesting that these may be highly related to the given dataset. It logically explains the different capacity requirements in the third paragraph, attributing them to input modality differences. The comment also offers a constructive suggestion for evaluating disentanglement, proposing that it should provide enough capacity and training time, which is powerful enough to achieve the DCI evaluation. If the capacity of probing needs to be evaluated, the comment advises considering the training time, cost, and learning rate. This feedback is clear and actionable, providing the authors with specific guidance on how to improve their evaluation and analysis of the dataset. However, it could be more helpful if it included examples or references to support the claims or suggestions. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper title should not include abbreviations. This provides a clear and direct action for the authors to take, ensuring that the title is more straightforward and understandable. The comment is specific and provides concrete guidance on what to change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper title, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of abbreviations in the title. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper title should not include abbreviations. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment provides a clear and direct suggestion regarding the paper title, advising that it should not include abbreviations. This feedback is actionable and can help the authors improve the clarity and accessibility of their paper title. However, the comment lacks further explanation or context on why abbreviations are not beneficial in the title or how they might negatively impact the paper\\'s readability. While it offers a specific and somewhat helpful suggestion, it could be more comprehensive with additional guidance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors mention the ability of the discriminator to transfer to other tasks and domains without further training, as well as its effectiveness with limited data. Additionally, it highlights an important insight at L400 where the discriminator can be small. However, the comment does not provide explicit instructions on how to incorporate these points into the paper or what specific sections to address. The actions are implied and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests mentioning the ability of the discriminator to transfer to other tasks and domains without further training, as well as its effectiveness with limited data. It also highlights an important insight at L400 where the discriminator can be small. However, the comment does not specify which part of the paper these points should be addressed in, nor does it provide detailed guidance on how to incorporate these insights. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting what needs to be addressed. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the discriminator can transfer to other tasks and domains without further training and that it can be effectively trained with limited data. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of these assertions. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors mention the ability of the discriminator to transfer to other tasks and domains without further training, as well as its effectiveness with limited data. It also highlights an important insight at L400 where the discriminator can be small, which is a valuable observation. However, the comment does not provide specific guidance on how to incorporate these points into the paper or what aspects of the discriminator\\'s performance should be emphasized. While it identifies important insights, the feedback lacks actionable suggestions for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add a specific baseline, the SOTA GNN-QE, which is the closest work in terms of components to their approach. This is a clear and direct action for the authors to take, as it provides a specific addition to the baseline comparisons. The comment also highlights the importance of including this baseline, making it concrete and actionable for the authors to implement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SOTA GNN-QE,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the SOTA GNN-QE as a baseline. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current SOTA GNN-QE is omitted from the baselines, despite being the closest work in terms of components to the approach being discussed. This claim is somewhat verifiable as it provides a logical reasoning for why the baseline should be included, but it lacks specific examples or references to support the claim. The authors might need to infer the significance of the SOTA GNN-QE and its relevance to their work, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific omission in the paper, noting that the SOTA GNN-QE, which is the closest work in terms of components to the approach being discussed, is not included as a baseline. This is a clear and actionable suggestion that could significantly improve the paper by providing a more comprehensive comparison. However, the comment could be more helpful if it explained why the inclusion of this baseline is important or how it would enhance the analysis. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the potential limitations of the pretraining data in allowing GPT-2 to understand language and questions the reasonableness of the setting. It suggests that facts may have been learned in GPT-2 before training. The reviewer acknowledges the paper's exploration of an interesting topic but emphasizes the need to address these concerns to prove the findings correct. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these concerns or what specific actions the authors should take. The authors are left to infer that they need to provide a detailed explanation or evidence to support their findings. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but lacks concrete instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses concerns about the pretraining data and its impact on GPT-2\\'s understanding of language. It suggests that the setting may not be reasonable and that facts may have been learned in GPT-2 before training. However, the comment does not specify which part of the paper these concerns are based on, making it weakly grounded. The authors can infer that it relates to the discussion of pretraining data or the methodology section, but this inference is not direct. The comment is specific in detailing the concerns about the setting and the need to address them to prove the findings correct. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the potential limitations of pretraining data in allowing GPT-2 to understand language. It questions the reasonableness of the setting and suggests that facts may have been learned in GPT-2 before training. The comment acknowledges the paper\\'s exploration of an interesting topic but emphasizes the need to address these concerns to prove the findings correct. While the comment provides a logical basis for the concerns, it lacks specific examples or references to support the claim that pretraining data is insufficient. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or reasoning to fully substantiate their argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper regarding the role of pretraining data in allowing GPT-2 to understand language. It questions the reasonableness of the setting and suggests that facts may have been learned in GPT-2 before training. While the comment acknowledges the paper\\'s exploration of an interesting topic, it highlights essential concerns that need to be addressed to prove the findings correct. The reviewer expresses a willingness to raise their score if the authors successfully address these concerns. However, the comment lacks specific guidance or suggestions on how the authors might address these issues, leaving them to infer the necessary steps. Therefore, the comment is somewhat helpful, as it points out important areas for improvement but does not provide detailed guidance on how to achieve them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific areas where the proposed method is not thoroughly explained, such as the computation of some terms in (4) and the optimization algorithm. It explicitly states that the computation of terms in (4) is missing and suggests that the optimization algorithm should be explained, including how to calculate $p(x_k|d)$. The comment provides clear and concrete guidance on what needs to be added to the explanation, making it highly actionable. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the computation of some terms in (4) and the optimization algorithm, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the missing computation of terms in (4) and the optimization algorithm, including how to calculate $p(x_k|d)$. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not thoroughly explained, specifically mentioning the missing computation of some terms in (4) and the optimization algorithm, such as how to calculate $p(x_k|d)$. The reviewer provides logical reasoning by suggesting that if math formulas are used, every term should be clearly explained, except for cases where it is obvious. This reasoning is somewhat verifiable as it provides a general guideline for explaining mathematical concepts, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the proposed method is not thoroughly explained, such as the computation of some terms in (4) and the optimization algorithm, including how to calculate $p(x_k|d)$. It provides clear and actionable feedback by suggesting that every term should be clearly explained, except for cases where it is extremely obvious. This feedback is valuable as it guides the authors to improve the clarity and completeness of their explanation, which is crucial for effectively communicating their method. However, the comment could be more helpful if it offered examples or additional guidance on how to clarify these points. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments are not provided. It also points out that the lack of these details makes the experimental results unreproducible and difficult to assess the fairness of comparisons. The comment provides a clear and direct action for the authors to take, which is to include a thorough description of the implementation details. This guidance is explicit and concrete, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of implementation details and the impact on the reproducibility and fairness of the experiments. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of implementation details makes the experimental results unreproducible and difficult to assess the fairness of comparisons. It also suggests that the absence of these details weakens the overall contribution. The comment provides a logical reasoning by highlighting the importance of including implementation details to ensure reproducibility and fairness in the experiments. However, it does not provide specific examples or references to support the claim about the impact on fairness or the significance of the experimental results. This makes the claim somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of implementation details for the RAMP algorithm and other aspects of the experiments. This lack of detail makes the experimental results unreproducible and difficult to assess the fairness of comparisons with existing methods. The comment highlights the importance of including a thorough description of the implementation details to address these issues. This feedback is clear and actionable, providing the authors with a direct and specific suggestion for improvement. By addressing this point, the authors can significantly enhance the reproducibility and robustness of their work, which is valuable for the overall contribution. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the use of a mixture of experts (MoE) for a task is not unusual, given its extensive application in various tasks such as general LLM, summarization, and machine translation. However, it also notes that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. While the comment provides some context about the applicability of MoE, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to address the comment or suggestions for improvement. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the concept of employing a mixture of experts (MoE) for a task, specifically in the context of text detection. It acknowledges that the application of MoE in this context is not groundbreaking, given its extensive application in other tasks such as general LLM, summarization, and machine translation. However, the comment does not specify which part of the paper discusses the application of MoE in text detection, making it weakly grounded. The comment is specific in its critique of the novelty of the application of MoE in text detection, but without explicit references to the relevant sections, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the concept of employing a mixture of experts (MoE) for a task is not unusual, given its extensive application in various tasks such as general LLM, summarization, and machine translation. The reviewer acknowledges that while the application of MoE in text detection is relatively new, it is not groundbreaking in terms of its fundamental idea. This claim is somewhat verifiable as it provides a logical reasoning based on the widespread application of MoE in different tasks. However, it lacks specific examples or references to support the assertion that the application of MoE in text detection is not groundbreaking. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the concept of employing a mixture of experts (MoE) for a task is not unusual, given its extensive application in various tasks such as general LLM, summarization, and machine translation. It also notes that while the application of MoE in text detection is relatively new, it is not a groundbreaking concept in terms of its fundamental idea. This feedback provides some insight into the context of MoE applications, which is helpful for the authors. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their work. It lacks actionable advice or detailed feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim a significant performance improvement for SpaceTGN but do not provide a statistical analysis to support this claim of significance. This feedback implies that the authors should include a statistical analysis to substantiate their claim. However, it does not explicitly instruct the authors to perform a statistical analysis or specify which statistical method should be used. The action is clear but not explicitly stated, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about SpaceTGN achieving significant performance improvement and the lack of statistical analysis to support this claim. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a statistical analysis to support the claim of significance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors make a claim about SpaceTGN achieving significant performance improvement but do not provide a statistical analysis to support this claim. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the claim of significant performance improvement for SpaceTGN without providing a statistical analysis to support this claim. This is a critical point as it undermines the credibility of the authors\\' claims. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending a specific statistical method or approach. While it highlights a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential source of confusion regarding the excerpting versus reproducing of certain scores. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the distinction or what specific changes should be made to improve the clarity. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out a potential source of confusion regarding the excerpting versus reproducing of certain scores, but it does not specify which part of the paper this issue pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this issue. Additionally, the comment lacks specificity regarding what needs to be clarified or improved regarding the excerpting and reproducing of scores. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the excerpting versus reproducing of certain scores may cause confusion. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential source of confusion regarding the excerpting versus reproducing of certain scores, which could impact the clarity of the paper. However, it does not provide specific guidance or suggestions on how to address this issue or clarify the distinction. Without actionable feedback or detailed advice, the authors are left without a clear path to improve the draft. Therefore, the comment is rated as barely helpful, as it points out a potential problem but lacks depth and specificity in its guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more information on how consistency models achieve something that previous generative models cannot. It highlights a potential weakness and points out that this is also listed as a question for the authors. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of the novelty of their method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the method of applying consistency models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the novelty of the method and how it differs from previous generative models. The comment suggests that the authors should provide more information on how consistency models achieve something that previous generative models cannot, which is a clear and specific point for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is \"somewhat simply applying consistency models in place of other generative models for learning target distributions,\" suggesting a lack of novelty. The reviewer supports this claim by pointing out that consistency models are a recent trend and that the method does not achieve something that previous generative models cannot. However, the comment lacks specific examples or references to support the claim that consistency models are a recent trend or that they offer unique advantages over other generative models. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, noting that the method is somewhat simply applying consistency models in place of other generative models for learning target distributions. It suggests that the authors should provide more information on how consistency models achieve something that previous generative models cannot, which could enhance the novelty of the work. This feedback is clear and actionable, as it points out a specific area for improvement and offers a direction for the authors to explore. However, the comment could be more helpful if it provided examples or references to support the claim about the novelty of consistency models. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation metric in Table 2 only uses MSE, which does not accurately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether they should consider alternative metrics, how to incorporate them, or what specific changes should be made to the evaluation method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the evaluation metric, noting that it only uses MSE and does not reflect the accuracy of nowcasting. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation metric in Table 2 only uses MSE, which does not accurately reflect the accuracy of nowcasting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why MSE is insufficient for evaluating nowcasting accuracy. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation metric used in Table 2, noting that it only uses MSE and does not accurately reflect the accuracy of nowcasting. This feedback is valuable as it highlights a potential limitation in the paper\\'s evaluation methodology, which could impact the authors\\' conclusions. However, the comment does not provide suggestions or guidance on how the authors might address this issue or what alternative metrics could be considered. While it points out a relevant concern, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the benefit of FFA-LoRA on differential privacy (DP) is not well supported by empirical evaluation, specifically noting that the performance gap remains the same across various privacy budgets $\\\\epsilon$. The reviewer suggests that this empirical result suggests that the impact of DP noise is the same on both the vanilla LoRA and the proposed FFA-LoRA. While the comment identifies a gap in the empirical evaluation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more empirical evaluations to support the claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"benefit of FFA-LoRA on differential privacy (DP)\" and the \"performance gap between the vanilla LoRA and the proposed FFA-LoRA,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the empirical evaluation does not adequately support the claim about the benefit of FFA-LoRA on DP. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the benefit of FFA-LoRA on differential privacy (DP) is not well supported by empirical evaluation. It suggests that the performance gap remains the same across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$. This claim is somewhat verifiable as it provides a logical reasoning based on the empirical result, which suggests that the impact of DP noise is the same on both the vanilla LoRA and the proposed FFA-LoRA. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the benefit of FFA-LoRA on differential privacy (DP) is not well supported by empirical evaluation. It points out that the performance gap remains the same across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$, suggesting that the impact of DP noise is the same on both the vanilla LoRA and the proposed FFA-LoRA. This feedback is clear and actionable, as it highlights a critical area for improvement in the empirical evaluation section. By addressing this issue, the authors can enhance the credibility and robustness of their findings. However, the comment could be more helpful if it provided suggestions on how to conduct a more robust empirical evaluation or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add Cap-CapNE-ClipNE-EA and Cap-CapNE-ClipNE-NE-EA to the ablation study of ENGINE, as per the overview model. It also recommends providing more detailed analysis of the ablation results. This feedback is clear and concrete, as it specifies exactly what needs to be added and how to improve the analysis. The authors know exactly what actions to take to enhance their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study of ENGINE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added to the ablation study, such as Cap-CapNE-ClipNE-EA and Cap-CapNE-ClipNE-NE-EA, and recommends providing more detailed analysis of the results. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study of ENGINE is incomplete and suggests adding Cap-CapNE-ClipNE-EA and Cap-CapNE-ClipNE-NE-EA to the overview model. However, the comment lacks specific reasoning or evidence to support why these additions are necessary or how they would improve the ablation study. Without detailed justification or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the ablation study of ENGINE, noting that it is incomplete and recommending the addition of Cap-CapNE-ClipNE-EA and Cap-CapNE-ClipNE-NE-EA to the overview model. It also suggests providing more detailed analysis of the ablation results. This feedback is clear and actionable, as it specifies exactly what needs to be added and how to enhance the analysis. By addressing these points, the authors can significantly improve the completeness and depth of their ablation study, making this comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the discrepancy in mode coverage between GDIM and DDGAN, suggesting that providing results on more challenging high-resolution datasets like LSUN and ImageNet would be more convincing. While the comment implies that the authors should provide additional results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide results on more challenging datasets. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GDIM\" and \"DDGAN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why GAN optimization produces poor mode coverage in GDIM and good mode coverage in DDGAN, and suggests providing results on more challenging high-resolution datasets like LSUN and ImageNet. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the discrepancy in mode coverage between GDIM and DDGAN, suggesting that providing results on more challenging high-resolution datasets like LSUN and ImageNet would be more convincing. The comment does not make a subjective claim or express an opinion but rather seeks clarification and additional evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the discrepancy in mode coverage between GDIM and DDGAN, suggesting that providing results on more challenging high-resolution datasets like LSUN and ImageNet would be more convincing. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s analysis and suggests a direction for improvement. However, the comment could be more helpful if it provided specific examples or guidance on how to address the issue or what specific results should be included. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the meaning of the statement \"Each attribute of the table feature represents a scene\" from Section 5.1. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should clarify or rephrase this statement, leaving them without a clear understanding of what is expected of them. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of the statement \"Each attribute of the table feature represents a scene,\" which provides clear guidance on what needs to be clarified or revised. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of a specific statement in the paper, \"Each attribute of the table feature represents a scene.\" However, it does not provide any context or explanation for why this statement is unclear or problematic. Without additional information or reasoning, the claim is not verifiable, as it lacks the necessary support to guide the authors in understanding or addressing the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the meaning of a specific statement in the paper, \"Each attribute of the table feature represents a scene,\" which is a clear indication of a lack of clarity or understanding. However, it does not provide any context or explanation for why this statement is problematic or how it could be improved. Without additional guidance or suggestions, the authors are left without actionable feedback on how to address the issue. Therefore, the comment is not helpful, as it lacks depth and does not assist the authors in improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that the authors should consider comparing the logsumexp aggregation with direct addition, which corresponds to a basic prototype comparison with reweighted averages on each prototype. Additionally, the comment questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN, and it raises a concern about the logsumexp aggregator's comparison. While the comment provides a clear direction for the authors to consider conducting an ablation study and comparing the aggregation schemes, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer the need to conduct the study and understand the comparison. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison between the logsumexp aggregation and direct addition, and the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the absence of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that the authors should compare the logsumexp aggregation with direct addition, which corresponds to a basic prototype comparison with reweighted averages on each prototype. The comment also questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN. However, the comment lacks specific examples or references to support the claim that the logsumexp aggregation is better than direct addition or that the token reweighting scheme is compatible with existing classifiers. This makes the claim somewhat verifiable, as the authors would need to make a logical deduction or conduct additional research to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that the authors should conduct such a study to compare the logsumexp aggregation with direct addition, which corresponds to a basic prototype comparison with reweighted averages on each prototype. Additionally, the comment raises a broader question about the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN. This feedback is clear and actionable, providing the authors with specific directions for improving their draft. However, it could be more helpful if it included examples or references to similar studies that have conducted such ablation studies or comparisons. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the limited number of datasets used to evaluate the effectiveness of ECGs is insufficient. It explicitly recommends considering the large-scale datasets mentioned in [2] and provides specific references to external works that discuss similar topics. This feedback is clear and provides concrete guidance on how the authors can expand their dataset evaluation, making it highly actionable. The authors know exactly which datasets to consider and where to find them, ensuring they can effectively address the comment.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of limited datasets and suggests considering the large-scale datasets mentioned in [2]. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. It is also specific because it clearly specifies what needs to be addressed, namely the insufficiency of the five datasets and the recommendation to consider the large-scale datasets mentioned in [2]. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the limited number of datasets used to evaluate the effectiveness of ECGs is insufficient. It suggests that the large-scale datasets mentioned in [2] should be considered. The reviewer provides references to external works that discuss similar topics, such as \"Breaking the Limit of Graph Neural Networks\" and \"Large Scale Learning on Non-Homophilous Graphs.\" These references provide a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by explaining why these external works are relevant to the current study or how they could be integrated into the evaluation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically the insufficiency of the five datasets used to evaluate the effectiveness of ECGs. It suggests that the authors should consider the large-scale datasets mentioned in [2], which are relevant to the topic of graph neural networks. The comment provides specific references to external works that discuss similar topics, such as \"Breaking the Limit of Graph Neural Networks\" and \"Large Scale Learning on Non-Homophilous Graphs.\" This feedback is clear and actionable, as it directs the authors to consider additional datasets that could enhance their evaluation. However, it could be more helpful if it explained why these external works are relevant to the current study or how they could be integrated into the evaluation. Overall, the comment is mostly helpful as it guides the authors toward a more comprehensive evaluation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clearly state the limitation of their analysis, which is that they only analyze fully connected ResNets, while ResNets typically use convolutional layers in practice. It also suggests that this limitation should be included in the Broader Impact section. The comment provides a clear and direct action for the authors to take, specifying where the limitation should be addressed and how it should be integrated into the paper. The action is concrete, as it specifies the exact part of the paper where the limitation should be discussed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"fully connected ResNets\" and suggests that the paper should include a discussion of the use of convolutional layers in practice. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the limitation of only analyzing fully connected ResNets and the need to include this in the Broader Impact section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only analyzes fully connected ResNets, which is a limitation, and suggests that this should be addressed in the Broader Impact section. The comment provides a logical reasoning by pointing out that ResNets typically use convolutional layers in practice. However, it lacks specific examples or references to support the claim that this limitation is significant or impactful. While the claim is somewhat verifiable, it could be strengthened with additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, noting that it only analyzes fully connected ResNets, while ResNets typically use convolutional layers in practice. This is a critical observation that could impact the broader impact and applicability of the work. The comment suggests that the authors should clearly state this limitation and include it in the Broader Impact section. This feedback is clear and actionable, as it provides a specific direction for the authors to address the limitation and enhance the comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to integrate this limitation into the broader impact section or provided examples of how other works have addressed similar limitations. Overall, the comment is mostly helpful as it effectively points out a critical issue and provides a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider training a student model on the training set, especially considering the student is a ResNet18, which is a medium-sized model. It provides specific examples of the student model's performance on MNIST, SVHN, and CIFAR10, indicating that standard KD methods such as Early KD methods (Hinton et al., 2015) and FitNets (Romero et al., 2015) have surpassed the reported KD performance. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific modifications to the training process should be made. The action is implicit and somewhat vague, as the authors need to infer that they should consider training the student model on the training set to improve performance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider training a student model on the training set, especially considering the student is a ResNet18, which is a medium-sized model. It provides specific examples of the student model\\'s performance on MNIST, SVHN, and CIFAR10, indicating that standard KD methods such as Early KD methods (Hinton et al., 2015) and FitNets (Romero et al., 2015) have surpassed the reported KD performance. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing the performance of the student model and the need to consider training on the training set. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider training a student model on the training set, especially considering the student is a ResNet18, which is a medium-sized model. It provides specific examples of the student model\\'s performance on MNIST, SVHN, and CIFAR10, indicating that standard KD methods such as Early KD methods (Hinton et al., 2015) and FitNets (Romero et al., 2015) have surpassed the reported KD performance. This claim is supported by logical reasoning and specific examples, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or references to the specific KD methods mentioned. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific suggestion for the authors to consider training a student model on the training set, especially considering the student is a ResNet18, which is a medium-sized model. It supports this suggestion by providing specific examples of the student model\\'s performance on MNIST, SVHN, and CIFAR10, indicating that standard KD methods such as Early KD methods (Hinton et al., 2015) and FitNets (Romero et al., 2015) have surpassed the reported KD performance. This feedback is clear and actionable, as it guides the authors on how to potentially improve their model\\'s performance. However, it could be more helpful if it provided additional context or suggestions on how to implement this training approach or what specific modifications to the training process might be necessary. Overall, the comment is mostly helpful as it offers a concrete direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the causal graph assumption in the proposed framework, specifically questioning whether the coupling of message and passing routes in certain GCN variants, such as Geniepath and Gated GNN, would break the assumption. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or what specific changes should be made to the framework. The authors are left to infer that they might need to reconsider their assumptions about causal factors and the influence of path direction, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the causal graph assumption in the proposed framework, specifically questioning whether the coupling of message and passing routes in certain GCN variants, such as Geniepath and Gated GNN, would break the assumption. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its questioning of the causal graph assumption, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the assumption that only node attributes X would affect the causal factors and suggests that the coupling of message and passing routes in certain GCN variants, such as Geniepath and Gated GNN, could break the causal graph assumption in the proposed framework. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without detailed evidence or reasoning, the claim is not fully verifiable, as it relies on general assertions without concrete examples or references. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical question about the causal graph assumption in the proposed framework, specifically questioning whether the coupling of message and passing routes in certain GCN variants, such as Geniepath and Gated GNN, would break the assumption. This is an important consideration for the authors to address, as it could impact the validity and applicability of their framework. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern or what changes they should make to their framework. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out an important area for consideration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete suggestions for improvement. It points out that the author only considered message-passing layers and notes that different tasks may require different pre-/post-processing modules. The reviewer suggests that the authors should list the performance of SOTA algorithms in each dataset discussed in Table 1, which would help readers understand the gap between NAS models and human-engineered SOTA architectures. This feedback is clear and actionable, as it directly instructs the authors on how to enhance their draft by including performance comparisons. The authors know exactly what needs to be done to address the comment, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"pre-processing, message-passing, and post-processing,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to list the performance of SOTA algorithms in each dataset discussed in Table 1 to help readers understand the gap between NAS models and human-engineered SOTA architectures. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors only considered message-passing layers and that this is not convincing due to the varying pre-/post-processing modules used in different tasks. The reviewer suggests that listing the performance of SOTA algorithms in each dataset discussed in Table 1 would help readers understand the gap between NAS models and human-engineered SOTA architectures. This claim is somewhat verifiable as it provides a logical reasoning for why the authors should consider additional evidence to support their claim about the importance of message-passing layers. However, the comment lacks specific examples or references to SOTA algorithms or datasets, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement. It points out that the authors only considered message-passing layers and noted that different tasks may require different pre-/post-processing modules. The reviewer suggests that listing the performance of SOTA algorithms in each dataset discussed in Table 1 would help readers understand the gap between NAS models and human-engineered SOTA architectures. This feedback is valuable as it directs the authors to include a more comprehensive comparison of their work with existing state-of-the-art algorithms, which could enhance the paper\\'s clarity and credibility. By addressing this suggestion, the authors can significantly improve the draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be useful to show whether learning the advantage directly is beneficial. It acknowledges that the paper makes a case for the advantage being a quantity of interest but questions the importance of learning it directly with the proposed method compared to other methods. However, the comment does not provide specific guidance on how to demonstrate this or what kind of evidence would be sufficient. The action is implicit and somewhat vague, as the authors can infer that they need to provide more evidence or examples to support their claim, but the comment lacks concrete details on how to implement this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be useful to show whether learning the advantage directly is beneficial, and it questions the importance of learning it directly with the proposed method compared to other methods. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment where this could be addressed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for evidence or comparison, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be useful to demonstrate whether learning the advantage directly is beneficial. The reviewer acknowledges that the paper makes a case for the advantage being a quantity of interest but questions the importance of learning it directly with the proposed method compared to other methods. However, the comment lacks specific examples or references to support the claim that learning the advantage directly is not beneficial. Without such evidence or reasoning, the claim remains somewhat verifiable, as the authors may find it challenging to understand the basis of the critique without additional context or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the importance of learning the advantage directly with the proposed method compared to other methods. It suggests that the paper should demonstrate whether learning the advantage directly is beneficial, which is a valuable point for the authors to consider. However, the comment lacks specific suggestions or examples on how to address this issue or what kind of evidence would be needed to support the claim. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide explanations about the meaning of the variable symbols used in the appended algorithms. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that explanations about the meaning of variable symbols such as \u03c2 , r_i , \u03b1_i, and so on in the appended algorithms should be added. However, it does not specify which part of the paper these symbols are used in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the need for explanations, it lacks grounding as it does not identify the exact location in the paper where these symbols are used. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that explanations about the meaning of variable symbols such as \u03c2 , r_i , \u03b1_i, and so on in the appended algorithms should be added. However, the comment does not provide any reasoning, examples, or references to support why these explanations are necessary or how they would improve the clarity of the paper. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that explanations about the meaning of variable symbols used in the appended algorithms should be added. This feedback is clear and actionable, as it directs the authors to provide clarity on the symbols' significance in the context of the algorithms. However, the comment could be more helpful if it included examples or suggestions on how to present these explanations effectively. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and accessibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the limited performance gains indicate a lack of innovation in the method, which may not advance the field meaningfully. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the innovation or what specific changes could be made to the method to make it more impactful. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the limited performance gains indicate a lack of innovation in the method, which may not advance the field meaningfully. However, it does not specify which part of the paper this observation is based on, such as specific sections, tables, or figures where the performance gains are discussed. Without explicit references, the authors cannot confidently determine which parts of the paper need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the method are lacking in innovation or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the limited performance gains suggest a lack of innovation in the method, which may not advance the field meaningfully. However, the comment does not provide any specific examples, data, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the limited performance gains indicate a lack of innovation in the method, which may not advance the field meaningfully. It implies that the method may represent incremental changes to established methods rather than offering significant advancements. However, the comment does not provide specific examples or suggestions for how the authors might address this concern or improve the innovation of their method. Without actionable feedback or guidance, the authors are left without a clear path forward to enhance the impact of their work. Therefore, the comment is rated as barely helpful, as it identifies a potential issue but lacks depth and specificity in its critique.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This implies that the authors should include such comparisons in their work to provide a clearer picture of the relative strengths and weaknesses of their proposed system. However, the comment does not specify which existing methods or systems should be compared or how to conduct the comparative analysis. While the action is implied, it is not explicitly stated, and the authors are left to infer the details of how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not specify which part of the paper this analysis should be included in, nor does it provide details on what specific comparisons should be made or how they should be conducted. This lack of explicit grounding and specificity makes it difficult for the authors to identify the exact areas that need improvement or how to implement the suggested comparative analysis. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This claim is somewhat verifiable as it logically suggests that such an analysis would provide a clearer picture of the relative strengths and weaknesses of the proposed system. However, the comment lacks specific examples or references to existing methods or systems that could be compared, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback is valuable as it identifies a potential area for improvement in the paper, which could enhance its credibility and comprehensiveness. However, the comment lacks specific guidance on which existing methods or systems should be compared, how to conduct the comparative analysis, or what specific aspects to focus on. While it points out a potential weakness, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a general direction for improvement but lacks actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment highlights a concern about the practical usefulness of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ due to its prediction performance not outperforming existing methods on a real dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"PH-GDN$_{\\\\text{C}}$,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the method, namely that its prediction performance does not outperform existing methods on a real dataset, which limits its practical usefulness. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ does not outperform existing methods on a real dataset, which limits its practical usefulness. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment highlights a concern about the practical usefulness of a method, specifically $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$, due to its prediction performance not outperforming existing methods on a real dataset. This observation is relevant and could prompt the authors to reconsider the method's practical applicability. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the method's performance. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that it is unfair to compare the proposed algorithm with offline RL algorithms for single agents, as the target of those algorithms is not to find an equilibrium. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to the comparison. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison between the proposed algorithm and offline RL algorithms for single agents, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, namely that the target of offline RL algorithms is not to find an equilibrium. This provides clear guidance on what needs to be addressed in the comparison section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single agents, as the target of those algorithms is not to find an equilibrium. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between the proposed algorithm and offline RL algorithms for single agents, noting that the target of the latter is not to find an equilibrium. This feedback is somewhat helpful as it highlights a potential misalignment in the comparison, which could impact the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what specific aspects of the comparison should be revised. While it points out a relevant concern, it does not provide actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify their unique contributions in methodology and purpose, suggesting that they provide more detailed comparisons to similar works. This feedback is clear and concrete, as it specifies the need for a detailed comparison to prior works and the importance of clarifying the paper\\'s unique contributions. The authors know exactly what needs to be done to address this feedback, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the overlap with prior work, specifically mentioning the three tasks of unanswerable, inconsistent, and counterfactual. It suggests that the paper should clarify its unique contributions in methodology and purpose, and provide more detailed comparisons to similar works. However, the comment does not specify which part of the paper should include these clarifications or comparisons, leaving the authors to infer where these sections might be. While the comment is specific in its suggestion for improvement, it lacks full grounding as it does not directly reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overlaps with prior work, specifically mentioning the tasks of unanswerable, inconsistent, and counterfactual. It suggests that the paper should clarify its unique contributions in methodology and purpose, and provide more detailed comparisons to similar works. While the comment identifies a potential issue with the paper\\'s originality, it lacks specific references to the prior works mentioned or detailed examples of how the paper could improve its comparisons. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks detailed guidance or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the three tasks of unanswerable, inconsistent, and counterfactual have been partially covered in prior benchmarks. It suggests that the paper should clarify its unique contributions in methodology and purpose, and provide more detailed comparisons to similar works. This feedback is clear and actionable, as it directs the authors to address a specific area of overlap with prior work and to provide a more comprehensive comparison to similar studies. However, the comment could be more helpful if it included specific examples of how the paper\\'s contributions differ from prior work or suggested ways to enhance the comparisons. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and originality of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the statement in Section 1, \"human perception is usually invariant to the texture resampling,\" lacks support materials. This provides a clear and direct action for the authors to take, which is to include additional evidence or examples to support this claim. The comment is specific about what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the statement \"human perception is usually invariant to the texture resampling\" lacks support materials. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"human perception is usually invariant to the texture resampling\" lacks support materials. However, it does not provide any specific examples or references to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in Section 1, noting that the statement \"human perception is usually invariant to the texture resampling\" lacks support materials. This feedback is clear and actionable, as it directs the authors to provide additional evidence or examples to substantiate their claim. By addressing this point, the authors can enhance the credibility and robustness of their argument. However, the comment could be more helpful if it suggested specific types of support materials or examples that would strengthen the claim. Overall, the comment is mostly helpful as it effectively points out a gap in the paper that the authors can address to improve its rigor and persuasiveness.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should demonstrate the applicability of MiPKD to other computer vision (CV) tasks beyond SR tasks. It encourages the authors to conduct additional experiments on a broader range of tasks to enhance the method\\'s perceived generalizability. While the comment provides a clear action\u2014conducting additional experiments\u2014it does not specify which tasks should be included or how to conduct these experiments. The authors are left to infer the details of how to implement this suggestion, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"performance in SR tasks\" and suggests that the paper should demonstrate applicability to other CV tasks. It also provides specific guidance on how to enhance the method\\'s perceived generalizability by conducting additional experiments on a broader range of tasks. This level of detail allows the authors to accurately identify the parts of the paper being addressed and what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper primarily discusses MiPKD\\'s performance in SR tasks but does not mention that MiPKD is not specially designed for SR tasks. The comment encourages the authors to show the applicability of MiPKD to other CV tasks and suggests conducting additional experiments to enhance its perceived generalizability. However, the comment lacks specific examples or references to support the claim that MiPKD is not designed for SR tasks. This makes the claim somewhat verifiable, as the authors would need to infer the basis of the claim and potentially conduct additional research to fully understand and address it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that MiPKD is primarily discussed in the context of SR tasks but is not specially designed for them. It suggests that the authors should demonstrate the applicability of MiPKD to other CV tasks to enhance its perceived generalizability. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental scope and demonstrate the method\\'s versatility. However, the comment could be more helpful if it offered examples of other tasks where MiPKD could be applied or provided guidance on how to conduct these additional experiments. Overall, the comment is mostly helpful as it effectively guides the authors in improving the generalizability and applicability of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Equations 21 and 22, which describe an alternative scheme, may be omitted as they are not actually used and do not impact the flow of the section. This feedback provides a clear and explicit action for the authors to consider removing these equations if they are not necessary for the paper\\'s flow. The comment is specific in identifying the equations and their potential impact on the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Equations 21 and 22,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that these equations describe an alternative scheme that is not used and may be omitted without affecting the flow of the section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equations 21 and 22 are not used and may be omitted without affecting the flow of the section. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these equations are unnecessary or how omitting them would impact the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that Equations 21 and 22 describe an alternative scheme that is not actually used and may be omitted without affecting the flow of the section. This feedback is clear and actionable, as it suggests that the authors consider removing these equations if they are not necessary for the paper\\'s flow. However, the comment could be more helpful if it provided additional context or justification for why these equations are not essential. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the optimization module applies a simple iteration strategy to optimize the two loss functions, which implies that the model is not innovative or original. However, it does not provide specific guidance on how the authors could address this issue or suggest alternative approaches to improve the model. The comment lacks concrete actions or detailed suggestions, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the optimization module applies a simple iteration strategy to optimize the two loss functions, implying that the model is not innovative or original. However, it does not specify which part of the paper this optimization module is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the optimization module are considered simple or incremental. Without clear references or detailed feedback, the authors cannot effectively address the critique. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the optimization module applies a simple iteration strategy to optimize the two loss functions, suggesting that the model is not innovative or original. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to traditional approaches that the model is standing on, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the optimization module applies a simple iteration strategy to optimize the two loss functions, which implies that the overall model is not innovative or original. It points out that the model seems to be an incremental improvement over traditional approaches. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors could address this issue or improve the model. Without detailed guidance or examples, the authors are left without a clear path forward. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing of the paper could be improved by clarifying the choice of F(X) for the E(d) case. It also requests that the authors elaborate on the construction of F(X) in the main paper and provide examples for the other two in the appendix. While the comment provides a clear direction for improvement, it does not specify which parts of the paper need elaboration or which examples should be included. The action is explicit but somewhat vague, as the authors know they need to provide more detail but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the writing of the paper could be improved, specifically regarding the choice of F(X) for the E(d) case. It also requests that the authors elaborate on the construction of F(X) in the main paper and provide examples in the appendix. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The suggestion to elaborate on the construction of F(X) is specific, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing of the paper could be improved by clarifying the choice of F(X) for the E(d) case. It also requests that the authors elaborate on the construction of F(X) in the main paper and provide examples in the appendix. However, the comment lacks specific examples or references to support the claim that the choice of F(X) is unclear or confusing. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper\\'s writing, suggesting that the choice of F(X) for the E(d) case could be better explained. It provides a clear and actionable suggestion by recommending that the authors elaborate on the construction of F(X) in the main paper and provide examples in the appendix. This feedback is valuable as it directs the authors to enhance the clarity and comprehensibility of their work, which can significantly improve the paper\\'s readability and accessibility. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to construct F(X) or what aspects of the explanation should be emphasized. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implicit assumptions that the paper makes to ensure the success of few-shot learning. It suggests that the paper might rely on the meta-distribution assumption or distribution-closeness assumption. While the comment implies that the authors should clarify these assumptions, it does not provide explicit guidance on how to do so or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should address these assumptions but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the implicit assumptions that the paper makes to ensure the success of few-shot learning. It suggests that the paper might rely on the meta-distribution assumption or distribution-closeness assumption. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in identifying the assumptions that need to be clarified, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the implicit assumptions that the paper makes to ensure the success of few-shot learning. It suggests that the paper might rely on the meta-distribution assumption or distribution-closeness assumption. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these assumptions are relevant or how they might impact the paper\\'s findings. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the implicit assumptions that the paper makes regarding the success of few-shot learning. It suggests that the paper might rely on the meta-distribution assumption or distribution-closeness assumption, which are common in the field. This feedback is somewhat helpful as it prompts the authors to consider and clarify these assumptions, which could enhance the transparency and robustness of their work. However, the comment could be more helpful if it provided specific examples or references to these assumptions, as this would guide the authors on how to address the issue more effectively. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for standard benchmarks in the literature to facilitate comparison with prior work. While the comment provides a clear direction for improvement, it does not specify which specific tasks or benchmarks should be included or how to implement these changes. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for standard benchmarks in the literature to facilitate comparison with prior work. However, the comment does not specify which part of the paper this suggestion pertains to, such as specific sections or results where these comparisons should be included. While the authors might have an idea of where these comparisons should be made, the comment lacks full grounding. It is specific in suggesting improvements but does not provide detailed guidance on how to implement them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for standard benchmarks in the literature to facilitate comparison with prior work. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to prior work or standard benchmarks that could be considered. This makes the claim somewhat verifiable, as the authors would need to infer the specific tasks and benchmarks to address the suggestion effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the comparison to prior work, suggesting that it could be more thorough by considering other tasks and large-scale models. It also recommends providing results for standard benchmarks in the literature to facilitate comparison with prior work. This feedback is clear and actionable, as it provides specific areas for improvement that could enhance the comprehensiveness and relevance of the comparison. However, the comment could be more helpful if it included examples of which tasks or benchmarks should be considered or how to effectively present the comparison results. Overall, the comment is mostly helpful as it guides the authors toward improving the depth and scope of their comparisons.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved by suggesting that the authors explore more innovative approaches or consider alternative methods. However, the comment does not provide specific guidance on how to achieve this improvement or what alternative methods could be considered. The action is implicit and somewhat vague, as the authors can infer that they need to explore more innovative approaches but are not given concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not specify which part of the paper this assessment is based on, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment also suggests that the contribution could be improved, but it does not provide specific guidance on how to achieve this improvement. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is under-specific in terms of what needs to be improved.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or examples to substantiate the comparison to a traditional removal method, making it difficult for the authors to understand the basis of the critique. As a result, the claim is not fully verifiable, as it relies on a general assertion without sufficient evidence or explanation. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It acknowledges that the contribution of the manuscript still has room for improvement, but does not provide specific guidance or suggestions on how to enhance the contribution. The comment lacks actionable feedback or detailed insights into what aspects of the manuscript could be improved or how the authors might differentiate their work from existing approaches. As a result, the comment is somewhat helpful, as it identifies a potential issue but does not offer concrete steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two issues with the paper: the abstract nature of Benefit 1 and the lack of supporting references for Benefit 3. While it points out specific problems, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more contextual detail for Benefit 1 and address the lack of supporting references for Benefit 3. The feedback is somewhat actionable as it highlights areas that need improvement, but it lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the three claimed benefits of the paper, specifically mentioning \"understanding the agent\u2019s performance post-training from the learning process of the policy and the sequences of training tasks.\" This provides full grounding as it clearly identifies the part of the paper being discussed. However, the comment is not specific as it does not detail what aspects of the benefits are difficult to grasp or lack contextual detail. Additionally, it does not specify what specific references are missing or how the broad statements in Benefit 3 could be supported. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the three claimed benefits of the paper are difficult to grasp, specifically mentioning that Benefit 1 is too abstract and lacks contextual detail. It also criticizes Benefit 3 for including broad statements without supporting references. While the comment identifies specific issues with the claims, it does not provide detailed reasoning or examples to support the claim that the benefits are difficult to grasp or lack contextual detail. The mention of unsupported references is specific but lacks detailed examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper\\'s claims regarding the benefits of understanding the agent\\'s performance post-training. It points out that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements without supporting references. This feedback is somewhat helpful as it highlights areas where the paper could be improved by providing more context and evidence to support its claims. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what kind of contextual detail or references would be beneficial. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem and notes that the qualitative results are impressive but insufficient for evaluating effectiveness. It also provides a general conclusion about the paper, noting that it presents an interesting and novel approach with sufficient experimental evidence to show effectiveness. However, the comment does not provide explicit guidance on what specific quantitative results should be included or how to address the issue of limited impact. The authors are left to infer that they need to provide quantitative results, but without detailed instructions on how to do so, the action remains vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem and provides a general conclusion about the paper. It does not specify which part of the paper this issue pertains to, making it weakly grounded. However, it does specify the issue of the lack of quantitative results and the need for more evidence to evaluate effectiveness. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but insufficient for evaluating effectiveness. The reviewer provides a general conclusion about the paper, stating that it presents an interesting and novel approach with sufficient experimental evidence to show effectiveness. However, the comment also acknowledges the limited impact of the approach, which is a subjective judgment. The claim is somewhat verifiable as it provides some reasoning and evidence, but it lacks specific examples or detailed justification to fully substantiate the claim about the impact. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point about the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but insufficient for evaluating effectiveness. It also provides a general conclusion about the paper, noting that it presents an interesting and novel approach with sufficient experimental evidence to show effectiveness. However, the comment acknowledges the limited impact of the approach, which is a significant concern. While the feedback identifies a gap in the paper\\'s quantitative results, it lacks specific suggestions on how to address this issue or what additional quantitative results could be included. This limits the comment\\'s helpfulness, as it provides insight but does not offer actionable guidance for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the categorization of the paper under the Fairness/Accountability/Transparency (FAT) framework. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to address this concern. The comment lacks guidance on what the authors should do to clarify the categorization or if there are specific aspects that need to be considered. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the categorization of the paper under the Fairness/Accountability/Transparency (FAT) framework, but it does not specify which part of the paper is being addressed. The authors cannot confidently determine which section or aspect of the paper is being questioned. Additionally, the comment lacks specificity regarding what aspect of the categorization is unclear or inaccurate. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the categorization of the paper under the Fairness/Accountability/Transparency (FAT) framework. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about the categorization of the paper under the Fairness/Accountability/Transparency (FAT) framework, which could indicate a misunderstanding or misalignment with the paper\\'s content. However, it does not provide any context or explanation for why the categorization is questionable or what aspects of the paper might be misaligned with the FAT framework. Without additional context or guidance, the authors may struggle to understand the basis of the question or how to address it. Therefore, the comment is barely helpful, as it identifies a potential issue but lacks depth and actionable suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include machine learning 2-step baselines to compare their approach with NaviFormer. This feedback implies that the current comparison to heuristic methods is insufficient and that a more comprehensive evaluation would be beneficial. However, the comment does not provide specific guidance on how to implement this suggestion or what specific machine learning baselines should be included. While the action is implied, it lacks concrete details on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison to baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including machine learning 2-step baselines to provide a more comprehensive comparison. This feedback is clear and provides a clear direction for improvement, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that all approaches appear to be heuristic methods and suggests that including machine learning 2-step baselines would provide a more comprehensive comparison. The reviewer provides a logical reasoning by pointing out that the improvement could be due to the class of algorithm rather than the authors\\' assertion of NaviFormer\\'s superiority. However, the comment lacks specific examples or references to support the claim that NaviFormer beats baselines due to its joint tackling of routing and path planning problems. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the comparison of the proposed approach to baselines, noting that all approaches appear to be heuristic methods. It suggests that including machine learning 2-step baselines would provide a more comprehensive comparison, as the improvement could be due to the class of algorithm rather than the authors\\' assertion of NaviFormer\\'s superiority. This feedback is clear and actionable, as it points out a specific area for improvement and offers a concrete suggestion for enhancing the comparison. However, the comment could be more helpful if it provided examples of machine learning 2-step baselines that could be considered. Overall, the comment is mostly helpful as it guides the authors toward a more robust evaluation of their approach.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct a fair comparison by applying the planning and layering method to the design image generated by other image generative models. This explicit suggestion provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific in detailing the need for a fair comparison and provides a concrete example of how to implement it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests a fair comparison by applying the planning and layering method to the design image generated by other image generative models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this comparison could be made. The authors can infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in suggesting a fair comparison, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results might be better than other methods due to a better image generative model. However, it does not provide any evidence, reasoning, or references to support this claim. The suggestion to conduct a fair comparison by applying the planning and layering method to the design image generated by other image generative models is logical but lacks specific examples or detailed justification. This makes the claim somewhat verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results, suggesting that the better performance might be due to a better image generative model rather than the method being evaluated. It provides a specific suggestion for a fair comparison by applying the planning and layering method to the design image generated by other image generative models. This feedback is clear and actionable, offering a concrete step for the authors to take in order to validate their results and improve the clarity of their paper. However, the comment could be more helpful if it provided additional context or examples of how this comparison could be conducted. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the comparative study should include more advanced baselines, such as SOTA methods mentioned in the literature. It provides specific references to relevant works, which are Ma et al (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019). This guidance is clear and concrete, as it directly instructs the authors to include these references in their comparative study. The action is explicit and leaves no ambiguity, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"comparative study,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more advanced baselines, such as SOTA methods, in the comparative study. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparative study should include more advanced baselines, such as SOTA methods, to justify the authors\\' claims about the modality-missing data. The comment provides specific references to relevant works, including Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019), which supports the suggestion that more advanced baselines should be included. This provides a clear and robust foundation for the claim, making it mostly verifiable. However, the comment could be further strengthened by explaining why these specific works are relevant or how they would impact the comparative study. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the comparative study, noting that the proposed method was compared with relatively simple baselines but not with state-of-the-art (SOTA) methods. It provides a clear and actionable suggestion by recommending the inclusion of specific SOTA methods, such as Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019). This feedback is valuable as it guides the authors to enhance their comparative study, which could significantly impact the credibility and relevance of their findings. By addressing this suggestion, the authors can strengthen their work and provide a more comprehensive evaluation of their method. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion of the dataset is confusing and suggests that if the information is not relevant to the experiments, it should not be mentioned. This feedback provides a clear and explicit action for the authors to take, which is to clarify or remove the confusing information. The comment is specific about what needs to be addressed, making it highly actionable. The authors know exactly what changes to make to improve the clarity of their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 329-334,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the discussion of the dataset, particularly the mention of \"opinion holder\" and \"opinion targets.\" The comment suggests that if these pieces of information are not relevant to the experiments, they should not be mentioned. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion of the dataset is confusing, specifically mentioning the terms \"opinion holder\" and \"opinion targets.\" The reviewer suggests that if these terms are not relevant to the experiments, they should not be mentioned. However, the comment does not provide any supporting evidence or reasoning to justify why these terms are confusing or unrelated to the experiments. Without additional context or explanation, the claim remains somewhat verifiable, as the authors may find it challenging to understand the basis of the confusion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the discussion regarding the dataset, noting that the terms \"opinion holder\" and \"opinion targets\" are confusing and potentially unrelated to the experiments. It suggests that if these terms are not relevant, they should not be mentioned. This feedback is clear and actionable, as it provides the authors with a specific area to focus on for improving the clarity and relevance of their discussion. By addressing this issue, the authors can enhance the readability and comprehensibility of their paper. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the capsule networks, specifically the group CapNet being deeper than the simple CapNet and the lack of information on the number of parameters in the group CapNet. This implies that the authors should provide this information to enable a proper evaluation of the benefits of enforcing equivariance strictly. However, the comment does not explicitly instruct the authors to include this information, leaving it somewhat vague. While the action is implied, the authors can infer that they need to provide this information, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"previous comment\" and the \"group CapNet,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of information on the number of parameters in the group CapNet and the potential impact on the evaluation of enforcing equivariance strictly. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the capsule networks, specifically the group CapNet being deeper than the simple CapNet and the lack of information on the number of parameters in the group CapNet. The comment suggests that this could impact the evaluation of enforcing equivariance strictly. However, the comment does not provide specific examples or references to support the claim that the original CapNet captures some variations in the data. This lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the significance of the issue themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the capsule networks, specifically the group CapNet being deeper than the simple CapNet and the lack of information on the number of parameters in the group CapNet. This highlights a gap in the experimental setup that could impact the authors\\' ability to evaluate the benefits of enforcing equivariance strictly. The comment suggests that the original CapNet may capture some variations in the data, which is an important consideration for the authors to address. However, the comment does not provide specific suggestions or guidance on how to address this issue or what additional information should be included. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific critique of the paper regarding the challenge of obtaining meaningful gradients with respect to noisy intermediate images, referencing previous approaches like DiME and FastDiME. It also mentions a specific implementation by He et al. that addresses this issue. However, the comment does not explicitly instruct the authors on how to address this issue or suggest improvements. While it points out a potential problem, it lacks actionable guidance on how to resolve it. The authors are left to infer that they should consider these references or approaches, but the comment does not provide concrete steps for implementation. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the challenge of obtaining meaningful gradients with respect to noisy intermediate images, referencing previous approaches like DiME and FastDiME. The comment provides specific examples of existing solutions, such as computing gradients with respect to denoised images, which adds clarity to the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the challenge of obtaining meaningful gradients with respect to noisy intermediate images, referencing previous approaches like DiME and FastDiME. The reviewer provides specific references to these approaches, which adds a level of verifiability to the claim. However, the comment could be strengthened by providing more detailed comparisons or examples of how these approaches address the issue, which would further substantiate the claim. As it stands, the comment is mostly verifiable, as it provides a solid foundation for the authors to explore and address the challenge.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper regarding the challenge of obtaining meaningful gradients with respect to noisy intermediate images. It references previous approaches like DiME and FastDiME, which have addressed this issue, and provides specific examples of how these approaches compute gradients with respect to denoised images. This feedback is valuable as it highlights a potential gap in the paper and suggests ways to address it. However, the comment could be more helpful if it provided additional guidance on how the authors might incorporate these approaches or adapt them to their specific context. Overall, the comment is mostly helpful as it directs the authors to relevant literature and offers a starting point for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include an evaluation of inference speed on the hardware. This is a clear and direct action, as it specifies a specific improvement that the authors should make to enhance the paper. The comment provides a concrete suggestion for enhancing the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that an evaluation of inference speed on the hardware would be beneficial. However, it does not specify which part of the paper this evaluation should be included in, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an evaluation of inference speed, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an evaluation of inference speed on the hardware would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an evaluation of inference speed on the hardware would be beneficial. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, which could enhance its comprehensiveness and credibility. However, the comment lacks specific guidance on how to conduct this evaluation or what aspects of inference speed should be evaluated. While it points out a potential gap, it does not provide detailed instructions or examples on how to address it. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for the SDP (Semi-Definite Programming) formulation, which is a specific request for information that the authors need to provide. This is a clear and direct action, as it specifies exactly what the reviewer is looking for, making it highly actionable. The authors know exactly what additional information is needed to address the comment.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"modified problem\" and the \"SDP formulation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the SDP formulation, and it implies that the authors should provide this information. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the modified problem is convex and can be solved via an SDP. However, it does not provide any supporting evidence, reasoning, or references to challenge this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the reviewer\\'s skepticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of an SDP (Semi-Definite Programming) formulation for the modified problem. This is a clear and actionable point, as it prompts the authors to provide the missing information. By addressing this issue, the authors can improve the clarity and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present the SDP formulation effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the evaluation of compositional generalizability, noting that the number of new task combinations used for evaluation is not mentioned in line 558. Additionally, it points out that the test results in Table 7 are based on only 30 composite instructions. While the comment identifies the specific line and table where the issue is located, it does not provide explicit guidance on how to address this issue. The authors can infer that they need to include the number of task combinations used and possibly expand the test results to include more composite instructions. However, the action is implicit and somewhat vague, as it lacks detailed instructions on how to implement the suggested changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 558\" and \"Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the number of new task combinations used for evaluation and the limited number of composite instructions in the test results. This provides clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of new task combinations used for evaluating compositional generalizability is not mentioned in line 558 and that the test results in Table 7 are based on only 30 composite instructions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the evaluation. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of compositional generalizability, noting that the number of new task combinations used for evaluation is not mentioned in line 558 and that the test results in Table 7 are based on only 30 composite instructions. This feedback is clear and actionable, as it points out a specific area where the authors need to provide more detail and context to enhance the transparency and comprehensiveness of their evaluation. By addressing this issue, the authors can improve the clarity and robustness of their results. However, the comment could be more helpful if it suggested ways to expand the evaluation or provided examples of how to present the additional information. Overall, the comment is mostly helpful as it effectively guides the authors on how to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper, particularly the figures, is not well-organized in terms of layout. However, it does not provide any specific guidance or suggestions on how to improve the layout or what aspects of the layout need attention. The comment lacks explicit instructions or concrete details on how to address the issue, leaving the authors uncertain about how to make the necessary changes. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions the layout of the paper, particularly the figures, which provides some grounding as it suggests a specific area of the paper that needs attention. However, it does not specify which figures or parts of the layout are problematic, making it weakly grounded. The comment is specific in identifying the issue with the layout, but it lacks detailed guidance on how to improve it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper, particularly the figures, is not well-organized in terms of layout. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting that the layout, particularly the figures, is not well-organized. However, it lacks depth and does not provide any specific suggestions or guidance on how to improve the layout or what aspects of the figures need attention. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is barely helpful, as it points out a problem but does not offer a way for the authors to improve their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the lack of clear differentiation from existing works and detailed comparisons with similar techniques, which could affect the perceived novelty and value of the paper. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should provide a more detailed comparison or differentiation, but it lacks specific instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more comprehensive comparison or differentiation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a concern about the lack of clear differentiation from existing works and detailed comparisons with similar techniques, which could affect the perceived novelty and value of the paper. However, it does not specify which part of the paper this issue pertains to, such as specific sections or comparisons that need improvement. The authors can infer that it relates to the discussion of related work or the comparison with other techniques, but this inference is not direct. The comment is specific in detailing the issue of lacking differentiation and comparisons, but it is not grounded as it does not explicitly mention which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks clear differentiation from existing works and detailed comparisons with similar techniques, which could affect the perceived novelty and value of the work within the NLP community. This claim is somewhat verifiable as it logically suggests that a lack of differentiation and comparisons could impact the perception of the paper. However, the comment does not provide specific examples or references to existing works or techniques that could be used for comparison, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, noting that it lacks clear differentiation from existing works and detailed comparisons with similar techniques. This lack of differentiation could affect the perceived novelty and value of the work within the NLP community. The comment highlights a crucial aspect of the paper that needs attention, providing a clear direction for improvement. However, it does not offer specific suggestions or examples of how the authors might address this issue, such as which existing works to compare with or how to differentiate their approach. While the feedback is valuable, it could be more actionable with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explain the discrepancy between the baseline results in Table 2 and those from Table 3 in [3]. This is a clear and direct action that the authors can take to address the issue. The comment provides a specific point of interest and guidance on what needs to be clarified, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3 in [3],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the discrepancy between the baseline results in the two tables. This provides clear guidance on what the authors need to clarify or explain in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the discrepancy between the baseline results in Table 2 and those from Table 3 in [3]. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific issue with the paper, namely the discrepancy between the baseline results in Table 2 and those from Table 3 in [3]. By pointing out this inconsistency, the comment prompts the authors to clarify or explain the reason for the difference, which is crucial for maintaining the integrity and credibility of their work. This feedback is clear and actionable, guiding the authors to address a critical aspect of their analysis. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the use of \"execution feedback\" in the title and Figure 2 is misleading, as no execution feedback is actually used in the work. It clarifies that execution feedback is approximated based on structural perturbations in the Abstract Syntax Tree (AST) and that the authors assume any such perturbation results in a failure as execution feedback (EF = 0). The reviewer also notes that there is no guarantee that such perturbations will make the tests fail, as seen in Equation 1. The comment provides a clear and explicit action for the authors to correct the misleading use of \"execution feedback\" in their paper. The authors are given specific guidance on how to revise their terminology and ensure that their work accurately reflects the methods used. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"Lines 233-238,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the use of \"execution feedback\" in the title and Figure 2, explaining that no execution feedback is actually used in the work. The comment further details the misleading nature of the term \"execution feedback\" and clarifies that it is based on structural perturbations in the AST, not actual execution feedback. Additionally, it points out that the authors assume any such perturbation results in a failure as execution feedback, which is not guaranteed. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"execution feedback\" is misleading, as no execution feedback is actually used in the work. It further explains that execution feedback is approximated based on structural perturbations in the Abstract Syntax Tree (AST) and that the authors assume any such perturbation results in a failure as execution feedback (EF = 0). The reviewer references specific lines of code (Lines 233-238) to support this claim. Additionally, the comment provides a logical explanation of how execution feedback is defined in Equation 1, which helps clarify the issue. This detailed reasoning and reference to specific lines of code make the claim mostly verifiable, as it provides a clear understanding of the misleading nature of the term \"execution feedback.\" Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the use of terminology in the paper, specifically the misleading use of \"execution feedback.\" It points out that no execution feedback is actually used in the work, as it is approximated based on structural perturbations in the Abstract Syntax Tree (AST). The reviewer provides a detailed explanation of how execution feedback is defined and clarifies that the authors assume any such perturbation results in a failure as execution feedback (EF = 0). This feedback is highly valuable as it helps the authors understand the misleading nature of their terminology and correct it to accurately reflect their work. By addressing this issue, the authors can improve the clarity and accuracy of their paper, making the comment highly helpful. Therefore, it deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two specific areas where additional information is needed: the use of \"40 target words\" and the method of removing bias through \"a sequence of dots.\" It also points out the lack of detail regarding the number of games sampled to demonstrate the severity of the bias problem. While the comment identifies specific areas that need clarification or expansion, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more information on these topics, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"40 target words\" and \"a sequence of dots,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by pointing out the lack of information regarding the use of \"40 target words\" and the method of removing bias through \"a sequence of dots.\" Additionally, it highlights the absence of detail regarding the number of games sampled to demonstrate the severity of the bias problem. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of information regarding the use of \"40 target words\" and the method of removing bias through \"a sequence of dots.\" It also questions the lack of detail regarding the number of games sampled to demonstrate the severity of the bias problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks detail and clarity, particularly regarding the use of \"40 target words\" and the method of removing bias through \"a sequence of dots.\" It also points out the lack of detail regarding the number of games sampled to demonstrate the severity of the bias problem. This feedback is clear and actionable, as it directs the authors to provide more information in these areas to enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it effectively guides the authors in improving their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments are conducted on simple datasets and that the uniformly random missing is unrealistic in practice. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these issues, such as suggesting alternative datasets or methods to improve realism. The lack of actionable advice leaves the authors without a clear path forward, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the experiments conducted on simple datasets and the unrealistic nature of the uniformly random missing. However, it does not specify which part of the paper these experiments are discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the experiments are considered unrealistic or how they could be improved. Without clear guidance on where to focus the revision, the authors may struggle to address the issues effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experiments are conducted on simple datasets and that the uniformly random missing is unrealistic in practice. However, it does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experiments conducted on simple datasets and the unrealistic nature of the uniformly random missing. However, it does not provide specific guidance or suggestions on how to address these concerns, such as recommending alternative datasets or methods to improve realism. The comment highlights a potential weakness but lacks actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include legends for the plots in Figure 4, which would make them easier to interpret. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific suggestion on what needs to be added, ensuring that the authors know exactly what is expected of them. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of legends for the plots to improve interpretability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4 lacks legends, making it difficult to interpret the plots. This is a factual observation about the content of the figure. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why legends are necessary or how they would improve interpretation. Without additional context or explanation, the claim remains somewhat verifiable, as it lacks detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that it lacks legends for the plots, making them difficult to interpret. This feedback is clear and actionable, as it directly suggests that the authors should include legends to improve the figure\\'s clarity. By addressing this point, the authors can enhance the reader\\'s understanding and interpretation of the data presented. However, the comment could be more helpful if it provided additional guidance on how to label the plots or what information should be included in the legends. Overall, the comment is mostly helpful as it effectively points out a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the paper is specifically focused on sequence-to-sequence (seq2seq) models and suggests that the general quantization aware training strategy could be extended to other models. It also asks if there are specific benefits of the proposed robustness-aware quantization scheme for seq2seq models. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete steps for how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to these questions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the focus of the paper on sequence-to-sequence (seq2seq) models and suggests that the general quantization aware training strategy could be extended to other models. It also asks if there are specific benefits of the proposed robustness-aware quantization scheme for seq2seq models. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where quantization and seq2seq models are discussed. The comment is specific in its request for clarification and highlighting any benefits for seq2seq models. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the focus of the paper on sequence-to-sequence (seq2seq) models and suggests that the general quantization aware training strategy could be extended to other models. It also asks if there are specific benefits of the proposed robustness-aware quantization scheme for seq2seq models. The comment is somewhat verifiable as it provides a logical reasoning for the question, but it lacks specific examples or references to support the claim that the general quantization strategy could be extended to other models. The suggestion to highlight specific benefits for seq2seq models is reasonable but not fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the focus of the paper on sequence-to-sequence (seq2seq) models and suggests that the general quantization aware training strategy could be extended to other models. It also asks if there are specific benefits of the proposed robustness-aware quantization scheme for seq2seq models. While the comment identifies a potential area for improvement by suggesting that the authors highlight specific benefits for seq2seq models, it lacks specific guidance or suggestions on how to address these points. The feedback is somewhat helpful as it prompts the authors to consider the broader applicability of their work, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests additional ablation studies on how the algorithm's behavior and accuracy of its Q estimates change as the hyperparameter lambda changes. This is a clear and direct action for the authors to take, as it provides a specific area for further exploration and analysis. The comment is specific in detailing what additional information is needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 2\" and \"lambda,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests additional ablation studies on how the algorithm's behavior and accuracy of its Q estimates change as lambda changes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional ablation studies on how the algorithm's behavior and accuracy of its Q estimates change as the hyperparameter lambda changes. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification and additional analysis, making it a factual statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by requesting additional ablation studies on how the algorithm's behavior and accuracy of its Q estimates change as the hyperparameter lambda changes. This is a clear and actionable suggestion that can help the authors better understand the impact of their model's hyperparameters on its performance. By addressing this feedback, the authors can enhance the robustness and generalizability of their results. However, the comment could be more helpful if it provided guidance on how to conduct these ablation studies or suggested specific analyses to consider. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for further exploration and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the base encoder of the proposed model and whether the authors train the model from scratch. While it does not explicitly instruct the authors to make any changes or provide specific guidance on how to address the question, it does imply that the authors should clarify this aspect of their work. The action is implicit but concrete, as the authors can infer that they need to provide a clear explanation of the base encoder and training process. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the base encoder of the proposed model and whether the authors train the model from scratch. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification about the base encoder and training process, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for clarification about the base encoder of the proposed model and whether the authors train the model from scratch. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the base encoder of the proposed model and whether the authors train the model from scratch. While it identifies a potential area of confusion or misunderstanding, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward. Therefore, it is rated as barely helpful, as it points out a potential weakness but does not offer any direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the Ethical Statement is well written but should be extended with more concrete discussion on challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment implies that the authors should add more discussion, it does not explicitly instruct them to do so or provide specific guidance on how to address these challenges. The action is implicit and somewhat vague, as the authors need to infer that they should expand the Ethical Statement to include these topics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Ethical Statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more concrete discussion on challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Ethical Statement is well written but should be extended with more concrete discussion on challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. However, the comment does not provide any specific examples, reasoning, or references to support why these challenges are important or how they could be addressed. Without additional context or evidence, the claim is somewhat verifiable, as it lacks detailed justification or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the Ethical Statement, suggesting that it should be extended to include more concrete discussion on challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their Ethical Statement and address potential gaps in their analysis. However, the comment could be more helpful if it offered specific examples or suggestions on how to incorporate these discussions into the paper. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the transformation from $\\\\hat{m}_t$ and $g_t$ in equation (13) to $x$ in equation (14). While it does not explicitly instruct the authors to clarify this transformation, the question implies that the authors should provide a clear explanation or justification for this change. The action is implicit but concrete, as the authors can infer that they need to address this issue to improve the clarity of their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (13)\" and \"equation (14),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the transformation from $\\\\hat{m}_t$ and $g_t$ to $x$ in equation (14). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the transformation from $\\\\hat{m}_t$ and $g_t$ to $x$ in equation (14). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the transformation from $\\\\hat{m}_t$ and $g_t$ to $x$ in equation (14), which is a clarity issue that could impact the understanding of the paper. While it identifies a specific area that needs clarification, the comment does not provide any suggestions or guidance on how the authors might address this issue. Without actionable feedback or additional context, the authors may find it challenging to improve the clarity of their draft. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the length of the mini-batches tau_t being non-integers and suggests that this should be clarified to ensure there are no side effects. The reviewer also raises a question about what happens if tau_t is very small, implying that the analysis might not be valid in this case. While the comment identifies a specific issue that needs clarification, it does not provide explicit instructions on how to address it or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the issue and address the question about the analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"length of the mini-batches tau_t,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the potential issue with non-integer values of tau_t and the question about what happens if tau_t is very small. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the length of the mini-batches tau_t being non-integers and suggests that this should be clarified to ensure there are no side effects. The reviewer questions what happens if tau_t is very small, implying that the analysis might not be valid. However, the comment lacks specific examples or references to support the claim that the analysis might be invalid. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the length of the mini-batches tau_t being non-integers, which could lead to side effects. It raises a specific question about what happens if tau_t is very small, suggesting that the analysis might not be valid in this case. This feedback is clear and actionable, as it prompts the authors to clarify this aspect of their work to ensure its validity. However, the comment could be more helpful if it provided additional guidance on how to address this issue or what specific aspects of the analysis might be affected. Overall, the comment is mostly helpful as it highlights a critical aspect of the paper that needs clarification, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to examine the computational cost associated with the inference process of the SCALE model, specifically mentioning the two types of decoding: STM decoding and LLM decoding. This provides a clear and concrete action for the authors to take, as they are directly told what aspect of the model to analyze and how it relates to the inference cost. The comment is specific and provides a direct path for the authors to follow in order to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SCALE model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the computational cost associated with the inference process of the SCALE model, and it differentiates between STM decoding and LLM decoding. This provides clear guidance on what aspect of the model needs to be analyzed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the SCALE model involves two types of decoding, STM decoding and LLM decoding, and suggests that it is important to examine the computational cost associated with the inference process of the SCALE model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is important or how it affects the overall performance of the model. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to be considered fully verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors examine the computational cost associated with the inference process of the SCALE model. It highlights the importance of considering both STM decoding and LLM decoding, which are two types of decoding used in the model. This feedback is clear and actionable, as it directs the authors to a specific aspect of the model that could impact its performance and efficiency. However, the comment could be more helpful if it provided additional context or examples on how to measure or analyze the computational cost. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues with the paper: the use of a subset of the complete dataset and the lack of performance comparisons with state-of-the-art models, making it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it points out some peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment identifies these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to expand their dataset and include comparisons with state-of-the-art models, but the comment lacks concrete suggestions on how to implement these changes. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"the 5th row,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the paper: the use of a subset of the complete dataset and the lack of performance comparisons with state-of-the-art models, as well as the peculiar experimental results. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only uses a subset of the complete dataset and lacks performance comparisons with state-of-the-art models, making it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it points out some peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. The comment provides some logical reasoning by highlighting the importance of using a complete dataset and comparisons with state-of-the-art models to demonstrate effectiveness. However, it lacks specific examples or references to support the claim about the peculiar experimental results. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper: the use of a subset of the complete dataset and the lack of performance comparisons with state-of-the-art models, making it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it points out some peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to address them. The authors are left with a general understanding of the problems but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, it does not provide any guidance on how the authors should address this issue or what specific aspects of the phrase need further elaboration. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"lacks inherent semantic meaning,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of elaboration on the meaning of the phrase. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. This feedback highlights a potential gap in the paper\\'s explanation or justification, which could lead to confusion or misunderstanding by readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what additional elaboration might be needed. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors do not provide sufficient details or justification for using a large number of hidden units and an additional elementwise function. It also mentions that treating unobserved ratings as zeros may introduce bias, which is not justified. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific details or justifications are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the use of a large number of hidden units and an additional elementwise function, as well as the treatment of unobserved ratings as zeros. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of justification for using a large number of hidden units and the potential bias introduced by treating unobserved ratings as zeros. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not provide sufficient details or justification for using a large number of hidden units and an additional elementwise function, and that treating unobserved ratings as zeros may introduce bias, which is not justified. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, particularly regarding the use of a large number of hidden units and an additional elementwise function. It also points out that treating unobserved ratings as zeros may introduce bias, which is not justified. This feedback is somewhat helpful as it highlights areas where the authors need to provide more detailed justification or explanation. However, the comment could be more helpful if it suggested ways to address these issues or provided examples of how similar approaches have been justified in the literature. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the claim regarding motivation is not robust, as MathGLM achieves a high accuracy of 93.03% on a constructed dataset for complex computations, but these computations can be done with 100% accuracy using other tools. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the robustness of the claim or what specific steps to take to ensure its validity. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim regarding motivation, specifically mentioning the high accuracy of 93.03% achieved by MathGLM on a constructed dataset for complex computations. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing the issue with the claim, noting that these complex computations can be done with 100% accuracy using other tools. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for the paper is not robust, as MathGLM achieves a high accuracy of 93.03% on a constructed dataset for complex computations, which can be done with 100% accuracy using other tools. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains unverifiable, as it does not provide sufficient justification for the authors to address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a weakness in the paper\\'s claim regarding motivation, specifically noting that MathGLM achieves a high accuracy of 93.03% on a constructed dataset for complex computations, which can be replicated with 100% accuracy using other tools. This feedback highlights a potential issue with the robustness of the claim, suggesting that the authors should reconsider the basis of their motivation. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the robustness of the claim. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a significant weakness in the paper, which is the reliance on synthetic datasets for evaluating event-based dense tracking. It suggests that this approach does not truly reflect event-based dense tracking. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might improve their evaluation or what specific steps they could take to better reflect event-based dense tracking. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of using synthetic datasets for evaluating event-based dense tracking, suggesting that this approach does not truly reflect event-based dense tracking. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue with the evaluation method but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of synthetic datasets for evaluating event-based dense tracking does not accurately reflect event-based dense tracking. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without concrete evidence or detailed reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, which is the reliance on synthetic datasets for evaluating event-based dense tracking. It points out that this approach does not truly reflect event-based dense tracking, as it lacks real-world scenarios. This feedback is valuable as it highlights an important limitation in the paper\\'s evaluation methodology, which could impact the validity and applicability of the results. However, the comment could be more helpful if it suggested ways to address this issue, such as recommending the use of real-world datasets or providing guidance on how to better reflect event-based dense tracking. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a critical area for improvement, but it lacks actionable suggestions for enhancing the paper.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the paper's motivation, specifically questioning the opposition to common understanding regarding the importance of diversity in instruction-tuning data. It points out that the experiments are weak due to the limited dataset and LLM size, and the results are unconvincing. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the clarity of their motivation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide stronger justification or validation for their claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation of the paper, specifically questioning the opposition to common understanding regarding the importance of diversity in instruction-tuning data. It mentions the experiments, which are considered weak due to the limited dataset and LLM size. However, the comment does not specify which part of the paper discusses this motivation or the experiments, making it weakly grounded. The comment is specific in detailing the issues with the experiments and the potential for misleading the community, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s motivation is unclear and opposes common understanding regarding the importance of diversity in instruction-tuning data. The reviewer questions the strength of the justification and the persuasiveness of the experiments, noting that the dataset and LLM size are limited. However, the comment lacks specific examples or references to support the claim that the results are unconvincing or potentially misleading. While the reviewer provides some reasoning, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s motivation, noting that it opposes common understanding regarding the importance of diversity in instruction-tuning data without providing strong justification. The reviewer points out that the experiments are weak due to the limited dataset and LLM size, and the results are unconvincing. This feedback is valuable as it highlights a critical area for improvement in the paper, specifically the clarity and persuasiveness of the arguments presented. However, the comment could be more helpful if it provided specific suggestions on how the authors might strengthen their justification or validate their results. Overall, the comment is mostly helpful as it directs the authors\\' attention to a crucial aspect of their paper that needs attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the absence of confidence intervals on the substitution ASR in Table 3. While it implies that the authors should include confidence intervals, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add confidence intervals. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the absence of confidence intervals on the substitution ASR, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment is a request for clarification regarding the absence of confidence intervals in Table 3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the absence of confidence intervals in Table 3, which is a relevant point for clarity and completeness. However, it does not provide any suggestions or guidance on how to address this issue or what impact the absence of confidence intervals might have on the paper. While it identifies a potential gap in the presentation, it lacks actionable advice or context that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out an area for clarification but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the estimation of the mean element, mu_g, for different kernel spaces. However, it does not provide any explicit guidance or suggestions on how to address this issue. The authors are left to infer that they need to clarify this aspect, but without specific instructions or examples, the action remains vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of estimating the mean element, mu_g, for different kernel spaces. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not provide details on what aspects of the estimation process are unclear or how they could be improved. Without additional guidance or examples, the authors may struggle to address the issue effectively. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that it is not clear how to estimate the mean element, mu_g, for different kernel spaces. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the estimation of the mean element, mu_g, for different kernel spaces. This is a clear and actionable point that can help the authors improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how it might be approached. Despite this, the feedback is still valuable as it directs the authors to a critical aspect of their work that needs clarification. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it is still helpful to consider datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, despite some baselines not working on larger datasets. This feedback implies that the authors should consider these datasets as part of their analysis. However, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider these datasets but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, despite some baselines not working on larger datasets. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of these datasets to make the story more complete. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it is still helpful to consider datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, despite some baselines not working on larger datasets. This claim is somewhat verifiable as it provides a logical reasoning for considering these datasets, which could enhance the study's completeness. However, the comment lacks specific examples or references to support the claim that these datasets are beneficial or how they would improve the study. This makes the claim somewhat verifiable, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that despite some baselines not working on larger datasets, it is still beneficial to consider datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions. This feedback provides a constructive suggestion that could enhance the study's completeness by including datasets with larger numbers of clusters. However, the comment lacks specific guidance or examples on how to implement this suggestion or what specific aspects of the study would benefit from this inclusion. While it offers a valuable insight, the lack of detailed instructions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the cosine similarity score would be more effective than the Euclidean distance when computing the Decidability. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps to consider. The authors are left without any clear direction on how to incorporate this suggestion into their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the effectiveness of using cosine similarity over Euclidean distance when computing the Decidability. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this comparison is made. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the cosine similarity score or Euclidean distance should be considered or how they might be compared. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the effectiveness of using cosine similarity over Euclidean distance when computing the Decidability. However, it does not present any evidence, reasoning, or references to support this claim. The comment lacks any justification or explanation for why cosine similarity might be more effective, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the effectiveness of using cosine similarity over Euclidean distance when computing the Decidability. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or suggestions on how to address this issue. The authors are left with a vague question that does not offer actionable steps or detailed reasoning for why cosine similarity might be more effective. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the experiments, including the lack of comparison with other counterpart methods and the insufficiency of the experimental results to validate the proposed method. However, it does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve the experiments. The feedback is vague and lacks concrete steps for the authors to take, leaving them uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the experiments, specifically mentioning that the paper only conducts a toy experiment and an experiment on a real-world dataset. It also points out the lack of comparison with other counterpart methods and the insufficiency of the experimental results to validate the effectiveness of the proposed method. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what is missing or inadequate in the experiments, but without clear grounding, the authors cannot confidently identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are weak and lacks comparison with other counterpart methods. It also criticizes the insufficiency of the experimental results to validate the effectiveness of the proposed method. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several weaknesses in the experiments, including the lack of comparison with other counterpart methods and the insufficiency of the experimental results to validate the effectiveness of the proposed method. It highlights the limited scope of the experiments, which only involve a toy experiment and an experiment on a real-world dataset. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the experimental design. While it points out areas for improvement, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This provides a clear and direct action for the authors to take, which is to ensure that these figures are properly referenced in the appendix. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"figures related to completion errors\" and the \"relevant analysis sections of the appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of reference to these figures in the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their work. By pointing out this oversight, the comment provides valuable guidance on how to enhance the paper\\'s presentation and organization. However, the comment could be more helpful if it offered suggestions on how to effectively reference the figures or provided examples of how this could be done. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether perplexity is measured consistently across validation sets at different levels. While it implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether perplexity is measured consistently across validation sets at different levels. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where perplexity is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the consistency of perplexity measurements, but without grounding, it lacks clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether perplexity is measured consistently across validation sets at different levels. However, it does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency might be an issue or how it affects the paper\\'s conclusions. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the concern. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the consistency of perplexity measurements across validation sets at different levels, which could be an important aspect to clarify in the paper. However, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the perplexity measurements might be problematic. While it identifies a potential area for improvement, the comment lacks depth and actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the setting and algorithm lack originality and are merely incremental combinations of existing methods. However, it also acknowledges the efficiency and novelty of the algorithm for graph labelings. While the comment implies that the authors should consider enhancing the originality of their work, it does not provide specific guidance on how to achieve this or what aspects of the algorithm could be improved to make it more original. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the originality but without concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the setting and algorithm lack originality and are merely incremental combinations of existing methods. However, it does not specify which parts of the paper these claims are based on, making it difficult for the authors to pinpoint the exact sections that need attention. The comment also acknowledges the efficiency and novelty of the algorithm for graph labelings, which could be a positive aspect. Overall, the comment is weakly grounded because it does not specify the part of the paper being addressed, and it is not specific in detailing what needs to be improved or how to enhance originality. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the setting and algorithm lack originality and are merely incremental combinations of existing methods. However, it also acknowledges the efficiency and novelty of the algorithm for graph labelings. The comment provides a somewhat verifiable claim by pointing out the potential lack of originality but does not provide specific examples or references to substantiate the claim. The authors might need to further explore the originality of their work and consider how it differs from existing methods. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the setting and algorithm lack originality and are merely incremental combinations of existing methods, which could be seen as a critique of the paper\\'s contribution. However, it also acknowledges the efficiency and novelty of the algorithm for graph labelings, which is a positive aspect. While the comment identifies a potential weakness in the originality of the work, it does not provide specific suggestions or guidance on how to enhance the originality or differentiate the algorithm from existing methods. The feedback is somewhat helpful as it points out a potential issue but lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with using the state action of the current policy in the target environment as regularization, as it could lead to suboptimal learning. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The comment lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the use of state action of the current policy in the target environment as regularization, suggesting that it could harm learning due to the potential for suboptimal state action distribution. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with using state action as regularization, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using the state action of the current policy in the target environment as regularization can harm learning due to the potential for suboptimal state action distribution. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without concrete evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with using the state action of the current policy in the target environment as regularization, suggesting that it could lead to suboptimal learning due to the distribution of suboptimal state actions. This is a valuable observation that could help the authors reconsider their approach to regularization. However, the comment lacks specific suggestions or guidance on how to address this issue or alternative methods to consider. While it points out a potential problem, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the objective of the feature compactness loss and sharpness-aware minimization, noting that it could negatively impact the model\\'s performance on the base classes. It suggests that if such degradation occurs, the authors should discuss how to mitigate it to maintain performance on the base classes. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss mitigation strategies. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the objective of the feature compactness loss and sharpness-aware minimization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of concern, which is the potential negative impact on the model\\'s performance on base classes. The comment suggests discussing mitigation strategies if such degradation occurs, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the objective of the feature compactness loss and sharpness-aware minimization could negatively impact the model\\'s performance on base classes. However, the comment lacks specific evidence or examples to support this claim. It suggests that if such degradation occurs, the authors should discuss mitigation strategies, but without detailed reasoning or references, the claim remains somewhat verifiable. The authors would need to make a significant effort to understand and address the concern, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the objective of the feature compactness loss and sharpness-aware minimization, noting that it could negatively impact the model\\'s performance on base classes. It suggests that if such degradation occurs, the authors should discuss how to mitigate it to maintain performance on the base classes. This feedback is clear and actionable, as it points out a specific area of concern and provides a direction for improvement. However, the comment could be more helpful if it offered suggestions on how to assess or mitigate the potential degradation. Overall, the comment is mostly helpful as it provides valuable insights and guidance for the authors to address a critical aspect of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: \"What is the insight from this work to develop new methods?\" and \"How to prevent the attention collapse in CL?\" These questions imply that the authors should provide a clear explanation of the insights gained from their work and how they plan to address the issue of attention collapse in CL. However, the comment does not explicitly instruct the authors to do so, nor does it offer specific guidance on how to address these questions. The action is implicit and somewhat vague, as the authors can infer that they need to provide a detailed explanation and solution, but the comment lacks concrete details on how to implement this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions about the insights gained from the work and how to prevent attention collapse in CL. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of explicit grounding and specificity makes it challenging for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two questions: \"What is the insight from this work to develop new methods?\" and \"How to prevent the attention collapse in CL?\" These questions are factual in nature and do not contain subjective claims or opinions that require verification. They are purely requests for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that are relevant to the paper\\'s contribution and potential impact. The first question asks for the insight gained from the work that could lead to the development of new methods. The second question seeks to understand how to prevent attention collapse in CL. While these questions are important and could guide the authors in improving their draft, the comment lacks specific suggestions or guidance on how to address these issues. It does not provide actionable advice or examples, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3, as it offers some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the impact of the CHC model on MLLMs and seeks clarification on specific attributes or behaviors that would result from grounding MLLMs in CHC theory. It also asks if there are any case studies or pilot experiments that illustrate the significance of this influence. While the comment implies that the authors should provide more information or examples to address this question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information to clarify the impact. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main content\" and the \"CHC model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the impact of the CHC model on MLLMs and the specific attributes or behaviors that would result from grounding MLLMs in CHC theory. Additionally, it asks for case studies or pilot experiments to illustrate the significance of this influence. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of the CHC model on MLLMs and seeks clarification on specific attributes or behaviors that would result from grounding MLLMs in CHC theory. It also asks for case studies or pilot experiments to illustrate the significance of this influence. While the comment identifies a gap in understanding, it does not provide specific examples or references to support the claim that the CHC model affects MLLMs. This makes the claim somewhat verifiable, as the authors would need to make a significant effort to address the question effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the impact of the CHC model on MLLMs and seeks clarification on specific attributes or behaviors that would result from grounding MLLMs in CHC theory. It also asks for case studies or pilot experiments to illustrate the significance of this influence. This feedback is clear and actionable, as it guides the authors to provide more detailed information about the relationship between the CHC model and MLLMs. By addressing these questions, the authors can enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider integrating more up-to-date pretraining models to showcase the significance and practical usage of their approach. It provides specific examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation with Hierarchical Prompts,\" which could be integrated. However, the comment does not explicitly instruct the authors on how to integrate these models or what specific aspects of their approach should be compared with these examples. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Pre-GNN\" model and the authors\\' work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the integration of more up-to-date pretraining models to showcase the significance and practical usage of the authors\\' approach. The comment provides examples of recent works, \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which could be integrated. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the pretraining model, Pre-GNN, is relatively old in the context of molecular pretraining and suggests that the authors should consider integrating more up-to-date models to showcase the significance and practical usage of their approach. The reviewer provides some support by mentioning specific recent works, \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which could be integrated. However, the comment lacks detailed reasoning or explanation of why these newer models are more significant or how they would enhance the authors\\' approach. While the suggestion is logical, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific critique of the authors\\' approach by pointing out that the pretraining model, Pre-GNN, is relatively old in the context of molecular pretraining. It suggests that the authors should consider integrating more up-to-date pretraining models to showcase the significance and practical usage of their approach. The comment also provides examples of recent works, \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which could be integrated. This feedback is clear and actionable, as it directs the authors to consider incorporating more recent models to enhance the impact and relevance of their work. However, the comment could be more helpful if it offered guidance on how to integrate these models or what specific aspects of the approach should be compared with the examples provided. Overall, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the model takes the difference between current object pose and target object pose as input, which can present significant engineering challenges. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these challenges or suggestions for improvement. The comment does not offer any concrete steps for the authors to follow, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the model\\'s approach, specifically mentioning the difference between current object pose and target object pose as input. This provides full grounding as it allows the authors to accurately identify the part of the paper being discussed, which is Sec. A.3. The comment is also specific because it highlights the engineering challenges posed by this approach and acknowledges the authors\\' documentation efforts. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges that the model takes the difference between current object pose and target object pose as input, which can present significant engineering challenges. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The comment does not offer any analysis or references to substantiate the claim about engineering challenges, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the model\\'s approach of taking the difference between current object pose and target object pose as input, which can present significant engineering challenges. However, it also highlights that the authors have documented their approach well in Sec. A.3. This feedback is somewhat helpful as it points out a potential issue and provides a positive aspect, but it lacks depth and specific suggestions for improvement. The authors are informed of a potential challenge and the authors\\' efforts to address it, but the comment could be more actionable and detailed to fully support the authors in improving their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more downstream performance examples of their controllable text generation models, specifically mentioning the connection to real NLG applications and the potential advantage of their model. The reviewer also mentions style transfer as a potential starting point. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to implement this suggestion or what specific examples should be included. The action is explicit but somewhat vague in terms of execution, as the authors know they need to provide more downstream performance examples but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 116-117,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more downstream performance examples of the controllable text generation models and how they connect to real NLG applications. The comment suggests using style transfer as a starting point, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more downstream performance examples of their controllable text generation models, specifically mentioning the connection to real NLG applications and the potential advantage of their model. The reviewer suggests that style transfer could be a good starting point. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that style transfer would be beneficial. This makes the claim somewhat verifiable, as the authors would need to make a logical inference to understand the suggestion fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement by recommending that the authors include more downstream performance examples of their controllable text generation models. It specifically mentions the need to connect these models to real NLG applications and highlights style transfer as a potential starting point. This feedback is valuable as it guides the authors on how to enhance the practical relevance and applicability of their work. However, the comment could be more helpful if it provided specific examples or case studies of how these downstream applications could be integrated or how the authors could demonstrate the advantage of their model. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the test set performance on GLUE datasets, specifically asking if the labels for these datasets are not available to the public. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them uncertain about how to proceed. As a result, the action is implicit and vague, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the test set performance on GLUE datasets, specifically asking if the labels for these datasets are not available to the public. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where the test set performance is discussed. Without explicit references or clear indications, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the test set performance is confusing or how it could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the test set performance on GLUE datasets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the test set performance on GLUE datasets, specifically asking if the labels for these datasets are not available to the public. While this question highlights a potential issue with the paper\\'s methodology, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address the confusion or improve their draft. As a result, it offers limited value to the authors in terms of enhancing the clarity or quality of their work. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3.2 may be shortened because many equations are not proposed by the work but are already well-known in the community. It suggests that this would save space to include important missing details. While the comment implies that the authors should shorten the section, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should shorten the section to include missing details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that many equations are not proposed by the work but are already well-known in the community, and suggests that this could save space to include important missing details. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Section 3.2 may be shortened because many equations are not proposed by the work but are already well-known in the community. This claim is somewhat verifiable as it provides a logical reasoning for suggesting a reduction in length, which could save space to include important missing details. However, the comment lacks specific examples or references to well-known equations, making it somewhat verifiable. The authors would need to infer the specific equations and their relevance to the paper, which could be challenging without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper, Section 3.2, where the authors may consider shortening the content. It suggests that many equations are not proposed by the work but are already well-known in the community, which could save space to include important missing details. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by reducing redundancy and focusing on key contributions. However, the comment could be more helpful if it specified which equations or details should be included to enhance the section. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the evaluation method used in Figure 3, Table 3, and Figure 5, specifically inquiring about the use of automatic or human evaluation. While the comment does not explicitly instruct the authors to make a change or provide specific guidance on how to address this issue, it does imply that the authors should clarify or provide more information about the evaluation methods used. The action is implicit but concrete, as the authors can infer that they need to provide additional details about the evaluation methods. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3, Table 3, and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks a clear question about the evaluation method used, which provides a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the evaluation method used in specific figures. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the evaluation method used in Figure 3, Table 3, and Figure 5, which is a clear and actionable point. By asking for clarification on the evaluation method, the reviewer prompts the authors to provide more detailed information about their methodology, which could enhance the transparency and reproducibility of their work. This feedback is valuable as it directs the authors to a specific area that needs clarification, making it mostly helpful. However, it could be more helpful if it included suggestions on how to present this information or what additional details might be beneficial. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the average coverage rate being larger than the bound by theorem, suggesting that the authors should correct their understanding or provide additional assumptions to achieve the desired coverage rate. However, the comment does not explicitly instruct the authors on how to correct their understanding or what assumptions to consider. While it implies that the authors should take action, the lack of concrete guidance on how to address the issue makes the comment somewhat actionable. The authors can infer that they need to reconsider their assumptions or understanding, but the comment lacks specific details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific calculation involving the average coverage rate and the bound by theorem, suggesting that the authors correct their understanding or provide additional assumptions to achieve the desired coverage rate. However, it does not specify which part of the paper this calculation is located in, making it weakly grounded. The comment is specific in detailing the issue with the average coverage rate and the potential implications for the theorem, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the average coverage rate is larger than the bound by theorem, suggesting that the authors need to correct their understanding or provide additional assumptions to achieve the desired coverage rate. The reviewer provides a logical reasoning by explaining that at odd times, the value of \\theta is not equal to one, allowing the adversary to generate data to make an error. This reasoning is based on a logical interpretation of the theorem and its implications, but it lacks specific examples or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable explanation but could benefit from more detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the average coverage rate being larger than the bound by theorem, suggesting that the authors may need to correct their understanding or provide additional assumptions to achieve the desired coverage rate. The reviewer provides a logical explanation of the problem, noting that at odd times, the value of \\theta is not equal to one, allowing the adversary to generate data to make an error. This feedback is somewhat helpful as it points out a potential weakness in the paper and suggests a direction for improvement. However, the comment could be more helpful if it provided specific suggestions on how to correct the understanding or what assumptions to consider. Overall, the comment offers some guidance but lacks detailed actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that using a single translator per language for producing annotations may not be sufficient, as different translators may have different choices. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what alternative approach might be more appropriate. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of using a single translator per language for producing annotations, suggesting that this approach may not be sufficient due to the variability in choices made by different translators. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the annotation process, but the lack of explicit mention makes it weakly grounded. The comment is specific in its critique of the approach, suggesting that using a single translator may not be enough. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using a single translator per language for producing annotations may not be sufficient due to the variability in choices made by different translators. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential limitation in the methodology, specifically the use of a single translator per language for producing annotations. It suggests that this approach may not be sufficient due to the variability in choices made by different translators. While the comment highlights an important consideration, it lacks specific guidance or suggestions on how the authors might address this issue or what alternative approaches might be more appropriate. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment questions the statement \"people wear a hat and play guitar not vice-versa,\" suggesting that the authors should provide a rationale for this claim. However, it does not explicitly instruct the authors to provide this rationale or specify how it should be presented. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification but are not given clear guidance on what that justification should entail. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the statement \"people wear a hat and play guitar not vice-versa,\" suggesting that the authors should provide a rationale for this claim. However, it does not specify which part of the paper this statement is made in, nor does it provide any context or guidance on what kind of rationale would be appropriate. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper needs revision. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the statement \"people wear a hat and play guitar not vice-versa,\" suggesting that the authors should provide a rationale for this claim. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this claim is questionable or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the statement \"people wear a hat and play guitar not vice-versa,\" suggesting that the authors should provide a rationale for this claim. While it identifies a potential issue with the statement, it lacks depth and does not provide specific guidance on how the authors might address this concern or what kind of rationale would be appropriate. The comment is somewhat helpful as it points out a potential weakness but does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive and constructive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the number of examples used in the model may be insufficient for it to learn the transformation correctly. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how many examples would be sufficient or what steps to take to ensure the model learns the transformation correctly. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the number of examples used in the model may be insufficient for it to learn the transformation correctly. However, it does not specify which part of the paper this issue pertains to, such as the experimental setup or results section. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the model\\'s learning process are insufficient or how the authors might address this issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the number of examples used in the model may be insufficient for it to learn the transformation correctly. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the number of examples used in the model, suggesting that it may not be sufficient for the model to learn the transformation correctly. However, it lacks specificity and does not provide any guidance on how the authors might address this issue or what steps to take to ensure the model\\'s effectiveness. Without actionable advice or suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the differences between Algorithm 1 and variational inference, specifically asking for clarification on the advantages of Algorithm 1. While the comment implies that the authors should provide a detailed explanation or comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation or comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the differences between Algorithm 1 and variational inference, and it asks for clarification on the advantages of Algorithm 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the differences between Algorithm 1 and variational inference, and it does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the differences between Algorithm 1 and variational inference, specifically asking for clarification on the advantages of Algorithm 1. This is a valuable point as it prompts the authors to clarify their methodology and provide a deeper understanding of their approach. However, the comment lacks specific guidance or suggestions on how to address this question or what aspects of the algorithm should be emphasized. While it identifies an area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential gap in the explanation but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the entailment exercise lacks basic details and is difficult to assess due to the lack of empirical and analyzed information. It suggests that the exercise should be removed or provided with more details. This feedback is clear and provides a direct action for the authors to take, either by removing the exercise or by adding more information to support it. The comment is specific in its request for additional details, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"entailment exercise,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of basic details and the difficulty in assessing the efficacy of the technique due to the absence of empirical and analyzed information. This provides clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the entailment exercise lacks basic details and is difficult to assess due to the lack of empirical and analyzed information. This claim is somewhat verifiable as it provides a logical reasoning for the need for more detailed information, but it lacks specific examples or references to support the claim. The authors might find it challenging to understand the exact details that are missing or how to address the issue without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the entailment exercise, noting that it lacks basic details and is difficult to assess due to the absence of empirical and analyzed information. It suggests that the exercise should be removed or provided with more details to enhance its utility. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it could be more helpful if it offered specific examples of what additional details or analysis might be needed. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and utility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the mathematical expression of the Gaussian distribution is ambiguous in lines 225 and 227. This provides a clear and direct action for the authors to take, which is to clarify or correct the expression to avoid confusion. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (225 and 227), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the mathematical expression of the Gaussian distribution being ambiguous. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mathematical expression of the Gaussian distribution is ambiguous in lines 225 and 227. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the ambiguity and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, noting that it is ambiguous. This feedback is clear and actionable, as it directs the authors to clarify or correct the expression to avoid confusion. By addressing this issue, the authors can improve the clarity and accuracy of their mathematical presentation, which is crucial for scientific rigor. However, the comment could be more helpful if it provided additional guidance on how to clarify the expression or suggested specific improvements. Overall, the comment is mostly helpful as it effectively points out a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the current testing is insufficient and recommends considering additional types of responses. However, it does not provide specific guidance on which types of responses should be considered or how to implement this suggestion. The action is implicit and vague, as the authors are left to infer that they need to expand their testing but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the current testing is insufficient and recommends considering additional types of responses. However, it does not specify which part of the paper this issue pertains to, such as the experimental setup or results section. The authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding which additional types of responses should be considered or how they would enhance the testing. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the current testing is insufficient and recommends considering additional types of responses. However, it does not provide any supporting evidence, reasoning, or examples to justify why the current testing is inadequate or how adding more types of responses would improve it. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential weakness in the testing methodology, suggesting that the current approach may not be sufficient. It recommends considering additional types of responses to enhance the testing. However, the comment lacks specificity and does not provide guidance on which types of responses should be considered or how they would improve the testing. Without actionable suggestions or detailed feedback, the authors are left with a general direction but no clear path for implementation. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the privacy protection capability, noting that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information. It also points out that relying solely on manipulating the temperature (T) may not be sufficient for effective text sanitization. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve their privacy protection capabilities. The action is implicit and somewhat vague, as the authors can infer that they need to consider additional methods for ensuring privacy protection, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of chatGPT for text paraphrasing and the issue with relying solely on manipulating the temperature (T) for text privacy protection. This allows the authors to accurately identify the specific part of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies the problem with the privacy protection capability, noting that chatGPT may not guarantee the removal of privacy information and that relying solely on temperature manipulation may not be sufficient for effective text sanitization. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the privacy protection capability is insufficient and that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information. It also suggests that relying solely on manipulating the temperature (T) may not be sufficient for effective text sanitization. The comment provides logical reasoning by pointing out the limitations of chatGPT and the need for additional methods to ensure privacy protection. However, it lacks specific examples or references to support the claim, such as studies or experiments that demonstrate the inadequacy of chatGPT or the insufficiency of temperature manipulation. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the privacy protection capability of the paper, noting that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information. It also points out that relying solely on manipulating the temperature (T) may not be sufficient for effective text sanitization. This feedback is valuable as it highlights a critical area for improvement in the paper, particularly regarding the privacy protection capabilities. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or what additional methods they could consider to ensure effective privacy protection. Overall, the comment is somewhat helpful as it identifies a significant weakness but lacks detailed guidance on how to improve it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the approach described in the manuscript is not significant enough, specifically mentioning the use of word embeddings to define the weight of each lexicon term. However, it does not provide any guidance on how the authors might address this issue or what specific changes could be made to enhance the novelty. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the novelty of the approach is not significant enough, particularly regarding the use of word embeddings to define the weight of each lexicon term. This provides clear guidance on what needs to be addressed in the General Discussion section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the approach described in the manuscript is not significant enough, specifically mentioning the use of word embeddings to define the weight of each lexicon term. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that the novelty of the approach described in the \"General Discussion\" section is not significant enough. It points out the use of word embeddings to define the weight of each lexicon term, which is a relatively new method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might enhance the novelty or improve the approach. While it highlights an area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides some insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should compare its method to non-NeRF methods on the mentioned tasks. This provides a clear and direct action for the authors to take, as it specifies the need for a comparison that can help readers better understand the advantages of the proposed method in relation to conventional methods. The comment is specific and provides concrete guidance on how to enhance the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed method to non-NeRF methods on specific tasks, which implies that the authors should address this comparison in their paper. However, it does not specify which tasks or which non-NeRF methods should be compared, making it weakly grounded. The comment is specific in suggesting a particular comparison that could enhance the paper, but without explicit references or detailed guidance, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from comparing its method to non-NeRF methods on specific tasks. This claim is somewhat verifiable as it logically suggests that such a comparison could provide valuable insights into the strengths and weaknesses of the proposed method relative to existing methods. However, the comment lacks specific examples or references to non-NeRF methods that could be used for comparison, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from comparing its method to non-NeRF methods on specific tasks. This suggestion is a clear and actionable piece of feedback that could help the authors better understand the strengths and limitations of their proposed method in relation to existing methods. By providing a specific direction for comparison, the comment offers a concrete way for the authors to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included examples of non-NeRF methods that should be compared or detailed guidance on how to conduct the comparison. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the authors\\' use of the term \"NLU\" and questions whether some lower-level tasks should be considered NLU or syntactic tasks. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific changes or clarifications to be made in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (178:181), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors\\' use of the term \"NLU\" and whether some lower-level tasks should be considered NLU or syntactic tasks. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the use of the term \"NLU\" and whether some lower-level tasks should be considered NLU or syntactic tasks. However, it does not provide any supporting evidence, reasoning, or references to justify the claim that there is a rich literature on morphological and syntactic probing tasks. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the term \"NLU\" in the paper and questions whether some lower-level tasks should be considered NLU or syntactic tasks. This feedback is somewhat helpful as it points out a potential inconsistency in the paper\\'s terminology, which could be clarified for readers. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as providing examples of lower-level tasks that might be considered syntactic tasks. While it highlights an area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should briefly discuss the relationship of their idea to traditional approaches in computer vision, specifically mentioning the use of long-term motion trajectories. While the comment implies that this discussion would strengthen the theoretical and academic value of their approach, it does not provide explicit instructions on how to conduct this discussion or what specific aspects to cover. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of long-term motion trajectories, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should discuss the relationship of their idea to traditional approaches in computer vision, such as motion segmentation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that using long-term motion trajectories is a traditional idea in computer vision, especially for motion segmentation. The reviewer provides a reference to a specific work ([a]) to support this claim. However, the comment also suggests that discussing the relationship of the authors\\' idea to these traditional approaches could strengthen the theoretical and academic value of their work. While the reference provides some support, the comment could be more fully verifiable by explaining why discussing the relationship is important or how it would enhance the paper. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion by pointing out that the use of long-term motion trajectories is a traditional idea in computer vision, especially for motion segmentation. It suggests that discussing the relationship of the authors\\' idea to these traditional approaches could strengthen the theoretical and academic value of their work. While the comment identifies a potential area for improvement, it does not provide specific guidance on how to integrate this discussion into the paper or what aspects of the traditional approaches should be compared. This limits the comment\\'s helpfulness, as it offers a direction for improvement but lacks detailed instructions. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks a clear description of the specific task types addressed on graph data. It also points out that the purpose of this section is unclear, as it does not convey the author\\'s task objectives. This feedback provides a clear and explicit action for the authors to take, which is to clarify the specific task types and objectives in the problem formalization section. The comment is concrete in its guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"problem formalization section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a clear description of the specific task types addressed on graph data and the failure to convey the author\\'s task objectives. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the problem formalization section lacks a clear description of the specific task types addressed on graph data, and it focuses primarily on formalizing the challenges faced. The reviewer suggests that the purpose of this section is unclear, as it does not convey the author\\'s task objectives. This claim is somewhat verifiable as it provides a logical reasoning for the critique, but it lacks specific examples or references to support the assertion that the section is unclear. The authors might need to further explore the issue to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks a clear description of the specific task types addressed on graph data. It also points out that the purpose of this section is unclear, as it fails to convey the author\\'s task objectives. This feedback is valuable as it highlights a critical area for improvement in the paper, which is the clarity of the task objectives and the description of the specific task types. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific task types or objectives to include. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that an ablation study on training techniques is missing, specifically mentioning Informative Prior Initialization (IPI) and v-prediction. It highlights the importance of this study to assess the specific impact of these techniques and to compare YOSO's performance with other models that could potentially leverage them. The comment provides a clear and concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and v-prediction. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for an ablation study to assess the impact of these techniques and compare YOSO's performance with other models. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of an ablation study on training techniques makes it difficult to assess their specific impact and to compare YOSO's performance with other models that could potentially leverage these techniques. This claim is somewhat verifiable as it logically suggests that an ablation study would be beneficial for understanding the impact of these techniques. However, the comment lacks specific examples or references to support the claim, such as mentioning which models could potentially benefit from these techniques or providing data or analysis to substantiate the claim. This makes the comment somewhat verifiable, as it provides a logical basis but requires more detailed evidence to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of an ablation study on training techniques. It highlights the importance of including such a study to assess the specific impact of these techniques and to compare YOSO's performance with other models that could potentially leverage them. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to include an ablation study in their work. By addressing this point, the authors can enhance the comprehensiveness and rigor of their analysis, which is valuable for improving the draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the paper, such as redundant descriptions and a lack of validation experiments. It provides explicit suggestions for improvement, including recommending a small-scale validation experiment using one of the datasets mentioned in the paper. This feedback is clear and concrete, giving the authors direct actions to take to enhance their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (229 to 272) and datasets mentioned in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the redundancy in the descriptions and the lack of validation experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the content of the paper is limited and that there are instances of redundant descriptions, specifically mentioning the two paragraphs from line 229 to line 272 that redundantly describe the motivation and work approach already covered in the introduction. The reviewer also suggests conducting a small-scale validation experiment using one of the datasets mentioned in the paper, given the author\\'s acknowledgment of the lack of domain knowledge in LLMs for specific tasks. The claim is somewhat verifiable as it provides a specific example of redundancy and suggests a potential improvement, but it lacks detailed reasoning or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s content, noting that it is limited in scope and contains redundant descriptions. It provides specific examples, such as the two paragraphs from line 229 to line 272, which redundantly describe the motivation and work approach already covered in the introduction. Additionally, the reviewer suggests conducting a small-scale validation experiment using one of the datasets mentioned in the paper, given the author\\'s acknowledgment of the lack of domain knowledge in LLMs for specific tasks. This feedback is clear and actionable, offering concrete steps for the authors to enhance their draft. However, it could be more helpful if it provided additional guidance on how to conduct the validation experiment or suggested specific datasets to use. Overall, the comment is mostly helpful, as it directs the authors toward improving the paper\\'s content and scope.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite the section to make the connections between the theoretical contributions and the proposed method clearer. It provides a specific suggestion to clarify how the theoretical contributions support the proposed method, particularly by addressing the issue of segregated feature vectors for backdoored vs. clean data. This feedback is concrete and provides a clear action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the theoretical contributions and the section where they are discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unclear connections between the theoretical contributions and the proposed method, particularly regarding the segregated feature vectors for backdoored vs. clean data. This provides clear guidance on what needs to be revised to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical contributions are too abstract and unclear in their connection to the proposed method. It suggests that the segregated feature vectors for backdoored vs. clean data seem artificial and not directly related to the EigenGuard method. The comment provides a logical reasoning by pointing out the lack of clarity in the theoretical contributions, but it does not provide specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a basis for the claim but lacks detailed evidence or references to fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical contributions, noting that they seem too abstract and unclear in their connection to the proposed method. It suggests that the segregated feature vectors for backdoored vs. clean data seem artificial and not directly related to the EigenGuard method. The comment provides a clear and actionable suggestion for improvement by instructing the authors to rewrite the section to make the connections with the proposed method clearer. This feedback is valuable as it guides the authors on how to enhance the clarity and relevance of their theoretical contributions, which is crucial for the overall understanding and impact of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of whether the code will be released, noting that the GCN implementation may be difficult to reproduce without the original code. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider releasing the code, but it lacks concrete steps or details on how to do so. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of code availability, specifically mentioning the GCN implementation and the difficulty in reproducing it without the original code. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the reproducibility of the code, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of code availability, noting that the GCN implementation may be difficult to reproduce without the original code. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the code is difficult to reproduce or why the authors\\' descriptions are insufficient. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the clarity of code availability, specifically regarding the GCN implementation. It notes that the original code may be necessary for reproducing the results, which could be a concern for readers. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending code sharing or offering alternative approaches to simplify the implementation. While it points out a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the use of second-order Taylor expansions in Equations (9) and (10) instead of using the differential functions themselves. While it does not explicitly instruct the authors to use the differential functions, it implies that the authors should consider this option. The comment is somewhat actionable as it provides a clear direction for the authors to consider, but it lacks concrete guidance on how to implement this change or why it might be beneficial. Therefore, the authors can infer that they should reconsider using the differential functions, but the action is not explicitly stated.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equations (9) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of second-order Taylor expansions in place of differential functions and asks for clarification on why this choice was made. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of second-order Taylor expansions in Equations (9) and (10) instead of using differential functions. However, it does not provide any reasoning or evidence to support why the differential functions should be preferred over the Taylor expansions. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of second-order Taylor expansions in Equations (9) and (10) instead of using differential functions. It suggests that the differential functions themselves could be used, which could provide a more accurate representation. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on why the differential functions might be preferable or how they could be incorporated into the equations. The feedback is somewhat helpful as it points out a potential improvement but does not offer detailed instructions or examples for the authors to follow. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing recall on lemmas/forms seen in training for en-cs BPE to character results in Table 3. It references specific works by Pourdamghani, He, and Ryskina to support the claim. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their results. The authors are left to infer that they need to investigate the recall issue and potentially consult the referenced works for guidance. While the comment identifies a problem, it lacks concrete instructions on how to resolve it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"en-cs BPE to character results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing recall on lemmas/forms seen in training, referencing specific works to support the claim. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the en-cs BPE to character results in Table 3 are missing recall on lemmas/forms seen in training, referencing specific works to support the claim. This provides a logical reasoning based on external references to substantiate the claim. However, the comment could be strengthened by including more detailed explanations or examples from the referenced works to further clarify the issue. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the claim but lacks complete justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in Table 3, noting the missing recall on lemmas/forms seen in training. It references external works by Pourdamghani, He, and Ryskina to support the claim, providing a clear and actionable suggestion for the authors to investigate the issue further. However, the comment could be more helpful if it offered additional guidance on how to address the missing recall or suggested specific experiments or analyses to conduct. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and provides a starting point for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of the proposed method on the MLSC setup, specifically questioning why the method does not improve many-to-many translation despite the claim of better word-alignment. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this question or improve their draft. The authors are left to infer that they should provide an explanation or justification for the lack of impact, but without specific instructions, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the impact of the proposed method on the MLSC setup and pointing out the lack of explanation in Section 4. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that better word-alignment improves many-to-many translation, as the proposed method has no impact on the MLSC setup (Table 3). The reviewer references Section 4, which touches on this point, but does not provide specific details or evidence to support the claim that the method has no impact. This lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to further explore the reasoning behind the claim and the potential impact on the MLSC setup. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the claim that better word-alignment improves many-to-many translation, noting that the proposed method has no impact on the MLSC setup (Table 3). It highlights a discrepancy between the claim and the results presented in the paper. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this discrepancy or improve their explanation. The feedback is somewhat helpful as it points out a gap in the paper, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the method is restricted to an offline setting and cannot be applied in an online setting where policies interact with the environment. It highlights the limitation of the offline assumption on the applicability of the method. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to adapt the method for online settings or suggestions for overcoming the offline assumption. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"offline setting\" and the \"method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the method, which is that it requires pre-collected offline datasets and cannot be applied in an online setting where policies interact with the environment. This provides clear guidance on what needs to be addressed to improve the applicability of the method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is restricted to an offline setting and cannot be applied in an online setting where policies interact with the environment. This claim is somewhat verifiable as it logically follows that a method that relies on pre-collected datasets cannot be applied in real-time settings. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the methodology, specifically that the method is restricted to an offline setting and cannot be applied in an online setting where policies interact with the environment. This is a critical observation that highlights a potential weakness in the applicability of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or adapt the method for online settings. While it points out an important issue, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the evaluation of the learned representation, noting that it was only tested on the linear evaluation setting. It suggests that additional downstream tasks could be used, such as fine-tuning, detection, and segmentation, as reported in the literature. While the comment implies that the authors should consider these additional tasks, it does not explicitly instruct them to do so or provide specific guidance on how to implement these tasks. The action is implicit and somewhat vague, as the authors need to infer that they should consider additional tasks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"quality of the learned representation\" and the \"linear evaluation setting,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the evaluation is insufficient and suggests additional downstream tasks that could be used, such as fine-tuning, detection, and segmentation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of the learned representation is insufficient because it was only conducted on the linear evaluation setting. The reviewer suggests that additional downstream tasks, such as fine-tuning, detection, and segmentation, could be used as reported in the literature. However, the comment lacks specific examples or references to these tasks or how they would enhance the evaluation. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed justification to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the learned representation, noting that it was only tested on the linear evaluation setting. It suggests that additional downstream tasks, such as fine-tuning, detection, and segmentation, could be used to provide a more comprehensive evaluation. This feedback is somewhat helpful as it points out a potential gap in the evaluation process and suggests ways to enhance it. However, the comment could be more helpful if it provided specific examples or references to the literature where these tasks have been used in similar contexts. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the novelty of the paper is very low due to the use of stage-wise and progressive training, which have been used for a long time. It does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the novelty or what specific aspects of the paper could be revised to enhance its originality. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, specifically mentioning the use of stage-wise and progressive training, which have been used for a long time. However, it does not specify which part of the paper discusses these methods, making it difficult for the authors to pinpoint the exact section that needs revision. The comment lacks specificity regarding what aspects of the paper are lacking in novelty or how the authors could enhance it. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is very low due to the use of stage-wise and progressive training, which have been used for a long time. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the novelty of the paper, stating that the use of stage-wise and progressive training is not novel. It points out that these methods have been used for a long time, making the paper's contribution lacking in originality. However, the comment does not provide any specific suggestions or guidance on how the authors could enhance the novelty or innovation of their work. Without actionable feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the generalizability of the analysis to more complex cases, such as handling more general Markov chains and considering the presence of a FFN and nonlinearity on top of the attention layer. While these questions imply that the authors should consider these aspects in their analysis, they do not provide explicit instructions or concrete steps on how to address them. The authors can infer that they need to expand their analysis to include these scenarios, but the comment lacks detailed guidance on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the generalizability of the analysis to more complex cases, such as handling more general Markov chains and considering the presence of a FFN and nonlinearity on top of the attention layer. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in its inquiry about the generalizability of the analysis, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions asking for clarification and extension of the analysis to more general cases. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the generalizability of the analysis to more complex cases, such as handling more general Markov chains and considering the presence of a FFN and nonlinearity on top of the attention layer. These questions prompt the authors to consider the limitations and potential extensions of their analysis, which could enhance the robustness and applicability of their work. However, the comment does not provide specific guidance or suggestions on how to address these questions or what specific aspects of the analysis need to be expanded. While it highlights areas for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while the authors mention [19], it is unclear in section 3.1 and line 57 whether [19] uses the same fine state automaton or if there are any differences. This implies that the authors should clarify this point in their draft. However, the comment does not explicitly instruct the authors to make this clarification, leaving it somewhat vague. The action is implicit and somewhat vague, as the authors need to infer that they should clarify this point. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1\" and \"line 57,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the issue of clarifying whether [19] uses the same fine state automaton or if there are any differences. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that while the authors mention [19], it is unclear in section 3.1 and line 57 whether [19] uses the same fine state automaton or if there are any differences. This claim is somewhat verifiable as it points out a specific issue with the clarity of the reference in the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further investigate the reference to understand the exact issue and address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of a reference, noting that while the authors mention [19], it is unclear in section 3.1 and line 57 whether [19] uses the same fine state automaton or if there are any differences. This feedback is clear and actionable, as it directs the authors to clarify this point in their draft. By addressing this issue, the authors can improve the clarity and accuracy of their references, which is valuable for ensuring the robustness and credibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to clarify the reference. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the auto_weight scheme in Algorithm 1, noting that it might require a lot of memory due to the need for intermediate gradients for each domain. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to reduce memory usage or alternative approaches to consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"auto_weight scheme,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the auto_weight scheme, noting that it might require a lot of memory due to the need for intermediate gradients for each domain. The comment provides references to external works, which further supports the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the auto_weight scheme in Algorithm 1 might require a lot of memory due to the need for intermediate gradients for each domain. The reviewer supports this claim by referencing two external works, \"FedGP: Buffer-based Gradient Projection for Continual Federated Learning\" by Dai et al. (2023) and \"FLamby: Datasets and Benchmarks for Cross-Silo Federated Learning in Realistic Healthcare Settings\" by Terrail et al. (2022). These references provide a logical basis for the claim, as they discuss memory requirements in similar contexts. However, the comment could be strengthened by further elaborating on how these references relate to the specific issue in the paper. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the auto_weight scheme in Algorithm 1, noting that it might require a lot of memory due to the need for intermediate gradients for each domain. This is a relevant observation that could impact the scalability and efficiency of the algorithm. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as suggesting alternative approaches or ways to optimize memory usage. While it points out a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the methodology, specifically the use of a double LSTM as the backbone while excluding popular transformers. It points out that this approach may not be sufficient for more extensive model structures. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest specific actions to improve the methodology. The authors are left to infer that they should consider expanding the methodology to include transformers or other models. While the comment identifies an area for improvement, it lacks concrete steps or detailed suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of a double LSTM as the backbone and the exclusion of popular transformers, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of the methodology being limited to specific encoders and pre-trained language models, and points out the potential concern of its applicability to more extensive model structures. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of a double LSTM as the backbone is a limitation, as it excludes popular transformers and may not be sufficient for more extensive model structures. The comment references the limitations mentioned in Section 6, suggesting that they are not sufficient. However, the comment does not provide specific examples or references to support the claim that the double LSTM is insufficient or that the limitations are not adequately addressed. This lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to further explore the limitations themselves to fully understand and address the issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the methodology, specifically the use of a double LSTM as the backbone while excluding popular transformers. It points out that this approach may not be sufficient for more extensive model structures and highlights the limitations mentioned in Section 6 as insufficient. While the comment provides a clear direction for improvement by suggesting that the authors should consider expanding their methodology to include transformers or other models, it lacks specific suggestions or guidance on how to address the limitations effectively. This makes the comment somewhat helpful, as it provides insight into a potential issue but does not offer detailed guidance on how to resolve it. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the contribution and novelty of the paper are limited, as the proposed model essentially combines existing techniques, such as structure learning regularization and missing value imputation, with variational inference for model parameter learning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or contribution of the paper, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the contribution and novelty of the paper, stating that the proposed model essentially combines existing techniques, such as structure learning regularization and missing value imputation, with variational inference for model parameter learning. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the combination of existing techniques, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution and novelty of the paper are limited, as the proposed model essentially combines existing techniques, such as structure learning regularization and missing value imputation, with variational inference for model parameter learning. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s contribution and novelty, stating that the proposed model essentially combines existing techniques, such as structure learning regularization and missing value imputation, with variational inference for model parameter learning. This feedback highlights a potential issue with the paper\\'s originality and innovation, which is important for authors to consider when seeking to publish their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the MSLR approach with directly tuning a late-fusion model with separate learning rates for each modality, especially with a similar or less compute budget. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this comparison to address the issue raised. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of MSLR requiring knowledge of unimodal optimal learning rates in advance, which is a specific concern regarding the methodology. It suggests comparing the MSLR approach with directly tuning a late-fusion model with separate learning rates for each modality, especially with a similar or less compute budget. However, the comment does not specify which part of the paper this comparison should be discussed, making it weakly grounded. The suggestion is specific, as it outlines a potential comparison that could be made to address the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the MSLR approach with directly tuning a late-fusion model with separate learning rates for each modality, especially with a similar or less compute budget. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is relevant or beneficial. Without additional context or examples, the claim remains unverifiable, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the MSLR approach, noting that it requires knowledge of unimodal optimal learning rates in advance, which can be costly and result in discarded models. It suggests an interesting comparison with directly tuning a late-fusion model with separate learning rates for each modality, especially with a similar or less compute budget. This feedback is somewhat helpful as it points out a potential area for improvement and provides a direction for further exploration. However, the comment could be more helpful if it offered specific suggestions or examples of how to conduct this comparison or what aspects to focus on. Overall, the comment provides some guidance but lacks depth and actionable details, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the ambiguity of the notation for L_{flow}(X) and questions whether L_{flow}(F) or L_{flow}(F,S) would be more appropriate to reflect the actual inputs. While the comment implies that the authors should consider clarifying this notation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the notation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the notation for L_{flow}(X), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the notation being ambiguous and questions whether L_{flow}(F) or L_{flow}(F,S) would be more appropriate to reflect the actual inputs. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the ambiguity of the notation for L_{flow}(X) and suggests that L_{flow}(F) or L_{flow}(F,S) might be more appropriate to reflect the actual inputs. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these alternatives might be more appropriate. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the notation for L_{flow}(X) and questions whether L_{flow}(F) or L_{flow}(F,S) would be more appropriate to reflect the actual inputs. This feedback is somewhat helpful as it points out a potential issue with the clarity of the notation, which could be confusing for readers. However, the comment lacks specific suggestions or guidance on how to address this ambiguity, such as providing alternative explanations or examples. While it highlights an area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the purpose of representing the input using 8 bits and questions the novelty of the work due to the existence of 8-bit batch norm in literature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the purpose of representing the input using 8 bits and questions the novelty of the work due to the existence of 8-bit batch norm in literature. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the 8-bit representation is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the novelty aspect but lacks grounding in terms of identifying the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the work by referencing the existence of 8-bit batch norm in literature, specifically citing a specific paper. This claim is somewhat verifiable as it references an external source, which provides some basis for the assertion that the 8-bit batch norm is not novel. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid question about the purpose of representing the input using 8 bits and questions the novelty of the work due to the existence of 8-bit batch norm in literature. This is an important point that could impact the perceived originality of the work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their draft. It does not provide actionable feedback or detailed advice on how to respond to the critique, such as suggesting alternative approaches or explaining the novelty of the work in the context of existing literature. As a result, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the practical relevance of the proposed framework may be limited due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the framework's practical relevance or how to differentiate it from existing GNNs. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the practical relevance of the proposed framework may be limited due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not specify which part of the paper this concern is based on, such as specific sections, figures, or experiments where GNNs are discussed. Without explicit references, the authors cannot confidently determine which parts of the paper need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the framework are considered less relevant or how it could be improved to overcome this limitation. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the practical relevance of the proposed framework may be limited due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, data, or comparisons, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the practical relevance of the proposed framework may be limited due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. While this observation highlights a potential issue, it lacks specificity and actionable guidance on how the authors might address this concern or differentiate their framework from existing GNNs. Without detailed suggestions or examples, the comment does not provide the authors with a clear path forward to enhance the practical relevance of their work. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an experiment demonstrating the necessity of including $X$ in the calculation of M_{t}. While the comment implies that the authors should add this experiment, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors need to infer the exact steps to conduct the experiment and how it would be integrated into the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding an experiment to demonstrate the necessity of including $X$ in the calculation of M_{t}. However, it does not specify which part of the paper this experiment should be added to, nor does it provide details on what the experiment should entail or how it would be integrated into the existing work. This lack of specificity makes it difficult for the authors to pinpoint the exact section that needs revision. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that if M_{t} is calculated only using $C$ without $X$, the results might be questionable. However, it does not provide any evidence or reasoning to support this claim. The comment implies that an experiment should be added to demonstrate the necessity of $X$, but it lacks specific details or examples to substantiate the claim. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include an experiment to demonstrate the necessity of including $X$ in the calculation of M_{t}. This feedback is somewhat helpful as it identifies a potential weakness in the paper and provides a clear direction for improvement. However, the comment lacks specific guidance on how to conduct the experiment or what specific aspects of the results should be emphasized. While it points out an area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment states a fact about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. It does not provide any actionable advice or suggestions for the authors to improve their draft. There is no guidance on how the authors might address this issue or what specific changes could be made to improve the complexity of their work. As a result, the comment lacks actionability and is not helpful for the authors to understand what steps to take to enhance their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment does not specify which part of the paper it addresses, making it not grounded. It is a general statement about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. The comment lacks specificity as it does not provide any details or suggestions for improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a factual statement about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment is a factual observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. It does not provide any actionable feedback, suggestions, or insights for the authors to improve their draft. Without any guidance or constructive criticism, the comment offers limited value to the authors in terms of enhancing their work. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the generalizability of their observations, specifically those in Figure 4. It points out that various hyperparameters, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling, could influence implicit biases in the algorithm, affecting neural representations, geometric metrics, and the stages of learning. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them on how to address this issue or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing the generalizability of observations, specifically those in Figure 4. It mentions various hyperparameters that could influence implicit biases in the algorithm, affecting neural representations, geometric metrics, and the stages of learning. However, it does not explicitly mention which part of the paper Figure 4 is in, making it weakly grounded. The comment is specific in detailing the potential influence of hyperparameters on the generalizability of the observations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the generalizability of observations, specifically those in Figure 4, could be improved by discussing the influence of various hyperparameters on implicit biases in the algorithm. The comment provides a logical reasoning by mentioning specific hyperparameters that could affect neural representations, geometric metrics, and learning stages. However, it lacks specific examples or references to support the claim that these hyperparameters influence implicit biases. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to discuss the generalizability of their observations, specifically those in Figure 4. It highlights the potential influence of various hyperparameters, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling, on implicit biases in the algorithm. This feedback is valuable as it prompts the authors to consider the broader implications of their findings and how they might be applied to other contexts. However, the comment could be more helpful if it provided specific examples or references to studies that have explored these effects, which would guide the authors in developing a more comprehensive discussion. Overall, the comment is mostly helpful as it offers a clear direction for improvement but could be expanded to be fully comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honest\" in section 4. The reviewer suggests using \"honest-but-curious\" instead, which is a more standard term to describe a server that cannot modify local updates but tries to infer private information of clients. While the comment provides a specific term to use, it does not offer detailed guidance on how to reorganize the paper or address the issue of non-standard terminology. The action is explicit but somewhat vague, as the authors know what term to use but may not be entirely sure how to implement the suggested change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of non-standard terminology, particularly the term \"semi-honest,\" and suggests using \"honest-but-curious\" instead. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honest\" in section 4. The reviewer suggests using \"honest-but-curious\" instead, which is a more standard term to describe a server that cannot modify local updates but tries to infer private information of clients. The comment provides a specific example of non-standard terminology and suggests a more appropriate term, which is a logical and verifiable claim. However, it could be strengthened by providing a more detailed explanation of why \"semi-honest\" is not standard terminology or how it might confuse readers. Overall, the claim is mostly verifiable, as it is supported by a specific example and a logical suggestion for improvement.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s organization and terminology, specifically noting the use of non-standard terminology like \"semi-honest\" in section 4. The reviewer provides a specific suggestion to use \"honest-but-curious\" instead, which is a more standard term to describe a server that cannot modify local updates but tries to infer private information of clients. This feedback is clear and actionable, as it offers a concrete way to improve the paper\\'s clarity and consistency. However, the comment could be more helpful if it provided additional guidance on how to address the issue of non-standard terminology throughout the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of specific information about the optimizer, initialization, and PPO-zero in the experimental details. While it identifies these as missing elements, it does not provide explicit instructions on how to address these gaps. The authors are left to infer that they need to include this information, but the comment lacks concrete guidance on how to present it or what specific details should be included. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of specific information about the optimizer, initialization, and PPO-zero in the experimental details. However, it does not specify which part of the paper these details are missing in, making it weakly grounded. The comment is specific in identifying what is missing, but without clear grounding, the authors may struggle to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"lots of experimental details are missing,\" specifically mentioning the optimizer, initialization, and PPO-zero. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where experimental details are missing, including the optimizer, initialization, and PPO-zero. This feedback is clear and actionable, as it directs the authors to provide these missing details in order to improve the comprehensiveness and transparency of their experimental section. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is mostly helpful as it effectively points out a gap in the paper and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the need for a detailed comparison of the proposed method's efficiency and complexity in terms of model parameters, FLOPs, and memory. It explicitly states that a comparison with and without the detector/LaVIT is necessary. This provides clear and concrete guidance on what the authors need to do to improve their draft, making the action explicit and specific. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"Region Sampler,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is a detailed comparison of the method's efficiency and complexity in terms of model parameters, FLOPs, and memory. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method requires additional components, such as LaVIT and a detector, which are not present in other existing works. The comment suggests that a detailed comparison of efficiency and complexity is needed, including model parameters, FLOPs, and memory. While the comment provides a logical reasoning for the need for such a comparison, it lacks specific examples or references to existing works that do not require these additional components. This makes the claim somewhat verifiable, as the authors would need to conduct their own research to fully understand and verify the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the efficiency and complexity of the proposed method. It points out that the method requires additional components, such as LaVIT and a detector, which are not present in other existing works. The comment suggests a detailed comparison of the method's efficiency in terms of model parameters, FLOPs, and memory, both with and without these additional components. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by addressing the efficiency and complexity of their proposed method. However, the comment could be more helpful if it included examples or references to existing works that do not require these additional components, which would further substantiate the claim. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims extrapolation error is a major issue in MARL but lacks evidence to support this claim. It also notes that the proposed techniques are for bias/variance reduction and do not seem directly related to extrapolation error. The reviewer suggests that there is no evidence that the proposed method mitigates extrapolation error, which leads to better performance. While the comment identifies a specific issue with the paper\\'s claims and suggests that evidence is needed to support them, it does not provide explicit guidance on how to address this issue or what kind of evidence would be sufficient. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence to support their claims. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about extrapolation error being a major issue in MARL, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the authors do not provide evidence to support this claim and that the proposed techniques are for bias/variance reduction, which are not directly related to extrapolation error. The comment further highlights the lack of evidence that the proposed method mitigates extrapolation error, leading to better performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim about extrapolation error being a major issue in MARL lacks evidence. It further suggests that the proposed techniques are for bias/variance reduction and do not directly address extrapolation error. The reviewer argues that there is no evidence that the proposed method mitigates extrapolation error, leading to better performance. This claim is somewhat verifiable as it provides a logical reasoning for the lack of evidence and suggests a potential issue with the paper\\'s claims. However, it could be strengthened by providing specific examples or references to support the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s claims regarding extrapolation error being a major issue in MARL. It points out that the authors do not provide any evidence to support this claim and that the proposed techniques are for bias/variance reduction, which are not directly related to extrapolation error. The comment further highlights the lack of evidence that the proposed method mitigates extrapolation error, leading to better performance. This feedback is clear and actionable, as it directs the authors to provide evidence or clarify their claims regarding extrapolation error. By addressing this issue, the authors can significantly improve the clarity and credibility of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a gap in the paper regarding the exploration of on-device efficiency for SCHEME. It suggests that while theoretical complexity advantages are demonstrated, the on-device efficiency is underexplored. The reviewer recommends presenting detailed on-device results across ablation and comparison studies, including benchmark configurations, hardware, and input shapes. This feedback provides clear and explicit actions for the authors to take, such as conducting on-device benchmarks and including detailed information about the hardware and input shapes. The suggestions are concrete and specific, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 4 and 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the exploration of on-device efficiency for SCHEME and the need for detailed on-device results across ablation and comparison studies. The comment also suggests including benchmark configurations, hardware, and input shapes to ensure fair comparisons. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical complexity advantages of SCHEME are demonstrated but that its on-device efficiency is underexplored. It suggests that limited throughput comparisons are presented in Tables 4 and 8, and that an on-device benchmark has been implemented. The reviewer recommends including detailed on-device results across ablation and comparison studies to substantiate claims about SCHEME\\'s efficiency over conventional FFNs. Additionally, the comment suggests providing details on the benchmark configurations, hardware, and input shapes to ensure fair comparisons. The claim is mostly verifiable as it provides a logical reasoning for the need to explore on-device efficiency and includes specific suggestions for improvement. However, the comment could be strengthened by referencing specific examples or studies that demonstrate the importance of on-device efficiency. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the exploration of on-device efficiency for SCHEME. It highlights that while theoretical complexity advantages are demonstrated, the on-device efficiency is underexplored. The reviewer suggests that detailed on-device results across ablation and comparison studies would substantiate claims about SCHEME\\'s efficiency over conventional FFNs. Additionally, the comment recommends including benchmark configurations, hardware, and input shapes to ensure fair comparisons. This feedback is clear and actionable, providing the authors with specific steps to enhance the paper\\'s evaluation and substantiate their claims. By addressing these points, the authors can significantly improve the comprehensiveness and credibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the name of the strategy, \"LongShortTerm Strategy,\" may be misleading and reminiscent of Long Short Term Memory (LSTM), which could lead to confusion. However, it does not provide explicit guidance on what alternative name might be more appropriate or how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider a different name but are not given specific suggestions or details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the name of the strategy, \"LongShortTerm Strategy,\" may be misleading and reminiscent of Long Short Term Memory (LSTM), which could lead to confusion. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the name is used. The authors can infer that it relates to the strategy or methodology section, but this inference is not direct. The comment is specific in its critique of the name but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the name of the strategy, \"LongShortTerm Strategy,\" may be misleading and reminiscent of Long Short Term Memory (LSTM), which could lead to confusion. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples to substantiate the concern about the name's potential impact on clarity or understanding. As a result, the claim is not fully verifiable, as it relies solely on the reviewer\\'s subjective interpretation without sufficient evidence or justification. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the name of the strategy, \"LongShortTerm Strategy,\" suggesting that it may be misleading and reminiscent of Long Short Term Memory (LSTM). This feedback is somewhat helpful as it points out a potential source of confusion that the authors should consider. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending an alternative name or explaining why the current name is problematic. While it highlights a relevant concern, the lack of actionable advice limits its usefulness for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method is not the best performer in both robustness and fidelity. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. There is no actionable advice or concrete steps for the authors to take to improve their draft. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights that the proposed method is not the best performer in both robustness and fidelity, but it does not specify which experiments or results are being referred to. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the method are not performing well or how they could be improved. Without explicit references or detailed suggestions, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method is not the best performer in both robustness and fidelity. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or details, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a significant issue with the proposed method, noting that it is not the best performer in both robustness and fidelity. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the method need to be addressed or how to enhance its performance. As a result, the comment is not helpful, as it does not offer any constructive feedback that could assist the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the motivation and logical connection between the concepts of isometry, OT, and disentanglement. It points out that the authors claim that adding geometrical constraints (isometry) can help disentanglement but does not explain this connection well. The reviewer suggests that the authors should clarify these connections more clearly in the paper, particularly by explaining why OT is required for isometry and why isometry mapping alone is sufficient. This feedback provides explicit and concrete actions for the authors to take, such as expanding on the logical connection and clarifying the role of OT. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the concepts of isometry, OT, and disentanglement, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the motivation and logical connection between these concepts. The comment provides guidance on how to improve the explanation of these connections, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation and logical connection between the concepts of isometry, OT, and disentanglement are not clear. It suggests that the authors need to clarify the connections and explain why OT is required for isometry. The comment provides a logical reasoning by pointing out that the authors claim that adding geometrical constraints (isometry) can help disentanglement but do not explain this connection well. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further develop the reasoning to fully substantiate the claim, but the feedback provides a clear direction for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the motivation and logical connection between the concepts of isometry, OT, and disentanglement. It points out that the authors claim that adding geometrical constraints (isometry) can help disentanglement but do not explain this connection well. The reviewer suggests that the authors should clarify these connections more clearly in the paper, particularly by explaining why OT is required for isometry and why isometry mapping alone is sufficient. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the clarity and coherence of their paper. By addressing these points, the authors can significantly enhance the understanding and impact of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the relevance of the results on regular languages to understanding how and why real-world language models work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they could take to improve the connection between the results and the broader context. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the results on regular languages, suggesting that while they are great, they do not provide insight into how and why real-world language models work. However, it does not specify which part of the paper these results are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for a connection to real-world applications, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the relevance of the results on regular languages to understanding how and why real-world language models work. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid point about the relevance of the results on regular languages to understanding how and why real-world language models work. It highlights a potential gap in the paper\\'s explanation of its findings and their practical implications. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the results could be better explained. While it identifies an area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the novelty of the paper, specifically questioning the differences between it and the Venom paper. It implies that the authors should clarify or address this issue, but it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison or explanation of the differences. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the novelty of the paper, specifically questioning the differences between it and the Venom paper. However, it does not specify which part of the paper this question pertains to, such as the introduction, results, or discussion sections. The authors cannot confidently determine which part of the paper is being addressed, making this comment weakly grounded. The comment is specific in its inquiry about the differences between the proposed method and Venom, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the differences between the paper and the Venom paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the paper, specifically questioning the differences between it and the Venom paper. It points out that V:N:M was proposed in the Venom paper and asks how the current paper differs from Venom. While the comment identifies a potential area for clarification or differentiation, it lacks specific guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to consider the novelty and uniqueness of their work, but it could be more actionable with additional details or suggestions on how to improve the comparison or differentiation. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the attribution maps, specifically noting that they do not seem qualitatively intuitive. It points out that the attended areas of the image do not seem related to the actual task, and that there are clusters of attended pixels without a clear semantic meaning. However, the reviewer acknowledges that the resulting analysis seems to work, despite the lack of qualitative value. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should make the attribution maps more intuitive, but the comment lacks specific suggestions or examples on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the attribution maps, noting that they are not qualitatively intuitive and pointing out specific examples, such as the 3D worth pixels not being attended in 3D tasks. The comment further acknowledges that the resulting analysis seems to work, but questions the lack of qualitative value. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the attribution maps are not qualitatively intuitive, specifically mentioning that the attended areas of the image do not seem related to the actual task. The reviewer acknowledges that the resulting analysis seems to work, but questions the lack of qualitative value. This claim is somewhat verifiable as it provides a specific observation about the attribution maps, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the attribution maps, noting that they are not qualitatively intuitive. It points out that the attended areas of the image do not seem related to the actual task, and that there are clusters of attended pixels without a clear semantic meaning. However, the reviewer acknowledges that the resulting analysis seems to work, which suggests that the quantitative value exists. Despite this, the reviewer questions the lack of qualitative value, indicating that the attribution maps do not provide a clear understanding of the model's behavior. This feedback is somewhat helpful as it highlights a potential weakness in the paper, but it could be more beneficial if it offered suggestions on how to improve the attribution maps or what aspects of the analysis might be misleading. Overall, the comment provides some insight but lacks actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the title overclaims the contribution of the paper, as it only shows results on two language models (BERT and RoBERTa) but does not include results on larger language models (LLMs) like Llama2-70b. The reviewer suggests that if the proposed method is scalable to LLMs, empirical justification should be provided. Additionally, the comment points out a minor issue with the inconsistent use of the term \"RoBERTa\" in Section 3.3 and \"RoBerta\" in the Introduction. While the action to address the title and the inconsistency is explicit, the comment lacks detailed guidance on how to demonstrate scalability or provide empirical justification. Therefore, the comment is somewhat actionable, as it identifies specific areas for improvement but does not provide detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title and the specific issue with the results being shown only on BERT and RoBERTa, which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the title overclaiming the contribution and suggests that if the method is scalable to larger language models (LLMs), empirical justification should be provided. Additionally, it points out a minor issue with the inconsistent use of the term \"RoBERTa\" in Section 3.3 and \"RoBerta\" in the Introduction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the title overclaims the contribution of the paper, as it only shows results on two language models (BERT and RoBERTa) and does not include results on larger language models (LLMs) like Llama2-70b. The reviewer suggests that if the proposed method is scalable to LLMs, empirical justification should be provided. The comment also points out a minor issue with the inconsistent use of the term \"RoBERTa\" in Section 3.3 and \"RoBerta\" in the Introduction. While the claim about the title overclaiming the contribution is logical, the lack of specific examples or references to LLMs makes it somewhat verifiable. The suggestion to provide empirical justification is reasonable, but the comment could be strengthened with more detailed guidance on how to demonstrate scalability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable critique of the paper\\'s title, noting that it overclaims the contribution as it only shows results on two language models (BERT and RoBERTa) and does not include results on larger language models (LLMs) like Llama2-70b. The reviewer suggests that if the proposed method is scalable to LLMs, empirical justification should be provided. Additionally, the comment points out a minor issue with the inconsistent use of the term \"RoBERTa\" in Section 3.3 and \"RoBerta\" in the Introduction. While the feedback identifies specific areas for improvement, it could be more helpful by providing guidance on how to demonstrate scalability or how to address the inconsistency in terminology. Overall, the comment is somewhat helpful as it highlights important areas for improvement but lacks detailed guidance on execution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not provide a clear motivation for choosing date and country as potential spurious correlating variables with gender. It suggests that the authors should provide more detailed reasoning or examples to justify this choice. However, the comment does not explicitly instruct the authors on how to address this issue or what specific information should be included. While the action is implied, it is not concrete, as the authors are left to infer what additional information would be beneficial. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of motivation for choosing date and country as potential spurious correlating variables with gender. It suggests that the paper should provide more detailed reasoning or examples to justify this choice. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of motivation and suggests a potential solution, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks motivation for choosing date and country as potential spurious correlating variables with gender. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the motivation for choosing date and country as potential spurious correlating variables with gender. It points out that the paper only speculates on the potential for spurious correlations without providing a clear rationale or evidence to support this choice. This feedback is somewhat helpful as it highlights an area where the paper could be improved by providing more detailed reasoning or examples to justify the selection of these variables. However, the comment could be more helpful if it suggested specific ways to address this issue or provided examples of how other studies have justified their variable choices. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the contribution of exchanging channels, suggesting that it is only achieved using BN and questioning whether it is incremental. The reviewer also mentions that the rationale of Theorem 1 is based on [38] and seems like a simple fact. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve their draft. It lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the contribution of exchanging channels and questions whether it is incremental, suggesting that the rationale of Theorem 1 is based on [38]. However, it does not specify which part of the paper discusses the exchange of channels or the rationale of Theorem 1, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the contribution and the rationale, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the contribution of exchanging channels, suggesting that it is only achieved using BN and questioning its incremental nature. The reviewer also mentions that the rationale of Theorem 1 is based on [38] and seems like a simple fact. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references makes the claim somewhat verifiable, as it requires further elaboration for the authors to fully understand and address the feedback.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the contribution of exchanging channels, suggesting that it is only achieved using BN and questioning its incremental nature. It also critiques the rationale of Theorem 1, noting that it is based on [38] and seems like a simple fact. While the comment identifies potential weaknesses in the paper, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it points out areas for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that if the method is meant to be a main contribution and practical method, then more in-depth studies are needed to establish whether it improves damping in second-order methods. However, it does not provide specific guidance on how to conduct these studies or what aspects should be focused on. Additionally, the comment asks about the meaning of K, which first appears in section 4.1, and whether K=NC. While the comment implies that more information is needed, it does not offer concrete steps for the authors to take. The action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more in-depth studies to establish whether the method improves damping in second-order methods and the question about the meaning of K. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that if the method is meant to be a main contribution and practical method, more in-depth studies are needed to establish whether it improves damping in second-order methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Additionally, the question about the meaning of K and whether K=NC is not directly related to the main claim and does not contribute to the verifiability of the comment. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s contribution, suggesting that if the method is meant to be a main contribution and practical method, more in-depth studies are needed to establish whether it improves damping in second-order methods. This is a relevant point that could help the authors strengthen their argument and provide a more robust basis for their claims. However, the comment also includes minor questions about the meaning of K and whether K=NC, which are not directly related to the main contribution. While the feedback highlights an important area for improvement, it could be more helpful if it focused solely on the contribution aspect. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also recommends additional analysis of the running time or complexity, specifically the impact of the parameters k and N on the running time. These suggestions are clear and provide concrete actions for the authors to take. Additionally, the comment points out a minor issue with the Figure 2 description, which is not aligned with the corresponding text. This feedback is explicit and provides specific guidance on how to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the ablation study\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely an in-depth analysis of the parameters k and N in the ablation study and additional analysis of the running time or complexity. The comment also points out a minor issue with the Figure 2 description, providing clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. This claim is somewhat verifiable as it logically suggests that such an analysis would provide valuable insights, but it lacks specific examples or references to support the claim. Similarly, the suggestion to analyze the running time or complexity is logical but lacks detailed justification or examples. The minor comment about the Figure 2 description is factual and does not require verification. Therefore, the overall comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two main pieces of feedback. First, it suggests that an in-depth analysis of the parameters k and N in the ablation study would greatly enhance readers\\' understanding of the algorithm. This is a clear and actionable suggestion that could significantly improve the clarity and depth of the paper. Second, it recommends additional analysis of the running time or complexity, specifically the impact of the parameters k and N on the running time. This suggestion is also actionable and could help the authors better understand and communicate the performance of their algorithm. The minor comment about the Figure 2 description is minor and does not impact the overall helpfulness of the feedback. Overall, the comment is mostly helpful as it provides clear and actionable suggestions for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the standard deviation of results presented in Appendix B, noting the absence of such information. It also asks whether the 10 runs were conducted over random hyperparameter configurations for all baselines or with the best selected hyperparameters. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include standard deviation information and specify whether the runs were conducted with random or best hyperparameters. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix B,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the absence of standard deviation information and the question of whether the 10 runs were conducted with random or best hyperparameters. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the absence of standard deviation information in Appendix B and asks whether the 10 runs were conducted with random or best hyperparameters. While the comment highlights a potential issue, it does not provide any supporting evidence or reasoning to justify why this information is important or how it would impact the paper\\'s conclusions. The lack of detailed explanation or references makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides a logical question but lacks sufficient justification or evidence to support it fully.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Appendix B, noting the absence of standard deviation information and questioning whether the 10 runs were conducted with random or best hyperparameters. This feedback is clear and actionable, as it prompts the authors to include this important information in their results section. By addressing this point, the authors can enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or explained why standard deviation is important. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include more details about the task generation process in the main text, rather than only in the appendix section. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific in its request for additional information and provides concrete guidance on where to include it, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the task generation process, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the main text, rather than just in the appendix section, and why this would enhance the paper\\'s presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more details about the task generation process should be included in the main text, rather than only in the appendix section. This claim is somewhat verifiable as it logically suggests that providing additional information in the main text would enhance the paper\\'s presentation and understanding. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to include more details about the task generation process in the main text, rather than only in the appendix section. This feedback is valuable as it directly addresses a potential weakness in the paper\\'s presentation, which could enhance the reader\\'s understanding of the experimental setup. By suggesting a specific improvement, the comment offers a concrete way for the authors to strengthen their draft. However, it could be more helpful if it provided additional context or examples on how these details might be integrated into the main text. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify that entropy depends on a datapoint, such as $H(p^a|x)$, to make formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$ more understandable. This feedback is explicit and provides a clear action for the authors to take, which is to clarify the dependency of entropy on a datapoint. The comment is concrete because it specifies the exact change needed to improve the clarity of the formulas. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paragraphs \"Individual-level entropy\" and \"Group-level entropy,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the clarification of entropy dependence on a datapoint, such as $H(p^a|x)$. This provides clear guidance on how to improve the clarity of the formulas. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify the dependency of entropy on a datapoint, such as $H(p^a|x)$, to improve the clarity of formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$. The comment provides a logical reasoning that clarifying the dependency would enhance the understanding of the formulas. However, it lacks specific examples or references to similar works that have addressed this issue, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable argument but could be further substantiated with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper, particularly in the sections on \"Individual-level entropy\" and \"Group-level entropy,\" where the authors represent entropy with $H$. The comment suggests that it would be clearer to specify the dependency of entropy on a datapoint, such as $H(p^a|x)$, to improve the understanding of formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$. This feedback is actionable and provides a clear direction for the authors to enhance the clarity of their formulas, which is valuable for improving the readability and comprehensibility of the paper. However, the comment could be more helpful if it included examples or additional guidance on how to implement this clarification. Overall, the comment is mostly helpful as it effectively points out a specific area for improvement and offers a clear suggestion for enhancing the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper connects tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to implement this suggestion or what specific changes should be made to the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper connects tokens beyond local windows by forming new groups across previous local windows. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the current connection method need improvement or how it should be revised. Without clear guidance on where to focus the revision, the authors may struggle to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper connects tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it relates to the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the paper that suggests a potential improvement. It points out that the paper connects tokens beyond local windows by forming new groups across previous local windows. While this feedback highlights an area for potential enhancement, it lacks depth and does not provide specific guidance on how to implement this suggestion or what aspects of the current method need improvement. The comment could be more helpful if it offered suggestions on how to structure or analyze the new groups, or provided examples of how this approach might be beneficial. As it stands, the comment provides some insight but lacks actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide a more comprehensive illustration of the advantages of using entropy to capture the difference between distributions in the context of Distributionally Robust Optimization (DRO). It highlights that there are various distance metrics used in DRO literature, such as $f$-divergence, Wasserstein distance, and MMD distance, and questions why entropy is preferred. The comment implies that the authors should explain the benefits of using entropy over other distance metrics, potentially by referencing relevant literature. While the action is implicit, it is clear and provides a specific direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"relationship with Distributionally Robust Optimization\" and the \"proposed DD risk,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the advantage of using entropy to capture the difference between distributions and asks for a more comprehensive illustration of this advantage. The comment provides a clear direction for improvement by suggesting that the authors should explain the benefits of using entropy over other distance metrics in the context of DRO. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the advantage of using entropy to capture the difference between distributions in the context of Distributionally Robust Optimization (DRO) and suggests that the authors provide a more comprehensive illustration of this advantage. The reviewer references works using $f$-divergence, Wasserstein distance, and MMD distance, which are commonly used in DRO literature, to support the claim that there are alternative distance metrics that could be considered. However, the comment lacks specific examples or detailed reasoning from the referenced works to fully substantiate the claim. While it provides some context and references, the lack of detailed justification makes the claim somewhat verifiable, as the authors would need to further explore the literature to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the proposed method, questioning the advantage of using entropy to capture the difference between distributions in the context of Distributionally Robust Optimization (DRO). It references commonly used distance metrics in DRO literature, such as $f$-divergence, Wasserstein distance, and MMD distance, and suggests that the authors should provide a more comprehensive illustration of the benefits of using entropy over these alternatives. This feedback is clear and actionable, as it guides the authors to address a specific area of concern by providing a rationale for why entropy might be advantageous. However, the comment could be more helpful if it included specific examples or references to literature that support the use of entropy or other distance metrics. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear path for enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the nature of the T-REx dataset, specifically whether it is a distantly supervised dataset with no human labels. The reviewer asks if it is possible to evaluate over an annotated dataset, such as TACRED or FewRel. While the comment implies that the authors should consider evaluating their model on an annotated dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should evaluate on an annotated dataset. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the T-REx dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the nature of the dataset and whether it is possible to evaluate it over an annotated dataset like TACRED or FewRel. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the nature of the T-REx dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the nature of the T-REx dataset, specifically whether it is a distantly supervised dataset with no human labels. It also asks if it is possible to evaluate the model on an annotated dataset like TACRED or FewRel. While the comment identifies a potential area for clarification, it does not provide any actionable feedback or suggestions for improvement. The authors are left with a question but no guidance on how to address it or what specific aspects of the dataset should be clarified. Therefore, the comment is somewhat helpful, as it points out a potential area for clarification but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It explicitly instructs them to give the appendix a proofread, specifically mentioning the need to correct \"poster mean,\" \"peicewise-linear,\" and \"sugggest\" in sections P6 and P9. Additionally, it suggests expanding on the potential negative societal impacts discussed in the paper. The comment is clear and provides concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as correcting typographical errors and expanding on the potential negative societal impacts. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the appendix does not follow the NeurIPS 2021 style files and recommends a proofread. It also suggests expanding on the potential negative societal impacts discussed in the paper. While the comment identifies specific typographical errors, it lacks detailed reasoning or references to support the claim about the appendix style. The suggestion to expand on the negative societal impacts is more vague and could benefit from additional context or examples. Overall, the claim is somewhat verifiable, as it provides some evidence but lacks comprehensive justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the appendix, noting that it does not follow the NeurIPS 2021 style files. It provides a clear and actionable suggestion to give the appendix a proofread, which is a straightforward and important step for improving the paper. Additionally, the comment suggests expanding on the potential negative societal impacts discussed in the paper, which could enhance the authors\\' understanding of the broader implications of their work. While the comment could be more helpful by providing examples or guidance on how to address the societal impacts, it still offers valuable insights that can help the authors improve their draft. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider examining training and validation curves for the different losses and determine whether the model can bring all three losses down simultaneously. Additionally, it raises a question about any tricks related to weighing these losses. While the comment implies that the authors should conduct these analyses, it does not explicitly instruct them to do so. The action is clear but not explicitly stated, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests examining training and validation curves for different losses and determining whether the model can bring all three losses down simultaneously. It also raises a question about any tricks related to weighing these losses. However, the comment does not specify which part of the paper should include these analyses or where the validation curves are currently presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of training and validation curves and the consideration of weighing losses, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should examine training and validation curves for different losses and determine whether the model can bring all three losses down simultaneously. It also raises a question about any tricks related to weighing these losses. While the comment provides a logical suggestion for further analysis, it lacks specific examples or references to support the claim that these analyses would be beneficial. The absence of detailed justification or evidence makes the claim somewhat verifiable, as it requires more information to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should examine training and validation curves for different losses and determine whether the model can bring all three losses down simultaneously. It also raises a question about any tricks related to weighing these losses. This feedback is clear and actionable, as it provides specific guidance on how the authors might improve their analysis and understanding of the model\\'s performance. By addressing these points, the authors can enhance the transparency and comprehensiveness of their results. However, the comment could be more helpful if it included examples or references to similar analyses in related works, which would further support the authors in implementing these suggestions. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims that computing the GOSPA metric is NP-hard but lacks a rigorous theoretical argument or proof. It suggests that the authors should provide a more detailed explanation or proof of this claim, as it is not generally true for assignment problems. Additionally, the comment notes that the paper assumes access to the optimal assignment matrix, which could limit its applicability. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed theoretical argument or proof. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"NP-hardness\" claim and the specific section where it is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a rigorous theoretical argument or proof for the NP-hardness claim. The comment provides a detailed critique of the claim and suggests that the paper\\'s applicability may be limited due to the assumption of access to the optimal assignment matrix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim of NP-hardness for computing the GOSPA metric is not substantiated by a rigorous theoretical argument or proof. The reviewer provides a logical reasoning by pointing out that the claim is not generally true for assignment problems and suggests that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem. However, the comment lacks specific references or examples to support the claim that the paper\\'s assumption of access to the optimal assignment matrix limits its applicability. While the reasoning is sound, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s claim of NP-hardness for computing the GOSPA metric. It points out that the paper lacks a rigorous theoretical argument or proof to support this claim, which is a critical aspect of the paper\\'s theoretical foundation. The reviewer provides a logical reasoning by suggesting that the claim is not generally true for assignment problems and that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem. Additionally, the comment highlights a potential limitation in the applicability of the paper due to the assumption of access to the optimal assignment matrix. This feedback is highly valuable as it guides the authors to strengthen their theoretical foundation and address a critical weakness in their work. However, the comment could be more helpful if it provided specific suggestions on how to present the theoretical argument or proof more effectively. Overall, the comment is highly helpful as it directs the authors to a crucial area for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that an algorithmic writeup of the solution to the pricing problem would be helpful. This provides a clear and direct action for the authors to take, as it specifies a specific improvement that would enhance the clarity and understanding of their work. The comment is specific in detailing what is needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that an algorithmic writeup of the solution to the pricing problem would be helpful. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an improvement, but without clear grounding, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an algorithmic writeup of the solution to the pricing problem would be helpful. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that an algorithmic writeup of the solution to the pricing problem would be helpful. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity and understanding of the paper. By including an algorithmic writeup, the authors can enhance the transparency and reproducibility of their work, which is a valuable contribution. However, the comment could be more helpful if it explained why an algorithmic writeup is necessary or how it would benefit the paper. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the role of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this balance requires the policy to explore intelligently and update gradually during initialization. However, it does not provide specific guidance on how the authors should address this issue or what steps to take to clarify the relationship between the proposed technique and the trade-off. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"numerical evaluation\" and the \"trade-off between KL divergence and reward,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the role of model averaging in balancing the trade-off. The comment suggests that achieving this balance requires the policy to explore intelligently and update gradually during initialization, but it does not provide specific examples or detailed explanations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the effectiveness of model averaging in balancing the trade-off between KL divergence and reward, suggesting that achieving this balance requires the policy to explore intelligently and update gradually during initialization. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. It relies on the reviewer\\'s understanding and interpretation, making it somewhat verifiable. The authors would need to make a significant effort to verify the claim themselves, as the comment does not provide sufficient evidence or justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the role of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this balance requires the policy to explore intelligently and update gradually during initialization. However, the comment does not provide specific suggestions or examples on how the authors might address this issue or what alternative mechanisms might be considered. While it points out a potential area for improvement, the feedback lacks actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a discussion regarding a possible generalization with a different distribution for the size of the batches could be included. While the comment implies that the authors should consider this topic, it does not provide specific guidance on how to approach this discussion or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on generalization with different batch sizes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a discussion regarding a possible generalization with a different distribution for the size of the batches could be included. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the generalization should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that a discussion regarding a possible generalization with a different distribution for the size of the batches could be included. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that a discussion regarding a possible generalization with a different distribution for the size of the batches could be included. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to approach this discussion or what aspects to consider. The comment is vague and does not offer actionable steps for the authors to take, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis only considers the case of batch size equal to 1 and questions how the batch size affects the effective initialization scale. While the comment identifies a specific issue with the analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to consider different batch sizes and explore the impact on the effective initialization scale. The action is implicit and somewhat vague, as it lacks concrete steps on how to implement the suggested change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the analysis only considers the case of batch size = 1 and questions how the batch size affects the effective initialization scale. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis only considers the case of batch size = 1 and questions how the batch size affects the effective initialization scale. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the analysis, noting that it only considers the case of batch size equal to 1 and questions how the batch size affects the effective initialization scale. This feedback is valuable as it highlights a potential limitation in the analysis and prompts the authors to consider the impact of different batch sizes. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific aspects of the analysis should be expanded to include different batch sizes. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance on how to implement it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results shown in Figure 7, specifically asking why more data leads to lower results on the ImageNet linear evaluation. It also suggests that sampling 50% of the data seems to yield better results than sampling 100% of the data. While the comment does not explicitly instruct the authors to make changes or provide specific guidance on how to address this issue, it does imply that the authors should investigate the reasons behind these results and potentially adjust their sampling strategies. The action is implicit but concrete, as it points to a specific area of the paper that needs further exploration. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results shown in the figure and suggests that sampling 50% of the data seems to yield better results than sampling 100% of the data. This provides clear guidance on what needs to be addressed in the paper, namely the interpretation of the results and the sampling strategy. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the results shown in Figure 7. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the results shown in Figure 7, specifically questioning why more data leads to lower results on the ImageNet linear evaluation. It suggests that sampling 50% of the data seems to yield better results than sampling 100% of the data. While the comment identifies a potential issue with the results, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis. The feedback is somewhat helpful as it points out a potential area for further exploration, but it lacks actionable advice or detailed guidance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the paper, namely the lack of comprehensive evaluation on mainstream metrics such as FVD. It explicitly states that including FVD would enhance the paper\\'s credibility and make it more comparable to other video generation methods. The comment provides a clear and direct action for the authors to take, which is to include FVD results in their evaluation. This guidance is explicit and concrete, as it specifies exactly what needs to be done to improve the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of the newly proposed VBench as the primary evaluation benchmark and the lack of comprehensive evaluation on mainstream metrics such as FVD. This allows the authors to accurately identify the part of the paper being addressed, which is the evaluation section. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of FVD results to enhance the paper\\'s credibility and comparability with other video generation methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comprehensive evaluation, specifically mentioning the absence of FVD results. The comment supports this claim by referencing the widely recognized and robust nature of FVD for evaluating temporal video prediction. However, the comment does not provide specific examples or references to FVD results from other studies, which would strengthen the argument for the importance of including FVD in the evaluation. While the reasoning is logical and the reference to FVD is relevant, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely the lack of comprehensive evaluation on mainstream metrics such as FVD. It highlights the importance of including these metrics to enhance the paper\\'s credibility and comparability with other video generation methods. The comment provides a clear and actionable suggestion for improvement, which is to include FVD results in the evaluation section. This feedback is valuable as it guides the authors to address a critical gap in their work, thereby enhancing its impact and rigor. However, the comment could be more helpful if it included specific examples or references to studies that have used FVD for evaluating temporal video prediction. Overall, the comment is mostly helpful as it effectively directs the authors to a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical details in section 2.2 are difficult to follow. However, it does not provide any explicit or implicit suggestions for how the authors might improve the clarity or presentation of these details. There is no guidance on what specific aspects of the technical details are problematic or how they could be better explained. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"2.2,\" which provides some grounding as it refers to a specific section of the paper. However, it does not specify what aspect of the technical details is difficult to follow, making it weakly grounded. The comment is specific in identifying the issue with the technical details being hard to follow, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical details in section 2.2 are difficult to follow. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific issue with the technical details in section 2.2, noting that they are difficult to follow. However, it does not provide any suggestions or guidance on how the authors might improve the clarity or presentation of these details. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies a weakness but lacks depth and specificity in its feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the improvement of EVA over the backbone models, specifically OT-Flow, in terms of designability and success rates. It suggests that if the main contribution is the addition of geometry information and motif-interpolation, the authors should clarify whether these design choices offer benefits over prior backbones. While the comment implies that the authors should provide a comparison between EVA and OT-Flow, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"RFDiffusion benchmark\" and \"in-silico vaccine design benchmark,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvement of EVA over backbone models, particularly OT-Flow, in terms of designability and success rates. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the improvement of EVA over the backbone models, specifically OT-Flow, in terms of designability and success rates. It suggests that if the main contribution is the addition of geometry information and motif-interpolation, the authors should clarify whether these design choices offer benefits over prior backbones. The comment is somewhat verifiable as it logically questions the improvement of EVA over OT-Flow, but it lacks specific examples or references to support the claim. The authors would need to provide more detailed evidence or comparisons to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the improvement of EVA over the backbone models, specifically OT-Flow, in terms of designability and success rates. It suggests that if the main contribution is the addition of geometry information and motif-interpolation, the authors should clarify whether these design choices offer benefits over prior backbones. This feedback is somewhat helpful as it prompts the authors to consider the strengths and weaknesses of their approach relative to existing methods. However, the comment could be more helpful if it provided specific examples or comparisons to support the claim. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that there are too many identical sentences in the Abstract, Introduction, and Conclusion sections of the paper. However, it does not provide any specific guidance on how to address this issue, such as suggesting ways to vary the language or structure of these sections. The action is implicit and vague, as the authors are left to infer that they need to revise these sections to avoid repetition. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment points out that there are too many identical sentences in the Abstract, Introduction, and Conclusion sections of the paper. However, it does not specify which sentences are identical or where they appear in the paper. Without explicit references to specific sections or sentences, the authors cannot confidently determine which parts need revision. The comment is specific in identifying the issue of repetition but lacks grounding as it does not point to specific sections or sentences. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are too many identical sentences in the Abstract, Introduction, and Conclusion sections of the paper. However, it does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed examples or references, the claim lacks verifiability, making it challenging for the authors to understand and act upon the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that there are too many identical sentences in the Abstract, Introduction, and Conclusion sections. This is a clear and actionable point that can help the authors improve the clarity and originality of their draft. However, the comment could be more helpful if it provided suggestions on how to vary the language or structure of these sections to avoid repetition. Despite this, the feedback is valuable as it directs the authors to a specific area for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks about the reward function used in the ablation studies, specifically inquiring whether it is sEH. This question is clear and direct, providing the authors with a specific action to take: to clarify or provide information about the reward function used. The comment is highly actionable as it clearly instructs the authors on what to include in their draft, ensuring that they know exactly what information is needed to address the reviewer\\'s concern.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"reward function\" and the \"ablation studies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification about the reward function used in the ablation studies, specifically inquiring whether it is sEH. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the reward function used in the ablation studies. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the reward function used in the ablation studies, asking whether it is sEH. This is a clear and actionable request for clarification, as it prompts the authors to provide additional information that could enhance the transparency and understanding of their methodology. By addressing this question, the authors can improve the clarity and completeness of their draft, which is beneficial for both the reviewer and the authors. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the comparison between self-generated code and a placeholder, noting that using the self-generated code samples the model 2x for each generation, which may not be a fair comparison to previous work. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to ensure fairness in the comparison. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of using self-generated code versus a placeholder in the comparison with previous work. It highlights that using self-generated code samples the model 2x for each generation, which may not be a fair comparison. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the comparison, but without explicit references to sections or specific elements, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using self-generated code is not a fair comparison to previous work, as it samples the model 2x for each generation. The comment provides a logical reasoning by explaining that using a placeholder code was intended in the original technique, and that generating the code only once is more appropriate. However, the comment lacks specific examples or references to support the claim that using self-generated code is not a fair comparison. This makes the claim somewhat verifiable, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between self-generated code and a placeholder, noting that using the self-generated code samples the model 2x for each generation, which may not be a fair comparison to previous work. The comment highlights that using a placeholder code was somewhat intended in the original technique, suggesting that generating the code only once would be more appropriate. While the comment points out a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the fairness of the comparison. The feedback is somewhat helpful as it alerts the authors to a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the presentation of Sections 3 and 4, suggesting that they should be the main contributions of the paper but are only briefly discussed on a single page. It points out the absence of precise mathematical definitions for the quantum states in Equation (4), which makes it difficult to follow. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to expand and clarify these sections, but the comment lacks concrete details on how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sections 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the presentation of these sections, noting that they should be the main contributions but are only briefly discussed on a single page. Additionally, it points out the absence of precise mathematical definitions for the quantum states in Equation (4), which makes it difficult to follow. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Sections 3 and 4, which should be the main contributions of the paper, are only briefly discussed on a single page. It also notes the absence of precise mathematical definitions for the quantum states in Equation (4), which makes it difficult to follow. This claim is somewhat verifiable as it provides a logical reasoning for the critique, but it lacks specific examples or references to support the assertion about the lack of mathematical definitions. The authors would need to make a significant effort to verify the claim themselves, as the comment does not provide detailed guidance on how to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the presentation of Sections 3 and 4, which should be the main contributions of the paper but are only briefly discussed on a single page. It points out the absence of precise mathematical definitions for the quantum states in Equation (4), which makes it difficult for readers to follow. This feedback is clear and actionable, as it highlights specific areas that need improvement and provides a concrete suggestion for expanding and clarifying these sections. However, the comment could be more helpful if it offered suggestions on how to present these sections more effectively or provided examples of how to address the lack of mathematical definitions. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the results are fair with respect to under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete guidance on how to do so. The authors can infer that they need to analyze and discuss the potential impact on under-represented groups, but the comment lacks specific details on how to conduct this analysis or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of the results with respect to under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment where this issue might be addressed. The authors can infer that it relates to the results or analysis sections, but this inference is not direct. The comment is specific in its request for an analysis of fairness with respect to under-represented groups, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the fairness of the results with respect to under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the fairness of the results with respect to under-represented groups, specifically asking if females or blacks are discriminated by the recommendations of LLMs. This is a relevant and thought-provoking question that could prompt the authors to consider and address potential biases in their work. However, the comment lacks specific guidance or suggestions on how to investigate or analyze this issue, leaving the authors with a general direction but without detailed steps to follow. Therefore, the comment is somewhat helpful, as it identifies a critical area for consideration but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that the paragraph describing Co-variance is too long, which reduces the legibility of the paper. It also recommends adding more details for the generation of two types of long-tailed datasets, as experiments on long-tailed datasets are important for affirming the contribution of the paper. Additionally, the reviewer suggests that due to the limited pages, the tables and figures might be too dense, and recommends using more pages for the experiments on long-tailed datasets. Each of these suggestions is clear and actionable, providing the authors with specific guidance on how to improve the clarity and comprehensiveness of their paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1\" and \"the paragraph that describes Co-variance,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the length of the paragraph and the need for more details on the generation of long-tailed datasets. The comment also suggests that the tables and figures might be too dense due to the limited pages, and recommends using more pages for the experiments on long-tailed datasets. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims regarding the length of the paragraph describing Co-variance, the need for more details on the generation of long-tailed datasets, and the density of tables and figures due to limited pages. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or examples, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides several specific and actionable suggestions for improving the clarity and comprehensiveness of the paper. It identifies a potential issue with the length of the paragraph describing Co-variance, which could reduce the legibility of the paper. It also recommends adding more details on the generation of two types of long-tailed datasets, which are important for affirming the contribution of the paper. Additionally, the reviewer suggests that due to the limited pages, the tables and figures might be too dense, and recommends using more pages for the experiments on long-tailed datasets. These suggestions are clear and actionable, providing the authors with concrete steps to enhance the clarity and impact of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the necessary changes to make EC-Diffusers work on real-world data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific modifications or improvements are needed, nor are there suggestions for how to address the issue. As a result, the authors are left without any clear direction on how to proceed with this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about necessary changes to make EC-Diffusers work on real-world data, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what changes are needed or how they might be implemented. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about necessary changes to make EC-Diffusers work on real-world data. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about necessary changes to make EC-Diffusers work on real-world data. However, it lacks specificity and does not provide any guidance or suggestions on what those changes might entail or how they could be implemented. Without actionable feedback or detailed insights, the authors are left without a clear path forward in addressing this issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the reliability of the evaluation and suggests the need for a human study to assess the efficacy of the evaluation protocol. While the comment implies that the authors should consider conducting a human study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a human study to address the concerns raised. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the reliability of the evaluation and suggests the need for a human study to assess the efficacy of the evaluation protocol. However, it does not specify which part of the paper this evaluation is discussed in, nor does it provide details on what aspects of the evaluation are questionable. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the reliability of the evaluation and suggests the need for a human study to assess the efficacy of the evaluation protocol. However, it does not provide any supporting evidence, reasoning, or references to justify why a human study is necessary or how it would improve the evaluation. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary support to guide the authors in addressing the concern. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the reliability of the evaluation and suggests the need for a human study to assess the efficacy of the evaluation protocol. This is an important point that could help the authors improve the robustness and credibility of their work. However, the comment lacks specific guidance on how to conduct such a study or what aspects of the evaluation should be tested. While it identifies a potential weakness, it does not provide actionable steps for the authors to address it. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the novelty of the work, comparing it to prior work and finding it somewhat incremental. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the novelty or what specific aspects of the work could be revised to enhance its originality. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the work, comparing it to prior work (von Kugelgen et al. 2021; Daunhawer et al. 2023). However, it does not specify which part of the paper discusses the technical contribution or the novelty, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the technical contribution being incremental, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution of the work is somewhat incremental, comparing it to prior work (von Kugelgen et al. 2021; Daunhawer et al. 2023). However, the comment does not provide specific examples or detailed reasoning from the referenced works to support this claim. Without such references or detailed justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment expresses a concern about the novelty of the work, comparing it to prior work and finding it somewhat incremental. While it identifies a potential issue with the technical contribution, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The comment lacks actionable feedback or detailed advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as barely helpful, as it points out a potential weakness but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting an analysis on the performance of PromptMix in relation to the quality of questions/answers generated by a large language model (LLM). It proposes two specific actions: (1) identifying which open-source LLMs would work with this approach and (2) finding a LLM parameter count cutoff (e.g., 7B) that would indicate when performance starts to degrade. These actions are explicit and provide concrete steps for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"PromptMix\" and \"the quality of questions / answers generated by the LLM,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting an analysis on the performance of PromptMix in relation to the quality of questions/answers generated by an LLM, and it proposes specific actions, such as identifying which open-source LLMs would work with this approach and finding a LLM parameter count cutoff. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the performance of PromptMix depends on the quality of questions/answers generated by a large language model (LLM). It proposes an analysis to identify which open-source LLMs would work with this approach and suggests finding a LLM parameter count cutoff (e.g., 7B) that would indicate when performance starts to degrade. While the comment provides a logical basis for the claim, it lacks specific examples or references to support the assertion about the LLMs that would work or the specific cutoff point. This makes the claim somewhat verifiable, as the authors would need to conduct their own analysis to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of the quality of questions/answers generated by a large language model (LLM) for the performance of PromptMix. The comment suggests conducting an analysis to identify which open-source LLMs would work with this approach and proposes finding a LLM parameter count cutoff (e.g., 7B) that would indicate when performance starts to degrade. This feedback is specific and provides a clear direction for the authors to explore and potentially improve their work. By offering concrete steps for further analysis, the comment is highly helpful in guiding the authors towards enhancing their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should comment on the feasibility of the submodularity approach, specifically regarding the SATURATE algorithm and its scalability with N. It also asks for the runtimes of simulations for large models in Section 6. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added, but it is somewhat vague in terms of how to present this information. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"submodularity approach subroutine\" and \"SATURATE algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of the approach and requests information on the runtimes of simulations for large models in Section 6. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the feasibility of the submodularity approach, specifically mentioning the SATURATE algorithm and its scalability with N. The reviewer suggests that it would be worth commenting on the runtimes of simulations for large models in Section 6. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim about the feasibility of the approach. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the paper that could be improved by commenting on the feasibility of the submodularity approach, particularly the SATURATE algorithm and its scalability with N. It suggests that the authors should provide information on the runtimes of simulations for large models in Section 6. This feedback is clear and actionable, as it directs the authors to address a potential weakness in their work by providing additional data or analysis. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and robustness of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the inference at test time could benefit from more details. However, it does not provide specific guidance on what additional details are needed or how to incorporate them into the paper. The action is implicit and vague, as the authors are left to infer that they need to provide more details but without clear instructions on what those details should be. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"594,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more details on inference at test time. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the inference at test time could benefit from more details. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could benefit from more detail, specifically regarding inference at test time. While it highlights a potential gap in the explanation, it does not provide specific suggestions or guidance on what additional details might be needed or how to incorporate them into the paper. This feedback is somewhat helpful as it points out an area for improvement but lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the correctness and soundness of the paper, including the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of the chain of self-revisions. However, it does not provide explicit or implicit actions for the authors to take to address these concerns. The comment lacks specific guidance on how to improve the evaluation or clarify the alignment with human preference, nor does it suggest ways to enhance the effectiveness of sub-module generation or the analysis of the chain of self-revisions. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses several issues related to the correctness and soundness of the paper, including the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of the chain of self-revisions. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides some specific concerns, it lacks full grounding as it does not specify the exact parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the correctness and soundness of the paper, including the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of the chain of self-revisions. However, the comment lacks specific evidence or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed reasoning or examples makes the claims unverifiable, as the authors are left without clear guidance on how to improve their work. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas of concern regarding the correctness and soundness of the paper, including the evaluation of programs generated by CodeChain, the effectiveness of sub-module generation, and the analysis of the chain of self-revisions. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their work. It does not provide actionable feedback or detailed insights into what changes could be made to enhance the paper\\'s rigor or clarity. As a result, the comment is somewhat helpful, as it points out potential weaknesses but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' argument regarding the accuracy of deferring classifiers compared to non-deferring classifiers. It seeks clarification on whether the authors\\' claim implies that the differences in error rates between subgroups are larger for the deferring classifier, making it less fair. While the comment implies that the authors should clarify their argument or provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of fairness in their argument. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 306-307, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\\' argument about the accuracy of deferring classifiers and seeks clarification on the implications for fairness. The comment provides clear guidance on what needs to be addressed, namely the interpretation of the authors\\' argument regarding the differences in error rates between subgroups. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' argument about the accuracy of deferring classifiers compared to non-deferring classifiers. It seeks clarification on whether the differences in error rates between subgroups are larger for the deferring classifier, making it less fair. The comment is somewhat verifiable as it logically questions the authors\\' claim, but it lacks specific examples or references to support the argument. The authors would need to provide additional evidence or reasoning to fully substantiate their claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the authors\\' argument regarding the accuracy of deferring classifiers compared to non-deferring classifiers. It seeks clarification on whether the differences in error rates between subgroups are larger for the deferring classifier, making it less fair. This feedback is valuable as it prompts the authors to reconsider their argument and potentially revise their conclusions. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or clarified the implications of the authors\\' argument. Overall, the comment is somewhat helpful as it identifies a potential weakness in the paper but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to report the improvement in object classification directly, in addition to the overall scene graph results. This is a clear and concrete action that the authors can take to strengthen their case. The comment provides a specific suggestion for enhancing the paper by including additional results, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of results to support the claim about the relational embedding module improving object classification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the relational embedding module significantly improves object classification but lacks supporting evidence or references to substantiate this claim. The reviewer suggests that reporting the improvement in object classification directly would strengthen the paper. However, the comment does not provide any specific examples or data to support the claim or suggest how the authors might present this information. This lack of detailed evidence or reasoning makes the claim unverifiable, as it does not provide sufficient support for the authors to address the critique effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the claim about the relational embedding module significantly improving object classification is not supported by any results or evidence. It suggests that reporting the improvement in object classification directly would strengthen the case of the paper. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance their draft by including additional results to support their claims. By addressing this point, the authors can improve the credibility and persuasiveness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a critique of the paper\\'s scope, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph. It references a previous work on hypergraph attention networks for multimodal learning, suggesting that the novelty of the manuscript is limited to adding self-supervised learning on top of it. However, the comment does not provide explicit guidance on how the authors should address this critique or improve the scope of their work. The action is implicit and somewhat vague, as the authors can infer that they need to expand the scope or find ways to differentiate their work from the reference. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"CVPR 2020 paper\" and the \"hypergraph attention network for multimodal learning,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the novelty of the manuscript is limited to adding self-supervised learning on top of the existing multimodal representation learning. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s scope is narrow because it combines self-supervised learning with multimodal representation learning based on hypergraph, referencing a previous work on hypergraph attention networks for multimodal learning. The reviewer suggests that the novelty of the manuscript is limited to adding self-supervised learning on top of the existing multimodal representation learning. However, the comment lacks specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to infer the basis of the critique and potentially conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critical analysis of the paper\\'s scope, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph. It references a previous work on hypergraph attention networks for multimodal learning, suggesting that the novelty of the manuscript is limited to adding self-supervised learning on top of it. While the comment identifies a potential weakness in the paper\\'s scope, it does not offer specific suggestions or guidance on how the authors might address this issue or expand the scope of their work. The feedback is somewhat helpful as it points out a limitation, but it lacks actionable advice or detailed insights that could help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difficulty of finding intuitive attention examples similar to those in Figure 4. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or a clear direction, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper Figure 4 is discussed in, nor does it provide context on what intuitive attention examples are being referred to. Without explicit references or clear indications, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity as it does not provide details on what the reviewer is asking or what the issue is with finding intuitive attention examples. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the difficulty of finding intuitive attention examples similar to those in Figure 4. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment poses a question about the difficulty of finding intuitive attention examples similar to those in Figure 4. While it highlights an area of interest, it does not provide any guidance or suggestions for improvement. It lacks actionable feedback or context that would help the authors understand how to address this issue or improve their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difference between two specific values, 01 and 10, in Figure 1. While it does not explicitly instruct the authors to make any changes or provide guidance on how to address this question, it does prompt them to clarify the meaning behind these values. The action is implicit, as the authors can infer that they need to provide an explanation or clarification regarding the values in Figure 1. However, the comment is concrete in that it clearly identifies the issue and provides a specific question to be addressed. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the difference between two specific values, 01 and 10, in Figure 1. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the difference between two specific values, 01 and 10, in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the difference between two specific values, 01 and 10, in Figure 1. While it highlights an area of confusion or potential misunderstanding, it does not provide any guidance or suggestions for clarification or improvement. The comment does not offer actionable feedback or insight into how the authors might address this issue or enhance the clarity of their presentation. As a result, it lacks helpfulness and does not assist the authors in improving their draft. Therefore, it is rated as 1: Not Helpful at All.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to keep a separate \"Related Work\" section and suggests shifting the three bullet points about related work from the \"Introduction\" section to this new section. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific in detailing which bullet points should be moved and where they should be placed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section and suggests shifting the \"Traditional AES,\" \"Deep Neural AES,\" and \"Pre-training AES\" bullet points to the \"Related Work\" section. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the relocation of the related work bullet points to the \"Related Work\" section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the \"Introduction\" section is too long and should be separated into a \"Related Work\" section. The reviewer provides a specific suggestion to shift the three bullet points about related work to this new section. This claim is somewhat verifiable as it provides a logical reasoning for separating the related work information, but it lacks detailed justification or examples to fully substantiate the need for this separation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to improve the organization and presentation of the paper. It identifies that the \"Introduction\" section is too long and suggests separating the related work information into a \"Related Work\" section. This feedback is specific and offers a concrete way to improve the paper\\'s structure and clarity, making it easier for readers to understand the context and relevance of the related work. By following this suggestion, the authors can enhance the readability and accessibility of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the overall process and rationale for constructing the benchmark, suggesting that the paper could present these more clearly. However, it does not provide specific guidance on how to improve the clarity or what aspects need more detail. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the clarity but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could present the overall process and rationale for constructing the benchmark more clearly. However, it does not specify which part of the paper this issue pertains to, such as the sections discussing the rules or data augmentation methods. Without explicit references to sections or specific elements, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the process or rationale need clarification. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could present the overall process and rationale for constructing the benchmark more clearly. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the clarity of the overall process and rationale for constructing the benchmark. It suggests that the paper could present these aspects more clearly, which is a valuable point for the authors to consider. However, the comment lacks specific guidance or examples on how to enhance the clarity or what aspects need more detail. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a significant lack of literature reviews on recent advances in active learning communities, especially in the context of Bayesian learning. It points out that the Bayesian Coreset is directly relevant to the work and has been overlooked in the literature review. Additionally, it suggests that the current setup might be more advanced than related studies, such as [1][2]. While the comment provides explicit actions\u2014to include literature reviews and discuss the current setup's advancements\u2014it does so in a somewhat vague manner. The authors are given a clear direction but may need to infer the specific details of how to implement these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of content in the paper, specifically the literature review on recent advances in active learning communities, especially in the context of Bayesian learning. It references the Bayesian Coreset as directly relevant to the work and points out that it has been overlooked in the literature review. Additionally, it suggests discussing how the current setup is more advanced than related studies, such as [1][2]. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks content, specifically in the literature review of recent advances in active learning communities, especially in the context of Bayesian learning. The reviewer provides specific examples, such as the Bayesian Coreset, which is directly relevant to the work but has been overlooked in the literature review. Additionally, the reviewer suggests that the current setup might be more advanced than related studies, such as [1][2]. This claim is supported by logical reasoning and specific examples, making it mostly verifiable. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of content in the literature review on recent advances in active learning communities, especially in the context of Bayesian learning. It points out that the Bayesian Coreset is directly relevant to the work and has been overlooked in the literature review. Additionally, it suggests discussing how the current setup is more advanced than related studies, such as [1][2]. This feedback is clear and actionable, providing the authors with specific areas to address in their literature review and potential improvements to their work. By addressing these points, the authors can significantly enhance the comprehensiveness and rigor of their review. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"one-to-many relationship\" in Figure 2 makes it difficult to understand the presented trends and that the plots seem to contain a considerable amount of noise. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve the clarity or reduce the noise in the figures. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the \"one-to-many relationship\" in the plot, which makes it difficult to understand the presented trends, and the presence of noise in the plots. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"one-to-many relationship\" in Figure 2 makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. However, the comment does not provide any specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, noting that the \"one-to-many relationship\" in the plot makes it difficult to understand the presented trends. It also points out that the plots seem to contain a considerable amount of noise. While the comment highlights these concerns, it lacks specific suggestions or guidance on how the authors might address these issues, such as recommending alternative visualizations or methods to reduce noise. This limits the comment\\'s helpfulness, as it provides some insight but does not offer actionable advice for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the comparison between DFSSATTEN and existing algorithms like Performer and Reformer, noting that the speedup is mostly due to low-level optimization and hardware support. It suggests that directly comparing these algorithms might be unfair due to their lack of deep optimization. Additionally, the comment points out that the authors argue that these methods are usually trained from scratch, which is a significant direction in pretraining. The reviewer questions whether DFSSATTEN supports training from scratch and suggests that it would be beneficial if it did. However, the comment does not provide explicit instructions on how to address this issue or what specific actions the authors should take to investigate this aspect. The feedback is somewhat actionable as it identifies a potential area for improvement but lacks concrete guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"DFSSATTEN\" algorithm, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison between DFSSATTEN and existing algorithms like Performer and Reformer, noting that the speedup is mostly due to low-level optimization and hardware support. The comment also raises a question about whether DFSSATTEN supports training from scratch, which is a significant direction in pretraining. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the speedup achieved by DFSSATTEN is mostly due to low-level optimization and hardware support, and that existing algorithms like Performer and Reformer are not deeply optimized. The reviewer suggests that directly comparing DFSSATTEN with these algorithms might be unfair. Additionally, the comment points out that the authors argue that these methods are usually trained from scratch, which is a significant direction in pretraining. The reviewer questions whether DFSSATTEN supports training from scratch, implying that this aspect should be studied. The comment is mostly verifiable as it provides logical reasoning and references to existing practices, such as training from scratch, to support the claim. However, it could be strengthened by providing specific examples or references to studies that demonstrate the importance of training from scratch. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable critique of the paper\\'s comparison with existing algorithms like Performer and Reformer. It points out that the speedup achieved by DFSSATTEN is mostly due to low-level optimization and hardware support, which could make direct comparisons unfair. This is an important observation that the authors should consider when evaluating the performance of their algorithm. Additionally, the comment highlights the significance of training from scratch, which is a significant direction in pretraining, and questions whether DFSSATTEN supports this approach. This feedback is valuable as it prompts the authors to consider whether their algorithm can be trained from scratch, which could enhance its applicability and impact. Overall, the comment is mostly helpful as it offers clear and actionable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that the VMI-SI-TI-DI-FDSM method was evaluated on a black-box setting when their method was tested on a defended model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific improvements could be made. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"VMI-SI-TI-DI-FDSM\" and \"black-box setting\" and \"defended model,\" which provides some context for the authors to identify the part of the paper being addressed. However, it does not specify which section or part of the paper this evaluation is based on, making it weakly grounded. The comment is specific in detailing what was examined and how it was evaluated, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the VMI-SI-TI-DI-FDSM method was evaluated on a black-box setting when their method was tested on a defended model. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it affects the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment mentions that the VMI-SI-TI-DI-FDSM method was evaluated on a black-box setting when their method was tested on a defended model. However, it does not provide any further context, explanation, or suggestions for improvement. Without additional information or guidance, the authors are left without actionable feedback or insights into how to address this issue or improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the clarity of the proposed method's description could be improved and recommends referring to the questions section for details. While the comment implies that the authors should enhance the clarity of their method description, it does not provide specific guidance on how to achieve this improvement or what aspects of the description are unclear. The action is implicit and somewhat vague, as the authors need to infer that they should refer to the questions section for clarity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the clarity of the proposed method\\'s description could be improved, but it does not specify which part of the paper this pertains to. The mention of the questions section implies that the authors should refer to it for details, but this is not explicitly stated. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in suggesting a potential improvement but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the clarity of the proposed method\\'s description could be improved, but it does not provide any specific examples or reasoning to support this claim. The mention of the questions section implies that there might be additional information or clarification needed, but this is not detailed enough to be fully verifiable. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the clarity of the proposed method\\'s description could be improved, specifically mentioning that the questions section might provide additional details. While this feedback points out an area for improvement, it lacks specificity and does not offer guidance on how to enhance the clarity or what aspects of the description are unclear. The comment is somewhat helpful as it identifies a potential issue but does not provide actionable steps for the authors to address it. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the independence of the pruning strategy across different layers in the GNN. It suggests that if an edge is pruned in one layer, it should also be pruned in other layers. The reviewer asks if there are any observations made in the empirical evaluations regarding this issue or if the authors can explain why such correlations are not considered. While the comment implies that the authors should address this question or observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or observation regarding the pruning strategy across layers. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the independence of the pruning strategy across different layers in the GNN, specifically questioning whether an edge pruned in one layer should also be pruned in other layers. It suggests that this might be an observation made in the empirical evaluations or that the authors should explain why such correlations are not considered. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its question about the independence of the pruning strategy, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the independence of the pruning strategy across different layers in the GNN. It suggests that if an edge is pruned in one layer, it should also be pruned in other layers. The reviewer asks if there are any observations made in the empirical evaluations regarding this issue or if the authors can explain why such correlations are not considered. While the comment highlights a potential inconsistency in the pruning strategy, it lacks specific examples or references to support the claim. The authors would need to make a logical deduction to understand the basis of the question. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the question but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the independence of the pruning strategy across different layers in the GNN, suggesting that if an edge is pruned in one layer, it should also be pruned in other layers. It asks if there are any observations made in the empirical evaluations regarding this issue or if the authors can explain why such correlations are not considered. This feedback is somewhat helpful as it prompts the authors to consider a potential inconsistency in their pruning strategy across layers. However, the comment lacks specific guidance or suggestions on how to address this issue or what specific observations might be made. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. It questions whether the conclusions would generalize to other datasets and suggests that some nuances might be necessary. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to ensure generalizability. The action is implicit and somewhat vague, as the authors can infer that they need to consider additional datasets and possibly adjust their conclusions, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental validation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the limitation of considering only CIFAR-10/100 as in-distribution data and questions whether the conclusions would generalize to other datasets. The comment suggests that some nuances might be necessary, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the experimental validation, specifically questioning whether the conclusions would generalize to other datasets. The reviewer acknowledges that the results are strong for CIFAR-10/100 but suggests that nuances might be necessary for other datasets. The comment is somewhat verifiable as it provides a logical basis for the concern, but it lacks specific examples or references to support the claim that the conclusions might not generalize. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. This is a relevant observation that could impact the generalizability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or what additional datasets could be considered. While it raises a valid point, the feedback lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights into the effectiveness of their method. This is an explicit request for additional data or analysis, which is clear and concrete. The authors know exactly what needs to be done to address the comment, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests showing the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights into the effectiveness of the method. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights into the effectiveness of their method. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this additional analysis is necessary or how it would benefit the paper. Without such justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where additional analysis could be beneficial. It suggests showing the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights into the effectiveness of the method. This feedback is clear and actionable, as it directs the authors to include a specific analysis that could enhance the understanding and interpretation of their results. However, the comment could be more helpful if it explained why this analysis is important or how it would contribute to the overall contribution of the paper. Despite this, the feedback is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the explicit SDF supervision in Section 3.2 and its connection to occlusion handling and view-aware reasoning. It suggests that a simpler approach might be to sample a subset of the sparse point cloud and apply the loss without occlusion reasoning. The reviewer also points out the absence of a good reason or ablation study for this setup. While the comment provides a clear suggestion for simplifying the approach, it lacks specific guidance on how to implement this change or what specific aspects of the ablation study should be included. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.2\" and \"L. 165,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the rationale behind the explicit SDF supervision with occlusion handling and view-aware reasoning, suggesting a simpler approach. The comment further provides a specific suggestion for an ablation study to address the complexity of the setup. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind the explicit SDF supervision with occlusion handling and view-aware reasoning, suggesting a simpler approach. The reviewer provides a logical reasoning by proposing a simpler method that does not involve occlusion handling or view-aware reasoning. However, the comment lacks specific examples or references to support the claim that the simpler approach is more straightforward or effective. While the reasoning is clear, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the explicit SDF supervision in Section 3.2, questioning the rationale behind its connection to occlusion handling and view-aware reasoning. It suggests a simpler approach that could be considered, which involves sampling a subset of the sparse point cloud and applying the loss without occlusion reasoning. The comment also points out the absence of a good reason or ablation study for this complicated setup. This feedback is clear and actionable, providing the authors with a concrete suggestion for simplifying their approach and a direction for further exploration. However, it could be more helpful if it included specific examples or references to similar studies that have successfully implemented this approach. Overall, the comment is mostly helpful as it guides the authors toward a more straightforward and simplified approach while highlighting a gap in the explanation and justification for the current setup.', 'helpfulness_label': '4'}"}
