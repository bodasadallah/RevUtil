{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of HIERENC is unclear and suggests that it might introduce noise due to the averaging of multiple contextual representations. However, it does not provide explicit guidance on how to clarify the description or address the issue of noise. The authors are left to infer that they need to clarify the description and possibly reconsider the averaging approach. While the comment identifies a potential problem, it lacks concrete instructions on how to resolve it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, pointing out that the averaging of multiple contextual representations might introduce noise and suggesting that only one instantiation is likely correct. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that averaging multiple contextual representations might introduce noise. The reviewer provides a logical reasoning by explaining that only one instantiation is likely correct and that averaging multiple representations could lead to noise. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and potential consequences to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the averaging of multiple contextual representations might introduce noise. It provides a logical reasoning that only one instantiation is likely correct, which could lead to noise. This feedback is clear and actionable, as it points out a potential weakness in the description and suggests a possible improvement. However, the comment could be more helpful if it provided specific suggestions on how to clarify the description or address the issue of noise. Overall, the comment is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include an ablation study to evaluate the importance of the postprocessing steps proposed to filter out \"falsepositive\" neurons. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct an ablation study but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of integrated gradients to measure attribution and the proposed postprocessing steps to filter out \"falsepositive\" neurons. It also suggests an ablation study, providing clear guidance on what needs to be addressed. However, the comment does not specify which part of the paper should include the ablation study, making it fully grounded but underspecific. Therefore, this comment is categorized as 4, aligning with category 4.", "verifiability_rationale": "The review point claims that using integrated gradients to measure attribution has been studied in existing papers and suggests that an ablation study may be needed to evaluate the importance of the postprocessing steps proposed to filter out \"falsepositive\" neurons. However, the comment lacks specific references to these existing studies or detailed reasoning to support the claim that an ablation study is necessary. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 3, as it provides a logical suggestion but lacks the necessary evidence or detailed reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by suggesting an ablation study to evaluate the importance of the postprocessing steps proposed to filter out \"falsepositive\" neurons. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance their work. However, the comment could be more helpful if it explained why an ablation study is necessary or how it would benefit the paper. Despite this, the suggestion is valuable and provides a clear direction for the authors to improve their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how an antecedent is identified when the prediction is a pronoun, and it suggests a method of matching the head of noun phrases. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the method. The comment lacks concrete instructions or detailed suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about identifying antecedents in the context of a prediction using pronouns. It suggests a method of matching the head of noun phrases, but does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but the comment lacks explicit grounding. It is specific in its question about the handling of pronouns and the proposed method, but without clear grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about identifying antecedents in the context of a prediction using pronouns. It suggests a method of matching the head of noun phrases, but does not provide any supporting evidence, reasoning, or references to justify the claim. The comment lacks detailed explanation or examples, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about identifying antecedents in the context of a prediction using pronouns. It suggests a method of matching the head of noun phrases, which is a relevant point for clarifying the methodology. However, the comment lacks depth and does not provide detailed guidance or suggestions on how the authors might address this issue or improve their explanation. While it points out a potential area for improvement, it does not offer actionable steps or examples to help the authors enhance their draft. Therefore, the comment is 3, as it identifies a specific area for clarification but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment implies that the authors should consider including these baselines, it does not provide explicit instructions or detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should include additional baselines but are not given specific steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, it does not specify which part of the paper this extension or the baselines should be added to, making it weakly grounded. The comment is specific in suggesting the inclusion of character embeddings as a baseline, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension is necessary or how character embeddings would enhance the work. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to implement these additional baselines or why they are necessary. The suggestion is 3 as it points out a potential area for enhancement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that while it is easier to show that something (e.g., attention in seq2seq MTL) is not working, the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide explicit guidance on how to identify the reasons for failure or how to modify the attention mechanism. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate the reasons for failure and make changes to the attention mechanism. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that it is easier to show that something (e.g., attention in seq2seq MTL) is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. The authors can infer that it relates to the discussion of attention mechanisms, but this inference is not direct. The comment is specific in its suggestion to investigate and modify the attention mechanism, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is easier to show that something (e.g., attention in seq2seq MTL) is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment highlights a common issue in research, where it is easier to show that something is not working but more challenging to identify the underlying reasons and make improvements. It suggests that the true value lies in finding out why something fails and changing the attention mechanism to make it work. While the comment identifies a general problem, it does not provide specific guidance or suggestions on how to address this issue in the paper. The authors are left to infer that they need to investigate the reasons for failure and modify the attention mechanism, but without detailed instructions or examples, the feedback is 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve the experiments. The feedback is vague and lacks concrete steps for the authors to take, leaving them without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main weaknesses of the paper, specifically the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the experiments and the potential of the proposed augmentation method, but without clear grounding, the authors may struggle to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are the main weakness of the paper, as they are limited to an extremely lowresource regime and sentence classification, which are not the only cases for data augmentation in realworld applications. The reviewer also suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. The comment provides some reasoning by pointing out the limitations of the experiments and the potential of the proposed method, but it lacks specific examples or references to support the claim. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. The comment highlights the need for the paper to address these limitations and provide more comprehensive evidence of the method\"s applicability. While it points out areas for improvement, the feedback lacks specific suggestions or guidance on how the authors might strengthen their experiments or present their findings more effectively. This limits the comment\"s utility in helping the authors improve their draft. Therefore, the comment is 3, as it provides some direction but could be more actionable with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper\"s claims would benefit from more indepth analysis. However, it does not provide specific examples or details of which claims need more analysis or how to conduct this analysis. The comment lacks explicit guidance on which claims should be further explored or how to approach this analysis. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that a number of claims from the paper would benefit from more indepth analysis, but it does not specify which claims are being referred to or where in the paper they are made. This lack of specificity makes it difficult for the authors to identify the exact parts of the paper that need further analysis. Additionally, the comment does not provide any guidance on what specific aspects of these claims should be analyzed or how to conduct the analysis. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a number of claims from the paper would benefit from more indepth analysis. However, it does not provide any specific examples or reasoning to support why these claims need further exploration. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand which claims need more analysis and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a number of claims from the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or provide any examples of where these claims could be improved with additional analysis. Without specific guidance or actionable suggestions, the authors are left without a clear path for enhancing their draft. The comment lacks depth and specificity, making it 2 for the authors in terms of improving their work. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment raises concerns about the paper\"s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words. It also questions the use of constituent parse as knowledge and points out that the term \"knowledge\" may be misleading in this context. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to clarify the terminology. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the use of \"knowledge\" and the generalization of the model, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific concerns about the paper\"s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words and questioning the use of constituent parse as knowledge. It also points out that the term \"knowledge\" may be misleading in this context, as it is typically used to refer to external knowledge sources like a knowledge base of entities. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the use of \"knowledge\" and the generalization of the model, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words and questioning the use of constituent parse as knowledge. The reviewer also points out that the term \"knowledge\" may be misleading, as it is typically used to refer to external knowledge sources like a knowledge base of entities, whereas here it is used to describe syntax or semantics. The comment provides a logical reasoning and specific examples to support the claim that the term \"knowledge\" is misleading in this context. However, it could be strengthened by providing more detailed references or examples from the literature to further substantiate the critique. Overall, the comment is 4, as it provides a clear rationale and examples to support the claim, but it could be more fully substantiated with additional references or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also points out that the term \"knowledge\" may be misleading, as it is typically used to refer to external knowledge sources like a knowledge base of entities, whereas here it is used to describe syntax or semantics. This feedback is clear and actionable, as it provides the authors with a concrete direction for clarifying their terminology and improving the accuracy of their claims. By addressing these concerns, the authors can enhance the clarity and precision of their work, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the poor performance on nouns and questions the generalizability of the clustering approach to all parts of speech. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable steps or concrete details on how to improve the draft, such as recommending specific analyses or experiments to better understand the gap between the oracle GAP and the clustering approach. As a result, the authors are left without a clear path forward, making this comment 1.", "grounding_specificity_rationale": "The comment addresses the performance on nouns and the contradiction between the claim of generalizability and the performance on specific parts of speech. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the oracle GAP and the contradiction with the claim of generalizability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the performance on nouns and questions the generalizability of the clustering approach to all parts of speech. It references the oracle GAP for PPDBClus and the fact that it is higher than most clustering approaches, which is a logical point of concern. However, the comment does not provide specific examples or references to support the claim that the clustering approach is not generalizable. The lack of detailed evidence or examples makes the claim 3, as the authors would need to further investigate the issue themselves to fully understand and address the concern.", "helpfulness_rationale": "The review comment identifies a concern about the performance on nouns and questions the generalizability of the clustering approach to all parts of speech. It highlights the contradiction between the claim of generalizability and the performance on specific parts of speech, as evidenced by the oracle GAP for PPDBClus being higher than most clustering approaches. This feedback is 3 as it points out a potential weakness in the paper\"s claims, but it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. The comment could be more helpful if it provided actionable steps or examples of how to better understand and address the gap between the oracle GAP and the clustering approach. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the claim of \"no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. This feedback is clear and directs the authors to review the references mentioned, which can help them understand the existing tools in the reinforcement learning setting. The action is explicit and concrete, as the authors know exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the absence of corresponding tools for the reinforcement learning setting, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides references to support the claim, which helps the authors understand the context and the basis of the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"there is no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. However, the comment does not specify which references are being referred to or how they support the claim. This lack of detailed explanation or references makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some evidence but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment challenges a claim made in the paper regarding the absence of corresponding tools for the reinforcement learning setting. It provides references to support the claim, which is a valuable piece of information for the authors. However, the comment could be more helpful if it explained why these references are relevant or how they address the issue raised. While the feedback is 3, it lacks depth and could be more actionable with additional context or explanation. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison with other methods and consider promoting existing methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed method, such as its use of a proposal generator pretrained on MSCOCO and its potential impact on existing class incremental semantic segmentation methods. It also mentions the authors\" adequate addressing of limitations and potential negative societal impact. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its questions about the fairness of comparison and the potential promotion of existing methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about fairness or the potential impact on existing methods. This makes the claim 3, as the authors would need to infer the basis of the critique and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the fairness of comparing the proposed method with other methods and its potential impact on existing class incremental semantic segmentation methods. It also acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. While it identifies areas for consideration, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 4 could benefit from a slower development to improve readability. However, it does not provide specific guidance on how to achieve this or what aspects of the section need more development. The comment lacks concrete details on how to implement this suggestion, such as recommending additional content or a different structure. As a result, the authors are left without clear instructions on how to enhance the readability of the section. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the section is \"very tersely written\" and could benefit from a slower development for easier readability. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Section 4 is \"very tersely written\" and could benefit from a slower development to improve readability. However, the comment does not provide any specific reasoning or examples to support this claim. It lacks detailed justification or references to similar works that might have addressed this issue, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the writing style of Section 4, noting that it is \"very tersely written\" and could benefit from a slower development to improve readability. While it highlights a potential problem, it lacks specific suggestions or guidance on how to achieve this improvement. The comment could be more helpful if it provided examples of how to develop the content more gradually or offered specific recommendations for enhancing the readability. As it stands, the feedback is 3, as it points out an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the lack of comparison with a highly relevant method, specifically mentioning 1 and its proposed approach of utilizing previous knowledge with intertask ensemble. It also highlights the absence of a comparison with the current task\"s performance using intratask ensemble. The comment clearly identifies the missing element of comparison, providing a direct action for the authors to include this analysis in their draft. The explicit nature of the suggestion and the concrete details on what to compare make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, specifically mentioning 1 and its approach of utilizing previous knowledge with intertask ensemble. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the absence of a comparison with the current task\"s performance using intratask ensemble. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning 1 and its approach of utilizing previous knowledge with intertask ensemble. The reviewer also notes the absence of a comparison with the current task\"s performance using intratask ensemble. However, the comment does not provide specific details or references to support the claim that this comparison is necessary or how it would enhance the paper. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of the comparison themselves.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of comparison with a highly relevant method, 1, which proposes utilizing previous knowledge with intertask ensemble. The comment also highlights the absence of a comparison with the current task\"s performance using intratask ensemble. This feedback is clear and actionable, as it directs the authors to include these comparisons in their analysis. By addressing this gap, the authors can enhance the comprehensiveness and rigor of their evaluation. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue with the baseline models or how to improve the pipeline style method. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the pipeline style method, which includes two models, and notes that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses the pipeline style method or the baseline models, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific about the issue of average results and the need for better introduction of baseline models, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered 2, as it provides some indication but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the pipeline style method, which includes two models, not yielding better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. While the comment highlights a potential problem, it lacks specific suggestions or guidance on how the authors might address this issue or improve the pipeline style method. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is 3, as it points out a weakness but does not provide enough detail for the authors to effectively improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve their methodology. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their methodology but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. However, it does not specify which part of the paper this observation is made in, making it weakly grounded. The comment is specific in detailing the issue with the authors\" methodology, questioning why this observation needs to be made using the \"coarse\" methodology. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have reproduced a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion that this observation is unnecessary. The authors may need to further substantiate the claim by providing evidence or references to similar works that have already addressed this issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. This feedback highlights a potential redundancy in the authors\" approach and suggests that they might need to reconsider their methodology or provide a more novel contribution. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their work. While it identifies a potential weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It explicitly asks for more explanations on how to obtain a small degree of bias from a clear community structure. This feedback provides a clear and direct action for the authors to take, which is to provide additional explanations or examples to clarify this relationship. The comment is specific and actionable, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by the theorems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2 is not intuitive enough. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks the necessary evidence or explanation to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It points out that while the theorems prove conformity to a clearer community structure, the relationship with degree bias is not intuitive. This feedback is valuable as it highlights a potential gap in the paper\"s explanation, which the authors can address to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify this relationship or examples of how it might be explained. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, it does not provide explicit guidance on what additional information is needed or how to clarify this notation. The comment implies that the authors should provide more information, but it lacks concrete steps or suggestions on how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it is confusing. However, it does not specify which part of the paper this notation is used in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does provide some specificity by indicating that more information is required, such as what S and Xt represent. However, without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, the comment does not provide any specific reasoning or examples to support this claim, nor does it offer suggestions for how the authors might clarify the notation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the notation used to separate \"static\" and temporal features into two variables. It points out that this notation is confusing and requires more information than what is provided in the paper. While the comment highlights an important issue, it lacks specific guidance or suggestions on how the authors might clarify this notation or provide additional information. The feedback is 3 as it directs the authors to a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment questions the claim made in section 2 that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, the comment does not provide specific guidance on what aspect of the claim is questionable or how it could be improved. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim made in section 2 that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. The reviewer points out that a model that can only handle a single time series data is almost useless. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this concern or what aspects of the claim are misleading. As a result, the comment is not helpful, as it does not provide the authors with a clear path forward to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. The reviewer suggests that this condition is not realistic and may lead to unreasonably large learning rates when learning on largescale datasets. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on whether the authors should modify the condition, provide a rationale for its use, or explore alternative approaches. As a result, the comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. It provides a clear rationale for why this condition is not realistic and may lead to unreasonably large learning rates when learning on largescale datasets. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the condition and its implications, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the condition on the learning rate is not scalable, as it does not grow with the number of samples in practice. The reviewer provides a logical reasoning by explaining that this condition leads to unreasonably large learning rates when learning on largescale datasets. However, the comment lacks specific examples or references to support the claim that this condition is not realistic. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. This is a critical observation, as it highlights a potential flaw in the methodology that could lead to unreasonably large learning rates when learning on largescale datasets. The comment provides a clear and actionable suggestion for improvement by pointing out the need for a more realistic condition. However, it could be more helpful if it offered suggestions on how the authors might address this issue or provided examples of alternative conditions that could be considered. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use a more convincing setting for training, similar to what was done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification. It provides a specific reference to the paper by He et al. (EMNLP 2018) as an example of a convincing setting. This feedback is explicit and provides a clear action for the authors to take, which is to adopt a more convincing training approach. The suggestion is concrete and provides a specific method to implement the change, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)\" and suggests that the data is perfectly balanced, which is impractical in realworld applications. It also references a specific paper, \"Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018,\" which suggests using a more convincing setting for training. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the perfectly balanced unlabeled data from the preprocessed Amazon review dataset is impractical in realworld applications. It suggests that the authors should use a more convincing setting, like the one described in the reference to Adaptive Semisupervised Learning for Crossdomain Sentiment Classification. The comment provides a specific reference to the paper by He et al. (EMNLP 2018) to support the claim. This reference provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the perfectly balanced unlabeled data from the preprocessed Amazon review dataset, noting that this is impractical in realworld applications. It suggests that the authors should use a more convincing setting, like the one described in the reference to Adaptive Semisupervised Learning for Crossdomain Sentiment Classification. This feedback is clear and actionable, providing the authors with a specific approach to address the issue of unbalanced data. By suggesting a reference to a relevant paper, the comment offers a concrete direction for improvement. However, it could be more helpful if it explained why the current setting is impractical or how the suggested approach might improve the results. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity regarding how to sample from the DPP if the eigenfunctions e_n are inaccessible, referencing a specific line in the paper (line 130). It also mentions a similar issue with sampling from the leverage score in a previous work. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the clarity of their explanation. The action is implicit and vague, as the authors are left to infer that they need to clarify their sampling process, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 130\" and \"Eq (10),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the problem of sampling from the DPP if the eigenfunctions e_n are inaccessible, and it references a similar issue in a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of sampling from the DPP if the eigenfunctions e_n are inaccessible, referencing a specific line in the paper (line 130). It also mentions a similar issue in a previous work, suggesting that sampling from the DPP might be more difficult than sampling from the leverage score. However, the comment lacks specific examples or detailed reasoning to support the claim that sampling from the DPP is more challenging. While it points out a potential problem, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the paper regarding the sampling process from the DPP when the eigenfunctions e_n are inaccessible. It references a specific line in the paper (line 130) and compares it to a similar issue in a previous work, suggesting that sampling from the DPP might be more difficult than sampling from the leverage score. This feedback is clear and actionable, as it points out a potential weakness in the paper that the authors can address to improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the sampling process or offered examples of how similar issues have been addressed in other works. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the absence of experiments on specific settings. It highlights the need for experiments on surveillance in museums with thresholded rewards and privacypreserving data collection. While the comment identifies a specific issue with the experimental section, it does not provide explicit guidance on how to address this concern. The authors are left to infer that they should include experiments on these settings, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the specific settings used in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the absence of experiments on certain settings and the lack of simulated experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the validity of the experimental results, specifically the absence of experiments on certain settings. It references the examples of surveillance in museums with thresholded rewards and privacypreserving data collection as motivating cases for the paper. However, the comment lacks specific evidence or detailed reasoning to support why these examples are insufficient or why the experiments are not useful. The claim is 3 as it highlights a potential issue but does not provide sufficient justification or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, questioning the relevance and usefulness of the examples used to motivate the paper\"s solution. It points out the absence of experiments on specific settings, such as surveillance in museums with thresholded rewards and privacypreserving data collection, which are relevant to the paper\"s topic. This feedback highlights a critical gap in the experimental section, suggesting that the authors should include experiments on these settings to enhance the paper\"s credibility and usefulness. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific experiments could be conducted. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also notes that this limitation prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take to study the effect of noise accumulation. The action is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"sequential ensembling\" and \"homomorphic encryption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of noise accumulation in the context of homomorphic encryption, which prevents the use of even single deep neural networks on homomorphically encrypted data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that noise accumulation in the context of homomorphic encryption is a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper regarding the use of deep neural networks on homomorphically encrypted data due to noise accumulation. It highlights the importance of studying this effect in the context of homomorphic encryption. While the comment points out a potential issue, it lacks specific suggestions or guidance on how the authors might address this limitation or what specific experiments could be conducted to study the effect of noise accumulation. The feedback is 3 as it directs the authors\" attention to a relevant area for further exploration, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case, the authors should use a standard regularization trick. While the comment implies that the authors should apply this standard technique, it does not provide explicit instructions on how to implement it or which specific regularization trick to use. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison is discussed. The authors can infer that it relates to the results or analysis section, but this inference is not direct. The comment is specific in suggesting the use of a standard regularization trick, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this standard technique is necessary or how it would improve the comparison. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance on which standard regularization trick to use or how it would impact the comparison. The feedback is 3 as it points out a potential issue but does not offer detailed instructions or examples to help the authors address it effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the need to discuss how to handle different types of inputs and the disorganization of the citation. While the first point suggests that the authors should discuss their solutions for handling different input types, it does not provide specific guidance on how to structure this discussion or what aspects to cover. The second point mentions that the citation seems disorganized but does not offer suggestions for improvement. Both points are implicit, as the authors need to infer what actions to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss \"different types of inputs\" and the disorganization of the citation, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to discuss how to handle different input types and the disorganization of the citation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims: the need to discuss different types of inputs and the disorganization of the citation. The first claim is 3 as it suggests that the paper should include a discussion on handling different input types, but it lacks specific guidance on how to structure this discussion or what aspects to cover. The second claim about the citation being disorganized is 3 as it points out a potential issue but does not provide specific examples or suggestions for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two areas for improvement: discussing different types of inputs and addressing the disorganization of the citation. While it highlights these issues, it does not provide specific guidance or suggestions on how to address them. The comment lacks depth and actionable advice, leaving the authors with a general understanding of the problem but without clear steps to improve their draft. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant issue with the ICLHAR, noting that it improves consistency and verifiability but significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. The reviewer suggests that this issue should be discussed or acknowledged in the main text in more detail. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is concrete, as it points out the need to discuss or acknowledge the impact on accuracy scores, but it is somewhat vague in terms of how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ICLHAR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ICLHAR, noting that it improves consistency and verifiability but significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the ICLHAR improves consistency and verifiability but significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This claim is 3 as it provides a specific numerical example (70.4 to 55.6) to support the assertion of a significant impact on accuracy scores. However, the comment lacks detailed reasoning or explanation of why this impact occurs or how it could be addressed. Additionally, it does not provide references to external works or studies that might substantiate the claim further. Therefore, the comment is rated as 3, as it provides some support but lacks depth and detailed justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the ICLHAR, noting that while it improves consistency and verifiability, it significantly impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This is a critical observation that the authors should address, as it affects the overall quality and reliability of their results. The comment suggests that this issue should be discussed or acknowledged in the main text in more detail, providing a clear direction for the authors to improve their draft. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what aspects of the ICLHAR might be contributing to the accuracy drop. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to address it."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any explicit guidance or suggestions on how to address these issues. The authors are left to infer that they need to improve their writing quality, but without concrete steps or examples, they may struggle to know where to focus their efforts. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment identifies specific issues with the writing quality of the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity in detailing what exactly is unclear or needs improvement in the writing. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address them effectively. Without specific examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies significant writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. While it highlights these problems, it does not provide specific examples or suggestions on how to address them. The comment lacks actionable guidance or detailed feedback that would help the authors improve their draft. Without specific examples or constructive advice, the authors are left with a general understanding of the problems but no clear path to improvement. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the statement regarding the biological plausibility of backpropagation in the introduction may be too weak and points out that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to strengthen the statement. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the statement and provide more robust evidence or reasoning to support it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the introduction regarding the biological plausibility of backpropagation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the weakness of the statement and the widely accepted view that backpropagation is biologically implausible. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation in the introduction is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the introduction regarding the biological plausibility of backpropagation. It points out that the statement may be too weak and that the widely accepted view is that backpropagation is biologically implausible. This feedback is 3 as it highlights an area where the authors may need to provide more robust evidence or reasoning to support their claims. However, the comment could be more helpful if it suggested specific ways to strengthen the statement or provided examples of alternative perspectives or evidence that could be considered. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. However, it does not provide specific guidance on how the authors should address this issue or what additional exploration is needed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the generalizability of their results. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s exploration of the implications of the proposed method for other NLP tasks, suggesting that the paper\"s generalizability is somewhat limited due to this lack of exploration. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of limited generalizability, but without explicit references to sections or specific elements, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which somewhat limits its generalizability. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides a logical argument but lacks the necessary support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. This observation highlights a potential weakness in the generalizability of the results, which is an important consideration for broader impact and applicability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional exploration could be conducted. While it points out a relevant area for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the use of the terminology \"certificate\" in the paper, as it has a strong meaning in complexity theory. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to avoid misinterpretation. The action is implicit and vague, as the authors are left to infer that they need to reconsider the use of this terminology and possibly provide clarification. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the terminology \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of the terminology \"certificate\" in some contexts could be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of terminology in the paper, specifically the term \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. This is a valuable observation that could help the authors avoid confusion or misunderstanding in their work. However, the comment lacks specific guidance on how to address this issue, such as suggesting alternative terminology or providing examples of where the term might be misinterpreted. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiments are limited to toy data and recommends expanding the scope to include real data. It explicitly states that there is a range of problems with real data where barycenters can be used and suggests that the method should be tested in those settings. This provides a clear and concrete action for the authors to take, as it specifies the need to include real data experiments and the potential benefits of doing so. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests expanding the scope of the experiments to include real data, which implies that the current experiments are limited to toy data. However, it does not specify which part of the paper discusses the experiments or where the limitation is mentioned, making it weakly grounded. The comment is specific in suggesting that real data experiments could be beneficial and highlighting the potential use of barycenters in realworld scenarios. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to toy data and recommends expanding the scope to include real data. However, the comment does not provide specific examples or references to realworld scenarios where barycenters can be used, nor does it explain why this would be beneficial or how it would impact the results. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the benefits of including real data experiments themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are currently limited to toy data. It suggests expanding the scope to include real data, which could provide a more comprehensive understanding of the method\"s performance in realworld scenarios. This feedback is clear and actionable, as it directs the authors to consider testing their method on real data. However, the comment could be more helpful if it provided specific examples or guidance on how to implement this expansion or what aspects of realworld data to focus on. Overall, the comment is 4 as it points out a potential area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. The reviewer implies that this makes the motivation for Algorithm 1 unclear. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address this issue. It lacks actionable details, such as suggesting how to clarify the motivation or how to incorporate this insight into the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem can be reformulated using the conjugate function, making the motivation unclear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is 3 as it provides a logical reasoning based on the conjugate function, which is a common mathematical concept. However, the comment lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation could lead to a clearer understanding of the problem and its solution. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the motivation for Algorithm 1. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS, particularly when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take based on this observation. There is no guidance on how to incorporate this understanding into the paper or what specific aspects of the paper should be revised to reflect this perspective. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the paper should be revised or how the authors should address this suggestion. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that KD can be considered a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. It provides a specific scenario where this equivalence occurs, which could be valuable for the authors to consider when discussing their results or methodology. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might incorporate this perspective into their work. While it provides some insight, it could be more helpful with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the captions should be more descriptive and provides a specific example of the issue of having to search through the text for interpretations of figures, which are usually on a different page. It also requests an explanation of the scramble network. While the comment provides a clear action to make the captions more descriptive and an explicit request for an explanation of the scramble network, it does not offer detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specifics of how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests making the captions more descriptive and provides an example of the issue of having to search through the text for interpretations of figures, which are usually on a different page. It also requests an explanation of the scramble network. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the figures or captions in the paper. The comment is specific in its request for more descriptive captions and an explanation of the scramble network, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions are not descriptive and that it is annoying to have to search through the text for interpretations of figures, which are usually on a different page. It also requests an explanation of the scramble network. While the comment identifies a specific issue with the captions, it lacks detailed reasoning or examples to support why this is a problem or how it could be improved. The suggestion to make the captions more descriptive is logical, but the lack of specific guidance or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the captions should be more descriptive, which would improve the clarity and accessibility of the figures in the paper. It also highlights the issue of having to search through the text for interpretations of figures, which are usually on a different page. This feedback is valuable as it directly addresses a common challenge in scientific writing and offers a clear solution to improve the draft. Additionally, the comment requests an explanation of the scramble network, which could further enhance the clarity and understanding of the paper. Overall, the comment is 5 as it provides clear and actionable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the choice of using randomly sampled CIFAR images as backgrounds for the task, suggesting that the motivation for this choice is not wellexplained. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the motivation should be clarified. The comment lacks concrete suggestions or examples of how the authors might improve the explanation or justification for their choice. As a result, the authors are left without clear direction on how to address the issue, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the use of randomly sampled CIFAR images as backgrounds for the task, suggesting that the motivation for this choice is not wellexplained. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the motivation behind the choice and asking for clarification, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds for the task, suggesting that this choice is not wellmotivated. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds for the task, suggesting that this choice is not wellmotivated. It highlights a potential weakness in the paper\"s explanation of the task difficulty, which could be a significant area for improvement. However, the comment does not provide specific suggestions or examples of how the authors might address this issue or what alternative motivations could be considered. While it identifies a potential area for improvement, the feedback lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide explicit instructions or concrete steps for the authors to take. It lacks actionable details, such as recommending specific modifications or experiments to address this concern. As a result, the authors are left without a clear path forward, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, such as specific experiments or sections where the results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the role of periodicity in the results, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides a logical basis for the question but lacks sufficient evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve their results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending experiments or modifications to the model. While it provides a thoughtprovoking insight, it could be more helpful with additional actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern regarding the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the claim is to establish the paper as a foundation model, it should be clearer and include a future useful application. While the comment implies that the authors should provide a clearer justification for their method, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison and justification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the goal of the paper and the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. It also suggests that if the claim is to establish the paper as a foundation model, it should be clearer and include a future useful application. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the claim is to establish the paper as a foundation model, it should be clearer and include a future useful application. This claim is 3 as it logically points out the need for comparison and justification, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. It suggests that if the paper claims to establish a foundation model, it should be clearer and include a future useful application. This feedback is 3 as it points out a critical area for improvement, but it could be more beneficial if it provided specific suggestions on how to address these issues or what aspects of the comparison or justification should be emphasized. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It asks whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. While the comment implies that the authors should consider this limitation and potentially explore alternatives, it does not provide explicit instructions or concrete suggestions on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider extending their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its inquiry about whether the limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual observation seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a valid concern about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It questions whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. This feedback prompts the authors to consider whether their approach is limited by the specific windowing method or if it can be extended to accommodate different windowing methods. While the comment identifies a potential weakness, it does not provide specific suggestions or guidance on how to address this limitation or explore alternative approaches. Therefore, the comment is 3, as it points out an area for improvement but lacks actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper and suggests that related work might be relevant but not necessarily detrimental to the novelty of the paper. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions to take. The comment lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"sequence of episodes\" and suggesting that related work might be relevant but not detrimental to the novelty of the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions and observations about the definition of \"sequence of episodes\" and the relevance of related work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper, which is a relevant point for clarity. It also suggests that related work might be relevant but not detrimental to the novelty of the paper. While the comment identifies a potential area for improvement by suggesting the inclusion of related work, it lacks specific guidance or suggestions on how to address this issue or incorporate related work into the paper. The feedback is 3 as it points out a potential gap in the paper, but it could be more actionable and detailed to be fully helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should make this distinction, it does not provide explicit instructions on how to do so or what specific aspects of the paper need to be revised. The action is implicit and somewhat vague, as the authors need to infer that they need to make a distinction but are not given specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide detailed guidance on how to make this distinction. The authors can infer that it relates to the discussion or analysis of the results, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would benefit the paper. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in making the suggested distinction. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While this feedback identifies a potential area for clarification and differentiation, it lacks specific guidance on how to achieve this distinction or what aspects of the paper need to be revised. The comment highlights a potential issue but does not provide actionable steps for the authors to address it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should make the proof of Theorem 8 clearer, but it lacks specific instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to improve the clarity of the proof, but without concrete steps on how to achieve this. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the linear convergence rates relying on Theorem 8, which is buried in the appendix and whose proof is unclear. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that all linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that all linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. This is a clear and actionable point that the authors can address to improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the proof or how to better integrate Theorem 8 into the main text. Despite this, the feedback is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the inaccuracy of a statement about the Walkman algorithm and the lack of clarity in the reference to \"it\" in Section 3. The comment explicitly instructs the authors to correct the inaccuracy regarding the Walkman algorithm, specifying that it is solved by ADMM with two versions. It also points out the lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors clarify the intended reference. These actions are explicit and provide concrete guidance on what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about the Walkman algorithm, noting that it is solved by ADMM with two versions, and that it is inaccurate to say that these works are all based on simple SGD for decentralized optimization. Additionally, it points out the lack of clarity in the reference to \"it\" in Section 3. This provides clear guidance on what needs to be addressed in these parts of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that \"these works are all based on the simple SGD for decentralized optimization.\" It provides a specific correction by noting that the Walkman algorithm is solved by ADMM with two versions, which contradicts the statement. This is a logical and factual observation that requires no additional evidence or references to support the claim. Therefore, the comment is 5, as it provides a clear and accurate correction to the authors.", "helpfulness_rationale": "The review comment is 4 as it identifies specific inaccuracies in the paper regarding the Walkman algorithm and its solution by ADMM. It provides clear and actionable feedback by instructing the authors to correct the statement about the Walkman algorithm, noting that it is not accurate to say that these works are all based on simple SGD for decentralized optimization. Additionally, it points out the lack of clarity in the reference to \"it\" in Section 3, which could be improved to enhance the paper\"s clarity. However, the comment could be more helpful if it offered suggestions on how to clarify the reference or provided additional context on the significance of the Walkman algorithm. Overall, the feedback is valuable but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This feedback implies that the authors should expand their analysis to include more comparisons and consider additional NAS approaches. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on which NAS approaches to include or how to conduct the analysis. While the action is implied, it is not as concrete as it could be, leaving the authors with a general idea of what needs to be done but without detailed instructions on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis on BRPNAS, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the analysis is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This provides clear guidance on what needs to be addressed in the analysis section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. However, the comment does not provide specific examples or references to these other NAS approaches, nor does it explain why these comparisons are necessary or how they would enhance the analysis. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the analysis section of the paper, specifically noting that the BRPNAS analysis only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This feedback highlights an area where the paper could be expanded to provide a more comprehensive analysis. However, the comment does not offer specific suggestions on how to address this issue or which NAS approaches to consider, leaving the authors with a general understanding of the need for improvement but without detailed guidance on how to achieve it. Therefore, the comment is 3, as it points out a potential weakness but lacks actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment results could be enriched by adding attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that these additions would improve the results, it does not provide specific guidance on how to implement these changes or what specific types of attacks or threshold analyses should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to enhance their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or figures where these additions could be made. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting what could be added to enhance the results, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that these additions would improve the results. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered 2, as it provides a general direction but lacks sufficient justification or examples.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the experiment results by suggesting the addition of attacks with different strengths and an exploration of how different thresholds influence detection performance. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experimental analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or what specific types of attacks or threshold analyses should be considered. Despite this, the feedback is 4 as it directs the authors toward improving their experimental design and results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or suggestions on how to address this question. The action is implicit and somewhat vague, as the authors need to infer that they should consider the applicability of their method to natural images. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, it does not specify which part of the paper this question pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its question about the applicability of the method to natural images, but without explicit grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, the comment lacks any supporting evidence, reasoning, or references to justify why the method might not be applicable to natural images. Without such information, the claim remains 1, as it does not provide a clear basis for the authors to address the concern. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. This is an important consideration for the authors, as natural images have wider applications in the real world. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or expand their method to natural images. While it identifies a potential limitation, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the organization or presentation of the prompts, nor are there suggestions for alternative approaches. As a result, the authors are left without any clear direction on how to improve their draft in this area. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 6, 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the prompts being poorly organized, with all sentences squeezed together. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of the prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is 3 as it points out a clear area for improvement in the presentation of the prompts. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the organization. While it highlights a potential problem, it does not offer actionable guidance or detailed advice for the authors to enhance their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to improve the clarity of the figures and label the modules, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"CMAF, L_BT, VoLTA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the clarity of the figures, particularly the confusion regarding the relation between subfigures and the lack of labeling for certain modules. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning Figure 2 and the confusion regarding the relation between subfigures. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the need for clarity and labeling, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. This feedback is clear and actionable, as it directs the authors to improve the clarity and labeling of the figures to enhance the reader\"s understanding. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered examples of how similar issues have been addressed in other works. Overall, the comment is 4 as it effectively highlights areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to control domain drift. The comment lacks actionable details, such as recommending specific methods or experiments to explore, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the use of perplexity and the need to control domain drift, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, the comment does not provide specific examples or references to support the claim that perplexity is an inappropriate measure or that domain drift is a significant issue. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. This is an important point that could impact the validity and reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or control domain drift. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and points out that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to improve their dataset. The action is implicit and somewhat vague, as the authors can infer that they need to consider the size and diversity of their dataset, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient and compares them to the typical training data for LLMs, which is typically on trillions of tokens. The comment suggests that the dataset needs to be massive to cover varied domains. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. The authors can infer that it relates to the dataset used for training, but this inference is not direct. The comment is specific in its critique of the dataset size and the need for diversity, but it lacks grounding as it does not explicitly mention which part of the paper it addresses. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, comparing them to the typical training data for LLMs, which is typically on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. While the comment provides a logical reasoning for the need for a larger dataset, it lacks specific examples or references to support the claim that 44k dialogues are insufficient. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of the training data for capturing a wide range of user traits and personalities across different content topics. It questions whether 44k dialogues are sufficient, given that LLMs are typically trained on trillions of tokens. The comment highlights the need for a massive dataset to cover varied domains, which is a crucial consideration for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might improve their dataset or what additional data sources might be considered. While it identifies a potential weakness, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the work only uses binary features and questions whether the method is applicable to real and categorical features. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to consider real and categorical features. The comment lacks concrete details on how to incorporate these features or what specific modifications are needed. As a result, the authors are left without clear direction on how to improve their draft in this area. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of binary features in the work and questions whether the method is applicable to real and categorical features. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the limitation of binary features and suggesting that the method may not be applicable to real and categorical features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work only uses binary features, which is a factual observation. However, it questions whether the method is applicable to real and categorical features, suggesting that this limitation needs to be addressed. The comment does not provide specific examples or references to support this claim, making it 3. The authors may need to infer the importance of considering real and categorical features, but the lack of detailed evidence or reasoning makes the claim 3.", "helpfulness_rationale": "The review comment identifies a limitation in the work, noting that it only uses binary features while realworld data typically includes a mix of binary, real, and categorical features. This is a relevant observation that could impact the applicability and generalizability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate real and categorical features into their analysis. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or details about what is unclear or how the writing could be improved. The comment lacks explicit guidance on how to address the issues, leaving the authors without a clear understanding of what changes to make. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide examples of what needs to be clarified. Without specific references to sections, figures, or other elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing need improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not provide specific examples or detailed reasoning to support why the writing is unclear or how it could be improved. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing should be improved, indicating that some points in the paper are unclear. However, it does not provide specific examples or detailed feedback on what aspects of the writing are unclear or how they could be clarified. Without this level of detail, the authors are left without actionable guidance on how to enhance their draft. The comment lacks depth and specificity, making it 2 as it points out an area for improvement but does not offer concrete steps for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should use other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback provides a clear and explicit action for the authors to take, which is to consider using additional metrics for evaluating their results. The suggestion is concrete, as it specifies a specific metric to use, making it easy for the authors to understand and implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation of results, but the lack of explicit reference makes it weakly grounded. The comment is specific in suggesting the use of BERTScore as an alternative metric, providing some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, the comment does not provide any reasoning or evidence to support why BERTScore is a better choice or why the current metrics are insufficient. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the suggestion.", "helpfulness_rationale": "The review comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback is 3 as it identifies a potential area for improvement by suggesting the use of a different metric for evaluating the results. However, the comment lacks depth and does not provide detailed guidance on why BERTScore might be a better choice or how it could be integrated into the evaluation process. Additionally, it does not address other aspects of the paper, such as methodology or theoretical contributions. While the suggestion is a step in the right direction, it could be more helpful with additional context and explanation. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of discussion on the scalability bounds of FedDES, specifically mentioning the need for a clear discussion on memory requirements and computational complexity. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should include a discussion on scalability bounds, but the comment lacks concrete suggestions on what specific aspects to cover or how to present this information. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"upper limits of FedDES\"s scalability\" and \"memory requirements or computational complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the scalability bounds, memory requirements, and computational complexity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a thorough exploration of the upper limits of FedDES\"s scalability and does not provide a clear discussion on memory requirements or computational complexity. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of a thorough exploration of the scalability bounds of FedDES. It points out that there is no clear discussion on memory requirements or computational complexity, which are crucial aspects of the system\"s performance. This feedback is valuable as it highlights an area where the authors can enhance their draft by providing a more comprehensive analysis of the system\"s scalability. However, the comment could be more helpful if it offered specific suggestions on how to address these gaps or provided examples of how similar studies have approached this issue. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that needs further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It seeks clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment implies that the authors should provide more information or clarification on this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement \"NodeSort differentially sorts nodes depending on the base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the implications of this statement, including whether the base node affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the implications of a statement regarding \"NodeSort differentially sorting nodes depending on the base node.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node,\" seeking clarification on whether the base node affects the ordering, key nodes for attention, and model performance. This is a relevant question that could help the authors better understand the potential impact of their method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential area for clarification, it lacks actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. This question implies that the authors should clarify or correct the arrow direction to better align with the intended purpose of the figure. However, the comment does not explicitly instruct the authors to make this change, leaving it somewhat vague. While the action is implied, the authors can infer that they need to address this issue, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the direction of the arrow in the figure, which is a clear indication of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. The reviewer expresses confusion about the purpose of the figure, which is to influence n^(i). However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim or clarify the authors\" intentions. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the direction of the arrow in Figure 2, specifically questioning why it goes from a Gaussian space into the latent space rather than the other way around. This feedback highlights a potential inconsistency in the figure and prompts the authors to clarify or correct the direction of the arrow to better align with the intended purpose of the figure. While the comment identifies a specific issue, it lacks depth and does not provide detailed guidance on how to address this inconsistency or improve the figure. Therefore, the comment is 3, as it points out a potential problem but does not fully support the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that many abbreviations lack definitions and cause confusion, specifically mentioning \"AR\" in Table 5 as an example. It provides a clear and specific action for the authors to take, which is to define these abbreviations in the text or provide a glossary. This guidance is direct and concrete, leaving no ambiguity about what needs to be done to improve the clarity of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abbreviation \"AR\" in Table 5, noting that it stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definitions and cause confusion. It provides a specific example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This claim is 3 as it points out a specific issue with the clarity of the paper, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to infer the extent of the issue and the impact on the clarity of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that many abbreviations lack definitions and cause confusion. It provides a clear example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is actionable as it directs the authors to clarify these abbreviations to improve the clarity and accessibility of their work. However, the comment could be more helpful if it suggested ways to standardize the use of abbreviations throughout the paper or provided examples of how to define them. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific technical considerations should be explored or how to address them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what technical considerations are being questioned or how they might impact the analysis. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not present any claims, opinions, or suggestions that require verification. It is a request for clarification, which is not a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, which is a relevant point for the authors to address. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might explore or justify their choice of using advantage over q value. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the setting of Unsupervised Online Adaptation is strange, as it requires a training set, including documents, queries, and labels. The reviewer suggests that this is not \"Unsupervised\" because the training set also requires annotations. While the comment identifies a potential issue with the labeling process, it does not provide explicit guidance on how to address this issue or suggest specific changes to improve the clarity or accuracy of the description. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the nature of the training set and its annotation requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The comment provides clear guidance on what needs to be addressed, namely the clarification of the training set and its annotation requirements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The reviewer supports this claim by referencing Section 3.1, where the model\"s training requirements are described. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as explaining why the training set\"s requirements make it less unsupervised. While the reference to Section 3.1 provides some context, the comment could be strengthened with additional explanation or examples to fully justify the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed support to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, noting that the model requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The reviewer references Section 3.1 to support their claim, providing a clear basis for the critique. However, the comment could be more helpful by offering suggestions on how to clarify or address this issue, such as explaining why the training set\"s requirements might impact the unsupervised nature or proposing alternative approaches to maintain the unsupervised aspect. While it points out a relevant concern, the comment lacks actionable guidance, making it 3 but not comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an issue with the performance comparison in Table 1, specifically noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This implies that the comparison is unfair and suggests that the authors should address this issue to ensure fairness in their evaluation. However, the comment does not provide explicit guidance on how to rectify this issue or what specific changes should be made to the evaluation process. While the action is implied, it is not detailed enough for the authors to know exactly how to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance comparison, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights while most baselines use a uniform weight of 1. This claim is 3 as it provides a logical reasoning for the unfairness, but it lacks specific examples or references to support the assertion that this difference significantly impacts the comparison. The authors would need to make a concerted effort to understand and address the issue, which requires more detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This is a relevant observation that could impact the fairness and validity of the comparison. However, the comment does not provide suggestions or guidance on how the authors might address this issue, such as recommending a standardized weighting scheme or explaining the potential impact of this difference. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. However, it does not provide any guidance on how to address this issue or suggest improvements to the presentation. The comment lacks explicit instructions or concrete details on how to improve the presentation, leaving the authors uncertain about what changes to make. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" and the \"first 1000 episodes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes and questioning the reason for presenting them in this way. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted way, specifically mentioning the disregard of safety violations in the first 1000 episodes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this presentation is problematic or how it affects the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. It highlights the unclear reason for presenting the results in this way, which is a critical observation that could impact the interpretation and understanding of the results. However, the comment lacks depth and does not provide suggestions or guidance on how to address this issue or improve the presentation. While it points out a potential problem, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance on how to improve the allocation or what aspects of the figure are considered naive. The comment lacks concrete details or suggestions on how to address the issue, leaving the authors uncertain about how to apply the feedback. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment mentions \"Figure 1,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not detail what is considered naive about the allocation of Figure 1 or how it could be improved. Without specific guidance or examples, the authors may struggle to understand and address the issue effectively. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is \"too naive\" and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support why the allocation is considered naive or how it could be improved. Without specific examples or references, the claim is difficult for the authors to understand and address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance or suggestions on how to improve the allocation or what aspects of the figure are considered naive. Without detailed feedback or actionable advice, the authors are left without a clear path to address the issue. Therefore, the comment is 1, as it lacks the necessary depth and specificity to be useful for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the planbased method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or improve their method. The action is implicit and somewhat vague, as the authors can infer that they need to consider the generalizability of their method to new datasets without the ground truth summary. However, the comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment addresses the planbased method, specifically mentioning the requirement for manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also compares the learned plan methods to those with predefined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the planbased method is discussed. The comment is specific in detailing the issue with the planbased method and its limitations, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the planbased method is unrealistic in realworld scenarios due to the requirement for manually designing a plan based on the ground truth in advance. It also compares the learned plan methods to those with predefined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment provides some reasoning and logical reasoning, it lacks specific examples or references to support the claim that the planbased method is unrealistic. The comparison to predefined plans is somewhat vague, and the authors may need to infer the specifics of the comparison. Therefore, the comment is 3, as it provides some support but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential weakness in the planbased method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also highlights a limitation in the learned plan methods compared to those with predefined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. This feedback is 3 as it points out a critical issue with the methodology that the authors should consider addressing. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or improve the generalizability of the method. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a lack of convincing evidence in the paper\"s conclusions, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer suggests that the results might be due to limited exploration of combination methods and points to recent works that have shown the potential of feature replay methods in continual learning. While the comment provides a specific area for improvement by suggesting the exploration of combination methods, it does not offer concrete guidance on how to implement this suggestion or what specific combination methods should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific conclusion about continuous learning with unlabeled data and the claim that it accumulates noise, which is detrimental to representation quality. It also references specific works, such as R1, R2, and R3, to support the claim that feature replay methods have shown great potential in continual learning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some conclusions in the paper are not convincing, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer supports this claim by referencing recent works that have shown the potential of feature replay methods in continual learning, such as R1, R2, and R3. These references provide a logical basis for the claim, as they demonstrate the effectiveness of feature replay methods in continual learning scenarios. However, the comment could be strengthened by providing more detailed analysis or specific examples from these works to further substantiate the claim. Overall, the claim is 4, as it is supported by relevant references, but it could be more fully substantiated with additional details.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s conclusions, noting that some are not convincing. It provides a detailed example by referencing recent works that have shown the potential of feature replay methods in continual learning, such as R1, R2, and R3. This feedback is clear and actionable, as it suggests that the authors should explore the use of combination methods, which could strengthen their conclusions. By pointing to relevant literature, the comment offers a concrete direction for improvement, making it 5 for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. While the comment implies that the authors should address these questions, it does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to investigate the accuracy of the ground truth and the noticeability/measurability of the difference, but the comment lacks specific guidance on how to conduct this investigation or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. However, it does not specify which part of the paper these questions pertain to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its inquiry about the accuracy and noticeability of the differences, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the accuracy and reliability of the results presented in the paper. It questions whether the small differences observed are actually noticeable or due to noise or randomness in the training process. Additionally, it points out a lack of difference between the results reported in the ablation study table. While the comment identifies potential issues, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve their analysis. The feedback is 3 as it prompts the authors to consider the reliability of their results, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, it does not provide specific guidance on how to tone down the language or suggest alternative phrasing. The comment lacks explicit instructions or concrete examples of what constitutes overly exaggerated or flamboyant language, making it difficult for the authors to know exactly how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, describing it as overly exaggerated and flamboyant. This provides clear guidance on what needs to be addressed in the conclusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or references to overly exaggerated phrases, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant in multiple places. This feedback is 3 as it points out a potential problem in the language used, which could be revised to be more appropriate and professional. However, the comment lacks specific examples or suggestions on how to tone down the language or what alternative phrasing might be more appropriate. While it highlights an area for improvement, it does not provide detailed guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement, but it does not provide explicit instructions or concrete steps for the authors to follow. The comment mentions that Figure 5a seems strange and asks for more explanations, but it does not specify what aspects of the figure are problematic or how to address them. Similarly, it mentions the handling of DVS input when the input is in AER format but does not offer guidance on how to improve this aspect. The comment also suggests analyzing energy consumption like reference 15 did, but it does not provide details on how to implement this analysis or what specific aspects to focus on. Overall, the comment lacks explicit actions or detailed guidance, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5a\" and \"11,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with \"Fig. 5a\" and suggests providing more explanations, as well as addressing the handling of DVS input when the input is in AER format. Additionally, it suggests analyzing energy consumption like reference 15 did, which provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of several questions and suggestions for improvement, rather than making a subjective claim or opinion. It does not contain any claims or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several pieces of feedback that can help the authors improve their draft. It points out that Figure 5a seems strange and suggests that more explanations are needed. It also raises a question about how the authors handled DVS input when the input is in AER format. Additionally, it suggests analyzing energy consumption like reference 15 did, which could strengthen the paper. While the comment identifies areas for improvement, it lacks specific guidance or detailed suggestions on how to address these issues. The authors are given direction but may need to infer more detailed steps to fully implement the feedback. Therefore, the comment is 3, as it provides a starting point for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, noting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not provide any explicit or implicit actions for the authors to take to address these concerns. It lacks guidance on how to improve the innovation or how to differentiate the approach from existing methods. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, noting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing what is considered a common approach and what is lacking in the paper\"s contribution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks, and that merely migrating this approach to the field of MLMs is not innovative. The reviewer supports this claim by referencing the article itself, which implies that the authors should have known this. However, the comment lacks specific examples or references to support the claim that merely migrating this approach is not innovative. This makes the claim 3, as it provides some evidence but could be strengthened with more detailed examples or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, noting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. While the comment identifies a potential weakness in the paper\"s contribution, it lacks specific suggestions or guidance on how the authors might address this issue or differentiate their approach from existing methods. The feedback is 3 as it highlights a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments to address the concerns raised. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or the transfer performance of the model. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the concerns about the model\"s generalization and suggesting additional experiments, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that selecting positive samples without introducing perturbation noise could lead to lower generalization performance. The comment is 3 as it provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments to validate the claim, making the comment 3. Therefore, the score is 3.", "helpfulness_rationale": "The review comment raises important concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how to conduct these additional experiments or what specific downstream tasks should be considered. The feedback is 3 as it points out a potential issue but does not provide detailed guidance on how to resolve it. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clearly defined. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should provide more detailed definitions or examples, or how to improve the clarity of these concepts in the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment points out that the types of situations and social norms, such as physical and psychological safety, are not clearly defined in the main paper. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of these situations and social norms are unclear or how they could be better defined. Without explicit references or detailed guidance, the authors may find it challenging to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the types of situations and social norms, such as physical and psychological safety, are not clearly defined in the main paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the paper, noting that the types of situations and social norms, such as physical and psychological safety, are not clearly defined. This feedback is 3 as it points out a potential area for improvement, but it lacks specific guidance on how the authors might clarify these concepts or what aspects of the definitions might be unclear. While the comment highlights an important area for enhancement, it does not provide detailed suggestions or examples to help the authors address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more baselines should be compared and more domains should be tested. It also mentions that the choices of weighting and learning density functions are not strongly motivated, and that stronger empirical results are needed. However, the comment does not provide specific guidance on which baselines to compare or how to test the additional domains. The authors are left to infer that they need to expand their experimental setup, but without concrete suggestions on which baselines or domains to include, the action remains vague. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that more baselines should be compared and more domains should be tested, and it mentions the choices of weighting and learning density functions as areas for improvement. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or experiments where these improvements could be made. Additionally, it lacks specific guidance on which baselines or domains should be included. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that more baselines should be compared and more domains should be tested, and it critiques the choices of weighting and learning density functions as not being strongly motivated. However, the comment lacks specific examples or references to support the claim that these choices are not wellmotivated. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that more baselines should be compared and more domains should be tested. It also critiques the choices of weighting and learning density functions as not being strongly motivated, implying that stronger empirical results are needed. While the comment highlights areas for improvement, it lacks specific suggestions on which baselines or domains to include, making it 3. The authors are given a general direction for improvement but are not provided with detailed guidance on how to implement these changes. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. However, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the clarity of the symbols or the explanation of the process. The authors are left to infer that they need to clarify the symbols and provide more information on the process, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. This provides clear guidance on what needs to be addressed in the figure and the process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. However, the comment does not provide specific examples or detailed reasoning to support the claim of ambiguity or the need for clarification. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. This feedback is 3 as it points out a potential area for improvement in the clarity and comprehensibility of the figure. However, it lacks depth and does not provide specific suggestions or guidance on how to address the ambiguity or improve the explanation of the symbols. While it highlights an issue, the comment could be more helpful with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the paper regarding the assumption that the spectrum of a kernel is subgaussian, noting that this assumption excludes popular classes of kernels like Matern kernels. The reviewer suggests that the results could be restrictive due to this assumption. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to broaden the scope of the results. The action is implicit and somewhat vague, as the authors need to infer that they should consider including other classes of kernels in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the assumption regarding the spectrum of a kernel being subgaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the assumption excludes popular classes of kernels like Matern kernels, which could limit the scope of the results. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the assumption of the spectrum of a kernel being subgaussian is a limitation, as it excludes popular classes of kernels like Matern kernels. The reviewer supports this claim by noting that Matern kernels have polynomially decaying spectra, which could restrict the applicability of the results. However, the comment lacks specific examples or references to Matern kernels or other classes of kernels to fully substantiate the claim. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the assumption that the spectrum of a kernel is subgaussian, which excludes popular classes of kernels like Matern kernels. This is a relevant point that could impact the applicability and generalizability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or broaden the scope of their analysis to include other classes of kernels. While it highlights an important issue, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the writing is difficult to follow in many places and suggests simplifying it. However, it does not provide specific examples or guidance on how to achieve this simplification. The authors are left to infer that they need to make their writing more accessible, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and suggests simplifying it. However, it does not specify which parts of the paper are particularly challenging or where the simplification is needed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests simplifying it. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or examples, the authors may find it challenging to understand where the writing is difficult to follow and how to simplify it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a general issue with the writing being difficult to follow in many places. However, it does not provide specific examples or suggestions for simplification or improvement. Without actionable guidance or detailed feedback, the authors are left with a general observation but no clear path for addressing the issue. Therefore, the comment is 2, as it points out a potential problem but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the action is implicit, it is clear that the authors need to expand their testing to include more datasets. The comment provides a specific suggestion for improvement, which is to test on additional datasets. However, it does not offer detailed guidance on which datasets to use or how to conduct the additional testing. Therefore, the action is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the testing and evaluation of the method, but this inference is not direct. The comment is specific in suggesting the need for additional testing, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not provide any supporting evidence, reasoning, or references to justify why testing on more datasets would be beneficial or necessary. The claim is based on a logical assumption, but without additional context or examples, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. This is a reasonable suggestion that could improve the robustness and generalizability of the results. However, the comment lacks specificity and does not provide guidance on which datasets to use or how to conduct the additional testing. Without detailed suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify their explanation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the problem of gradient bias in Batch Normalization and the potential of Online Normalization. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the difference between Online Normalization and Batch Normalization, asking why Online Normalization is unbiased while Batch Normalization is biased. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that Online Normalization is unbiased and Batch Normalization is biased, suggesting that the authors have not adequately explained this difference. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. This is a relevant point that could help the authors clarify their explanation or provide additional context to readers. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should reconsider their statement about overparameterization, which is currently perceived as a negative aspect. The reviewer provides a rationale by pointing out that overparameterization can be beneficial for supervised learning of deep neural networks in practice, and references a theoretical work that supports this claim. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their stance on overparameterization. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 47  48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the authors\" claim about overparameterization and provides a rationale by pointing out its benefits in practice and referencing theoretical work. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point challenges the authors\" claim about overparameterization, suggesting that it is beneficial for supervised learning of deep neural networks in practice. The reviewer provides a rationale by referencing theoretical work that supports the benefits of overparameterization, such as 1. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or specific references to the theoretical work, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment challenges the authors\" claim about overparameterization, suggesting that it is beneficial for supervised learning of deep neural networks in practice. The reviewer provides a rationale by referencing theoretical work that supports the benefits of overparameterization, such as 1. This feedback is 3 as it prompts the authors to reconsider their stance on overparameterization and potentially explore its advantages in their work. However, the comment could be more helpful if it provided specific examples or additional references to support the argument further. Overall, the comment offers a valuable perspective but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experiments are limited to one game environment and suggests that more experiments are necessary. This provides a clear and direct action for the authors to take, which is to expand their experimental scope to include additional game environments. The comment is specific in its request for additional experiments, making it 5.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to conduct more experiments, but without clear references to specific sections or experiments, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation is problematic or how it affects the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are conducted on only one game environment. It suggests that more experiments are necessary to provide a broader understanding of the results. This feedback is clear and actionable, as it directs the authors to expand their experimental scope to include additional game environments. However, the comment could be more helpful if it provided specific suggestions on which environments to include or how to design these experiments. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what specific changes could be made to improve the argument or simulations. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific argument related to the practicality of the recognition process, particularly in the context of old vs. new judgments. However, it does not specify which part of the paper this argument is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the exhaustive list of items and how it relates to concrete predictions through simulations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. The reviewer points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. This claim is 3 as it provides a logical reasoning for the difficulty in implementing the argument, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the argument presented regarding the recall of recognition lists based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their argument. The feedback is 3 as it prompts the authors to consider the practicality of their argument, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pretrained model as the compared methods. It points out that if not, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the initialization process and possibly rerun experiments with different initialization methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness of the comparison due to the initialization of the proposed method before the finetuning stage. The comment suggests that if the compared methods were not initialized with the same pretrained model, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pretrained model as the compared methods. The reviewer supports this claim by referencing Table 1, which shows the inferior performance of the proposed method without SSL compared to most of the compared methods. This provides a logical basis for the claim, as it highlights a potential issue in the experimental setup that could affect the results. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have addressed this issue. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the initialization of the proposed method before the finetuning stage. It points out that if the compared methods were not initialized with the same pretrained model, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. This feedback is 3 as it highlights a potential weakness in the experimental setup that the authors should address to ensure fairness and validity. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a specific initialization method or suggesting ways to standardize the initialization process across methods. Overall, the comment identifies a critical area for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset, specifically referring to Table 3 on page 7. It also provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016.\" The comment is explicit in its suggestion to use better metadata embeddings and provides a specific reference to a related work. However, it does not provide detailed guidance on how to implement this suggestion or what specific steps to take. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of better metadata embeddings for the zeroshot learning results on the CUB dataset. The comment provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the authors should consider this approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset, specifically referring to Table 3 on page 7. The reviewer provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016.\" This reference provides a clear rationale for the suggestion, as it demonstrates that better metadata embeddings can lead to improved performance. However, the comment could be strengthened by providing more detailed analysis or specific examples of how the proposed method could benefit from these embeddings. Overall, the claim is 4, as it is supported by a specific example and logical reasoning, but it could be further substantiated with additional evidence or detailed explanation.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by recommending the use of better metadata embeddings for the zeroshot learning results on the CUB dataset. It references a specific example from a related work, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which demonstrates the potential for better metadata embeddings to improve performance. This feedback is actionable and provides a clear direction for the authors to enhance their results. However, the comment could be more helpful if it included additional details or guidance on how to implement this suggestion or what specific metadata embeddings options might be considered. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a lack of clarity in the paper regarding the nature of the contribution with respect to ECE_sweep. It explicitly states that the contribution is not clearly described and suggests that the authors should be upfront about it. The reviewer provides a concrete example of what is missing, which is the autotuning of a hyperparameter in the estimate. This feedback is specific and provides a clear direction for the authors to improve their draft by clarifying the contribution. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ECE_sweep\" and the issue with the contribution being unclearly described. It specifies the problem by pointing out that the contribution is not clearly described, particularly regarding the autotuning of a hyperparameter in the estimate. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the contribution with respect to ECE_sweep is not clearly described in the text. It provides a specific example of the issue, which is the autotuning of a hyperparameter in the estimate, and suggests that this is not fundamentally different from the contribution. The reviewer acknowledges confusion and provides a clear explanation of the issue, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim that this is not a fundamentally different contribution. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the contribution regarding ECE_sweep. It points out that the contribution is not clearly described, particularly regarding the autotuning of a hyperparameter in the estimate. The reviewer acknowledges that this led to confusion and suggests that the paper should be more upfront about the contribution. This feedback is clear and actionable, as it provides a concrete example of what needs to be clarified and improved in the paper. By addressing this issue, the authors can enhance the clarity and transparency of their contribution, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. It also mentions that the authors might have missed this in the appendix. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the resilience of the metric to the choice of random projection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the chosen random projection matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. The comment also mentions that the authors might have missed this in the appendix, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. However, the comment lacks specific examples or references to support the claim that such pathological projection matrices are unlikely with random projections. While it highlights a potential concern, the lack of detailed evidence or examples makes the claim 3. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results obtained using the chosen random projection matrix, suggesting that pathological projection matrices could skew the MFTMA capacity and width scores. It also points out that the authors might have missed this in the appendix. While the comment highlights an important area for investigation, it lacks specific guidance or suggestions on how to address this issue or what specific tests could be conducted. The feedback is 3 as it prompts the authors to consider the robustness of their results, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just being limited to the ablation study. While the comment implies that the authors should expand the evaluation to include additional comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden the evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just being limited to the ablation study. However, it does not specify which part of the paper this evaluation is currently limited to, nor does it provide guidance on how to expand the evaluation. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in its suggestion to broaden the evaluation, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation of FGT is limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of FGT, noting that it is currently limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for expanding the evaluation to include additional comparisons. However, the comment could be more helpful if it offered specific examples of how to conduct these comparisons or provided guidance on which methods to include. Despite this, the feedback is 4 as it points out a critical area for improvement and provides a clear direction for the authors to enhance their evaluation."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not contribute novelly to the understanding of the winnertakeall property, as it uses extremely simplified settings and reports findings that have been previously reported in other works. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the originality or how to present the findings in a more novel or innovative way. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"winnertakeall property\" and \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not contribute novelly to the understanding of this behavior due to the use of extremely simplified settings and the repetition of findings from previous works. This provides clear guidance on what needs to be addressed to improve the originality of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not contribute novelly to the understanding of the winnertakeall property due to the use of extremely simplified settings and the repetition of findings from previous works. However, the comment lacks specific references to these previous works or detailed examples of how the findings have been reported. Without such references or detailed justification, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2, as it provides some evidence but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it does not contribute novelly to the understanding of the winnertakeall property due to the use of extremely simplified settings and the repetition of findings from previous works. This is a critical observation that could impact the paper\"s originality and impact. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from previous studies. While it points out a potential weakness, it does not provide actionable feedback or detailed advice on how to improve the paper. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors leverage the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes could be made to improve the directness of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" approach to addressing the problem, specifically mentioning the use of the Witness oracle and its complexity. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspect of the complexity issue is problematic or how it could be addressed. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not address the problem directly by leveraging the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" approach, specifically the use of the Witness oracle and its complexity. It suggests that the authors may not be addressing the problem directly, as the oracle is described as \"polynomial time\" in the tabular case. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their approach. Without detailed guidance or examples, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of detail in the experimental description, suggesting that increased clarity would be beneficial. It explicitly states that the current state of the manuscript makes it difficult for readers to judge the results. The comment provides a reference to \"Questions\" for further details, which implies that the authors should refer to this section for guidance on how to improve the clarity of their experimental description. However, the comment does not specify which details are missing or how to address them, leaving the authors with a general direction but without concrete steps to follow. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental details\" and the \"Questions\" section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the experimental description and the difficulty in judging the results due to the current state of the manuscript. The reference to \"Questions\" provides additional guidance on where to find more details. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental description lacks detail and clarity, making it difficult for readers to judge the results. This claim is 3 as it highlights a specific issue with the manuscript, but it does not provide detailed examples or references to support the claim. The mention of \"Questions\" suggests that further details are available elsewhere, but this does not fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, namely the lack of detail in the experimental description. It highlights the importance of clarity in the results section and suggests that increased detail would significantly benefit the user\"s ability to judge the results. The comment provides a reference to \"Questions\" for further details, which is helpful in guiding the authors to where they can expand their explanation. However, the comment could be more helpful if it offered specific suggestions on what details are missing or how to improve the clarity of the experimental description. Overall, the comment is 4 as it points out a critical area for improvement but lacks detailed guidance on execution."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, specifically regarding the potential disadvantage of MMD DRO compared to the variance regularized problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this confusion or clarify the statement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the statement in the theorem, which could indicate a disadvantage of MMD DRO compared to the variance regularized problem. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO compared to the variance regularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding a statement in Theorem 5.1, which could indicate a disadvantage of MMD DRO compared to the variance regularized problem. This feedback is 3 as it points out a specific area that may need clarification or further explanation. However, the comment lacks depth and does not provide suggestions on how to address the confusion or improve the clarity of the statement. While it highlights an area for potential improvement, it does not offer actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide more information on how to use morphologic segmentation across different domains and how it should be conducted differently for each domain. It also questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on morphologic segmentation across domains. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"morphologic segmentation\" and \"domain\" aspects, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of morphologic segmentation across domains and how it should differ for each domain. The comment also raises important questions about the assumption of morphologic segmentation invariance across domains, which is relevant to the task of domain adaptation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks information on how to use morphologic segmentation across domains and how it should be conducted differently for each domain. It questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. The comment suggests that the paper assumes morphologic segmentation to be invariant, which is a logical claim based on the paper\"s focus on domain adaptation. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the need for more information on morphologic segmentation across domains, but the lack of detailed evidence or examples makes the claim 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the use of morphologic segmentation across domains and how it should differ for each domain. It questions the assumption of morphologic segmentation invariance across domains, given the task of domain adaptation. This feedback is valuable as it highlights an important area for improvement in the paper, particularly regarding the applicability of morphologic segmentation across different domains. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions or how to conduct morphologic segmentation differently for each domain. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that needs further exploration and clarification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the object detectionbased attention being performed on the image or on some convolutional feature map. It suggests clarifying this point and potentially rescaling based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the object detectionbased attention, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on whether the attention is performed on the image or on some convolutional feature map, and whether rescaling is done based on the receptive field. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the object detectionbased attention and its application. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the object detectionbased attention, specifically asking whether it is performed on the image or on some convolutional feature map. It also suggests that rescaling might be necessary based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how to clarify or address this issue. The feedback is 3 as it points out a potential area for clarification, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of a discussion about Set Transformer and other related works that use summary tokens. This provides a clear and direct action for the authors to take, which is to include a discussion on these topics. The comment is specific in identifying the missing content and provides a concrete action for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Set Transformer\" and \"other related works that also use summary tokens,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the use of summary tokens and related works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there is a missing discussion about Set Transformer and other related works that use summary tokens. However, it does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a discussion about Set Transformer and other related works that use summary tokens. This feedback is clear and actionable, as it directs the authors to expand their literature review to include relevant works that could enhance their understanding and analysis. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it provided additional context or examples of how these works could be integrated into the paper. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors conducted statistical significance tests for the numbers presented in the paper. While it implies that the authors should consider conducting such tests, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct statistical significance tests. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. However, it does not specify which part of the paper this comparison is presented in, making it weakly grounded. The comment is specific in its request for statistical significance tests, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. However, it does not provide any supporting evidence, reasoning, or references to justify why this claim is relevant or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the statistical significance of the numbers presented in the paper, specifically regarding the comparison between the proposed method and baselines. This is a valuable point as it highlights a potential area for improvement in the paper, which could enhance the credibility and robustness of the results. However, the comment lacks specific guidance on how to conduct statistical significance tests or what aspects of the comparison should be analyzed. While it identifies an important area for consideration, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the choice of significance testing method used in the paper, suggesting that a paired test setting like the Wilcoxon signedranked test might be more appropriate. While the comment implies that the authors should consider using a different test, it does not explicitly instruct them to do so or provide guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choice of significance testing method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of significance testing method used in the paper, specifically questioning the appropriateness of the current method. However, it does not specify which part of the paper discusses this choice, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in suggesting an alternative test, the Wilcoxon signedranked test, but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples of why the current test might be inappropriate or how the suggested test would be more suitable. As a result, the claim is not 5, as it relies on a vague suggestion without sufficient justification or evidence. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. While it identifies a potential issue with the current choice, it does not provide specific guidance or examples of alternative tests that could be used. The comment lacks depth and does not offer actionable steps for the authors to address the concern. As a result, it provides some insight but does not fully support the authors in improving their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what alternative demonstrations could be used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific statement \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim that \"better than random\" is a strong demonstration of capability, providing a clear point of critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that \"better than random\" is a strong demonstration of capability. However, it does not provide any supporting evidence, reasoning, or references to justify why this claim is questionable. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. This feedback is 3 as it points out a potential weakness in the paper\"s argument, prompting the authors to reconsider the strength of their evidence. However, the comment lacks specific suggestions or guidance on how to strengthen the demonstration or what alternative methods could be used to substantiate the claim. While it identifies an area for improvement, it does not provide detailed guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should enhance the background knowledge and literature description. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, it does not specify which sections or parts of the paper need these improvements, making it weakly grounded. The comment is specific in suggesting that the background knowledge and literature description should be brought forward, but without explicit references to sections or parts of the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, the comment does not provide specific examples or references to support why these changes would be beneficial or how they would improve the paper. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s organization, suggesting that it could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. This feedback is 3 as it points out a specific area for improvement, but it lacks depth and does not provide detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specific steps to take. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While it identifies a potential gap in the comparison, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include these models in their comparison, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific models, \"PanopticFPN\" and \"Mask2Former,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of these models in the comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these models should be included in the comparison. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper\"s conclusions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared. This feedback is valuable as it highlights an area where the paper could be expanded to include more comprehensive comparisons. However, the comment lacks depth and does not provide specific suggestions on how to incorporate these models into the comparison or what aspects to focus on. While it points out a potential weakness, it does not offer actionable guidance for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might incorporate diversity into their model or what specific changes could be made to improve the paper. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the paper\"s motivation for diversity, specifically mentioning that the model does not enforce diversity explicitly. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the model\"s lack of diversity enforcement, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model. The reviewer expresses disappointment that the diversity term is not present in the model. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the basis of the claim and potentially conduct additional analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. This is a critical point as it undermines the paper\"s claims about its contributions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their model to enforce diversity. Without actionable feedback or detailed advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on how the authors should address this issue or what specific experiments should be included. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated into the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence affects the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue by pointing out the absence of certain experiments, such as contrastive learning and adversarial learning. This feedback is 3 as it highlights a potential gap in the experimental setup, which the authors should address to provide a more comprehensive evaluation of their work. However, the comment lacks depth and does not offer suggestions on how to incorporate these experiments or what specific aspects of the paper would benefit from their inclusion. While it points out a potential area for improvement, it does not provide detailed guidance on how to address it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should test inverse triples in other embedding models besides CP, which could provide additional insights into the effectiveness of their approach. While the comment implies that the authors should conduct these tests, it does not explicitly instruct them to do so. The action is concrete, as it specifies a specific test that could be conducted, but it is somewhat vague because it does not provide detailed guidance on how to implement these tests or what specific models should be tested. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should test inverse triples in other embedding models besides CP, which could provide additional insights into the effectiveness of their approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental setup, but this inference is not direct. The comment is specific in suggesting a potential test, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that introducing inverse triples might be useful in other embedding models besides CP, but it does not provide any evidence or reasoning to support this claim. The comment lacks specific examples or references to other models where inverse triples could be applied, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors test inverse triples in other embedding models besides CP. This is a relevant point as it could provide additional insights into the effectiveness of their approach. However, the comment lacks specific guidance on which models should be tested or how to implement these tests. While it highlights a potential area for improvement, it does not offer detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The comment implies that the authors should provide more information about the parameters and their relationship to the kernel height/width and depth, but it lacks concrete steps or examples to follow. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. The comment provides a clear direction for the authors to address the issue by explaining the relationship between the kernel height/width, depth, and parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of parameters should change or how the efficiency could be improved. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the S2D structure regarding the number of parameters and suggests that more details are expected regarding the efficiency improvements. It acknowledges that the FLOP is quadratic on the activation side length but points out that the number of parameters could increase due to the depth of the structure. This feedback is 3 as it highlights a potential area for improvement and encourages the authors to provide more details regarding the efficiency improvements. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address this issue or what additional details should be included. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results from the Atari game are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the interpretability of their results. There is no guidance on whether they should expand the experiment to include more games or baselines, or how they might present their findings more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the interpretation of the Atari game results, specifically noting that the results are limited to a single game and a single baseline. This feedback highlights an area where the authors could improve the clarity and generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional experiments or analyses. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep at the time, to provide context. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim. While it implies that the authors should provide more detailed information or examples, it lacks concrete guidance on what specific aspects to address or how to present the information. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks.\" It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in suggesting that quantifying and clarifying the claim could be beneficial. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. This reference provides some context for the claim, but it does not offer specific examples or detailed reasoning to fully substantiate the claim. The comment is 3, as it provides a logical connection to the original work but lacks detailed evidence or examples to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be beneficial. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. This reference provides some context for the claim, but the comment lacks specific guidance on how to quantify or clarify the claim. While it points out a potential area for improvement, it does not offer detailed suggestions or examples on how to address the issue. Therefore, the comment is 3, as it identifies a potential weakness but lacks depth and actionable advice for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure the availability of the environment or a good OPE method. The action is implicit and somewhat vague, as the authors can infer that they need to consider these factors but are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the finetuning is mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these hyperparameters are introduced, the comment lacks full grounding. It is specific about the issue of finetuning and the dependence on the environment or OPE method, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of two additional hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim remains 1, as it does not provide sufficient justification for the authors to make improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. This feedback is 3 as it points out a potential problem that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to ensure the availability of the environment or a good OPE method. Without actionable advice or detailed explanation, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the understanding of Figure 5 or the labels being incorrect. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific steps to take to improve the figure or labels. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper, such as Figure 5, is being addressed. It lacks specificity because it does not provide details on what is unclear or incorrect about the figure or labels. Without explicit references or detailed feedback, the authors cannot effectively identify the issues or make improvements. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The comment claims that either the reviewer does not understand Figure 5 or the labels are incorrect. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the clarity or accuracy of Figure 5 or the labels used in the figure. However, it does not provide any specific guidance or suggestions on how to address this issue, such as suggesting alternative labels or clarifying the figure\"s purpose. Without actionable feedback or detailed explanations, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. It also notes that the benchmarks used are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of minimal performance differences or how to update the benchmarks. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance differences between methods, noting that they are minimal across evaluations and often less than 1 percentage point. It also mentions that the benchmarks used are outdated and likely saturated, referencing specific works. However, the comment does not specify which part of the paper discusses these performance differences or the benchmarks, making it weakly grounded. The comment is specific in detailing the issue of minimal performance differences and the need to update the benchmarks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point, which may be due to random variation. The reviewer supports this claim by referencing the outdated and likely saturated benchmarks used. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some evidence, it could be strengthened with more detailed analysis or references to specific studies that support the claim. Therefore, the comment is 3, as it provides some evidence but could be more fully substantiated with additional details or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. This observation suggests that the methods may be overfitting or that the benchmarks are saturated. The comment also points out that the benchmarks used are outdated, which could impact the relevance and applicability of the results. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. Providing more detailed advice or examples on how to update the benchmarks or improve the performance evaluation would make the comment more actionable. Therefore, the comment is 3, as it identifies a significant weakness but lacks depth in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two main issues with the experimental section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparison with other stateoftheart methods that do not rely on gyrostructures. While the comment highlights these gaps, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to include more interpretive insights and comparisons with other methods. The action is implicit and somewhat vague, as it lacks concrete steps or examples of what specific insights or comparisons should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It also specifies the issues with the related discussion, noting the lack of interpretive insights and the need for comparison with other stateoftheart methods. The comment further highlights the absence of comparison with methods that do not rely on gyrostructures, which makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights and that the paper lacks comparison with other stateoftheart methods that do not rely on gyrostructures. The comment suggests that this omission makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques. However, the comment does not provide specific examples or references to support these claims, making it 3. The authors would need to infer the importance of these comparisons and the potential impact on the conclusions of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two significant issues with the experimental section of the paper. First, it points out the lack of interpretive insights into why the proposed gyrostructures outperform existing methods. This feedback highlights an important area for improvement, as it would help the authors better understand and communicate the strengths of their approach. Second, the comment notes the absence of comparison with other stateoftheart methods that do not rely on gyrostructures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques. This omission is crucial for the paper\"s conclusions and impact, and the comment provides a clear and actionable suggestion for improvement. By addressing these issues, the authors can enhance the clarity and robustness of their experimental findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It highlights the need for proper ablation studies to verify this claim. While the comment identifies a potential problem, it does not provide explicit instructions on how to conduct these studies or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for ablation studies and determine how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It points out the need for proper ablation studies to verify this claim. However, the comment does not specify which part of the paper discusses the distillation process or the claim about its effectiveness. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the claim and the need for ablation studies, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. The reviewer provides a logical reasoning by pointing out that the finetuning without earlystopping could lead to high variances, which would affect the validity of the claim. However, the comment lacks specific examples or references to support the argument, such as data or studies that demonstrate the impact of regularization on teacher performance. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or references to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim that the improvements in teacher performance are due to distillation. It suggests that the improvements might be due to regularization effects instead, given the lack of earlystopping and the high variances in finetuning. This is a valuable observation that prompts the authors to reconsider their claims and potentially conduct proper ablation studies to verify the effectiveness of distillation. However, the comment could be more helpful if it provided specific guidance on how to conduct these studies or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and encourages the authors to conduct further analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of insight into the rationale behind the need for selfsupervised learning on 360 video data with spatial audio. It implies that the authors should provide more detailed explanations or justifications for this approach. However, the comment does not explicitly instruct the authors to do so or offer specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results and suggests that while the proposed approach is valuable for selfsupervised learning on 360 video data with spatial audio, it lacks insights into why this approach is needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of insight into the rationale behind the need for selfsupervised learning on this kind of data. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results suggest the proposed approach is valuable for selfsupervised learning on 360 video data with spatial audio but lacks insights into why this approach is needed. The comment provides a logical reasoning by pointing out the absence of detailed explanations for the rationale behind the approach. However, it does not provide specific examples or references to support the claim, making it 3. The authors may need to infer the need for more detailed explanations themselves, which could lead to some confusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the rationale behind the need for selfsupervised learning on 360 video data with spatial audio. It highlights that while the experimental results suggest the approach\"s value, the paper lacks insights into why this approach is necessary. This feedback is 3 as it points out an area where the authors could provide more context or explanation to enhance the paper\"s clarity and depth. However, the comment could be more helpful if it suggested specific ways to address this issue, such as providing examples or references to similar approaches or discussing the benefits of selfsupervised learning in this context. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue with the paper, noting that it only covers the SimCLR case and lacks analysis on the projection head, which is considered important. However, it does not provide explicit guidance on what specific analysis should be conducted or how to address this gap. The authors are left to infer that they need to include analysis on the projection head, but without concrete instructions or examples, the action remains vague. Therefore, this comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the \"projection head,\" which is a critical component of the SimCLR approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only covers the SimCLR case and lacks analysis on the projection head, which is considered important. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why the projection head is crucial or how it relates to the SimCLR case. Without this additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that it only covers the SimCLR case and lacks analysis on the projection head, which is considered important. This feedback highlights a gap in the analysis that could enhance the paper\"s comprehensiveness and relevance. However, the comment does not provide detailed guidance on how to address this issue or what specific analysis should be conducted on the projection head. While it points out a critical area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments. The comment is specific about the types of experiments that are missing, giving the authors a concrete understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the lack of additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing the types of experiments that are missing, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide specific examples or detailed reasoning to support why these experiments are necessary or how they would enhance the paper. Without such evidence or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly points out areas where the paper could be strengthened by including these experiments. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the experimental results, noting that the proposed method does not show any advantage without prior information, but only when using prior knowledge. The reviewer suggests that this comparison is unfair because the proposed method requires two separate representation models, which adds complexity and cost. While the comment identifies an issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors can infer that they need to consider the extra complexity and cost of using prior knowledge, but it is not explicitly stated. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not show any advantage without prior information but only when using prior knowledge. This provides clear guidance on what needs to be addressed, namely the fairness of the comparison and the additional complexity and cost of using prior knowledge. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not show any advantage without prior information but only when using prior knowledge. The reviewer supports this claim by explaining that the comparison is unfair because the proposed method requires two separate representation models, which adds complexity and cost. This reasoning is logical and provides a clear explanation for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to similar studies that have addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that the proposed method does not show any advantage without prior information but only when using prior knowledge. The reviewer points out that this comparison is unfair because the proposed method requires two separate representation models, which adds complexity and cost. This feedback is valuable as it highlights a potential weakness in the experimental setup and suggests that the authors should consider the impact of prior knowledge on the results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or how to design a more fair comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also mentions the use of alternative statistics, such as the median, to replace the mean and standard deviation in the regularization. While the comment implies that the authors should explore these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the regularization term, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the adhoc nature of the regularization term and suggests the use of alternative statistics, such as the median, to replace the mean and standard deviation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also mentions the use of alternative statistics, such as the median, to replace the mean and standard deviation in the regularization. While the comment provides logical reasoning by suggesting the use of alternative statistics, it lacks specific examples or references to support the claim that the median is a better choice. This makes the claim 3, as the authors would need to explore the rationale themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the adhoc nature of the regularization term and suggests that the authors should provide more theoretical support. It also provides a specific suggestion to consider alternative statistics, such as the median, to replace the mean and standard deviation in the regularization. This feedback is actionable and constructive, as it offers a clear direction for the authors to enhance the theoretical foundation of their work. However, the comment could be more helpful if it provided examples or references to support the use of alternative statistics. Overall, the comment is 4, as it effectively guides the authors toward improving the theoretical underpinning of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the iteration cost (computational budget) of their proposed method and to include the iteration cost of all related methods, including baseline methods. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and direct, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the iteration cost should be discussed, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the iteration cost of the proposed method and the iteration cost of all related methods, including baseline methods. This provides clear guidance on what the authors need to include in their discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the iteration cost is a critical aspect to discuss. The authors are left to infer the importance of this discussion themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including a detailed discussion on computational efficiency. By addressing this point, the authors can improve the comprehensiveness and clarity of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed this issue. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the description of the VAD is puzzling and suggests that the authors should clarify what they mean by \"discarding TF bins with a magnitude of less than epsilon.\" It also notes that this approach is not consistent with a VAD, which is supposed to look for speech presence and is not typically defined over frequency. The comment implies that the authors should reconsider their approach and provide a more accurate description of their VAD. While the action is implicit, it is clear and concrete, as it specifies what needs to be clarified and corrected. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic with the VAD description, namely that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The comment further explains that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description is puzzling and suggests that the authors are discarding TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The reviewer argues that a VAD should look for speech presence and is unlikely to be defined over frequency. This claim is 3 as it provides a logical reasoning for why the current description is problematic, but it lacks specific examples or references to support the assertion that a VAD should not be defined over frequency. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the description of the VAD, noting that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. It points out that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear understanding of what a VAD should entail. The comment offers a constructive suggestion by suggesting that the authors should reconsider their approach and provide a more accurate description of their VAD. This feedback is actionable and helps the authors improve the clarity and accuracy of their description, making it 5. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider presenting results on ImageNet to enhance the convincingness of their proposed method. While the comment implies that the authors should include these results, it does not provide specific guidance on how to conduct the experiments or what aspects of the results should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should include results on ImageNet to improve the paper\"s credibility. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or the methodology. Without explicit references to sections or specific results, the authors cannot confidently determine which parts need to be addressed. The comment is 1 and lacks specificity, making it difficult for the authors to understand and act upon the suggestion. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that results on ImageNet could be more convincing for the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to justify why this would be beneficial or how it would enhance the credibility of the method. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. However, it does not provide specific guidance on how to achieve this or what aspects of the results on ImageNet would be most impactful. Without detailed suggestions or examples, the authors are left with a general idea of what could be improved but without actionable steps to take. Therefore, the comment is 3 as it identifies a potential area for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the insufficiency of the contribution and suggests that the authors should further explore how to leverage the connection between complementary and model robustness to improve model robustness. While the comment implies that more insightful findings or solutions should be included, it does not provide specific guidance on what these findings or solutions should be. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their analysis to be more comprehensive. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, specifically the connection between complementary and model robustness. It suggests that while the authors have studied this connection, they have not explored how to leverage these characteristics to improve model robustness. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely, more insightful findings or solutions to improve model robustness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution is insufficient and suggests that the authors should further explore how to leverage the connection between complementary and model robustness to improve model robustness. The reviewer provides a logical reasoning by stating that the conclusion is easily and intuitively obtained, given the relationship between multimodal complementary and robustness. However, the comment lacks specific examples or references to support the claim that the contribution is insufficient or to suggest how to improve it. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant concern about the contribution of the paper, noting that while the authors have studied the connection between complementary and model robustness, they have not explored how to leverage this connection to improve model robustness. The reviewer suggests that the conclusion is easily and intuitively obtained, and that more insightful findings or solutions should be included. However, the comment does not provide specific guidance or suggestions on how the authors might expand their analysis or what additional insights or solutions could be explored. While it highlights a potential area for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of connection between the theoretical analysis and the proposed method, specifically questioning the enhancement of generalization for distant nodes. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what specific steps could be taken to strengthen the connection between theory and method. As a result, the authors are left without a clear understanding of what changes or improvements are needed to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical analysis and the proposed method, specifically mentioning the derivation of PACBayesian bound for GNNs in the transductive setting and the interplay between training and testing sets. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the lack of a strong connection between the theoretical analysis and the proposed method, as well as the issue of adopting the selfattention mechanism from the transformer. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical analysis does not have a strong connection to the proposed method, and that the method seems to simply adopt the selfattention mechanism from the transformer. The reviewer questions how the proposed method enhances generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of a strong connection between the theoretical analysis and the proposed method. It points out that the method seems to simply adopt the selfattention mechanism from the transformer and apply it to the graph, without explaining how this enhances generalization for distant nodes. The comment highlights a critical gap in the paper that needs to be addressed, providing a clear direction for the authors to improve their draft. However, it could be more helpful if it offered suggestions on how to strengthen the connection between theory and method or provided examples of how other methods have successfully bridged this gap. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It explicitly states that these heads are active at the S2 token but do not primarily attend to it, referencing Section 3 of Wang et al., 2023. This provides a clear and concrete action for the authors to correct the statement in their draft. The comment is explicit and provides specific guidance on how to revise the text, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section of the paper, \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the incorrect claim about the attention of these heads and references Section 3 of Wang et al., 2023 to support its assertion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\" is incorrect, citing Section 3 of Wang et al., 2023. This claim is supported by a specific reference to the external work, which provides a clear and verifiable basis for the assertion. The reviewer logically explains the correct behavior of these heads, making the claim 4. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It points out that these heads are active at the S2 token but do not primarily attend to it, which is a critical correction for the authors to make. The comment is clear and actionable, providing the authors with specific guidance on how to correct their draft. By addressing this issue, the authors can improve the accuracy and clarity of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the eta_ri term is not clearly explained as a noncentral chisquared distribution. However, it does not provide any guidance on how the authors should address this issue or what specific steps they should take to clarify this point. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the eta_ri term, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the eta_ri term being a noncentral chisquared distribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the eta_ri term being a noncentral chisquared distribution. However, it does not provide any supporting evidence, reasoning, or references to justify why this term should be considered unclear or how it could be clarified. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the eta_ri term being a noncentral chisquared distribution. This is a clear and actionable point that the authors can address to improve the understanding of their work. However, the comment could be more helpful if it provided additional context or examples to help the authors better understand the implications of this clarification. Overall, the comment is 3 as it points out a specific area for improvement but lacks depth and detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of speed analysis in the experiments, specifically noting the absence of comparisons of inference speed between the proposed network and prior work. It suggests that the improvement on inference speed would be more interesting than reducing FLOPs. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include speed analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of speed analysis and the comparison of inference speed between the proposed network and prior work. It specifies the issue by pointing out the absence of such comparisons, which allows the authors to identify the exact part of the paper being addressed. The comment is also specific because it clearly articulates the need for comparisons of inference speed and why this would be more interesting than reducing FLOPs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of speed analysis is a significant issue, as the experiments have compared GFLOPs of different segmentation networks but not the inference speed between the proposed network and prior work. The reviewer suggests that the improvement on inference speed would be more interesting than reducing FLOPs. This claim is 3 as it logically points out the importance of speed analysis, but it lacks specific examples or references to support the assertion that the improvement on inference speed is more significant. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of speed analysis in the experiments. It highlights the importance of comparing inference speed between the proposed network and prior work, suggesting that this would be more interesting than simply reducing FLOPs. This feedback is clear and actionable, as it directs the authors to include speed analysis in their experiments. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects of inference speed to focus on. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the proposed method is not wellpositioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It suggests that the authors should conduct a thorough literature review to identify other works that use this property. While the comment explicitly states the need for a literature review, it does not provide specific guidance on how to conduct it or what aspects to focus on. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of originality in the proposed method and the need for a thorough literature review to identify other works that use the same property. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. The reviewer supports this claim by referencing specific works, such as the original denoising score matching objective and scoreinterpolation, which have used this property. This provides a clear and robust justification for the claim, making it 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known in the literature. It provides specific examples of existing works that use this property, such as the original denoising score matching objective and scoreinterpolation. This feedback is valuable as it highlights a potential gap in originality and suggests a thorough literature review to address it. However, the comment could be more helpful if it offered guidance on how to conduct the literature review or what specific aspects to focus on. Overall, the comment is 4 as it provides actionable feedback on a critical aspect of the paper, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects to focus on. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this curiosity pertains to, such as a specific section, table, or figure where this combination is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it identifies an area of interest, it lacks specificity and actionable guidance for the authors. It does not provide details on what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Without this information, the authors may struggle to understand how to address the curiosity or what potential benefits or limitations might arise from such an analysis. Therefore, the comment is 3, as it points out an area of interest but lacks depth and actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback implies that the authors should expand their discussion of related work to include a comparison with their own work. While the action is implicit, it is clear that the authors need to include a more detailed discussion of related work, which provides a concrete direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. However, it does not specify which part of the paper this discussion should be included in, such as the introduction, literature review, or results section. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting a more detailed discussion of related work, but without explicit references to sections or elements, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This claim is 3 as it provides a logical reasoning for expanding the discussion of related work. However, it lacks specific examples or references to support the claim that the current discussion is insufficient. The authors would need to infer the specific aspects of the related work that should be discussed and how these differences should be highlighted. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback is clear and actionable, as it provides a specific direction for improvement by encouraging the authors to expand their discussion of related work. However, the comment could be more helpful if it offered examples of how to structure this discussion or what specific aspects to focus on. Overall, the comment is 4 as it provides a clear and constructive suggestion for enhancing the paper, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include attacks on other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should consider conducting experiments on these additional tasks, it does not provide specific guidance on how to implement these changes or what specific architectures or tasks should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper these experiments should be added to or which specific architectures or tasks should be considered. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections that need revision. The suggestion is specific in terms of what additional experiments could be conducted, but without clear grounding, it is challenging for the authors to effectively address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends expanding them to include attacks on other architectures and classification tasks. However, the comment does not provide any supporting evidence, examples, or references to justify why this expansion is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it identifies a potential area for improvement in the paper, which could enhance its scope and relevance. However, the comment lacks specific guidance on which architectures or tasks should be considered, how to implement these changes, or what potential benefits this expansion could offer. While it points out a potential area for improvement, the lack of detailed suggestions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the output from the algorithm depends on the order in which the data is processed and suggests that this should be clarified. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to clarify this point. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the order of data processing. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the output from the algorithm depends on the order in which the data is processed and recommends clarifying this aspect. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of the algorithm\"s dependence on data order, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output from the algorithm depends on the order in which the data is processed, suggesting that this should be clarified. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm\"s output, suggesting that it depends on the order in which the data is processed. This is a clear and actionable point that the authors should address to improve the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify this aspect or offered examples of how other studies have addressed similar issues. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\"s utility, it could deter their adoption. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to mitigate the potential impact. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the potential impact of their mitigation strategies on performance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the mitigation strategies aimed at reducing memorization and questions their impact on overall performance. It suggests that there might be a tradeoff between reducing a particular behavior and maintaining high performance, and warns that significant impairment of the model\"s utility could deter adoption. However, the comment does not specify which part of the paper discusses these mitigation strategies, making it weakly grounded. The comment is specific in its concern about the potential impact on performance, but without explicit references to sections or details, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. The comment highlights a potential issue with the adoption of these strategies if they significantly impair the model\"s utility. However, the comment lacks specific examples or references to support the claim that such a tradeoff exists or that the mitigation strategies might significantly impair the model. Without detailed evidence or examples, the claim is 3, as it provides a logical argument but lacks the necessary support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies aimed at reducing memorization, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It raises a concern about the impact of these strategies on the overall performance of the model, noting that if they significantly impair the model\"s utility, it could deter their adoption. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or mitigate the potential impact on performance. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the reason for using 6fold crossvalidation in the experiments. It points out that other papers in the field did not use crossvalidation, which raises questions about its necessity. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the rationale behind the crossvalidation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clear explanation for the use of crossvalidation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of 6fold crossvalidation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the reason for using crossvalidation is unclear due to its absence in other papers compared to this work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the reason for using 6fold crossvalidation is unclear because it is not used in other papers compared to this work. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the reason for using 6fold crossvalidation. It points out that other papers in the field did not use this validation method, which raises questions about its necessity. This feedback is 3 as it highlights an area where the authors need to provide more detailed explanation or justification for their methodology. However, the comment could be more helpful if it suggested ways to address this issue, such as explaining the rationale behind the choice of crossvalidation or providing a comparison with other validation methods. Overall, the comment provides some insight but lacks actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper discusses ODA as a method for solving the MOIP problem but does not clearly explain how the presented method improves performance and computation speed over ODA. However, it does not provide specific guidance on how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ODA,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not clearly explain how the presented method improves performance and computation speed over ODA. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not clearly explain how the presented method improves performance and computation speed over ODA, which is a subjective claim. The reviewer provides a logical reasoning by pointing out that ODA is a method for solving the MOIP problem and that the paper does not clearly suggest how the presented method enhances performance and speed. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it does not clearly explain how the presented method improves performance and computation speed over ODA, which is one of the methods for solving the MOIP problem. This feedback is valuable as it highlights a gap in the paper\"s explanation, prompting the authors to clarify their contributions. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how the authors might improve their explanation. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the sampling method used to obtain different initializations x_0, noting that this sampling is important for convergence to the optimum. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the evaluation. The comment suggests that the sampling method should be experimentally evaluated on the proposed benchmarks, but it does not specify which benchmarks or how the evaluation should be conducted. The lack of concrete details makes it difficult for the authors to know exactly what steps to take to improve their draft. Therefore, the comment is 3, as it identifies an area for improvement but lacks specific guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sampling performed to obtain different initializations x_0, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this sampling is important for convergence to the optimum but is not evaluated carefully on the proposed benchmarks, except for Table 1 in the supplementary. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sampling method used to obtain different initializations x_0 is important for convergence to the optimum, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the sampling method should be evaluated on the proposed benchmarks, but it does not specify which benchmarks or how the evaluation should be conducted. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the sampling method used to obtain different initializations x_0, noting that this sampling is important for convergence to the optimum. However, it points out that this sampling is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary. While the comment highlights an area for improvement, it lacks specific guidance on how the authors should address this issue or what additional experiments could be conducted. The feedback is 3 as it directs the authors to consider evaluating the sampling method more thoroughly, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting but not necessary to explore how the model works with tabular data, specifically by considering each attribute dimension as a modality. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore tabular data but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this exploration could be discussed. The authors can infer that it relates to the model evaluation or methodology sections, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding as it does not explicitly mention where in the paper this should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality, would be interesting but not necessary. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this exploration would be beneficial or necessary. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests exploring how the model works with tabular data, specifically by considering each attribute dimension as a modality. This is a valuable suggestion as it could provide insights into the model\"s applicability to different forms of data. However, the comment lacks specific guidance on how to implement this exploration or what aspects of the model should be considered. While it identifies a potential area for improvement, the lack of detailed instructions or examples limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed guidance for the authors to fully address the suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This provides a clear and explicit action for the authors to take, which is to include additional details on using attention in an appendix. The suggestion is concrete, as it specifies the exact location where the additional information should be included, making it 5.", "grounding_specificity_rationale": "The comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, it does not specify which part of the paper discusses attention or where the additional details should be added. This makes the comment weakly grounded, as the authors cannot confidently determine which section is being addressed. The comment is specific in suggesting an appendix as a potential location for the additional details, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why additional details on attention are necessary or how they would benefit the paper. Without such justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper by adding more details on a particular aspect. However, the comment could be more helpful if it elaborated on what specific details would be beneficial or how they could enhance the understanding of the attention mechanism. Despite this, the suggestion is a valuable starting point for the authors to consider, making the comment 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and points out that the pseudocode of the proposed method is missing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve their draft. The comment lacks actionable details, such as recommending specific steps to include the missing pseudocode or explaining why the explicit methods perform better. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"locomotion tasks\" and the \"proposed method,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the performance of explicit methods compared to implicit methods and points out the missing pseudocode of the proposed method. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and mentions the missing pseudocode of the proposed method. However, it does not provide any evidence, reasoning, or references to support the claim that explicit methods perform better. The mention of external references, such as S\u00f8ren Asmussen and Peter W Glynn\"s book and P. Florence et al.\"s paper, suggests that the reviewer is aware of relevant literature, but this does not directly support the claim. Therefore, the comment is 3, as it provides some context but lacks detailed justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and points out that the pseudocode of the proposed method is missing. This feedback is 3 as it identifies a potential gap in the paper that could be addressed to provide a more comprehensive understanding of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what specific aspects of the pseudocode should be included. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from 1 and references 2 to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. While the comment provides some guidance on what needs to be improved, it lacks explicit instructions on how to simplify the result descriptions or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the need for simpler and clearer descriptions of results, specifically mentioning the convoluted nature of some descriptions. It provides a specific suggestion to consider a related idea from 1 and references 2 to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. However, the comment does not explicitly mention which part of the paper these issues pertain to, making it weakly grounded. The suggestions are specific, but without clear grounding, the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the result descriptions are needlessly convoluted and suggests that the authors consider a related idea from 1 and check for useful communication in light of 2. The reviewer provides references to external works, which supports the claim by offering a logical connection to related literature. However, the comment could be strengthened by providing more detailed reasoning or examples of specific convoluted descriptions that need simplification. Overall, the claim is 4 due to the references, but it could be further substantiated with additional details.", "helpfulness_rationale": "The review comment identifies a specific issue with the complexity and clarity of the result descriptions, noting that some are needlessly convoluted. It provides a constructive suggestion by referencing a related idea from 1 and referencing 2 to check for useful communication. The comment also points out that the differences in figures seem too small, but acknowledges that the topography plots indicate something reasonable. This feedback is 4 as it offers actionable steps for simplifying the result descriptions and providing more clarity. However, it could be more helpful if it included specific examples of convoluted descriptions or detailed guidance on how to simplify them. Overall, the comment is 4 as it provides clear and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the experimental validation, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to provide more detailed information about the optimization strategy and consider related works, but the comment lacks specific instructions on how to implement these improvements. Therefore, the comment is 3, as it identifies areas for improvement but does not offer concrete steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental validation\" and \"shallow networks\" being considered, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental validation, such as the lack of description of the optimization strategy and the consideration of layer redundancy in the context of network pruning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing, specifically mentioning the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, such as layer redundancy in the context of network pruning. The reviewer provides a reference to a specific paper that discusses this issue, which adds some level of verification to the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation section, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how to address them. The reference to a specific paper on network pruning could be more helpful if it included suggestions on how to incorporate this work into the experimental validation. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the testing of the bAbI model, specifically asking whether it was only tested on a single supporting fact dataset (Task 1). While the comment implies that the authors should consider testing the model on other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should test the model on additional tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"bAbI\" and \"Task 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the model was only tested on a single supporting fact dataset, which is a clear and specific concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking about the testing of the bAbI model on other tasks beyond Task 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the testing of the bAbI model, specifically asking whether it was only tested on a single supporting fact dataset (Task 1). This is a pertinent inquiry that could help the authors ensure that their model is thoroughly evaluated across different tasks. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback for improvement. Therefore, the comment is 3, as it identifies an area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the authors should improve Section 3.2 by providing more illustrations and examples. This feedback is clear and direct, giving the authors a specific action to take to enhance the clarity and comprehensibility of their draft. The comment provides a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more illustrations and examples to improve the clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Section 3.2 is difficult to follow and recommends providing more illustrations and examples to improve clarity. However, the comment does not provide specific examples or detailed reasoning to support why the section is challenging to understand or how additional illustrations and examples would enhance comprehension. Without these details, the authors may find it difficult to address the issue effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It suggests that the authors might improve the section by providing more illustrations and examples, which could enhance its clarity and comprehensibility. While the comment highlights a clear area for improvement, it lacks specific guidance on what types of illustrations or examples would be most beneficial. This limits the comment\"s helpfulness, as it provides a general direction but does not offer detailed suggestions or examples to guide the authors in making improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that a comparison of the authors\" approach with other LLMs could be included, specifically mentioning the transferability to other LLMs. Additionally, it points out a minor issue with the jailbreaking percentage being low for certain LLMs. While the comment implies that the authors should include this comparison and address the jailbreaking issue, it does not provide explicit instructions or detailed guidance on how to implement these suggestions. The action is clear but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GCG\" and \"their approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison with other LLMs and the issue of low jailbreaking percentages for certain LLMs. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a comparison with other LLMs could be included, as well as addressing the issue of low jailbreaking percentages for certain LLMs. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the jailbreaking percentage is low for certain LLMs. This makes the claim 3, as the authors would need to infer the specific LLMs and jailbreaking percentages to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by recommending the inclusion of a comparison with other LLMs, specifically mentioning the transferability of the authors\" approach. This feedback is valuable as it encourages the authors to expand their work by demonstrating the applicability of their approach to a broader range of LLMs. Additionally, the comment points out a minor issue with the jailbreaking percentage being low for certain LLMs, which could be addressed to improve the robustness of the study. However, the comment could be more helpful if it provided specific guidance on how to conduct the comparison or suggested which LLMs to include. Overall, the comment is 4 as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment points out that the parameter S remains a problem, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps the authors should consider to improve the parameter setting. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the issue of setting the parameter S, but it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the parameter S setting is problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The comment claims that \"How to set the parameter S remains a problem.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific issue with the parameter S, indicating that it remains a problem. However, it lacks any detailed guidance or suggestions on how to address this issue or what specific aspects of the parameter setting are problematic. Without actionable advice or examples, the comment does not provide the authors with a clear path forward to improve their draft. Therefore, it is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that while the introduction claims that shape constraints do not require tuning a free parameter, the choice of employing a convex or concave constraint, and an increasing/decreasing constraint, can be considered a hyperparameter that needs to be chosen or tuned. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to apply the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that shape constraints do not require tuning a free parameter. The comment points out that the choice of convex or concave constraints and increasing/decreasing constraints can be considered hyperparameters that need to be chosen or tuned. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction statement about shape constraints not requiring tuning is technically true but misleading. The reviewer provides a logical reasoning by pointing out that the choice of convex or concave constraints and increasing/decreasing constraints can be considered hyperparameters that need to be chosen or tuned. This reasoning is based on a logical interpretation of the claim and the distinction between constraints and hyperparameters, making the claim 3. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential misconception in the introduction regarding the claim that shape constraints do not require tuning a free parameter. It points out that the choice of convex or concave constraints, and increasing or decreasing constraints, can be considered hyperparameters that need to be chosen or tuned. This feedback is valuable as it highlights a specific area where the authors may need to clarify or correct their claims, ensuring that their work is accurate and clear. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present the constraints in a more accurate manner. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues: the limited scope of datasets and models used in the study and the lack of assessment of other important biases and datasets. It also points out the absence of assessments on stateoftheart generative models like GPT. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should expand their dataset and model selection and include assessments on additional biases and models like GPT. However, the comment lacks concrete suggestions on how to implement these changes or what specific datasets or models should be considered. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the limitations of the datasets and models used in the study, specifically mentioning the bias benchmarks and the absence of assessments on stateoftheart generative models like GPT. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the limitations of the dataset and model selection and the need for additional assessments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the datasets and models used in the study are limited and that the bias benchmarks only assess gender, race, and religion. It also mentions the absence of assessments on stateoftheart generative models like GPT. While the comment identifies specific limitations, it lacks detailed justification or examples to fully substantiate the claim. The authors would need to infer the importance of these assessments and the potential impact on the study\"s conclusions. Therefore, the comment is 3, as it provides some basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant limitation in the study, noting that the datasets and models used are limited and that the bias benchmarks only assess gender, race, and religion. It also points out the absence of assessments on stateoftheart generative models like GPT. This feedback is valuable as it highlights areas where the study could be expanded to include a broader range of biases and models, which would enhance its scope and relevance. However, the comment could be more helpful if it provided specific suggestions on which datasets or models to consider or how to incorporate assessments of generative models like GPT. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies issues with Figure 3, including the unclear workflow and captions, as well as the confusing representation of communication modes on the left side. This provides clear and direct guidance on what needs to be improved, namely the clarity and comprehensibility of the figure. The comment offers concrete suggestions for improvement, making it 5. Authors know exactly what needs to be addressed to improve the figure, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions and the confusing representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as the representation of communication modes on the left side. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks specific references or examples to clarify the issues, making it difficult for the authors to address the feedback effectively. Therefore, the claim is considered 2, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies specific issues with Figure 3, noting that the workflow and captions are unclear and the representation of communication modes on the left side is confusing. This feedback is actionable as it provides the authors with a clear understanding of what needs to be improved in the figure. By addressing these issues, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar figures have been effectively presented. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"learned MASK embedding\" is unclear in the SSL pretraining stage of the proposed method. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this term or what specific actions they should take to address this issue. The comment lacks actionable details, such as recommending a definition or clarification of the term, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SSL pretraining stage\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"learned MASK embedding,\" which is unclear in the context of SSL pretraining. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"learned MASK embedding\" is unclear in the SSL pretraining stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to explain why this term is unclear or how it could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the term \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. This is a clear and actionable point that can help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the term or offered examples of how it might be defined or explained. Overall, the comment is 3 as it points out a specific area for improvement but lacks detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This guidance is clear and specific, giving the authors a direct action to take. The comment also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the importance of error analysis and its role in evaluating model performance and identifying potential issues. It also encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This provides clear guidance on what needs to be addressed, making the comment fully grounded. The comment is specific because it clearly specifies the need for error analysis and its importance in guiding subsequent improvements and expansions of the ERC research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This claim is 3 as it logically supports the importance of error analysis in the context of model evaluation and improvement. However, the comment lacks specific examples or references to substantiate the claim fully. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of error analysis in evaluating model performance and identifying potential issues, and encourages the authors to conduct such analysis and provide detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their draft by incorporating error analysis, which can significantly aid in guiding subsequent improvements and expansions of the ERC research. However, the comment could be more helpful if it included specific examples or suggestions on how to conduct the error analysis or what aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the authors claim their work as preliminary but question the NLPspecific aspects of their approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of their approach should be revised to better align with an NLPspecific focus. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the claim made by the authors regarding their work being preliminary and discusses the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspect of the approach is lacking in being NLPspecific. Without clear guidance on where the issue is located or what needs to be addressed, the authors cannot effectively improve their draft. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors claim their work as preliminary but question the NLPspecific aspects of their approach. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a discrepancy between the authors\" claim of their work as preliminary and the lack of NLPspecific aspects in their approach. However, it does not provide any constructive feedback or suggestions on how the authors might address this issue or improve their draft. Without actionable advice or guidance, the comment offers limited value to the authors in terms of improving their work. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods, noting that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superiority of the proposed method may be due to the largerscale datasets. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors can infer that they should consider the impact of dataset size on performance and potentially adjust the comparison with SOTA methods. However, the comment lacks concrete steps or suggestions on how to conduct this adjustment or what specific aspects of the comparison should be revised. Therefore, the comment is 3, as it points out an issue but does not provide detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with stateoftheart (SOTA) methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This provides clear guidance on what needs to be addressed, namely the fairness of the comparison with SOTA methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods may be unfair due to the difference in dataset size. The reviewer provides a logical reasoning by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This observation highlights a potential issue with the comparison, suggesting that the superiority of the proposed method may be due to the largerscale datasets. However, the comment lacks specific examples or references to existing methods or datasets to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the proposed method with stateoftheart (SOTA) methods. It points out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This observation highlights a potential bias in the comparison, as the superiority of the proposed method may be due to the largerscale datasets. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a fairer comparison method or suggesting ways to adjust the dataset size for a more accurate comparison. While the comment raises an important point, it lacks actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add supportive references for the claims made in the paper, specifically mentioning Lines 5564. It highlights that many of the factors mentioned have been discussed in existing studies, providing a clear action for the authors to take. The comment is explicit and concrete, as it specifies the exact section and the need for references, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to add supportive references for the claims made in the paper. This provides clear guidance on how to improve the draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some claims may be inspired by existing studies and suggests that it is critical to add supportive references. The reviewer provides a specific example by referencing lines 5564, where the factors affecting the performance of chainofthought prompting are discussed. However, the comment lacks specific references to the existing studies that support these claims, making it 3. The authors would need to infer the references themselves, which could be challenging without explicit citations. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that some claims may be inspired by existing studies and suggesting that supportive references are necessary. It provides a specific example by referencing lines 5564, where the factors affecting the performance of chainofthought prompting are discussed. This feedback is clear and actionable, as it directs the authors to include references to support their claims. However, the comment could be more helpful if it suggested specific studies or references to include, which would provide the authors with a more comprehensive understanding of the existing literature. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance the rigor and credibility of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the first paragraph of the Introduction is not central to the paper and provides little valuable information. It suggests that the focus on DNNs is not relevant to the paper\"s core focus on detecting drift types and magnitude. The comment implies that the authors should reconsider the content and relevance of this paragraph, but it does not provide specific guidance on how to revise it or what alternative content could be included. The action is implicit and somewhat vague, as the authors need to infer the exact changes required to improve the draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic: the lack of mention of drift in the introduction, which is central to the paper\"s focus. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is not central to the paper and provides little valuable information. This claim is 3 as it logically argues that the introduction of DNNs is not relevant to the paper\"s core focus on detecting drift types and magnitude. However, the comment lacks specific examples or references to support the claim, making it 3. The authors may need to infer the relevance of the DNN introduction themselves, which could lead to some confusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the paper\"s core focus. This feedback is clear and actionable, as it suggests that the authors should reconsider the relevance and content of this paragraph to ensure it aligns with the paper\"s central theme. By addressing this issue, the authors can improve the clarity and focus of their introduction, making the paper more effective for its intended audience. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. While the comment implies that the authors should consider using more advanced prompting techniques, it does not provide specific guidance on how to implement this suggestion or what criteria to use for selecting prompts. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, suggesting that it is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. The suggestion to use carefully curated prompts is specific, but without clear grounding, the authors may struggle to identify the exact section that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It suggests that using carefully curated prompts can lead to better results in generating systematic reviews. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as the authors would need to infer the basis of the critique and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the study, namely the basic nature of the prompting technique used and its failure to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment highlights an important area for improvement, it lacks specific guidance on how to implement this suggestion or what criteria to use for selecting prompts. This limits the comment\"s helpfulness, as it provides a general direction but does not offer detailed steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue, such as suggesting ways to improve the method on larger backbones or providing specific examples of how to test the method on different models. The action is implicit and somewhat vague, as the authors can infer that they need to consider testing on larger backbones but are not given clear steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. It also suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the relative gains and the potential impact of the global pooling structure, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to further explore the issue themselves to understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that the relative gains are not very strong, even on smaller backbone models like ResNet50. It suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as suggesting ways to improve the method on larger backbones or providing examples of how to test the method on different models. While the comment highlights a potential weakness, it lacks actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the rigor of the evaluation given the limited number of datasets for each task (5, 6, and 4) and the potential issue of some datasets being too large for all algorithms. It suggests that having more datasets might be necessary for a thorough evaluation. However, the comment does not provide specific guidance on how to address this issue or what additional datasets should be considered. The authors are left to infer that they should consider adding more datasets, but without concrete details on which datasets to include or how to implement this change, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the rigor of the evaluation by questioning the number and choice of datasets used for the tasks. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough for a thorough evaluation, particularly if some datasets are too large for all algorithms. The comment is specific in its critique of the dataset selection and provides a rationale for why additional datasets might be necessary. However, it does not explicitly mention which datasets are problematic or how the authors could address this issue. Therefore, the comment is weakly grounded as it does not specify the exact parts of the paper being addressed, but it is specific in its critique. This aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the rigor of the evaluation given the limited number of datasets for each task (5, 6, and 4) and the potential issue of some datasets being too large for all algorithms. The reviewer suggests that having more datasets might be necessary for a thorough evaluation. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the need for additional datasets. The suggestion is based on logical reasoning but lacks specific examples or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the rigor of the evaluation, given the limited number of datasets for each task (5, 6, and 4) and the potential issue of some datasets being too large for all algorithms. It suggests that having more datasets might be necessary for a thorough evaluation. However, the comment does not provide specific suggestions on how to address this issue or which datasets should be considered. While it identifies a potential weakness, the feedback lacks actionable guidance or detailed advice on how to improve the evaluation. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment identifies two main issues: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific guidance on how to address these issues or what aspects of the proof or discussion are confusing. It lacks concrete details on how to improve the clarity or depth of the paper. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies specific issues with the proof of the main results, suggesting that there are confusing mistakes. However, it does not specify which part of the proof is confusing or where the mistakes are located. Additionally, it mentions the lack of a detailed discussion and comparison with previous work, but again does not specify which sections or aspects are missing. The comment also suggests that the paper lacks new insights, but does not provide specific examples or details to support this claim. Overall, the comment is 1 and lacks specificity, making it difficult for the authors to understand and address the issues. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there are \"confusing mistakes\" in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. Additionally, it suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of specific examples or references makes the claim 1, as it does not provide sufficient evidence or justification to support the claims. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed guidance on how to address these issues or what aspects of the proof or discussion are confusing. Without actionable feedback or suggestions for improvement, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses several issues related to the motivation, experimental results, and comparison of the proposed model. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment does provide some specificity by mentioning the addition of CAT and GAN, which could be used to guide the authors in identifying the relevant sections. Overall, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in identifying the issues. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the motivation for using an adversarial network is unclear and that the experimental results are unfair. It also suggests that the proposed model is equipped with a larger CAT and GAN, which could be considered an unfair comparison. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network and the unfairness of the experimental results. It also points out that the proposed model is equipped with a larger CAT and GAN, which could be considered an unfair comparison. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is 3 as it directs the authors\" attention to potential weaknesses, but it lacks actionable advice or detailed guidance on how to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the reliability of the results or what specific steps to take to validate them. As a result, the authors are left without clear direction on how to improve the draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, particularly the MSE being significantly smaller than the MAE, which raises concerns about their validity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results and highlights a potential weakness in the paper. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the reliability of their experimental results. Without specific recommendations or examples, the feedback lacks depth and does not fully support the authors in improving their draft. Therefore, the comment is rated as 2, as it points out a problem but does not offer a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific techniques or approaches to incorporate adversarial loss or explaining why it is necessary. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where this is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the adversarial loss are missing or how it could be incorporated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is no adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, noting the absence of adversarial loss to ensure that perturbed data is similar to authentic data. This is a relevant point that could impact the validity and reliability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or incorporate adversarial loss. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the verylongterm forecasting task is of limited practical significance and that the discussion requires improvement. It explicitly recommends conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments and adjusting the model training to improve the context of their results. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment addresses the issue of the verylongterm forecasting task being of limited practical significance and suggests that the discussion requires improvement. However, it does not specify which part of the paper discusses this task or the specific aspects that need improvement. The authors can infer that it relates to the discussion section, but the comment lacks full grounding as it does not explicitly mention the section. Additionally, while it suggests conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon, it does not provide detailed guidance on how to implement these improvements. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests that the discussion requires improvement. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the task is of limited practical significance or how the discussion could be improved. Without specific examples or detailed explanations, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the limited practical significance of the verylongterm forecasting task. It suggests that the discussion requires improvement by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback is clear and actionable, providing the authors with specific steps to enhance the relevance and practical significance of their work. However, the comment could be more helpful if it explained why the current discussion is insufficient or how the suggested improvements would impact the paper\"s contribution. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or methods to ensure privacy protection. As a result, the authors are left without a clear understanding of what steps to take to improve their draft in this area. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of analysis on the security (protection of privacy) of the proposed framework. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection where the analysis should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue of security analysis, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, noting that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. This is a critical oversight that could impact the overall robustness and trustworthiness of the work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending particular analyses or methods to ensure privacy protection. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that \"Memb\" is mentioned as the previous stateoftheart but there is no reference provided. This implies that the authors should include a reference to the work that Memb is based on. However, the comment does not specify which work or where the reference should be added, leaving the authors with a vague understanding of what needs to be done. The action is explicit in identifying the missing reference, but it lacks concrete guidance on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment mentions \"Memb\" as the previous stateoftheart, but it does not specify which part of the paper this claim is made in. Without explicit references to sections or figures, the authors cannot confidently determine where this claim is being made. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the reference to Memb. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"Memb\" is mentioned as the previous stateoftheart but lacks a reference to any work. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential oversight in the paper, noting that \"Memb\" is mentioned as the previous stateoftheart but no reference is provided. This is a clear and actionable observation that can help the authors improve the clarity and accuracy of their work. However, the comment lacks specific guidance on which reference should be included or how to address this issue. While it identifies a critical area for improvement, it could be more helpful with additional details or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difficulty of finding examples that illustrate the loss principles clearly, and it specifically questions the weaknesses of the proposed FSR metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the difficulty of finding examples that illustrate the loss principles clearly, and it specifically questions the weaknesses of the proposed FSR metric. However, it does not specify which part of the paper or supplement this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the examples and the weaknesses of the FSR metric, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difficulty of finding examples that illustrate the loss principles clearly, and it questions the weaknesses of the proposed FSR metric. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without specific examples or detailed explanations, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the difficulty of finding examples that illustrate the loss principles clearly, which is a valid point. It also questions the weaknesses of the proposed FSR metric, which is a constructive critique. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or examples, the authors may find it challenging to understand and implement the necessary improvements. Therefore, the comment is 3, as it identifies areas for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the quality of paraphrases generated for training data, specifically noting that the paraphrases need to be sufficiently different from the original sentences. It suggests that this impacts the subsequent steps in the process, as the model relies heavily on the quality of these paraphrases. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve the quality of the paraphrases. While the action is implied, it is not detailed enough for the authors to know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the process of generating paraphrases for training data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear paraphrases and how this impacts the quality of the final training data. The comment provides a clear rationale for the concern, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paraphrases generated for training data are unclear and impact the quality of the final training data. This claim is 3 as it logically follows that if the paraphrases are not sufficiently different from the original sentences, the quality of the training data could suffer. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the comment does not provide detailed guidance on how to improve the paraphrases. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the quality of paraphrases generated for training data, noting that the paraphrases need to be sufficiently different from the original sentences. This is crucial because the model\"s reliance on these paraphrases affects the quality of the final training data. The comment highlights the potential consequences of using paraphrases that are not sufficiently different, which could lead to lowquality training data and a reduced number of pairs added to the new training data. This feedback is clear and actionable, as it provides the authors with a specific area to focus on to improve the quality of their training data. However, it could be more helpful if it offered suggestions on how to measure or evaluate the difference between paraphrases and original sentences. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific actions they should take to improve their draft. The comment lacks explicit or implicit actions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, nor does it provide any context or background information that would help the authors identify the relevant section. Without explicit references or context, the authors cannot confidently determine which part of the paper needs attention. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the concatenation of text input by the four text elements of an object. While it highlights a potential area of interest, it lacks any guidance or suggestions on how the authors might address this question or what implications it might have for their work. Without actionable feedback or context, the comment does not provide the authors with a clear path forward in improving their draft. Therefore, it is 1."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper should provide a stronger motivation for why the topic is important. However, it does not specify what kind of motivation is needed or how it should be presented. The authors are left to infer that they need to include a motivation section, but without concrete guidance on what to include or how to structure it, the action remains vague. Therefore, this comment is 3, as it implies an action but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not specify which part of the paper this issue pertains to, such as the introduction or the main results section. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this suggestion. Additionally, the comment lacks specificity regarding what kind of motivation is needed or how it should be presented. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not provide any specific reasoning or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to achieve this motivation or what kind of motivation would be effective. Without actionable advice or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it points out an area for improvement but does not offer sufficient guidance for the authors to act upon it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative comparisons that might be more fair. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their comparisons, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the domainspecific model being trained on Pix3D and the experiments being conducted on Pix3D, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the comparisons to zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparisons between the domainspecific model and zeroshot singleimage 3D reconstruction models are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these comparisons are unfair. Without additional context or explanation, the claim remains 1, as it lacks the necessary information to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This feedback highlights a potential bias in the experimental setup that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the bias in their comparisons. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. While the suggestion is clear, it lacks specific guidance on how to conduct these experiments or what specific aspects of the C2D method should be tested on these datasets. The authors are left to infer that they should conduct these experiments, but without detailed instructions on how to implement them, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting the need for additional experiments but lacks grounding as it does not explicitly mention which part of the paper should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the method. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This is a clear and actionable suggestion that could enhance the robustness and generalizability of the method. However, the comment lacks specific guidance on which aspects of the C2D method should be tested or how these experiments should be designed. While it points to a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. It also mentions minor problems, but does not provide further details or suggestions for improvement. The comment implies that the authors should clarify this aspect of their methodology, but it lacks explicit guidance on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the grid search process but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grid search of learning rate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking whether the grid search is performed on the validation set, providing clear guidance on what needs to be clarified. However, the comment does not provide specific suggestions or examples on how to improve the clarity or accuracy of this part of the paper. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking about the grid search for learning rate, specifically whether it is performed on the validation set. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. This is a relevant point that could impact the robustness and generalizability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for clarification, it does not offer actionable advice or detailed feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they need to consider diversity but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. However, it does not provide any supporting evidence, reasoning, or references to justify why this diversity is important or how it might impact the results. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. This is a relevant and insightful point that could help the authors consider the broader implications of their findings and ensure that their work is inclusive and applicable to diverse populations. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional analyses or discussions. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific properties of Z should be considered or how to address the issue of nonconvexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 182184,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it specifies the issue of nonconvexity and suggests that it may not be a problem if the function Z has certain properties. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. However, the comment lacks any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific line in the paper (ln. 182184) and suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. While this feedback highlights a potential issue, it lacks depth and does not provide specific guidance or examples of what properties of Z would be beneficial for convergence. The comment could be more helpful if it offered suggestions on how to explore or test these properties, or if it provided references to similar studies or literature. As it stands, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues: the lack of proper experimental settings and the absence of code. While it points out the importance of result reproducibility, it does not provide specific guidance on how to address these issues. The authors are left to infer that they need to include detailed experimental settings and provide the code, but the comment lacks concrete steps or examples on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental settings\" and the absence of \"code,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for proper experimental settings and the provision of code to ensure result reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly and that the result reproducibility is critical. It also notes the absence of code, which is a significant concern. However, the comment does not provide specific examples or detailed reasoning to support why the experimental settings are not mentioned or how the lack of code affects result reproducibility. This makes the claim 3, as the authors would need to infer the importance of these issues and potentially conduct additional research to fully understand the implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental settings and the absence of code, which affects the reproducibility of results. It highlights the importance of providing detailed experimental settings and code to ensure the reliability of the findings. However, the comment does not offer specific suggestions or guidance on how to address these issues, such as recommending particular experimental settings or code sharing practices. While it points out a significant problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not provide specific guidance on how to improve the clarity or what aspects of the motivation should be emphasized. The comment lacks concrete details or suggestions on how to enhance the explanation, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making it difficult for the authors to determine exactly what steps to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this topic is discussed, the comment lacks full grounding. It is specific in suggesting that the motivation needs clarification, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the clarity of the motivation behind applying CMD in federated learning. It suggests that the motivation could benefit from a more explicit demonstration or explanation. While the comment highlights an area for improvement, it lacks specific guidance on how to enhance the clarity or what aspects of the motivation should be emphasized. The feedback is 3 as it points out a potential issue, but it does not provide actionable steps for the authors to address it. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform and suggesting that comparisons to UNets are necessary. While the comment identifies a potential issue with the model, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should make comparisons to UNets, but the comment lacks specific instructions on how to conduct these comparisons or what aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed CoNO model\" and the \"complex UNet part after the fractional transform,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the contribution of the UNet part and suggests comparisons to UNets, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the contribution of the UNet part in the CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the claimed performance boost. The reviewer references external works, such as Raonic et al and Gupta et al, to support their claim about the strong performance of UNets on regular gridded domains. This provides a logical basis for the claim, but the comment could be strengthened by providing more detailed comparisons or examples from the referenced works. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform. It suggests that the authors should make comparisons to UNets, as UNets have shown strong performance on regular gridded domains. This feedback is 3 as it points out a potential area for improvement and provides a rationale for why such comparisons are necessary. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. While the comment implies that the authors should consider including more details about these experiments in the main text, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they should provide more information but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment appreciates the inclusion of a comprehensive Appendix and acknowledges the additional detail it provides. However, it does not specify which part of the paper the Appendix is attached to, making it weakly grounded. The comment also mentions the Brusselator as an example of an additional experiment, but it does not specify which part of the Appendix this experiment is discussed in. This lack of specificity makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This statement is a factual observation about the reviewer\"s experience and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment appreciates the inclusion of a comprehensive Appendix and acknowledges the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This feedback highlights a potential limitation in the paper, as it suggests that the main text may not fully convey the significance or results of these experiments. While the comment identifies an area for improvement, it does not provide specific suggestions or guidance on how to address this issue. The authors are left with a general understanding of the need to include more information in the main text, but without detailed guidance on how to achieve this. Therefore, the comment is 3, as it points out a potential weakness but lacks actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that W1 and W2 are not defined, and it speculates that they might denote the Encoder and Decoder networks. It also mentions that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and directs the authors to define these terms, which is a concrete action for them to take. The comment is 5 as it provides specific guidance on what needs to be clarified or defined in the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W1 and W2\" and \"W and V,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that these terms are not defined, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"W1 and W2 are not defined\" and speculates that they might denote the Encoder and Decoder networks. It also mentions that \"W and V\" are not defined, providing references to specific pages and equations. However, the comment lacks detailed reasoning or examples to support why these terms should be defined or how they are relevant to the paper. While the references provide some context, the claim could be strengthened with additional explanation or examples. Therefore, the comment is 3, as it provides some support but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that W1 and W2 are not defined and speculating that they might denote the Encoder and Decoder networks. It also points out that W and V are not defined in the same context, providing specific references to page 3, line A4, and equation 3. This feedback is clear and actionable, as it directs the authors to clarify these terms and their definitions. By addressing this issue, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it offered suggestions on how to define these terms or provided examples of how they might be used in the context of the paper. Overall, the comment is 4 as it effectively guides the authors to improve the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the authors\" understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It also points out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the formulation. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider their assumptions about the observations and their aggregation process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the integral in Equation (1)\" and references specific works, \"Law et al., NeurIPS\"18\" and \"4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the integral in Equation (1) corresponds to the bag observation model in Law et al., NeurIPS\"18 or the spatial aggregation process in 4. The reviewer provides references to these works, which supports the claim by referencing established models and processes. However, the comment lacks detailed explanation or analysis of why these references are relevant to the current work or how they impact the authors\" understanding of their formulation. While the references provide some context, the comment could be strengthened by further elaboration on the implications of these references for the authors\" work. Therefore, the comment is 3, as it provides some support but lacks detailed justification or explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It points out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. The comment provides a clear and actionable suggestion for the authors to reconsider their assumptions about the observations and their aggregation process. However, it could be more helpful if it offered specific guidance on how the authors might address this issue or what alternative aggregation methods might be considered. Overall, the comment is 4 as it highlights a critical area for improvement and provides a direction for the authors to explore, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. While the comment implies that the authors should modify their experimental setup, it does not provide explicit instructions on how to implement this change or what specific tasks to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or the discussion of the results. The authors can infer that it relates to the latter part, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks full grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the setting with a fixed policy is a subset of reinforcement learning and proposes that tasks could be made more complex to test the policy\"s adaptability. However, the comment lacks specific examples or references to support this claim or to justify why the current setting is insufficient. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the suggestion. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. This feedback is 3 as it identifies a potential area for improvement in the experimental setup. However, the comment lacks specific guidance on which tasks to consider or how to implement this change. Additionally, it does not provide detailed reasoning or examples to support the suggestion, which limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to establish this relationship or what specific steps to take to improve the study. As a result, the authors are left without any clear direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the study, namely the lack of establishment of the relationship between the top selected patches and the disease. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this relationship should be discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the relationship need to be established or how the authors might address this issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the study, noting that the relationship between the top selected patches and the disease is not yet established. This is a critical point that could impact the validity and reliability of the study. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to establish this relationship. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is 3, as it points out a critical area for improvement but does not provide enough detail for the authors to fully address it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with 5 being unfair because 5 is designed for a more complex problem. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the evaluation. The comment lacks actionable details, such as suggesting alternative evaluation methods or providing specific examples of how the comparison could be improved. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the numerical evaluation and the comparison with 5, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation, noting that the method is only evaluated on synthetic data and that the comparison with 5 is not fair due to the complexity of the problem. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with 5 being unfair. The reviewer supports this claim by explaining that 5 is designed for a more complex problem, specifically mentioning the absence of knowledge of camera pose parameters. This provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the complex problem addressed by 5, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with 5 is unfair due to the complexity of the problem addressed by 5. This feedback is valuable as it highlights a potential weakness in the paper\"s evaluation, which could impact the credibility of the results. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as suggesting alternative evaluation methods or explaining why the comparison with 5 is unfair. Despite this, the comment still offers a clear direction for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two concerns: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they need to clarify the use of \u03b2 and the difference between QRS and RS, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the proposed relaxation of rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. The comment provides a clear direction for improvement by suggesting that the authors clarify the use of \u03b2 and the difference between QRS and RS. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the use of an arbitrary parameter \u03b2 in rejection sampling and questions the lack of clarity regarding the difference between QRS and RS in Algorithm 1. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the authors should have used Importance sampling instead of rejection sampling. Additionally, the comment lacks specific examples or detailed explanations to support the claim about the difference between QRS and RS. As a result, the claim is not 5, making it difficult for the authors to understand and address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial if it offered actionable steps or examples to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the comparison in terms of computation cost or running time. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific aspects of the computation cost or running time should be compared, nor is there any suggestion for how the authors might address this issue. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the computation cost or running time should be compared or how the authors might address this issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the comparison in terms of computation cost or running time, but it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment poses a question about the comparison in terms of computation cost or running time, which could be an important aspect of the paper. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or what aspects of the computation cost or running time should be compared. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of comparison against baselines and notes that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. It suggests that this is a widelyunderstood binary analysis application and that many papers have developed architectureagnostic similarity comparison (or codesearch). While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include comparisons against baselines, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it identifies an area for improvement but does not offer specific steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of comparison against baselines and the need for architectureagnostic similarity comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparison against baselines and that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. The reviewer supports this claim by referencing the widelyunderstood nature of binary analysis applications and the existence of architectureagnostic similarity comparison (or codesearch) in many papers. This provides a logical basis for the claim, but it could be strengthened with specific references to these papers or examples of how other studies have addressed this issue. Therefore, the comment is 4, as it provides a reasonable basis for the claim but lacks detailed examples or references to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of comparison against baselines and the limited scope of the functionality similarity comparison study. It highlights that this is a widelyunderstood binary analysis application and that many papers have developed architectureagnostic similarity comparison (or codesearch). This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific suggestions on how to address this gap, such as which baselines to consider or how to extend the current study to include them. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. While it identifies the issue, it does not provide explicit guidance on how the authors should address this discrepancy. The comment lacks concrete suggestions or actions for the authors to take, such as suggesting a correction or clarification in the abstract or text. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and the text, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract statement about requiring the proposal distribution to upper bound the target everywhere is not true, as the authors themselves clarify in the text. However, the comment does not provide specific references or examples from the text to support this claim, making it difficult for the authors to verify the accuracy of the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This is a critical issue that could impact the validity of the paper\"s claims. However, the comment does not provide specific guidance or suggestions on how the authors might address this discrepancy or clarify the text. While it points out a potential problem, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an important issue but does not fully support the authors in resolving it."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, indicating that the authors need to clarify or provide more context for this section. However, it does not offer any specific guidance or suggestions on how to address this issue. The action is implicit and vague, as the authors are left to infer that they need to provide more information or clarification about the section. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the intent of this section, indicating that the authors need to clarify or provide more context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking about the intent of Section 5.2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, indicating that the authors need to clarify or provide more context for this section. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The comment is 3 as it points out a potential gap in the paper, but it does not provide actionable advice or detailed feedback to help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. It acknowledges that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not provide specific guidance on what aspects need clarification or how to clarify them. It lacks concrete suggestions or examples of what the authors should focus on to improve the clarity of their approach. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights that many aspects of the approach need clarification and expresses concern about the interaction between knowledge about objects and verbs. It mentions that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not specify which parts of the paper need clarification or provide detailed comments. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in identifying the need for clarification but lacks grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that many aspects of the approach need clarification and expresses concern about the interaction between knowledge about objects and verbs. It suggests that the paper lacks a clear explanation of the overall approach and its benefits, diving into technical details too quickly. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies several areas where the paper needs clarification, particularly regarding the interaction between knowledge about objects and verbs in the approach. It expresses concern about the lack of a clear explanation of the overall approach and its benefits, noting that the paper dives into technical details too quickly without providing a comprehensive understanding. While the comment highlights important areas for improvement, it does not offer specific suggestions or guidance on how to clarify these aspects. The authors are left with a general sense of what needs to be addressed but without actionable steps to improve their draft. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the chatgpt baseline is rudimentary and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. While the comment provides a clear action to test a fewshot approach and includes a suggestion for enhancing the baseline, it lacks specific guidance on how to implement these changes or what specific aspects of the fewshot approach should be tested. The authors are given a general direction but may need to infer the details of execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the chatgpt baseline, suggesting that it is rudimentary and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. However, the comment does not specify which part of the paper discusses the chatgpt baseline or the fewshot approach, making it weakly grounded. The suggestion to include discourse relation information is specific, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the chatgpt baseline is \"very rudimentary\" and suggests testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. While the comment provides a logical reasoning for the suggestion to test a fewshot approach, it lacks specific examples or references to support the claim that the chatgpt baseline is \"very rudimentary.\" The suggestion to include discourse relation information is 3, as it provides a direction for improvement but lacks detailed justification or examples. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the chatgpt baseline, suggesting that it is \"very rudimentary\" and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. This feedback is clear and actionable, as it provides a concrete direction for improvement by suggesting a more comprehensive evaluation of the chatgpt baseline. However, the comment could be more helpful if it included specific examples or references to support the claim about the rudimentary nature of the baseline or the potential benefits of the fewshot approach. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors did not provide information on the number of parameters used in each approach in Section B.3. This is a clear and direct request for additional information, which the authors can easily address by including this detail in their draft. The action is explicit and concrete, as it specifies exactly what needs to be added to improve the clarity of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information on the number of parameters used in each approach. This provides clear guidance on what the authors need to add to improve the clarity of their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment is a request for clarification regarding the number of parameters used in each approach in Section B.3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the lack of information on the number of parameters used in each approach in Section B.3. This feedback is clear and actionable, as it directs the authors to provide this missing information to improve the clarity of their work. By addressing this point, the authors can enhance the transparency and accessibility of their methodology. However, the comment could be more helpful if it provided suggestions on how to present this information effectively or offered guidance on potential impacts of varying parameter counts. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation results in Table 1 are based on only three trials for each case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense due to the small sample size. While the comment identifies a specific issue with the evaluation results, it does not provide explicit guidance on how to address this issue or improve the analysis. The authors are left to infer that they should reconsider the statistical significance of their results and potentially increase the number of trials. Therefore, the comment is 3, as it identifies an issue but lacks concrete instructions on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation results, noting that the three trials per case are not statistically significant and that the deviations reported are not meaningful. The comment further explains why this is problematic, suggesting that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense due to the small sample size. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are based on only three trials per case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense due to the small sample size. The comment provides a logical reasoning by explaining the statistical significance of the results and the implications for the authors\" claims. However, it could be strengthened by providing specific references or examples to support the claim about statistical significance. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation results presented in Table 1, noting that the analysis is based on only three trials per case, which is not statistically significant. This observation is important as it highlights a potential weakness in the study\"s methodology and the validity of the results. The comment also points out that the deviations reported are often zero, which undermines the authors\" claims of superior performance. By addressing this issue, the authors can improve the robustness and credibility of their findings. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a larger sample size or alternative statistical tests. Overall, the comment is 4 as it identifies a critical area for improvement but lacks detailed guidance on how to resolve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This implies that the authors should provide a more detailed explanation of the architecture in their paper. However, the comment does not specify which parts of the paper need more detail or how to present the architecture information. While the action is implied, it is not explicitly stated, and the lack of concrete guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear explanation of the architecture and the reliance on external work for details. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This suggests that the paper lacks selfcontainment. However, the comment does not provide specific examples or references to the architecture or the external work, making it difficult for the authors to understand the exact issue and address it. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the specifics of the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained and that the authors rely on external work for details. This lack of selfcontainment makes the paper less accessible to readers who may not be familiar with the referenced work. The comment provides a clear and actionable suggestion for improvement, encouraging the authors to include more detailed explanations of the architecture in their paper. However, it could be more helpful if it offered specific guidance on how to present this information or what aspects should be emphasized. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the presentation quality of the paper, such as the lack of informative content in certain tables and figures, the management of Fig. 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. While the comment highlights these areas for improvement, it does not provide explicit instructions or concrete guidance on how to address these issues. The authors are left to infer that they need to improve the presentation quality, but without specific suggestions on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures and tables, such as Figs 1&2, the \"Dataset\" columns in the tables, and Table 1 with a \"*\" appearing without indication of meaning. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issues with the presentation quality, such as the lack of informative content in certain tables and figures, the management of Fig. 3 and Table 2, and the use of a \"*\" in Table 1 without explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific issues with the presentation quality of the paper, such as the lack of informative content in certain tables and figures, the management of Fig. 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. These claims are supported by specific examples, which provide a clear rationale for the reviewer\"s concerns. However, the comment could be strengthened by providing more detailed explanations or references to similar issues in highquality publications, which would further substantiate the claim. Overall, the comment is 4, as it offers a thorough basis for the critique but lacks additional evidence or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies specific issues with the presentation quality of the paper, such as the lack of informative content in certain tables and figures, the management of Fig. 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. This feedback is clear and actionable, as it points out specific areas where the paper could be improved in terms of clarity and professional presentation standards. By addressing these issues, the authors can enhance the quality of their paper and increase its chances of being accepted for publication. However, the comment could be more helpful if it provided suggestions on how to improve the presentation quality or offered examples of best practices in academic publishing. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiomspecific and that the results merely indicate that better NMT systems are better at idiomatic translations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. It lacks concrete steps or detailed advice on how to make the methods more idiomspecific or how to improve the results. As a result, the authors are left without clear direction on how to address the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed upweighing and KNN methods\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the methods are not idiomspecific and that the results indicate that better NMT systems are better at idiomatic translations. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods are not idiomspecific and that the results indicate that better NMT systems are better at idiomatic translations. The comment supports this claim by referencing \"Figure 3,\" which presumably shows the impact of the methods on idiomatic vs. random data. However, the comment does not provide detailed analysis or specific examples from the figure to substantiate the claim fully. While the reference to Figure 3 suggests that the claim is based on empirical evidence, the lack of detailed explanation or additional context makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiomspecific and that the results merely indicate that better NMT systems are better at idiomatic translations. While the comment identifies a potential weakness in the methods, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methods to be more idiomspecific. The feedback is 3 as it points out a potential limitation, but it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to cite and discuss important references for domain adaptation in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for references and discussions on domain adaptation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, namely references and discussions on domain adaptation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact references that are missing. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of important references for domain adaptation. It explicitly instructs the authors to cite and discuss these references in the revised manuscript. This feedback is clear and actionable, providing the authors with a direct and specific way to enhance the paper\"s comprehensiveness and relevance. By addressing this issue, the authors can significantly improve the quality and depth of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the claim about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the claim. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to improve their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about treating climate emulation as a diagnostictype prediction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is misleading about the claim, namely that prior work (e.g., ClimateBench or ClimateSet) already does this. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, the comment does not provide specific examples or references to these works, nor does it explain how they address the issue. Without detailed evidence or references, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a misleading claim in the paper regarding the treatment of climate emulation as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, already addresses this issue. This feedback is valuable as it highlights a potential oversight or misrepresentation in the paper, which the authors can address to improve the accuracy and clarity of their claims. However, the comment could be more helpful if it provided specific examples or references to the prior work that already addresses this issue, which would guide the authors in making the necessary corrections. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more actionable with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should change the notation, provide additional clarification, or revise the terminology. As a result, the comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems, which is confusing. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the confusion regarding the use of \"r\" for both risks. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is confusing or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and actionable observation that can help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending alternative notations or explaining the context in which these terms are used. Overall, the comment is 4 as it points out a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to improve the table or what specific changes could be made to enhance the information presented. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the factors in a table do not effectively convey more messages than pure text, and there is no additional information. However, it does not specify which table or part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the table\"s effectiveness, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific issue with the table, suggesting that the factors do not effectively convey more messages than pure text, as there is no additional information. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the table\"s effectiveness. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it identifies a weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the authors\" approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"pruning\" and \"distributed settings,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential need to find global top Q values of the metric over the average of gradients, which could impact acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients. This is a logical claim based on the observation that pruning is often used with large networks and that distributed settings are common for training. However, the comment lacks specific examples or references to support the claim that finding global top Q values is necessary to avoid breaking acceleration techniques like quantization and sparsification. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. This feedback is valuable as it highlights a potential gap in the authors\" discussion of pruning techniques and their impact on distributed settings. However, the comment could be more helpful if it provided specific examples or references to support the claim about the necessity of global top Q values. Overall, the comment is 3 as it directs the authors\" attention to an important aspect of their work that requires further consideration."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific changes should be made to the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the claim regarding the existence of multiple entities in both sentences and documents, including relation classification. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the existence of multiple entities in both sentences and documents, including relation classification. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. This is a clear observation that could lead to a more accurate understanding of the context and scope of the work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their claims. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about how the proposed method compares with prior art. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so or offer guidance on how to conduct the comparison. The action is implicit and somewhat vague, as the authors can infer that they need to address this issue but may not be entirely sure of the specifics. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the comparison with prior art is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison with prior art. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about how the proposed method compares with prior art. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the comparison of the proposed method with prior art. While it highlights an important area for the authors to address, it does not provide any guidance or suggestions on how to conduct this comparison or what specific aspects to focus on. The comment lacks actionable feedback or detailed advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as 2, as it identifies an area for improvement but does not offer sufficient guidance for the authors to act upon."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the RQ1 mentioned in the paper is redundant and does not provide additional information. It also proposes an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reviewer provides a specific reference to a related work that could guide the authors in conducting this analysis. While the comment implies that the authors should reconsider their RQ1 and explore the proposed analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1\" and \"RQ2\" and \"RQ3 tsne plots,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the redundancy of RQ1 and the potential analysis on the effect of explicit hate information on implicit hate speech detection performance. The comment provides a reference to a related work, which is helpful in guiding the authors on how to proceed with their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the RQ1 mentioned in the paper is redundant and does not provide additional information. It suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reviewer provides a reference to a related work, which supports the claim by suggesting a specific direction for analysis. This provides a clear rationale and logical reasoning for the claim, making it 4. However, the comment could be strengthened by including more detailed examples or specific data from the reference to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the RQ1 mentioned in the paper and suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance. It also proposes an exploration of how this affects RQ2 and RQ3 tsne plots. The comment provides a specific reference to a related work, which could guide the authors in conducting this analysis. While the comment identifies a clear area for improvement, it lacks detailed guidance on how to implement the suggested analysis or what specific aspects of the analysis should be considered. This limits the comment\"s helpfulness, as it provides a direction but not comprehensive instructions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network computing the value functions for the states during the finetuning stage. While the comment provides a clear action\u2014adding another head to the network\u2014it does not specify how to implement this addition or what specific changes are needed in the code or methodology. The authors are left to infer the details of execution, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the objective for the LSTM part, specifically mentioning the probabilities of actions and the finetuning stage. However, it does not specify which part of the paper this pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the objective and the potential approach for finetuning, but it lacks grounding as it does not explicitly mention where this information is discussed in the paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network during the finetuning stage. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the objective of the LSTM part, suggesting that it is the same for pretraining and finetuning. It also provides a possible solution by suggesting that the authors may add another head to the network during the finetuning stage to compute the value functions for the states. This feedback is 3 as it points out a potential weakness and offers a direction for improvement. However, it could be more helpful if it provided more detailed guidance on how to implement this suggestion or what specific changes are needed in the methodology. Overall, the comment offers some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge some of the older works related to supervised, multilingual systems. While the comment implies that the authors should include this acknowledgment, it does not provide specific guidance on which works to mention or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works related to supervised, multilingual systems, providing clear guidance on what needs to be addressed in this section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works related to supervised, multilingual systems. However, it does not provide specific examples or references to these older works, nor does it explain why acknowledging them is important. Without additional context or reasoning, the claim lacks verifiability, as it does not provide sufficient evidence or justification for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works related to supervised, multilingual systems. While it identifies a potential gap in the literature review, it does not provide specific examples of older works to consider or explain why acknowledging them would be beneficial. The comment is 3 as it points out an area for improvement, but it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling method, which appears to underperform uniform sampling. The reviewer points out that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their results. The authors are left to infer that they need to reconsider their sampling method or provide additional analysis to support their claims. While the comment highlights a potential issue, it lacks concrete instructions on how to resolve it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the results in Table 2, particularly the linear/exponentialdecay sampling method, which appears to underperform uniform sampling. The comment further explains the potential issue by suggesting that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the results in Table 2, specifically the linear/exponentialdecay sampling method, which appears to underperform uniform sampling. The reviewer argues that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is rather close. This claim is 3 as it provides a logical reasoning based on the assumption of predictor accuracy in the good subregion. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling method, which appears to underperform uniform sampling. The reviewer points out that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is rather close. This feedback highlights a potential issue with the results and suggests a possible explanation for the observed underperformance. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or what additional analyses could be conducted to support their claims. Overall, the comment identifies a potential weakness but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment requests that the authors provide a rationale for why their SE framework can help improve the system and how it manages to do so. It suggests that the authors should not just present their achievements but also explain the underlying reasons and mechanisms. The reviewer references a specific work, 1 Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not explicitly instruct the authors to use this reference or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of their approach and its benefits. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4\" and \"2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the rationale for why the SE framework can help improve the system and how it manages to do so. The reference to 1 Luo, et al. provides additional context and guidance for the authors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind the SE framework and requests a detailed explanation of how it can help improve the system. The reviewer references a specific work, 1 Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not provide any further explanation or justification for why this reference is relevant or how it relates to the current work. The lack of detailed reasoning or examples makes the claim 3, as the authors would need to infer the connection and provide additional context to fully address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of explanation for why the SE framework can help improve the system and how it manages to do so. It suggests that the authors should provide a detailed rationale and not just present their achievements. The reviewer references a specific work, 1 Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. This reference could be useful for the authors to consider in their response. However, the comment does not offer specific guidance on how to address this issue or what aspects of the framework should be explained. While it highlights an important area for improvement, the feedback could be more actionable and detailed. Therefore, the comment is 3, as it points out a critical area for improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. It notes that these metrics are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to adapt the metrics or suggest alternative approaches for evaluating continual learning in such settings. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the metrics used for evaluating continual learning, loss after switch, and recovery time after switch, which are key aspects of the paper. It also specifies the issue by pointing out that these metrics would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This claim is 3 as it provides a logical reasoning based on the nature of the metrics and their applicability to specific scenarios. However, it lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. It points out that these metrics are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This feedback highlights an important consideration for the applicability of the metrics in different contexts, which could impact the validity and relevance of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or adapt their metrics for different scenarios. While it raises an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It also mentions that this information cannot be computed accurately without the same runtime as required for ridge regression. The reviewer suggests that this issue is not discussed in the paper and raises a similar concern regarding the surrogate sketch. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to discuss this issue but are not given clear instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to debias the sketch and the statistical dimension d_lambda of the design matrix A, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of not being able to compute this dimension accurately without the same runtime as ridge regression, and raises a similar concern regarding the surrogate sketch. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statistical dimension d_lambda of the design matrix A cannot be computed accurately without the same runtime as required for ridge regression. The reviewer suggests that this issue could lead to bias and potentially defeat the purpose of the approach. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the comment does not provide enough detail to guide them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It points out that this information cannot be computed accurately without the same runtime as required for ridge regression, which could lead to bias and potentially defeat the purpose of the approach. The comment also notes that this issue is not discussed in the paper, which is a significant oversight. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or discuss it in the paper. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly points out the absence of an error analysis on the movie dataset and highlights the need for clarity on the cases where the model fails. This provides a clear and direct action for the authors to take, which is to include an error analysis in their draft. The comment is specific and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely an error analysis on the movie dataset, and why it is important for other researchers to understand the cases where the model fails. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the paper\"s contribution. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this omission. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the absence of an error analysis on the movie dataset. It highlights the importance of including this analysis for other researchers who may continue this work. However, the comment does not provide specific guidance on how to conduct the error analysis or what aspects should be covered. While it points out a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more detailed plan on how they intend to address the limitations mentioned in the paper. This is a clear and direct action that the authors can take to improve their draft. The comment is specific in its request for a detailed plan, which provides a concrete direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitations mentioned in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more detailed plan on how to address the limitations in future work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they intend to address the limitations mentioned in the paper. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide a more detailed plan on how they intend to address the limitations mentioned in the paper. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive approach to addressing the drawbacks. However, the comment could be more helpful if it offered specific suggestions on what aspects of the plan should be included or how to present it effectively. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison in their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FedMITR,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the amount of computation required for FedMITR compared to other methods, indicating a potential area for improvement or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment poses a question about the expected computation of FedMITR compared to other methods, suggesting that this might be an area for comparison. While it highlights a potential weakness or area for improvement, it does not provide specific guidance or suggestions on how to address this issue or what specific comparisons should be made. The comment is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it unclear whether this suggestion is being implemented. The comment provides a specific action\u2014using a generic external knowledge base\u2014but lacks concrete guidance on how to implement it or address the confusion in the writing. The authors are left with a clear action but without detailed instructions on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests avoiding \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, it acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment references \"1) and 2)\" and Figure 3, it does not specify which parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting the use of a generic external knowledge base, but without detailed guidance on how to address the confusion in the writing, it remains underspecific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using a generic external knowledge base (as shown in Figure 3) can avoid \"1) and 2)\" and that the writing is confusing. However, the comment lacks specific examples or detailed reasoning to support the claim that the external knowledge base would be beneficial or how it would address the confusion in the writing. Without additional context or evidence, the authors may find it challenging to understand and implement the suggestion. Therefore, the claim is considered 2, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as shown in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment provides a specific actionable suggestion, it lacks depth and does not offer detailed guidance on how to effectively implement the external knowledge base or address the confusion in the writing. The feedback is 3 as it points out a potential solution but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. Additionally, it notes that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. While the comment provides explicit guidance on what needs to be corrected, it does not offer specific suggestions on how to revise the definition or equation to ensure accuracy. The action is clear but lacks concrete details on how to implement the correction, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is incorrect about the definition of perplexity and the equation mentioned, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. The reviewer also notes that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the paper regarding the definition of perplexity, noting that it is not correctly defined. It also points out that the equation mentioned does not resemble perplexity but instead appears to be crossentropy. This feedback is clear and actionable, as it provides the authors with specific guidance on how to correct the errors in their work. By addressing these issues, the authors can improve the accuracy and clarity of their paper. However, the comment could be more helpful if it offered suggestions on how to revise the definition or equation to ensure correctness. Overall, the comment is 4 as it directs the authors to a critical area needing correction, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the documentation. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed information about the hyperparameters. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the model, noting that many components have hyperparameters that are not fully provided. This provides full grounding as it allows the authors to identify the part of the paper being discussed, which is the model components and their hyperparameters. However, the comment lacks specificity as it does not detail what specific hyperparameters are missing or how they should be addressed. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model, noting that many components have hyperparameters that are not fully provided. This is a clear and actionable observation, as it highlights a potential gap in the paper\"s documentation or explanation. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or improve the clarity of the model components. While it points out a relevant area for improvement, it does not offer detailed guidance or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific claim made by the authors on line 238, which is incorrect according to the Central Limit Theorem (CLT). It highlights that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment explicitly identifies the issue with the claim and provides a clear explanation of why it is incorrect. However, it does not offer any guidance on how the authors should address this issue or suggest alternative statements to correct the claim. The action is explicit but lacks concrete details on how to implement the correction, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made by the authors regarding the Central Limit Theorem (CLT) and why it is incorrect. The comment provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim made by the authors regarding the Central Limit Theorem (CLT) and its applicability to a finite linear combination of random variables. The reviewer provides a detailed explanation of why the claim is incorrect, citing specific aspects of the CLT that do not hold in a nonasymptotic regime. This logical reasoning and reference to established theory provide a strong basis for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the Central Limit Theorem (CLT) and its applicability to a finite linear combination of random variables. It points out that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it highlights a critical error in the authors\" understanding of the CLT. By correcting this mistake, the authors can improve the accuracy and rigor of their work. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue. Overall, the comment is 4 as it effectively guides the authors in correcting a significant error in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also points out that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. The reviewer suggests that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. While the comment identifies potential issues, it does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to improve the evaluation. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the relevance and effectiveness of their method in the context of scorebased evaluation systems. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also mentions the framework FFAEVAL and similar frameworks like Chatbot Arena, suggesting that these systems may not be suitable for evaluating a single dialogue system. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the relevance and effectiveness of the proposed method in the context of scorebased evaluation systems. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. The reviewer provides logical reasoning by explaining that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. However, the comment lacks specific examples or references to support the claim that these systems are not effective for evaluating single dialogue systems. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also points out that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. This feedback is 3 as it highlights a potential weakness in the methodology and suggests that the authors should reconsider the relevance and effectiveness of their method in the context of scorebased evaluation systems. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or what alternative methods might be more appropriate for evaluating single dialogue systems. Overall, the comment offers valuable insights but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTabase instead of BERT. While it does not explicitly instruct the authors to use RoBERTabase, the implication is clear that they should consider this option. The comment is 3 as it provides a concrete suggestion for improvement but lacks explicit guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"encoder\" and compares it to \"RoBERTabase,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the observed improvement could be achieved with a better encoder, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about the potential improvement in the observed results with a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. However, it does not provide any supporting evidence, reasoning, or references to justify why RoBERTabase might be a better choice or how it could lead to improved results. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the potential improvement in the observed results with a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. This is a relevant point that could prompt the authors to consider alternative models for their encoder, which could potentially enhance the performance of their system. However, the comment lacks depth and does not provide specific guidance or suggestions on how to implement this change or what specific aspects of the current encoder might be limiting its performance. While it points out a potential area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" While the action is implicit, it is clear that the authors need to provide a method for achieving fair policy learning without negatively impacting the predictive model\"s performance. However, the comment does not specify how to achieve this or what specific steps to take, leaving some ambiguity. Therefore, the comment is 3, as it provides a direction but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where this demonstration could be included. Without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it could be achieved. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" This feedback is 3 as it identifies a potential weakness in the paper, specifically the impact on predictive model performance when implementing fairness measures. However, the comment lacks specific guidance or examples on how to achieve this balance or what specific steps the authors should take to address this issue. While it points out an area for improvement, it does not provide detailed instructions or suggestions for improvement, making it 3 but not fully actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280. While the comment identifies a specific problem, it does not provide any guidance on how to address this issue. The authors are left to infer that they should consider revising or clarifying the phrase to improve clarity. However, the comment lacks explicit instructions or concrete suggestions on how to make these changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the pervasive use of the phrase \"to meet\" and how it affects clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. This feedback is clear and actionable, as it points out a specific area where the language could be improved for clarity. However, the comment could be more helpful if it provided suggestions on how to rephrase or clarify the phrase to enhance comprehension. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. While the comment identifies a specific area of concern, it does not provide explicit instructions on how to address this issue or what changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to make a correction but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Perceptual Metric should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the Perceptual Metric in Figure 2, noting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback is clear and actionable, as it points out a potential error in the experimental setup that the authors can correct to ensure the accuracy of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining why this distinction is important or offering guidance on how to implement the correction. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between Figures 1 and 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback implies that the authors should reconcile these figures to ensure consistency. However, the comment does not provide explicit instructions on how to address this issue, such as suggesting specific changes or clarifications. While the action is implied, it lacks concrete guidance on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the figures, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Fig 1 is inconsistent with Fig 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This claim is 3 as it highlights a discrepancy between the figures, but it lacks detailed explanation or justification for why this inconsistency is problematic or how it affects the paper\"s overall message. The authors might need to further investigate the implications of this inconsistency and determine if it requires correction or clarification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between Figures 1 and 2, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback highlights an inconsistency in the figures, which could impact the clarity and coherence of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending changes to the figures or explaining the rationale behind the discrepancy. While it points out a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several areas where the paper\"s main contribution is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to clarify the main contribution. The feedback is 3 as it highlights areas that need improvement, but it lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the main contribution of the paper, which is the proposed method\"s novel properties and how it copes with dynamic largescale multitasking. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issues with the clarity of the main contribution, such as overstated ability or applicability and unclear automation. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. The reviewer suggests that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or reasoning makes the claim 3, as the authors would need to make a significant effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s main contribution, which is the clarity of the proposed method\"s novel properties and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. This feedback is valuable as it highlights areas where the authors need to improve the clarity and substance of their work. However, the comment could be more helpful if it provided specific examples or suggestions on how to address these issues, such as by providing more detailed explanations or references to support the claims. Overall, the comment is 3 as it directs the authors\" attention to critical areas needing improvement, but it lacks detailed guidance for implementation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The authors are left to infer that they should consider these alternatives, but without specific guidance on how to integrate them into their work, the action remains vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in suggesting alternative approaches, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints. However, it does not provide any supporting evidence, reasoning, or references to justify why these alternatives might be more appealing or effective. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is not verifiable, and the authors may find it challenging to address the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. While these suggestions are interesting and could potentially improve the paper, the comment lacks specific guidance or examples on how to implement these alternatives. It does not provide detailed instructions or explain why these directions might be more effective or beneficial. As a result, the authors are left with a general idea of what to explore but without clear steps on how to integrate these suggestions into their work. Therefore, the comment is 3, as it points out potential areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these issues, such as suggesting additional teacher architectures or suggesting more recent methods to compare. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experiments and specifically mentions the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what is lacking in the experiments, such as the limited types of teacher architectures and the age of the compared methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient and that there are limited types of teacher architectures. It also mentions that most compared methods are proposed before 2019. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. While it highlights these areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The mention of a table suggests that the authors should refer to it for more information, but without further elaboration, the comment lacks depth and actionable advice. Therefore, the authors are left with a general understanding of the issues but without clear steps to improve their draft. This makes the comment 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. It suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their comparisons and ensure they are using the same amount of data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparisons made in the table, suggesting that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. The comment also points out that H>N>H and H>N>H use less data than H>N+B>H. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. The reviewer suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, the comment points out that H>N>H and H>N>H use less data than H>N+B>H. While the comment identifies potential issues with the comparisons, it lacks specific examples or references to support the claim that these comparisons are inappropriate. This makes the claim 3, as the authors would need to further explore and address the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparisons made in Table 2, questioning whether they are comparing apples to apples by using the same amount of data. It suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This feedback is clear and actionable, as it provides the authors with a concrete direction for improving the comparisons in their table. By addressing these issues, the authors can enhance the clarity and validity of their results. Therefore, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the practicality of the proposed work, specifically regarding the use of known causal relationships between features. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve the practicality of their work or what specific steps they could take to ensure the validity of their causal relationships. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the paper\"s proposal to use known causal relationships between features, noting that prior knowledge might not always be available or accurate for specific subpopulations. It raises a concern about the practicality of the work, which is relevant to the paper\"s focus on causal relationship mining from data automatically. However, the comment does not specify which part of the paper discusses this proposal or where the authors should address the concern. While the authors might infer that it relates to the methodology or results sections, the comment lacks explicit grounding. It is specific about the concern regarding practicality, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the proposed work relies on known causal relationships between features, which might not always be available or accurate for specific subpopulations. The reviewer supports this claim by noting that most researchers focus on mining causal relationships from data automatically. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3, as it requires more detailed support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s proposal, noting that the use of known causal relationships between features might not always be available or accurate for specific subpopulations. This is a relevant concern that could impact the practicality of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the practicality of their approach. While it highlights an important consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of polishing in figures and empirical results, which affects clarity and confidence in empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. However, the comment does not explicitly instruct the authors on how to address these issues or provide guidance on how to improve the clarity and polish of the figures and results. While the actions are implied, they are not stated directly, making the comment 3. The authors can infer that they need to improve the clarity and polish of their figures and results, but the lack of concrete guidance makes it somewhat challenging to implement the suggested improvements.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the figures and empirical results, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the lack of polishing in figures and empirical results, including missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks polishing in figures and empirical results, which affects clarity and confidence in empirical findings. The comment provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These examples provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have addressed these issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity and confidence in the empirical findings of the paper. It points out specific problems, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These observations highlight areas where the paper could be improved in terms of polish and presentation, which are crucial for ensuring the validity and impact of the results. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending specific improvements or examples of how similar studies have handled these challenges. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance on how to achieve them."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is a lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This implies that the authors should include these comparisons in Section 4.3 to showcase the unique advantages or potential shortcomings of their proposed method in a broader context. The action is clear and concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it suggests that including these comparisons would provide a broader context for the proposed method. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of these comparisons themselves, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback highlights the importance of including such comparisons to showcase the unique advantages or potential shortcomings of the proposed method in a broader context. By suggesting these comparisons, the comment provides clear and actionable guidance for the authors to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully included such comparisons. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be further enhanced with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit suggestions for how the authors should improve the discussion. There is no guidance on what aspects of the discussion need to be expanded or clarified, nor are there any concrete steps offered to enhance the explanation. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the discussion around equation (10) is terse and not clearly explained. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is \"very terse\" and not \"very clearly explained.\" However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is 3 as it points out a specific area that needs improvement, allowing the authors to focus on enhancing the clarity and depth of their discussion. However, the comment lacks detailed guidance or suggestions on how to improve the discussion, such as recommending specific ways to expand or clarify the explanation. While it highlights an area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, consistent with a score of 3."}
